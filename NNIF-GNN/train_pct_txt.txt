naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4138
Epoch [2/50] - Loss: 1.0580
Epoch [3/50] - Loss: 0.7746
Epoch [4/50] - Loss: 0.6107
Epoch [5/50] - Loss: 0.5451
Epoch [6/50] - Loss: 0.5409
Epoch [7/50] - Loss: 0.5371
Epoch [8/50] - Loss: 0.5134
Epoch [9/50] - Loss: 0.4865
Epoch [10/50] - Loss: 0.4407
Epoch [11/50] - Loss: 0.4072
Epoch [12/50] - Loss: 0.3731
Epoch [13/50] - Loss: 0.3468
Epoch [14/50] - Loss: 0.3341
Epoch [15/50] - Loss: 0.3266
Epoch [16/50] - Loss: 0.3189
Epoch [17/50] - Loss: 0.3043
Epoch [18/50] - Loss: 0.2958
Epoch [19/50] - Loss: 0.2742
Epoch [20/50] - Loss: 0.2593
Epoch [21/50] - Loss: 0.2480
Epoch [22/50] - Loss: 0.2364
Epoch [23/50] - Loss: 0.2258
Epoch [24/50] - Loss: 0.2161
Epoch [25/50] - Loss: 0.2077
Epoch [26/50] - Loss: 0.1956
Epoch [27/50] - Loss: 0.1881
Epoch [28/50] - Loss: 0.1819
Epoch [29/50] - Loss: 0.1773
Epoch [30/50] - Loss: 0.1715
Epoch [31/50] - Loss: 0.1639
Epoch [32/50] - Loss: 0.1617
Epoch [33/50] - Loss: 0.1566
Epoch [34/50] - Loss: 0.1497
Epoch [35/50] - Loss: 0.1480
Epoch [36/50] - Loss: 0.1474
Epoch [37/50] - Loss: 0.1439
Epoch [38/50] - Loss: 0.1384
Epoch [39/50] - Loss: 0.1382
Epoch [40/50] - Loss: 0.1353
Epoch [41/50] - Loss: 0.1337
Epoch [42/50] - Loss: 0.1318
Epoch [43/50] - Loss: 0.1325
Epoch [44/50] - Loss: 0.1291
Epoch [45/50] - Loss: 0.1275
Epoch [46/50] - Loss: 0.1268
Epoch [47/50] - Loss: 0.1263
Epoch [48/50] - Loss: 0.1220
Epoch [49/50] - Loss: 0.1233
Epoch [50/50] - Loss: 0.1239
sum preds 12
sum labels 421
 - Test Metrics: Accuracy=0.8651, F1=0.0508, Recall=0.0261, Precision=0.9167
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1774
Epoch [2/50] - Loss: 0.8969
Epoch [3/50] - Loss: 0.6962
Epoch [4/50] - Loss: 0.5844
Epoch [5/50] - Loss: 0.5369
Epoch [6/50] - Loss: 0.5358
Epoch [7/50] - Loss: 0.5109
Epoch [8/50] - Loss: 0.5038
Epoch [9/50] - Loss: 0.4695
Epoch [10/50] - Loss: 0.4369
Epoch [11/50] - Loss: 0.3965
Epoch [12/50] - Loss: 0.3663
Epoch [13/50] - Loss: 0.3536
Epoch [14/50] - Loss: 0.3416
Epoch [15/50] - Loss: 0.3295
Epoch [16/50] - Loss: 0.3176
Epoch [17/50] - Loss: 0.3119
Epoch [18/50] - Loss: 0.2927
Epoch [19/50] - Loss: 0.2809
Epoch [20/50] - Loss: 0.2655
Epoch [21/50] - Loss: 0.2577
Epoch [22/50] - Loss: 0.2435
Epoch [23/50] - Loss: 0.2350
Epoch [24/50] - Loss: 0.2232
Epoch [25/50] - Loss: 0.2187
Epoch [26/50] - Loss: 0.2105
Epoch [27/50] - Loss: 0.2042
Epoch [28/50] - Loss: 0.1945
Epoch [29/50] - Loss: 0.1891
Epoch [30/50] - Loss: 0.1832
Epoch [31/50] - Loss: 0.1802
Epoch [32/50] - Loss: 0.1777
Epoch [33/50] - Loss: 0.1718
Epoch [34/50] - Loss: 0.1668
Epoch [35/50] - Loss: 0.1686
Epoch [36/50] - Loss: 0.1641
Epoch [37/50] - Loss: 0.1615
Epoch [38/50] - Loss: 0.1582
Epoch [39/50] - Loss: 0.1558
Epoch [40/50] - Loss: 0.1553
Epoch [41/50] - Loss: 0.1531
Epoch [42/50] - Loss: 0.1515
Epoch [43/50] - Loss: 0.1447
Epoch [44/50] - Loss: 0.1482
Epoch [45/50] - Loss: 0.1408
Epoch [46/50] - Loss: 0.1445
Epoch [47/50] - Loss: 0.1394
Epoch [48/50] - Loss: 0.1336
Epoch [49/50] - Loss: 0.1283
Epoch [50/50] - Loss: 0.1265
sum preds 12
sum labels 421
 - Test Metrics: Accuracy=0.8651, F1=0.0508, Recall=0.0261, Precision=0.9167
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4636
Epoch [2/50] - Loss: 1.1642
Epoch [3/50] - Loss: 0.8914
Epoch [4/50] - Loss: 0.6937
Epoch [5/50] - Loss: 0.5841
Epoch [6/50] - Loss: 0.5568
Epoch [7/50] - Loss: 0.5567
Epoch [8/50] - Loss: 0.5580
Epoch [9/50] - Loss: 0.5329
Epoch [10/50] - Loss: 0.5036
Epoch [11/50] - Loss: 0.4702
Epoch [12/50] - Loss: 0.4289
Epoch [13/50] - Loss: 0.4028
Epoch [14/50] - Loss: 0.3732
Epoch [15/50] - Loss: 0.3528
Epoch [16/50] - Loss: 0.3388
Epoch [17/50] - Loss: 0.3352
Epoch [18/50] - Loss: 0.3218
Epoch [19/50] - Loss: 0.3085
Epoch [20/50] - Loss: 0.2957
Epoch [21/50] - Loss: 0.2822
Epoch [22/50] - Loss: 0.2705
Epoch [23/50] - Loss: 0.2517
Epoch [24/50] - Loss: 0.2405
Epoch [25/50] - Loss: 0.2318
Epoch [26/50] - Loss: 0.2211
Epoch [27/50] - Loss: 0.2135
Epoch [28/50] - Loss: 0.2079
Epoch [29/50] - Loss: 0.2009
Epoch [30/50] - Loss: 0.1919
Epoch [31/50] - Loss: 0.1874
Epoch [32/50] - Loss: 0.1766
Epoch [33/50] - Loss: 0.1746
Epoch [34/50] - Loss: 0.1679
Epoch [35/50] - Loss: 0.1629
Epoch [36/50] - Loss: 0.1571
Epoch [37/50] - Loss: 0.1550
Epoch [38/50] - Loss: 0.1525
Epoch [39/50] - Loss: 0.1494
Epoch [40/50] - Loss: 0.1460
Epoch [41/50] - Loss: 0.1420
Epoch [42/50] - Loss: 0.1392
Epoch [43/50] - Loss: 0.1396
Epoch [44/50] - Loss: 0.1334
Epoch [45/50] - Loss: 0.1313
Epoch [46/50] - Loss: 0.1315
Epoch [47/50] - Loss: 0.1317
Epoch [48/50] - Loss: 0.1280
Epoch [49/50] - Loss: 0.1286
Epoch [50/50] - Loss: 0.1279
sum preds 8
sum labels 421
 - Test Metrics: Accuracy=0.8645, F1=0.0373, Recall=0.0190, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_naive_naive_1804082149.csv.
Average F1 over valid seeds: 0.0463 ± 0.0064
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and naive, MLP,0.4: 0.0463 ± 0.0064
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2501
Epoch [2/50] - Loss: 0.7461
Epoch [3/50] - Loss: 0.5634
Epoch [4/50] - Loss: 0.5458
Epoch [5/50] - Loss: 0.5437
Epoch [6/50] - Loss: 0.5279
Epoch [7/50] - Loss: 0.4862
Epoch [8/50] - Loss: 0.4479
Epoch [9/50] - Loss: 0.4113
Epoch [10/50] - Loss: 0.3780
Epoch [11/50] - Loss: 0.3694
Epoch [12/50] - Loss: 0.3596
Epoch [13/50] - Loss: 0.3615
Epoch [14/50] - Loss: 0.3529
Epoch [15/50] - Loss: 0.3452
Epoch [16/50] - Loss: 0.3373
Epoch [17/50] - Loss: 0.3236
Epoch [18/50] - Loss: 0.3158
Epoch [19/50] - Loss: 0.3125
Epoch [20/50] - Loss: 0.2995
Epoch [21/50] - Loss: 0.2916
Epoch [22/50] - Loss: 0.2908
Epoch [23/50] - Loss: 0.2822
Epoch [24/50] - Loss: 0.2777
Epoch [25/50] - Loss: 0.2700
Epoch [26/50] - Loss: 0.2671
Epoch [27/50] - Loss: 0.2603
Epoch [28/50] - Loss: 0.2596
Epoch [29/50] - Loss: 0.2599
Epoch [30/50] - Loss: 0.2542
Epoch [31/50] - Loss: 0.2525
Epoch [32/50] - Loss: 0.2472
Epoch [33/50] - Loss: 0.2463
Epoch [34/50] - Loss: 0.2414
Epoch [35/50] - Loss: 0.2413
Epoch [36/50] - Loss: 0.2400
Epoch [37/50] - Loss: 0.2376
Epoch [38/50] - Loss: 0.2324
Epoch [39/50] - Loss: 0.2347
Epoch [40/50] - Loss: 0.2274
Epoch [41/50] - Loss: 0.2284
Epoch [42/50] - Loss: 0.2282
Epoch [43/50] - Loss: 0.2279
Epoch [44/50] - Loss: 0.2242
Epoch [45/50] - Loss: 0.2185
Epoch [46/50] - Loss: 0.2215
Epoch [47/50] - Loss: 0.2136
Epoch [48/50] - Loss: 0.2238
Epoch [49/50] - Loss: 0.2184
Epoch [50/50] - Loss: 0.2118
sum preds 68
sum labels 421
 - Test Metrics: Accuracy=0.8756, F1=0.2249, Recall=0.1306, Precision=0.8088
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1036
Epoch [2/50] - Loss: 0.5957
Epoch [3/50] - Loss: 0.5527
Epoch [4/50] - Loss: 0.5437
Epoch [5/50] - Loss: 0.4953
Epoch [6/50] - Loss: 0.4373
Epoch [7/50] - Loss: 0.3893
Epoch [8/50] - Loss: 0.3545
Epoch [9/50] - Loss: 0.3543
Epoch [10/50] - Loss: 0.3517
Epoch [11/50] - Loss: 0.3486
Epoch [12/50] - Loss: 0.3360
Epoch [13/50] - Loss: 0.3225
Epoch [14/50] - Loss: 0.3113
Epoch [15/50] - Loss: 0.2963
Epoch [16/50] - Loss: 0.2931
Epoch [17/50] - Loss: 0.2863
Epoch [18/50] - Loss: 0.2802
Epoch [19/50] - Loss: 0.2726
Epoch [20/50] - Loss: 0.2682
Epoch [21/50] - Loss: 0.2611
Epoch [22/50] - Loss: 0.2540
Epoch [23/50] - Loss: 0.2528
Epoch [24/50] - Loss: 0.2432
Epoch [25/50] - Loss: 0.2390
Epoch [26/50] - Loss: 0.2365
Epoch [27/50] - Loss: 0.2300
Epoch [28/50] - Loss: 0.2281
Epoch [29/50] - Loss: 0.2234
Epoch [30/50] - Loss: 0.2140
Epoch [31/50] - Loss: 0.2127
Epoch [32/50] - Loss: 0.2063
Epoch [33/50] - Loss: 0.2095
Epoch [34/50] - Loss: 0.2032
Epoch [35/50] - Loss: 0.2011
Epoch [36/50] - Loss: 0.1966
Epoch [37/50] - Loss: 0.1975
Epoch [38/50] - Loss: 0.1933
Epoch [39/50] - Loss: 0.1818
Epoch [40/50] - Loss: 0.1853
Epoch [41/50] - Loss: 0.1800
Epoch [42/50] - Loss: 0.1807
Epoch [43/50] - Loss: 0.1819
Epoch [44/50] - Loss: 0.1713
Epoch [45/50] - Loss: 0.1739
Epoch [46/50] - Loss: 0.1708
Epoch [47/50] - Loss: 0.1633
Epoch [48/50] - Loss: 0.1634
Epoch [49/50] - Loss: 0.1655
Epoch [50/50] - Loss: 0.1614
sum preds 49
sum labels 421
 - Test Metrics: Accuracy=0.8707, F1=0.1617, Recall=0.0903, Precision=0.7755
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1723
Epoch [2/50] - Loss: 0.6740
Epoch [3/50] - Loss: 0.5586
Epoch [4/50] - Loss: 0.5480
Epoch [5/50] - Loss: 0.5491
Epoch [6/50] - Loss: 0.5132
Epoch [7/50] - Loss: 0.4673
Epoch [8/50] - Loss: 0.4135
Epoch [9/50] - Loss: 0.3825
Epoch [10/50] - Loss: 0.3692
Epoch [11/50] - Loss: 0.3630
Epoch [12/50] - Loss: 0.3602
Epoch [13/50] - Loss: 0.3538
Epoch [14/50] - Loss: 0.3450
Epoch [15/50] - Loss: 0.3363
Epoch [16/50] - Loss: 0.3226
Epoch [17/50] - Loss: 0.3147
Epoch [18/50] - Loss: 0.3061
Epoch [19/50] - Loss: 0.3148
Epoch [20/50] - Loss: 0.2998
Epoch [21/50] - Loss: 0.2961
Epoch [22/50] - Loss: 0.2858
Epoch [23/50] - Loss: 0.2878
Epoch [24/50] - Loss: 0.2759
Epoch [25/50] - Loss: 0.2822
Epoch [26/50] - Loss: 0.2746
Epoch [27/50] - Loss: 0.2690
Epoch [28/50] - Loss: 0.2647
Epoch [29/50] - Loss: 0.2651
Epoch [30/50] - Loss: 0.2559
Epoch [31/50] - Loss: 0.2597
Epoch [32/50] - Loss: 0.2515
Epoch [33/50] - Loss: 0.2529
Epoch [34/50] - Loss: 0.2486
Epoch [35/50] - Loss: 0.2450
Epoch [36/50] - Loss: 0.2434
Epoch [37/50] - Loss: 0.2446
Epoch [38/50] - Loss: 0.2400
Epoch [39/50] - Loss: 0.2408
Epoch [40/50] - Loss: 0.2346
Epoch [41/50] - Loss: 0.2329
Epoch [42/50] - Loss: 0.2315
Epoch [43/50] - Loss: 0.2298
Epoch [44/50] - Loss: 0.2230
Epoch [45/50] - Loss: 0.2256
Epoch [46/50] - Loss: 0.2227
Epoch [47/50] - Loss: 0.2160
Epoch [48/50] - Loss: 0.2135
Epoch [49/50] - Loss: 0.2147
Epoch [50/50] - Loss: 0.2067
sum preds 68
sum labels 421
 - Test Metrics: Accuracy=0.8776, F1=0.2372, Recall=0.1378, Precision=0.8529
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_naive_naive_1804082237.csv.
Average F1 over valid seeds: 0.2080 ± 0.0331
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and naive, GATConv,0.4: 0.2080 ± 0.0331
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2702
Epoch [2/50] - Loss: 0.7854
Epoch [3/50] - Loss: 0.5968
Epoch [4/50] - Loss: 0.5587
Epoch [5/50] - Loss: 0.5554
Epoch [6/50] - Loss: 0.5448
Epoch [7/50] - Loss: 0.5065
Epoch [8/50] - Loss: 0.4770
Epoch [9/50] - Loss: 0.4244
Epoch [10/50] - Loss: 0.3972
Epoch [11/50] - Loss: 0.3800
Epoch [12/50] - Loss: 0.3744
Epoch [13/50] - Loss: 0.3680
Epoch [14/50] - Loss: 0.3683
Epoch [15/50] - Loss: 0.3605
Epoch [16/50] - Loss: 0.3570
Epoch [17/50] - Loss: 0.3446
Epoch [18/50] - Loss: 0.3393
Epoch [19/50] - Loss: 0.3310
Epoch [20/50] - Loss: 0.3291
Epoch [21/50] - Loss: 0.3246
Epoch [22/50] - Loss: 0.3180
Epoch [23/50] - Loss: 0.3164
Epoch [24/50] - Loss: 0.3082
Epoch [25/50] - Loss: 0.3022
Epoch [26/50] - Loss: 0.3038
Epoch [27/50] - Loss: 0.2955
Epoch [28/50] - Loss: 0.2941
Epoch [29/50] - Loss: 0.2919
Epoch [30/50] - Loss: 0.2900
Epoch [31/50] - Loss: 0.2890
Epoch [32/50] - Loss: 0.2860
Epoch [33/50] - Loss: 0.2855
Epoch [34/50] - Loss: 0.2821
Epoch [35/50] - Loss: 0.2775
Epoch [36/50] - Loss: 0.2798
Epoch [37/50] - Loss: 0.2745
Epoch [38/50] - Loss: 0.2716
Epoch [39/50] - Loss: 0.2745
Epoch [40/50] - Loss: 0.2715
Epoch [41/50] - Loss: 0.2723
Epoch [42/50] - Loss: 0.2690
Epoch [43/50] - Loss: 0.2624
Epoch [44/50] - Loss: 0.2628
Epoch [45/50] - Loss: 0.2620
Epoch [46/50] - Loss: 0.2623
Epoch [47/50] - Loss: 0.2623
Epoch [48/50] - Loss: 0.2562
Epoch [49/50] - Loss: 0.2621
Epoch [50/50] - Loss: 0.2585
sum preds 0
sum labels 421
 - Test Metrics: Accuracy=0.8618, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0391
Epoch [2/50] - Loss: 0.5884
Epoch [3/50] - Loss: 0.5805
Epoch [4/50] - Loss: 0.5468
Epoch [5/50] - Loss: 0.4645
Epoch [6/50] - Loss: 0.4011
Epoch [7/50] - Loss: 0.3682
Epoch [8/50] - Loss: 0.3649
Epoch [9/50] - Loss: 0.3696
Epoch [10/50] - Loss: 0.3659
Epoch [11/50] - Loss: 0.3537
Epoch [12/50] - Loss: 0.3436
Epoch [13/50] - Loss: 0.3270
Epoch [14/50] - Loss: 0.3195
Epoch [15/50] - Loss: 0.3166
Epoch [16/50] - Loss: 0.3139
Epoch [17/50] - Loss: 0.3104
Epoch [18/50] - Loss: 0.3059
Epoch [19/50] - Loss: 0.2999
Epoch [20/50] - Loss: 0.2955
Epoch [21/50] - Loss: 0.2942
Epoch [22/50] - Loss: 0.2869
Epoch [23/50] - Loss: 0.2854
Epoch [24/50] - Loss: 0.2875
Epoch [25/50] - Loss: 0.2819
Epoch [26/50] - Loss: 0.2795
Epoch [27/50] - Loss: 0.2779
Epoch [28/50] - Loss: 0.2797
Epoch [29/50] - Loss: 0.2718
Epoch [30/50] - Loss: 0.2732
Epoch [31/50] - Loss: 0.2721
Epoch [32/50] - Loss: 0.2676
Epoch [33/50] - Loss: 0.2673
Epoch [34/50] - Loss: 0.2634
Epoch [35/50] - Loss: 0.2654
Epoch [36/50] - Loss: 0.2644
Epoch [37/50] - Loss: 0.2652
Epoch [38/50] - Loss: 0.2644
Epoch [39/50] - Loss: 0.2617
Epoch [40/50] - Loss: 0.2600
Epoch [41/50] - Loss: 0.2590
Epoch [42/50] - Loss: 0.2550
Epoch [43/50] - Loss: 0.2575
Epoch [44/50] - Loss: 0.2558
Epoch [45/50] - Loss: 0.2550
Epoch [46/50] - Loss: 0.2504
Epoch [47/50] - Loss: 0.2539
Epoch [48/50] - Loss: 0.2510
Epoch [49/50] - Loss: 0.2500
Epoch [50/50] - Loss: 0.2547
sum preds 55
sum labels 421
 - Test Metrics: Accuracy=0.8779, F1=0.2185, Recall=0.1235, Precision=0.9455
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1284
Epoch [2/50] - Loss: 0.6269
Epoch [3/50] - Loss: 0.5605
Epoch [4/50] - Loss: 0.5793
Epoch [5/50] - Loss: 0.5469
Epoch [6/50] - Loss: 0.4772
Epoch [7/50] - Loss: 0.4198
Epoch [8/50] - Loss: 0.3782
Epoch [9/50] - Loss: 0.3736
Epoch [10/50] - Loss: 0.3729
Epoch [11/50] - Loss: 0.3763
Epoch [12/50] - Loss: 0.3659
Epoch [13/50] - Loss: 0.3487
Epoch [14/50] - Loss: 0.3407
Epoch [15/50] - Loss: 0.3315
Epoch [16/50] - Loss: 0.3297
Epoch [17/50] - Loss: 0.3191
Epoch [18/50] - Loss: 0.3218
Epoch [19/50] - Loss: 0.3149
Epoch [20/50] - Loss: 0.3088
Epoch [21/50] - Loss: 0.3048
Epoch [22/50] - Loss: 0.3023
Epoch [23/50] - Loss: 0.2996
Epoch [24/50] - Loss: 0.2932
Epoch [25/50] - Loss: 0.2924
Epoch [26/50] - Loss: 0.2810
Epoch [27/50] - Loss: 0.2824
Epoch [28/50] - Loss: 0.2793
Epoch [29/50] - Loss: 0.2795
Epoch [30/50] - Loss: 0.2793
Epoch [31/50] - Loss: 0.2761
Epoch [32/50] - Loss: 0.2736
Epoch [33/50] - Loss: 0.2753
Epoch [34/50] - Loss: 0.2678
Epoch [35/50] - Loss: 0.2689
Epoch [36/50] - Loss: 0.2671
Epoch [37/50] - Loss: 0.2689
Epoch [38/50] - Loss: 0.2621
Epoch [39/50] - Loss: 0.2637
Epoch [40/50] - Loss: 0.2631
Epoch [41/50] - Loss: 0.2630
Epoch [42/50] - Loss: 0.2620
Epoch [43/50] - Loss: 0.2594
Epoch [44/50] - Loss: 0.2586
Epoch [45/50] - Loss: 0.2596
Epoch [46/50] - Loss: 0.2616
Epoch [47/50] - Loss: 0.2543
Epoch [48/50] - Loss: 0.2624
Epoch [49/50] - Loss: 0.2547
Epoch [50/50] - Loss: 0.2572
sum preds 40
sum labels 421
 - Test Metrics: Accuracy=0.8723, F1=0.1562, Recall=0.0855, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_naive_naive_1804082329.csv.
Average F1 over valid seeds: 0.1249 ± 0.0919
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and naive, GCNConv,0.4: 0.1249 ± 0.0919
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4147
Epoch [2/50] - Loss: 1.0386
Epoch [3/50] - Loss: 0.7333
Epoch [4/50] - Loss: 0.5438
Epoch [5/50] - Loss: 0.4638
Epoch [6/50] - Loss: 0.4552
Epoch [7/50] - Loss: 0.4630
Epoch [8/50] - Loss: 0.4516
Epoch [9/50] - Loss: 0.4413
Epoch [10/50] - Loss: 0.4029
Epoch [11/50] - Loss: 0.3802
Epoch [12/50] - Loss: 0.3456
Epoch [13/50] - Loss: 0.3162
Epoch [14/50] - Loss: 0.2922
Epoch [15/50] - Loss: 0.2792
Epoch [16/50] - Loss: 0.2713
Epoch [17/50] - Loss: 0.2592
Epoch [18/50] - Loss: 0.2564
Epoch [19/50] - Loss: 0.2409
Epoch [20/50] - Loss: 0.2297
Epoch [21/50] - Loss: 0.2175
Epoch [22/50] - Loss: 0.2039
Epoch [23/50] - Loss: 0.1939
Epoch [24/50] - Loss: 0.1845
Epoch [25/50] - Loss: 0.1754
Epoch [26/50] - Loss: 0.1657
Epoch [27/50] - Loss: 0.1567
Epoch [28/50] - Loss: 0.1505
Epoch [29/50] - Loss: 0.1450
Epoch [30/50] - Loss: 0.1391
Epoch [31/50] - Loss: 0.1328
Epoch [32/50] - Loss: 0.1296
Epoch [33/50] - Loss: 0.1258
Epoch [34/50] - Loss: 0.1201
Epoch [35/50] - Loss: 0.1171
Epoch [36/50] - Loss: 0.1161
Epoch [37/50] - Loss: 0.1129
Epoch [38/50] - Loss: 0.1085
Epoch [39/50] - Loss: 0.1075
Epoch [40/50] - Loss: 0.1057
Epoch [41/50] - Loss: 0.1042
Epoch [42/50] - Loss: 0.1016
Epoch [43/50] - Loss: 0.1021
Epoch [44/50] - Loss: 0.0996
Epoch [45/50] - Loss: 0.0987
Epoch [46/50] - Loss: 0.0969
Epoch [47/50] - Loss: 0.0973
Epoch [48/50] - Loss: 0.0941
Epoch [49/50] - Loss: 0.0953
Epoch [50/50] - Loss: 0.0960
sum preds 2
sum labels 491
 - Test Metrics: Accuracy=0.8431, F1=0.0081, Recall=0.0041, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1657
Epoch [2/50] - Loss: 0.8644
Epoch [3/50] - Loss: 0.6434
Epoch [4/50] - Loss: 0.5145
Epoch [5/50] - Loss: 0.4586
Epoch [6/50] - Loss: 0.4543
Epoch [7/50] - Loss: 0.4343
Epoch [8/50] - Loss: 0.4401
Epoch [9/50] - Loss: 0.4205
Epoch [10/50] - Loss: 0.3982
Epoch [11/50] - Loss: 0.3617
Epoch [12/50] - Loss: 0.3303
Epoch [13/50] - Loss: 0.3122
Epoch [14/50] - Loss: 0.2927
Epoch [15/50] - Loss: 0.2804
Epoch [16/50] - Loss: 0.2671
Epoch [17/50] - Loss: 0.2640
Epoch [18/50] - Loss: 0.2504
Epoch [19/50] - Loss: 0.2420
Epoch [20/50] - Loss: 0.2313
Epoch [21/50] - Loss: 0.2229
Epoch [22/50] - Loss: 0.2071
Epoch [23/50] - Loss: 0.1986
Epoch [24/50] - Loss: 0.1873
Epoch [25/50] - Loss: 0.1806
Epoch [26/50] - Loss: 0.1723
Epoch [27/50] - Loss: 0.1662
Epoch [28/50] - Loss: 0.1583
Epoch [29/50] - Loss: 0.1534
Epoch [30/50] - Loss: 0.1479
Epoch [31/50] - Loss: 0.1443
Epoch [32/50] - Loss: 0.1415
Epoch [33/50] - Loss: 0.1362
Epoch [34/50] - Loss: 0.1308
Epoch [35/50] - Loss: 0.1330
Epoch [36/50] - Loss: 0.1289
Epoch [37/50] - Loss: 0.1265
Epoch [38/50] - Loss: 0.1244
Epoch [39/50] - Loss: 0.1212
Epoch [40/50] - Loss: 0.1213
Epoch [41/50] - Loss: 0.1189
Epoch [42/50] - Loss: 0.1168
Epoch [43/50] - Loss: 0.1132
Epoch [44/50] - Loss: 0.1157
Epoch [45/50] - Loss: 0.1107
Epoch [46/50] - Loss: 0.1143
Epoch [47/50] - Loss: 0.1113
Epoch [48/50] - Loss: 0.1063
Epoch [49/50] - Loss: 0.1045
Epoch [50/50] - Loss: 0.1057
sum preds 1
sum labels 491
 - Test Metrics: Accuracy=0.8428, F1=0.0041, Recall=0.0020, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4670
Epoch [2/50] - Loss: 1.1517
Epoch [3/50] - Loss: 0.8599
Epoch [4/50] - Loss: 0.6419
Epoch [5/50] - Loss: 0.5139
Epoch [6/50] - Loss: 0.4669
Epoch [7/50] - Loss: 0.4638
Epoch [8/50] - Loss: 0.4662
Epoch [9/50] - Loss: 0.4550
Epoch [10/50] - Loss: 0.4397
Epoch [11/50] - Loss: 0.4197
Epoch [12/50] - Loss: 0.3875
Epoch [13/50] - Loss: 0.3603
Epoch [14/50] - Loss: 0.3334
Epoch [15/50] - Loss: 0.3027
Epoch [16/50] - Loss: 0.2838
Epoch [17/50] - Loss: 0.2766
Epoch [18/50] - Loss: 0.2654
Epoch [19/50] - Loss: 0.2578
Epoch [20/50] - Loss: 0.2494
Epoch [21/50] - Loss: 0.2415
Epoch [22/50] - Loss: 0.2336
Epoch [23/50] - Loss: 0.2178
Epoch [24/50] - Loss: 0.2046
Epoch [25/50] - Loss: 0.1952
Epoch [26/50] - Loss: 0.1843
Epoch [27/50] - Loss: 0.1787
Epoch [28/50] - Loss: 0.1715
Epoch [29/50] - Loss: 0.1683
Epoch [30/50] - Loss: 0.1580
Epoch [31/50] - Loss: 0.1541
Epoch [32/50] - Loss: 0.1445
Epoch [33/50] - Loss: 0.1415
Epoch [34/50] - Loss: 0.1358
Epoch [35/50] - Loss: 0.1306
Epoch [36/50] - Loss: 0.1268
Epoch [37/50] - Loss: 0.1262
Epoch [38/50] - Loss: 0.1222
Epoch [39/50] - Loss: 0.1193
Epoch [40/50] - Loss: 0.1166
Epoch [41/50] - Loss: 0.1121
Epoch [42/50] - Loss: 0.1111
Epoch [43/50] - Loss: 0.1107
Epoch [44/50] - Loss: 0.1060
Epoch [45/50] - Loss: 0.1037
Epoch [46/50] - Loss: 0.1035
Epoch [47/50] - Loss: 0.1036
Epoch [48/50] - Loss: 0.1009
Epoch [49/50] - Loss: 0.1014
Epoch [50/50] - Loss: 0.1002
sum preds 2
sum labels 491
 - Test Metrics: Accuracy=0.8431, F1=0.0081, Recall=0.0041, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_naive_naive_1804082421.csv.
Average F1 over valid seeds: 0.0068 ± 0.0019
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and naive, MLP,0.3: 0.0068 ± 0.0019
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2419
Epoch [2/50] - Loss: 0.6976
Epoch [3/50] - Loss: 0.4876
Epoch [4/50] - Loss: 0.4563
Epoch [5/50] - Loss: 0.4612
Epoch [6/50] - Loss: 0.4684
Epoch [7/50] - Loss: 0.4455
Epoch [8/50] - Loss: 0.4223
Epoch [9/50] - Loss: 0.3935
Epoch [10/50] - Loss: 0.3519
Epoch [11/50] - Loss: 0.3336
Epoch [12/50] - Loss: 0.3137
Epoch [13/50] - Loss: 0.3115
Epoch [14/50] - Loss: 0.3041
Epoch [15/50] - Loss: 0.3046
Epoch [16/50] - Loss: 0.3035
Epoch [17/50] - Loss: 0.2919
Epoch [18/50] - Loss: 0.2823
Epoch [19/50] - Loss: 0.2769
Epoch [20/50] - Loss: 0.2642
Epoch [21/50] - Loss: 0.2549
Epoch [22/50] - Loss: 0.2529
Epoch [23/50] - Loss: 0.2458
Epoch [24/50] - Loss: 0.2401
Epoch [25/50] - Loss: 0.2355
Epoch [26/50] - Loss: 0.2310
Epoch [27/50] - Loss: 0.2237
Epoch [28/50] - Loss: 0.2216
Epoch [29/50] - Loss: 0.2203
Epoch [30/50] - Loss: 0.2170
Epoch [31/50] - Loss: 0.2126
Epoch [32/50] - Loss: 0.2090
Epoch [33/50] - Loss: 0.2078
Epoch [34/50] - Loss: 0.2054
Epoch [35/50] - Loss: 0.2045
Epoch [36/50] - Loss: 0.1991
Epoch [37/50] - Loss: 0.2003
Epoch [38/50] - Loss: 0.1922
Epoch [39/50] - Loss: 0.1943
Epoch [40/50] - Loss: 0.1869
Epoch [41/50] - Loss: 0.1890
Epoch [42/50] - Loss: 0.1893
Epoch [43/50] - Loss: 0.1899
Epoch [44/50] - Loss: 0.1849
Epoch [45/50] - Loss: 0.1793
Epoch [46/50] - Loss: 0.1824
Epoch [47/50] - Loss: 0.1766
Epoch [48/50] - Loss: 0.1786
Epoch [49/50] - Loss: 0.1723
Epoch [50/50] - Loss: 0.1694
sum preds 15
sum labels 491
 - Test Metrics: Accuracy=0.8460, F1=0.0514, Recall=0.0265, Precision=0.8667
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0860
Epoch [2/50] - Loss: 0.5250
Epoch [3/50] - Loss: 0.4647
Epoch [4/50] - Loss: 0.4801
Epoch [5/50] - Loss: 0.4702
Epoch [6/50] - Loss: 0.4327
Epoch [7/50] - Loss: 0.3897
Epoch [8/50] - Loss: 0.3286
Epoch [9/50] - Loss: 0.3071
Epoch [10/50] - Loss: 0.3033
Epoch [11/50] - Loss: 0.3059
Epoch [12/50] - Loss: 0.2996
Epoch [13/50] - Loss: 0.2901
Epoch [14/50] - Loss: 0.2795
Epoch [15/50] - Loss: 0.2615
Epoch [16/50] - Loss: 0.2577
Epoch [17/50] - Loss: 0.2489
Epoch [18/50] - Loss: 0.2442
Epoch [19/50] - Loss: 0.2419
Epoch [20/50] - Loss: 0.2392
Epoch [21/50] - Loss: 0.2291
Epoch [22/50] - Loss: 0.2244
Epoch [23/50] - Loss: 0.2223
Epoch [24/50] - Loss: 0.2126
Epoch [25/50] - Loss: 0.2107
Epoch [26/50] - Loss: 0.2085
Epoch [27/50] - Loss: 0.2025
Epoch [28/50] - Loss: 0.1992
Epoch [29/50] - Loss: 0.1987
Epoch [30/50] - Loss: 0.1894
Epoch [31/50] - Loss: 0.1866
Epoch [32/50] - Loss: 0.1819
Epoch [33/50] - Loss: 0.1787
Epoch [34/50] - Loss: 0.1768
Epoch [35/50] - Loss: 0.1749
Epoch [36/50] - Loss: 0.1697
Epoch [37/50] - Loss: 0.1682
Epoch [38/50] - Loss: 0.1659
Epoch [39/50] - Loss: 0.1596
Epoch [40/50] - Loss: 0.1587
Epoch [41/50] - Loss: 0.1555
Epoch [42/50] - Loss: 0.1543
Epoch [43/50] - Loss: 0.1501
Epoch [44/50] - Loss: 0.1465
Epoch [45/50] - Loss: 0.1498
Epoch [46/50] - Loss: 0.1456
Epoch [47/50] - Loss: 0.1344
Epoch [48/50] - Loss: 0.1403
Epoch [49/50] - Loss: 0.1429
Epoch [50/50] - Loss: 0.1357
sum preds 37
sum labels 491
 - Test Metrics: Accuracy=0.8460, F1=0.0909, Recall=0.0489, Precision=0.6486
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1580
Epoch [2/50] - Loss: 0.6167
Epoch [3/50] - Loss: 0.4671
Epoch [4/50] - Loss: 0.4566
Epoch [5/50] - Loss: 0.4713
Epoch [6/50] - Loss: 0.4531
Epoch [7/50] - Loss: 0.4317
Epoch [8/50] - Loss: 0.3866
Epoch [9/50] - Loss: 0.3492
Epoch [10/50] - Loss: 0.3218
Epoch [11/50] - Loss: 0.3051
Epoch [12/50] - Loss: 0.2991
Epoch [13/50] - Loss: 0.3003
Epoch [14/50] - Loss: 0.2978
Epoch [15/50] - Loss: 0.2926
Epoch [16/50] - Loss: 0.2805
Epoch [17/50] - Loss: 0.2725
Epoch [18/50] - Loss: 0.2577
Epoch [19/50] - Loss: 0.2631
Epoch [20/50] - Loss: 0.2532
Epoch [21/50] - Loss: 0.2469
Epoch [22/50] - Loss: 0.2390
Epoch [23/50] - Loss: 0.2423
Epoch [24/50] - Loss: 0.2307
Epoch [25/50] - Loss: 0.2360
Epoch [26/50] - Loss: 0.2284
Epoch [27/50] - Loss: 0.2222
Epoch [28/50] - Loss: 0.2221
Epoch [29/50] - Loss: 0.2193
Epoch [30/50] - Loss: 0.2110
Epoch [31/50] - Loss: 0.2140
Epoch [32/50] - Loss: 0.2076
Epoch [33/50] - Loss: 0.2106
Epoch [34/50] - Loss: 0.2077
Epoch [35/50] - Loss: 0.2028
Epoch [36/50] - Loss: 0.2017
Epoch [37/50] - Loss: 0.2043
Epoch [38/50] - Loss: 0.2007
Epoch [39/50] - Loss: 0.1991
Epoch [40/50] - Loss: 0.1976
Epoch [41/50] - Loss: 0.1943
Epoch [42/50] - Loss: 0.1967
Epoch [43/50] - Loss: 0.1936
Epoch [44/50] - Loss: 0.1890
Epoch [45/50] - Loss: 0.1893
Epoch [46/50] - Loss: 0.1870
Epoch [47/50] - Loss: 0.1817
Epoch [48/50] - Loss: 0.1799
Epoch [49/50] - Loss: 0.1810
Epoch [50/50] - Loss: 0.1753
sum preds 24
sum labels 491
 - Test Metrics: Accuracy=0.8476, F1=0.0777, Recall=0.0407, Precision=0.8333
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_naive_naive_1804082512.csv.
Average F1 over valid seeds: 0.0733 ± 0.0164
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and naive, GATConv,0.3: 0.0733 ± 0.0164
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2642
Epoch [2/50] - Loss: 0.7386
Epoch [3/50] - Loss: 0.5217
Epoch [4/50] - Loss: 0.4705
Epoch [5/50] - Loss: 0.4729
Epoch [6/50] - Loss: 0.4758
Epoch [7/50] - Loss: 0.4633
Epoch [8/50] - Loss: 0.4532
Epoch [9/50] - Loss: 0.4046
Epoch [10/50] - Loss: 0.3707
Epoch [11/50] - Loss: 0.3461
Epoch [12/50] - Loss: 0.3289
Epoch [13/50] - Loss: 0.3196
Epoch [14/50] - Loss: 0.3185
Epoch [15/50] - Loss: 0.3154
Epoch [16/50] - Loss: 0.3147
Epoch [17/50] - Loss: 0.3075
Epoch [18/50] - Loss: 0.3015
Epoch [19/50] - Loss: 0.2920
Epoch [20/50] - Loss: 0.2903
Epoch [21/50] - Loss: 0.2822
Epoch [22/50] - Loss: 0.2757
Epoch [23/50] - Loss: 0.2710
Epoch [24/50] - Loss: 0.2655
Epoch [25/50] - Loss: 0.2602
Epoch [26/50] - Loss: 0.2616
Epoch [27/50] - Loss: 0.2561
Epoch [28/50] - Loss: 0.2519
Epoch [29/50] - Loss: 0.2495
Epoch [30/50] - Loss: 0.2480
Epoch [31/50] - Loss: 0.2455
Epoch [32/50] - Loss: 0.2439
Epoch [33/50] - Loss: 0.2418
Epoch [34/50] - Loss: 0.2395
Epoch [35/50] - Loss: 0.2341
Epoch [36/50] - Loss: 0.2382
Epoch [37/50] - Loss: 0.2318
Epoch [38/50] - Loss: 0.2305
Epoch [39/50] - Loss: 0.2335
Epoch [40/50] - Loss: 0.2280
Epoch [41/50] - Loss: 0.2284
Epoch [42/50] - Loss: 0.2276
Epoch [43/50] - Loss: 0.2202
Epoch [44/50] - Loss: 0.2213
Epoch [45/50] - Loss: 0.2215
Epoch [46/50] - Loss: 0.2212
Epoch [47/50] - Loss: 0.2200
Epoch [48/50] - Loss: 0.2154
Epoch [49/50] - Loss: 0.2206
Epoch [50/50] - Loss: 0.2181
sum preds 0
sum labels 491
 - Test Metrics: Accuracy=0.8425, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0147
Epoch [2/50] - Loss: 0.5051
Epoch [3/50] - Loss: 0.4984
Epoch [4/50] - Loss: 0.5045
Epoch [5/50] - Loss: 0.4603
Epoch [6/50] - Loss: 0.3983
Epoch [7/50] - Loss: 0.3426
Epoch [8/50] - Loss: 0.3156
Epoch [9/50] - Loss: 0.3162
Epoch [10/50] - Loss: 0.3224
Epoch [11/50] - Loss: 0.3171
Epoch [12/50] - Loss: 0.3131
Epoch [13/50] - Loss: 0.2964
Epoch [14/50] - Loss: 0.2854
Epoch [15/50] - Loss: 0.2779
Epoch [16/50] - Loss: 0.2714
Epoch [17/50] - Loss: 0.2667
Epoch [18/50] - Loss: 0.2653
Epoch [19/50] - Loss: 0.2606
Epoch [20/50] - Loss: 0.2570
Epoch [21/50] - Loss: 0.2547
Epoch [22/50] - Loss: 0.2460
Epoch [23/50] - Loss: 0.2432
Epoch [24/50] - Loss: 0.2465
Epoch [25/50] - Loss: 0.2417
Epoch [26/50] - Loss: 0.2396
Epoch [27/50] - Loss: 0.2363
Epoch [28/50] - Loss: 0.2372
Epoch [29/50] - Loss: 0.2310
Epoch [30/50] - Loss: 0.2317
Epoch [31/50] - Loss: 0.2320
Epoch [32/50] - Loss: 0.2275
Epoch [33/50] - Loss: 0.2289
Epoch [34/50] - Loss: 0.2240
Epoch [35/50] - Loss: 0.2257
Epoch [36/50] - Loss: 0.2229
Epoch [37/50] - Loss: 0.2244
Epoch [38/50] - Loss: 0.2234
Epoch [39/50] - Loss: 0.2223
Epoch [40/50] - Loss: 0.2212
Epoch [41/50] - Loss: 0.2177
Epoch [42/50] - Loss: 0.2140
Epoch [43/50] - Loss: 0.2152
Epoch [44/50] - Loss: 0.2134
Epoch [45/50] - Loss: 0.2152
Epoch [46/50] - Loss: 0.2110
Epoch [47/50] - Loss: 0.2124
Epoch [48/50] - Loss: 0.2113
Epoch [49/50] - Loss: 0.2085
Epoch [50/50] - Loss: 0.2135
sum preds 2
sum labels 491
 - Test Metrics: Accuracy=0.8431, F1=0.0081, Recall=0.0041, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1119
Epoch [2/50] - Loss: 0.5577
Epoch [3/50] - Loss: 0.4687
Epoch [4/50] - Loss: 0.4956
Epoch [5/50] - Loss: 0.4976
Epoch [6/50] - Loss: 0.4482
Epoch [7/50] - Loss: 0.4033
Epoch [8/50] - Loss: 0.3492
Epoch [9/50] - Loss: 0.3212
Epoch [10/50] - Loss: 0.3087
Epoch [11/50] - Loss: 0.3140
Epoch [12/50] - Loss: 0.3114
Epoch [13/50] - Loss: 0.3064
Epoch [14/50] - Loss: 0.2985
Epoch [15/50] - Loss: 0.2869
Epoch [16/50] - Loss: 0.2825
Epoch [17/50] - Loss: 0.2684
Epoch [18/50] - Loss: 0.2688
Epoch [19/50] - Loss: 0.2625
Epoch [20/50] - Loss: 0.2595
Epoch [21/50] - Loss: 0.2581
Epoch [22/50] - Loss: 0.2548
Epoch [23/50] - Loss: 0.2528
Epoch [24/50] - Loss: 0.2436
Epoch [25/50] - Loss: 0.2420
Epoch [26/50] - Loss: 0.2319
Epoch [27/50] - Loss: 0.2324
Epoch [28/50] - Loss: 0.2317
Epoch [29/50] - Loss: 0.2317
Epoch [30/50] - Loss: 0.2297
Epoch [31/50] - Loss: 0.2263
Epoch [32/50] - Loss: 0.2249
Epoch [33/50] - Loss: 0.2258
Epoch [34/50] - Loss: 0.2181
Epoch [35/50] - Loss: 0.2197
Epoch [36/50] - Loss: 0.2196
Epoch [37/50] - Loss: 0.2183
Epoch [38/50] - Loss: 0.2150
Epoch [39/50] - Loss: 0.2151
Epoch [40/50] - Loss: 0.2146
Epoch [41/50] - Loss: 0.2151
Epoch [42/50] - Loss: 0.2127
Epoch [43/50] - Loss: 0.2121
Epoch [44/50] - Loss: 0.2111
Epoch [45/50] - Loss: 0.2128
Epoch [46/50] - Loss: 0.2138
Epoch [47/50] - Loss: 0.2075
Epoch [48/50] - Loss: 0.2128
Epoch [49/50] - Loss: 0.2065
Epoch [50/50] - Loss: 0.2074
sum preds 0
sum labels 491
 - Test Metrics: Accuracy=0.8425, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_naive_naive_1804082618.csv.
Average F1 over valid seeds: 0.0027 ± 0.0038
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and naive, GCNConv,0.3: 0.0027 ± 0.0038
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4158
Epoch [2/50] - Loss: 1.0196
Epoch [3/50] - Loss: 0.6897
Epoch [4/50] - Loss: 0.4735
Epoch [5/50] - Loss: 0.3702
Epoch [6/50] - Loss: 0.3458
Epoch [7/50] - Loss: 0.3438
Epoch [8/50] - Loss: 0.3411
Epoch [9/50] - Loss: 0.3475
Epoch [10/50] - Loss: 0.3297
Epoch [11/50] - Loss: 0.3255
Epoch [12/50] - Loss: 0.3011
Epoch [13/50] - Loss: 0.2812
Epoch [14/50] - Loss: 0.2528
Epoch [15/50] - Loss: 0.2291
Epoch [16/50] - Loss: 0.2180
Epoch [17/50] - Loss: 0.1953
Epoch [18/50] - Loss: 0.1917
Epoch [19/50] - Loss: 0.1799
Epoch [20/50] - Loss: 0.1752
Epoch [21/50] - Loss: 0.1694
Epoch [22/50] - Loss: 0.1613
Epoch [23/50] - Loss: 0.1540
Epoch [24/50] - Loss: 0.1468
Epoch [25/50] - Loss: 0.1372
Epoch [26/50] - Loss: 0.1268
Epoch [27/50] - Loss: 0.1177
Epoch [28/50] - Loss: 0.1129
Epoch [29/50] - Loss: 0.1087
Epoch [30/50] - Loss: 0.1043
Epoch [31/50] - Loss: 0.0989
Epoch [32/50] - Loss: 0.0958
Epoch [33/50] - Loss: 0.0928
Epoch [34/50] - Loss: 0.0885
Epoch [35/50] - Loss: 0.0849
Epoch [36/50] - Loss: 0.0845
Epoch [37/50] - Loss: 0.0812
Epoch [38/50] - Loss: 0.0776
Epoch [39/50] - Loss: 0.0776
Epoch [40/50] - Loss: 0.0757
Epoch [41/50] - Loss: 0.0746
Epoch [42/50] - Loss: 0.0732
Epoch [43/50] - Loss: 0.0731
Epoch [44/50] - Loss: 0.0703
Epoch [45/50] - Loss: 0.0697
Epoch [46/50] - Loss: 0.0684
Epoch [47/50] - Loss: 0.0694
Epoch [48/50] - Loss: 0.0662
Epoch [49/50] - Loss: 0.0682
Epoch [50/50] - Loss: 0.0677
sum preds 1
sum labels 561
 - Test Metrics: Accuracy=0.8243, F1=0.0036, Recall=0.0018, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1542
Epoch [2/50] - Loss: 0.8328
Epoch [3/50] - Loss: 0.5918
Epoch [4/50] - Loss: 0.4392
Epoch [5/50] - Loss: 0.3608
Epoch [6/50] - Loss: 0.3444
Epoch [7/50] - Loss: 0.3260
Epoch [8/50] - Loss: 0.3391
Epoch [9/50] - Loss: 0.3324
Epoch [10/50] - Loss: 0.3193
Epoch [11/50] - Loss: 0.2957
Epoch [12/50] - Loss: 0.2778
Epoch [13/50] - Loss: 0.2642
Epoch [14/50] - Loss: 0.2398
Epoch [15/50] - Loss: 0.2273
Epoch [16/50] - Loss: 0.2062
Epoch [17/50] - Loss: 0.2011
Epoch [18/50] - Loss: 0.1866
Epoch [19/50] - Loss: 0.1837
Epoch [20/50] - Loss: 0.1774
Epoch [21/50] - Loss: 0.1758
Epoch [22/50] - Loss: 0.1655
Epoch [23/50] - Loss: 0.1596
Epoch [24/50] - Loss: 0.1515
Epoch [25/50] - Loss: 0.1442
Epoch [26/50] - Loss: 0.1346
Epoch [27/50] - Loss: 0.1305
Epoch [28/50] - Loss: 0.1228
Epoch [29/50] - Loss: 0.1184
Epoch [30/50] - Loss: 0.1105
Epoch [31/50] - Loss: 0.1088
Epoch [32/50] - Loss: 0.1057
Epoch [33/50] - Loss: 0.1015
Epoch [34/50] - Loss: 0.0982
Epoch [35/50] - Loss: 0.0977
Epoch [36/50] - Loss: 0.0947
Epoch [37/50] - Loss: 0.0926
Epoch [38/50] - Loss: 0.0915
Epoch [39/50] - Loss: 0.0875
Epoch [40/50] - Loss: 0.0874
Epoch [41/50] - Loss: 0.0860
Epoch [42/50] - Loss: 0.0834
Epoch [43/50] - Loss: 0.0818
Epoch [44/50] - Loss: 0.0846
Epoch [45/50] - Loss: 0.0808
Epoch [46/50] - Loss: 0.0838
Epoch [47/50] - Loss: 0.0802
Epoch [48/50] - Loss: 0.0781
Epoch [49/50] - Loss: 0.0773
Epoch [50/50] - Loss: 0.0783
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4709
Epoch [2/50] - Loss: 1.1394
Epoch [3/50] - Loss: 0.8291
Epoch [4/50] - Loss: 0.5871
Epoch [5/50] - Loss: 0.4357
Epoch [6/50] - Loss: 0.3714
Epoch [7/50] - Loss: 0.3558
Epoch [8/50] - Loss: 0.3538
Epoch [9/50] - Loss: 0.3552
Epoch [10/50] - Loss: 0.3529
Epoch [11/50] - Loss: 0.3434
Epoch [12/50] - Loss: 0.3257
Epoch [13/50] - Loss: 0.3057
Epoch [14/50] - Loss: 0.2903
Epoch [15/50] - Loss: 0.2629
Epoch [16/50] - Loss: 0.2367
Epoch [17/50] - Loss: 0.2230
Epoch [18/50] - Loss: 0.2090
Epoch [19/50] - Loss: 0.1973
Epoch [20/50] - Loss: 0.1876
Epoch [21/50] - Loss: 0.1853
Epoch [22/50] - Loss: 0.1824
Epoch [23/50] - Loss: 0.1726
Epoch [24/50] - Loss: 0.1623
Epoch [25/50] - Loss: 0.1560
Epoch [26/50] - Loss: 0.1470
Epoch [27/50] - Loss: 0.1402
Epoch [28/50] - Loss: 0.1339
Epoch [29/50] - Loss: 0.1273
Epoch [30/50] - Loss: 0.1189
Epoch [31/50] - Loss: 0.1153
Epoch [32/50] - Loss: 0.1065
Epoch [33/50] - Loss: 0.1042
Epoch [34/50] - Loss: 0.1001
Epoch [35/50] - Loss: 0.0963
Epoch [36/50] - Loss: 0.0929
Epoch [37/50] - Loss: 0.0912
Epoch [38/50] - Loss: 0.0885
Epoch [39/50] - Loss: 0.0869
Epoch [40/50] - Loss: 0.0846
Epoch [41/50] - Loss: 0.0811
Epoch [42/50] - Loss: 0.0793
Epoch [43/50] - Loss: 0.0797
Epoch [44/50] - Loss: 0.0755
Epoch [45/50] - Loss: 0.0737
Epoch [46/50] - Loss: 0.0733
Epoch [47/50] - Loss: 0.0735
Epoch [48/50] - Loss: 0.0717
Epoch [49/50] - Loss: 0.0719
Epoch [50/50] - Loss: 0.0718
sum preds 1
sum labels 561
 - Test Metrics: Accuracy=0.8243, F1=0.0036, Recall=0.0018, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_naive_naive_1804082713.csv.
Average F1 over valid seeds: 0.0024 ± 0.0017
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and naive, MLP,0.2: 0.0024 ± 0.0017
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2338
Epoch [2/50] - Loss: 0.6491
Epoch [3/50] - Loss: 0.4031
Epoch [4/50] - Loss: 0.3443
Epoch [5/50] - Loss: 0.3486
Epoch [6/50] - Loss: 0.3579
Epoch [7/50] - Loss: 0.3517
Epoch [8/50] - Loss: 0.3517
Epoch [9/50] - Loss: 0.3427
Epoch [10/50] - Loss: 0.3102
Epoch [11/50] - Loss: 0.2966
Epoch [12/50] - Loss: 0.2675
Epoch [13/50] - Loss: 0.2542
Epoch [14/50] - Loss: 0.2361
Epoch [15/50] - Loss: 0.2327
Epoch [16/50] - Loss: 0.2298
Epoch [17/50] - Loss: 0.2269
Epoch [18/50] - Loss: 0.2267
Epoch [19/50] - Loss: 0.2245
Epoch [20/50] - Loss: 0.2162
Epoch [21/50] - Loss: 0.2049
Epoch [22/50] - Loss: 0.1980
Epoch [23/50] - Loss: 0.1898
Epoch [24/50] - Loss: 0.1862
Epoch [25/50] - Loss: 0.1811
Epoch [26/50] - Loss: 0.1776
Epoch [27/50] - Loss: 0.1699
Epoch [28/50] - Loss: 0.1680
Epoch [29/50] - Loss: 0.1680
Epoch [30/50] - Loss: 0.1622
Epoch [31/50] - Loss: 0.1605
Epoch [32/50] - Loss: 0.1535
Epoch [33/50] - Loss: 0.1530
Epoch [34/50] - Loss: 0.1495
Epoch [35/50] - Loss: 0.1492
Epoch [36/50] - Loss: 0.1445
Epoch [37/50] - Loss: 0.1440
Epoch [38/50] - Loss: 0.1374
Epoch [39/50] - Loss: 0.1374
Epoch [40/50] - Loss: 0.1296
Epoch [41/50] - Loss: 0.1328
Epoch [42/50] - Loss: 0.1338
Epoch [43/50] - Loss: 0.1353
Epoch [44/50] - Loss: 0.1305
Epoch [45/50] - Loss: 0.1246
Epoch [46/50] - Loss: 0.1268
Epoch [47/50] - Loss: 0.1247
Epoch [48/50] - Loss: 0.1249
Epoch [49/50] - Loss: 0.1194
Epoch [50/50] - Loss: 0.1224
sum preds 2
sum labels 561
 - Test Metrics: Accuracy=0.8246, F1=0.0071, Recall=0.0036, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0705
Epoch [2/50] - Loss: 0.4503
Epoch [3/50] - Loss: 0.3471
Epoch [4/50] - Loss: 0.3584
Epoch [5/50] - Loss: 0.3730
Epoch [6/50] - Loss: 0.3630
Epoch [7/50] - Loss: 0.3485
Epoch [8/50] - Loss: 0.2945
Epoch [9/50] - Loss: 0.2591
Epoch [10/50] - Loss: 0.2312
Epoch [11/50] - Loss: 0.2218
Epoch [12/50] - Loss: 0.2176
Epoch [13/50] - Loss: 0.2155
Epoch [14/50] - Loss: 0.2134
Epoch [15/50] - Loss: 0.2020
Epoch [16/50] - Loss: 0.1982
Epoch [17/50] - Loss: 0.1876
Epoch [18/50] - Loss: 0.1823
Epoch [19/50] - Loss: 0.1769
Epoch [20/50] - Loss: 0.1753
Epoch [21/50] - Loss: 0.1693
Epoch [22/50] - Loss: 0.1686
Epoch [23/50] - Loss: 0.1652
Epoch [24/50] - Loss: 0.1567
Epoch [25/50] - Loss: 0.1527
Epoch [26/50] - Loss: 0.1499
Epoch [27/50] - Loss: 0.1473
Epoch [28/50] - Loss: 0.1431
Epoch [29/50] - Loss: 0.1437
Epoch [30/50] - Loss: 0.1358
Epoch [31/50] - Loss: 0.1334
Epoch [32/50] - Loss: 0.1276
Epoch [33/50] - Loss: 0.1268
Epoch [34/50] - Loss: 0.1218
Epoch [35/50] - Loss: 0.1216
Epoch [36/50] - Loss: 0.1166
Epoch [37/50] - Loss: 0.1141
Epoch [38/50] - Loss: 0.1164
Epoch [39/50] - Loss: 0.1127
Epoch [40/50] - Loss: 0.1108
Epoch [41/50] - Loss: 0.1083
Epoch [42/50] - Loss: 0.1063
Epoch [43/50] - Loss: 0.1064
Epoch [44/50] - Loss: 0.1013
Epoch [45/50] - Loss: 0.1018
Epoch [46/50] - Loss: 0.0957
Epoch [47/50] - Loss: 0.0923
Epoch [48/50] - Loss: 0.0947
Epoch [49/50] - Loss: 0.0967
Epoch [50/50] - Loss: 0.0918
sum preds 18
sum labels 561
 - Test Metrics: Accuracy=0.8259, F1=0.0415, Recall=0.0214, Precision=0.6667
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1439
Epoch [2/50] - Loss: 0.5537
Epoch [3/50] - Loss: 0.3657
Epoch [4/50] - Loss: 0.3428
Epoch [5/50] - Loss: 0.3557
Epoch [6/50] - Loss: 0.3577
Epoch [7/50] - Loss: 0.3659
Epoch [8/50] - Loss: 0.3368
Epoch [9/50] - Loss: 0.3155
Epoch [10/50] - Loss: 0.2851
Epoch [11/50] - Loss: 0.2569
Epoch [12/50] - Loss: 0.2353
Epoch [13/50] - Loss: 0.2310
Epoch [14/50] - Loss: 0.2264
Epoch [15/50] - Loss: 0.2249
Epoch [16/50] - Loss: 0.2207
Epoch [17/50] - Loss: 0.2176
Epoch [18/50] - Loss: 0.2069
Epoch [19/50] - Loss: 0.2100
Epoch [20/50] - Loss: 0.1999
Epoch [21/50] - Loss: 0.1894
Epoch [22/50] - Loss: 0.1820
Epoch [23/50] - Loss: 0.1827
Epoch [24/50] - Loss: 0.1738
Epoch [25/50] - Loss: 0.1770
Epoch [26/50] - Loss: 0.1728
Epoch [27/50] - Loss: 0.1671
Epoch [28/50] - Loss: 0.1648
Epoch [29/50] - Loss: 0.1617
Epoch [30/50] - Loss: 0.1525
Epoch [31/50] - Loss: 0.1577
Epoch [32/50] - Loss: 0.1522
Epoch [33/50] - Loss: 0.1518
Epoch [34/50] - Loss: 0.1496
Epoch [35/50] - Loss: 0.1461
Epoch [36/50] - Loss: 0.1464
Epoch [37/50] - Loss: 0.1447
Epoch [38/50] - Loss: 0.1448
Epoch [39/50] - Loss: 0.1417
Epoch [40/50] - Loss: 0.1399
Epoch [41/50] - Loss: 0.1381
Epoch [42/50] - Loss: 0.1377
Epoch [43/50] - Loss: 0.1368
Epoch [44/50] - Loss: 0.1320
Epoch [45/50] - Loss: 0.1328
Epoch [46/50] - Loss: 0.1337
Epoch [47/50] - Loss: 0.1260
Epoch [48/50] - Loss: 0.1245
Epoch [49/50] - Loss: 0.1257
Epoch [50/50] - Loss: 0.1197
sum preds 10
sum labels 561
 - Test Metrics: Accuracy=0.8259, F1=0.0280, Recall=0.0143, Precision=0.8000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_naive_naive_1804082815.csv.
Average F1 over valid seeds: 0.0255 ± 0.0141
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and naive, GATConv,0.2: 0.0255 ± 0.0141
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2578
Epoch [2/50] - Loss: 0.6898
Epoch [3/50] - Loss: 0.4363
Epoch [4/50] - Loss: 0.3556
Epoch [5/50] - Loss: 0.3483
Epoch [6/50] - Loss: 0.3598
Epoch [7/50] - Loss: 0.3658
Epoch [8/50] - Loss: 0.3688
Epoch [9/50] - Loss: 0.3487
Epoch [10/50] - Loss: 0.3247
Epoch [11/50] - Loss: 0.3014
Epoch [12/50] - Loss: 0.2817
Epoch [13/50] - Loss: 0.2638
Epoch [14/50] - Loss: 0.2552
Epoch [15/50] - Loss: 0.2442
Epoch [16/50] - Loss: 0.2379
Epoch [17/50] - Loss: 0.2354
Epoch [18/50] - Loss: 0.2353
Epoch [19/50] - Loss: 0.2311
Epoch [20/50] - Loss: 0.2309
Epoch [21/50] - Loss: 0.2225
Epoch [22/50] - Loss: 0.2173
Epoch [23/50] - Loss: 0.2115
Epoch [24/50] - Loss: 0.2062
Epoch [25/50] - Loss: 0.1977
Epoch [26/50] - Loss: 0.2005
Epoch [27/50] - Loss: 0.1943
Epoch [28/50] - Loss: 0.1925
Epoch [29/50] - Loss: 0.1882
Epoch [30/50] - Loss: 0.1879
Epoch [31/50] - Loss: 0.1853
Epoch [32/50] - Loss: 0.1820
Epoch [33/50] - Loss: 0.1799
Epoch [34/50] - Loss: 0.1774
Epoch [35/50] - Loss: 0.1728
Epoch [36/50] - Loss: 0.1763
Epoch [37/50] - Loss: 0.1735
Epoch [38/50] - Loss: 0.1686
Epoch [39/50] - Loss: 0.1693
Epoch [40/50] - Loss: 0.1667
Epoch [41/50] - Loss: 0.1672
Epoch [42/50] - Loss: 0.1654
Epoch [43/50] - Loss: 0.1604
Epoch [44/50] - Loss: 0.1587
Epoch [45/50] - Loss: 0.1605
Epoch [46/50] - Loss: 0.1594
Epoch [47/50] - Loss: 0.1582
Epoch [48/50] - Loss: 0.1556
Epoch [49/50] - Loss: 0.1596
Epoch [50/50] - Loss: 0.1562
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.9891
Epoch [2/50] - Loss: 0.4028
Epoch [3/50] - Loss: 0.3750
Epoch [4/50] - Loss: 0.3980
Epoch [5/50] - Loss: 0.3893
Epoch [6/50] - Loss: 0.3614
Epoch [7/50] - Loss: 0.3144
Epoch [8/50] - Loss: 0.2726
Epoch [9/50] - Loss: 0.2442
Epoch [10/50] - Loss: 0.2344
Epoch [11/50] - Loss: 0.2292
Epoch [12/50] - Loss: 0.2345
Epoch [13/50] - Loss: 0.2317
Epoch [14/50] - Loss: 0.2264
Epoch [15/50] - Loss: 0.2195
Epoch [16/50] - Loss: 0.2075
Epoch [17/50] - Loss: 0.1984
Epoch [18/50] - Loss: 0.1943
Epoch [19/50] - Loss: 0.1896
Epoch [20/50] - Loss: 0.1891
Epoch [21/50] - Loss: 0.1874
Epoch [22/50] - Loss: 0.1840
Epoch [23/50] - Loss: 0.1811
Epoch [24/50] - Loss: 0.1801
Epoch [25/50] - Loss: 0.1759
Epoch [26/50] - Loss: 0.1735
Epoch [27/50] - Loss: 0.1704
Epoch [28/50] - Loss: 0.1738
Epoch [29/50] - Loss: 0.1675
Epoch [30/50] - Loss: 0.1665
Epoch [31/50] - Loss: 0.1680
Epoch [32/50] - Loss: 0.1638
Epoch [33/50] - Loss: 0.1646
Epoch [34/50] - Loss: 0.1596
Epoch [35/50] - Loss: 0.1626
Epoch [36/50] - Loss: 0.1611
Epoch [37/50] - Loss: 0.1608
Epoch [38/50] - Loss: 0.1601
Epoch [39/50] - Loss: 0.1587
Epoch [40/50] - Loss: 0.1568
Epoch [41/50] - Loss: 0.1550
Epoch [42/50] - Loss: 0.1524
Epoch [43/50] - Loss: 0.1544
Epoch [44/50] - Loss: 0.1516
Epoch [45/50] - Loss: 0.1541
Epoch [46/50] - Loss: 0.1502
Epoch [47/50] - Loss: 0.1504
Epoch [48/50] - Loss: 0.1511
Epoch [49/50] - Loss: 0.1490
Epoch [50/50] - Loss: 0.1517
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0951
Epoch [2/50] - Loss: 0.4758
Epoch [3/50] - Loss: 0.3477
Epoch [4/50] - Loss: 0.3715
Epoch [5/50] - Loss: 0.3963
Epoch [6/50] - Loss: 0.3732
Epoch [7/50] - Loss: 0.3660
Epoch [8/50] - Loss: 0.3268
Epoch [9/50] - Loss: 0.2979
Epoch [10/50] - Loss: 0.2624
Epoch [11/50] - Loss: 0.2443
Epoch [12/50] - Loss: 0.2317
Epoch [13/50] - Loss: 0.2286
Epoch [14/50] - Loss: 0.2305
Epoch [15/50] - Loss: 0.2278
Epoch [16/50] - Loss: 0.2283
Epoch [17/50] - Loss: 0.2154
Epoch [18/50] - Loss: 0.2110
Epoch [19/50] - Loss: 0.2005
Epoch [20/50] - Loss: 0.1963
Epoch [21/50] - Loss: 0.1914
Epoch [22/50] - Loss: 0.1916
Epoch [23/50] - Loss: 0.1909
Epoch [24/50] - Loss: 0.1830
Epoch [25/50] - Loss: 0.1804
Epoch [26/50] - Loss: 0.1708
Epoch [27/50] - Loss: 0.1706
Epoch [28/50] - Loss: 0.1690
Epoch [29/50] - Loss: 0.1701
Epoch [30/50] - Loss: 0.1671
Epoch [31/50] - Loss: 0.1646
Epoch [32/50] - Loss: 0.1635
Epoch [33/50] - Loss: 0.1617
Epoch [34/50] - Loss: 0.1557
Epoch [35/50] - Loss: 0.1576
Epoch [36/50] - Loss: 0.1578
Epoch [37/50] - Loss: 0.1548
Epoch [38/50] - Loss: 0.1518
Epoch [39/50] - Loss: 0.1519
Epoch [40/50] - Loss: 0.1548
Epoch [41/50] - Loss: 0.1531
Epoch [42/50] - Loss: 0.1513
Epoch [43/50] - Loss: 0.1512
Epoch [44/50] - Loss: 0.1465
Epoch [45/50] - Loss: 0.1488
Epoch [46/50] - Loss: 0.1494
Epoch [47/50] - Loss: 0.1463
Epoch [48/50] - Loss: 0.1492
Epoch [49/50] - Loss: 0.1440
Epoch [50/50] - Loss: 0.1453
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_naive_naive_1804082915.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and naive, GCNConv,0.2: 0.0000 ± 0.0000
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8750, F1=0.2013, Recall=0.1140, Precision=0.8571
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8782, F1=0.2319, Recall=0.1330, Precision=0.9032
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8805, F1=0.2448, Recall=0.1401, Precision=0.9672
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_NNIF_NNIF_1804083016.csv.
Average F1 over valid seeds: 0.2260 ± 0.0183
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and NNIF, MLP,0.4: 0.2260 ± 0.0183
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8531, F1=0.1423, Recall=0.0774, Precision=0.8837
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8563, F1=0.1825, Recall=0.1018, Precision=0.8772
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8637, F1=0.2478, Recall=0.1426, Precision=0.9459
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_NNIF_NNIF_1804083106.csv.
Average F1 over valid seeds: 0.1909 ± 0.0435
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and NNIF, MLP,0.3: 0.1909 ± 0.0435
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8287, F1=0.0619, Recall=0.0321, Precision=0.8571
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8334, F1=0.1194, Recall=0.0642, Precision=0.8571
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8353, F1=0.1294, Recall=0.0695, Precision=0.9286
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_NNIF_NNIF_1804083136.csv.
Average F1 over valid seeds: 0.1035 ± 0.0298
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and NNIF, MLP,0.2: 0.1035 ± 0.0298
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4135
Epoch [2/50] - Loss: 1.0606
Epoch [3/50] - Loss: 0.7756
Epoch [4/50] - Loss: 0.6110
Epoch [5/50] - Loss: 0.5426
Epoch [6/50] - Loss: 0.5353
Epoch [7/50] - Loss: 0.5287
Epoch [8/50] - Loss: 0.5110
Epoch [9/50] - Loss: 0.4656
Epoch [10/50] - Loss: 0.4290
Epoch [11/50] - Loss: 0.3905
Epoch [12/50] - Loss: 0.3552
Epoch [13/50] - Loss: 0.3302
Epoch [14/50] - Loss: 0.3139
Epoch [15/50] - Loss: 0.3027
Epoch [16/50] - Loss: 0.2913
Epoch [17/50] - Loss: 0.2848
Epoch [18/50] - Loss: 0.2722
Epoch [19/50] - Loss: 0.2558
Epoch [20/50] - Loss: 0.2409
Epoch [21/50] - Loss: 0.2328
Epoch [22/50] - Loss: 0.2137
Epoch [23/50] - Loss: 0.2114
Epoch [24/50] - Loss: 0.2009
Epoch [25/50] - Loss: 0.1949
Epoch [26/50] - Loss: 0.1862
Epoch [27/50] - Loss: 0.1770
Epoch [28/50] - Loss: 0.1732
Epoch [29/50] - Loss: 0.1681
Epoch [30/50] - Loss: 0.1630
Epoch [31/50] - Loss: 0.1576
Epoch [32/50] - Loss: 0.1528
Epoch [33/50] - Loss: 0.1482
Epoch [34/50] - Loss: 0.1428
Epoch [35/50] - Loss: 0.1425
Epoch [36/50] - Loss: 0.1391
Epoch [37/50] - Loss: 0.1399
Epoch [38/50] - Loss: 0.1378
Epoch [39/50] - Loss: 0.1340
Epoch [40/50] - Loss: 0.1336
Epoch [41/50] - Loss: 0.1312
Epoch [42/50] - Loss: 0.1281
Epoch [43/50] - Loss: 0.1293
Epoch [44/50] - Loss: 0.1274
Epoch [45/50] - Loss: 0.1219
Epoch [46/50] - Loss: 0.1229
Epoch [47/50] - Loss: 0.1239
Epoch [48/50] - Loss: 0.1197
Epoch [49/50] - Loss: 0.1218
Epoch [50/50] - Loss: 0.1186
sum preds 36
sum labels 421
 - Test Metrics: Accuracy=0.8710, F1=0.1400, Recall=0.0760, Precision=0.8889
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1777
Epoch [2/50] - Loss: 0.8976
Epoch [3/50] - Loss: 0.6948
Epoch [4/50] - Loss: 0.5779
Epoch [5/50] - Loss: 0.5376
Epoch [6/50] - Loss: 0.5135
Epoch [7/50] - Loss: 0.5043
Epoch [8/50] - Loss: 0.4810
Epoch [9/50] - Loss: 0.4565
Epoch [10/50] - Loss: 0.4167
Epoch [11/50] - Loss: 0.3861
Epoch [12/50] - Loss: 0.3566
Epoch [13/50] - Loss: 0.3384
Epoch [14/50] - Loss: 0.3180
Epoch [15/50] - Loss: 0.3045
Epoch [16/50] - Loss: 0.2979
Epoch [17/50] - Loss: 0.2886
Epoch [18/50] - Loss: 0.2696
Epoch [19/50] - Loss: 0.2556
Epoch [20/50] - Loss: 0.2425
Epoch [21/50] - Loss: 0.2356
Epoch [22/50] - Loss: 0.2123
Epoch [23/50] - Loss: 0.2013
Epoch [24/50] - Loss: 0.1912
Epoch [25/50] - Loss: 0.1734
Epoch [26/50] - Loss: 0.1564
Epoch [27/50] - Loss: 0.1415
Epoch [28/50] - Loss: 0.1281
Epoch [29/50] - Loss: 0.1153
Epoch [30/50] - Loss: 0.1046
Epoch [31/50] - Loss: 0.0965
Epoch [32/50] - Loss: 0.0860
Epoch [33/50] - Loss: 0.0772
Epoch [34/50] - Loss: 0.0690
Epoch [35/50] - Loss: 0.0630
Epoch [36/50] - Loss: 0.0556
Epoch [37/50] - Loss: 0.0507
Epoch [38/50] - Loss: 0.0465
Epoch [39/50] - Loss: 0.0419
Epoch [40/50] - Loss: 0.0387
Epoch [41/50] - Loss: 0.0351
Epoch [42/50] - Loss: 0.0328
Epoch [43/50] - Loss: 0.0300
Epoch [44/50] - Loss: 0.0279
Epoch [45/50] - Loss: 0.0259
Epoch [46/50] - Loss: 0.0243
Epoch [47/50] - Loss: 0.0235
Epoch [48/50] - Loss: 0.0219
Epoch [49/50] - Loss: 0.0210
Epoch [50/50] - Loss: 0.0197
sum preds 69
sum labels 421
 - Test Metrics: Accuracy=0.8779, F1=0.2408, Recall=0.1401, Precision=0.8551
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4635
Epoch [2/50] - Loss: 1.1670
Epoch [3/50] - Loss: 0.8971
Epoch [4/50] - Loss: 0.6981
Epoch [5/50] - Loss: 0.5825
Epoch [6/50] - Loss: 0.5377
Epoch [7/50] - Loss: 0.5476
Epoch [8/50] - Loss: 0.5399
Epoch [9/50] - Loss: 0.5280
Epoch [10/50] - Loss: 0.4946
Epoch [11/50] - Loss: 0.4648
Epoch [12/50] - Loss: 0.4124
Epoch [13/50] - Loss: 0.3813
Epoch [14/50] - Loss: 0.3581
Epoch [15/50] - Loss: 0.3401
Epoch [16/50] - Loss: 0.3233
Epoch [17/50] - Loss: 0.3123
Epoch [18/50] - Loss: 0.3015
Epoch [19/50] - Loss: 0.2854
Epoch [20/50] - Loss: 0.2719
Epoch [21/50] - Loss: 0.2625
Epoch [22/50] - Loss: 0.2470
Epoch [23/50] - Loss: 0.2366
Epoch [24/50] - Loss: 0.2265
Epoch [25/50] - Loss: 0.2154
Epoch [26/50] - Loss: 0.2089
Epoch [27/50] - Loss: 0.1995
Epoch [28/50] - Loss: 0.1922
Epoch [29/50] - Loss: 0.1869
Epoch [30/50] - Loss: 0.1770
Epoch [31/50] - Loss: 0.1717
Epoch [32/50] - Loss: 0.1654
Epoch [33/50] - Loss: 0.1613
Epoch [34/50] - Loss: 0.1575
Epoch [35/50] - Loss: 0.1538
Epoch [36/50] - Loss: 0.1490
Epoch [37/50] - Loss: 0.1453
Epoch [38/50] - Loss: 0.1456
Epoch [39/50] - Loss: 0.1385
Epoch [40/50] - Loss: 0.1376
Epoch [41/50] - Loss: 0.1346
Epoch [42/50] - Loss: 0.1335
Epoch [43/50] - Loss: 0.1320
Epoch [44/50] - Loss: 0.1300
Epoch [45/50] - Loss: 0.1269
Epoch [46/50] - Loss: 0.1254
Epoch [47/50] - Loss: 0.1236
Epoch [48/50] - Loss: 0.1213
Epoch [49/50] - Loss: 0.1173
Epoch [50/50] - Loss: 0.1155
sum preds 43
sum labels 421
 - Test Metrics: Accuracy=0.8753, F1=0.1810, Recall=0.0998, Precision=0.9767
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_two_nnif_two_nnif_1804083207.csv.
Average F1 over valid seeds: 0.1873 ± 0.0414
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and two_nnif, MLP,0.4: 0.1873 ± 0.0414
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2492
Epoch [2/50] - Loss: 0.7508
Epoch [3/50] - Loss: 0.5719
Epoch [4/50] - Loss: 0.5287
Epoch [5/50] - Loss: 0.5175
Epoch [6/50] - Loss: 0.5149
Epoch [7/50] - Loss: 0.4813
Epoch [8/50] - Loss: 0.4275
Epoch [9/50] - Loss: 0.3806
Epoch [10/50] - Loss: 0.3602
Epoch [11/50] - Loss: 0.3470
Epoch [12/50] - Loss: 0.3442
Epoch [13/50] - Loss: 0.3362
Epoch [14/50] - Loss: 0.3298
Epoch [15/50] - Loss: 0.3226
Epoch [16/50] - Loss: 0.3126
Epoch [17/50] - Loss: 0.3043
Epoch [18/50] - Loss: 0.2914
Epoch [19/50] - Loss: 0.2850
Epoch [20/50] - Loss: 0.2758
Epoch [21/50] - Loss: 0.2723
Epoch [22/50] - Loss: 0.2646
Epoch [23/50] - Loss: 0.2585
Epoch [24/50] - Loss: 0.2539
Epoch [25/50] - Loss: 0.2520
Epoch [26/50] - Loss: 0.2469
Epoch [27/50] - Loss: 0.2438
Epoch [28/50] - Loss: 0.2401
Epoch [29/50] - Loss: 0.2275
Epoch [30/50] - Loss: 0.2299
Epoch [31/50] - Loss: 0.2272
Epoch [32/50] - Loss: 0.2262
Epoch [33/50] - Loss: 0.2224
Epoch [34/50] - Loss: 0.2168
Epoch [35/50] - Loss: 0.2171
Epoch [36/50] - Loss: 0.2148
Epoch [37/50] - Loss: 0.2117
Epoch [38/50] - Loss: 0.2119
Epoch [39/50] - Loss: 0.2004
Epoch [40/50] - Loss: 0.2024
Epoch [41/50] - Loss: 0.2013
Epoch [42/50] - Loss: 0.2065
Epoch [43/50] - Loss: 0.1950
Epoch [44/50] - Loss: 0.1947
Epoch [45/50] - Loss: 0.1852
Epoch [46/50] - Loss: 0.1903
Epoch [47/50] - Loss: 0.1804
Epoch [48/50] - Loss: 0.1783
Epoch [49/50] - Loss: 0.1822
Epoch [50/50] - Loss: 0.1726
sum preds 123
sum labels 421
 - Test Metrics: Accuracy=0.8910, F1=0.3897, Recall=0.2518, Precision=0.8618
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1073
Epoch [2/50] - Loss: 0.5961
Epoch [3/50] - Loss: 0.5358
Epoch [4/50] - Loss: 0.5208
Epoch [5/50] - Loss: 0.4832
Epoch [6/50] - Loss: 0.4140
Epoch [7/50] - Loss: 0.3532
Epoch [8/50] - Loss: 0.3357
Epoch [9/50] - Loss: 0.3261
Epoch [10/50] - Loss: 0.3259
Epoch [11/50] - Loss: 0.3187
Epoch [12/50] - Loss: 0.3055
Epoch [13/50] - Loss: 0.2922
Epoch [14/50] - Loss: 0.2821
Epoch [15/50] - Loss: 0.2665
Epoch [16/50] - Loss: 0.2559
Epoch [17/50] - Loss: 0.2508
Epoch [18/50] - Loss: 0.2410
Epoch [19/50] - Loss: 0.2342
Epoch [20/50] - Loss: 0.2248
Epoch [21/50] - Loss: 0.2199
Epoch [22/50] - Loss: 0.2169
Epoch [23/50] - Loss: 0.2095
Epoch [24/50] - Loss: 0.2026
Epoch [25/50] - Loss: 0.2047
Epoch [26/50] - Loss: 0.1924
Epoch [27/50] - Loss: 0.1924
Epoch [28/50] - Loss: 0.1834
Epoch [29/50] - Loss: 0.1790
Epoch [30/50] - Loss: 0.1748
Epoch [31/50] - Loss: 0.1753
Epoch [32/50] - Loss: 0.1734
Epoch [33/50] - Loss: 0.1734
Epoch [34/50] - Loss: 0.1689
Epoch [35/50] - Loss: 0.1612
Epoch [36/50] - Loss: 0.1609
Epoch [37/50] - Loss: 0.1564
Epoch [38/50] - Loss: 0.1563
Epoch [39/50] - Loss: 0.1482
Epoch [40/50] - Loss: 0.1578
Epoch [41/50] - Loss: 0.1472
Epoch [42/50] - Loss: 0.1539
Epoch [43/50] - Loss: 0.1446
Epoch [44/50] - Loss: 0.1466
Epoch [45/50] - Loss: 0.1422
Epoch [46/50] - Loss: 0.1532
Epoch [47/50] - Loss: 0.1490
Epoch [48/50] - Loss: 0.1347
Epoch [49/50] - Loss: 0.1441
Epoch [50/50] - Loss: 0.1381
sum preds 118
sum labels 421
 - Test Metrics: Accuracy=0.8901, F1=0.3785, Recall=0.2423, Precision=0.8644
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1744
Epoch [2/50] - Loss: 0.6783
Epoch [3/50] - Loss: 0.5533
Epoch [4/50] - Loss: 0.5540
Epoch [5/50] - Loss: 0.5432
Epoch [6/50] - Loss: 0.5089
Epoch [7/50] - Loss: 0.4364
Epoch [8/50] - Loss: 0.3910
Epoch [9/50] - Loss: 0.3637
Epoch [10/50] - Loss: 0.3408
Epoch [11/50] - Loss: 0.3374
Epoch [12/50] - Loss: 0.3407
Epoch [13/50] - Loss: 0.3337
Epoch [14/50] - Loss: 0.3226
Epoch [15/50] - Loss: 0.3108
Epoch [16/50] - Loss: 0.2941
Epoch [17/50] - Loss: 0.2960
Epoch [18/50] - Loss: 0.2791
Epoch [19/50] - Loss: 0.2745
Epoch [20/50] - Loss: 0.2730
Epoch [21/50] - Loss: 0.2659
Epoch [22/50] - Loss: 0.2575
Epoch [23/50] - Loss: 0.2544
Epoch [24/50] - Loss: 0.2475
Epoch [25/50] - Loss: 0.2429
Epoch [26/50] - Loss: 0.2429
Epoch [27/50] - Loss: 0.2359
Epoch [28/50] - Loss: 0.2321
Epoch [29/50] - Loss: 0.2252
Epoch [30/50] - Loss: 0.2162
Epoch [31/50] - Loss: 0.2144
Epoch [32/50] - Loss: 0.2098
Epoch [33/50] - Loss: 0.2069
Epoch [34/50] - Loss: 0.2088
Epoch [35/50] - Loss: 0.1994
Epoch [36/50] - Loss: 0.1947
Epoch [37/50] - Loss: 0.1883
Epoch [38/50] - Loss: 0.1880
Epoch [39/50] - Loss: 0.1850
Epoch [40/50] - Loss: 0.1759
Epoch [41/50] - Loss: 0.1783
Epoch [42/50] - Loss: 0.1733
Epoch [43/50] - Loss: 0.1695
Epoch [44/50] - Loss: 0.1686
Epoch [45/50] - Loss: 0.1641
Epoch [46/50] - Loss: 0.1577
Epoch [47/50] - Loss: 0.1559
Epoch [48/50] - Loss: 0.1549
Epoch [49/50] - Loss: 0.1555
Epoch [50/50] - Loss: 0.1538
sum preds 105
sum labels 421
 - Test Metrics: Accuracy=0.8878, F1=0.3498, Recall=0.2185, Precision=0.8762
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_two_nnif_two_nnif_1804083316.csv.
Average F1 over valid seeds: 0.3727 ± 0.0168
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and two_nnif, GATConv,0.4: 0.3727 ± 0.0168
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2726
Epoch [2/50] - Loss: 0.7890
Epoch [3/50] - Loss: 0.5945
Epoch [4/50] - Loss: 0.5560
Epoch [5/50] - Loss: 0.5461
Epoch [6/50] - Loss: 0.5357
Epoch [7/50] - Loss: 0.4915
Epoch [8/50] - Loss: 0.4495
Epoch [9/50] - Loss: 0.4072
Epoch [10/50] - Loss: 0.3806
Epoch [11/50] - Loss: 0.3621
Epoch [12/50] - Loss: 0.3571
Epoch [13/50] - Loss: 0.3445
Epoch [14/50] - Loss: 0.3403
Epoch [15/50] - Loss: 0.3426
Epoch [16/50] - Loss: 0.3336
Epoch [17/50] - Loss: 0.3256
Epoch [18/50] - Loss: 0.3104
Epoch [19/50] - Loss: 0.3057
Epoch [20/50] - Loss: 0.3053
Epoch [21/50] - Loss: 0.3002
Epoch [22/50] - Loss: 0.2934
Epoch [23/50] - Loss: 0.2930
Epoch [24/50] - Loss: 0.2965
Epoch [25/50] - Loss: 0.2809
Epoch [26/50] - Loss: 0.2809
Epoch [27/50] - Loss: 0.2750
Epoch [28/50] - Loss: 0.2768
Epoch [29/50] - Loss: 0.2688
Epoch [30/50] - Loss: 0.2702
Epoch [31/50] - Loss: 0.2712
Epoch [32/50] - Loss: 0.2674
Epoch [33/50] - Loss: 0.2677
Epoch [34/50] - Loss: 0.2621
Epoch [35/50] - Loss: 0.2594
Epoch [36/50] - Loss: 0.2503
Epoch [37/50] - Loss: 0.2612
Epoch [38/50] - Loss: 0.2465
Epoch [39/50] - Loss: 0.2513
Epoch [40/50] - Loss: 0.2548
Epoch [41/50] - Loss: 0.2457
Epoch [42/50] - Loss: 0.2463
Epoch [43/50] - Loss: 0.2422
Epoch [44/50] - Loss: 0.2430
Epoch [45/50] - Loss: 0.2411
Epoch [46/50] - Loss: 0.2442
Epoch [47/50] - Loss: 0.2440
Epoch [48/50] - Loss: 0.2424
Epoch [49/50] - Loss: 0.2350
Epoch [50/50] - Loss: 0.2360
sum preds 84
sum labels 421
 - Test Metrics: Accuracy=0.8841, F1=0.3010, Recall=0.1805, Precision=0.9048
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0402
Epoch [2/50] - Loss: 0.5769
Epoch [3/50] - Loss: 0.5690
Epoch [4/50] - Loss: 0.5232
Epoch [5/50] - Loss: 0.4386
Epoch [6/50] - Loss: 0.3872
Epoch [7/50] - Loss: 0.3421
Epoch [8/50] - Loss: 0.3406
Epoch [9/50] - Loss: 0.3428
Epoch [10/50] - Loss: 0.3355
Epoch [11/50] - Loss: 0.3241
Epoch [12/50] - Loss: 0.3156
Epoch [13/50] - Loss: 0.3007
Epoch [14/50] - Loss: 0.3009
Epoch [15/50] - Loss: 0.2901
Epoch [16/50] - Loss: 0.2873
Epoch [17/50] - Loss: 0.2851
Epoch [18/50] - Loss: 0.2741
Epoch [19/50] - Loss: 0.2741
Epoch [20/50] - Loss: 0.2650
Epoch [21/50] - Loss: 0.2675
Epoch [22/50] - Loss: 0.2626
Epoch [23/50] - Loss: 0.2592
Epoch [24/50] - Loss: 0.2557
Epoch [25/50] - Loss: 0.2542
Epoch [26/50] - Loss: 0.2529
Epoch [27/50] - Loss: 0.2497
Epoch [28/50] - Loss: 0.2479
Epoch [29/50] - Loss: 0.2460
Epoch [30/50] - Loss: 0.2442
Epoch [31/50] - Loss: 0.2436
Epoch [32/50] - Loss: 0.2401
Epoch [33/50] - Loss: 0.2416
Epoch [34/50] - Loss: 0.2387
Epoch [35/50] - Loss: 0.2347
Epoch [36/50] - Loss: 0.2351
Epoch [37/50] - Loss: 0.2340
Epoch [38/50] - Loss: 0.2332
Epoch [39/50] - Loss: 0.2324
Epoch [40/50] - Loss: 0.2249
Epoch [41/50] - Loss: 0.2176
Epoch [42/50] - Loss: 0.2177
Epoch [43/50] - Loss: 0.2190
Epoch [44/50] - Loss: 0.2132
Epoch [45/50] - Loss: 0.2119
Epoch [46/50] - Loss: 0.2079
Epoch [47/50] - Loss: 0.2074
Epoch [48/50] - Loss: 0.1999
Epoch [49/50] - Loss: 0.1970
Epoch [50/50] - Loss: 0.1967
sum preds 153
sum labels 421
 - Test Metrics: Accuracy=0.9002, F1=0.4704, Recall=0.3207, Precision=0.8824
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1313
Epoch [2/50] - Loss: 0.6275
Epoch [3/50] - Loss: 0.5682
Epoch [4/50] - Loss: 0.5593
Epoch [5/50] - Loss: 0.5223
Epoch [6/50] - Loss: 0.4439
Epoch [7/50] - Loss: 0.4029
Epoch [8/50] - Loss: 0.3700
Epoch [9/50] - Loss: 0.3591
Epoch [10/50] - Loss: 0.3567
Epoch [11/50] - Loss: 0.3583
Epoch [12/50] - Loss: 0.3456
Epoch [13/50] - Loss: 0.3376
Epoch [14/50] - Loss: 0.3230
Epoch [15/50] - Loss: 0.3135
Epoch [16/50] - Loss: 0.3019
Epoch [17/50] - Loss: 0.2942
Epoch [18/50] - Loss: 0.2982
Epoch [19/50] - Loss: 0.2995
Epoch [20/50] - Loss: 0.2908
Epoch [21/50] - Loss: 0.2807
Epoch [22/50] - Loss: 0.2769
Epoch [23/50] - Loss: 0.2792
Epoch [24/50] - Loss: 0.2755
Epoch [25/50] - Loss: 0.2656
Epoch [26/50] - Loss: 0.2688
Epoch [27/50] - Loss: 0.2629
Epoch [28/50] - Loss: 0.2594
Epoch [29/50] - Loss: 0.2635
Epoch [30/50] - Loss: 0.2619
Epoch [31/50] - Loss: 0.2593
Epoch [32/50] - Loss: 0.2529
Epoch [33/50] - Loss: 0.2510
Epoch [34/50] - Loss: 0.2536
Epoch [35/50] - Loss: 0.2514
Epoch [36/50] - Loss: 0.2470
Epoch [37/50] - Loss: 0.2482
Epoch [38/50] - Loss: 0.2468
Epoch [39/50] - Loss: 0.2453
Epoch [40/50] - Loss: 0.2459
Epoch [41/50] - Loss: 0.2470
Epoch [42/50] - Loss: 0.2434
Epoch [43/50] - Loss: 0.2383
Epoch [44/50] - Loss: 0.2462
Epoch [45/50] - Loss: 0.2456
Epoch [46/50] - Loss: 0.2381
Epoch [47/50] - Loss: 0.2382
Epoch [48/50] - Loss: 0.2419
Epoch [49/50] - Loss: 0.2382
Epoch [50/50] - Loss: 0.2342
sum preds 103
sum labels 421
 - Test Metrics: Accuracy=0.8884, F1=0.3511, Recall=0.2185, Precision=0.8932
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_two_nnif_two_nnif_1804083425.csv.
Average F1 over valid seeds: 0.3742 ± 0.0710
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and two_nnif, GCNConv,0.4: 0.3742 ± 0.0710
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4146
Epoch [2/50] - Loss: 1.0469
Epoch [3/50] - Loss: 0.7403
Epoch [4/50] - Loss: 0.5497
Epoch [5/50] - Loss: 0.4704
Epoch [6/50] - Loss: 0.4437
Epoch [7/50] - Loss: 0.4539
Epoch [8/50] - Loss: 0.4528
Epoch [9/50] - Loss: 0.4335
Epoch [10/50] - Loss: 0.3947
Epoch [11/50] - Loss: 0.3713
Epoch [12/50] - Loss: 0.3419
Epoch [13/50] - Loss: 0.3015
Epoch [14/50] - Loss: 0.2775
Epoch [15/50] - Loss: 0.2561
Epoch [16/50] - Loss: 0.2496
Epoch [17/50] - Loss: 0.2391
Epoch [18/50] - Loss: 0.2294
Epoch [19/50] - Loss: 0.2247
Epoch [20/50] - Loss: 0.2131
Epoch [21/50] - Loss: 0.1982
Epoch [22/50] - Loss: 0.1882
Epoch [23/50] - Loss: 0.1764
Epoch [24/50] - Loss: 0.1670
Epoch [25/50] - Loss: 0.1640
Epoch [26/50] - Loss: 0.1505
Epoch [27/50] - Loss: 0.1489
Epoch [28/50] - Loss: 0.1424
Epoch [29/50] - Loss: 0.1344
Epoch [30/50] - Loss: 0.1278
Epoch [31/50] - Loss: 0.1262
Epoch [32/50] - Loss: 0.1227
Epoch [33/50] - Loss: 0.1184
Epoch [34/50] - Loss: 0.1189
Epoch [35/50] - Loss: 0.1143
Epoch [36/50] - Loss: 0.1114
Epoch [37/50] - Loss: 0.1094
Epoch [38/50] - Loss: 0.1067
Epoch [39/50] - Loss: 0.1050
Epoch [40/50] - Loss: 0.1022
Epoch [41/50] - Loss: 0.0996
Epoch [42/50] - Loss: 0.1016
Epoch [43/50] - Loss: 0.0996
Epoch [44/50] - Loss: 0.0972
Epoch [45/50] - Loss: 0.0981
Epoch [46/50] - Loss: 0.0990
Epoch [47/50] - Loss: 0.0960
Epoch [48/50] - Loss: 0.0969
Epoch [49/50] - Loss: 0.0932
Epoch [50/50] - Loss: 0.0966
sum preds 30
sum labels 491
 - Test Metrics: Accuracy=0.8515, F1=0.1113, Recall=0.0591, Precision=0.9667
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1686
Epoch [2/50] - Loss: 0.8731
Epoch [3/50] - Loss: 0.6563
Epoch [4/50] - Loss: 0.5246
Epoch [5/50] - Loss: 0.4701
Epoch [6/50] - Loss: 0.4537
Epoch [7/50] - Loss: 0.4369
Epoch [8/50] - Loss: 0.4210
Epoch [9/50] - Loss: 0.3998
Epoch [10/50] - Loss: 0.3799
Epoch [11/50] - Loss: 0.3482
Epoch [12/50] - Loss: 0.3145
Epoch [13/50] - Loss: 0.2901
Epoch [14/50] - Loss: 0.2776
Epoch [15/50] - Loss: 0.2557
Epoch [16/50] - Loss: 0.2512
Epoch [17/50] - Loss: 0.2415
Epoch [18/50] - Loss: 0.2356
Epoch [19/50] - Loss: 0.2273
Epoch [20/50] - Loss: 0.2138
Epoch [21/50] - Loss: 0.2031
Epoch [22/50] - Loss: 0.1909
Epoch [23/50] - Loss: 0.1848
Epoch [24/50] - Loss: 0.1753
Epoch [25/50] - Loss: 0.1644
Epoch [26/50] - Loss: 0.1585
Epoch [27/50] - Loss: 0.1543
Epoch [28/50] - Loss: 0.1476
Epoch [29/50] - Loss: 0.1456
Epoch [30/50] - Loss: 0.1410
Epoch [31/50] - Loss: 0.1356
Epoch [32/50] - Loss: 0.1335
Epoch [33/50] - Loss: 0.1307
Epoch [34/50] - Loss: 0.1270
Epoch [35/50] - Loss: 0.1240
Epoch [36/50] - Loss: 0.1253
Epoch [37/50] - Loss: 0.1214
Epoch [38/50] - Loss: 0.1226
Epoch [39/50] - Loss: 0.1187
Epoch [40/50] - Loss: 0.1169
Epoch [41/50] - Loss: 0.1146
Epoch [42/50] - Loss: 0.1137
Epoch [43/50] - Loss: 0.1127
Epoch [44/50] - Loss: 0.1078
Epoch [45/50] - Loss: 0.1068
Epoch [46/50] - Loss: 0.1005
Epoch [47/50] - Loss: 0.0968
Epoch [48/50] - Loss: 0.0899
Epoch [49/50] - Loss: 0.0795
Epoch [50/50] - Loss: 0.0665
sum preds 36
sum labels 491
 - Test Metrics: Accuracy=0.8534, F1=0.1328, Recall=0.0713, Precision=0.9722
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4663
Epoch [2/50] - Loss: 1.1545
Epoch [3/50] - Loss: 0.8663
Epoch [4/50] - Loss: 0.6510
Epoch [5/50] - Loss: 0.5108
Epoch [6/50] - Loss: 0.4582
Epoch [7/50] - Loss: 0.4576
Epoch [8/50] - Loss: 0.4483
Epoch [9/50] - Loss: 0.4383
Epoch [10/50] - Loss: 0.4236
Epoch [11/50] - Loss: 0.3958
Epoch [12/50] - Loss: 0.3763
Epoch [13/50] - Loss: 0.3418
Epoch [14/50] - Loss: 0.3084
Epoch [15/50] - Loss: 0.2764
Epoch [16/50] - Loss: 0.2630
Epoch [17/50] - Loss: 0.2542
Epoch [18/50] - Loss: 0.2386
Epoch [19/50] - Loss: 0.2331
Epoch [20/50] - Loss: 0.2287
Epoch [21/50] - Loss: 0.2173
Epoch [22/50] - Loss: 0.2072
Epoch [23/50] - Loss: 0.1976
Epoch [24/50] - Loss: 0.1872
Epoch [25/50] - Loss: 0.1828
Epoch [26/50] - Loss: 0.1676
Epoch [27/50] - Loss: 0.1612
Epoch [28/50] - Loss: 0.1534
Epoch [29/50] - Loss: 0.1493
Epoch [30/50] - Loss: 0.1401
Epoch [31/50] - Loss: 0.1384
Epoch [32/50] - Loss: 0.1331
Epoch [33/50] - Loss: 0.1296
Epoch [34/50] - Loss: 0.1253
Epoch [35/50] - Loss: 0.1267
Epoch [36/50] - Loss: 0.1199
Epoch [37/50] - Loss: 0.1167
Epoch [38/50] - Loss: 0.1147
Epoch [39/50] - Loss: 0.1132
Epoch [40/50] - Loss: 0.1110
Epoch [41/50] - Loss: 0.1084
Epoch [42/50] - Loss: 0.1070
Epoch [43/50] - Loss: 0.1049
Epoch [44/50] - Loss: 0.1067
Epoch [45/50] - Loss: 0.1025
Epoch [46/50] - Loss: 0.1018
Epoch [47/50] - Loss: 0.1015
Epoch [48/50] - Loss: 0.1003
Epoch [49/50] - Loss: 0.0960
Epoch [50/50] - Loss: 0.0987
sum preds 33
sum labels 491
 - Test Metrics: Accuracy=0.8524, F1=0.1221, Recall=0.0652, Precision=0.9697
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_two_nnif_two_nnif_1804083535.csv.
Average F1 over valid seeds: 0.1221 ± 0.0088
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and two_nnif, MLP,0.3: 0.1221 ± 0.0088
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2420
Epoch [2/50] - Loss: 0.7066
Epoch [3/50] - Loss: 0.5023
Epoch [4/50] - Loss: 0.4532
Epoch [5/50] - Loss: 0.4511
Epoch [6/50] - Loss: 0.4528
Epoch [7/50] - Loss: 0.4380
Epoch [8/50] - Loss: 0.4069
Epoch [9/50] - Loss: 0.3693
Epoch [10/50] - Loss: 0.3359
Epoch [11/50] - Loss: 0.3074
Epoch [12/50] - Loss: 0.3012
Epoch [13/50] - Loss: 0.2925
Epoch [14/50] - Loss: 0.2864
Epoch [15/50] - Loss: 0.2868
Epoch [16/50] - Loss: 0.2806
Epoch [17/50] - Loss: 0.2723
Epoch [18/50] - Loss: 0.2614
Epoch [19/50] - Loss: 0.2567
Epoch [20/50] - Loss: 0.2432
Epoch [21/50] - Loss: 0.2401
Epoch [22/50] - Loss: 0.2363
Epoch [23/50] - Loss: 0.2267
Epoch [24/50] - Loss: 0.2206
Epoch [25/50] - Loss: 0.2234
Epoch [26/50] - Loss: 0.2160
Epoch [27/50] - Loss: 0.2084
Epoch [28/50] - Loss: 0.2055
Epoch [29/50] - Loss: 0.2031
Epoch [30/50] - Loss: 0.1962
Epoch [31/50] - Loss: 0.1945
Epoch [32/50] - Loss: 0.1970
Epoch [33/50] - Loss: 0.1901
Epoch [34/50] - Loss: 0.1863
Epoch [35/50] - Loss: 0.1866
Epoch [36/50] - Loss: 0.1863
Epoch [37/50] - Loss: 0.1767
Epoch [38/50] - Loss: 0.1798
Epoch [39/50] - Loss: 0.1807
Epoch [40/50] - Loss: 0.1770
Epoch [41/50] - Loss: 0.1756
Epoch [42/50] - Loss: 0.1717
Epoch [43/50] - Loss: 0.1774
Epoch [44/50] - Loss: 0.1701
Epoch [45/50] - Loss: 0.1685
Epoch [46/50] - Loss: 0.1662
Epoch [47/50] - Loss: 0.1658
Epoch [48/50] - Loss: 0.1662
Epoch [49/50] - Loss: 0.1600
Epoch [50/50] - Loss: 0.1579
sum preds 71
sum labels 491
 - Test Metrics: Accuracy=0.8614, F1=0.2313, Recall=0.1324, Precision=0.9155
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0890
Epoch [2/50] - Loss: 0.5371
Epoch [3/50] - Loss: 0.4542
Epoch [4/50] - Loss: 0.4813
Epoch [5/50] - Loss: 0.4581
Epoch [6/50] - Loss: 0.4110
Epoch [7/50] - Loss: 0.3470
Epoch [8/50] - Loss: 0.3121
Epoch [9/50] - Loss: 0.2921
Epoch [10/50] - Loss: 0.2877
Epoch [11/50] - Loss: 0.2805
Epoch [12/50] - Loss: 0.2751
Epoch [13/50] - Loss: 0.2727
Epoch [14/50] - Loss: 0.2531
Epoch [15/50] - Loss: 0.2478
Epoch [16/50] - Loss: 0.2314
Epoch [17/50] - Loss: 0.2269
Epoch [18/50] - Loss: 0.2201
Epoch [19/50] - Loss: 0.2190
Epoch [20/50] - Loss: 0.2125
Epoch [21/50] - Loss: 0.2092
Epoch [22/50] - Loss: 0.2017
Epoch [23/50] - Loss: 0.1976
Epoch [24/50] - Loss: 0.1860
Epoch [25/50] - Loss: 0.1837
Epoch [26/50] - Loss: 0.1789
Epoch [27/50] - Loss: 0.1755
Epoch [28/50] - Loss: 0.1710
Epoch [29/50] - Loss: 0.1730
Epoch [30/50] - Loss: 0.1616
Epoch [31/50] - Loss: 0.1606
Epoch [32/50] - Loss: 0.1583
Epoch [33/50] - Loss: 0.1562
Epoch [34/50] - Loss: 0.1504
Epoch [35/50] - Loss: 0.1512
Epoch [36/50] - Loss: 0.1464
Epoch [37/50] - Loss: 0.1403
Epoch [38/50] - Loss: 0.1381
Epoch [39/50] - Loss: 0.1391
Epoch [40/50] - Loss: 0.1360
Epoch [41/50] - Loss: 0.1410
Epoch [42/50] - Loss: 0.1355
Epoch [43/50] - Loss: 0.1321
Epoch [44/50] - Loss: 0.1340
Epoch [45/50] - Loss: 0.1263
Epoch [46/50] - Loss: 0.1282
Epoch [47/50] - Loss: 0.1251
Epoch [48/50] - Loss: 0.1195
Epoch [49/50] - Loss: 0.1238
Epoch [50/50] - Loss: 0.1242
sum preds 99
sum labels 491
 - Test Metrics: Accuracy=0.8646, F1=0.2847, Recall=0.1711, Precision=0.8485
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1612
Epoch [2/50] - Loss: 0.6253
Epoch [3/50] - Loss: 0.4617
Epoch [4/50] - Loss: 0.4582
Epoch [5/50] - Loss: 0.4575
Epoch [6/50] - Loss: 0.4526
Epoch [7/50] - Loss: 0.4060
Epoch [8/50] - Loss: 0.3705
Epoch [9/50] - Loss: 0.3179
Epoch [10/50] - Loss: 0.2960
Epoch [11/50] - Loss: 0.2900
Epoch [12/50] - Loss: 0.2817
Epoch [13/50] - Loss: 0.2752
Epoch [14/50] - Loss: 0.2702
Epoch [15/50] - Loss: 0.2652
Epoch [16/50] - Loss: 0.2566
Epoch [17/50] - Loss: 0.2446
Epoch [18/50] - Loss: 0.2406
Epoch [19/50] - Loss: 0.2292
Epoch [20/50] - Loss: 0.2262
Epoch [21/50] - Loss: 0.2225
Epoch [22/50] - Loss: 0.2190
Epoch [23/50] - Loss: 0.2134
Epoch [24/50] - Loss: 0.2117
Epoch [25/50] - Loss: 0.2045
Epoch [26/50] - Loss: 0.2014
Epoch [27/50] - Loss: 0.1967
Epoch [28/50] - Loss: 0.1881
Epoch [29/50] - Loss: 0.1957
Epoch [30/50] - Loss: 0.1886
Epoch [31/50] - Loss: 0.1844
Epoch [32/50] - Loss: 0.1845
Epoch [33/50] - Loss: 0.1814
Epoch [34/50] - Loss: 0.1754
Epoch [35/50] - Loss: 0.1765
Epoch [36/50] - Loss: 0.1768
Epoch [37/50] - Loss: 0.1718
Epoch [38/50] - Loss: 0.1658
Epoch [39/50] - Loss: 0.1639
Epoch [40/50] - Loss: 0.1630
Epoch [41/50] - Loss: 0.1591
Epoch [42/50] - Loss: 0.1569
Epoch [43/50] - Loss: 0.1572
Epoch [44/50] - Loss: 0.1512
Epoch [45/50] - Loss: 0.1526
Epoch [46/50] - Loss: 0.1445
Epoch [47/50] - Loss: 0.1472
Epoch [48/50] - Loss: 0.1404
Epoch [49/50] - Loss: 0.1387
Epoch [50/50] - Loss: 0.1338
sum preds 113
sum labels 491
 - Test Metrics: Accuracy=0.8723, F1=0.3411, Recall=0.2098, Precision=0.9115
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_two_nnif_two_nnif_1804083641.csv.
Average F1 over valid seeds: 0.2857 ± 0.0448
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and two_nnif, GATConv,0.3: 0.2857 ± 0.0448
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2648
Epoch [2/50] - Loss: 0.7527
Epoch [3/50] - Loss: 0.5261
Epoch [4/50] - Loss: 0.4748
Epoch [5/50] - Loss: 0.4743
Epoch [6/50] - Loss: 0.4713
Epoch [7/50] - Loss: 0.4487
Epoch [8/50] - Loss: 0.4234
Epoch [9/50] - Loss: 0.3983
Epoch [10/50] - Loss: 0.3675
Epoch [11/50] - Loss: 0.3273
Epoch [12/50] - Loss: 0.3154
Epoch [13/50] - Loss: 0.3053
Epoch [14/50] - Loss: 0.3039
Epoch [15/50] - Loss: 0.2990
Epoch [16/50] - Loss: 0.2993
Epoch [17/50] - Loss: 0.2882
Epoch [18/50] - Loss: 0.2823
Epoch [19/50] - Loss: 0.2730
Epoch [20/50] - Loss: 0.2671
Epoch [21/50] - Loss: 0.2643
Epoch [22/50] - Loss: 0.2572
Epoch [23/50] - Loss: 0.2521
Epoch [24/50] - Loss: 0.2516
Epoch [25/50] - Loss: 0.2496
Epoch [26/50] - Loss: 0.2347
Epoch [27/50] - Loss: 0.2386
Epoch [28/50] - Loss: 0.2376
Epoch [29/50] - Loss: 0.2331
Epoch [30/50] - Loss: 0.2329
Epoch [31/50] - Loss: 0.2254
Epoch [32/50] - Loss: 0.2272
Epoch [33/50] - Loss: 0.2261
Epoch [34/50] - Loss: 0.2218
Epoch [35/50] - Loss: 0.2240
Epoch [36/50] - Loss: 0.2210
Epoch [37/50] - Loss: 0.2160
Epoch [38/50] - Loss: 0.2092
Epoch [39/50] - Loss: 0.2188
Epoch [40/50] - Loss: 0.2165
Epoch [41/50] - Loss: 0.2107
Epoch [42/50] - Loss: 0.2101
Epoch [43/50] - Loss: 0.2113
Epoch [44/50] - Loss: 0.2088
Epoch [45/50] - Loss: 0.2044
Epoch [46/50] - Loss: 0.2058
Epoch [47/50] - Loss: 0.2007
Epoch [48/50] - Loss: 0.2026
Epoch [49/50] - Loss: 0.2007
Epoch [50/50] - Loss: 0.2084
sum preds 0
sum labels 491
 - Test Metrics: Accuracy=0.8425, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0198
Epoch [2/50] - Loss: 0.5098
Epoch [3/50] - Loss: 0.4805
Epoch [4/50] - Loss: 0.5054
Epoch [5/50] - Loss: 0.4477
Epoch [6/50] - Loss: 0.3790
Epoch [7/50] - Loss: 0.3194
Epoch [8/50] - Loss: 0.3010
Epoch [9/50] - Loss: 0.2907
Epoch [10/50] - Loss: 0.3020
Epoch [11/50] - Loss: 0.2982
Epoch [12/50] - Loss: 0.2903
Epoch [13/50] - Loss: 0.2787
Epoch [14/50] - Loss: 0.2670
Epoch [15/50] - Loss: 0.2615
Epoch [16/50] - Loss: 0.2559
Epoch [17/50] - Loss: 0.2479
Epoch [18/50] - Loss: 0.2482
Epoch [19/50] - Loss: 0.2431
Epoch [20/50] - Loss: 0.2343
Epoch [21/50] - Loss: 0.2356
Epoch [22/50] - Loss: 0.2281
Epoch [23/50] - Loss: 0.2297
Epoch [24/50] - Loss: 0.2268
Epoch [25/50] - Loss: 0.2214
Epoch [26/50] - Loss: 0.2213
Epoch [27/50] - Loss: 0.2166
Epoch [28/50] - Loss: 0.2159
Epoch [29/50] - Loss: 0.2156
Epoch [30/50] - Loss: 0.2175
Epoch [31/50] - Loss: 0.2113
Epoch [32/50] - Loss: 0.2160
Epoch [33/50] - Loss: 0.2095
Epoch [34/50] - Loss: 0.2071
Epoch [35/50] - Loss: 0.2033
Epoch [36/50] - Loss: 0.2070
Epoch [37/50] - Loss: 0.2012
Epoch [38/50] - Loss: 0.2073
Epoch [39/50] - Loss: 0.2039
Epoch [40/50] - Loss: 0.2003
Epoch [41/50] - Loss: 0.1962
Epoch [42/50] - Loss: 0.1977
Epoch [43/50] - Loss: 0.2003
Epoch [44/50] - Loss: 0.1965
Epoch [45/50] - Loss: 0.1979
Epoch [46/50] - Loss: 0.1907
Epoch [47/50] - Loss: 0.1960
Epoch [48/50] - Loss: 0.1935
Epoch [49/50] - Loss: 0.1897
Epoch [50/50] - Loss: 0.1902
sum preds 80
sum labels 491
 - Test Metrics: Accuracy=0.8662, F1=0.2697, Recall=0.1568, Precision=0.9625
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1109
Epoch [2/50] - Loss: 0.5653
Epoch [3/50] - Loss: 0.4676
Epoch [4/50] - Loss: 0.4813
Epoch [5/50] - Loss: 0.4710
Epoch [6/50] - Loss: 0.4371
Epoch [7/50] - Loss: 0.3816
Epoch [8/50] - Loss: 0.3277
Epoch [9/50] - Loss: 0.2995
Epoch [10/50] - Loss: 0.2888
Epoch [11/50] - Loss: 0.2881
Epoch [12/50] - Loss: 0.2839
Epoch [13/50] - Loss: 0.2793
Epoch [14/50] - Loss: 0.2722
Epoch [15/50] - Loss: 0.2672
Epoch [16/50] - Loss: 0.2545
Epoch [17/50] - Loss: 0.2440
Epoch [18/50] - Loss: 0.2410
Epoch [19/50] - Loss: 0.2339
Epoch [20/50] - Loss: 0.2301
Epoch [21/50] - Loss: 0.2334
Epoch [22/50] - Loss: 0.2257
Epoch [23/50] - Loss: 0.2243
Epoch [24/50] - Loss: 0.2234
Epoch [25/50] - Loss: 0.2174
Epoch [26/50] - Loss: 0.2146
Epoch [27/50] - Loss: 0.2066
Epoch [28/50] - Loss: 0.2045
Epoch [29/50] - Loss: 0.2040
Epoch [30/50] - Loss: 0.2034
Epoch [31/50] - Loss: 0.2009
Epoch [32/50] - Loss: 0.2038
Epoch [33/50] - Loss: 0.1982
Epoch [34/50] - Loss: 0.1955
Epoch [35/50] - Loss: 0.2017
Epoch [36/50] - Loss: 0.2002
Epoch [37/50] - Loss: 0.1962
Epoch [38/50] - Loss: 0.1983
Epoch [39/50] - Loss: 0.1899
Epoch [40/50] - Loss: 0.1938
Epoch [41/50] - Loss: 0.1870
Epoch [42/50] - Loss: 0.1933
Epoch [43/50] - Loss: 0.1915
Epoch [44/50] - Loss: 0.1875
Epoch [45/50] - Loss: 0.1917
Epoch [46/50] - Loss: 0.1895
Epoch [47/50] - Loss: 0.1835
Epoch [48/50] - Loss: 0.1862
Epoch [49/50] - Loss: 0.1825
Epoch [50/50] - Loss: 0.1847
sum preds 72
sum labels 491
 - Test Metrics: Accuracy=0.8617, F1=0.2345, Recall=0.1344, Precision=0.9167
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_two_nnif_two_nnif_1804083758.csv.
Average F1 over valid seeds: 0.1681 ± 0.1197
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and two_nnif, GCNConv,0.3: 0.1681 ± 0.1197
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4172
Epoch [2/50] - Loss: 1.0299
Epoch [3/50] - Loss: 0.7020
Epoch [4/50] - Loss: 0.4873
Epoch [5/50] - Loss: 0.3785
Epoch [6/50] - Loss: 0.3547
Epoch [7/50] - Loss: 0.3437
Epoch [8/50] - Loss: 0.3625
Epoch [9/50] - Loss: 0.3636
Epoch [10/50] - Loss: 0.3580
Epoch [11/50] - Loss: 0.3245
Epoch [12/50] - Loss: 0.3082
Epoch [13/50] - Loss: 0.2660
Epoch [14/50] - Loss: 0.2353
Epoch [15/50] - Loss: 0.2231
Epoch [16/50] - Loss: 0.1963
Epoch [17/50] - Loss: 0.1888
Epoch [18/50] - Loss: 0.1784
Epoch [19/50] - Loss: 0.1729
Epoch [20/50] - Loss: 0.1651
Epoch [21/50] - Loss: 0.1597
Epoch [22/50] - Loss: 0.1503
Epoch [23/50] - Loss: 0.1485
Epoch [24/50] - Loss: 0.1356
Epoch [25/50] - Loss: 0.1272
Epoch [26/50] - Loss: 0.1189
Epoch [27/50] - Loss: 0.1137
Epoch [28/50] - Loss: 0.1065
Epoch [29/50] - Loss: 0.1028
Epoch [30/50] - Loss: 0.1002
Epoch [31/50] - Loss: 0.0985
Epoch [32/50] - Loss: 0.0912
Epoch [33/50] - Loss: 0.0899
Epoch [34/50] - Loss: 0.0873
Epoch [35/50] - Loss: 0.0842
Epoch [36/50] - Loss: 0.0829
Epoch [37/50] - Loss: 0.0781
Epoch [38/50] - Loss: 0.0783
Epoch [39/50] - Loss: 0.0763
Epoch [40/50] - Loss: 0.0767
Epoch [41/50] - Loss: 0.0757
Epoch [42/50] - Loss: 0.0740
Epoch [43/50] - Loss: 0.0763
Epoch [44/50] - Loss: 0.0736
Epoch [45/50] - Loss: 0.0718
Epoch [46/50] - Loss: 0.0688
Epoch [47/50] - Loss: 0.0712
Epoch [48/50] - Loss: 0.0688
Epoch [49/50] - Loss: 0.0702
Epoch [50/50] - Loss: 0.0685
sum preds 8
sum labels 561
 - Test Metrics: Accuracy=0.8246, F1=0.0176, Recall=0.0089, Precision=0.6250
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1567
Epoch [2/50] - Loss: 0.8397
Epoch [3/50] - Loss: 0.6031
Epoch [4/50] - Loss: 0.4469
Epoch [5/50] - Loss: 0.3812
Epoch [6/50] - Loss: 0.3507
Epoch [7/50] - Loss: 0.3401
Epoch [8/50] - Loss: 0.3301
Epoch [9/50] - Loss: 0.3202
Epoch [10/50] - Loss: 0.3199
Epoch [11/50] - Loss: 0.2941
Epoch [12/50] - Loss: 0.2674
Epoch [13/50] - Loss: 0.2395
Epoch [14/50] - Loss: 0.2409
Epoch [15/50] - Loss: 0.2120
Epoch [16/50] - Loss: 0.1932
Epoch [17/50] - Loss: 0.1847
Epoch [18/50] - Loss: 0.1853
Epoch [19/50] - Loss: 0.1770
Epoch [20/50] - Loss: 0.1691
Epoch [21/50] - Loss: 0.1643
Epoch [22/50] - Loss: 0.1549
Epoch [23/50] - Loss: 0.1476
Epoch [24/50] - Loss: 0.1424
Epoch [25/50] - Loss: 0.1333
Epoch [26/50] - Loss: 0.1305
Epoch [27/50] - Loss: 0.1219
Epoch [28/50] - Loss: 0.1203
Epoch [29/50] - Loss: 0.1130
Epoch [30/50] - Loss: 0.1074
Epoch [31/50] - Loss: 0.1093
Epoch [32/50] - Loss: 0.1012
Epoch [33/50] - Loss: 0.0954
Epoch [34/50] - Loss: 0.1002
Epoch [35/50] - Loss: 0.0986
Epoch [36/50] - Loss: 0.0941
Epoch [37/50] - Loss: 0.0910
Epoch [38/50] - Loss: 0.0903
Epoch [39/50] - Loss: 0.0912
Epoch [40/50] - Loss: 0.0889
Epoch [41/50] - Loss: 0.0870
Epoch [42/50] - Loss: 0.0851
Epoch [43/50] - Loss: 0.0841
Epoch [44/50] - Loss: 0.0832
Epoch [45/50] - Loss: 0.0853
Epoch [46/50] - Loss: 0.0829
Epoch [47/50] - Loss: 0.0812
Epoch [48/50] - Loss: 0.0833
Epoch [49/50] - Loss: 0.0809
Epoch [50/50] - Loss: 0.0802
sum preds 2
sum labels 561
 - Test Metrics: Accuracy=0.8246, F1=0.0071, Recall=0.0036, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4706
Epoch [2/50] - Loss: 1.1465
Epoch [3/50] - Loss: 0.8381
Epoch [4/50] - Loss: 0.5998
Epoch [5/50] - Loss: 0.4462
Epoch [6/50] - Loss: 0.3800
Epoch [7/50] - Loss: 0.3615
Epoch [8/50] - Loss: 0.3610
Epoch [9/50] - Loss: 0.3587
Epoch [10/50] - Loss: 0.3547
Epoch [11/50] - Loss: 0.3298
Epoch [12/50] - Loss: 0.3098
Epoch [13/50] - Loss: 0.2947
Epoch [14/50] - Loss: 0.2832
Epoch [15/50] - Loss: 0.2481
Epoch [16/50] - Loss: 0.2246
Epoch [17/50] - Loss: 0.2063
Epoch [18/50] - Loss: 0.1969
Epoch [19/50] - Loss: 0.1859
Epoch [20/50] - Loss: 0.1751
Epoch [21/50] - Loss: 0.1676
Epoch [22/50] - Loss: 0.1645
Epoch [23/50] - Loss: 0.1611
Epoch [24/50] - Loss: 0.1514
Epoch [25/50] - Loss: 0.1437
Epoch [26/50] - Loss: 0.1360
Epoch [27/50] - Loss: 0.1267
Epoch [28/50] - Loss: 0.1208
Epoch [29/50] - Loss: 0.1181
Epoch [30/50] - Loss: 0.1091
Epoch [31/50] - Loss: 0.1067
Epoch [32/50] - Loss: 0.1043
Epoch [33/50] - Loss: 0.0986
Epoch [34/50] - Loss: 0.0933
Epoch [35/50] - Loss: 0.0888
Epoch [36/50] - Loss: 0.0882
Epoch [37/50] - Loss: 0.0871
Epoch [38/50] - Loss: 0.0825
Epoch [39/50] - Loss: 0.0797
Epoch [40/50] - Loss: 0.0806
Epoch [41/50] - Loss: 0.0813
Epoch [42/50] - Loss: 0.0784
Epoch [43/50] - Loss: 0.0762
Epoch [44/50] - Loss: 0.0765
Epoch [45/50] - Loss: 0.0727
Epoch [46/50] - Loss: 0.0745
Epoch [47/50] - Loss: 0.0739
Epoch [48/50] - Loss: 0.0712
Epoch [49/50] - Loss: 0.0708
Epoch [50/50] - Loss: 0.0718
sum preds 14
sum labels 561
 - Test Metrics: Accuracy=0.8284, F1=0.0487, Recall=0.0250, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_two_nnif_two_nnif_1804083905.csv.
Average F1 over valid seeds: 0.0245 ± 0.0177
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and two_nnif, MLP,0.2: 0.0245 ± 0.0177
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2344
Epoch [2/50] - Loss: 0.6571
Epoch [3/50] - Loss: 0.4199
Epoch [4/50] - Loss: 0.3540
Epoch [5/50] - Loss: 0.3517
Epoch [6/50] - Loss: 0.3544
Epoch [7/50] - Loss: 0.3735
Epoch [8/50] - Loss: 0.3467
Epoch [9/50] - Loss: 0.3354
Epoch [10/50] - Loss: 0.3012
Epoch [11/50] - Loss: 0.2765
Epoch [12/50] - Loss: 0.2577
Epoch [13/50] - Loss: 0.2430
Epoch [14/50] - Loss: 0.2299
Epoch [15/50] - Loss: 0.2239
Epoch [16/50] - Loss: 0.2241
Epoch [17/50] - Loss: 0.2145
Epoch [18/50] - Loss: 0.2171
Epoch [19/50] - Loss: 0.2134
Epoch [20/50] - Loss: 0.2012
Epoch [21/50] - Loss: 0.1950
Epoch [22/50] - Loss: 0.1914
Epoch [23/50] - Loss: 0.1810
Epoch [24/50] - Loss: 0.1753
Epoch [25/50] - Loss: 0.1740
Epoch [26/50] - Loss: 0.1684
Epoch [27/50] - Loss: 0.1616
Epoch [28/50] - Loss: 0.1647
Epoch [29/50] - Loss: 0.1591
Epoch [30/50] - Loss: 0.1508
Epoch [31/50] - Loss: 0.1468
Epoch [32/50] - Loss: 0.1467
Epoch [33/50] - Loss: 0.1460
Epoch [34/50] - Loss: 0.1374
Epoch [35/50] - Loss: 0.1405
Epoch [36/50] - Loss: 0.1368
Epoch [37/50] - Loss: 0.1321
Epoch [38/50] - Loss: 0.1320
Epoch [39/50] - Loss: 0.1294
Epoch [40/50] - Loss: 0.1294
Epoch [41/50] - Loss: 0.1241
Epoch [42/50] - Loss: 0.1250
Epoch [43/50] - Loss: 0.1271
Epoch [44/50] - Loss: 0.1207
Epoch [45/50] - Loss: 0.1208
Epoch [46/50] - Loss: 0.1260
Epoch [47/50] - Loss: 0.1175
Epoch [48/50] - Loss: 0.1119
Epoch [49/50] - Loss: 0.1150
Epoch [50/50] - Loss: 0.1115
sum preds 17
sum labels 561
 - Test Metrics: Accuracy=0.8255, F1=0.0381, Recall=0.0196, Precision=0.6471
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0729
Epoch [2/50] - Loss: 0.4648
Epoch [3/50] - Loss: 0.3574
Epoch [4/50] - Loss: 0.3672
Epoch [5/50] - Loss: 0.3808
Epoch [6/50] - Loss: 0.3482
Epoch [7/50] - Loss: 0.3168
Epoch [8/50] - Loss: 0.2888
Epoch [9/50] - Loss: 0.2343
Epoch [10/50] - Loss: 0.2156
Epoch [11/50] - Loss: 0.2117
Epoch [12/50] - Loss: 0.2023
Epoch [13/50] - Loss: 0.2085
Epoch [14/50] - Loss: 0.1985
Epoch [15/50] - Loss: 0.1982
Epoch [16/50] - Loss: 0.1851
Epoch [17/50] - Loss: 0.1823
Epoch [18/50] - Loss: 0.1715
Epoch [19/50] - Loss: 0.1666
Epoch [20/50] - Loss: 0.1582
Epoch [21/50] - Loss: 0.1567
Epoch [22/50] - Loss: 0.1546
Epoch [23/50] - Loss: 0.1456
Epoch [24/50] - Loss: 0.1469
Epoch [25/50] - Loss: 0.1394
Epoch [26/50] - Loss: 0.1377
Epoch [27/50] - Loss: 0.1348
Epoch [28/50] - Loss: 0.1348
Epoch [29/50] - Loss: 0.1261
Epoch [30/50] - Loss: 0.1238
Epoch [31/50] - Loss: 0.1209
Epoch [32/50] - Loss: 0.1127
Epoch [33/50] - Loss: 0.1101
Epoch [34/50] - Loss: 0.1079
Epoch [35/50] - Loss: 0.1053
Epoch [36/50] - Loss: 0.1017
Epoch [37/50] - Loss: 0.1013
Epoch [38/50] - Loss: 0.1043
Epoch [39/50] - Loss: 0.0977
Epoch [40/50] - Loss: 0.0941
Epoch [41/50] - Loss: 0.0931
Epoch [42/50] - Loss: 0.0883
Epoch [43/50] - Loss: 0.0919
Epoch [44/50] - Loss: 0.0982
Epoch [45/50] - Loss: 0.0875
Epoch [46/50] - Loss: 0.0838
Epoch [47/50] - Loss: 0.0825
Epoch [48/50] - Loss: 0.0827
Epoch [49/50] - Loss: 0.0810
Epoch [50/50] - Loss: 0.0816
sum preds 52
sum labels 561
 - Test Metrics: Accuracy=0.8378, F1=0.1566, Recall=0.0856, Precision=0.9231
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1468
Epoch [2/50] - Loss: 0.5634
Epoch [3/50] - Loss: 0.3796
Epoch [4/50] - Loss: 0.3471
Epoch [5/50] - Loss: 0.3536
Epoch [6/50] - Loss: 0.3574
Epoch [7/50] - Loss: 0.3583
Epoch [8/50] - Loss: 0.3431
Epoch [9/50] - Loss: 0.3022
Epoch [10/50] - Loss: 0.2720
Epoch [11/50] - Loss: 0.2518
Epoch [12/50] - Loss: 0.2236
Epoch [13/50] - Loss: 0.2200
Epoch [14/50] - Loss: 0.2173
Epoch [15/50] - Loss: 0.2109
Epoch [16/50] - Loss: 0.2072
Epoch [17/50] - Loss: 0.1999
Epoch [18/50] - Loss: 0.1975
Epoch [19/50] - Loss: 0.1872
Epoch [20/50] - Loss: 0.1844
Epoch [21/50] - Loss: 0.1811
Epoch [22/50] - Loss: 0.1686
Epoch [23/50] - Loss: 0.1665
Epoch [24/50] - Loss: 0.1654
Epoch [25/50] - Loss: 0.1664
Epoch [26/50] - Loss: 0.1618
Epoch [27/50] - Loss: 0.1522
Epoch [28/50] - Loss: 0.1554
Epoch [29/50] - Loss: 0.1467
Epoch [30/50] - Loss: 0.1460
Epoch [31/50] - Loss: 0.1434
Epoch [32/50] - Loss: 0.1424
Epoch [33/50] - Loss: 0.1380
Epoch [34/50] - Loss: 0.1373
Epoch [35/50] - Loss: 0.1368
Epoch [36/50] - Loss: 0.1353
Epoch [37/50] - Loss: 0.1357
Epoch [38/50] - Loss: 0.1341
Epoch [39/50] - Loss: 0.1279
Epoch [40/50] - Loss: 0.1276
Epoch [41/50] - Loss: 0.1278
Epoch [42/50] - Loss: 0.1279
Epoch [43/50] - Loss: 0.1263
Epoch [44/50] - Loss: 0.1157
Epoch [45/50] - Loss: 0.1128
Epoch [46/50] - Loss: 0.1166
Epoch [47/50] - Loss: 0.1132
Epoch [48/50] - Loss: 0.1126
Epoch [49/50] - Loss: 0.1085
Epoch [50/50] - Loss: 0.1047
sum preds 59
sum labels 561
 - Test Metrics: Accuracy=0.8375, F1=0.1645, Recall=0.0909, Precision=0.8644
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_two_nnif_two_nnif_1804084011.csv.
Average F1 over valid seeds: 0.1197 ± 0.0578
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and two_nnif, GATConv,0.2: 0.1197 ± 0.0578
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2592
Epoch [2/50] - Loss: 0.7056
Epoch [3/50] - Loss: 0.4521
Epoch [4/50] - Loss: 0.3731
Epoch [5/50] - Loss: 0.3568
Epoch [6/50] - Loss: 0.3699
Epoch [7/50] - Loss: 0.3791
Epoch [8/50] - Loss: 0.3607
Epoch [9/50] - Loss: 0.3417
Epoch [10/50] - Loss: 0.3279
Epoch [11/50] - Loss: 0.3059
Epoch [12/50] - Loss: 0.2802
Epoch [13/50] - Loss: 0.2589
Epoch [14/50] - Loss: 0.2408
Epoch [15/50] - Loss: 0.2319
Epoch [16/50] - Loss: 0.2304
Epoch [17/50] - Loss: 0.2299
Epoch [18/50] - Loss: 0.2273
Epoch [19/50] - Loss: 0.2244
Epoch [20/50] - Loss: 0.2161
Epoch [21/50] - Loss: 0.2099
Epoch [22/50] - Loss: 0.2072
Epoch [23/50] - Loss: 0.1997
Epoch [24/50] - Loss: 0.1933
Epoch [25/50] - Loss: 0.1869
Epoch [26/50] - Loss: 0.1841
Epoch [27/50] - Loss: 0.1904
Epoch [28/50] - Loss: 0.1887
Epoch [29/50] - Loss: 0.1801
Epoch [30/50] - Loss: 0.1804
Epoch [31/50] - Loss: 0.1771
Epoch [32/50] - Loss: 0.1755
Epoch [33/50] - Loss: 0.1703
Epoch [34/50] - Loss: 0.1655
Epoch [35/50] - Loss: 0.1693
Epoch [36/50] - Loss: 0.1587
Epoch [37/50] - Loss: 0.1668
Epoch [38/50] - Loss: 0.1595
Epoch [39/50] - Loss: 0.1631
Epoch [40/50] - Loss: 0.1583
Epoch [41/50] - Loss: 0.1565
Epoch [42/50] - Loss: 0.1552
Epoch [43/50] - Loss: 0.1594
Epoch [44/50] - Loss: 0.1495
Epoch [45/50] - Loss: 0.1480
Epoch [46/50] - Loss: 0.1501
Epoch [47/50] - Loss: 0.1452
Epoch [48/50] - Loss: 0.1504
Epoch [49/50] - Loss: 0.1481
Epoch [50/50] - Loss: 0.1473
sum preds 5
sum labels 561
 - Test Metrics: Accuracy=0.8249, F1=0.0141, Recall=0.0071, Precision=0.8000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.9936
Epoch [2/50] - Loss: 0.4200
Epoch [3/50] - Loss: 0.3792
Epoch [4/50] - Loss: 0.4012
Epoch [5/50] - Loss: 0.3877
Epoch [6/50] - Loss: 0.3446
Epoch [7/50] - Loss: 0.2943
Epoch [8/50] - Loss: 0.2539
Epoch [9/50] - Loss: 0.2326
Epoch [10/50] - Loss: 0.2230
Epoch [11/50] - Loss: 0.2230
Epoch [12/50] - Loss: 0.2189
Epoch [13/50] - Loss: 0.2189
Epoch [14/50] - Loss: 0.2155
Epoch [15/50] - Loss: 0.2041
Epoch [16/50] - Loss: 0.1961
Epoch [17/50] - Loss: 0.1849
Epoch [18/50] - Loss: 0.1834
Epoch [19/50] - Loss: 0.1799
Epoch [20/50] - Loss: 0.1741
Epoch [21/50] - Loss: 0.1762
Epoch [22/50] - Loss: 0.1687
Epoch [23/50] - Loss: 0.1737
Epoch [24/50] - Loss: 0.1600
Epoch [25/50] - Loss: 0.1651
Epoch [26/50] - Loss: 0.1551
Epoch [27/50] - Loss: 0.1631
Epoch [28/50] - Loss: 0.1611
Epoch [29/50] - Loss: 0.1559
Epoch [30/50] - Loss: 0.1554
Epoch [31/50] - Loss: 0.1575
Epoch [32/50] - Loss: 0.1545
Epoch [33/50] - Loss: 0.1532
Epoch [34/50] - Loss: 0.1496
Epoch [35/50] - Loss: 0.1492
Epoch [36/50] - Loss: 0.1525
Epoch [37/50] - Loss: 0.1430
Epoch [38/50] - Loss: 0.1466
Epoch [39/50] - Loss: 0.1498
Epoch [40/50] - Loss: 0.1477
Epoch [41/50] - Loss: 0.1467
Epoch [42/50] - Loss: 0.1441
Epoch [43/50] - Loss: 0.1430
Epoch [44/50] - Loss: 0.1454
Epoch [45/50] - Loss: 0.1446
Epoch [46/50] - Loss: 0.1413
Epoch [47/50] - Loss: 0.1393
Epoch [48/50] - Loss: 0.1411
Epoch [49/50] - Loss: 0.1414
Epoch [50/50] - Loss: 0.1393
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0966
Epoch [2/50] - Loss: 0.4918
Epoch [3/50] - Loss: 0.3666
Epoch [4/50] - Loss: 0.3722
Epoch [5/50] - Loss: 0.3743
Epoch [6/50] - Loss: 0.3746
Epoch [7/50] - Loss: 0.3536
Epoch [8/50] - Loss: 0.3242
Epoch [9/50] - Loss: 0.2835
Epoch [10/50] - Loss: 0.2548
Epoch [11/50] - Loss: 0.2316
Epoch [12/50] - Loss: 0.2205
Epoch [13/50] - Loss: 0.2206
Epoch [14/50] - Loss: 0.2149
Epoch [15/50] - Loss: 0.2200
Epoch [16/50] - Loss: 0.2156
Epoch [17/50] - Loss: 0.2062
Epoch [18/50] - Loss: 0.1957
Epoch [19/50] - Loss: 0.1847
Epoch [20/50] - Loss: 0.1788
Epoch [21/50] - Loss: 0.1744
Epoch [22/50] - Loss: 0.1770
Epoch [23/50] - Loss: 0.1712
Epoch [24/50] - Loss: 0.1720
Epoch [25/50] - Loss: 0.1683
Epoch [26/50] - Loss: 0.1598
Epoch [27/50] - Loss: 0.1597
Epoch [28/50] - Loss: 0.1542
Epoch [29/50] - Loss: 0.1571
Epoch [30/50] - Loss: 0.1537
Epoch [31/50] - Loss: 0.1503
Epoch [32/50] - Loss: 0.1494
Epoch [33/50] - Loss: 0.1480
Epoch [34/50] - Loss: 0.1526
Epoch [35/50] - Loss: 0.1502
Epoch [36/50] - Loss: 0.1499
Epoch [37/50] - Loss: 0.1461
Epoch [38/50] - Loss: 0.1487
Epoch [39/50] - Loss: 0.1471
Epoch [40/50] - Loss: 0.1418
Epoch [41/50] - Loss: 0.1439
Epoch [42/50] - Loss: 0.1431
Epoch [43/50] - Loss: 0.1418
Epoch [44/50] - Loss: 0.1410
Epoch [45/50] - Loss: 0.1329
Epoch [46/50] - Loss: 0.1365
Epoch [47/50] - Loss: 0.1395
Epoch [48/50] - Loss: 0.1351
Epoch [49/50] - Loss: 0.1351
Epoch [50/50] - Loss: 0.1357
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_two_nnif_two_nnif_1804084120.csv.
Average F1 over valid seeds: 0.0047 ± 0.0067
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and two_nnif, GCNConv,0.2: 0.0047 ± 0.0067
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7131
Epoch [2/50] - Loss: 0.6712
Epoch [3/50] - Loss: 0.6250
Epoch [4/50] - Loss: 0.5757
Epoch [5/50] - Loss: 0.5248
Epoch [6/50] - Loss: 0.4738
Epoch [7/50] - Loss: 0.4247
Epoch [8/50] - Loss: 0.3788
Epoch [9/50] - Loss: 0.3365
Epoch [10/50] - Loss: 0.2978
Epoch [11/50] - Loss: 0.2623
Epoch [12/50] - Loss: 0.2299
Epoch [13/50] - Loss: 0.2005
Epoch [14/50] - Loss: 0.1740
Epoch [15/50] - Loss: 0.1501
Epoch [16/50] - Loss: 0.1288
Epoch [17/50] - Loss: 0.1100
Epoch [18/50] - Loss: 0.0935
Epoch [19/50] - Loss: 0.0791
Epoch [20/50] - Loss: 0.0668
Epoch [21/50] - Loss: 0.0563
Epoch [22/50] - Loss: 0.0475
Epoch [23/50] - Loss: 0.0401
Epoch [24/50] - Loss: 0.0340
Epoch [25/50] - Loss: 0.0290
Epoch [26/50] - Loss: 0.0248
Epoch [27/50] - Loss: 0.0213
Epoch [28/50] - Loss: 0.0185
Epoch [29/50] - Loss: 0.0161
Epoch [30/50] - Loss: 0.0141
Epoch [31/50] - Loss: 0.0125
Epoch [32/50] - Loss: 0.0111
Epoch [33/50] - Loss: 0.0099
Epoch [34/50] - Loss: 0.0089
Epoch [35/50] - Loss: 0.0081
Epoch [36/50] - Loss: 0.0074
Epoch [37/50] - Loss: 0.0068
Epoch [38/50] - Loss: 0.0063
Epoch [39/50] - Loss: 0.0059
Epoch [40/50] - Loss: 0.0055
Epoch [41/50] - Loss: 0.0051
Epoch [42/50] - Loss: 0.0048
Epoch [43/50] - Loss: 0.0046
Epoch [44/50] - Loss: 0.0044
Epoch [45/50] - Loss: 0.0042
Epoch [46/50] - Loss: 0.0040
Epoch [47/50] - Loss: 0.0038
Epoch [48/50] - Loss: 0.0037
Epoch [49/50] - Loss: 0.0036
Epoch [50/50] - Loss: 0.0035
sum preds 468
sum labels 421
 - Test Metrics: Accuracy=0.8612, F1=0.5242, Recall=0.5534, Precision=0.4979
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6935
Epoch [2/50] - Loss: 0.6490
Epoch [3/50] - Loss: 0.6006
Epoch [4/50] - Loss: 0.5493
Epoch [5/50] - Loss: 0.4961
Epoch [6/50] - Loss: 0.4432
Epoch [7/50] - Loss: 0.3936
Epoch [8/50] - Loss: 0.3480
Epoch [9/50] - Loss: 0.3062
Epoch [10/50] - Loss: 0.2679
Epoch [11/50] - Loss: 0.2333
Epoch [12/50] - Loss: 0.2022
Epoch [13/50] - Loss: 0.1746
Epoch [14/50] - Loss: 0.1502
Epoch [15/50] - Loss: 0.1287
Epoch [16/50] - Loss: 0.1099
Epoch [17/50] - Loss: 0.0935
Epoch [18/50] - Loss: 0.0792
Epoch [19/50] - Loss: 0.0670
Epoch [20/50] - Loss: 0.0565
Epoch [21/50] - Loss: 0.0476
Epoch [22/50] - Loss: 0.0402
Epoch [23/50] - Loss: 0.0339
Epoch [24/50] - Loss: 0.0288
Epoch [25/50] - Loss: 0.0246
Epoch [26/50] - Loss: 0.0211
Epoch [27/50] - Loss: 0.0182
Epoch [28/50] - Loss: 0.0158
Epoch [29/50] - Loss: 0.0139
Epoch [30/50] - Loss: 0.0122
Epoch [31/50] - Loss: 0.0109
Epoch [32/50] - Loss: 0.0097
Epoch [33/50] - Loss: 0.0088
Epoch [34/50] - Loss: 0.0079
Epoch [35/50] - Loss: 0.0072
Epoch [36/50] - Loss: 0.0067
Epoch [37/50] - Loss: 0.0061
Epoch [38/50] - Loss: 0.0057
Epoch [39/50] - Loss: 0.0053
Epoch [40/50] - Loss: 0.0050
Epoch [41/50] - Loss: 0.0047
Epoch [42/50] - Loss: 0.0045
Epoch [43/50] - Loss: 0.0042
Epoch [44/50] - Loss: 0.0040
Epoch [45/50] - Loss: 0.0039
Epoch [46/50] - Loss: 0.0037
Epoch [47/50] - Loss: 0.0036
Epoch [48/50] - Loss: 0.0035
Epoch [49/50] - Loss: 0.0033
Epoch [50/50] - Loss: 0.0032
sum preds 487
sum labels 421
 - Test Metrics: Accuracy=0.8576, F1=0.5220, Recall=0.5629, Precision=0.4867
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7156
Epoch [2/50] - Loss: 0.6799
Epoch [3/50] - Loss: 0.6423
Epoch [4/50] - Loss: 0.5975
Epoch [5/50] - Loss: 0.5490
Epoch [6/50] - Loss: 0.5005
Epoch [7/50] - Loss: 0.4546
Epoch [8/50] - Loss: 0.4106
Epoch [9/50] - Loss: 0.3674
Epoch [10/50] - Loss: 0.3258
Epoch [11/50] - Loss: 0.2873
Epoch [12/50] - Loss: 0.2526
Epoch [13/50] - Loss: 0.2214
Epoch [14/50] - Loss: 0.1932
Epoch [15/50] - Loss: 0.1677
Epoch [16/50] - Loss: 0.1449
Epoch [17/50] - Loss: 0.1247
Epoch [18/50] - Loss: 0.1072
Epoch [19/50] - Loss: 0.0920
Epoch [20/50] - Loss: 0.0789
Epoch [21/50] - Loss: 0.0676
Epoch [22/50] - Loss: 0.0578
Epoch [23/50] - Loss: 0.0495
Epoch [24/50] - Loss: 0.0425
Epoch [25/50] - Loss: 0.0365
Epoch [26/50] - Loss: 0.0315
Epoch [27/50] - Loss: 0.0273
Epoch [28/50] - Loss: 0.0238
Epoch [29/50] - Loss: 0.0208
Epoch [30/50] - Loss: 0.0183
Epoch [31/50] - Loss: 0.0162
Epoch [32/50] - Loss: 0.0144
Epoch [33/50] - Loss: 0.0129
Epoch [34/50] - Loss: 0.0116
Epoch [35/50] - Loss: 0.0106
Epoch [36/50] - Loss: 0.0097
Epoch [37/50] - Loss: 0.0089
Epoch [38/50] - Loss: 0.0082
Epoch [39/50] - Loss: 0.0076
Epoch [40/50] - Loss: 0.0071
Epoch [41/50] - Loss: 0.0067
Epoch [42/50] - Loss: 0.0063
Epoch [43/50] - Loss: 0.0060
Epoch [44/50] - Loss: 0.0057
Epoch [45/50] - Loss: 0.0054
Epoch [46/50] - Loss: 0.0051
Epoch [47/50] - Loss: 0.0049
Epoch [48/50] - Loss: 0.0047
Epoch [49/50] - Loss: 0.0045
Epoch [50/50] - Loss: 0.0044
sum preds 487
sum labels 421
 - Test Metrics: Accuracy=0.8503, F1=0.4978, Recall=0.5368, Precision=0.4641
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_spy_spy_1804084232.csv.
Average F1 over valid seeds: 0.5147 ± 0.0120
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and spy, MLP,0.4: 0.5147 ± 0.0120
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7006
Epoch [2/50] - Loss: 0.6169
Epoch [3/50] - Loss: 0.5427
Epoch [4/50] - Loss: 0.4707
Epoch [5/50] - Loss: 0.4048
Epoch [6/50] - Loss: 0.3495
Epoch [7/50] - Loss: 0.3086
Epoch [8/50] - Loss: 0.2785
Epoch [9/50] - Loss: 0.2541
Epoch [10/50] - Loss: 0.2320
Epoch [11/50] - Loss: 0.2118
Epoch [12/50] - Loss: 0.1940
Epoch [13/50] - Loss: 0.1786
Epoch [14/50] - Loss: 0.1651
Epoch [15/50] - Loss: 0.1527
Epoch [16/50] - Loss: 0.1413
Epoch [17/50] - Loss: 0.1309
Epoch [18/50] - Loss: 0.1221
Epoch [19/50] - Loss: 0.1144
Epoch [20/50] - Loss: 0.1074
Epoch [21/50] - Loss: 0.1006
Epoch [22/50] - Loss: 0.0942
Epoch [23/50] - Loss: 0.0884
Epoch [24/50] - Loss: 0.0832
Epoch [25/50] - Loss: 0.0782
Epoch [26/50] - Loss: 0.0733
Epoch [27/50] - Loss: 0.0686
Epoch [28/50] - Loss: 0.0646
Epoch [29/50] - Loss: 0.0614
Epoch [30/50] - Loss: 0.0587
Epoch [31/50] - Loss: 0.0560
Epoch [32/50] - Loss: 0.0534
Epoch [33/50] - Loss: 0.0508
Epoch [34/50] - Loss: 0.0481
Epoch [35/50] - Loss: 0.0455
Epoch [36/50] - Loss: 0.0432
Epoch [37/50] - Loss: 0.0414
Epoch [38/50] - Loss: 0.0398
Epoch [39/50] - Loss: 0.0383
Epoch [40/50] - Loss: 0.0370
Epoch [41/50] - Loss: 0.0357
Epoch [42/50] - Loss: 0.0343
Epoch [43/50] - Loss: 0.0330
Epoch [44/50] - Loss: 0.0318
Epoch [45/50] - Loss: 0.0308
Epoch [46/50] - Loss: 0.0299
Epoch [47/50] - Loss: 0.0293
Epoch [48/50] - Loss: 0.0289
Epoch [49/50] - Loss: 0.0284
Epoch [50/50] - Loss: 0.0280
sum preds 409
sum labels 421
 - Test Metrics: Accuracy=0.8943, F1=0.6120, Recall=0.6033, Precision=0.6210
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6974
Epoch [2/50] - Loss: 0.6046
Epoch [3/50] - Loss: 0.5330
Epoch [4/50] - Loss: 0.4705
Epoch [5/50] - Loss: 0.4136
Epoch [6/50] - Loss: 0.3618
Epoch [7/50] - Loss: 0.3176
Epoch [8/50] - Loss: 0.2829
Epoch [9/50] - Loss: 0.2557
Epoch [10/50] - Loss: 0.2322
Epoch [11/50] - Loss: 0.2103
Epoch [12/50] - Loss: 0.1905
Epoch [13/50] - Loss: 0.1736
Epoch [14/50] - Loss: 0.1584
Epoch [15/50] - Loss: 0.1442
Epoch [16/50] - Loss: 0.1313
Epoch [17/50] - Loss: 0.1195
Epoch [18/50] - Loss: 0.1091
Epoch [19/50] - Loss: 0.1000
Epoch [20/50] - Loss: 0.0919
Epoch [21/50] - Loss: 0.0851
Epoch [22/50] - Loss: 0.0792
Epoch [23/50] - Loss: 0.0736
Epoch [24/50] - Loss: 0.0681
Epoch [25/50] - Loss: 0.0631
Epoch [26/50] - Loss: 0.0587
Epoch [27/50] - Loss: 0.0552
Epoch [28/50] - Loss: 0.0525
Epoch [29/50] - Loss: 0.0504
Epoch [30/50] - Loss: 0.0484
Epoch [31/50] - Loss: 0.0465
Epoch [32/50] - Loss: 0.0448
Epoch [33/50] - Loss: 0.0432
Epoch [34/50] - Loss: 0.0418
Epoch [35/50] - Loss: 0.0405
Epoch [36/50] - Loss: 0.0395
Epoch [37/50] - Loss: 0.0387
Epoch [38/50] - Loss: 0.0379
Epoch [39/50] - Loss: 0.0369
Epoch [40/50] - Loss: 0.0360
Epoch [41/50] - Loss: 0.0352
Epoch [42/50] - Loss: 0.0345
Epoch [43/50] - Loss: 0.0339
Epoch [44/50] - Loss: 0.0332
Epoch [45/50] - Loss: 0.0325
Epoch [46/50] - Loss: 0.0319
Epoch [47/50] - Loss: 0.0313
Epoch [48/50] - Loss: 0.0306
Epoch [49/50] - Loss: 0.0300
Epoch [50/50] - Loss: 0.0292
sum preds 432
sum labels 421
 - Test Metrics: Accuracy=0.8835, F1=0.5838, Recall=0.5914, Precision=0.5764
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7068
Epoch [2/50] - Loss: 0.6291
Epoch [3/50] - Loss: 0.5704
Epoch [4/50] - Loss: 0.5117
Epoch [5/50] - Loss: 0.4506
Epoch [6/50] - Loss: 0.3947
Epoch [7/50] - Loss: 0.3541
Epoch [8/50] - Loss: 0.3266
Epoch [9/50] - Loss: 0.3030
Epoch [10/50] - Loss: 0.2783
Epoch [11/50] - Loss: 0.2538
Epoch [12/50] - Loss: 0.2331
Epoch [13/50] - Loss: 0.2163
Epoch [14/50] - Loss: 0.2014
Epoch [15/50] - Loss: 0.1859
Epoch [16/50] - Loss: 0.1704
Epoch [17/50] - Loss: 0.1576
Epoch [18/50] - Loss: 0.1482
Epoch [19/50] - Loss: 0.1409
Epoch [20/50] - Loss: 0.1330
Epoch [21/50] - Loss: 0.1248
Epoch [22/50] - Loss: 0.1175
Epoch [23/50] - Loss: 0.1115
Epoch [24/50] - Loss: 0.1064
Epoch [25/50] - Loss: 0.1010
Epoch [26/50] - Loss: 0.0958
Epoch [27/50] - Loss: 0.0912
Epoch [28/50] - Loss: 0.0869
Epoch [29/50] - Loss: 0.0821
Epoch [30/50] - Loss: 0.0777
Epoch [31/50] - Loss: 0.0742
Epoch [32/50] - Loss: 0.0709
Epoch [33/50] - Loss: 0.0677
Epoch [34/50] - Loss: 0.0652
Epoch [35/50] - Loss: 0.0627
Epoch [36/50] - Loss: 0.0601
Epoch [37/50] - Loss: 0.0580
Epoch [38/50] - Loss: 0.0555
Epoch [39/50] - Loss: 0.0533
Epoch [40/50] - Loss: 0.0517
Epoch [41/50] - Loss: 0.0500
Epoch [42/50] - Loss: 0.0484
Epoch [43/50] - Loss: 0.0468
Epoch [44/50] - Loss: 0.0455
Epoch [45/50] - Loss: 0.0442
Epoch [46/50] - Loss: 0.0431
Epoch [47/50] - Loss: 0.0421
Epoch [48/50] - Loss: 0.0408
Epoch [49/50] - Loss: 0.0398
Epoch [50/50] - Loss: 0.0388
sum preds 462
sum labels 421
 - Test Metrics: Accuracy=0.8743, F1=0.5663, Recall=0.5938, Precision=0.5411
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_spy_spy_1804084253.csv.
Average F1 over valid seeds: 0.5874 ± 0.0189
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and spy, GATConv,0.4: 0.5874 ± 0.0189
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6972
Epoch [2/50] - Loss: 0.6166
Epoch [3/50] - Loss: 0.5425
Epoch [4/50] - Loss: 0.4698
Epoch [5/50] - Loss: 0.4025
Epoch [6/50] - Loss: 0.3467
Epoch [7/50] - Loss: 0.3071
Epoch [8/50] - Loss: 0.2779
Epoch [9/50] - Loss: 0.2526
Epoch [10/50] - Loss: 0.2298
Epoch [11/50] - Loss: 0.2102
Epoch [12/50] - Loss: 0.1939
Epoch [13/50] - Loss: 0.1801
Epoch [14/50] - Loss: 0.1675
Epoch [15/50] - Loss: 0.1558
Epoch [16/50] - Loss: 0.1452
Epoch [17/50] - Loss: 0.1360
Epoch [18/50] - Loss: 0.1284
Epoch [19/50] - Loss: 0.1218
Epoch [20/50] - Loss: 0.1158
Epoch [21/50] - Loss: 0.1101
Epoch [22/50] - Loss: 0.1050
Epoch [23/50] - Loss: 0.1007
Epoch [24/50] - Loss: 0.0971
Epoch [25/50] - Loss: 0.0940
Epoch [26/50] - Loss: 0.0909
Epoch [27/50] - Loss: 0.0879
Epoch [28/50] - Loss: 0.0849
Epoch [29/50] - Loss: 0.0822
Epoch [30/50] - Loss: 0.0796
Epoch [31/50] - Loss: 0.0771
Epoch [32/50] - Loss: 0.0747
Epoch [33/50] - Loss: 0.0726
Epoch [34/50] - Loss: 0.0706
Epoch [35/50] - Loss: 0.0688
Epoch [36/50] - Loss: 0.0669
Epoch [37/50] - Loss: 0.0650
Epoch [38/50] - Loss: 0.0632
Epoch [39/50] - Loss: 0.0617
Epoch [40/50] - Loss: 0.0602
Epoch [41/50] - Loss: 0.0589
Epoch [42/50] - Loss: 0.0576
Epoch [43/50] - Loss: 0.0564
Epoch [44/50] - Loss: 0.0553
Epoch [45/50] - Loss: 0.0543
Epoch [46/50] - Loss: 0.0532
Epoch [47/50] - Loss: 0.0522
Epoch [48/50] - Loss: 0.0513
Epoch [49/50] - Loss: 0.0503
Epoch [50/50] - Loss: 0.0494
sum preds 466
sum labels 421
 - Test Metrics: Accuracy=0.8907, F1=0.6246, Recall=0.6580, Precision=0.5944
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6830
Epoch [2/50] - Loss: 0.6042
Epoch [3/50] - Loss: 0.5362
Epoch [4/50] - Loss: 0.4782
Epoch [5/50] - Loss: 0.4267
Epoch [6/50] - Loss: 0.3838
Epoch [7/50] - Loss: 0.3492
Epoch [8/50] - Loss: 0.3201
Epoch [9/50] - Loss: 0.2945
Epoch [10/50] - Loss: 0.2721
Epoch [11/50] - Loss: 0.2526
Epoch [12/50] - Loss: 0.2355
Epoch [13/50] - Loss: 0.2205
Epoch [14/50] - Loss: 0.2070
Epoch [15/50] - Loss: 0.1948
Epoch [16/50] - Loss: 0.1837
Epoch [17/50] - Loss: 0.1735
Epoch [18/50] - Loss: 0.1644
Epoch [19/50] - Loss: 0.1561
Epoch [20/50] - Loss: 0.1485
Epoch [21/50] - Loss: 0.1416
Epoch [22/50] - Loss: 0.1353
Epoch [23/50] - Loss: 0.1296
Epoch [24/50] - Loss: 0.1243
Epoch [25/50] - Loss: 0.1193
Epoch [26/50] - Loss: 0.1146
Epoch [27/50] - Loss: 0.1100
Epoch [28/50] - Loss: 0.1055
Epoch [29/50] - Loss: 0.1011
Epoch [30/50] - Loss: 0.0968
Epoch [31/50] - Loss: 0.0927
Epoch [32/50] - Loss: 0.0888
Epoch [33/50] - Loss: 0.0851
Epoch [34/50] - Loss: 0.0817
Epoch [35/50] - Loss: 0.0786
Epoch [36/50] - Loss: 0.0757
Epoch [37/50] - Loss: 0.0730
Epoch [38/50] - Loss: 0.0705
Epoch [39/50] - Loss: 0.0681
Epoch [40/50] - Loss: 0.0659
Epoch [41/50] - Loss: 0.0637
Epoch [42/50] - Loss: 0.0615
Epoch [43/50] - Loss: 0.0595
Epoch [44/50] - Loss: 0.0575
Epoch [45/50] - Loss: 0.0556
Epoch [46/50] - Loss: 0.0538
Epoch [47/50] - Loss: 0.0520
Epoch [48/50] - Loss: 0.0504
Epoch [49/50] - Loss: 0.0489
Epoch [50/50] - Loss: 0.0475
sum preds 472
sum labels 421
 - Test Metrics: Accuracy=0.8730, F1=0.5666, Recall=0.6010, Precision=0.5360
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6973
Epoch [2/50] - Loss: 0.6258
Epoch [3/50] - Loss: 0.5680
Epoch [4/50] - Loss: 0.5063
Epoch [5/50] - Loss: 0.4469
Epoch [6/50] - Loss: 0.3980
Epoch [7/50] - Loss: 0.3623
Epoch [8/50] - Loss: 0.3346
Epoch [9/50] - Loss: 0.3092
Epoch [10/50] - Loss: 0.2856
Epoch [11/50] - Loss: 0.2653
Epoch [12/50] - Loss: 0.2485
Epoch [13/50] - Loss: 0.2338
Epoch [14/50] - Loss: 0.2197
Epoch [15/50] - Loss: 0.2060
Epoch [16/50] - Loss: 0.1934
Epoch [17/50] - Loss: 0.1825
Epoch [18/50] - Loss: 0.1732
Epoch [19/50] - Loss: 0.1647
Epoch [20/50] - Loss: 0.1568
Epoch [21/50] - Loss: 0.1495
Epoch [22/50] - Loss: 0.1433
Epoch [23/50] - Loss: 0.1380
Epoch [24/50] - Loss: 0.1330
Epoch [25/50] - Loss: 0.1280
Epoch [26/50] - Loss: 0.1233
Epoch [27/50] - Loss: 0.1192
Epoch [28/50] - Loss: 0.1153
Epoch [29/50] - Loss: 0.1116
Epoch [30/50] - Loss: 0.1079
Epoch [31/50] - Loss: 0.1046
Epoch [32/50] - Loss: 0.1016
Epoch [33/50] - Loss: 0.0987
Epoch [34/50] - Loss: 0.0958
Epoch [35/50] - Loss: 0.0931
Epoch [36/50] - Loss: 0.0905
Epoch [37/50] - Loss: 0.0881
Epoch [38/50] - Loss: 0.0856
Epoch [39/50] - Loss: 0.0833
Epoch [40/50] - Loss: 0.0812
Epoch [41/50] - Loss: 0.0792
Epoch [42/50] - Loss: 0.0772
Epoch [43/50] - Loss: 0.0753
Epoch [44/50] - Loss: 0.0735
Epoch [45/50] - Loss: 0.0718
Epoch [46/50] - Loss: 0.0701
Epoch [47/50] - Loss: 0.0685
Epoch [48/50] - Loss: 0.0669
Epoch [49/50] - Loss: 0.0655
Epoch [50/50] - Loss: 0.0641
sum preds 420
sum labels 421
 - Test Metrics: Accuracy=0.8802, F1=0.5660, Recall=0.5653, Precision=0.5667
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_spy_spy_1804084317.csv.
Average F1 over valid seeds: 0.5857 ± 0.0275
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and spy, GCNConv,0.4: 0.5857 ± 0.0275
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7226
Epoch [2/50] - Loss: 0.6727
Epoch [3/50] - Loss: 0.6229
Epoch [4/50] - Loss: 0.5747
Epoch [5/50] - Loss: 0.5299
Epoch [6/50] - Loss: 0.4887
Epoch [7/50] - Loss: 0.4500
Epoch [8/50] - Loss: 0.4125
Epoch [9/50] - Loss: 0.3752
Epoch [10/50] - Loss: 0.3387
Epoch [11/50] - Loss: 0.3035
Epoch [12/50] - Loss: 0.2711
Epoch [13/50] - Loss: 0.2421
Epoch [14/50] - Loss: 0.2166
Epoch [15/50] - Loss: 0.1934
Epoch [16/50] - Loss: 0.1718
Epoch [17/50] - Loss: 0.1513
Epoch [18/50] - Loss: 0.1319
Epoch [19/50] - Loss: 0.1139
Epoch [20/50] - Loss: 0.0976
Epoch [21/50] - Loss: 0.0834
Epoch [22/50] - Loss: 0.0714
Epoch [23/50] - Loss: 0.0613
Epoch [24/50] - Loss: 0.0528
Epoch [25/50] - Loss: 0.0457
Epoch [26/50] - Loss: 0.0395
Epoch [27/50] - Loss: 0.0341
Epoch [28/50] - Loss: 0.0294
Epoch [29/50] - Loss: 0.0254
Epoch [30/50] - Loss: 0.0221
Epoch [31/50] - Loss: 0.0192
Epoch [32/50] - Loss: 0.0169
Epoch [33/50] - Loss: 0.0149
Epoch [34/50] - Loss: 0.0133
Epoch [35/50] - Loss: 0.0120
Epoch [36/50] - Loss: 0.0108
Epoch [37/50] - Loss: 0.0098
Epoch [38/50] - Loss: 0.0089
Epoch [39/50] - Loss: 0.0081
Epoch [40/50] - Loss: 0.0074
Epoch [41/50] - Loss: 0.0068
Epoch [42/50] - Loss: 0.0063
Epoch [43/50] - Loss: 0.0058
Epoch [44/50] - Loss: 0.0054
Epoch [45/50] - Loss: 0.0051
Epoch [46/50] - Loss: 0.0047
Epoch [47/50] - Loss: 0.0045
Epoch [48/50] - Loss: 0.0042
Epoch [49/50] - Loss: 0.0040
Epoch [50/50] - Loss: 0.0038
sum preds 345
sum labels 491
 - Test Metrics: Accuracy=0.8659, F1=0.5000, Recall=0.4257, Precision=0.6058
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6930
Epoch [2/50] - Loss: 0.6381
Epoch [3/50] - Loss: 0.5840
Epoch [4/50] - Loss: 0.5323
Epoch [5/50] - Loss: 0.4827
Epoch [6/50] - Loss: 0.4349
Epoch [7/50] - Loss: 0.3887
Epoch [8/50] - Loss: 0.3446
Epoch [9/50] - Loss: 0.3033
Epoch [10/50] - Loss: 0.2656
Epoch [11/50] - Loss: 0.2314
Epoch [12/50] - Loss: 0.2010
Epoch [13/50] - Loss: 0.1739
Epoch [14/50] - Loss: 0.1496
Epoch [15/50] - Loss: 0.1279
Epoch [16/50] - Loss: 0.1085
Epoch [17/50] - Loss: 0.0917
Epoch [18/50] - Loss: 0.0772
Epoch [19/50] - Loss: 0.0649
Epoch [20/50] - Loss: 0.0547
Epoch [21/50] - Loss: 0.0461
Epoch [22/50] - Loss: 0.0390
Epoch [23/50] - Loss: 0.0330
Epoch [24/50] - Loss: 0.0281
Epoch [25/50] - Loss: 0.0239
Epoch [26/50] - Loss: 0.0205
Epoch [27/50] - Loss: 0.0176
Epoch [28/50] - Loss: 0.0153
Epoch [29/50] - Loss: 0.0134
Epoch [30/50] - Loss: 0.0118
Epoch [31/50] - Loss: 0.0104
Epoch [32/50] - Loss: 0.0092
Epoch [33/50] - Loss: 0.0083
Epoch [34/50] - Loss: 0.0074
Epoch [35/50] - Loss: 0.0067
Epoch [36/50] - Loss: 0.0061
Epoch [37/50] - Loss: 0.0056
Epoch [38/50] - Loss: 0.0052
Epoch [39/50] - Loss: 0.0048
Epoch [40/50] - Loss: 0.0045
Epoch [41/50] - Loss: 0.0042
Epoch [42/50] - Loss: 0.0039
Epoch [43/50] - Loss: 0.0037
Epoch [44/50] - Loss: 0.0035
Epoch [45/50] - Loss: 0.0033
Epoch [46/50] - Loss: 0.0032
Epoch [47/50] - Loss: 0.0030
Epoch [48/50] - Loss: 0.0029
Epoch [49/50] - Loss: 0.0028
Epoch [50/50] - Loss: 0.0027
sum preds 377
sum labels 491
 - Test Metrics: Accuracy=0.8723, F1=0.5415, Recall=0.4786, Precision=0.6233
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7279
Epoch [2/50] - Loss: 0.6852
Epoch [3/50] - Loss: 0.6493
Epoch [4/50] - Loss: 0.6119
Epoch [5/50] - Loss: 0.5733
Epoch [6/50] - Loss: 0.5335
Epoch [7/50] - Loss: 0.4923
Epoch [8/50] - Loss: 0.4494
Epoch [9/50] - Loss: 0.4063
Epoch [10/50] - Loss: 0.3651
Epoch [11/50] - Loss: 0.3277
Epoch [12/50] - Loss: 0.2942
Epoch [13/50] - Loss: 0.2632
Epoch [14/50] - Loss: 0.2334
Epoch [15/50] - Loss: 0.2047
Epoch [16/50] - Loss: 0.1777
Epoch [17/50] - Loss: 0.1531
Epoch [18/50] - Loss: 0.1317
Epoch [19/50] - Loss: 0.1131
Epoch [20/50] - Loss: 0.0970
Epoch [21/50] - Loss: 0.0828
Epoch [22/50] - Loss: 0.0703
Epoch [23/50] - Loss: 0.0595
Epoch [24/50] - Loss: 0.0504
Epoch [25/50] - Loss: 0.0429
Epoch [26/50] - Loss: 0.0367
Epoch [27/50] - Loss: 0.0317
Epoch [28/50] - Loss: 0.0276
Epoch [29/50] - Loss: 0.0241
Epoch [30/50] - Loss: 0.0211
Epoch [31/50] - Loss: 0.0186
Epoch [32/50] - Loss: 0.0165
Epoch [33/50] - Loss: 0.0149
Epoch [34/50] - Loss: 0.0135
Epoch [35/50] - Loss: 0.0123
Epoch [36/50] - Loss: 0.0113
Epoch [37/50] - Loss: 0.0104
Epoch [38/50] - Loss: 0.0096
Epoch [39/50] - Loss: 0.0089
Epoch [40/50] - Loss: 0.0084
Epoch [41/50] - Loss: 0.0079
Epoch [42/50] - Loss: 0.0075
Epoch [43/50] - Loss: 0.0071
Epoch [44/50] - Loss: 0.0067
Epoch [45/50] - Loss: 0.0064
Epoch [46/50] - Loss: 0.0061
Epoch [47/50] - Loss: 0.0059
Epoch [48/50] - Loss: 0.0057
Epoch [49/50] - Loss: 0.0055
Epoch [50/50] - Loss: 0.0053
sum preds 370
sum labels 491
 - Test Metrics: Accuracy=0.8630, F1=0.5041, Recall=0.4420, Precision=0.5865
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_spy_spy_1804084342.csv.
Average F1 over valid seeds: 0.5152 ± 0.0187
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and spy, MLP,0.3: 0.5152 ± 0.0187
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7038
Epoch [2/50] - Loss: 0.6097
Epoch [3/50] - Loss: 0.5447
Epoch [4/50] - Loss: 0.4901
Epoch [5/50] - Loss: 0.4401
Epoch [6/50] - Loss: 0.3924
Epoch [7/50] - Loss: 0.3498
Epoch [8/50] - Loss: 0.3162
Epoch [9/50] - Loss: 0.2922
Epoch [10/50] - Loss: 0.2744
Epoch [11/50] - Loss: 0.2584
Epoch [12/50] - Loss: 0.2419
Epoch [13/50] - Loss: 0.2251
Epoch [14/50] - Loss: 0.2092
Epoch [15/50] - Loss: 0.1957
Epoch [16/50] - Loss: 0.1846
Epoch [17/50] - Loss: 0.1746
Epoch [18/50] - Loss: 0.1650
Epoch [19/50] - Loss: 0.1557
Epoch [20/50] - Loss: 0.1473
Epoch [21/50] - Loss: 0.1399
Epoch [22/50] - Loss: 0.1330
Epoch [23/50] - Loss: 0.1264
Epoch [24/50] - Loss: 0.1197
Epoch [25/50] - Loss: 0.1130
Epoch [26/50] - Loss: 0.1066
Epoch [27/50] - Loss: 0.1009
Epoch [28/50] - Loss: 0.0959
Epoch [29/50] - Loss: 0.0910
Epoch [30/50] - Loss: 0.0862
Epoch [31/50] - Loss: 0.0812
Epoch [32/50] - Loss: 0.0763
Epoch [33/50] - Loss: 0.0714
Epoch [34/50] - Loss: 0.0667
Epoch [35/50] - Loss: 0.0620
Epoch [36/50] - Loss: 0.0576
Epoch [37/50] - Loss: 0.0537
Epoch [38/50] - Loss: 0.0505
Epoch [39/50] - Loss: 0.0477
Epoch [40/50] - Loss: 0.0450
Epoch [41/50] - Loss: 0.0422
Epoch [42/50] - Loss: 0.0396
Epoch [43/50] - Loss: 0.0371
Epoch [44/50] - Loss: 0.0349
Epoch [45/50] - Loss: 0.0329
Epoch [46/50] - Loss: 0.0311
Epoch [47/50] - Loss: 0.0295
Epoch [48/50] - Loss: 0.0279
Epoch [49/50] - Loss: 0.0266
Epoch [50/50] - Loss: 0.0253
sum preds 366
sum labels 491
 - Test Metrics: Accuracy=0.8880, F1=0.5928, Recall=0.5173, Precision=0.6940
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6927
Epoch [2/50] - Loss: 0.5814
Epoch [3/50] - Loss: 0.5084
Epoch [4/50] - Loss: 0.4561
Epoch [5/50] - Loss: 0.4085
Epoch [6/50] - Loss: 0.3650
Epoch [7/50] - Loss: 0.3277
Epoch [8/50] - Loss: 0.2958
Epoch [9/50] - Loss: 0.2680
Epoch [10/50] - Loss: 0.2457
Epoch [11/50] - Loss: 0.2279
Epoch [12/50] - Loss: 0.2121
Epoch [13/50] - Loss: 0.1963
Epoch [14/50] - Loss: 0.1801
Epoch [15/50] - Loss: 0.1644
Epoch [16/50] - Loss: 0.1512
Epoch [17/50] - Loss: 0.1411
Epoch [18/50] - Loss: 0.1330
Epoch [19/50] - Loss: 0.1253
Epoch [20/50] - Loss: 0.1176
Epoch [21/50] - Loss: 0.1100
Epoch [22/50] - Loss: 0.1033
Epoch [23/50] - Loss: 0.0971
Epoch [24/50] - Loss: 0.0915
Epoch [25/50] - Loss: 0.0860
Epoch [26/50] - Loss: 0.0810
Epoch [27/50] - Loss: 0.0765
Epoch [28/50] - Loss: 0.0726
Epoch [29/50] - Loss: 0.0692
Epoch [30/50] - Loss: 0.0658
Epoch [31/50] - Loss: 0.0617
Epoch [32/50] - Loss: 0.0584
Epoch [33/50] - Loss: 0.0560
Epoch [34/50] - Loss: 0.0535
Epoch [35/50] - Loss: 0.0519
Epoch [36/50] - Loss: 0.0495
Epoch [37/50] - Loss: 0.0471
Epoch [38/50] - Loss: 0.0459
Epoch [39/50] - Loss: 0.0446
Epoch [40/50] - Loss: 0.0429
Epoch [41/50] - Loss: 0.0417
Epoch [42/50] - Loss: 0.0410
Epoch [43/50] - Loss: 0.0402
Epoch [44/50] - Loss: 0.0386
Epoch [45/50] - Loss: 0.0379
Epoch [46/50] - Loss: 0.0372
Epoch [47/50] - Loss: 0.0363
Epoch [48/50] - Loss: 0.0355
Epoch [49/50] - Loss: 0.0351
Epoch [50/50] - Loss: 0.0347
sum preds 434
sum labels 491
 - Test Metrics: Accuracy=0.8816, F1=0.6011, Recall=0.5662, Precision=0.6406
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7131
Epoch [2/50] - Loss: 0.6199
Epoch [3/50] - Loss: 0.5607
Epoch [4/50] - Loss: 0.5157
Epoch [5/50] - Loss: 0.4759
Epoch [6/50] - Loss: 0.4349
Epoch [7/50] - Loss: 0.3934
Epoch [8/50] - Loss: 0.3558
Epoch [9/50] - Loss: 0.3245
Epoch [10/50] - Loss: 0.3003
Epoch [11/50] - Loss: 0.2823
Epoch [12/50] - Loss: 0.2666
Epoch [13/50] - Loss: 0.2494
Epoch [14/50] - Loss: 0.2297
Epoch [15/50] - Loss: 0.2102
Epoch [16/50] - Loss: 0.1944
Epoch [17/50] - Loss: 0.1823
Epoch [18/50] - Loss: 0.1722
Epoch [19/50] - Loss: 0.1624
Epoch [20/50] - Loss: 0.1520
Epoch [21/50] - Loss: 0.1418
Epoch [22/50] - Loss: 0.1327
Epoch [23/50] - Loss: 0.1257
Epoch [24/50] - Loss: 0.1195
Epoch [25/50] - Loss: 0.1134
Epoch [26/50] - Loss: 0.1071
Epoch [27/50] - Loss: 0.1007
Epoch [28/50] - Loss: 0.0952
Epoch [29/50] - Loss: 0.0904
Epoch [30/50] - Loss: 0.0856
Epoch [31/50] - Loss: 0.0807
Epoch [32/50] - Loss: 0.0762
Epoch [33/50] - Loss: 0.0725
Epoch [34/50] - Loss: 0.0688
Epoch [35/50] - Loss: 0.0650
Epoch [36/50] - Loss: 0.0616
Epoch [37/50] - Loss: 0.0586
Epoch [38/50] - Loss: 0.0560
Epoch [39/50] - Loss: 0.0534
Epoch [40/50] - Loss: 0.0511
Epoch [41/50] - Loss: 0.0489
Epoch [42/50] - Loss: 0.0467
Epoch [43/50] - Loss: 0.0446
Epoch [44/50] - Loss: 0.0428
Epoch [45/50] - Loss: 0.0411
Epoch [46/50] - Loss: 0.0397
Epoch [47/50] - Loss: 0.0382
Epoch [48/50] - Loss: 0.0367
Epoch [49/50] - Loss: 0.0353
Epoch [50/50] - Loss: 0.0339
sum preds 412
sum labels 491
 - Test Metrics: Accuracy=0.8823, F1=0.5936, Recall=0.5458, Precision=0.6505
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_spy_spy_1804084405.csv.
Average F1 over valid seeds: 0.5958 ± 0.0037
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and spy, GATConv,0.3: 0.5958 ± 0.0037
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7063
Epoch [2/50] - Loss: 0.6147
Epoch [3/50] - Loss: 0.5507
Epoch [4/50] - Loss: 0.4978
Epoch [5/50] - Loss: 0.4484
Epoch [6/50] - Loss: 0.4006
Epoch [7/50] - Loss: 0.3579
Epoch [8/50] - Loss: 0.3240
Epoch [9/50] - Loss: 0.2993
Epoch [10/50] - Loss: 0.2800
Epoch [11/50] - Loss: 0.2630
Epoch [12/50] - Loss: 0.2461
Epoch [13/50] - Loss: 0.2299
Epoch [14/50] - Loss: 0.2152
Epoch [15/50] - Loss: 0.2027
Epoch [16/50] - Loss: 0.1922
Epoch [17/50] - Loss: 0.1827
Epoch [18/50] - Loss: 0.1734
Epoch [19/50] - Loss: 0.1642
Epoch [20/50] - Loss: 0.1556
Epoch [21/50] - Loss: 0.1482
Epoch [22/50] - Loss: 0.1422
Epoch [23/50] - Loss: 0.1369
Epoch [24/50] - Loss: 0.1318
Epoch [25/50] - Loss: 0.1267
Epoch [26/50] - Loss: 0.1218
Epoch [27/50] - Loss: 0.1173
Epoch [28/50] - Loss: 0.1133
Epoch [29/50] - Loss: 0.1094
Epoch [30/50] - Loss: 0.1055
Epoch [31/50] - Loss: 0.1015
Epoch [32/50] - Loss: 0.0977
Epoch [33/50] - Loss: 0.0942
Epoch [34/50] - Loss: 0.0910
Epoch [35/50] - Loss: 0.0878
Epoch [36/50] - Loss: 0.0847
Epoch [37/50] - Loss: 0.0817
Epoch [38/50] - Loss: 0.0791
Epoch [39/50] - Loss: 0.0766
Epoch [40/50] - Loss: 0.0741
Epoch [41/50] - Loss: 0.0717
Epoch [42/50] - Loss: 0.0694
Epoch [43/50] - Loss: 0.0672
Epoch [44/50] - Loss: 0.0652
Epoch [45/50] - Loss: 0.0632
Epoch [46/50] - Loss: 0.0613
Epoch [47/50] - Loss: 0.0594
Epoch [48/50] - Loss: 0.0577
Epoch [49/50] - Loss: 0.0560
Epoch [50/50] - Loss: 0.0544
sum preds 410
sum labels 491
 - Test Metrics: Accuracy=0.8900, F1=0.6193, Recall=0.5682, Precision=0.6805
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6777
Epoch [2/50] - Loss: 0.5822
Epoch [3/50] - Loss: 0.5123
Epoch [4/50] - Loss: 0.4618
Epoch [5/50] - Loss: 0.4153
Epoch [6/50] - Loss: 0.3733
Epoch [7/50] - Loss: 0.3386
Epoch [8/50] - Loss: 0.3113
Epoch [9/50] - Loss: 0.2891
Epoch [10/50] - Loss: 0.2701
Epoch [11/50] - Loss: 0.2531
Epoch [12/50] - Loss: 0.2375
Epoch [13/50] - Loss: 0.2233
Epoch [14/50] - Loss: 0.2105
Epoch [15/50] - Loss: 0.1991
Epoch [16/50] - Loss: 0.1891
Epoch [17/50] - Loss: 0.1801
Epoch [18/50] - Loss: 0.1718
Epoch [19/50] - Loss: 0.1640
Epoch [20/50] - Loss: 0.1566
Epoch [21/50] - Loss: 0.1494
Epoch [22/50] - Loss: 0.1428
Epoch [23/50] - Loss: 0.1365
Epoch [24/50] - Loss: 0.1306
Epoch [25/50] - Loss: 0.1250
Epoch [26/50] - Loss: 0.1197
Epoch [27/50] - Loss: 0.1148
Epoch [28/50] - Loss: 0.1103
Epoch [29/50] - Loss: 0.1061
Epoch [30/50] - Loss: 0.1022
Epoch [31/50] - Loss: 0.0986
Epoch [32/50] - Loss: 0.0952
Epoch [33/50] - Loss: 0.0921
Epoch [34/50] - Loss: 0.0891
Epoch [35/50] - Loss: 0.0863
Epoch [36/50] - Loss: 0.0837
Epoch [37/50] - Loss: 0.0811
Epoch [38/50] - Loss: 0.0786
Epoch [39/50] - Loss: 0.0762
Epoch [40/50] - Loss: 0.0740
Epoch [41/50] - Loss: 0.0719
Epoch [42/50] - Loss: 0.0699
Epoch [43/50] - Loss: 0.0680
Epoch [44/50] - Loss: 0.0662
Epoch [45/50] - Loss: 0.0645
Epoch [46/50] - Loss: 0.0629
Epoch [47/50] - Loss: 0.0614
Epoch [48/50] - Loss: 0.0600
Epoch [49/50] - Loss: 0.0586
Epoch [50/50] - Loss: 0.0572
sum preds 466
sum labels 491
 - Test Metrics: Accuracy=0.8791, F1=0.6061, Recall=0.5906, Precision=0.6223
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7016
Epoch [2/50] - Loss: 0.6190
Epoch [3/50] - Loss: 0.5645
Epoch [4/50] - Loss: 0.5148
Epoch [5/50] - Loss: 0.4654
Epoch [6/50] - Loss: 0.4163
Epoch [7/50] - Loss: 0.3724
Epoch [8/50] - Loss: 0.3388
Epoch [9/50] - Loss: 0.3153
Epoch [10/50] - Loss: 0.2964
Epoch [11/50] - Loss: 0.2772
Epoch [12/50] - Loss: 0.2571
Epoch [13/50] - Loss: 0.2380
Epoch [14/50] - Loss: 0.2219
Epoch [15/50] - Loss: 0.2090
Epoch [16/50] - Loss: 0.1979
Epoch [17/50] - Loss: 0.1870
Epoch [18/50] - Loss: 0.1758
Epoch [19/50] - Loss: 0.1652
Epoch [20/50] - Loss: 0.1564
Epoch [21/50] - Loss: 0.1495
Epoch [22/50] - Loss: 0.1438
Epoch [23/50] - Loss: 0.1380
Epoch [24/50] - Loss: 0.1321
Epoch [25/50] - Loss: 0.1264
Epoch [26/50] - Loss: 0.1215
Epoch [27/50] - Loss: 0.1172
Epoch [28/50] - Loss: 0.1132
Epoch [29/50] - Loss: 0.1090
Epoch [30/50] - Loss: 0.1048
Epoch [31/50] - Loss: 0.1012
Epoch [32/50] - Loss: 0.0982
Epoch [33/50] - Loss: 0.0954
Epoch [34/50] - Loss: 0.0924
Epoch [35/50] - Loss: 0.0894
Epoch [36/50] - Loss: 0.0866
Epoch [37/50] - Loss: 0.0841
Epoch [38/50] - Loss: 0.0816
Epoch [39/50] - Loss: 0.0791
Epoch [40/50] - Loss: 0.0768
Epoch [41/50] - Loss: 0.0746
Epoch [42/50] - Loss: 0.0727
Epoch [43/50] - Loss: 0.0708
Epoch [44/50] - Loss: 0.0689
Epoch [45/50] - Loss: 0.0671
Epoch [46/50] - Loss: 0.0655
Epoch [47/50] - Loss: 0.0639
Epoch [48/50] - Loss: 0.0623
Epoch [49/50] - Loss: 0.0607
Epoch [50/50] - Loss: 0.0593
sum preds 362
sum labels 491
 - Test Metrics: Accuracy=0.8848, F1=0.5791, Recall=0.5031, Precision=0.6823
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_spy_spy_1804084429.csv.
Average F1 over valid seeds: 0.6015 ± 0.0167
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and spy, GCNConv,0.3: 0.6015 ± 0.0167
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7340
Epoch [2/50] - Loss: 0.6712
Epoch [3/50] - Loss: 0.6097
Epoch [4/50] - Loss: 0.5523
Epoch [5/50] - Loss: 0.5027
Epoch [6/50] - Loss: 0.4622
Epoch [7/50] - Loss: 0.4302
Epoch [8/50] - Loss: 0.4043
Epoch [9/50] - Loss: 0.3815
Epoch [10/50] - Loss: 0.3592
Epoch [11/50] - Loss: 0.3359
Epoch [12/50] - Loss: 0.3115
Epoch [13/50] - Loss: 0.2867
Epoch [14/50] - Loss: 0.2636
Epoch [15/50] - Loss: 0.2432
Epoch [16/50] - Loss: 0.2262
Epoch [17/50] - Loss: 0.2121
Epoch [18/50] - Loss: 0.2002
Epoch [19/50] - Loss: 0.1893
Epoch [20/50] - Loss: 0.1785
Epoch [21/50] - Loss: 0.1671
Epoch [22/50] - Loss: 0.1551
Epoch [23/50] - Loss: 0.1423
Epoch [24/50] - Loss: 0.1290
Epoch [25/50] - Loss: 0.1155
Epoch [26/50] - Loss: 0.1022
Epoch [27/50] - Loss: 0.0892
Epoch [28/50] - Loss: 0.0769
Epoch [29/50] - Loss: 0.0655
Epoch [30/50] - Loss: 0.0554
Epoch [31/50] - Loss: 0.0466
Epoch [32/50] - Loss: 0.0389
Epoch [33/50] - Loss: 0.0324
Epoch [34/50] - Loss: 0.0269
Epoch [35/50] - Loss: 0.0225
Epoch [36/50] - Loss: 0.0189
Epoch [37/50] - Loss: 0.0160
Epoch [38/50] - Loss: 0.0136
Epoch [39/50] - Loss: 0.0117
Epoch [40/50] - Loss: 0.0101
Epoch [41/50] - Loss: 0.0087
Epoch [42/50] - Loss: 0.0076
Epoch [43/50] - Loss: 0.0067
Epoch [44/50] - Loss: 0.0059
Epoch [45/50] - Loss: 0.0053
Epoch [46/50] - Loss: 0.0047
Epoch [47/50] - Loss: 0.0042
Epoch [48/50] - Loss: 0.0038
Epoch [49/50] - Loss: 0.0035
Epoch [50/50] - Loss: 0.0032
sum preds 251
sum labels 561
 - Test Metrics: Accuracy=0.8644, F1=0.4680, Recall=0.3387, Precision=0.7570
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6931
Epoch [2/50] - Loss: 0.6260
Epoch [3/50] - Loss: 0.5635
Epoch [4/50] - Loss: 0.5087
Epoch [5/50] - Loss: 0.4625
Epoch [6/50] - Loss: 0.4241
Epoch [7/50] - Loss: 0.3909
Epoch [8/50] - Loss: 0.3606
Epoch [9/50] - Loss: 0.3313
Epoch [10/50] - Loss: 0.3019
Epoch [11/50] - Loss: 0.2726
Epoch [12/50] - Loss: 0.2446
Epoch [13/50] - Loss: 0.2186
Epoch [14/50] - Loss: 0.1947
Epoch [15/50] - Loss: 0.1734
Epoch [16/50] - Loss: 0.1545
Epoch [17/50] - Loss: 0.1375
Epoch [18/50] - Loss: 0.1221
Epoch [19/50] - Loss: 0.1075
Epoch [20/50] - Loss: 0.0939
Epoch [21/50] - Loss: 0.0811
Epoch [22/50] - Loss: 0.0693
Epoch [23/50] - Loss: 0.0589
Epoch [24/50] - Loss: 0.0500
Epoch [25/50] - Loss: 0.0426
Epoch [26/50] - Loss: 0.0365
Epoch [27/50] - Loss: 0.0315
Epoch [28/50] - Loss: 0.0274
Epoch [29/50] - Loss: 0.0239
Epoch [30/50] - Loss: 0.0210
Epoch [31/50] - Loss: 0.0186
Epoch [32/50] - Loss: 0.0166
Epoch [33/50] - Loss: 0.0150
Epoch [34/50] - Loss: 0.0136
Epoch [35/50] - Loss: 0.0124
Epoch [36/50] - Loss: 0.0114
Epoch [37/50] - Loss: 0.0106
Epoch [38/50] - Loss: 0.0099
Epoch [39/50] - Loss: 0.0093
Epoch [40/50] - Loss: 0.0088
Epoch [41/50] - Loss: 0.0083
Epoch [42/50] - Loss: 0.0079
Epoch [43/50] - Loss: 0.0075
Epoch [44/50] - Loss: 0.0072
Epoch [45/50] - Loss: 0.0069
Epoch [46/50] - Loss: 0.0067
Epoch [47/50] - Loss: 0.0065
Epoch [48/50] - Loss: 0.0064
Epoch [49/50] - Loss: 0.0062
Epoch [50/50] - Loss: 0.0061
sum preds 272
sum labels 561
 - Test Metrics: Accuracy=0.8635, F1=0.4778, Recall=0.3547, Precision=0.7316
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7434
Epoch [2/50] - Loss: 0.6885
Epoch [3/50] - Loss: 0.6460
Epoch [4/50] - Loss: 0.6045
Epoch [5/50] - Loss: 0.5652
Epoch [6/50] - Loss: 0.5291
Epoch [7/50] - Loss: 0.4964
Epoch [8/50] - Loss: 0.4671
Epoch [9/50] - Loss: 0.4408
Epoch [10/50] - Loss: 0.4169
Epoch [11/50] - Loss: 0.3945
Epoch [12/50] - Loss: 0.3726
Epoch [13/50] - Loss: 0.3504
Epoch [14/50] - Loss: 0.3277
Epoch [15/50] - Loss: 0.3043
Epoch [16/50] - Loss: 0.2805
Epoch [17/50] - Loss: 0.2569
Epoch [18/50] - Loss: 0.2342
Epoch [19/50] - Loss: 0.2130
Epoch [20/50] - Loss: 0.1936
Epoch [21/50] - Loss: 0.1761
Epoch [22/50] - Loss: 0.1604
Epoch [23/50] - Loss: 0.1462
Epoch [24/50] - Loss: 0.1327
Epoch [25/50] - Loss: 0.1195
Epoch [26/50] - Loss: 0.1062
Epoch [27/50] - Loss: 0.0930
Epoch [28/50] - Loss: 0.0806
Epoch [29/50] - Loss: 0.0696
Epoch [30/50] - Loss: 0.0601
Epoch [31/50] - Loss: 0.0520
Epoch [32/50] - Loss: 0.0453
Epoch [33/50] - Loss: 0.0396
Epoch [34/50] - Loss: 0.0348
Epoch [35/50] - Loss: 0.0307
Epoch [36/50] - Loss: 0.0272
Epoch [37/50] - Loss: 0.0241
Epoch [38/50] - Loss: 0.0215
Epoch [39/50] - Loss: 0.0192
Epoch [40/50] - Loss: 0.0173
Epoch [41/50] - Loss: 0.0157
Epoch [42/50] - Loss: 0.0144
Epoch [43/50] - Loss: 0.0132
Epoch [44/50] - Loss: 0.0122
Epoch [45/50] - Loss: 0.0113
Epoch [46/50] - Loss: 0.0106
Epoch [47/50] - Loss: 0.0099
Epoch [48/50] - Loss: 0.0093
Epoch [49/50] - Loss: 0.0088
Epoch [50/50] - Loss: 0.0084
sum preds 230
sum labels 561
 - Test Metrics: Accuracy=0.8591, F1=0.4324, Recall=0.3048, Precision=0.7435
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_spy_spy_1804084452.csv.
Average F1 over valid seeds: 0.4594 ± 0.0195
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and spy, MLP,0.2: 0.4594 ± 0.0195
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7119
Epoch [2/50] - Loss: 0.5913
Epoch [3/50] - Loss: 0.5172
Epoch [4/50] - Loss: 0.4686
Epoch [5/50] - Loss: 0.4354
Epoch [6/50] - Loss: 0.4072
Epoch [7/50] - Loss: 0.3783
Epoch [8/50] - Loss: 0.3479
Epoch [9/50] - Loss: 0.3184
Epoch [10/50] - Loss: 0.2922
Epoch [11/50] - Loss: 0.2706
Epoch [12/50] - Loss: 0.2537
Epoch [13/50] - Loss: 0.2398
Epoch [14/50] - Loss: 0.2278
Epoch [15/50] - Loss: 0.2169
Epoch [16/50] - Loss: 0.2060
Epoch [17/50] - Loss: 0.1948
Epoch [18/50] - Loss: 0.1831
Epoch [19/50] - Loss: 0.1716
Epoch [20/50] - Loss: 0.1606
Epoch [21/50] - Loss: 0.1505
Epoch [22/50] - Loss: 0.1414
Epoch [23/50] - Loss: 0.1333
Epoch [24/50] - Loss: 0.1258
Epoch [25/50] - Loss: 0.1187
Epoch [26/50] - Loss: 0.1117
Epoch [27/50] - Loss: 0.1049
Epoch [28/50] - Loss: 0.0982
Epoch [29/50] - Loss: 0.0917
Epoch [30/50] - Loss: 0.0855
Epoch [31/50] - Loss: 0.0800
Epoch [32/50] - Loss: 0.0752
Epoch [33/50] - Loss: 0.0709
Epoch [34/50] - Loss: 0.0669
Epoch [35/50] - Loss: 0.0632
Epoch [36/50] - Loss: 0.0599
Epoch [37/50] - Loss: 0.0571
Epoch [38/50] - Loss: 0.0544
Epoch [39/50] - Loss: 0.0515
Epoch [40/50] - Loss: 0.0485
Epoch [41/50] - Loss: 0.0457
Epoch [42/50] - Loss: 0.0430
Epoch [43/50] - Loss: 0.0406
Epoch [44/50] - Loss: 0.0383
Epoch [45/50] - Loss: 0.0363
Epoch [46/50] - Loss: 0.0344
Epoch [47/50] - Loss: 0.0325
Epoch [48/50] - Loss: 0.0308
Epoch [49/50] - Loss: 0.0292
Epoch [50/50] - Loss: 0.0279
sum preds 318
sum labels 561
 - Test Metrics: Accuracy=0.8666, F1=0.5165, Recall=0.4046, Precision=0.7138
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6866
Epoch [2/50] - Loss: 0.5492
Epoch [3/50] - Loss: 0.4700
Epoch [4/50] - Loss: 0.4270
Epoch [5/50] - Loss: 0.3920
Epoch [6/50] - Loss: 0.3551
Epoch [7/50] - Loss: 0.3203
Epoch [8/50] - Loss: 0.2935
Epoch [9/50] - Loss: 0.2739
Epoch [10/50] - Loss: 0.2584
Epoch [11/50] - Loss: 0.2448
Epoch [12/50] - Loss: 0.2318
Epoch [13/50] - Loss: 0.2192
Epoch [14/50] - Loss: 0.2068
Epoch [15/50] - Loss: 0.1946
Epoch [16/50] - Loss: 0.1825
Epoch [17/50] - Loss: 0.1707
Epoch [18/50] - Loss: 0.1597
Epoch [19/50] - Loss: 0.1493
Epoch [20/50] - Loss: 0.1395
Epoch [21/50] - Loss: 0.1304
Epoch [22/50] - Loss: 0.1221
Epoch [23/50] - Loss: 0.1145
Epoch [24/50] - Loss: 0.1071
Epoch [25/50] - Loss: 0.0995
Epoch [26/50] - Loss: 0.0922
Epoch [27/50] - Loss: 0.0855
Epoch [28/50] - Loss: 0.0792
Epoch [29/50] - Loss: 0.0733
Epoch [30/50] - Loss: 0.0675
Epoch [31/50] - Loss: 0.0620
Epoch [32/50] - Loss: 0.0571
Epoch [33/50] - Loss: 0.0530
Epoch [34/50] - Loss: 0.0493
Epoch [35/50] - Loss: 0.0459
Epoch [36/50] - Loss: 0.0430
Epoch [37/50] - Loss: 0.0402
Epoch [38/50] - Loss: 0.0378
Epoch [39/50] - Loss: 0.0360
Epoch [40/50] - Loss: 0.0343
Epoch [41/50] - Loss: 0.0328
Epoch [42/50] - Loss: 0.0314
Epoch [43/50] - Loss: 0.0304
Epoch [44/50] - Loss: 0.0295
Epoch [45/50] - Loss: 0.0288
Epoch [46/50] - Loss: 0.0283
Epoch [47/50] - Loss: 0.0278
Epoch [48/50] - Loss: 0.0274
Epoch [49/50] - Loss: 0.0270
Epoch [50/50] - Loss: 0.0267
sum preds 258
sum labels 561
 - Test Metrics: Accuracy=0.8723, F1=0.5031, Recall=0.3672, Precision=0.7984
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7206
Epoch [2/50] - Loss: 0.5982
Epoch [3/50] - Loss: 0.5247
Epoch [4/50] - Loss: 0.4774
Epoch [5/50] - Loss: 0.4474
Epoch [6/50] - Loss: 0.4243
Epoch [7/50] - Loss: 0.4013
Epoch [8/50] - Loss: 0.3764
Epoch [9/50] - Loss: 0.3509
Epoch [10/50] - Loss: 0.3273
Epoch [11/50] - Loss: 0.3072
Epoch [12/50] - Loss: 0.2906
Epoch [13/50] - Loss: 0.2767
Epoch [14/50] - Loss: 0.2645
Epoch [15/50] - Loss: 0.2526
Epoch [16/50] - Loss: 0.2403
Epoch [17/50] - Loss: 0.2280
Epoch [18/50] - Loss: 0.2155
Epoch [19/50] - Loss: 0.2029
Epoch [20/50] - Loss: 0.1906
Epoch [21/50] - Loss: 0.1786
Epoch [22/50] - Loss: 0.1669
Epoch [23/50] - Loss: 0.1555
Epoch [24/50] - Loss: 0.1445
Epoch [25/50] - Loss: 0.1344
Epoch [26/50] - Loss: 0.1251
Epoch [27/50] - Loss: 0.1168
Epoch [28/50] - Loss: 0.1091
Epoch [29/50] - Loss: 0.1019
Epoch [30/50] - Loss: 0.0950
Epoch [31/50] - Loss: 0.0885
Epoch [32/50] - Loss: 0.0830
Epoch [33/50] - Loss: 0.0783
Epoch [34/50] - Loss: 0.0741
Epoch [35/50] - Loss: 0.0702
Epoch [36/50] - Loss: 0.0664
Epoch [37/50] - Loss: 0.0628
Epoch [38/50] - Loss: 0.0593
Epoch [39/50] - Loss: 0.0560
Epoch [40/50] - Loss: 0.0526
Epoch [41/50] - Loss: 0.0493
Epoch [42/50] - Loss: 0.0464
Epoch [43/50] - Loss: 0.0440
Epoch [44/50] - Loss: 0.0417
Epoch [45/50] - Loss: 0.0397
Epoch [46/50] - Loss: 0.0379
Epoch [47/50] - Loss: 0.0359
Epoch [48/50] - Loss: 0.0339
Epoch [49/50] - Loss: 0.0321
Epoch [50/50] - Loss: 0.0306
sum preds 289
sum labels 561
 - Test Metrics: Accuracy=0.8657, F1=0.4965, Recall=0.3761, Precision=0.7301
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_spy_spy_1804084514.csv.
Average F1 over valid seeds: 0.5053 ± 0.0083
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and spy, GATConv,0.2: 0.5053 ± 0.0083
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7111
Epoch [2/50] - Loss: 0.5956
Epoch [3/50] - Loss: 0.5227
Epoch [4/50] - Loss: 0.4753
Epoch [5/50] - Loss: 0.4433
Epoch [6/50] - Loss: 0.4161
Epoch [7/50] - Loss: 0.3878
Epoch [8/50] - Loss: 0.3575
Epoch [9/50] - Loss: 0.3273
Epoch [10/50] - Loss: 0.3000
Epoch [11/50] - Loss: 0.2778
Epoch [12/50] - Loss: 0.2608
Epoch [13/50] - Loss: 0.2477
Epoch [14/50] - Loss: 0.2366
Epoch [15/50] - Loss: 0.2260
Epoch [16/50] - Loss: 0.2149
Epoch [17/50] - Loss: 0.2031
Epoch [18/50] - Loss: 0.1909
Epoch [19/50] - Loss: 0.1789
Epoch [20/50] - Loss: 0.1678
Epoch [21/50] - Loss: 0.1580
Epoch [22/50] - Loss: 0.1494
Epoch [23/50] - Loss: 0.1420
Epoch [24/50] - Loss: 0.1352
Epoch [25/50] - Loss: 0.1287
Epoch [26/50] - Loss: 0.1222
Epoch [27/50] - Loss: 0.1158
Epoch [28/50] - Loss: 0.1098
Epoch [29/50] - Loss: 0.1043
Epoch [30/50] - Loss: 0.0996
Epoch [31/50] - Loss: 0.0954
Epoch [32/50] - Loss: 0.0915
Epoch [33/50] - Loss: 0.0877
Epoch [34/50] - Loss: 0.0839
Epoch [35/50] - Loss: 0.0802
Epoch [36/50] - Loss: 0.0769
Epoch [37/50] - Loss: 0.0739
Epoch [38/50] - Loss: 0.0711
Epoch [39/50] - Loss: 0.0685
Epoch [40/50] - Loss: 0.0659
Epoch [41/50] - Loss: 0.0635
Epoch [42/50] - Loss: 0.0611
Epoch [43/50] - Loss: 0.0590
Epoch [44/50] - Loss: 0.0571
Epoch [45/50] - Loss: 0.0553
Epoch [46/50] - Loss: 0.0534
Epoch [47/50] - Loss: 0.0517
Epoch [48/50] - Loss: 0.0500
Epoch [49/50] - Loss: 0.0485
Epoch [50/50] - Loss: 0.0470
sum preds 289
sum labels 561
 - Test Metrics: Accuracy=0.8663, F1=0.4988, Recall=0.3779, Precision=0.7336
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6751
Epoch [2/50] - Loss: 0.5533
Epoch [3/50] - Loss: 0.4758
Epoch [4/50] - Loss: 0.4335
Epoch [5/50] - Loss: 0.3999
Epoch [6/50] - Loss: 0.3643
Epoch [7/50] - Loss: 0.3303
Epoch [8/50] - Loss: 0.3034
Epoch [9/50] - Loss: 0.2831
Epoch [10/50] - Loss: 0.2668
Epoch [11/50] - Loss: 0.2529
Epoch [12/50] - Loss: 0.2403
Epoch [13/50] - Loss: 0.2289
Epoch [14/50] - Loss: 0.2179
Epoch [15/50] - Loss: 0.2074
Epoch [16/50] - Loss: 0.1974
Epoch [17/50] - Loss: 0.1876
Epoch [18/50] - Loss: 0.1783
Epoch [19/50] - Loss: 0.1695
Epoch [20/50] - Loss: 0.1614
Epoch [21/50] - Loss: 0.1537
Epoch [22/50] - Loss: 0.1467
Epoch [23/50] - Loss: 0.1401
Epoch [24/50] - Loss: 0.1340
Epoch [25/50] - Loss: 0.1282
Epoch [26/50] - Loss: 0.1225
Epoch [27/50] - Loss: 0.1171
Epoch [28/50] - Loss: 0.1120
Epoch [29/50] - Loss: 0.1072
Epoch [30/50] - Loss: 0.1028
Epoch [31/50] - Loss: 0.0988
Epoch [32/50] - Loss: 0.0951
Epoch [33/50] - Loss: 0.0915
Epoch [34/50] - Loss: 0.0880
Epoch [35/50] - Loss: 0.0845
Epoch [36/50] - Loss: 0.0811
Epoch [37/50] - Loss: 0.0777
Epoch [38/50] - Loss: 0.0745
Epoch [39/50] - Loss: 0.0713
Epoch [40/50] - Loss: 0.0683
Epoch [41/50] - Loss: 0.0655
Epoch [42/50] - Loss: 0.0628
Epoch [43/50] - Loss: 0.0605
Epoch [44/50] - Loss: 0.0583
Epoch [45/50] - Loss: 0.0562
Epoch [46/50] - Loss: 0.0543
Epoch [47/50] - Loss: 0.0524
Epoch [48/50] - Loss: 0.0506
Epoch [49/50] - Loss: 0.0489
Epoch [50/50] - Loss: 0.0474
sum preds 312
sum labels 561
 - Test Metrics: Accuracy=0.8792, F1=0.5590, Recall=0.4349, Precision=0.7821
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7083
Epoch [2/50] - Loss: 0.6012
Epoch [3/50] - Loss: 0.5370
Epoch [4/50] - Loss: 0.4920
Epoch [5/50] - Loss: 0.4610
Epoch [6/50] - Loss: 0.4366
Epoch [7/50] - Loss: 0.4130
Epoch [8/50] - Loss: 0.3873
Epoch [9/50] - Loss: 0.3598
Epoch [10/50] - Loss: 0.3322
Epoch [11/50] - Loss: 0.3071
Epoch [12/50] - Loss: 0.2856
Epoch [13/50] - Loss: 0.2684
Epoch [14/50] - Loss: 0.2546
Epoch [15/50] - Loss: 0.2425
Epoch [16/50] - Loss: 0.2315
Epoch [17/50] - Loss: 0.2205
Epoch [18/50] - Loss: 0.2089
Epoch [19/50] - Loss: 0.1968
Epoch [20/50] - Loss: 0.1847
Epoch [21/50] - Loss: 0.1732
Epoch [22/50] - Loss: 0.1629
Epoch [23/50] - Loss: 0.1540
Epoch [24/50] - Loss: 0.1464
Epoch [25/50] - Loss: 0.1396
Epoch [26/50] - Loss: 0.1334
Epoch [27/50] - Loss: 0.1272
Epoch [28/50] - Loss: 0.1210
Epoch [29/50] - Loss: 0.1151
Epoch [30/50] - Loss: 0.1098
Epoch [31/50] - Loss: 0.1051
Epoch [32/50] - Loss: 0.1010
Epoch [33/50] - Loss: 0.0973
Epoch [34/50] - Loss: 0.0936
Epoch [35/50] - Loss: 0.0899
Epoch [36/50] - Loss: 0.0863
Epoch [37/50] - Loss: 0.0830
Epoch [38/50] - Loss: 0.0801
Epoch [39/50] - Loss: 0.0774
Epoch [40/50] - Loss: 0.0748
Epoch [41/50] - Loss: 0.0722
Epoch [42/50] - Loss: 0.0696
Epoch [43/50] - Loss: 0.0673
Epoch [44/50] - Loss: 0.0651
Epoch [45/50] - Loss: 0.0632
Epoch [46/50] - Loss: 0.0613
Epoch [47/50] - Loss: 0.0594
Epoch [48/50] - Loss: 0.0576
Epoch [49/50] - Loss: 0.0558
Epoch [50/50] - Loss: 0.0542
sum preds 242
sum labels 561
 - Test Metrics: Accuracy=0.8685, F1=0.4782, Recall=0.3422, Precision=0.7934
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_spy_spy_1804084537.csv.
Average F1 over valid seeds: 0.5120 ± 0.0343
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and spy, GCNConv,0.2: 0.5120 ± 0.0343
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4925
Epoch [2/50] - Loss: 0.4699
Epoch [3/50] - Loss: 0.4458
Epoch [4/50] - Loss: 0.4191
Epoch [5/50] - Loss: 0.3903
Epoch [6/50] - Loss: 0.3598
Epoch [7/50] - Loss: 0.3285
Epoch [8/50] - Loss: 0.2976
Epoch [9/50] - Loss: 0.2676
Epoch [10/50] - Loss: 0.2393
Epoch [11/50] - Loss: 0.2129
Epoch [12/50] - Loss: 0.1883
Epoch [13/50] - Loss: 0.1653
Epoch [14/50] - Loss: 0.1438
Epoch [15/50] - Loss: 0.1233
Epoch [16/50] - Loss: 0.1045
Epoch [17/50] - Loss: 0.0972
Epoch [18/50] - Loss: 0.0885
Epoch [19/50] - Loss: 0.0792
Epoch [20/50] - Loss: 0.0695
Epoch [21/50] - Loss: 0.0601
Epoch [22/50] - Loss: 0.0512
Epoch [23/50] - Loss: 0.0431
Epoch [24/50] - Loss: 0.0359
Epoch [25/50] - Loss: 0.0381
Epoch [26/50] - Loss: 0.0383
Epoch [27/50] - Loss: 0.0310
Epoch [28/50] - Loss: 0.0242
Epoch [29/50] - Loss: 0.0236
Epoch [30/50] - Loss: 0.0226
Epoch [31/50] - Loss: 0.0214
Epoch [32/50] - Loss: 0.0200
Epoch [33/50] - Loss: 0.0185
Epoch [34/50] - Loss: 0.0170
Epoch [35/50] - Loss: 0.0154
Epoch [36/50] - Loss: 0.0139
Epoch [37/50] - Loss: 0.0124
Epoch [38/50] - Loss: 0.0111
Epoch [39/50] - Loss: 0.0098
Epoch [40/50] - Loss: 0.0087
Epoch [41/50] - Loss: 0.0077
Epoch [42/50] - Loss: 0.0068
Epoch [43/50] - Loss: 0.0104
Epoch [44/50] - Loss: 0.0058
Epoch [45/50] - Loss: 0.0056
Epoch [46/50] - Loss: 0.0054
Epoch [47/50] - Loss: 0.0051
Epoch [48/50] - Loss: 0.0048
Epoch [49/50] - Loss: 0.0046
Epoch [50/50] - Loss: 0.0043
sum preds 428
sum labels 421
 - Test Metrics: Accuracy=0.9084, F1=0.6714, Recall=0.6770, Precision=0.6659
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4658
Epoch [2/50] - Loss: 0.4390
Epoch [3/50] - Loss: 0.4104
Epoch [4/50] - Loss: 0.3803
Epoch [5/50] - Loss: 0.3497
Epoch [6/50] - Loss: 0.3196
Epoch [7/50] - Loss: 0.2907
Epoch [8/50] - Loss: 0.2638
Epoch [9/50] - Loss: 0.2395
Epoch [10/50] - Loss: 0.2175
Epoch [11/50] - Loss: 0.1976
Epoch [12/50] - Loss: 0.1791
Epoch [13/50] - Loss: 0.1615
Epoch [14/50] - Loss: 0.1443
Epoch [15/50] - Loss: 0.1271
Epoch [16/50] - Loss: 0.1189
Epoch [17/50] - Loss: 0.1099
Epoch [18/50] - Loss: 0.0997
Epoch [19/50] - Loss: 0.0886
Epoch [20/50] - Loss: 0.0772
Epoch [21/50] - Loss: 0.0659
Epoch [22/50] - Loss: 0.0552
Epoch [23/50] - Loss: 0.0454
Epoch [24/50] - Loss: 0.0397
Epoch [25/50] - Loss: 0.0407
Epoch [26/50] - Loss: 0.0355
Epoch [27/50] - Loss: 0.0269
Epoch [28/50] - Loss: 0.0252
Epoch [29/50] - Loss: 0.0232
Epoch [30/50] - Loss: 0.0211
Epoch [31/50] - Loss: 0.0190
Epoch [32/50] - Loss: 0.0170
Epoch [33/50] - Loss: 0.0151
Epoch [34/50] - Loss: 0.0134
Epoch [35/50] - Loss: 0.0118
Epoch [36/50] - Loss: 0.0118
Epoch [37/50] - Loss: 0.0099
Epoch [38/50] - Loss: 0.0094
Epoch [39/50] - Loss: 0.0088
Epoch [40/50] - Loss: 0.0083
Epoch [41/50] - Loss: 0.0077
Epoch [42/50] - Loss: 0.0071
Epoch [43/50] - Loss: 0.0066
Epoch [44/50] - Loss: 0.0060
Epoch [45/50] - Loss: 0.0055
Epoch [46/50] - Loss: 0.0050
Epoch [47/50] - Loss: 0.0045
Epoch [48/50] - Loss: 0.0041
Epoch [49/50] - Loss: 0.0037
Epoch [50/50] - Loss: 0.0033
sum preds 496
sum labels 421
 - Test Metrics: Accuracy=0.9038, F1=0.6805, Recall=0.7411, Precision=0.6290
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5239
Epoch [2/50] - Loss: 0.4991
Epoch [3/50] - Loss: 0.4728
Epoch [4/50] - Loss: 0.4439
Epoch [5/50] - Loss: 0.4130
Epoch [6/50] - Loss: 0.3808
Epoch [7/50] - Loss: 0.3481
Epoch [8/50] - Loss: 0.3161
Epoch [9/50] - Loss: 0.2853
Epoch [10/50] - Loss: 0.2562
Epoch [11/50] - Loss: 0.2287
Epoch [12/50] - Loss: 0.2029
Epoch [13/50] - Loss: 0.1786
Epoch [14/50] - Loss: 0.1558
Epoch [15/50] - Loss: 0.1342
Epoch [16/50] - Loss: 0.1137
Epoch [17/50] - Loss: 0.0943
Epoch [18/50] - Loss: 0.0838
Epoch [19/50] - Loss: 0.0759
Epoch [20/50] - Loss: 0.0671
Epoch [21/50] - Loss: 0.0582
Epoch [22/50] - Loss: 0.0495
Epoch [23/50] - Loss: 0.0414
Epoch [24/50] - Loss: 0.0342
Epoch [25/50] - Loss: 0.0279
Epoch [26/50] - Loss: 0.0337
Epoch [27/50] - Loss: 0.0333
Epoch [28/50] - Loss: 0.0251
Epoch [29/50] - Loss: 0.0191
Epoch [30/50] - Loss: 0.0188
Epoch [31/50] - Loss: 0.0183
Epoch [32/50] - Loss: 0.0176
Epoch [33/50] - Loss: 0.0167
Epoch [34/50] - Loss: 0.0157
Epoch [35/50] - Loss: 0.0147
Epoch [36/50] - Loss: 0.0136
Epoch [37/50] - Loss: 0.0125
Epoch [38/50] - Loss: 0.0115
Epoch [39/50] - Loss: 0.0105
Epoch [40/50] - Loss: 0.0096
Epoch [41/50] - Loss: 0.0087
Epoch [42/50] - Loss: 0.0080
Epoch [43/50] - Loss: 0.0073
Epoch [44/50] - Loss: 0.0067
Epoch [45/50] - Loss: 0.0061
Epoch [46/50] - Loss: 0.0057
Epoch [47/50] - Loss: 0.0053
Epoch [48/50] - Loss: 0.0049
Epoch [49/50] - Loss: 0.0046
Epoch [50/50] - Loss: 0.0083
sum preds 508
sum labels 421
 - Test Metrics: Accuracy=0.9032, F1=0.6825, Recall=0.7530, Precision=0.6240
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_nnpu_nnpu_1804084601.csv.
Average F1 over valid seeds: 0.6781 ± 0.0048
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and nnpu, MLP,0.4: 0.6781 ± 0.0048
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5021
Epoch [2/50] - Loss: 0.4447
Epoch [3/50] - Loss: 0.3887
Epoch [4/50] - Loss: 0.3347
Epoch [5/50] - Loss: 0.2873
Epoch [6/50] - Loss: 0.2477
Epoch [7/50] - Loss: 0.2155
Epoch [8/50] - Loss: 0.1883
Epoch [9/50] - Loss: 0.1639
Epoch [10/50] - Loss: 0.1407
Epoch [11/50] - Loss: 0.1245
Epoch [12/50] - Loss: 0.1119
Epoch [13/50] - Loss: 0.0981
Epoch [14/50] - Loss: 0.0847
Epoch [15/50] - Loss: 0.0726
Epoch [16/50] - Loss: 0.0618
Epoch [17/50] - Loss: 0.0524
Epoch [18/50] - Loss: 0.0460
Epoch [19/50] - Loss: 0.0460
Epoch [20/50] - Loss: 0.0408
Epoch [21/50] - Loss: 0.0344
Epoch [22/50] - Loss: 0.0325
Epoch [23/50] - Loss: 0.0306
Epoch [24/50] - Loss: 0.0285
Epoch [25/50] - Loss: 0.0265
Epoch [26/50] - Loss: 0.0246
Epoch [27/50] - Loss: 0.0227
Epoch [28/50] - Loss: 0.0209
Epoch [29/50] - Loss: 0.0192
Epoch [30/50] - Loss: 0.0199
Epoch [31/50] - Loss: 0.0170
Epoch [32/50] - Loss: 0.0162
Epoch [33/50] - Loss: 0.0154
Epoch [34/50] - Loss: 0.0146
Epoch [35/50] - Loss: 0.0138
Epoch [36/50] - Loss: 0.0129
Epoch [37/50] - Loss: 0.0121
Epoch [38/50] - Loss: 0.0113
Epoch [39/50] - Loss: 0.0123
Epoch [40/50] - Loss: 0.0105
Epoch [41/50] - Loss: 0.0103
Epoch [42/50] - Loss: 0.0101
Epoch [43/50] - Loss: 0.0098
Epoch [44/50] - Loss: 0.0096
Epoch [45/50] - Loss: 0.0093
Epoch [46/50] - Loss: 0.0090
Epoch [47/50] - Loss: 0.0088
Epoch [48/50] - Loss: 0.0085
Epoch [49/50] - Loss: 0.0083
Epoch [50/50] - Loss: 0.0081
sum preds 461
sum labels 421
 - Test Metrics: Accuracy=0.9225, F1=0.7324, Recall=0.7672, Precision=0.7007
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4956
Epoch [2/50] - Loss: 0.4247
Epoch [3/50] - Loss: 0.3496
Epoch [4/50] - Loss: 0.2871
Epoch [5/50] - Loss: 0.2425
Epoch [6/50] - Loss: 0.2127
Epoch [7/50] - Loss: 0.1925
Epoch [8/50] - Loss: 0.1773
Epoch [9/50] - Loss: 0.1660
Epoch [10/50] - Loss: 0.1601
Epoch [11/50] - Loss: 0.1513
Epoch [12/50] - Loss: 0.1399
Epoch [13/50] - Loss: 0.1269
Epoch [14/50] - Loss: 0.1134
Epoch [15/50] - Loss: 0.1003
Epoch [16/50] - Loss: 0.0880
Epoch [17/50] - Loss: 0.0765
Epoch [18/50] - Loss: 0.0656
Epoch [19/50] - Loss: 0.0556
Epoch [20/50] - Loss: 0.0465
Epoch [21/50] - Loss: 0.0418
Epoch [22/50] - Loss: 0.0455
Epoch [23/50] - Loss: 0.0430
Epoch [24/50] - Loss: 0.0344
Epoch [25/50] - Loss: 0.0291
Epoch [26/50] - Loss: 0.0284
Epoch [27/50] - Loss: 0.0274
Epoch [28/50] - Loss: 0.0261
Epoch [29/50] - Loss: 0.0246
Epoch [30/50] - Loss: 0.0230
Epoch [31/50] - Loss: 0.0215
Epoch [32/50] - Loss: 0.0200
Epoch [33/50] - Loss: 0.0185
Epoch [34/50] - Loss: 0.0170
Epoch [35/50] - Loss: 0.0156
Epoch [36/50] - Loss: 0.0144
Epoch [37/50] - Loss: 0.0134
Epoch [38/50] - Loss: 0.0124
Epoch [39/50] - Loss: 0.0114
Epoch [40/50] - Loss: 0.0106
Epoch [41/50] - Loss: 0.0099
Epoch [42/50] - Loss: 0.0102
Epoch [43/50] - Loss: 0.0090
Epoch [44/50] - Loss: 0.0087
Epoch [45/50] - Loss: 0.0084
Epoch [46/50] - Loss: 0.0081
Epoch [47/50] - Loss: 0.0078
Epoch [48/50] - Loss: 0.0075
Epoch [49/50] - Loss: 0.0073
Epoch [50/50] - Loss: 0.0071
sum preds 506
sum labels 421
 - Test Metrics: Accuracy=0.9137, F1=0.7163, Recall=0.7886, Precision=0.6561
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5028
Epoch [2/50] - Loss: 0.4562
Epoch [3/50] - Loss: 0.4133
Epoch [4/50] - Loss: 0.3701
Epoch [5/50] - Loss: 0.3283
Epoch [6/50] - Loss: 0.2898
Epoch [7/50] - Loss: 0.2556
Epoch [8/50] - Loss: 0.2257
Epoch [9/50] - Loss: 0.1995
Epoch [10/50] - Loss: 0.1758
Epoch [11/50] - Loss: 0.1534
Epoch [12/50] - Loss: 0.1318
Epoch [13/50] - Loss: 0.1137
Epoch [14/50] - Loss: 0.1003
Epoch [15/50] - Loss: 0.0858
Epoch [16/50] - Loss: 0.0713
Epoch [17/50] - Loss: 0.0579
Epoch [18/50] - Loss: 0.0539
Epoch [19/50] - Loss: 0.0524
Epoch [20/50] - Loss: 0.0466
Epoch [21/50] - Loss: 0.0365
Epoch [22/50] - Loss: 0.0308
Epoch [23/50] - Loss: 0.0290
Epoch [24/50] - Loss: 0.0270
Epoch [25/50] - Loss: 0.0249
Epoch [26/50] - Loss: 0.0228
Epoch [27/50] - Loss: 0.0208
Epoch [28/50] - Loss: 0.0188
Epoch [29/50] - Loss: 0.0170
Epoch [30/50] - Loss: 0.0153
Epoch [31/50] - Loss: 0.0138
Epoch [32/50] - Loss: 0.0126
Epoch [33/50] - Loss: 0.0115
Epoch [34/50] - Loss: 0.0106
Epoch [35/50] - Loss: 0.0120
Epoch [36/50] - Loss: 0.0095
Epoch [37/50] - Loss: 0.0092
Epoch [38/50] - Loss: 0.0089
Epoch [39/50] - Loss: 0.0086
Epoch [40/50] - Loss: 0.0082
Epoch [41/50] - Loss: 0.0079
Epoch [42/50] - Loss: 0.0075
Epoch [43/50] - Loss: 0.0072
Epoch [44/50] - Loss: 0.0068
Epoch [45/50] - Loss: 0.0065
Epoch [46/50] - Loss: 0.0063
Epoch [47/50] - Loss: 0.0060
Epoch [48/50] - Loss: 0.0058
Epoch [49/50] - Loss: 0.0057
Epoch [50/50] - Loss: 0.0055
sum preds 500
sum labels 421
 - Test Metrics: Accuracy=0.9091, F1=0.6992, Recall=0.7648, Precision=0.6440
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_nnpu_nnpu_1804084603.csv.
Average F1 over valid seeds: 0.7160 ± 0.0135
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and nnpu, GATConv,0.4: 0.7160 ± 0.0135
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4986
Epoch [2/50] - Loss: 0.4170
Epoch [3/50] - Loss: 0.3386
Epoch [4/50] - Loss: 0.2770
Epoch [5/50] - Loss: 0.2351
Epoch [6/50] - Loss: 0.2078
Epoch [7/50] - Loss: 0.1885
Epoch [8/50] - Loss: 0.1722
Epoch [9/50] - Loss: 0.1571
Epoch [10/50] - Loss: 0.1480
Epoch [11/50] - Loss: 0.1362
Epoch [12/50] - Loss: 0.1225
Epoch [13/50] - Loss: 0.1081
Epoch [14/50] - Loss: 0.0939
Epoch [15/50] - Loss: 0.0808
Epoch [16/50] - Loss: 0.0691
Epoch [17/50] - Loss: 0.0587
Epoch [18/50] - Loss: 0.0492
Epoch [19/50] - Loss: 0.0455
Epoch [20/50] - Loss: 0.0497
Epoch [21/50] - Loss: 0.0490
Epoch [22/50] - Loss: 0.0430
Epoch [23/50] - Loss: 0.0335
Epoch [24/50] - Loss: 0.0315
Epoch [25/50] - Loss: 0.0317
Epoch [26/50] - Loss: 0.0313
Epoch [27/50] - Loss: 0.0306
Epoch [28/50] - Loss: 0.0295
Epoch [29/50] - Loss: 0.0282
Epoch [30/50] - Loss: 0.0268
Epoch [31/50] - Loss: 0.0252
Epoch [32/50] - Loss: 0.0236
Epoch [33/50] - Loss: 0.0219
Epoch [34/50] - Loss: 0.0203
Epoch [35/50] - Loss: 0.0188
Epoch [36/50] - Loss: 0.0173
Epoch [37/50] - Loss: 0.0160
Epoch [38/50] - Loss: 0.0148
Epoch [39/50] - Loss: 0.0137
Epoch [40/50] - Loss: 0.0191
Epoch [41/50] - Loss: 0.0172
Epoch [42/50] - Loss: 0.0128
Epoch [43/50] - Loss: 0.0130
Epoch [44/50] - Loss: 0.0131
Epoch [45/50] - Loss: 0.0131
Epoch [46/50] - Loss: 0.0130
Epoch [47/50] - Loss: 0.0128
Epoch [48/50] - Loss: 0.0126
Epoch [49/50] - Loss: 0.0124
Epoch [50/50] - Loss: 0.0121
sum preds 476
sum labels 421
 - Test Metrics: Accuracy=0.9275, F1=0.7536, Recall=0.8029, Precision=0.7101
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5019
Epoch [2/50] - Loss: 0.4470
Epoch [3/50] - Loss: 0.3952
Epoch [4/50] - Loss: 0.3459
Epoch [5/50] - Loss: 0.3022
Epoch [6/50] - Loss: 0.2652
Epoch [7/50] - Loss: 0.2342
Epoch [8/50] - Loss: 0.2079
Epoch [9/50] - Loss: 0.1846
Epoch [10/50] - Loss: 0.1630
Epoch [11/50] - Loss: 0.1420
Epoch [12/50] - Loss: 0.1218
Epoch [13/50] - Loss: 0.1092
Epoch [14/50] - Loss: 0.0953
Epoch [15/50] - Loss: 0.0814
Epoch [16/50] - Loss: 0.0681
Epoch [17/50] - Loss: 0.0622
Epoch [18/50] - Loss: 0.0612
Epoch [19/50] - Loss: 0.0579
Epoch [20/50] - Loss: 0.0515
Epoch [21/50] - Loss: 0.0425
Epoch [22/50] - Loss: 0.0388
Epoch [23/50] - Loss: 0.0381
Epoch [24/50] - Loss: 0.0367
Epoch [25/50] - Loss: 0.0349
Epoch [26/50] - Loss: 0.0328
Epoch [27/50] - Loss: 0.0305
Epoch [28/50] - Loss: 0.0282
Epoch [29/50] - Loss: 0.0259
Epoch [30/50] - Loss: 0.0236
Epoch [31/50] - Loss: 0.0218
Epoch [32/50] - Loss: 0.0205
Epoch [33/50] - Loss: 0.0202
Epoch [34/50] - Loss: 0.0194
Epoch [35/50] - Loss: 0.0191
Epoch [36/50] - Loss: 0.0186
Epoch [37/50] - Loss: 0.0179
Epoch [38/50] - Loss: 0.0171
Epoch [39/50] - Loss: 0.0162
Epoch [40/50] - Loss: 0.0152
Epoch [41/50] - Loss: 0.0142
Epoch [42/50] - Loss: 0.0133
Epoch [43/50] - Loss: 0.0148
Epoch [44/50] - Loss: 0.0123
Epoch [45/50] - Loss: 0.0121
Epoch [46/50] - Loss: 0.0118
Epoch [47/50] - Loss: 0.0115
Epoch [48/50] - Loss: 0.0111
Epoch [49/50] - Loss: 0.0107
Epoch [50/50] - Loss: 0.0103
sum preds 531
sum labels 421
 - Test Metrics: Accuracy=0.9114, F1=0.7164, Recall=0.8100, Precision=0.6422
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5053
Epoch [2/50] - Loss: 0.4529
Epoch [3/50] - Loss: 0.4012
Epoch [4/50] - Loss: 0.3501
Epoch [5/50] - Loss: 0.3040
Epoch [6/50] - Loss: 0.2649
Epoch [7/50] - Loss: 0.2323
Epoch [8/50] - Loss: 0.2050
Epoch [9/50] - Loss: 0.1815
Epoch [10/50] - Loss: 0.1602
Epoch [11/50] - Loss: 0.1402
Epoch [12/50] - Loss: 0.1208
Epoch [13/50] - Loss: 0.1062
Epoch [14/50] - Loss: 0.0934
Epoch [15/50] - Loss: 0.0802
Epoch [16/50] - Loss: 0.0675
Epoch [17/50] - Loss: 0.0569
Epoch [18/50] - Loss: 0.0541
Epoch [19/50] - Loss: 0.0508
Epoch [20/50] - Loss: 0.0456
Epoch [21/50] - Loss: 0.0385
Epoch [22/50] - Loss: 0.0375
Epoch [23/50] - Loss: 0.0364
Epoch [24/50] - Loss: 0.0349
Epoch [25/50] - Loss: 0.0332
Epoch [26/50] - Loss: 0.0313
Epoch [27/50] - Loss: 0.0293
Epoch [28/50] - Loss: 0.0273
Epoch [29/50] - Loss: 0.0253
Epoch [30/50] - Loss: 0.0233
Epoch [31/50] - Loss: 0.0214
Epoch [32/50] - Loss: 0.0250
Epoch [33/50] - Loss: 0.0235
Epoch [34/50] - Loss: 0.0190
Epoch [35/50] - Loss: 0.0189
Epoch [36/50] - Loss: 0.0186
Epoch [37/50] - Loss: 0.0182
Epoch [38/50] - Loss: 0.0177
Epoch [39/50] - Loss: 0.0171
Epoch [40/50] - Loss: 0.0164
Epoch [41/50] - Loss: 0.0157
Epoch [42/50] - Loss: 0.0150
Epoch [43/50] - Loss: 0.0143
Epoch [44/50] - Loss: 0.0136
Epoch [45/50] - Loss: 0.0130
Epoch [46/50] - Loss: 0.0137
Epoch [47/50] - Loss: 0.0124
Epoch [48/50] - Loss: 0.0123
Epoch [49/50] - Loss: 0.0122
Epoch [50/50] - Loss: 0.0120
sum preds 498
sum labels 421
 - Test Metrics: Accuracy=0.9189, F1=0.7312, Recall=0.7981, Precision=0.6747
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_nnpu_nnpu_1804084606.csv.
Average F1 over valid seeds: 0.7337 ± 0.0153
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and nnpu, GCNConv,0.4: 0.7337 ± 0.0153
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4925
Epoch [2/50] - Loss: 0.4700
Epoch [3/50] - Loss: 0.4459
Epoch [4/50] - Loss: 0.4190
Epoch [5/50] - Loss: 0.3899
Epoch [6/50] - Loss: 0.3592
Epoch [7/50] - Loss: 0.3278
Epoch [8/50] - Loss: 0.2967
Epoch [9/50] - Loss: 0.2666
Epoch [10/50] - Loss: 0.2379
Epoch [11/50] - Loss: 0.2109
Epoch [12/50] - Loss: 0.1855
Epoch [13/50] - Loss: 0.1616
Epoch [14/50] - Loss: 0.1390
Epoch [15/50] - Loss: 0.1173
Epoch [16/50] - Loss: 0.1010
Epoch [17/50] - Loss: 0.0933
Epoch [18/50] - Loss: 0.0844
Epoch [19/50] - Loss: 0.0749
Epoch [20/50] - Loss: 0.0651
Epoch [21/50] - Loss: 0.0558
Epoch [22/50] - Loss: 0.0470
Epoch [23/50] - Loss: 0.0391
Epoch [24/50] - Loss: 0.0322
Epoch [25/50] - Loss: 0.0286
Epoch [26/50] - Loss: 0.0282
Epoch [27/50] - Loss: 0.0212
Epoch [28/50] - Loss: 0.0195
Epoch [29/50] - Loss: 0.0177
Epoch [30/50] - Loss: 0.0159
Epoch [31/50] - Loss: 0.0141
Epoch [32/50] - Loss: 0.0124
Epoch [33/50] - Loss: 0.0109
Epoch [34/50] - Loss: 0.0097
Epoch [35/50] - Loss: 0.0091
Epoch [36/50] - Loss: 0.0086
Epoch [37/50] - Loss: 0.0080
Epoch [38/50] - Loss: 0.0075
Epoch [39/50] - Loss: 0.0070
Epoch [40/50] - Loss: 0.0064
Epoch [41/50] - Loss: 0.0059
Epoch [42/50] - Loss: 0.0054
Epoch [43/50] - Loss: 0.0050
Epoch [44/50] - Loss: 0.0045
Epoch [45/50] - Loss: 0.0041
Epoch [46/50] - Loss: 0.0037
Epoch [47/50] - Loss: 0.0033
Epoch [48/50] - Loss: 0.0030
Epoch [49/50] - Loss: 0.0027
Epoch [50/50] - Loss: 0.0025
sum preds 468
sum labels 491
 - Test Metrics: Accuracy=0.8938, F1=0.6548, Recall=0.6395, Precision=0.6709
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4659
Epoch [2/50] - Loss: 0.4388
Epoch [3/50] - Loss: 0.4098
Epoch [4/50] - Loss: 0.3792
Epoch [5/50] - Loss: 0.3479
Epoch [6/50] - Loss: 0.3170
Epoch [7/50] - Loss: 0.2874
Epoch [8/50] - Loss: 0.2597
Epoch [9/50] - Loss: 0.2343
Epoch [10/50] - Loss: 0.2110
Epoch [11/50] - Loss: 0.1895
Epoch [12/50] - Loss: 0.1691
Epoch [13/50] - Loss: 0.1492
Epoch [14/50] - Loss: 0.1297
Epoch [15/50] - Loss: 0.1156
Epoch [16/50] - Loss: 0.1066
Epoch [17/50] - Loss: 0.0962
Epoch [18/50] - Loss: 0.0848
Epoch [19/50] - Loss: 0.0732
Epoch [20/50] - Loss: 0.0619
Epoch [21/50] - Loss: 0.0514
Epoch [22/50] - Loss: 0.0421
Epoch [23/50] - Loss: 0.0343
Epoch [24/50] - Loss: 0.0342
Epoch [25/50] - Loss: 0.0272
Epoch [26/50] - Loss: 0.0247
Epoch [27/50] - Loss: 0.0231
Epoch [28/50] - Loss: 0.0213
Epoch [29/50] - Loss: 0.0193
Epoch [30/50] - Loss: 0.0174
Epoch [31/50] - Loss: 0.0155
Epoch [32/50] - Loss: 0.0136
Epoch [33/50] - Loss: 0.0119
Epoch [34/50] - Loss: 0.0104
Epoch [35/50] - Loss: 0.0090
Epoch [36/50] - Loss: 0.0078
Epoch [37/50] - Loss: 0.0068
Epoch [38/50] - Loss: 0.0060
Epoch [39/50] - Loss: 0.0053
Epoch [40/50] - Loss: 0.0084
Epoch [41/50] - Loss: 0.0046
Epoch [42/50] - Loss: 0.0045
Epoch [43/50] - Loss: 0.0044
Epoch [44/50] - Loss: 0.0043
Epoch [45/50] - Loss: 0.0042
Epoch [46/50] - Loss: 0.0040
Epoch [47/50] - Loss: 0.0039
Epoch [48/50] - Loss: 0.0037
Epoch [49/50] - Loss: 0.0036
Epoch [50/50] - Loss: 0.0034
sum preds 410
sum labels 491
 - Test Metrics: Accuracy=0.8957, F1=0.6393, Recall=0.5866, Precision=0.7024
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5239
Epoch [2/50] - Loss: 0.4988
Epoch [3/50] - Loss: 0.4715
Epoch [4/50] - Loss: 0.4414
Epoch [5/50] - Loss: 0.4092
Epoch [6/50] - Loss: 0.3758
Epoch [7/50] - Loss: 0.3421
Epoch [8/50] - Loss: 0.3090
Epoch [9/50] - Loss: 0.2770
Epoch [10/50] - Loss: 0.2464
Epoch [11/50] - Loss: 0.2174
Epoch [12/50] - Loss: 0.1898
Epoch [13/50] - Loss: 0.1638
Epoch [14/50] - Loss: 0.1392
Epoch [15/50] - Loss: 0.1160
Epoch [16/50] - Loss: 0.0940
Epoch [17/50] - Loss: 0.0798
Epoch [18/50] - Loss: 0.0719
Epoch [19/50] - Loss: 0.0632
Epoch [20/50] - Loss: 0.0543
Epoch [21/50] - Loss: 0.0457
Epoch [22/50] - Loss: 0.0379
Epoch [23/50] - Loss: 0.0310
Epoch [24/50] - Loss: 0.0251
Epoch [25/50] - Loss: 0.0203
Epoch [26/50] - Loss: 0.0305
Epoch [27/50] - Loss: 0.0287
Epoch [28/50] - Loss: 0.0175
Epoch [29/50] - Loss: 0.0143
Epoch [30/50] - Loss: 0.0143
Epoch [31/50] - Loss: 0.0142
Epoch [32/50] - Loss: 0.0138
Epoch [33/50] - Loss: 0.0133
Epoch [34/50] - Loss: 0.0127
Epoch [35/50] - Loss: 0.0119
Epoch [36/50] - Loss: 0.0112
Epoch [37/50] - Loss: 0.0103
Epoch [38/50] - Loss: 0.0095
Epoch [39/50] - Loss: 0.0087
Epoch [40/50] - Loss: 0.0079
Epoch [41/50] - Loss: 0.0072
Epoch [42/50] - Loss: 0.0065
Epoch [43/50] - Loss: 0.0058
Epoch [44/50] - Loss: 0.0052
Epoch [45/50] - Loss: 0.0047
Epoch [46/50] - Loss: 0.0043
Epoch [47/50] - Loss: 0.0039
Epoch [48/50] - Loss: 0.0036
Epoch [49/50] - Loss: 0.0033
Epoch [50/50] - Loss: 0.0030
sum preds 430
sum labels 491
 - Test Metrics: Accuracy=0.9009, F1=0.6645, Recall=0.6232, Precision=0.7116
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_nnpu_nnpu_1804084609.csv.
Average F1 over valid seeds: 0.6529 ± 0.0104
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and nnpu, MLP,0.3: 0.6529 ± 0.0104
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5027
Epoch [2/50] - Loss: 0.4456
Epoch [3/50] - Loss: 0.3902
Epoch [4/50] - Loss: 0.3372
Epoch [5/50] - Loss: 0.2907
Epoch [6/50] - Loss: 0.2525
Epoch [7/50] - Loss: 0.2219
Epoch [8/50] - Loss: 0.1970
Epoch [9/50] - Loss: 0.1752
Epoch [10/50] - Loss: 0.1545
Epoch [11/50] - Loss: 0.1370
Epoch [12/50] - Loss: 0.1255
Epoch [13/50] - Loss: 0.1121
Epoch [14/50] - Loss: 0.0980
Epoch [15/50] - Loss: 0.0839
Epoch [16/50] - Loss: 0.0708
Epoch [17/50] - Loss: 0.0595
Epoch [18/50] - Loss: 0.0497
Epoch [19/50] - Loss: 0.0510
Epoch [20/50] - Loss: 0.0523
Epoch [21/50] - Loss: 0.0476
Epoch [22/50] - Loss: 0.0378
Epoch [23/50] - Loss: 0.0321
Epoch [24/50] - Loss: 0.0314
Epoch [25/50] - Loss: 0.0303
Epoch [26/50] - Loss: 0.0291
Epoch [27/50] - Loss: 0.0278
Epoch [28/50] - Loss: 0.0265
Epoch [29/50] - Loss: 0.0251
Epoch [30/50] - Loss: 0.0237
Epoch [31/50] - Loss: 0.0224
Epoch [32/50] - Loss: 0.0211
Epoch [33/50] - Loss: 0.0198
Epoch [34/50] - Loss: 0.0185
Epoch [35/50] - Loss: 0.0173
Epoch [36/50] - Loss: 0.0161
Epoch [37/50] - Loss: 0.0149
Epoch [38/50] - Loss: 0.0137
Epoch [39/50] - Loss: 0.0126
Epoch [40/50] - Loss: 0.0116
Epoch [41/50] - Loss: 0.0120
Epoch [42/50] - Loss: 0.0106
Epoch [43/50] - Loss: 0.0103
Epoch [44/50] - Loss: 0.0101
Epoch [45/50] - Loss: 0.0098
Epoch [46/50] - Loss: 0.0096
Epoch [47/50] - Loss: 0.0093
Epoch [48/50] - Loss: 0.0091
Epoch [49/50] - Loss: 0.0089
Epoch [50/50] - Loss: 0.0087
sum preds 506
sum labels 491
 - Test Metrics: Accuracy=0.9201, F1=0.7503, Recall=0.7617, Precision=0.7391
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4955
Epoch [2/50] - Loss: 0.4248
Epoch [3/50] - Loss: 0.3505
Epoch [4/50] - Loss: 0.2889
Epoch [5/50] - Loss: 0.2451
Epoch [6/50] - Loss: 0.2161
Epoch [7/50] - Loss: 0.1969
Epoch [8/50] - Loss: 0.1830
Epoch [9/50] - Loss: 0.1710
Epoch [10/50] - Loss: 0.1662
Epoch [11/50] - Loss: 0.1587
Epoch [12/50] - Loss: 0.1483
Epoch [13/50] - Loss: 0.1359
Epoch [14/50] - Loss: 0.1226
Epoch [15/50] - Loss: 0.1095
Epoch [16/50] - Loss: 0.0970
Epoch [17/50] - Loss: 0.0852
Epoch [18/50] - Loss: 0.0739
Epoch [19/50] - Loss: 0.0635
Epoch [20/50] - Loss: 0.0535
Epoch [21/50] - Loss: 0.0443
Epoch [22/50] - Loss: 0.0444
Epoch [23/50] - Loss: 0.0480
Epoch [24/50] - Loss: 0.0456
Epoch [25/50] - Loss: 0.0374
Epoch [26/50] - Loss: 0.0258
Epoch [27/50] - Loss: 0.0248
Epoch [28/50] - Loss: 0.0236
Epoch [29/50] - Loss: 0.0222
Epoch [30/50] - Loss: 0.0208
Epoch [31/50] - Loss: 0.0194
Epoch [32/50] - Loss: 0.0182
Epoch [33/50] - Loss: 0.0170
Epoch [34/50] - Loss: 0.0158
Epoch [35/50] - Loss: 0.0147
Epoch [36/50] - Loss: 0.0138
Epoch [37/50] - Loss: 0.0130
Epoch [38/50] - Loss: 0.0123
Epoch [39/50] - Loss: 0.0116
Epoch [40/50] - Loss: 0.0110
Epoch [41/50] - Loss: 0.0105
Epoch [42/50] - Loss: 0.0099
Epoch [43/50] - Loss: 0.0093
Epoch [44/50] - Loss: 0.0087
Epoch [45/50] - Loss: 0.0081
Epoch [46/50] - Loss: 0.0084
Epoch [47/50] - Loss: 0.0073
Epoch [48/50] - Loss: 0.0071
Epoch [49/50] - Loss: 0.0069
Epoch [50/50] - Loss: 0.0067
sum preds 518
sum labels 491
 - Test Metrics: Accuracy=0.9118, F1=0.7275, Recall=0.7475, Precision=0.7085
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5026
Epoch [2/50] - Loss: 0.4559
Epoch [3/50] - Loss: 0.4126
Epoch [4/50] - Loss: 0.3686
Epoch [5/50] - Loss: 0.3259
Epoch [6/50] - Loss: 0.2862
Epoch [7/50] - Loss: 0.2507
Epoch [8/50] - Loss: 0.2196
Epoch [9/50] - Loss: 0.1921
Epoch [10/50] - Loss: 0.1673
Epoch [11/50] - Loss: 0.1441
Epoch [12/50] - Loss: 0.1220
Epoch [13/50] - Loss: 0.1047
Epoch [14/50] - Loss: 0.0910
Epoch [15/50] - Loss: 0.0765
Epoch [16/50] - Loss: 0.0623
Epoch [17/50] - Loss: 0.0494
Epoch [18/50] - Loss: 0.0435
Epoch [19/50] - Loss: 0.0412
Epoch [20/50] - Loss: 0.0346
Epoch [21/50] - Loss: 0.0244
Epoch [22/50] - Loss: 0.0217
Epoch [23/50] - Loss: 0.0191
Epoch [24/50] - Loss: 0.0166
Epoch [25/50] - Loss: 0.0143
Epoch [26/50] - Loss: 0.0124
Epoch [27/50] - Loss: 0.0109
Epoch [28/50] - Loss: 0.0096
Epoch [29/50] - Loss: 0.0107
Epoch [30/50] - Loss: 0.0082
Epoch [31/50] - Loss: 0.0078
Epoch [32/50] - Loss: 0.0074
Epoch [33/50] - Loss: 0.0070
Epoch [34/50] - Loss: 0.0066
Epoch [35/50] - Loss: 0.0062
Epoch [36/50] - Loss: 0.0058
Epoch [37/50] - Loss: 0.0055
Epoch [38/50] - Loss: 0.0051
Epoch [39/50] - Loss: 0.0048
Epoch [40/50] - Loss: 0.0045
Epoch [41/50] - Loss: 0.0042
Epoch [42/50] - Loss: 0.0040
Epoch [43/50] - Loss: 0.0038
Epoch [44/50] - Loss: 0.0037
Epoch [45/50] - Loss: 0.0035
Epoch [46/50] - Loss: 0.0034
Epoch [47/50] - Loss: 0.0033
Epoch [48/50] - Loss: 0.0033
Epoch [49/50] - Loss: 0.0032
Epoch [50/50] - Loss: 0.0032
sum preds 507
sum labels 491
 - Test Metrics: Accuracy=0.9089, F1=0.7154, Recall=0.7271, Precision=0.7041
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_nnpu_nnpu_1804084610.csv.
Average F1 over valid seeds: 0.7310 ± 0.0144
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and nnpu, GATConv,0.3: 0.7310 ± 0.0144
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4986
Epoch [2/50] - Loss: 0.4172
Epoch [3/50] - Loss: 0.3396
Epoch [4/50] - Loss: 0.2786
Epoch [5/50] - Loss: 0.2373
Epoch [6/50] - Loss: 0.2107
Epoch [7/50] - Loss: 0.1925
Epoch [8/50] - Loss: 0.1780
Epoch [9/50] - Loss: 0.1640
Epoch [10/50] - Loss: 0.1569
Epoch [11/50] - Loss: 0.1474
Epoch [12/50] - Loss: 0.1357
Epoch [13/50] - Loss: 0.1223
Epoch [14/50] - Loss: 0.1082
Epoch [15/50] - Loss: 0.0943
Epoch [16/50] - Loss: 0.0812
Epoch [17/50] - Loss: 0.0694
Epoch [18/50] - Loss: 0.0589
Epoch [19/50] - Loss: 0.0497
Epoch [20/50] - Loss: 0.0482
Epoch [21/50] - Loss: 0.0523
Epoch [22/50] - Loss: 0.0525
Epoch [23/50] - Loss: 0.0478
Epoch [24/50] - Loss: 0.0395
Epoch [25/50] - Loss: 0.0310
Epoch [26/50] - Loss: 0.0308
Epoch [27/50] - Loss: 0.0302
Epoch [28/50] - Loss: 0.0292
Epoch [29/50] - Loss: 0.0280
Epoch [30/50] - Loss: 0.0266
Epoch [31/50] - Loss: 0.0250
Epoch [32/50] - Loss: 0.0234
Epoch [33/50] - Loss: 0.0219
Epoch [34/50] - Loss: 0.0203
Epoch [35/50] - Loss: 0.0189
Epoch [36/50] - Loss: 0.0175
Epoch [37/50] - Loss: 0.0162
Epoch [38/50] - Loss: 0.0152
Epoch [39/50] - Loss: 0.0146
Epoch [40/50] - Loss: 0.0141
Epoch [41/50] - Loss: 0.0136
Epoch [42/50] - Loss: 0.0131
Epoch [43/50] - Loss: 0.0131
Epoch [44/50] - Loss: 0.0130
Epoch [45/50] - Loss: 0.0128
Epoch [46/50] - Loss: 0.0126
Epoch [47/50] - Loss: 0.0124
Epoch [48/50] - Loss: 0.0120
Epoch [49/50] - Loss: 0.0117
Epoch [50/50] - Loss: 0.0113
sum preds 518
sum labels 491
 - Test Metrics: Accuracy=0.9214, F1=0.7572, Recall=0.7780, Precision=0.7375
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5019
Epoch [2/50] - Loss: 0.4472
Epoch [3/50] - Loss: 0.3957
Epoch [4/50] - Loss: 0.3471
Epoch [5/50] - Loss: 0.3043
Epoch [6/50] - Loss: 0.2684
Epoch [7/50] - Loss: 0.2390
Epoch [8/50] - Loss: 0.2146
Epoch [9/50] - Loss: 0.1938
Epoch [10/50] - Loss: 0.1745
Epoch [11/50] - Loss: 0.1555
Epoch [12/50] - Loss: 0.1361
Epoch [13/50] - Loss: 0.1207
Epoch [14/50] - Loss: 0.1070
Epoch [15/50] - Loss: 0.0924
Epoch [16/50] - Loss: 0.0780
Epoch [17/50] - Loss: 0.0646
Epoch [18/50] - Loss: 0.0638
Epoch [19/50] - Loss: 0.0645
Epoch [20/50] - Loss: 0.0625
Epoch [21/50] - Loss: 0.0567
Epoch [22/50] - Loss: 0.0479
Epoch [23/50] - Loss: 0.0376
Epoch [24/50] - Loss: 0.0377
Epoch [25/50] - Loss: 0.0378
Epoch [26/50] - Loss: 0.0372
Epoch [27/50] - Loss: 0.0360
Epoch [28/50] - Loss: 0.0344
Epoch [29/50] - Loss: 0.0324
Epoch [30/50] - Loss: 0.0302
Epoch [31/50] - Loss: 0.0278
Epoch [32/50] - Loss: 0.0255
Epoch [33/50] - Loss: 0.0232
Epoch [34/50] - Loss: 0.0210
Epoch [35/50] - Loss: 0.0191
Epoch [36/50] - Loss: 0.0174
Epoch [37/50] - Loss: 0.0173
Epoch [38/50] - Loss: 0.0171
Epoch [39/50] - Loss: 0.0151
Epoch [40/50] - Loss: 0.0150
Epoch [41/50] - Loss: 0.0148
Epoch [42/50] - Loss: 0.0144
Epoch [43/50] - Loss: 0.0140
Epoch [44/50] - Loss: 0.0136
Epoch [45/50] - Loss: 0.0130
Epoch [46/50] - Loss: 0.0125
Epoch [47/50] - Loss: 0.0119
Epoch [48/50] - Loss: 0.0113
Epoch [49/50] - Loss: 0.0107
Epoch [50/50] - Loss: 0.0102
sum preds 553
sum labels 491
 - Test Metrics: Accuracy=0.9095, F1=0.7299, Recall=0.7760, Precision=0.6890
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5053
Epoch [2/50] - Loss: 0.4529
Epoch [3/50] - Loss: 0.4007
Epoch [4/50] - Loss: 0.3490
Epoch [5/50] - Loss: 0.3021
Epoch [6/50] - Loss: 0.2619
Epoch [7/50] - Loss: 0.2284
Epoch [8/50] - Loss: 0.2001
Epoch [9/50] - Loss: 0.1755
Epoch [10/50] - Loss: 0.1532
Epoch [11/50] - Loss: 0.1323
Epoch [12/50] - Loss: 0.1124
Epoch [13/50] - Loss: 0.0990
Epoch [14/50] - Loss: 0.0863
Epoch [15/50] - Loss: 0.0734
Epoch [16/50] - Loss: 0.0610
Epoch [17/50] - Loss: 0.0516
Epoch [18/50] - Loss: 0.0491
Epoch [19/50] - Loss: 0.0457
Epoch [20/50] - Loss: 0.0400
Epoch [21/50] - Loss: 0.0328
Epoch [22/50] - Loss: 0.0309
Epoch [23/50] - Loss: 0.0287
Epoch [24/50] - Loss: 0.0263
Epoch [25/50] - Loss: 0.0238
Epoch [26/50] - Loss: 0.0214
Epoch [27/50] - Loss: 0.0218
Epoch [28/50] - Loss: 0.0189
Epoch [29/50] - Loss: 0.0177
Epoch [30/50] - Loss: 0.0173
Epoch [31/50] - Loss: 0.0166
Epoch [32/50] - Loss: 0.0159
Epoch [33/50] - Loss: 0.0150
Epoch [34/50] - Loss: 0.0142
Epoch [35/50] - Loss: 0.0133
Epoch [36/50] - Loss: 0.0124
Epoch [37/50] - Loss: 0.0116
Epoch [38/50] - Loss: 0.0109
Epoch [39/50] - Loss: 0.0102
Epoch [40/50] - Loss: 0.0096
Epoch [41/50] - Loss: 0.0090
Epoch [42/50] - Loss: 0.0110
Epoch [43/50] - Loss: 0.0085
Epoch [44/50] - Loss: 0.0084
Epoch [45/50] - Loss: 0.0083
Epoch [46/50] - Loss: 0.0082
Epoch [47/50] - Loss: 0.0081
Epoch [48/50] - Loss: 0.0079
Epoch [49/50] - Loss: 0.0078
Epoch [50/50] - Loss: 0.0076
sum preds 519
sum labels 491
 - Test Metrics: Accuracy=0.9127, F1=0.7307, Recall=0.7515, Precision=0.7110
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_nnpu_nnpu_1804084613.csv.
Average F1 over valid seeds: 0.7393 ± 0.0127
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and nnpu, GCNConv,0.3: 0.7393 ± 0.0127
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4928
Epoch [2/50] - Loss: 0.4697
Epoch [3/50] - Loss: 0.4447
Epoch [4/50] - Loss: 0.4167
Epoch [5/50] - Loss: 0.3864
Epoch [6/50] - Loss: 0.3546
Epoch [7/50] - Loss: 0.3223
Epoch [8/50] - Loss: 0.2901
Epoch [9/50] - Loss: 0.2588
Epoch [10/50] - Loss: 0.2289
Epoch [11/50] - Loss: 0.2003
Epoch [12/50] - Loss: 0.1730
Epoch [13/50] - Loss: 0.1471
Epoch [14/50] - Loss: 0.1223
Epoch [15/50] - Loss: 0.0993
Epoch [16/50] - Loss: 0.0916
Epoch [17/50] - Loss: 0.0826
Epoch [18/50] - Loss: 0.0730
Epoch [19/50] - Loss: 0.0633
Epoch [20/50] - Loss: 0.0538
Epoch [21/50] - Loss: 0.0450
Epoch [22/50] - Loss: 0.0369
Epoch [23/50] - Loss: 0.0299
Epoch [24/50] - Loss: 0.0240
Epoch [25/50] - Loss: 0.0221
Epoch [26/50] - Loss: 0.0200
Epoch [27/50] - Loss: 0.0157
Epoch [28/50] - Loss: 0.0147
Epoch [29/50] - Loss: 0.0135
Epoch [30/50] - Loss: 0.0124
Epoch [31/50] - Loss: 0.0113
Epoch [32/50] - Loss: 0.0103
Epoch [33/50] - Loss: 0.0094
Epoch [34/50] - Loss: 0.0085
Epoch [35/50] - Loss: 0.0077
Epoch [36/50] - Loss: 0.0070
Epoch [37/50] - Loss: 0.0063
Epoch [38/50] - Loss: 0.0058
Epoch [39/50] - Loss: 0.0052
Epoch [40/50] - Loss: 0.0047
Epoch [41/50] - Loss: 0.0042
Epoch [42/50] - Loss: 0.0038
Epoch [43/50] - Loss: 0.0034
Epoch [44/50] - Loss: 0.0031
Epoch [45/50] - Loss: 0.0027
Epoch [46/50] - Loss: 0.0024
Epoch [47/50] - Loss: 0.0022
Epoch [48/50] - Loss: 0.0021
Epoch [49/50] - Loss: 0.0020
Epoch [50/50] - Loss: 0.0020
sum preds 398
sum labels 561
 - Test Metrics: Accuracy=0.8830, F1=0.6111, Recall=0.5223, Precision=0.7362
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4657
Epoch [2/50] - Loss: 0.4379
Epoch [3/50] - Loss: 0.4074
Epoch [4/50] - Loss: 0.3748
Epoch [5/50] - Loss: 0.3414
Epoch [6/50] - Loss: 0.3083
Epoch [7/50] - Loss: 0.2764
Epoch [8/50] - Loss: 0.2464
Epoch [9/50] - Loss: 0.2183
Epoch [10/50] - Loss: 0.1922
Epoch [11/50] - Loss: 0.1676
Epoch [12/50] - Loss: 0.1442
Epoch [13/50] - Loss: 0.1215
Epoch [14/50] - Loss: 0.1069
Epoch [15/50] - Loss: 0.0985
Epoch [16/50] - Loss: 0.0890
Epoch [17/50] - Loss: 0.0789
Epoch [18/50] - Loss: 0.0687
Epoch [19/50] - Loss: 0.0587
Epoch [20/50] - Loss: 0.0493
Epoch [21/50] - Loss: 0.0408
Epoch [22/50] - Loss: 0.0334
Epoch [23/50] - Loss: 0.0271
Epoch [24/50] - Loss: 0.0245
Epoch [25/50] - Loss: 0.0226
Epoch [26/50] - Loss: 0.0177
Epoch [27/50] - Loss: 0.0164
Epoch [28/50] - Loss: 0.0150
Epoch [29/50] - Loss: 0.0136
Epoch [30/50] - Loss: 0.0123
Epoch [31/50] - Loss: 0.0112
Epoch [32/50] - Loss: 0.0101
Epoch [33/50] - Loss: 0.0091
Epoch [34/50] - Loss: 0.0083
Epoch [35/50] - Loss: 0.0075
Epoch [36/50] - Loss: 0.0069
Epoch [37/50] - Loss: 0.0062
Epoch [38/50] - Loss: 0.0057
Epoch [39/50] - Loss: 0.0052
Epoch [40/50] - Loss: 0.0047
Epoch [41/50] - Loss: 0.0042
Epoch [42/50] - Loss: 0.0037
Epoch [43/50] - Loss: 0.0033
Epoch [44/50] - Loss: 0.0029
Epoch [45/50] - Loss: 0.0059
Epoch [46/50] - Loss: 0.0025
Epoch [47/50] - Loss: 0.0025
Epoch [48/50] - Loss: 0.0024
Epoch [49/50] - Loss: 0.0023
Epoch [50/50] - Loss: 0.0023
sum preds 380
sum labels 561
 - Test Metrics: Accuracy=0.8867, F1=0.6164, Recall=0.5169, Precision=0.7632
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5240
Epoch [2/50] - Loss: 0.4983
Epoch [3/50] - Loss: 0.4698
Epoch [4/50] - Loss: 0.4383
Epoch [5/50] - Loss: 0.4045
Epoch [6/50] - Loss: 0.3695
Epoch [7/50] - Loss: 0.3342
Epoch [8/50] - Loss: 0.2993
Epoch [9/50] - Loss: 0.2651
Epoch [10/50] - Loss: 0.2319
Epoch [11/50] - Loss: 0.1999
Epoch [12/50] - Loss: 0.1693
Epoch [13/50] - Loss: 0.1402
Epoch [14/50] - Loss: 0.1126
Epoch [15/50] - Loss: 0.0867
Epoch [16/50] - Loss: 0.0700
Epoch [17/50] - Loss: 0.0625
Epoch [18/50] - Loss: 0.0545
Epoch [19/50] - Loss: 0.0465
Epoch [20/50] - Loss: 0.0389
Epoch [21/50] - Loss: 0.0322
Epoch [22/50] - Loss: 0.0265
Epoch [23/50] - Loss: 0.0217
Epoch [24/50] - Loss: 0.0176
Epoch [25/50] - Loss: 0.0143
Epoch [26/50] - Loss: 0.0115
Epoch [27/50] - Loss: 0.0205
Epoch [28/50] - Loss: 0.0150
Epoch [29/50] - Loss: 0.0080
Epoch [30/50] - Loss: 0.0076
Epoch [31/50] - Loss: 0.0072
Epoch [32/50] - Loss: 0.0068
Epoch [33/50] - Loss: 0.0063
Epoch [34/50] - Loss: 0.0058
Epoch [35/50] - Loss: 0.0053
Epoch [36/50] - Loss: 0.0049
Epoch [37/50] - Loss: 0.0045
Epoch [38/50] - Loss: 0.0041
Epoch [39/50] - Loss: 0.0037
Epoch [40/50] - Loss: 0.0034
Epoch [41/50] - Loss: 0.0031
Epoch [42/50] - Loss: 0.0028
Epoch [43/50] - Loss: 0.0025
Epoch [44/50] - Loss: 0.0023
Epoch [45/50] - Loss: 0.0021
Epoch [46/50] - Loss: 0.0019
Epoch [47/50] - Loss: 0.0018
Epoch [48/50] - Loss: 0.0016
Epoch [49/50] - Loss: 0.0015
Epoch [50/50] - Loss: 0.0014
sum preds 360
sum labels 561
 - Test Metrics: Accuracy=0.8779, F1=0.5776, Recall=0.4742, Precision=0.7389
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_nnpu_nnpu_1804084616.csv.
Average F1 over valid seeds: 0.6017 ± 0.0171
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and nnpu, MLP,0.2: 0.6017 ± 0.0171
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5027
Epoch [2/50] - Loss: 0.4451
Epoch [3/50] - Loss: 0.3892
Epoch [4/50] - Loss: 0.3352
Epoch [5/50] - Loss: 0.2874
Epoch [6/50] - Loss: 0.2478
Epoch [7/50] - Loss: 0.2158
Epoch [8/50] - Loss: 0.1891
Epoch [9/50] - Loss: 0.1660
Epoch [10/50] - Loss: 0.1444
Epoch [11/50] - Loss: 0.1310
Epoch [12/50] - Loss: 0.1193
Epoch [13/50] - Loss: 0.1057
Epoch [14/50] - Loss: 0.0912
Epoch [15/50] - Loss: 0.0766
Epoch [16/50] - Loss: 0.0632
Epoch [17/50] - Loss: 0.0518
Epoch [18/50] - Loss: 0.0422
Epoch [19/50] - Loss: 0.0457
Epoch [20/50] - Loss: 0.0467
Epoch [21/50] - Loss: 0.0401
Epoch [22/50] - Loss: 0.0279
Epoch [23/50] - Loss: 0.0257
Epoch [24/50] - Loss: 0.0250
Epoch [25/50] - Loss: 0.0241
Epoch [26/50] - Loss: 0.0230
Epoch [27/50] - Loss: 0.0218
Epoch [28/50] - Loss: 0.0207
Epoch [29/50] - Loss: 0.0196
Epoch [30/50] - Loss: 0.0186
Epoch [31/50] - Loss: 0.0176
Epoch [32/50] - Loss: 0.0167
Epoch [33/50] - Loss: 0.0158
Epoch [34/50] - Loss: 0.0150
Epoch [35/50] - Loss: 0.0141
Epoch [36/50] - Loss: 0.0132
Epoch [37/50] - Loss: 0.0126
Epoch [38/50] - Loss: 0.0121
Epoch [39/50] - Loss: 0.0116
Epoch [40/50] - Loss: 0.0113
Epoch [41/50] - Loss: 0.0110
Epoch [42/50] - Loss: 0.0107
Epoch [43/50] - Loss: 0.0104
Epoch [44/50] - Loss: 0.0101
Epoch [45/50] - Loss: 0.0098
Epoch [46/50] - Loss: 0.0095
Epoch [47/50] - Loss: 0.0092
Epoch [48/50] - Loss: 0.0089
Epoch [49/50] - Loss: 0.0086
Epoch [50/50] - Loss: 0.0084
sum preds 513
sum labels 561
 - Test Metrics: Accuracy=0.9128, F1=0.7412, Recall=0.7094, Precision=0.7758
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4959
Epoch [2/50] - Loss: 0.4245
Epoch [3/50] - Loss: 0.3488
Epoch [4/50] - Loss: 0.2854
Epoch [5/50] - Loss: 0.2396
Epoch [6/50] - Loss: 0.2085
Epoch [7/50] - Loss: 0.1867
Epoch [8/50] - Loss: 0.1693
Epoch [9/50] - Loss: 0.1589
Epoch [10/50] - Loss: 0.1509
Epoch [11/50] - Loss: 0.1399
Epoch [12/50] - Loss: 0.1268
Epoch [13/50] - Loss: 0.1132
Epoch [14/50] - Loss: 0.1001
Epoch [15/50] - Loss: 0.0879
Epoch [16/50] - Loss: 0.0765
Epoch [17/50] - Loss: 0.0657
Epoch [18/50] - Loss: 0.0554
Epoch [19/50] - Loss: 0.0462
Epoch [20/50] - Loss: 0.0382
Epoch [21/50] - Loss: 0.0323
Epoch [22/50] - Loss: 0.0343
Epoch [23/50] - Loss: 0.0288
Epoch [24/50] - Loss: 0.0226
Epoch [25/50] - Loss: 0.0210
Epoch [26/50] - Loss: 0.0194
Epoch [27/50] - Loss: 0.0177
Epoch [28/50] - Loss: 0.0161
Epoch [29/50] - Loss: 0.0145
Epoch [30/50] - Loss: 0.0131
Epoch [31/50] - Loss: 0.0120
Epoch [32/50] - Loss: 0.0111
Epoch [33/50] - Loss: 0.0103
Epoch [34/50] - Loss: 0.0097
Epoch [35/50] - Loss: 0.0092
Epoch [36/50] - Loss: 0.0088
Epoch [37/50] - Loss: 0.0085
Epoch [38/50] - Loss: 0.0082
Epoch [39/50] - Loss: 0.0079
Epoch [40/50] - Loss: 0.0077
Epoch [41/50] - Loss: 0.0074
Epoch [42/50] - Loss: 0.0072
Epoch [43/50] - Loss: 0.0086
Epoch [44/50] - Loss: 0.0068
Epoch [45/50] - Loss: 0.0067
Epoch [46/50] - Loss: 0.0066
Epoch [47/50] - Loss: 0.0065
Epoch [48/50] - Loss: 0.0064
Epoch [49/50] - Loss: 0.0064
Epoch [50/50] - Loss: 0.0063
sum preds 459
sum labels 561
 - Test Metrics: Accuracy=0.9008, F1=0.6902, Recall=0.6275, Precision=0.7669
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5026
Epoch [2/50] - Loss: 0.4557
Epoch [3/50] - Loss: 0.4118
Epoch [4/50] - Loss: 0.3667
Epoch [5/50] - Loss: 0.3226
Epoch [6/50] - Loss: 0.2815
Epoch [7/50] - Loss: 0.2446
Epoch [8/50] - Loss: 0.2120
Epoch [9/50] - Loss: 0.1828
Epoch [10/50] - Loss: 0.1562
Epoch [11/50] - Loss: 0.1315
Epoch [12/50] - Loss: 0.1102
Epoch [13/50] - Loss: 0.0976
Epoch [14/50] - Loss: 0.0838
Epoch [15/50] - Loss: 0.0696
Epoch [16/50] - Loss: 0.0562
Epoch [17/50] - Loss: 0.0443
Epoch [18/50] - Loss: 0.0411
Epoch [19/50] - Loss: 0.0386
Epoch [20/50] - Loss: 0.0293
Epoch [21/50] - Loss: 0.0225
Epoch [22/50] - Loss: 0.0203
Epoch [23/50] - Loss: 0.0178
Epoch [24/50] - Loss: 0.0154
Epoch [25/50] - Loss: 0.0132
Epoch [26/50] - Loss: 0.0114
Epoch [27/50] - Loss: 0.0099
Epoch [28/50] - Loss: 0.0086
Epoch [29/50] - Loss: 0.0075
Epoch [30/50] - Loss: 0.0066
Epoch [31/50] - Loss: 0.0059
Epoch [32/50] - Loss: 0.0052
Epoch [33/50] - Loss: 0.0047
Epoch [34/50] - Loss: 0.0043
Epoch [35/50] - Loss: 0.0040
Epoch [36/50] - Loss: 0.0038
Epoch [37/50] - Loss: 0.0043
Epoch [38/50] - Loss: 0.0036
Epoch [39/50] - Loss: 0.0035
Epoch [40/50] - Loss: 0.0035
Epoch [41/50] - Loss: 0.0035
Epoch [42/50] - Loss: 0.0035
Epoch [43/50] - Loss: 0.0035
Epoch [44/50] - Loss: 0.0035
Epoch [45/50] - Loss: 0.0034
Epoch [46/50] - Loss: 0.0034
Epoch [47/50] - Loss: 0.0034
Epoch [48/50] - Loss: 0.0033
Epoch [49/50] - Loss: 0.0033
Epoch [50/50] - Loss: 0.0033
sum preds 413
sum labels 561
 - Test Metrics: Accuracy=0.8933, F1=0.6509, Recall=0.5651, Precision=0.7676
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_nnpu_nnpu_1804084618.csv.
Average F1 over valid seeds: 0.6941 ± 0.0369
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and nnpu, GATConv,0.2: 0.6941 ± 0.0369
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4984
Epoch [2/50] - Loss: 0.4157
Epoch [3/50] - Loss: 0.3370
Epoch [4/50] - Loss: 0.2752
Epoch [5/50] - Loss: 0.2334
Epoch [6/50] - Loss: 0.2063
Epoch [7/50] - Loss: 0.1875
Epoch [8/50] - Loss: 0.1725
Epoch [9/50] - Loss: 0.1626
Epoch [10/50] - Loss: 0.1565
Epoch [11/50] - Loss: 0.1481
Epoch [12/50] - Loss: 0.1375
Epoch [13/50] - Loss: 0.1248
Epoch [14/50] - Loss: 0.1106
Epoch [15/50] - Loss: 0.0957
Epoch [16/50] - Loss: 0.0812
Epoch [17/50] - Loss: 0.0679
Epoch [18/50] - Loss: 0.0562
Epoch [19/50] - Loss: 0.0461
Epoch [20/50] - Loss: 0.0453
Epoch [21/50] - Loss: 0.0500
Epoch [22/50] - Loss: 0.0496
Epoch [23/50] - Loss: 0.0436
Epoch [24/50] - Loss: 0.0333
Epoch [25/50] - Loss: 0.0270
Epoch [26/50] - Loss: 0.0268
Epoch [27/50] - Loss: 0.0263
Epoch [28/50] - Loss: 0.0255
Epoch [29/50] - Loss: 0.0245
Epoch [30/50] - Loss: 0.0233
Epoch [31/50] - Loss: 0.0221
Epoch [32/50] - Loss: 0.0209
Epoch [33/50] - Loss: 0.0197
Epoch [34/50] - Loss: 0.0187
Epoch [35/50] - Loss: 0.0177
Epoch [36/50] - Loss: 0.0168
Epoch [37/50] - Loss: 0.0160
Epoch [38/50] - Loss: 0.0154
Epoch [39/50] - Loss: 0.0148
Epoch [40/50] - Loss: 0.0142
Epoch [41/50] - Loss: 0.0138
Epoch [42/50] - Loss: 0.0134
Epoch [43/50] - Loss: 0.0130
Epoch [44/50] - Loss: 0.0127
Epoch [45/50] - Loss: 0.0124
Epoch [46/50] - Loss: 0.0121
Epoch [47/50] - Loss: 0.0131
Epoch [48/50] - Loss: 0.0118
Epoch [49/50] - Loss: 0.0117
Epoch [50/50] - Loss: 0.0116
sum preds 525
sum labels 561
 - Test Metrics: Accuracy=0.9165, F1=0.7551, Recall=0.7308, Precision=0.7810
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5016
Epoch [2/50] - Loss: 0.4458
Epoch [3/50] - Loss: 0.3929
Epoch [4/50] - Loss: 0.3422
Epoch [5/50] - Loss: 0.2967
Epoch [6/50] - Loss: 0.2577
Epoch [7/50] - Loss: 0.2249
Epoch [8/50] - Loss: 0.1966
Epoch [9/50] - Loss: 0.1711
Epoch [10/50] - Loss: 0.1470
Epoch [11/50] - Loss: 0.1236
Epoch [12/50] - Loss: 0.1067
Epoch [13/50] - Loss: 0.0929
Epoch [14/50] - Loss: 0.0785
Epoch [15/50] - Loss: 0.0650
Epoch [16/50] - Loss: 0.0528
Epoch [17/50] - Loss: 0.0523
Epoch [18/50] - Loss: 0.0525
Epoch [19/50] - Loss: 0.0478
Epoch [20/50] - Loss: 0.0385
Epoch [21/50] - Loss: 0.0307
Epoch [22/50] - Loss: 0.0298
Epoch [23/50] - Loss: 0.0284
Epoch [24/50] - Loss: 0.0266
Epoch [25/50] - Loss: 0.0245
Epoch [26/50] - Loss: 0.0222
Epoch [27/50] - Loss: 0.0199
Epoch [28/50] - Loss: 0.0177
Epoch [29/50] - Loss: 0.0157
Epoch [30/50] - Loss: 0.0138
Epoch [31/50] - Loss: 0.0122
Epoch [32/50] - Loss: 0.0149
Epoch [33/50] - Loss: 0.0117
Epoch [34/50] - Loss: 0.0106
Epoch [35/50] - Loss: 0.0107
Epoch [36/50] - Loss: 0.0108
Epoch [37/50] - Loss: 0.0107
Epoch [38/50] - Loss: 0.0106
Epoch [39/50] - Loss: 0.0104
Epoch [40/50] - Loss: 0.0102
Epoch [41/50] - Loss: 0.0099
Epoch [42/50] - Loss: 0.0096
Epoch [43/50] - Loss: 0.0093
Epoch [44/50] - Loss: 0.0090
Epoch [45/50] - Loss: 0.0087
Epoch [46/50] - Loss: 0.0084
Epoch [47/50] - Loss: 0.0081
Epoch [48/50] - Loss: 0.0079
Epoch [49/50] - Loss: 0.0076
Epoch [50/50] - Loss: 0.0074
sum preds 507
sum labels 561
 - Test Metrics: Accuracy=0.9002, F1=0.7022, Recall=0.6684, Precision=0.7396
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5051
Epoch [2/50] - Loss: 0.4517
Epoch [3/50] - Loss: 0.3988
Epoch [4/50] - Loss: 0.3463
Epoch [5/50] - Loss: 0.2990
Epoch [6/50] - Loss: 0.2587
Epoch [7/50] - Loss: 0.2252
Epoch [8/50] - Loss: 0.1973
Epoch [9/50] - Loss: 0.1730
Epoch [10/50] - Loss: 0.1509
Epoch [11/50] - Loss: 0.1298
Epoch [12/50] - Loss: 0.1144
Epoch [13/50] - Loss: 0.1018
Epoch [14/50] - Loss: 0.0878
Epoch [15/50] - Loss: 0.0735
Epoch [16/50] - Loss: 0.0600
Epoch [17/50] - Loss: 0.0479
Epoch [18/50] - Loss: 0.0518
Epoch [19/50] - Loss: 0.0534
Epoch [20/50] - Loss: 0.0494
Epoch [21/50] - Loss: 0.0401
Epoch [22/50] - Loss: 0.0275
Epoch [23/50] - Loss: 0.0268
Epoch [24/50] - Loss: 0.0269
Epoch [25/50] - Loss: 0.0263
Epoch [26/50] - Loss: 0.0252
Epoch [27/50] - Loss: 0.0238
Epoch [28/50] - Loss: 0.0221
Epoch [29/50] - Loss: 0.0202
Epoch [30/50] - Loss: 0.0183
Epoch [31/50] - Loss: 0.0164
Epoch [32/50] - Loss: 0.0146
Epoch [33/50] - Loss: 0.0130
Epoch [34/50] - Loss: 0.0115
Epoch [35/50] - Loss: 0.0103
Epoch [36/50] - Loss: 0.0092
Epoch [37/50] - Loss: 0.0083
Epoch [38/50] - Loss: 0.0076
Epoch [39/50] - Loss: 0.0070
Epoch [40/50] - Loss: 0.0065
Epoch [41/50] - Loss: 0.0082
Epoch [42/50] - Loss: 0.0059
Epoch [43/50] - Loss: 0.0058
Epoch [44/50] - Loss: 0.0057
Epoch [45/50] - Loss: 0.0056
Epoch [46/50] - Loss: 0.0054
Epoch [47/50] - Loss: 0.0052
Epoch [48/50] - Loss: 0.0050
Epoch [49/50] - Loss: 0.0049
Epoch [50/50] - Loss: 0.0047
sum preds 524
sum labels 561
 - Test Metrics: Accuracy=0.9012, F1=0.7097, Recall=0.6863, Precision=0.7347
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_nnpu_nnpu_1804084621.csv.
Average F1 over valid seeds: 0.7223 ± 0.0233
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and nnpu, GCNConv,0.2: 0.7223 ± 0.0233
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4995
Epoch [2/50] - Loss: 0.4845
Epoch [3/50] - Loss: 0.4639
Epoch [4/50] - Loss: 0.4408
Epoch [5/50] - Loss: 0.4157
Epoch [6/50] - Loss: 0.3888
Epoch [7/50] - Loss: 0.3606
Epoch [8/50] - Loss: 0.3315
Epoch [9/50] - Loss: 0.3017
Epoch [10/50] - Loss: 0.2720
Epoch [11/50] - Loss: 0.2427
Epoch [12/50] - Loss: 0.2143
Epoch [13/50] - Loss: 0.1872
Epoch [14/50] - Loss: 0.1617
Epoch [15/50] - Loss: 0.1379
Epoch [16/50] - Loss: 0.1160
Epoch [17/50] - Loss: 0.0960
Epoch [18/50] - Loss: 0.0779
Epoch [19/50] - Loss: 0.0614
Epoch [20/50] - Loss: 0.0465
Epoch [21/50] - Loss: 0.0331
Epoch [22/50] - Loss: 0.0209
Epoch [23/50] - Loss: 0.0098
Epoch [24/50] - Loss: -0.0002
Epoch [25/50] - Loss: -0.0093
Epoch [26/50] - Loss: -0.0176
Epoch [27/50] - Loss: -0.0251
Epoch [28/50] - Loss: -0.0321
Epoch [29/50] - Loss: -0.0384
Epoch [30/50] - Loss: -0.0441
Epoch [31/50] - Loss: -0.0493
Epoch [32/50] - Loss: -0.0541
Epoch [33/50] - Loss: -0.0584
Epoch [34/50] - Loss: -0.0623
Epoch [35/50] - Loss: -0.0658
Epoch [36/50] - Loss: -0.0690
Epoch [37/50] - Loss: -0.0720
Epoch [38/50] - Loss: -0.0746
Epoch [39/50] - Loss: -0.0771
Epoch [40/50] - Loss: -0.0793
Epoch [41/50] - Loss: -0.0814
Epoch [42/50] - Loss: -0.0833
Epoch [43/50] - Loss: -0.0850
Epoch [44/50] - Loss: -0.0867
Epoch [45/50] - Loss: -0.0882
Epoch [46/50] - Loss: -0.0896
Epoch [47/50] - Loss: -0.0909
Epoch [48/50] - Loss: -0.0922
Epoch [49/50] - Loss: -0.0934
Epoch [50/50] - Loss: -0.0945
sum preds 116
sum labels 421
 - Test Metrics: Accuracy=0.8907, F1=0.3799, Recall=0.2423, Precision=0.8793
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4858
Epoch [3/50] - Loss: 0.4648
Epoch [4/50] - Loss: 0.4412
Epoch [5/50] - Loss: 0.4158
Epoch [6/50] - Loss: 0.3878
Epoch [7/50] - Loss: 0.3581
Epoch [8/50] - Loss: 0.3274
Epoch [9/50] - Loss: 0.2964
Epoch [10/50] - Loss: 0.2655
Epoch [11/50] - Loss: 0.2352
Epoch [12/50] - Loss: 0.2060
Epoch [13/50] - Loss: 0.1783
Epoch [14/50] - Loss: 0.1525
Epoch [15/50] - Loss: 0.1288
Epoch [16/50] - Loss: 0.1072
Epoch [17/50] - Loss: 0.0876
Epoch [18/50] - Loss: 0.0700
Epoch [19/50] - Loss: 0.0541
Epoch [20/50] - Loss: 0.0399
Epoch [21/50] - Loss: 0.0271
Epoch [22/50] - Loss: 0.0157
Epoch [23/50] - Loss: 0.0054
Epoch [24/50] - Loss: -0.0039
Epoch [25/50] - Loss: -0.0124
Epoch [26/50] - Loss: -0.0200
Epoch [27/50] - Loss: -0.0269
Epoch [28/50] - Loss: -0.0332
Epoch [29/50] - Loss: -0.0389
Epoch [30/50] - Loss: -0.0440
Epoch [31/50] - Loss: -0.0487
Epoch [32/50] - Loss: -0.0530
Epoch [33/50] - Loss: -0.0568
Epoch [34/50] - Loss: -0.0603
Epoch [35/50] - Loss: -0.0635
Epoch [36/50] - Loss: -0.0665
Epoch [37/50] - Loss: -0.0691
Epoch [38/50] - Loss: -0.0716
Epoch [39/50] - Loss: -0.0739
Epoch [40/50] - Loss: -0.0760
Epoch [41/50] - Loss: -0.0780
Epoch [42/50] - Loss: -0.0798
Epoch [43/50] - Loss: -0.0816
Epoch [44/50] - Loss: -0.0832
Epoch [45/50] - Loss: -0.0847
Epoch [46/50] - Loss: -0.0862
Epoch [47/50] - Loss: -0.0875
Epoch [48/50] - Loss: -0.0888
Epoch [49/50] - Loss: -0.0900
Epoch [50/50] - Loss: -0.0912
sum preds 132
sum labels 421
 - Test Metrics: Accuracy=0.8933, F1=0.4123, Recall=0.2708, Precision=0.8636
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4993
Epoch [2/50] - Loss: 0.4827
Epoch [3/50] - Loss: 0.4600
Epoch [4/50] - Loss: 0.4349
Epoch [5/50] - Loss: 0.4079
Epoch [6/50] - Loss: 0.3792
Epoch [7/50] - Loss: 0.3496
Epoch [8/50] - Loss: 0.3196
Epoch [9/50] - Loss: 0.2894
Epoch [10/50] - Loss: 0.2597
Epoch [11/50] - Loss: 0.2308
Epoch [12/50] - Loss: 0.2031
Epoch [13/50] - Loss: 0.1768
Epoch [14/50] - Loss: 0.1523
Epoch [15/50] - Loss: 0.1295
Epoch [16/50] - Loss: 0.1086
Epoch [17/50] - Loss: 0.0895
Epoch [18/50] - Loss: 0.0722
Epoch [19/50] - Loss: 0.0565
Epoch [20/50] - Loss: 0.0423
Epoch [21/50] - Loss: 0.0295
Epoch [22/50] - Loss: 0.0179
Epoch [23/50] - Loss: 0.0075
Epoch [24/50] - Loss: -0.0020
Epoch [25/50] - Loss: -0.0105
Epoch [26/50] - Loss: -0.0183
Epoch [27/50] - Loss: -0.0254
Epoch [28/50] - Loss: -0.0318
Epoch [29/50] - Loss: -0.0377
Epoch [30/50] - Loss: -0.0431
Epoch [31/50] - Loss: -0.0480
Epoch [32/50] - Loss: -0.0525
Epoch [33/50] - Loss: -0.0566
Epoch [34/50] - Loss: -0.0603
Epoch [35/50] - Loss: -0.0638
Epoch [36/50] - Loss: -0.0669
Epoch [37/50] - Loss: -0.0698
Epoch [38/50] - Loss: -0.0724
Epoch [39/50] - Loss: -0.0748
Epoch [40/50] - Loss: -0.0771
Epoch [41/50] - Loss: -0.0792
Epoch [42/50] - Loss: -0.0811
Epoch [43/50] - Loss: -0.0829
Epoch [44/50] - Loss: -0.0846
Epoch [45/50] - Loss: -0.0861
Epoch [46/50] - Loss: -0.0876
Epoch [47/50] - Loss: -0.0890
Epoch [48/50] - Loss: -0.0903
Epoch [49/50] - Loss: -0.0915
Epoch [50/50] - Loss: -0.0927
sum preds 126
sum labels 421
 - Test Metrics: Accuracy=0.8933, F1=0.4059, Recall=0.2637, Precision=0.8810
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_imbnnpu_imbnnpu_1804084624.csv.
Average F1 over valid seeds: 0.3993 ± 0.0140
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and imbnnpu, MLP,0.4: 0.3993 ± 0.0140
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4986
Epoch [2/50] - Loss: 0.4657
Epoch [3/50] - Loss: 0.4236
Epoch [4/50] - Loss: 0.3737
Epoch [5/50] - Loss: 0.3244
Epoch [6/50] - Loss: 0.2789
Epoch [7/50] - Loss: 0.2373
Epoch [8/50] - Loss: 0.2001
Epoch [9/50] - Loss: 0.1673
Epoch [10/50] - Loss: 0.1391
Epoch [11/50] - Loss: 0.1149
Epoch [12/50] - Loss: 0.0943
Epoch [13/50] - Loss: 0.0766
Epoch [14/50] - Loss: 0.0614
Epoch [15/50] - Loss: 0.0479
Epoch [16/50] - Loss: 0.0364
Epoch [17/50] - Loss: 0.0264
Epoch [18/50] - Loss: 0.0177
Epoch [19/50] - Loss: 0.0101
Epoch [20/50] - Loss: 0.0035
Epoch [21/50] - Loss: -0.0021
Epoch [22/50] - Loss: -0.0069
Epoch [23/50] - Loss: -0.0111
Epoch [24/50] - Loss: -0.0148
Epoch [25/50] - Loss: -0.0181
Epoch [26/50] - Loss: -0.0210
Epoch [27/50] - Loss: -0.0238
Epoch [28/50] - Loss: -0.0263
Epoch [29/50] - Loss: -0.0286
Epoch [30/50] - Loss: -0.0306
Epoch [31/50] - Loss: -0.0324
Epoch [32/50] - Loss: -0.0340
Epoch [33/50] - Loss: -0.0356
Epoch [34/50] - Loss: -0.0372
Epoch [35/50] - Loss: -0.0388
Epoch [36/50] - Loss: -0.0402
Epoch [37/50] - Loss: -0.0415
Epoch [38/50] - Loss: -0.0426
Epoch [39/50] - Loss: -0.0434
Epoch [40/50] - Loss: -0.0442
Epoch [41/50] - Loss: -0.0449
Epoch [42/50] - Loss: -0.0457
Epoch [43/50] - Loss: -0.0464
Epoch [44/50] - Loss: -0.0472
Epoch [45/50] - Loss: -0.0482
Epoch [46/50] - Loss: -0.0491
Epoch [47/50] - Loss: -0.0501
Epoch [48/50] - Loss: -0.0510
Epoch [49/50] - Loss: -0.0519
Epoch [50/50] - Loss: -0.0526
sum preds 319
sum labels 421
 - Test Metrics: Accuracy=0.9186, F1=0.6649, Recall=0.5843, Precision=0.7712
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5049
Epoch [2/50] - Loss: 0.4727
Epoch [3/50] - Loss: 0.4295
Epoch [4/50] - Loss: 0.3752
Epoch [5/50] - Loss: 0.3235
Epoch [6/50] - Loss: 0.2777
Epoch [7/50] - Loss: 0.2354
Epoch [8/50] - Loss: 0.1964
Epoch [9/50] - Loss: 0.1622
Epoch [10/50] - Loss: 0.1332
Epoch [11/50] - Loss: 0.1088
Epoch [12/50] - Loss: 0.0881
Epoch [13/50] - Loss: 0.0706
Epoch [14/50] - Loss: 0.0554
Epoch [15/50] - Loss: 0.0421
Epoch [16/50] - Loss: 0.0303
Epoch [17/50] - Loss: 0.0201
Epoch [18/50] - Loss: 0.0112
Epoch [19/50] - Loss: 0.0035
Epoch [20/50] - Loss: -0.0030
Epoch [21/50] - Loss: -0.0083
Epoch [22/50] - Loss: -0.0127
Epoch [23/50] - Loss: -0.0164
Epoch [24/50] - Loss: -0.0197
Epoch [25/50] - Loss: -0.0225
Epoch [26/50] - Loss: -0.0251
Epoch [27/50] - Loss: -0.0276
Epoch [28/50] - Loss: -0.0298
Epoch [29/50] - Loss: -0.0317
Epoch [30/50] - Loss: -0.0332
Epoch [31/50] - Loss: -0.0347
Epoch [32/50] - Loss: -0.0365
Epoch [33/50] - Loss: -0.0382
Epoch [34/50] - Loss: -0.0396
Epoch [35/50] - Loss: -0.0409
Epoch [36/50] - Loss: -0.0420
Epoch [37/50] - Loss: -0.0433
Epoch [38/50] - Loss: -0.0445
Epoch [39/50] - Loss: -0.0456
Epoch [40/50] - Loss: -0.0467
Epoch [41/50] - Loss: -0.0477
Epoch [42/50] - Loss: -0.0485
Epoch [43/50] - Loss: -0.0496
Epoch [44/50] - Loss: -0.0504
Epoch [45/50] - Loss: -0.0510
Epoch [46/50] - Loss: -0.0514
Epoch [47/50] - Loss: -0.0518
Epoch [48/50] - Loss: -0.0522
Epoch [49/50] - Loss: -0.0525
Epoch [50/50] - Loss: -0.0528
sum preds 291
sum labels 421
 - Test Metrics: Accuracy=0.9140, F1=0.6320, Recall=0.5344, Precision=0.7732
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4683
Epoch [3/50] - Loss: 0.4267
Epoch [4/50] - Loss: 0.3787
Epoch [5/50] - Loss: 0.3311
Epoch [6/50] - Loss: 0.2856
Epoch [7/50] - Loss: 0.2431
Epoch [8/50] - Loss: 0.2043
Epoch [9/50] - Loss: 0.1695
Epoch [10/50] - Loss: 0.1388
Epoch [11/50] - Loss: 0.1123
Epoch [12/50] - Loss: 0.0897
Epoch [13/50] - Loss: 0.0705
Epoch [14/50] - Loss: 0.0543
Epoch [15/50] - Loss: 0.0406
Epoch [16/50] - Loss: 0.0290
Epoch [17/50] - Loss: 0.0192
Epoch [18/50] - Loss: 0.0109
Epoch [19/50] - Loss: 0.0037
Epoch [20/50] - Loss: -0.0024
Epoch [21/50] - Loss: -0.0077
Epoch [22/50] - Loss: -0.0122
Epoch [23/50] - Loss: -0.0162
Epoch [24/50] - Loss: -0.0197
Epoch [25/50] - Loss: -0.0229
Epoch [26/50] - Loss: -0.0257
Epoch [27/50] - Loss: -0.0283
Epoch [28/50] - Loss: -0.0305
Epoch [29/50] - Loss: -0.0326
Epoch [30/50] - Loss: -0.0344
Epoch [31/50] - Loss: -0.0361
Epoch [32/50] - Loss: -0.0377
Epoch [33/50] - Loss: -0.0392
Epoch [34/50] - Loss: -0.0406
Epoch [35/50] - Loss: -0.0419
Epoch [36/50] - Loss: -0.0431
Epoch [37/50] - Loss: -0.0442
Epoch [38/50] - Loss: -0.0451
Epoch [39/50] - Loss: -0.0459
Epoch [40/50] - Loss: -0.0466
Epoch [41/50] - Loss: -0.0472
Epoch [42/50] - Loss: -0.0478
Epoch [43/50] - Loss: -0.0483
Epoch [44/50] - Loss: -0.0488
Epoch [45/50] - Loss: -0.0493
Epoch [46/50] - Loss: -0.0497
Epoch [47/50] - Loss: -0.0501
Epoch [48/50] - Loss: -0.0506
Epoch [49/50] - Loss: -0.0510
Epoch [50/50] - Loss: -0.0515
sum preds 341
sum labels 421
 - Test Metrics: Accuracy=0.9153, F1=0.6614, Recall=0.5986, Precision=0.7390
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_imbnnpu_imbnnpu_1804084626.csv.
Average F1 over valid seeds: 0.6528 ± 0.0147
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and imbnnpu, GATConv,0.4: 0.6528 ± 0.0147
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5023
Epoch [2/50] - Loss: 0.4635
Epoch [3/50] - Loss: 0.4158
Epoch [4/50] - Loss: 0.3577
Epoch [5/50] - Loss: 0.3026
Epoch [6/50] - Loss: 0.2544
Epoch [7/50] - Loss: 0.2125
Epoch [8/50] - Loss: 0.1768
Epoch [9/50] - Loss: 0.1469
Epoch [10/50] - Loss: 0.1223
Epoch [11/50] - Loss: 0.1023
Epoch [12/50] - Loss: 0.0858
Epoch [13/50] - Loss: 0.0721
Epoch [14/50] - Loss: 0.0606
Epoch [15/50] - Loss: 0.0507
Epoch [16/50] - Loss: 0.0422
Epoch [17/50] - Loss: 0.0349
Epoch [18/50] - Loss: 0.0286
Epoch [19/50] - Loss: 0.0230
Epoch [20/50] - Loss: 0.0181
Epoch [21/50] - Loss: 0.0137
Epoch [22/50] - Loss: 0.0099
Epoch [23/50] - Loss: 0.0064
Epoch [24/50] - Loss: 0.0032
Epoch [25/50] - Loss: 0.0004
Epoch [26/50] - Loss: -0.0022
Epoch [27/50] - Loss: -0.0045
Epoch [28/50] - Loss: -0.0066
Epoch [29/50] - Loss: -0.0085
Epoch [30/50] - Loss: -0.0103
Epoch [31/50] - Loss: -0.0119
Epoch [32/50] - Loss: -0.0135
Epoch [33/50] - Loss: -0.0149
Epoch [34/50] - Loss: -0.0163
Epoch [35/50] - Loss: -0.0176
Epoch [36/50] - Loss: -0.0189
Epoch [37/50] - Loss: -0.0202
Epoch [38/50] - Loss: -0.0214
Epoch [39/50] - Loss: -0.0226
Epoch [40/50] - Loss: -0.0238
Epoch [41/50] - Loss: -0.0249
Epoch [42/50] - Loss: -0.0259
Epoch [43/50] - Loss: -0.0270
Epoch [44/50] - Loss: -0.0280
Epoch [45/50] - Loss: -0.0290
Epoch [46/50] - Loss: -0.0299
Epoch [47/50] - Loss: -0.0307
Epoch [48/50] - Loss: -0.0314
Epoch [49/50] - Loss: -0.0321
Epoch [50/50] - Loss: -0.0327
sum preds 357
sum labels 421
 - Test Metrics: Accuracy=0.9160, F1=0.6710, Recall=0.6200, Precision=0.7311
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5014
Epoch [2/50] - Loss: 0.4698
Epoch [3/50] - Loss: 0.4267
Epoch [4/50] - Loss: 0.3749
Epoch [5/50] - Loss: 0.3250
Epoch [6/50] - Loss: 0.2802
Epoch [7/50] - Loss: 0.2401
Epoch [8/50] - Loss: 0.2046
Epoch [9/50] - Loss: 0.1738
Epoch [10/50] - Loss: 0.1476
Epoch [11/50] - Loss: 0.1256
Epoch [12/50] - Loss: 0.1073
Epoch [13/50] - Loss: 0.0920
Epoch [14/50] - Loss: 0.0790
Epoch [15/50] - Loss: 0.0679
Epoch [16/50] - Loss: 0.0584
Epoch [17/50] - Loss: 0.0501
Epoch [18/50] - Loss: 0.0430
Epoch [19/50] - Loss: 0.0366
Epoch [20/50] - Loss: 0.0310
Epoch [21/50] - Loss: 0.0259
Epoch [22/50] - Loss: 0.0214
Epoch [23/50] - Loss: 0.0172
Epoch [24/50] - Loss: 0.0134
Epoch [25/50] - Loss: 0.0100
Epoch [26/50] - Loss: 0.0067
Epoch [27/50] - Loss: 0.0037
Epoch [28/50] - Loss: 0.0009
Epoch [29/50] - Loss: -0.0017
Epoch [30/50] - Loss: -0.0042
Epoch [31/50] - Loss: -0.0065
Epoch [32/50] - Loss: -0.0087
Epoch [33/50] - Loss: -0.0108
Epoch [34/50] - Loss: -0.0127
Epoch [35/50] - Loss: -0.0145
Epoch [36/50] - Loss: -0.0161
Epoch [37/50] - Loss: -0.0176
Epoch [38/50] - Loss: -0.0190
Epoch [39/50] - Loss: -0.0203
Epoch [40/50] - Loss: -0.0215
Epoch [41/50] - Loss: -0.0227
Epoch [42/50] - Loss: -0.0237
Epoch [43/50] - Loss: -0.0247
Epoch [44/50] - Loss: -0.0257
Epoch [45/50] - Loss: -0.0266
Epoch [46/50] - Loss: -0.0274
Epoch [47/50] - Loss: -0.0282
Epoch [48/50] - Loss: -0.0290
Epoch [49/50] - Loss: -0.0297
Epoch [50/50] - Loss: -0.0304
sum preds 363
sum labels 421
 - Test Metrics: Accuracy=0.9180, F1=0.6811, Recall=0.6342, Precision=0.7355
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4978
Epoch [2/50] - Loss: 0.4626
Epoch [3/50] - Loss: 0.4183
Epoch [4/50] - Loss: 0.3684
Epoch [5/50] - Loss: 0.3213
Epoch [6/50] - Loss: 0.2784
Epoch [7/50] - Loss: 0.2393
Epoch [8/50] - Loss: 0.2045
Epoch [9/50] - Loss: 0.1744
Epoch [10/50] - Loss: 0.1486
Epoch [11/50] - Loss: 0.1268
Epoch [12/50] - Loss: 0.1084
Epoch [13/50] - Loss: 0.0930
Epoch [14/50] - Loss: 0.0799
Epoch [15/50] - Loss: 0.0687
Epoch [16/50] - Loss: 0.0591
Epoch [17/50] - Loss: 0.0507
Epoch [18/50] - Loss: 0.0433
Epoch [19/50] - Loss: 0.0367
Epoch [20/50] - Loss: 0.0309
Epoch [21/50] - Loss: 0.0256
Epoch [22/50] - Loss: 0.0209
Epoch [23/50] - Loss: 0.0166
Epoch [24/50] - Loss: 0.0128
Epoch [25/50] - Loss: 0.0093
Epoch [26/50] - Loss: 0.0063
Epoch [27/50] - Loss: 0.0035
Epoch [28/50] - Loss: 0.0010
Epoch [29/50] - Loss: -0.0013
Epoch [30/50] - Loss: -0.0034
Epoch [31/50] - Loss: -0.0053
Epoch [32/50] - Loss: -0.0070
Epoch [33/50] - Loss: -0.0086
Epoch [34/50] - Loss: -0.0101
Epoch [35/50] - Loss: -0.0115
Epoch [36/50] - Loss: -0.0128
Epoch [37/50] - Loss: -0.0141
Epoch [38/50] - Loss: -0.0152
Epoch [39/50] - Loss: -0.0163
Epoch [40/50] - Loss: -0.0173
Epoch [41/50] - Loss: -0.0183
Epoch [42/50] - Loss: -0.0193
Epoch [43/50] - Loss: -0.0202
Epoch [44/50] - Loss: -0.0212
Epoch [45/50] - Loss: -0.0221
Epoch [46/50] - Loss: -0.0230
Epoch [47/50] - Loss: -0.0238
Epoch [48/50] - Loss: -0.0247
Epoch [49/50] - Loss: -0.0254
Epoch [50/50] - Loss: -0.0261
sum preds 390
sum labels 421
 - Test Metrics: Accuracy=0.9235, F1=0.7127, Recall=0.6865, Precision=0.7410
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_imbnnpu_imbnnpu_1804084629.csv.
Average F1 over valid seeds: 0.6883 ± 0.0178
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and imbnnpu, GCNConv,0.4: 0.6883 ± 0.0178
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4995
Epoch [2/50] - Loss: 0.4845
Epoch [3/50] - Loss: 0.4644
Epoch [4/50] - Loss: 0.4412
Epoch [5/50] - Loss: 0.4158
Epoch [6/50] - Loss: 0.3884
Epoch [7/50] - Loss: 0.3596
Epoch [8/50] - Loss: 0.3298
Epoch [9/50] - Loss: 0.2993
Epoch [10/50] - Loss: 0.2687
Epoch [11/50] - Loss: 0.2385
Epoch [12/50] - Loss: 0.2091
Epoch [13/50] - Loss: 0.1809
Epoch [14/50] - Loss: 0.1544
Epoch [15/50] - Loss: 0.1297
Epoch [16/50] - Loss: 0.1069
Epoch [17/50] - Loss: 0.0862
Epoch [18/50] - Loss: 0.0673
Epoch [19/50] - Loss: 0.0503
Epoch [20/50] - Loss: 0.0350
Epoch [21/50] - Loss: 0.0212
Epoch [22/50] - Loss: 0.0088
Epoch [23/50] - Loss: -0.0025
Epoch [24/50] - Loss: -0.0125
Epoch [25/50] - Loss: -0.0216
Epoch [26/50] - Loss: -0.0298
Epoch [27/50] - Loss: -0.0372
Epoch [28/50] - Loss: -0.0439
Epoch [29/50] - Loss: -0.0499
Epoch [30/50] - Loss: -0.0553
Epoch [31/50] - Loss: -0.0602
Epoch [32/50] - Loss: -0.0646
Epoch [33/50] - Loss: -0.0686
Epoch [34/50] - Loss: -0.0722
Epoch [35/50] - Loss: -0.0754
Epoch [36/50] - Loss: -0.0784
Epoch [37/50] - Loss: -0.0811
Epoch [38/50] - Loss: -0.0835
Epoch [39/50] - Loss: -0.0858
Epoch [40/50] - Loss: -0.0879
Epoch [41/50] - Loss: -0.0898
Epoch [42/50] - Loss: -0.0915
Epoch [43/50] - Loss: -0.0932
Epoch [44/50] - Loss: -0.0947
Epoch [45/50] - Loss: -0.0961
Epoch [46/50] - Loss: -0.0974
Epoch [47/50] - Loss: -0.0987
Epoch [48/50] - Loss: -0.0998
Epoch [49/50] - Loss: -0.1009
Epoch [50/50] - Loss: -0.1019
sum preds 83
sum labels 491
 - Test Metrics: Accuracy=0.8620, F1=0.2509, Recall=0.1466, Precision=0.8675
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4854
Epoch [3/50] - Loss: 0.4642
Epoch [4/50] - Loss: 0.4404
Epoch [5/50] - Loss: 0.4143
Epoch [6/50] - Loss: 0.3858
Epoch [7/50] - Loss: 0.3553
Epoch [8/50] - Loss: 0.3238
Epoch [9/50] - Loss: 0.2919
Epoch [10/50] - Loss: 0.2599
Epoch [11/50] - Loss: 0.2285
Epoch [12/50] - Loss: 0.1982
Epoch [13/50] - Loss: 0.1695
Epoch [14/50] - Loss: 0.1428
Epoch [15/50] - Loss: 0.1182
Epoch [16/50] - Loss: 0.0958
Epoch [17/50] - Loss: 0.0755
Epoch [18/50] - Loss: 0.0573
Epoch [19/50] - Loss: 0.0410
Epoch [20/50] - Loss: 0.0265
Epoch [21/50] - Loss: 0.0134
Epoch [22/50] - Loss: 0.0018
Epoch [23/50] - Loss: -0.0087
Epoch [24/50] - Loss: -0.0181
Epoch [25/50] - Loss: -0.0265
Epoch [26/50] - Loss: -0.0341
Epoch [27/50] - Loss: -0.0410
Epoch [28/50] - Loss: -0.0471
Epoch [29/50] - Loss: -0.0527
Epoch [30/50] - Loss: -0.0577
Epoch [31/50] - Loss: -0.0623
Epoch [32/50] - Loss: -0.0664
Epoch [33/50] - Loss: -0.0701
Epoch [34/50] - Loss: -0.0734
Epoch [35/50] - Loss: -0.0765
Epoch [36/50] - Loss: -0.0793
Epoch [37/50] - Loss: -0.0819
Epoch [38/50] - Loss: -0.0843
Epoch [39/50] - Loss: -0.0865
Epoch [40/50] - Loss: -0.0885
Epoch [41/50] - Loss: -0.0904
Epoch [42/50] - Loss: -0.0922
Epoch [43/50] - Loss: -0.0939
Epoch [44/50] - Loss: -0.0955
Epoch [45/50] - Loss: -0.0969
Epoch [46/50] - Loss: -0.0983
Epoch [47/50] - Loss: -0.0996
Epoch [48/50] - Loss: -0.1008
Epoch [49/50] - Loss: -0.1020
Epoch [50/50] - Loss: -0.1030
sum preds 79
sum labels 491
 - Test Metrics: Accuracy=0.8608, F1=0.2386, Recall=0.1385, Precision=0.8608
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4993
Epoch [2/50] - Loss: 0.4820
Epoch [3/50] - Loss: 0.4589
Epoch [4/50] - Loss: 0.4329
Epoch [5/50] - Loss: 0.4047
Epoch [6/50] - Loss: 0.3748
Epoch [7/50] - Loss: 0.3438
Epoch [8/50] - Loss: 0.3123
Epoch [9/50] - Loss: 0.2809
Epoch [10/50] - Loss: 0.2499
Epoch [11/50] - Loss: 0.2199
Epoch [12/50] - Loss: 0.1912
Epoch [13/50] - Loss: 0.1641
Epoch [14/50] - Loss: 0.1389
Epoch [15/50] - Loss: 0.1156
Epoch [16/50] - Loss: 0.0942
Epoch [17/50] - Loss: 0.0749
Epoch [18/50] - Loss: 0.0574
Epoch [19/50] - Loss: 0.0417
Epoch [20/50] - Loss: 0.0276
Epoch [21/50] - Loss: 0.0149
Epoch [22/50] - Loss: 0.0035
Epoch [23/50] - Loss: -0.0067
Epoch [24/50] - Loss: -0.0160
Epoch [25/50] - Loss: -0.0243
Epoch [26/50] - Loss: -0.0319
Epoch [27/50] - Loss: -0.0388
Epoch [28/50] - Loss: -0.0450
Epoch [29/50] - Loss: -0.0507
Epoch [30/50] - Loss: -0.0559
Epoch [31/50] - Loss: -0.0606
Epoch [32/50] - Loss: -0.0648
Epoch [33/50] - Loss: -0.0687
Epoch [34/50] - Loss: -0.0721
Epoch [35/50] - Loss: -0.0752
Epoch [36/50] - Loss: -0.0781
Epoch [37/50] - Loss: -0.0806
Epoch [38/50] - Loss: -0.0830
Epoch [39/50] - Loss: -0.0852
Epoch [40/50] - Loss: -0.0872
Epoch [41/50] - Loss: -0.0890
Epoch [42/50] - Loss: -0.0907
Epoch [43/50] - Loss: -0.0923
Epoch [44/50] - Loss: -0.0938
Epoch [45/50] - Loss: -0.0952
Epoch [46/50] - Loss: -0.0966
Epoch [47/50] - Loss: -0.0978
Epoch [48/50] - Loss: -0.0990
Epoch [49/50] - Loss: -0.1001
Epoch [50/50] - Loss: -0.1011
sum preds 93
sum labels 491
 - Test Metrics: Accuracy=0.8678, F1=0.2945, Recall=0.1752, Precision=0.9247
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_imbnnpu_imbnnpu_1804084632.csv.
Average F1 over valid seeds: 0.2613 ± 0.0240
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and imbnnpu, MLP,0.3: 0.2613 ± 0.0240
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4994
Epoch [2/50] - Loss: 0.4674
Epoch [3/50] - Loss: 0.4267
Epoch [4/50] - Loss: 0.3781
Epoch [5/50] - Loss: 0.3294
Epoch [6/50] - Loss: 0.2841
Epoch [7/50] - Loss: 0.2426
Epoch [8/50] - Loss: 0.2051
Epoch [9/50] - Loss: 0.1719
Epoch [10/50] - Loss: 0.1428
Epoch [11/50] - Loss: 0.1178
Epoch [12/50] - Loss: 0.0964
Epoch [13/50] - Loss: 0.0781
Epoch [14/50] - Loss: 0.0623
Epoch [15/50] - Loss: 0.0488
Epoch [16/50] - Loss: 0.0370
Epoch [17/50] - Loss: 0.0266
Epoch [18/50] - Loss: 0.0173
Epoch [19/50] - Loss: 0.0091
Epoch [20/50] - Loss: 0.0020
Epoch [21/50] - Loss: -0.0041
Epoch [22/50] - Loss: -0.0094
Epoch [23/50] - Loss: -0.0139
Epoch [24/50] - Loss: -0.0179
Epoch [25/50] - Loss: -0.0215
Epoch [26/50] - Loss: -0.0246
Epoch [27/50] - Loss: -0.0272
Epoch [28/50] - Loss: -0.0295
Epoch [29/50] - Loss: -0.0316
Epoch [30/50] - Loss: -0.0336
Epoch [31/50] - Loss: -0.0353
Epoch [32/50] - Loss: -0.0368
Epoch [33/50] - Loss: -0.0382
Epoch [34/50] - Loss: -0.0394
Epoch [35/50] - Loss: -0.0406
Epoch [36/50] - Loss: -0.0416
Epoch [37/50] - Loss: -0.0427
Epoch [38/50] - Loss: -0.0437
Epoch [39/50] - Loss: -0.0447
Epoch [40/50] - Loss: -0.0457
Epoch [41/50] - Loss: -0.0467
Epoch [42/50] - Loss: -0.0477
Epoch [43/50] - Loss: -0.0487
Epoch [44/50] - Loss: -0.0496
Epoch [45/50] - Loss: -0.0504
Epoch [46/50] - Loss: -0.0511
Epoch [47/50] - Loss: -0.0517
Epoch [48/50] - Loss: -0.0523
Epoch [49/50] - Loss: -0.0531
Epoch [50/50] - Loss: -0.0537
sum preds 279
sum labels 491
 - Test Metrics: Accuracy=0.8980, F1=0.5870, Recall=0.4603, Precision=0.8100
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5050
Epoch [2/50] - Loss: 0.4730
Epoch [3/50] - Loss: 0.4307
Epoch [4/50] - Loss: 0.3778
Epoch [5/50] - Loss: 0.3273
Epoch [6/50] - Loss: 0.2818
Epoch [7/50] - Loss: 0.2391
Epoch [8/50] - Loss: 0.1997
Epoch [9/50] - Loss: 0.1651
Epoch [10/50] - Loss: 0.1355
Epoch [11/50] - Loss: 0.1102
Epoch [12/50] - Loss: 0.0886
Epoch [13/50] - Loss: 0.0699
Epoch [14/50] - Loss: 0.0536
Epoch [15/50] - Loss: 0.0397
Epoch [16/50] - Loss: 0.0279
Epoch [17/50] - Loss: 0.0177
Epoch [18/50] - Loss: 0.0091
Epoch [19/50] - Loss: 0.0018
Epoch [20/50] - Loss: -0.0042
Epoch [21/50] - Loss: -0.0093
Epoch [22/50] - Loss: -0.0139
Epoch [23/50] - Loss: -0.0182
Epoch [24/50] - Loss: -0.0223
Epoch [25/50] - Loss: -0.0256
Epoch [26/50] - Loss: -0.0281
Epoch [27/50] - Loss: -0.0304
Epoch [28/50] - Loss: -0.0327
Epoch [29/50] - Loss: -0.0347
Epoch [30/50] - Loss: -0.0365
Epoch [31/50] - Loss: -0.0382
Epoch [32/50] - Loss: -0.0399
Epoch [33/50] - Loss: -0.0414
Epoch [34/50] - Loss: -0.0430
Epoch [35/50] - Loss: -0.0445
Epoch [36/50] - Loss: -0.0460
Epoch [37/50] - Loss: -0.0475
Epoch [38/50] - Loss: -0.0492
Epoch [39/50] - Loss: -0.0510
Epoch [40/50] - Loss: -0.0526
Epoch [41/50] - Loss: -0.0538
Epoch [42/50] - Loss: -0.0546
Epoch [43/50] - Loss: -0.0553
Epoch [44/50] - Loss: -0.0560
Epoch [45/50] - Loss: -0.0566
Epoch [46/50] - Loss: -0.0573
Epoch [47/50] - Loss: -0.0578
Epoch [48/50] - Loss: -0.0583
Epoch [49/50] - Loss: -0.0587
Epoch [50/50] - Loss: -0.0591
sum preds 295
sum labels 491
 - Test Metrics: Accuracy=0.8954, F1=0.5852, Recall=0.4684, Precision=0.7797
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4665
Epoch [3/50] - Loss: 0.4240
Epoch [4/50] - Loss: 0.3751
Epoch [5/50] - Loss: 0.3264
Epoch [6/50] - Loss: 0.2798
Epoch [7/50] - Loss: 0.2363
Epoch [8/50] - Loss: 0.1966
Epoch [9/50] - Loss: 0.1609
Epoch [10/50] - Loss: 0.1294
Epoch [11/50] - Loss: 0.1021
Epoch [12/50] - Loss: 0.0789
Epoch [13/50] - Loss: 0.0594
Epoch [14/50] - Loss: 0.0432
Epoch [15/50] - Loss: 0.0296
Epoch [16/50] - Loss: 0.0181
Epoch [17/50] - Loss: 0.0084
Epoch [18/50] - Loss: 0.0002
Epoch [19/50] - Loss: -0.0067
Epoch [20/50] - Loss: -0.0126
Epoch [21/50] - Loss: -0.0177
Epoch [22/50] - Loss: -0.0220
Epoch [23/50] - Loss: -0.0259
Epoch [24/50] - Loss: -0.0292
Epoch [25/50] - Loss: -0.0321
Epoch [26/50] - Loss: -0.0347
Epoch [27/50] - Loss: -0.0371
Epoch [28/50] - Loss: -0.0393
Epoch [29/50] - Loss: -0.0414
Epoch [30/50] - Loss: -0.0433
Epoch [31/50] - Loss: -0.0450
Epoch [32/50] - Loss: -0.0465
Epoch [33/50] - Loss: -0.0479
Epoch [34/50] - Loss: -0.0492
Epoch [35/50] - Loss: -0.0503
Epoch [36/50] - Loss: -0.0514
Epoch [37/50] - Loss: -0.0524
Epoch [38/50] - Loss: -0.0534
Epoch [39/50] - Loss: -0.0543
Epoch [40/50] - Loss: -0.0554
Epoch [41/50] - Loss: -0.0564
Epoch [42/50] - Loss: -0.0574
Epoch [43/50] - Loss: -0.0585
Epoch [44/50] - Loss: -0.0595
Epoch [45/50] - Loss: -0.0606
Epoch [46/50] - Loss: -0.0615
Epoch [47/50] - Loss: -0.0624
Epoch [48/50] - Loss: -0.0631
Epoch [49/50] - Loss: -0.0637
Epoch [50/50] - Loss: -0.0642
sum preds 296
sum labels 491
 - Test Metrics: Accuracy=0.8964, F1=0.5896, Recall=0.4725, Precision=0.7838
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_imbnnpu_imbnnpu_1804084634.csv.
Average F1 over valid seeds: 0.5873 ± 0.0018
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and imbnnpu, GATConv,0.3: 0.5873 ± 0.0018
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5024
Epoch [2/50] - Loss: 0.4638
Epoch [3/50] - Loss: 0.4163
Epoch [4/50] - Loss: 0.3597
Epoch [5/50] - Loss: 0.3058
Epoch [6/50] - Loss: 0.2578
Epoch [7/50] - Loss: 0.2158
Epoch [8/50] - Loss: 0.1796
Epoch [9/50] - Loss: 0.1494
Epoch [10/50] - Loss: 0.1246
Epoch [11/50] - Loss: 0.1044
Epoch [12/50] - Loss: 0.0876
Epoch [13/50] - Loss: 0.0734
Epoch [14/50] - Loss: 0.0614
Epoch [15/50] - Loss: 0.0511
Epoch [16/50] - Loss: 0.0423
Epoch [17/50] - Loss: 0.0346
Epoch [18/50] - Loss: 0.0280
Epoch [19/50] - Loss: 0.0223
Epoch [20/50] - Loss: 0.0172
Epoch [21/50] - Loss: 0.0128
Epoch [22/50] - Loss: 0.0089
Epoch [23/50] - Loss: 0.0054
Epoch [24/50] - Loss: 0.0022
Epoch [25/50] - Loss: -0.0007
Epoch [26/50] - Loss: -0.0033
Epoch [27/50] - Loss: -0.0057
Epoch [28/50] - Loss: -0.0079
Epoch [29/50] - Loss: -0.0100
Epoch [30/50] - Loss: -0.0119
Epoch [31/50] - Loss: -0.0136
Epoch [32/50] - Loss: -0.0151
Epoch [33/50] - Loss: -0.0166
Epoch [34/50] - Loss: -0.0179
Epoch [35/50] - Loss: -0.0191
Epoch [36/50] - Loss: -0.0202
Epoch [37/50] - Loss: -0.0212
Epoch [38/50] - Loss: -0.0222
Epoch [39/50] - Loss: -0.0231
Epoch [40/50] - Loss: -0.0239
Epoch [41/50] - Loss: -0.0248
Epoch [42/50] - Loss: -0.0256
Epoch [43/50] - Loss: -0.0264
Epoch [44/50] - Loss: -0.0271
Epoch [45/50] - Loss: -0.0278
Epoch [46/50] - Loss: -0.0285
Epoch [47/50] - Loss: -0.0291
Epoch [48/50] - Loss: -0.0297
Epoch [49/50] - Loss: -0.0302
Epoch [50/50] - Loss: -0.0308
sum preds 347
sum labels 491
 - Test Metrics: Accuracy=0.9070, F1=0.6539, Recall=0.5580, Precision=0.7896
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5015
Epoch [2/50] - Loss: 0.4696
Epoch [3/50] - Loss: 0.4269
Epoch [4/50] - Loss: 0.3760
Epoch [5/50] - Loss: 0.3269
Epoch [6/50] - Loss: 0.2824
Epoch [7/50] - Loss: 0.2425
Epoch [8/50] - Loss: 0.2072
Epoch [9/50] - Loss: 0.1764
Epoch [10/50] - Loss: 0.1501
Epoch [11/50] - Loss: 0.1278
Epoch [12/50] - Loss: 0.1092
Epoch [13/50] - Loss: 0.0935
Epoch [14/50] - Loss: 0.0801
Epoch [15/50] - Loss: 0.0688
Epoch [16/50] - Loss: 0.0591
Epoch [17/50] - Loss: 0.0507
Epoch [18/50] - Loss: 0.0434
Epoch [19/50] - Loss: 0.0370
Epoch [20/50] - Loss: 0.0314
Epoch [21/50] - Loss: 0.0263
Epoch [22/50] - Loss: 0.0217
Epoch [23/50] - Loss: 0.0176
Epoch [24/50] - Loss: 0.0138
Epoch [25/50] - Loss: 0.0103
Epoch [26/50] - Loss: 0.0071
Epoch [27/50] - Loss: 0.0042
Epoch [28/50] - Loss: 0.0014
Epoch [29/50] - Loss: -0.0011
Epoch [30/50] - Loss: -0.0035
Epoch [31/50] - Loss: -0.0056
Epoch [32/50] - Loss: -0.0077
Epoch [33/50] - Loss: -0.0096
Epoch [34/50] - Loss: -0.0113
Epoch [35/50] - Loss: -0.0130
Epoch [36/50] - Loss: -0.0146
Epoch [37/50] - Loss: -0.0160
Epoch [38/50] - Loss: -0.0174
Epoch [39/50] - Loss: -0.0187
Epoch [40/50] - Loss: -0.0199
Epoch [41/50] - Loss: -0.0210
Epoch [42/50] - Loss: -0.0221
Epoch [43/50] - Loss: -0.0231
Epoch [44/50] - Loss: -0.0241
Epoch [45/50] - Loss: -0.0250
Epoch [46/50] - Loss: -0.0259
Epoch [47/50] - Loss: -0.0267
Epoch [48/50] - Loss: -0.0276
Epoch [49/50] - Loss: -0.0284
Epoch [50/50] - Loss: -0.0292
sum preds 371
sum labels 491
 - Test Metrics: Accuracy=0.9063, F1=0.6613, Recall=0.5804, Precision=0.7682
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4978
Epoch [2/50] - Loss: 0.4613
Epoch [3/50] - Loss: 0.4157
Epoch [4/50] - Loss: 0.3645
Epoch [5/50] - Loss: 0.3165
Epoch [6/50] - Loss: 0.2726
Epoch [7/50] - Loss: 0.2325
Epoch [8/50] - Loss: 0.1970
Epoch [9/50] - Loss: 0.1661
Epoch [10/50] - Loss: 0.1397
Epoch [11/50] - Loss: 0.1174
Epoch [12/50] - Loss: 0.0985
Epoch [13/50] - Loss: 0.0825
Epoch [14/50] - Loss: 0.0689
Epoch [15/50] - Loss: 0.0573
Epoch [16/50] - Loss: 0.0472
Epoch [17/50] - Loss: 0.0384
Epoch [18/50] - Loss: 0.0307
Epoch [19/50] - Loss: 0.0240
Epoch [20/50] - Loss: 0.0180
Epoch [21/50] - Loss: 0.0126
Epoch [22/50] - Loss: 0.0078
Epoch [23/50] - Loss: 0.0035
Epoch [24/50] - Loss: -0.0004
Epoch [25/50] - Loss: -0.0039
Epoch [26/50] - Loss: -0.0072
Epoch [27/50] - Loss: -0.0101
Epoch [28/50] - Loss: -0.0129
Epoch [29/50] - Loss: -0.0154
Epoch [30/50] - Loss: -0.0177
Epoch [31/50] - Loss: -0.0199
Epoch [32/50] - Loss: -0.0219
Epoch [33/50] - Loss: -0.0238
Epoch [34/50] - Loss: -0.0255
Epoch [35/50] - Loss: -0.0271
Epoch [36/50] - Loss: -0.0286
Epoch [37/50] - Loss: -0.0300
Epoch [38/50] - Loss: -0.0312
Epoch [39/50] - Loss: -0.0324
Epoch [40/50] - Loss: -0.0335
Epoch [41/50] - Loss: -0.0344
Epoch [42/50] - Loss: -0.0354
Epoch [43/50] - Loss: -0.0362
Epoch [44/50] - Loss: -0.0370
Epoch [45/50] - Loss: -0.0378
Epoch [46/50] - Loss: -0.0386
Epoch [47/50] - Loss: -0.0393
Epoch [48/50] - Loss: -0.0400
Epoch [49/50] - Loss: -0.0406
Epoch [50/50] - Loss: -0.0412
sum preds 372
sum labels 491
 - Test Metrics: Accuracy=0.9131, F1=0.6860, Recall=0.6029, Precision=0.7957
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_imbnnpu_imbnnpu_1804084637.csv.
Average F1 over valid seeds: 0.6671 ± 0.0137
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and imbnnpu, GCNConv,0.3: 0.6671 ± 0.0137
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4848
Epoch [3/50] - Loss: 0.4649
Epoch [4/50] - Loss: 0.4419
Epoch [5/50] - Loss: 0.4162
Epoch [6/50] - Loss: 0.3882
Epoch [7/50] - Loss: 0.3583
Epoch [8/50] - Loss: 0.3273
Epoch [9/50] - Loss: 0.2957
Epoch [10/50] - Loss: 0.2638
Epoch [11/50] - Loss: 0.2322
Epoch [12/50] - Loss: 0.2014
Epoch [13/50] - Loss: 0.1720
Epoch [14/50] - Loss: 0.1441
Epoch [15/50] - Loss: 0.1182
Epoch [16/50] - Loss: 0.0942
Epoch [17/50] - Loss: 0.0724
Epoch [18/50] - Loss: 0.0526
Epoch [19/50] - Loss: 0.0347
Epoch [20/50] - Loss: 0.0188
Epoch [21/50] - Loss: 0.0045
Epoch [22/50] - Loss: -0.0082
Epoch [23/50] - Loss: -0.0196
Epoch [24/50] - Loss: -0.0297
Epoch [25/50] - Loss: -0.0387
Epoch [26/50] - Loss: -0.0467
Epoch [27/50] - Loss: -0.0538
Epoch [28/50] - Loss: -0.0601
Epoch [29/50] - Loss: -0.0658
Epoch [30/50] - Loss: -0.0708
Epoch [31/50] - Loss: -0.0754
Epoch [32/50] - Loss: -0.0795
Epoch [33/50] - Loss: -0.0831
Epoch [34/50] - Loss: -0.0864
Epoch [35/50] - Loss: -0.0893
Epoch [36/50] - Loss: -0.0919
Epoch [37/50] - Loss: -0.0942
Epoch [38/50] - Loss: -0.0964
Epoch [39/50] - Loss: -0.0983
Epoch [40/50] - Loss: -0.1001
Epoch [41/50] - Loss: -0.1017
Epoch [42/50] - Loss: -0.1031
Epoch [43/50] - Loss: -0.1045
Epoch [44/50] - Loss: -0.1057
Epoch [45/50] - Loss: -0.1069
Epoch [46/50] - Loss: -0.1080
Epoch [47/50] - Loss: -0.1089
Epoch [48/50] - Loss: -0.1099
Epoch [49/50] - Loss: -0.1107
Epoch [50/50] - Loss: -0.1115
sum preds 37
sum labels 561
 - Test Metrics: Accuracy=0.8306, F1=0.0970, Recall=0.0517, Precision=0.7838
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4996
Epoch [2/50] - Loss: 0.4831
Epoch [3/50] - Loss: 0.4606
Epoch [4/50] - Loss: 0.4346
Epoch [5/50] - Loss: 0.4063
Epoch [6/50] - Loss: 0.3757
Epoch [7/50] - Loss: 0.3433
Epoch [8/50] - Loss: 0.3096
Epoch [9/50] - Loss: 0.2755
Epoch [10/50] - Loss: 0.2416
Epoch [11/50] - Loss: 0.2084
Epoch [12/50] - Loss: 0.1768
Epoch [13/50] - Loss: 0.1471
Epoch [14/50] - Loss: 0.1196
Epoch [15/50] - Loss: 0.0946
Epoch [16/50] - Loss: 0.0720
Epoch [17/50] - Loss: 0.0518
Epoch [18/50] - Loss: 0.0338
Epoch [19/50] - Loss: 0.0179
Epoch [20/50] - Loss: 0.0037
Epoch [21/50] - Loss: -0.0088
Epoch [22/50] - Loss: -0.0200
Epoch [23/50] - Loss: -0.0299
Epoch [24/50] - Loss: -0.0387
Epoch [25/50] - Loss: -0.0466
Epoch [26/50] - Loss: -0.0536
Epoch [27/50] - Loss: -0.0599
Epoch [28/50] - Loss: -0.0655
Epoch [29/50] - Loss: -0.0705
Epoch [30/50] - Loss: -0.0750
Epoch [31/50] - Loss: -0.0790
Epoch [32/50] - Loss: -0.0826
Epoch [33/50] - Loss: -0.0859
Epoch [34/50] - Loss: -0.0888
Epoch [35/50] - Loss: -0.0914
Epoch [36/50] - Loss: -0.0938
Epoch [37/50] - Loss: -0.0960
Epoch [38/50] - Loss: -0.0980
Epoch [39/50] - Loss: -0.0998
Epoch [40/50] - Loss: -0.1015
Epoch [41/50] - Loss: -0.1030
Epoch [42/50] - Loss: -0.1044
Epoch [43/50] - Loss: -0.1057
Epoch [44/50] - Loss: -0.1068
Epoch [45/50] - Loss: -0.1079
Epoch [46/50] - Loss: -0.1090
Epoch [47/50] - Loss: -0.1099
Epoch [48/50] - Loss: -0.1108
Epoch [49/50] - Loss: -0.1116
Epoch [50/50] - Loss: -0.1124
sum preds 49
sum labels 561
 - Test Metrics: Accuracy=0.8356, F1=0.1410, Recall=0.0766, Precision=0.8776
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4994
Epoch [2/50] - Loss: 0.4815
Epoch [3/50] - Loss: 0.4578
Epoch [4/50] - Loss: 0.4304
Epoch [5/50] - Loss: 0.4005
Epoch [6/50] - Loss: 0.3689
Epoch [7/50] - Loss: 0.3360
Epoch [8/50] - Loss: 0.3025
Epoch [9/50] - Loss: 0.2691
Epoch [10/50] - Loss: 0.2363
Epoch [11/50] - Loss: 0.2045
Epoch [12/50] - Loss: 0.1742
Epoch [13/50] - Loss: 0.1458
Epoch [14/50] - Loss: 0.1192
Epoch [15/50] - Loss: 0.0948
Epoch [16/50] - Loss: 0.0725
Epoch [17/50] - Loss: 0.0523
Epoch [18/50] - Loss: 0.0341
Epoch [19/50] - Loss: 0.0179
Epoch [20/50] - Loss: 0.0034
Epoch [21/50] - Loss: -0.0095
Epoch [22/50] - Loss: -0.0209
Epoch [23/50] - Loss: -0.0311
Epoch [24/50] - Loss: -0.0401
Epoch [25/50] - Loss: -0.0480
Epoch [26/50] - Loss: -0.0551
Epoch [27/50] - Loss: -0.0614
Epoch [28/50] - Loss: -0.0670
Epoch [29/50] - Loss: -0.0719
Epoch [30/50] - Loss: -0.0763
Epoch [31/50] - Loss: -0.0803
Epoch [32/50] - Loss: -0.0838
Epoch [33/50] - Loss: -0.0870
Epoch [34/50] - Loss: -0.0899
Epoch [35/50] - Loss: -0.0925
Epoch [36/50] - Loss: -0.0949
Epoch [37/50] - Loss: -0.0970
Epoch [38/50] - Loss: -0.0990
Epoch [39/50] - Loss: -0.1008
Epoch [40/50] - Loss: -0.1025
Epoch [41/50] - Loss: -0.1041
Epoch [42/50] - Loss: -0.1055
Epoch [43/50] - Loss: -0.1068
Epoch [44/50] - Loss: -0.1081
Epoch [45/50] - Loss: -0.1092
Epoch [46/50] - Loss: -0.1103
Epoch [47/50] - Loss: -0.1113
Epoch [48/50] - Loss: -0.1122
Epoch [49/50] - Loss: -0.1130
Epoch [50/50] - Loss: -0.1138
sum preds 39
sum labels 561
 - Test Metrics: Accuracy=0.8337, F1=0.1167, Recall=0.0624, Precision=0.8974
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_imbnnpu_imbnnpu_1804084640.csv.
Average F1 over valid seeds: 0.1182 ± 0.0180
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and imbnnpu, MLP,0.2: 0.1182 ± 0.0180
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4995
Epoch [2/50] - Loss: 0.4659
Epoch [3/50] - Loss: 0.4242
Epoch [4/50] - Loss: 0.3752
Epoch [5/50] - Loss: 0.3257
Epoch [6/50] - Loss: 0.2791
Epoch [7/50] - Loss: 0.2361
Epoch [8/50] - Loss: 0.1972
Epoch [9/50] - Loss: 0.1628
Epoch [10/50] - Loss: 0.1329
Epoch [11/50] - Loss: 0.1073
Epoch [12/50] - Loss: 0.0855
Epoch [13/50] - Loss: 0.0668
Epoch [14/50] - Loss: 0.0505
Epoch [15/50] - Loss: 0.0367
Epoch [16/50] - Loss: 0.0247
Epoch [17/50] - Loss: 0.0141
Epoch [18/50] - Loss: 0.0048
Epoch [19/50] - Loss: -0.0033
Epoch [20/50] - Loss: -0.0102
Epoch [21/50] - Loss: -0.0163
Epoch [22/50] - Loss: -0.0216
Epoch [23/50] - Loss: -0.0261
Epoch [24/50] - Loss: -0.0301
Epoch [25/50] - Loss: -0.0335
Epoch [26/50] - Loss: -0.0365
Epoch [27/50] - Loss: -0.0393
Epoch [28/50] - Loss: -0.0417
Epoch [29/50] - Loss: -0.0439
Epoch [30/50] - Loss: -0.0459
Epoch [31/50] - Loss: -0.0478
Epoch [32/50] - Loss: -0.0497
Epoch [33/50] - Loss: -0.0517
Epoch [34/50] - Loss: -0.0539
Epoch [35/50] - Loss: -0.0562
Epoch [36/50] - Loss: -0.0586
Epoch [37/50] - Loss: -0.0608
Epoch [38/50] - Loss: -0.0626
Epoch [39/50] - Loss: -0.0643
Epoch [40/50] - Loss: -0.0658
Epoch [41/50] - Loss: -0.0672
Epoch [42/50] - Loss: -0.0686
Epoch [43/50] - Loss: -0.0699
Epoch [44/50] - Loss: -0.0712
Epoch [45/50] - Loss: -0.0723
Epoch [46/50] - Loss: -0.0733
Epoch [47/50] - Loss: -0.0744
Epoch [48/50] - Loss: -0.0755
Epoch [49/50] - Loss: -0.0765
Epoch [50/50] - Loss: -0.0774
sum preds 182
sum labels 561
 - Test Metrics: Accuracy=0.8623, F1=0.4092, Recall=0.2709, Precision=0.8352
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5056
Epoch [2/50] - Loss: 0.4728
Epoch [3/50] - Loss: 0.4292
Epoch [4/50] - Loss: 0.3735
Epoch [5/50] - Loss: 0.3207
Epoch [6/50] - Loss: 0.2728
Epoch [7/50] - Loss: 0.2271
Epoch [8/50] - Loss: 0.1846
Epoch [9/50] - Loss: 0.1476
Epoch [10/50] - Loss: 0.1161
Epoch [11/50] - Loss: 0.0896
Epoch [12/50] - Loss: 0.0671
Epoch [13/50] - Loss: 0.0478
Epoch [14/50] - Loss: 0.0312
Epoch [15/50] - Loss: 0.0170
Epoch [16/50] - Loss: 0.0052
Epoch [17/50] - Loss: -0.0045
Epoch [18/50] - Loss: -0.0126
Epoch [19/50] - Loss: -0.0192
Epoch [20/50] - Loss: -0.0247
Epoch [21/50] - Loss: -0.0295
Epoch [22/50] - Loss: -0.0337
Epoch [23/50] - Loss: -0.0374
Epoch [24/50] - Loss: -0.0408
Epoch [25/50] - Loss: -0.0439
Epoch [26/50] - Loss: -0.0466
Epoch [27/50] - Loss: -0.0492
Epoch [28/50] - Loss: -0.0516
Epoch [29/50] - Loss: -0.0538
Epoch [30/50] - Loss: -0.0558
Epoch [31/50] - Loss: -0.0575
Epoch [32/50] - Loss: -0.0593
Epoch [33/50] - Loss: -0.0606
Epoch [34/50] - Loss: -0.0617
Epoch [35/50] - Loss: -0.0626
Epoch [36/50] - Loss: -0.0634
Epoch [37/50] - Loss: -0.0641
Epoch [38/50] - Loss: -0.0648
Epoch [39/50] - Loss: -0.0654
Epoch [40/50] - Loss: -0.0660
Epoch [41/50] - Loss: -0.0668
Epoch [42/50] - Loss: -0.0675
Epoch [43/50] - Loss: -0.0680
Epoch [44/50] - Loss: -0.0685
Epoch [45/50] - Loss: -0.0689
Epoch [46/50] - Loss: -0.0694
Epoch [47/50] - Loss: -0.0698
Epoch [48/50] - Loss: -0.0703
Epoch [49/50] - Loss: -0.0707
Epoch [50/50] - Loss: -0.0712
sum preds 217
sum labels 561
 - Test Metrics: Accuracy=0.8726, F1=0.4781, Recall=0.3316, Precision=0.8571
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4996
Epoch [2/50] - Loss: 0.4657
Epoch [3/50] - Loss: 0.4234
Epoch [4/50] - Loss: 0.3749
Epoch [5/50] - Loss: 0.3260
Epoch [6/50] - Loss: 0.2789
Epoch [7/50] - Loss: 0.2346
Epoch [8/50] - Loss: 0.1938
Epoch [9/50] - Loss: 0.1571
Epoch [10/50] - Loss: 0.1247
Epoch [11/50] - Loss: 0.0965
Epoch [12/50] - Loss: 0.0724
Epoch [13/50] - Loss: 0.0517
Epoch [14/50] - Loss: 0.0338
Epoch [15/50] - Loss: 0.0187
Epoch [16/50] - Loss: 0.0062
Epoch [17/50] - Loss: -0.0044
Epoch [18/50] - Loss: -0.0134
Epoch [19/50] - Loss: -0.0212
Epoch [20/50] - Loss: -0.0280
Epoch [21/50] - Loss: -0.0341
Epoch [22/50] - Loss: -0.0394
Epoch [23/50] - Loss: -0.0442
Epoch [24/50] - Loss: -0.0486
Epoch [25/50] - Loss: -0.0524
Epoch [26/50] - Loss: -0.0559
Epoch [27/50] - Loss: -0.0590
Epoch [28/50] - Loss: -0.0618
Epoch [29/50] - Loss: -0.0642
Epoch [30/50] - Loss: -0.0664
Epoch [31/50] - Loss: -0.0685
Epoch [32/50] - Loss: -0.0705
Epoch [33/50] - Loss: -0.0722
Epoch [34/50] - Loss: -0.0736
Epoch [35/50] - Loss: -0.0749
Epoch [36/50] - Loss: -0.0760
Epoch [37/50] - Loss: -0.0771
Epoch [38/50] - Loss: -0.0781
Epoch [39/50] - Loss: -0.0792
Epoch [40/50] - Loss: -0.0803
Epoch [41/50] - Loss: -0.0812
Epoch [42/50] - Loss: -0.0821
Epoch [43/50] - Loss: -0.0830
Epoch [44/50] - Loss: -0.0839
Epoch [45/50] - Loss: -0.0845
Epoch [46/50] - Loss: -0.0850
Epoch [47/50] - Loss: -0.0855
Epoch [48/50] - Loss: -0.0859
Epoch [49/50] - Loss: -0.0863
Epoch [50/50] - Loss: -0.0867
sum preds 197
sum labels 561
 - Test Metrics: Accuracy=0.8544, F1=0.3879, Recall=0.2620, Precision=0.7462
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_imbnnpu_imbnnpu_1804084642.csv.
Average F1 over valid seeds: 0.4251 ± 0.0385
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and imbnnpu, GATConv,0.2: 0.4251 ± 0.0385
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5022
Epoch [2/50] - Loss: 0.4639
Epoch [3/50] - Loss: 0.4159
Epoch [4/50] - Loss: 0.3594
Epoch [5/50] - Loss: 0.3058
Epoch [6/50] - Loss: 0.2574
Epoch [7/50] - Loss: 0.2141
Epoch [8/50] - Loss: 0.1762
Epoch [9/50] - Loss: 0.1446
Epoch [10/50] - Loss: 0.1185
Epoch [11/50] - Loss: 0.0969
Epoch [12/50] - Loss: 0.0788
Epoch [13/50] - Loss: 0.0635
Epoch [14/50] - Loss: 0.0507
Epoch [15/50] - Loss: 0.0399
Epoch [16/50] - Loss: 0.0307
Epoch [17/50] - Loss: 0.0228
Epoch [18/50] - Loss: 0.0160
Epoch [19/50] - Loss: 0.0100
Epoch [20/50] - Loss: 0.0047
Epoch [21/50] - Loss: -0.0000
Epoch [22/50] - Loss: -0.0043
Epoch [23/50] - Loss: -0.0080
Epoch [24/50] - Loss: -0.0114
Epoch [25/50] - Loss: -0.0145
Epoch [26/50] - Loss: -0.0172
Epoch [27/50] - Loss: -0.0197
Epoch [28/50] - Loss: -0.0219
Epoch [29/50] - Loss: -0.0240
Epoch [30/50] - Loss: -0.0259
Epoch [31/50] - Loss: -0.0277
Epoch [32/50] - Loss: -0.0295
Epoch [33/50] - Loss: -0.0312
Epoch [34/50] - Loss: -0.0330
Epoch [35/50] - Loss: -0.0348
Epoch [36/50] - Loss: -0.0366
Epoch [37/50] - Loss: -0.0383
Epoch [38/50] - Loss: -0.0400
Epoch [39/50] - Loss: -0.0414
Epoch [40/50] - Loss: -0.0428
Epoch [41/50] - Loss: -0.0440
Epoch [42/50] - Loss: -0.0452
Epoch [43/50] - Loss: -0.0462
Epoch [44/50] - Loss: -0.0472
Epoch [45/50] - Loss: -0.0482
Epoch [46/50] - Loss: -0.0490
Epoch [47/50] - Loss: -0.0498
Epoch [48/50] - Loss: -0.0506
Epoch [49/50] - Loss: -0.0514
Epoch [50/50] - Loss: -0.0522
sum preds 268
sum labels 561
 - Test Metrics: Accuracy=0.8773, F1=0.5283, Recall=0.3904, Precision=0.8172
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5011
Epoch [2/50] - Loss: 0.4662
Epoch [3/50] - Loss: 0.4203
Epoch [4/50] - Loss: 0.3667
Epoch [5/50] - Loss: 0.3146
Epoch [6/50] - Loss: 0.2674
Epoch [7/50] - Loss: 0.2256
Epoch [8/50] - Loss: 0.1890
Epoch [9/50] - Loss: 0.1572
Epoch [10/50] - Loss: 0.1301
Epoch [11/50] - Loss: 0.1073
Epoch [12/50] - Loss: 0.0881
Epoch [13/50] - Loss: 0.0721
Epoch [14/50] - Loss: 0.0587
Epoch [15/50] - Loss: 0.0473
Epoch [16/50] - Loss: 0.0377
Epoch [17/50] - Loss: 0.0294
Epoch [18/50] - Loss: 0.0221
Epoch [19/50] - Loss: 0.0158
Epoch [20/50] - Loss: 0.0101
Epoch [21/50] - Loss: 0.0051
Epoch [22/50] - Loss: 0.0005
Epoch [23/50] - Loss: -0.0037
Epoch [24/50] - Loss: -0.0076
Epoch [25/50] - Loss: -0.0112
Epoch [26/50] - Loss: -0.0145
Epoch [27/50] - Loss: -0.0177
Epoch [28/50] - Loss: -0.0207
Epoch [29/50] - Loss: -0.0236
Epoch [30/50] - Loss: -0.0264
Epoch [31/50] - Loss: -0.0291
Epoch [32/50] - Loss: -0.0317
Epoch [33/50] - Loss: -0.0341
Epoch [34/50] - Loss: -0.0364
Epoch [35/50] - Loss: -0.0385
Epoch [36/50] - Loss: -0.0405
Epoch [37/50] - Loss: -0.0424
Epoch [38/50] - Loss: -0.0441
Epoch [39/50] - Loss: -0.0458
Epoch [40/50] - Loss: -0.0473
Epoch [41/50] - Loss: -0.0486
Epoch [42/50] - Loss: -0.0498
Epoch [43/50] - Loss: -0.0509
Epoch [44/50] - Loss: -0.0519
Epoch [45/50] - Loss: -0.0529
Epoch [46/50] - Loss: -0.0537
Epoch [47/50] - Loss: -0.0546
Epoch [48/50] - Loss: -0.0553
Epoch [49/50] - Loss: -0.0561
Epoch [50/50] - Loss: -0.0568
sum preds 290
sum labels 561
 - Test Metrics: Accuracy=0.8842, F1=0.5664, Recall=0.4296, Precision=0.8310
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4974
Epoch [2/50] - Loss: 0.4606
Epoch [3/50] - Loss: 0.4152
Epoch [4/50] - Loss: 0.3642
Epoch [5/50] - Loss: 0.3154
Epoch [6/50] - Loss: 0.2701
Epoch [7/50] - Loss: 0.2285
Epoch [8/50] - Loss: 0.1914
Epoch [9/50] - Loss: 0.1590
Epoch [10/50] - Loss: 0.1312
Epoch [11/50] - Loss: 0.1074
Epoch [12/50] - Loss: 0.0873
Epoch [13/50] - Loss: 0.0701
Epoch [14/50] - Loss: 0.0554
Epoch [15/50] - Loss: 0.0428
Epoch [16/50] - Loss: 0.0319
Epoch [17/50] - Loss: 0.0224
Epoch [18/50] - Loss: 0.0142
Epoch [19/50] - Loss: 0.0069
Epoch [20/50] - Loss: 0.0006
Epoch [21/50] - Loss: -0.0051
Epoch [22/50] - Loss: -0.0101
Epoch [23/50] - Loss: -0.0145
Epoch [24/50] - Loss: -0.0184
Epoch [25/50] - Loss: -0.0220
Epoch [26/50] - Loss: -0.0252
Epoch [27/50] - Loss: -0.0281
Epoch [28/50] - Loss: -0.0307
Epoch [29/50] - Loss: -0.0331
Epoch [30/50] - Loss: -0.0353
Epoch [31/50] - Loss: -0.0374
Epoch [32/50] - Loss: -0.0393
Epoch [33/50] - Loss: -0.0410
Epoch [34/50] - Loss: -0.0426
Epoch [35/50] - Loss: -0.0441
Epoch [36/50] - Loss: -0.0455
Epoch [37/50] - Loss: -0.0469
Epoch [38/50] - Loss: -0.0482
Epoch [39/50] - Loss: -0.0495
Epoch [40/50] - Loss: -0.0507
Epoch [41/50] - Loss: -0.0519
Epoch [42/50] - Loss: -0.0531
Epoch [43/50] - Loss: -0.0542
Epoch [44/50] - Loss: -0.0554
Epoch [45/50] - Loss: -0.0565
Epoch [46/50] - Loss: -0.0576
Epoch [47/50] - Loss: -0.0587
Epoch [48/50] - Loss: -0.0597
Epoch [49/50] - Loss: -0.0608
Epoch [50/50] - Loss: -0.0618
sum preds 257
sum labels 561
 - Test Metrics: Accuracy=0.8745, F1=0.5110, Recall=0.3725, Precision=0.8132
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_imbnnpu_imbnnpu_1804084645.csv.
Average F1 over valid seeds: 0.5352 ± 0.0231
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and imbnnpu, GCNConv,0.2: 0.5352 ± 0.0231
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 5.9000
Epoch 10 / 50, Loss: 5.3871
Epoch 20 / 50, Loss: 5.1375
Epoch 30 / 50, Loss: 5.0879
Epoch 40 / 50, Loss: 4.6889
sum preds 149.0
sum labels 421
 - Test Metrics: Accuracy=0.9048, F1=0.4912, Recall=0.3325, Precision=0.9396
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.2496
Epoch 10 / 50, Loss: 5.7961
Epoch 20 / 50, Loss: 5.5335
Epoch 30 / 50, Loss: 5.4323
Epoch 40 / 50, Loss: 4.9799
sum preds 133.0
sum labels 421
 - Test Metrics: Accuracy=0.8976, F1=0.4368, Recall=0.2874, Precision=0.9098
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.0700
Epoch 10 / 50, Loss: 5.6316
Epoch 20 / 50, Loss: 5.5659
Epoch 30 / 50, Loss: 5.2298
Epoch 40 / 50, Loss: 5.0377
sum preds 155.0
sum labels 421
 - Test Metrics: Accuracy=0.8983, F1=0.4618, Recall=0.3159, Precision=0.8581
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_ours_1804084647.csv.
Average F1 over valid seeds: 0.4633 ± 0.0222
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and ours, GATConv,0.4: 0.4633 ± 0.0222
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.6696
Epoch 10 / 50, Loss: 6.2215
Epoch 20 / 50, Loss: 5.9373
Epoch 30 / 50, Loss: 5.8525
Epoch 40 / 50, Loss: 5.4527
sum preds 181.0
sum labels 491
 - Test Metrics: Accuracy=0.8896, F1=0.4881, Recall=0.3340, Precision=0.9061
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.1306
Epoch 10 / 50, Loss: 6.6947
Epoch 20 / 50, Loss: 6.4156
Epoch 30 / 50, Loss: 6.1083
Epoch 40 / 50, Loss: 5.7348
sum preds 186.0
sum labels 491
 - Test Metrics: Accuracy=0.8906, F1=0.4963, Recall=0.3422, Precision=0.9032
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.6558
Epoch 10 / 50, Loss: 6.3890
Epoch 20 / 50, Loss: 6.2508
Epoch 30 / 50, Loss: 5.8242
Epoch 40 / 50, Loss: 5.5084
sum preds 189.0
sum labels 491
 - Test Metrics: Accuracy=0.8916, F1=0.5029, Recall=0.3483, Precision=0.9048
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_ours_1804084738.csv.
Average F1 over valid seeds: 0.4958 ± 0.0061
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and ours, GATConv,0.3: 0.4958 ± 0.0061
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.5371
Epoch 10 / 50, Loss: 7.0250
Epoch 20 / 50, Loss: 6.8136
Epoch 30 / 50, Loss: 6.5761
Epoch 40 / 50, Loss: 6.1507
sum preds 169.0
sum labels 561
 - Test Metrics: Accuracy=0.8670, F1=0.4192, Recall=0.2727, Precision=0.9053
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.3832
Epoch 10 / 50, Loss: 7.1448
Epoch 20 / 50, Loss: 6.7529
Epoch 30 / 50, Loss: 6.4330
Epoch 40 / 50, Loss: 5.9719
sum preds 213.0
sum labels 561
 - Test Metrics: Accuracy=0.8808, F1=0.5090, Recall=0.3512, Precision=0.9249
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.4559
Epoch 10 / 50, Loss: 7.0924
Epoch 20 / 50, Loss: 6.9014
Epoch 30 / 50, Loss: 6.3095
Epoch 40 / 50, Loss: 6.1110
sum preds 184.0
sum labels 561
 - Test Metrics: Accuracy=0.8704, F1=0.4456, Recall=0.2959, Precision=0.9022
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SCAR_ours_1804084827.csv.
Average F1 over valid seeds: 0.4580 ± 0.0377
___________________________________________________________________________________
Avg F1 for citeseer with SCAR and ours, GATConv,0.2: 0.4580 ± 0.0377
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1095
Epoch [2/50] - Loss: 0.8796
Epoch [3/50] - Loss: 0.7009
Epoch [4/50] - Loss: 0.5881
Epoch [5/50] - Loss: 0.5382
Epoch [6/50] - Loss: 0.5238
Epoch [7/50] - Loss: 0.5036
Epoch [8/50] - Loss: 0.4837
Epoch [9/50] - Loss: 0.4554
Epoch [10/50] - Loss: 0.4136
Epoch [11/50] - Loss: 0.3798
Epoch [12/50] - Loss: 0.3540
Epoch [13/50] - Loss: 0.3413
Epoch [14/50] - Loss: 0.3244
Epoch [15/50] - Loss: 0.3145
Epoch [16/50] - Loss: 0.3023
Epoch [17/50] - Loss: 0.2889
Epoch [18/50] - Loss: 0.2768
Epoch [19/50] - Loss: 0.2582
Epoch [20/50] - Loss: 0.2525
Epoch [21/50] - Loss: 0.2361
Epoch [22/50] - Loss: 0.2293
Epoch [23/50] - Loss: 0.2210
Epoch [24/50] - Loss: 0.2113
Epoch [25/50] - Loss: 0.2076
Epoch [26/50] - Loss: 0.1964
Epoch [27/50] - Loss: 0.1958
Epoch [28/50] - Loss: 0.1921
Epoch [29/50] - Loss: 0.1879
Epoch [30/50] - Loss: 0.1820
Epoch [31/50] - Loss: 0.1798
Epoch [32/50] - Loss: 0.1765
Epoch [33/50] - Loss: 0.1725
Epoch [34/50] - Loss: 0.1692
Epoch [35/50] - Loss: 0.1660
Epoch [36/50] - Loss: 0.1679
Epoch [37/50] - Loss: 0.1641
Epoch [38/50] - Loss: 0.1613
Epoch [39/50] - Loss: 0.1591
Epoch [40/50] - Loss: 0.1575
Epoch [41/50] - Loss: 0.1603
Epoch [42/50] - Loss: 0.1544
Epoch [43/50] - Loss: 0.1562
Epoch [44/50] - Loss: 0.1521
Epoch [45/50] - Loss: 0.1489
Epoch [46/50] - Loss: 0.1516
Epoch [47/50] - Loss: 0.1487
Epoch [48/50] - Loss: 0.1493
Epoch [49/50] - Loss: 0.1432
Epoch [50/50] - Loss: 0.1415
sum preds 2
sum labels 421
 - Test Metrics: Accuracy=0.8625, F1=0.0095, Recall=0.0048, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4030
Epoch [2/50] - Loss: 1.0028
Epoch [3/50] - Loss: 0.7278
Epoch [4/50] - Loss: 0.5894
Epoch [5/50] - Loss: 0.5541
Epoch [6/50] - Loss: 0.5373
Epoch [7/50] - Loss: 0.5354
Epoch [8/50] - Loss: 0.5137
Epoch [9/50] - Loss: 0.4854
Epoch [10/50] - Loss: 0.4463
Epoch [11/50] - Loss: 0.4123
Epoch [12/50] - Loss: 0.3724
Epoch [13/50] - Loss: 0.3490
Epoch [14/50] - Loss: 0.3333
Epoch [15/50] - Loss: 0.3249
Epoch [16/50] - Loss: 0.3178
Epoch [17/50] - Loss: 0.3033
Epoch [18/50] - Loss: 0.2903
Epoch [19/50] - Loss: 0.2794
Epoch [20/50] - Loss: 0.2616
Epoch [21/50] - Loss: 0.2482
Epoch [22/50] - Loss: 0.2383
Epoch [23/50] - Loss: 0.2240
Epoch [24/50] - Loss: 0.2186
Epoch [25/50] - Loss: 0.2060
Epoch [26/50] - Loss: 0.1966
Epoch [27/50] - Loss: 0.1907
Epoch [28/50] - Loss: 0.1832
Epoch [29/50] - Loss: 0.1756
Epoch [30/50] - Loss: 0.1668
Epoch [31/50] - Loss: 0.1635
Epoch [32/50] - Loss: 0.1616
Epoch [33/50] - Loss: 0.1568
Epoch [34/50] - Loss: 0.1507
Epoch [35/50] - Loss: 0.1488
Epoch [36/50] - Loss: 0.1449
Epoch [37/50] - Loss: 0.1435
Epoch [38/50] - Loss: 0.1409
Epoch [39/50] - Loss: 0.1362
Epoch [40/50] - Loss: 0.1342
Epoch [41/50] - Loss: 0.1351
Epoch [42/50] - Loss: 0.1310
Epoch [43/50] - Loss: 0.1280
Epoch [44/50] - Loss: 0.1295
Epoch [45/50] - Loss: 0.1260
Epoch [46/50] - Loss: 0.1239
Epoch [47/50] - Loss: 0.1228
Epoch [48/50] - Loss: 0.1219
Epoch [49/50] - Loss: 0.1211
Epoch [50/50] - Loss: 0.1215
sum preds 6
sum labels 421
 - Test Metrics: Accuracy=0.8638, F1=0.0281, Recall=0.0143, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3639
Epoch [2/50] - Loss: 1.0149
Epoch [3/50] - Loss: 0.7510
Epoch [4/50] - Loss: 0.6042
Epoch [5/50] - Loss: 0.5496
Epoch [6/50] - Loss: 0.5417
Epoch [7/50] - Loss: 0.5243
Epoch [8/50] - Loss: 0.4976
Epoch [9/50] - Loss: 0.4756
Epoch [10/50] - Loss: 0.4454
Epoch [11/50] - Loss: 0.3986
Epoch [12/50] - Loss: 0.3601
Epoch [13/50] - Loss: 0.3425
Epoch [14/50] - Loss: 0.3272
Epoch [15/50] - Loss: 0.3148
Epoch [16/50] - Loss: 0.3039
Epoch [17/50] - Loss: 0.2914
Epoch [18/50] - Loss: 0.2839
Epoch [19/50] - Loss: 0.2656
Epoch [20/50] - Loss: 0.2519
Epoch [21/50] - Loss: 0.2364
Epoch [22/50] - Loss: 0.2247
Epoch [23/50] - Loss: 0.2162
Epoch [24/50] - Loss: 0.2081
Epoch [25/50] - Loss: 0.1925
Epoch [26/50] - Loss: 0.1909
Epoch [27/50] - Loss: 0.1832
Epoch [28/50] - Loss: 0.1747
Epoch [29/50] - Loss: 0.1691
Epoch [30/50] - Loss: 0.1673
Epoch [31/50] - Loss: 0.1606
Epoch [32/50] - Loss: 0.1562
Epoch [33/50] - Loss: 0.1521
Epoch [34/50] - Loss: 0.1481
Epoch [35/50] - Loss: 0.1482
Epoch [36/50] - Loss: 0.1413
Epoch [37/50] - Loss: 0.1420
Epoch [38/50] - Loss: 0.1375
Epoch [39/50] - Loss: 0.1381
Epoch [40/50] - Loss: 0.1348
Epoch [41/50] - Loss: 0.1342
Epoch [42/50] - Loss: 0.1321
Epoch [43/50] - Loss: 0.1326
Epoch [44/50] - Loss: 0.1290
Epoch [45/50] - Loss: 0.1242
Epoch [46/50] - Loss: 0.1282
Epoch [47/50] - Loss: 0.1280
Epoch [48/50] - Loss: 0.1232
Epoch [49/50] - Loss: 0.1223
Epoch [50/50] - Loss: 0.1228
sum preds 8
sum labels 421
 - Test Metrics: Accuracy=0.8645, F1=0.0373, Recall=0.0190, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_naive_naive_1804084914.csv.
Average F1 over valid seeds: 0.0250 ± 0.0116
___________________________________________________________________________________
Avg F1 for citeseer with SAR and naive, MLP,0.4: 0.0250 ± 0.0116
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2391
Epoch [2/50] - Loss: 0.7409
Epoch [3/50] - Loss: 0.5726
Epoch [4/50] - Loss: 0.5383
Epoch [5/50] - Loss: 0.5402
Epoch [6/50] - Loss: 0.5239
Epoch [7/50] - Loss: 0.4944
Epoch [8/50] - Loss: 0.4417
Epoch [9/50] - Loss: 0.4043
Epoch [10/50] - Loss: 0.3764
Epoch [11/50] - Loss: 0.3619
Epoch [12/50] - Loss: 0.3594
Epoch [13/50] - Loss: 0.3544
Epoch [14/50] - Loss: 0.3441
Epoch [15/50] - Loss: 0.3336
Epoch [16/50] - Loss: 0.3210
Epoch [17/50] - Loss: 0.3100
Epoch [18/50] - Loss: 0.3030
Epoch [19/50] - Loss: 0.2953
Epoch [20/50] - Loss: 0.2849
Epoch [21/50] - Loss: 0.2880
Epoch [22/50] - Loss: 0.2772
Epoch [23/50] - Loss: 0.2754
Epoch [24/50] - Loss: 0.2635
Epoch [25/50] - Loss: 0.2566
Epoch [26/50] - Loss: 0.2600
Epoch [27/50] - Loss: 0.2490
Epoch [28/50] - Loss: 0.2465
Epoch [29/50] - Loss: 0.2422
Epoch [30/50] - Loss: 0.2377
Epoch [31/50] - Loss: 0.2335
Epoch [32/50] - Loss: 0.2276
Epoch [33/50] - Loss: 0.2310
Epoch [34/50] - Loss: 0.2285
Epoch [35/50] - Loss: 0.2223
Epoch [36/50] - Loss: 0.2256
Epoch [37/50] - Loss: 0.2277
Epoch [38/50] - Loss: 0.2225
Epoch [39/50] - Loss: 0.2128
Epoch [40/50] - Loss: 0.2183
Epoch [41/50] - Loss: 0.2195
Epoch [42/50] - Loss: 0.2133
Epoch [43/50] - Loss: 0.2099
Epoch [44/50] - Loss: 0.2115
Epoch [45/50] - Loss: 0.2088
Epoch [46/50] - Loss: 0.2120
Epoch [47/50] - Loss: 0.2093
Epoch [48/50] - Loss: 0.2097
Epoch [49/50] - Loss: 0.2064
Epoch [50/50] - Loss: 0.2059
sum preds 63
sum labels 421
 - Test Metrics: Accuracy=0.8773, F1=0.2273, Recall=0.1306, Precision=0.8730
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1496
Epoch [2/50] - Loss: 0.6301
Epoch [3/50] - Loss: 0.5425
Epoch [4/50] - Loss: 0.5446
Epoch [5/50] - Loss: 0.5213
Epoch [6/50] - Loss: 0.4656
Epoch [7/50] - Loss: 0.3993
Epoch [8/50] - Loss: 0.3704
Epoch [9/50] - Loss: 0.3501
Epoch [10/50] - Loss: 0.3487
Epoch [11/50] - Loss: 0.3475
Epoch [12/50] - Loss: 0.3382
Epoch [13/50] - Loss: 0.3325
Epoch [14/50] - Loss: 0.3174
Epoch [15/50] - Loss: 0.3060
Epoch [16/50] - Loss: 0.2974
Epoch [17/50] - Loss: 0.2883
Epoch [18/50] - Loss: 0.2857
Epoch [19/50] - Loss: 0.2772
Epoch [20/50] - Loss: 0.2698
Epoch [21/50] - Loss: 0.2639
Epoch [22/50] - Loss: 0.2552
Epoch [23/50] - Loss: 0.2462
Epoch [24/50] - Loss: 0.2423
Epoch [25/50] - Loss: 0.2370
Epoch [26/50] - Loss: 0.2291
Epoch [27/50] - Loss: 0.2250
Epoch [28/50] - Loss: 0.2233
Epoch [29/50] - Loss: 0.2131
Epoch [30/50] - Loss: 0.2129
Epoch [31/50] - Loss: 0.2113
Epoch [32/50] - Loss: 0.2065
Epoch [33/50] - Loss: 0.2009
Epoch [34/50] - Loss: 0.1971
Epoch [35/50] - Loss: 0.1974
Epoch [36/50] - Loss: 0.1893
Epoch [37/50] - Loss: 0.1929
Epoch [38/50] - Loss: 0.1895
Epoch [39/50] - Loss: 0.1872
Epoch [40/50] - Loss: 0.1831
Epoch [41/50] - Loss: 0.1858
Epoch [42/50] - Loss: 0.1803
Epoch [43/50] - Loss: 0.1791
Epoch [44/50] - Loss: 0.1790
Epoch [45/50] - Loss: 0.1744
Epoch [46/50] - Loss: 0.1707
Epoch [47/50] - Loss: 0.1751
Epoch [48/50] - Loss: 0.1725
Epoch [49/50] - Loss: 0.1659
Epoch [50/50] - Loss: 0.1661
sum preds 61
sum labels 421
 - Test Metrics: Accuracy=0.8727, F1=0.1950, Recall=0.1116, Precision=0.7705
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1907
Epoch [2/50] - Loss: 0.6828
Epoch [3/50] - Loss: 0.5434
Epoch [4/50] - Loss: 0.5512
Epoch [5/50] - Loss: 0.5349
Epoch [6/50] - Loss: 0.4813
Epoch [7/50] - Loss: 0.4354
Epoch [8/50] - Loss: 0.3904
Epoch [9/50] - Loss: 0.3658
Epoch [10/50] - Loss: 0.3593
Epoch [11/50] - Loss: 0.3586
Epoch [12/50] - Loss: 0.3509
Epoch [13/50] - Loss: 0.3450
Epoch [14/50] - Loss: 0.3325
Epoch [15/50] - Loss: 0.3244
Epoch [16/50] - Loss: 0.3105
Epoch [17/50] - Loss: 0.3097
Epoch [18/50] - Loss: 0.3011
Epoch [19/50] - Loss: 0.2958
Epoch [20/50] - Loss: 0.2908
Epoch [21/50] - Loss: 0.2866
Epoch [22/50] - Loss: 0.2834
Epoch [23/50] - Loss: 0.2749
Epoch [24/50] - Loss: 0.2696
Epoch [25/50] - Loss: 0.2668
Epoch [26/50] - Loss: 0.2641
Epoch [27/50] - Loss: 0.2592
Epoch [28/50] - Loss: 0.2536
Epoch [29/50] - Loss: 0.2558
Epoch [30/50] - Loss: 0.2519
Epoch [31/50] - Loss: 0.2476
Epoch [32/50] - Loss: 0.2423
Epoch [33/50] - Loss: 0.2436
Epoch [34/50] - Loss: 0.2372
Epoch [35/50] - Loss: 0.2318
Epoch [36/50] - Loss: 0.2341
Epoch [37/50] - Loss: 0.2261
Epoch [38/50] - Loss: 0.2225
Epoch [39/50] - Loss: 0.2212
Epoch [40/50] - Loss: 0.2195
Epoch [41/50] - Loss: 0.2137
Epoch [42/50] - Loss: 0.2156
Epoch [43/50] - Loss: 0.2198
Epoch [44/50] - Loss: 0.2065
Epoch [45/50] - Loss: 0.2065
Epoch [46/50] - Loss: 0.2073
Epoch [47/50] - Loss: 0.2007
Epoch [48/50] - Loss: 0.1970
Epoch [49/50] - Loss: 0.2002
Epoch [50/50] - Loss: 0.1874
sum preds 63
sum labels 421
 - Test Metrics: Accuracy=0.8713, F1=0.1901, Recall=0.1093, Precision=0.7302
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_naive_naive_1804085014.csv.
Average F1 over valid seeds: 0.2041 ± 0.0165
___________________________________________________________________________________
Avg F1 for citeseer with SAR and naive, GATConv,0.4: 0.2041 ± 0.0165
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2149
Epoch [2/50] - Loss: 0.7288
Epoch [3/50] - Loss: 0.5808
Epoch [4/50] - Loss: 0.5520
Epoch [5/50] - Loss: 0.5589
Epoch [6/50] - Loss: 0.5291
Epoch [7/50] - Loss: 0.4761
Epoch [8/50] - Loss: 0.4393
Epoch [9/50] - Loss: 0.4058
Epoch [10/50] - Loss: 0.3849
Epoch [11/50] - Loss: 0.3694
Epoch [12/50] - Loss: 0.3668
Epoch [13/50] - Loss: 0.3618
Epoch [14/50] - Loss: 0.3546
Epoch [15/50] - Loss: 0.3520
Epoch [16/50] - Loss: 0.3412
Epoch [17/50] - Loss: 0.3258
Epoch [18/50] - Loss: 0.3195
Epoch [19/50] - Loss: 0.3118
Epoch [20/50] - Loss: 0.3117
Epoch [21/50] - Loss: 0.3148
Epoch [22/50] - Loss: 0.3095
Epoch [23/50] - Loss: 0.2985
Epoch [24/50] - Loss: 0.2946
Epoch [25/50] - Loss: 0.2897
Epoch [26/50] - Loss: 0.2874
Epoch [27/50] - Loss: 0.2875
Epoch [28/50] - Loss: 0.2849
Epoch [29/50] - Loss: 0.2806
Epoch [30/50] - Loss: 0.2784
Epoch [31/50] - Loss: 0.2750
Epoch [32/50] - Loss: 0.2724
Epoch [33/50] - Loss: 0.2768
Epoch [34/50] - Loss: 0.2712
Epoch [35/50] - Loss: 0.2674
Epoch [36/50] - Loss: 0.2610
Epoch [37/50] - Loss: 0.2643
Epoch [38/50] - Loss: 0.2632
Epoch [39/50] - Loss: 0.2639
Epoch [40/50] - Loss: 0.2619
Epoch [41/50] - Loss: 0.2585
Epoch [42/50] - Loss: 0.2555
Epoch [43/50] - Loss: 0.2584
Epoch [44/50] - Loss: 0.2516
Epoch [45/50] - Loss: 0.2529
Epoch [46/50] - Loss: 0.2523
Epoch [47/50] - Loss: 0.2518
Epoch [48/50] - Loss: 0.2484
Epoch [49/50] - Loss: 0.2509
Epoch [50/50] - Loss: 0.2474
sum preds 0
sum labels 421
 - Test Metrics: Accuracy=0.8618, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1063
Epoch [2/50] - Loss: 0.6082
Epoch [3/50] - Loss: 0.5652
Epoch [4/50] - Loss: 0.5471
Epoch [5/50] - Loss: 0.4913
Epoch [6/50] - Loss: 0.4324
Epoch [7/50] - Loss: 0.3852
Epoch [8/50] - Loss: 0.3607
Epoch [9/50] - Loss: 0.3583
Epoch [10/50] - Loss: 0.3569
Epoch [11/50] - Loss: 0.3476
Epoch [12/50] - Loss: 0.3405
Epoch [13/50] - Loss: 0.3283
Epoch [14/50] - Loss: 0.3204
Epoch [15/50] - Loss: 0.3124
Epoch [16/50] - Loss: 0.3076
Epoch [17/50] - Loss: 0.3009
Epoch [18/50] - Loss: 0.2996
Epoch [19/50] - Loss: 0.2960
Epoch [20/50] - Loss: 0.2891
Epoch [21/50] - Loss: 0.2854
Epoch [22/50] - Loss: 0.2851
Epoch [23/50] - Loss: 0.2808
Epoch [24/50] - Loss: 0.2757
Epoch [25/50] - Loss: 0.2771
Epoch [26/50] - Loss: 0.2724
Epoch [27/50] - Loss: 0.2679
Epoch [28/50] - Loss: 0.2695
Epoch [29/50] - Loss: 0.2651
Epoch [30/50] - Loss: 0.2651
Epoch [31/50] - Loss: 0.2608
Epoch [32/50] - Loss: 0.2568
Epoch [33/50] - Loss: 0.2568
Epoch [34/50] - Loss: 0.2527
Epoch [35/50] - Loss: 0.2501
Epoch [36/50] - Loss: 0.2525
Epoch [37/50] - Loss: 0.2473
Epoch [38/50] - Loss: 0.2535
Epoch [39/50] - Loss: 0.2500
Epoch [40/50] - Loss: 0.2420
Epoch [41/50] - Loss: 0.2442
Epoch [42/50] - Loss: 0.2462
Epoch [43/50] - Loss: 0.2407
Epoch [44/50] - Loss: 0.2389
Epoch [45/50] - Loss: 0.2400
Epoch [46/50] - Loss: 0.2383
Epoch [47/50] - Loss: 0.2351
Epoch [48/50] - Loss: 0.2371
Epoch [49/50] - Loss: 0.2368
Epoch [50/50] - Loss: 0.2399
sum preds 32
sum labels 421
 - Test Metrics: Accuracy=0.8697, F1=0.1236, Recall=0.0665, Precision=0.8750
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1047
Epoch [2/50] - Loss: 0.5945
Epoch [3/50] - Loss: 0.5828
Epoch [4/50] - Loss: 0.5476
Epoch [5/50] - Loss: 0.4896
Epoch [6/50] - Loss: 0.4274
Epoch [7/50] - Loss: 0.3868
Epoch [8/50] - Loss: 0.3621
Epoch [9/50] - Loss: 0.3626
Epoch [10/50] - Loss: 0.3678
Epoch [11/50] - Loss: 0.3593
Epoch [12/50] - Loss: 0.3442
Epoch [13/50] - Loss: 0.3354
Epoch [14/50] - Loss: 0.3241
Epoch [15/50] - Loss: 0.3155
Epoch [16/50] - Loss: 0.3146
Epoch [17/50] - Loss: 0.3056
Epoch [18/50] - Loss: 0.3035
Epoch [19/50] - Loss: 0.2996
Epoch [20/50] - Loss: 0.2954
Epoch [21/50] - Loss: 0.2871
Epoch [22/50] - Loss: 0.2884
Epoch [23/50] - Loss: 0.2826
Epoch [24/50] - Loss: 0.2754
Epoch [25/50] - Loss: 0.2776
Epoch [26/50] - Loss: 0.2771
Epoch [27/50] - Loss: 0.2724
Epoch [28/50] - Loss: 0.2675
Epoch [29/50] - Loss: 0.2662
Epoch [30/50] - Loss: 0.2644
Epoch [31/50] - Loss: 0.2628
Epoch [32/50] - Loss: 0.2621
Epoch [33/50] - Loss: 0.2575
Epoch [34/50] - Loss: 0.2574
Epoch [35/50] - Loss: 0.2568
Epoch [36/50] - Loss: 0.2565
Epoch [37/50] - Loss: 0.2543
Epoch [38/50] - Loss: 0.2528
Epoch [39/50] - Loss: 0.2482
Epoch [40/50] - Loss: 0.2486
Epoch [41/50] - Loss: 0.2507
Epoch [42/50] - Loss: 0.2568
Epoch [43/50] - Loss: 0.2499
Epoch [44/50] - Loss: 0.2473
Epoch [45/50] - Loss: 0.2453
Epoch [46/50] - Loss: 0.2426
Epoch [47/50] - Loss: 0.2456
Epoch [48/50] - Loss: 0.2466
Epoch [49/50] - Loss: 0.2383
Epoch [50/50] - Loss: 0.2395
sum preds 36
sum labels 421
 - Test Metrics: Accuracy=0.8691, F1=0.1269, Recall=0.0689, Precision=0.8056
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_naive_naive_1804085112.csv.
Average F1 over valid seeds: 0.0835 ± 0.0591
___________________________________________________________________________________
Avg F1 for citeseer with SAR and naive, GCNConv,0.4: 0.0835 ± 0.0591
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0944
Epoch [2/50] - Loss: 0.8477
Epoch [3/50] - Loss: 0.6501
Epoch [4/50] - Loss: 0.5191
Epoch [5/50] - Loss: 0.4534
Epoch [6/50] - Loss: 0.4395
Epoch [7/50] - Loss: 0.4331
Epoch [8/50] - Loss: 0.4163
Epoch [9/50] - Loss: 0.4061
Epoch [10/50] - Loss: 0.3686
Epoch [11/50] - Loss: 0.3429
Epoch [12/50] - Loss: 0.3100
Epoch [13/50] - Loss: 0.2914
Epoch [14/50] - Loss: 0.2713
Epoch [15/50] - Loss: 0.2603
Epoch [16/50] - Loss: 0.2537
Epoch [17/50] - Loss: 0.2451
Epoch [18/50] - Loss: 0.2381
Epoch [19/50] - Loss: 0.2213
Epoch [20/50] - Loss: 0.2148
Epoch [21/50] - Loss: 0.1991
Epoch [22/50] - Loss: 0.1917
Epoch [23/50] - Loss: 0.1821
Epoch [24/50] - Loss: 0.1731
Epoch [25/50] - Loss: 0.1700
Epoch [26/50] - Loss: 0.1608
Epoch [27/50] - Loss: 0.1580
Epoch [28/50] - Loss: 0.1536
Epoch [29/50] - Loss: 0.1496
Epoch [30/50] - Loss: 0.1442
Epoch [31/50] - Loss: 0.1411
Epoch [32/50] - Loss: 0.1393
Epoch [33/50] - Loss: 0.1370
Epoch [34/50] - Loss: 0.1343
Epoch [35/50] - Loss: 0.1297
Epoch [36/50] - Loss: 0.1308
Epoch [37/50] - Loss: 0.1282
Epoch [38/50] - Loss: 0.1278
Epoch [39/50] - Loss: 0.1250
Epoch [40/50] - Loss: 0.1251
Epoch [41/50] - Loss: 0.1268
Epoch [42/50] - Loss: 0.1234
Epoch [43/50] - Loss: 0.1246
Epoch [44/50] - Loss: 0.1209
Epoch [45/50] - Loss: 0.1188
Epoch [46/50] - Loss: 0.1217
Epoch [47/50] - Loss: 0.1195
Epoch [48/50] - Loss: 0.1188
Epoch [49/50] - Loss: 0.1150
Epoch [50/50] - Loss: 0.1131
sum preds 0
sum labels 491
 - Test Metrics: Accuracy=0.8425, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4033
Epoch [2/50] - Loss: 0.9792
Epoch [3/50] - Loss: 0.6810
Epoch [4/50] - Loss: 0.5212
Epoch [5/50] - Loss: 0.4682
Epoch [6/50] - Loss: 0.4513
Epoch [7/50] - Loss: 0.4480
Epoch [8/50] - Loss: 0.4418
Epoch [9/50] - Loss: 0.4303
Epoch [10/50] - Loss: 0.4003
Epoch [11/50] - Loss: 0.3783
Epoch [12/50] - Loss: 0.3386
Epoch [13/50] - Loss: 0.3103
Epoch [14/50] - Loss: 0.2867
Epoch [15/50] - Loss: 0.2741
Epoch [16/50] - Loss: 0.2639
Epoch [17/50] - Loss: 0.2540
Epoch [18/50] - Loss: 0.2462
Epoch [19/50] - Loss: 0.2413
Epoch [20/50] - Loss: 0.2279
Epoch [21/50] - Loss: 0.2172
Epoch [22/50] - Loss: 0.2060
Epoch [23/50] - Loss: 0.1922
Epoch [24/50] - Loss: 0.1851
Epoch [25/50] - Loss: 0.1769
Epoch [26/50] - Loss: 0.1651
Epoch [27/50] - Loss: 0.1615
Epoch [28/50] - Loss: 0.1552
Epoch [29/50] - Loss: 0.1482
Epoch [30/50] - Loss: 0.1404
Epoch [31/50] - Loss: 0.1376
Epoch [32/50] - Loss: 0.1358
Epoch [33/50] - Loss: 0.1297
Epoch [34/50] - Loss: 0.1258
Epoch [35/50] - Loss: 0.1217
Epoch [36/50] - Loss: 0.1192
Epoch [37/50] - Loss: 0.1184
Epoch [38/50] - Loss: 0.1142
Epoch [39/50] - Loss: 0.1101
Epoch [40/50] - Loss: 0.1081
Epoch [41/50] - Loss: 0.1083
Epoch [42/50] - Loss: 0.1050
Epoch [43/50] - Loss: 0.1026
Epoch [44/50] - Loss: 0.1043
Epoch [45/50] - Loss: 0.1011
Epoch [46/50] - Loss: 0.1003
Epoch [47/50] - Loss: 0.0985
Epoch [48/50] - Loss: 0.0978
Epoch [49/50] - Loss: 0.0964
Epoch [50/50] - Loss: 0.0972
sum preds 3
sum labels 491
 - Test Metrics: Accuracy=0.8434, F1=0.0121, Recall=0.0061, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3627
Epoch [2/50] - Loss: 0.9944
Epoch [3/50] - Loss: 0.7067
Epoch [4/50] - Loss: 0.5384
Epoch [5/50] - Loss: 0.4658
Epoch [6/50] - Loss: 0.4525
Epoch [7/50] - Loss: 0.4424
Epoch [8/50] - Loss: 0.4361
Epoch [9/50] - Loss: 0.4273
Epoch [10/50] - Loss: 0.4053
Epoch [11/50] - Loss: 0.3689
Epoch [12/50] - Loss: 0.3298
Epoch [13/50] - Loss: 0.3047
Epoch [14/50] - Loss: 0.2829
Epoch [15/50] - Loss: 0.2672
Epoch [16/50] - Loss: 0.2551
Epoch [17/50] - Loss: 0.2473
Epoch [18/50] - Loss: 0.2437
Epoch [19/50] - Loss: 0.2320
Epoch [20/50] - Loss: 0.2223
Epoch [21/50] - Loss: 0.2090
Epoch [22/50] - Loss: 0.1953
Epoch [23/50] - Loss: 0.1846
Epoch [24/50] - Loss: 0.1756
Epoch [25/50] - Loss: 0.1592
Epoch [26/50] - Loss: 0.1610
Epoch [27/50] - Loss: 0.1516
Epoch [28/50] - Loss: 0.1448
Epoch [29/50] - Loss: 0.1382
Epoch [30/50] - Loss: 0.1341
Epoch [31/50] - Loss: 0.1291
Epoch [32/50] - Loss: 0.1251
Epoch [33/50] - Loss: 0.1223
Epoch [34/50] - Loss: 0.1181
Epoch [35/50] - Loss: 0.1179
Epoch [36/50] - Loss: 0.1114
Epoch [37/50] - Loss: 0.1123
Epoch [38/50] - Loss: 0.1077
Epoch [39/50] - Loss: 0.1079
Epoch [40/50] - Loss: 0.1046
Epoch [41/50] - Loss: 0.1044
Epoch [42/50] - Loss: 0.1018
Epoch [43/50] - Loss: 0.1026
Epoch [44/50] - Loss: 0.1001
Epoch [45/50] - Loss: 0.0962
Epoch [46/50] - Loss: 0.0990
Epoch [47/50] - Loss: 0.0986
Epoch [48/50] - Loss: 0.0955
Epoch [49/50] - Loss: 0.0947
Epoch [50/50] - Loss: 0.0952
sum preds 3
sum labels 491
 - Test Metrics: Accuracy=0.8434, F1=0.0121, Recall=0.0061, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_naive_naive_1804085211.csv.
Average F1 over valid seeds: 0.0081 ± 0.0057
___________________________________________________________________________________
Avg F1 for citeseer with SAR and naive, MLP,0.3: 0.0081 ± 0.0057
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2279
Epoch [2/50] - Loss: 0.6902
Epoch [3/50] - Loss: 0.4916
Epoch [4/50] - Loss: 0.4456
Epoch [5/50] - Loss: 0.4528
Epoch [6/50] - Loss: 0.4504
Epoch [7/50] - Loss: 0.4454
Epoch [8/50] - Loss: 0.4062
Epoch [9/50] - Loss: 0.3707
Epoch [10/50] - Loss: 0.3367
Epoch [11/50] - Loss: 0.3142
Epoch [12/50] - Loss: 0.2989
Epoch [13/50] - Loss: 0.2952
Epoch [14/50] - Loss: 0.2897
Epoch [15/50] - Loss: 0.2855
Epoch [16/50] - Loss: 0.2791
Epoch [17/50] - Loss: 0.2708
Epoch [18/50] - Loss: 0.2588
Epoch [19/50] - Loss: 0.2522
Epoch [20/50] - Loss: 0.2396
Epoch [21/50] - Loss: 0.2439
Epoch [22/50] - Loss: 0.2368
Epoch [23/50] - Loss: 0.2328
Epoch [24/50] - Loss: 0.2244
Epoch [25/50] - Loss: 0.2167
Epoch [26/50] - Loss: 0.2170
Epoch [27/50] - Loss: 0.2076
Epoch [28/50] - Loss: 0.2046
Epoch [29/50] - Loss: 0.2029
Epoch [30/50] - Loss: 0.1989
Epoch [31/50] - Loss: 0.1924
Epoch [32/50] - Loss: 0.1887
Epoch [33/50] - Loss: 0.1890
Epoch [34/50] - Loss: 0.1877
Epoch [35/50] - Loss: 0.1836
Epoch [36/50] - Loss: 0.1849
Epoch [37/50] - Loss: 0.1808
Epoch [38/50] - Loss: 0.1804
Epoch [39/50] - Loss: 0.1723
Epoch [40/50] - Loss: 0.1770
Epoch [41/50] - Loss: 0.1747
Epoch [42/50] - Loss: 0.1741
Epoch [43/50] - Loss: 0.1676
Epoch [44/50] - Loss: 0.1690
Epoch [45/50] - Loss: 0.1645
Epoch [46/50] - Loss: 0.1699
Epoch [47/50] - Loss: 0.1686
Epoch [48/50] - Loss: 0.1657
Epoch [49/50] - Loss: 0.1635
Epoch [50/50] - Loss: 0.1636
sum preds 11
sum labels 491
 - Test Metrics: Accuracy=0.8454, F1=0.0398, Recall=0.0204, Precision=0.9091
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1345
Epoch [2/50] - Loss: 0.5658
Epoch [3/50] - Loss: 0.4492
Epoch [4/50] - Loss: 0.4585
Epoch [5/50] - Loss: 0.4640
Epoch [6/50] - Loss: 0.4425
Epoch [7/50] - Loss: 0.3852
Epoch [8/50] - Loss: 0.3477
Epoch [9/50] - Loss: 0.3036
Epoch [10/50] - Loss: 0.2908
Epoch [11/50] - Loss: 0.2879
Epoch [12/50] - Loss: 0.2870
Epoch [13/50] - Loss: 0.2856
Epoch [14/50] - Loss: 0.2760
Epoch [15/50] - Loss: 0.2663
Epoch [16/50] - Loss: 0.2559
Epoch [17/50] - Loss: 0.2456
Epoch [18/50] - Loss: 0.2419
Epoch [19/50] - Loss: 0.2348
Epoch [20/50] - Loss: 0.2305
Epoch [21/50] - Loss: 0.2252
Epoch [22/50] - Loss: 0.2196
Epoch [23/50] - Loss: 0.2110
Epoch [24/50] - Loss: 0.2101
Epoch [25/50] - Loss: 0.2042
Epoch [26/50] - Loss: 0.1936
Epoch [27/50] - Loss: 0.1920
Epoch [28/50] - Loss: 0.1918
Epoch [29/50] - Loss: 0.1816
Epoch [30/50] - Loss: 0.1820
Epoch [31/50] - Loss: 0.1793
Epoch [32/50] - Loss: 0.1742
Epoch [33/50] - Loss: 0.1678
Epoch [34/50] - Loss: 0.1634
Epoch [35/50] - Loss: 0.1656
Epoch [36/50] - Loss: 0.1586
Epoch [37/50] - Loss: 0.1611
Epoch [38/50] - Loss: 0.1561
Epoch [39/50] - Loss: 0.1527
Epoch [40/50] - Loss: 0.1567
Epoch [41/50] - Loss: 0.1551
Epoch [42/50] - Loss: 0.1485
Epoch [43/50] - Loss: 0.1516
Epoch [44/50] - Loss: 0.1470
Epoch [45/50] - Loss: 0.1478
Epoch [46/50] - Loss: 0.1402
Epoch [47/50] - Loss: 0.1454
Epoch [48/50] - Loss: 0.1391
Epoch [49/50] - Loss: 0.1374
Epoch [50/50] - Loss: 0.1322
sum preds 34
sum labels 491
 - Test Metrics: Accuracy=0.8489, F1=0.1029, Recall=0.0550, Precision=0.7941
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1788
Epoch [2/50] - Loss: 0.6246
Epoch [3/50] - Loss: 0.4556
Epoch [4/50] - Loss: 0.4650
Epoch [5/50] - Loss: 0.4706
Epoch [6/50] - Loss: 0.4356
Epoch [7/50] - Loss: 0.4138
Epoch [8/50] - Loss: 0.3665
Epoch [9/50] - Loss: 0.3295
Epoch [10/50] - Loss: 0.3073
Epoch [11/50] - Loss: 0.3007
Epoch [12/50] - Loss: 0.2953
Epoch [13/50] - Loss: 0.2974
Epoch [14/50] - Loss: 0.2910
Epoch [15/50] - Loss: 0.2837
Epoch [16/50] - Loss: 0.2695
Epoch [17/50] - Loss: 0.2662
Epoch [18/50] - Loss: 0.2557
Epoch [19/50] - Loss: 0.2474
Epoch [20/50] - Loss: 0.2450
Epoch [21/50] - Loss: 0.2402
Epoch [22/50] - Loss: 0.2397
Epoch [23/50] - Loss: 0.2296
Epoch [24/50] - Loss: 0.2243
Epoch [25/50] - Loss: 0.2214
Epoch [26/50] - Loss: 0.2178
Epoch [27/50] - Loss: 0.2137
Epoch [28/50] - Loss: 0.2087
Epoch [29/50] - Loss: 0.2115
Epoch [30/50] - Loss: 0.2068
Epoch [31/50] - Loss: 0.2038
Epoch [32/50] - Loss: 0.2014
Epoch [33/50] - Loss: 0.2012
Epoch [34/50] - Loss: 0.1950
Epoch [35/50] - Loss: 0.1906
Epoch [36/50] - Loss: 0.1933
Epoch [37/50] - Loss: 0.1871
Epoch [38/50] - Loss: 0.1870
Epoch [39/50] - Loss: 0.1840
Epoch [40/50] - Loss: 0.1853
Epoch [41/50] - Loss: 0.1778
Epoch [42/50] - Loss: 0.1824
Epoch [43/50] - Loss: 0.1934
Epoch [44/50] - Loss: 0.1757
Epoch [45/50] - Loss: 0.1739
Epoch [46/50] - Loss: 0.1783
Epoch [47/50] - Loss: 0.1757
Epoch [48/50] - Loss: 0.1714
Epoch [49/50] - Loss: 0.1730
Epoch [50/50] - Loss: 0.1654
sum preds 37
sum labels 491
 - Test Metrics: Accuracy=0.8511, F1=0.1212, Recall=0.0652, Precision=0.8649
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_naive_naive_1804085302.csv.
Average F1 over valid seeds: 0.0880 ± 0.0348
___________________________________________________________________________________
Avg F1 for citeseer with SAR and naive, GATConv,0.3: 0.0880 ± 0.0348
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2033
Epoch [2/50] - Loss: 0.6756
Epoch [3/50] - Loss: 0.4985
Epoch [4/50] - Loss: 0.4620
Epoch [5/50] - Loss: 0.4757
Epoch [6/50] - Loss: 0.4666
Epoch [7/50] - Loss: 0.4391
Epoch [8/50] - Loss: 0.4097
Epoch [9/50] - Loss: 0.3780
Epoch [10/50] - Loss: 0.3438
Epoch [11/50] - Loss: 0.3184
Epoch [12/50] - Loss: 0.3078
Epoch [13/50] - Loss: 0.3049
Epoch [14/50] - Loss: 0.3020
Epoch [15/50] - Loss: 0.3017
Epoch [16/50] - Loss: 0.2965
Epoch [17/50] - Loss: 0.2828
Epoch [18/50] - Loss: 0.2772
Epoch [19/50] - Loss: 0.2663
Epoch [20/50] - Loss: 0.2649
Epoch [21/50] - Loss: 0.2651
Epoch [22/50] - Loss: 0.2631
Epoch [23/50] - Loss: 0.2522
Epoch [24/50] - Loss: 0.2505
Epoch [25/50] - Loss: 0.2442
Epoch [26/50] - Loss: 0.2422
Epoch [27/50] - Loss: 0.2434
Epoch [28/50] - Loss: 0.2401
Epoch [29/50] - Loss: 0.2379
Epoch [30/50] - Loss: 0.2355
Epoch [31/50] - Loss: 0.2307
Epoch [32/50] - Loss: 0.2284
Epoch [33/50] - Loss: 0.2307
Epoch [34/50] - Loss: 0.2287
Epoch [35/50] - Loss: 0.2238
Epoch [36/50] - Loss: 0.2180
Epoch [37/50] - Loss: 0.2207
Epoch [38/50] - Loss: 0.2210
Epoch [39/50] - Loss: 0.2202
Epoch [40/50] - Loss: 0.2188
Epoch [41/50] - Loss: 0.2145
Epoch [42/50] - Loss: 0.2132
Epoch [43/50] - Loss: 0.2147
Epoch [44/50] - Loss: 0.2087
Epoch [45/50] - Loss: 0.2093
Epoch [46/50] - Loss: 0.2117
Epoch [47/50] - Loss: 0.2091
Epoch [48/50] - Loss: 0.2078
Epoch [49/50] - Loss: 0.2103
Epoch [50/50] - Loss: 0.2060
sum preds 0
sum labels 491
 - Test Metrics: Accuracy=0.8425, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0916
Epoch [2/50] - Loss: 0.5366
Epoch [3/50] - Loss: 0.4819
Epoch [4/50] - Loss: 0.4817
Epoch [5/50] - Loss: 0.4633
Epoch [6/50] - Loss: 0.4158
Epoch [7/50] - Loss: 0.3689
Epoch [8/50] - Loss: 0.3205
Epoch [9/50] - Loss: 0.3028
Epoch [10/50] - Loss: 0.2997
Epoch [11/50] - Loss: 0.2976
Epoch [12/50] - Loss: 0.2965
Epoch [13/50] - Loss: 0.2894
Epoch [14/50] - Loss: 0.2800
Epoch [15/50] - Loss: 0.2722
Epoch [16/50] - Loss: 0.2621
Epoch [17/50] - Loss: 0.2563
Epoch [18/50] - Loss: 0.2564
Epoch [19/50] - Loss: 0.2504
Epoch [20/50] - Loss: 0.2458
Epoch [21/50] - Loss: 0.2433
Epoch [22/50] - Loss: 0.2413
Epoch [23/50] - Loss: 0.2391
Epoch [24/50] - Loss: 0.2322
Epoch [25/50] - Loss: 0.2327
Epoch [26/50] - Loss: 0.2304
Epoch [27/50] - Loss: 0.2254
Epoch [28/50] - Loss: 0.2248
Epoch [29/50] - Loss: 0.2253
Epoch [30/50] - Loss: 0.2227
Epoch [31/50] - Loss: 0.2173
Epoch [32/50] - Loss: 0.2153
Epoch [33/50] - Loss: 0.2153
Epoch [34/50] - Loss: 0.2106
Epoch [35/50] - Loss: 0.2075
Epoch [36/50] - Loss: 0.2103
Epoch [37/50] - Loss: 0.2061
Epoch [38/50] - Loss: 0.2113
Epoch [39/50] - Loss: 0.2094
Epoch [40/50] - Loss: 0.2006
Epoch [41/50] - Loss: 0.2043
Epoch [42/50] - Loss: 0.2058
Epoch [43/50] - Loss: 0.2013
Epoch [44/50] - Loss: 0.2003
Epoch [45/50] - Loss: 0.1990
Epoch [46/50] - Loss: 0.1955
Epoch [47/50] - Loss: 0.1957
Epoch [48/50] - Loss: 0.1958
Epoch [49/50] - Loss: 0.1965
Epoch [50/50] - Loss: 0.2009
sum preds 3
sum labels 491
 - Test Metrics: Accuracy=0.8434, F1=0.0121, Recall=0.0061, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0860
Epoch [2/50] - Loss: 0.5203
Epoch [3/50] - Loss: 0.4940
Epoch [4/50] - Loss: 0.4890
Epoch [5/50] - Loss: 0.4641
Epoch [6/50] - Loss: 0.4290
Epoch [7/50] - Loss: 0.3779
Epoch [8/50] - Loss: 0.3308
Epoch [9/50] - Loss: 0.3142
Epoch [10/50] - Loss: 0.3178
Epoch [11/50] - Loss: 0.3172
Epoch [12/50] - Loss: 0.3110
Epoch [13/50] - Loss: 0.3081
Epoch [14/50] - Loss: 0.2936
Epoch [15/50] - Loss: 0.2804
Epoch [16/50] - Loss: 0.2767
Epoch [17/50] - Loss: 0.2649
Epoch [18/50] - Loss: 0.2654
Epoch [19/50] - Loss: 0.2609
Epoch [20/50] - Loss: 0.2580
Epoch [21/50] - Loss: 0.2492
Epoch [22/50] - Loss: 0.2506
Epoch [23/50] - Loss: 0.2445
Epoch [24/50] - Loss: 0.2360
Epoch [25/50] - Loss: 0.2377
Epoch [26/50] - Loss: 0.2381
Epoch [27/50] - Loss: 0.2339
Epoch [28/50] - Loss: 0.2301
Epoch [29/50] - Loss: 0.2264
Epoch [30/50] - Loss: 0.2247
Epoch [31/50] - Loss: 0.2227
Epoch [32/50] - Loss: 0.2244
Epoch [33/50] - Loss: 0.2185
Epoch [34/50] - Loss: 0.2180
Epoch [35/50] - Loss: 0.2176
Epoch [36/50] - Loss: 0.2183
Epoch [37/50] - Loss: 0.2170
Epoch [38/50] - Loss: 0.2153
Epoch [39/50] - Loss: 0.2100
Epoch [40/50] - Loss: 0.2105
Epoch [41/50] - Loss: 0.2120
Epoch [42/50] - Loss: 0.2159
Epoch [43/50] - Loss: 0.2102
Epoch [44/50] - Loss: 0.2069
Epoch [45/50] - Loss: 0.2048
Epoch [46/50] - Loss: 0.2030
Epoch [47/50] - Loss: 0.2071
Epoch [48/50] - Loss: 0.2081
Epoch [49/50] - Loss: 0.2004
Epoch [50/50] - Loss: 0.2010
sum preds 0
sum labels 491
 - Test Metrics: Accuracy=0.8425, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_naive_naive_1804085401.csv.
Average F1 over valid seeds: 0.0040 ± 0.0057
___________________________________________________________________________________
Avg F1 for citeseer with SAR and naive, GCNConv,0.3: 0.0040 ± 0.0057
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0795
Epoch [2/50] - Loss: 0.8158
Epoch [3/50] - Loss: 0.5954
Epoch [4/50] - Loss: 0.4436
Epoch [5/50] - Loss: 0.3608
Epoch [6/50] - Loss: 0.3393
Epoch [7/50] - Loss: 0.3313
Epoch [8/50] - Loss: 0.3212
Epoch [9/50] - Loss: 0.3248
Epoch [10/50] - Loss: 0.3069
Epoch [11/50] - Loss: 0.2924
Epoch [12/50] - Loss: 0.2665
Epoch [13/50] - Loss: 0.2472
Epoch [14/50] - Loss: 0.2213
Epoch [15/50] - Loss: 0.2050
Epoch [16/50] - Loss: 0.1922
Epoch [17/50] - Loss: 0.1832
Epoch [18/50] - Loss: 0.1787
Epoch [19/50] - Loss: 0.1690
Epoch [20/50] - Loss: 0.1671
Epoch [21/50] - Loss: 0.1579
Epoch [22/50] - Loss: 0.1514
Epoch [23/50] - Loss: 0.1425
Epoch [24/50] - Loss: 0.1342
Epoch [25/50] - Loss: 0.1273
Epoch [26/50] - Loss: 0.1210
Epoch [27/50] - Loss: 0.1158
Epoch [28/50] - Loss: 0.1122
Epoch [29/50] - Loss: 0.1105
Epoch [30/50] - Loss: 0.1055
Epoch [31/50] - Loss: 0.1007
Epoch [32/50] - Loss: 0.0994
Epoch [33/50] - Loss: 0.0967
Epoch [34/50] - Loss: 0.0941
Epoch [35/50] - Loss: 0.0920
Epoch [36/50] - Loss: 0.0911
Epoch [37/50] - Loss: 0.0900
Epoch [38/50] - Loss: 0.0877
Epoch [39/50] - Loss: 0.0873
Epoch [40/50] - Loss: 0.0882
Epoch [41/50] - Loss: 0.0885
Epoch [42/50] - Loss: 0.0875
Epoch [43/50] - Loss: 0.0865
Epoch [44/50] - Loss: 0.0837
Epoch [45/50] - Loss: 0.0821
Epoch [46/50] - Loss: 0.0845
Epoch [47/50] - Loss: 0.0830
Epoch [48/50] - Loss: 0.0840
Epoch [49/50] - Loss: 0.0811
Epoch [50/50] - Loss: 0.0801
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4039
Epoch [2/50] - Loss: 0.9569
Epoch [3/50] - Loss: 0.6324
Epoch [4/50] - Loss: 0.4471
Epoch [5/50] - Loss: 0.3716
Epoch [6/50] - Loss: 0.3496
Epoch [7/50] - Loss: 0.3398
Epoch [8/50] - Loss: 0.3446
Epoch [9/50] - Loss: 0.3442
Epoch [10/50] - Loss: 0.3285
Epoch [11/50] - Loss: 0.3194
Epoch [12/50] - Loss: 0.2918
Epoch [13/50] - Loss: 0.2692
Epoch [14/50] - Loss: 0.2383
Epoch [15/50] - Loss: 0.2238
Epoch [16/50] - Loss: 0.2072
Epoch [17/50] - Loss: 0.1945
Epoch [18/50] - Loss: 0.1827
Epoch [19/50] - Loss: 0.1797
Epoch [20/50] - Loss: 0.1715
Epoch [21/50] - Loss: 0.1646
Epoch [22/50] - Loss: 0.1593
Epoch [23/50] - Loss: 0.1492
Epoch [24/50] - Loss: 0.1407
Epoch [25/50] - Loss: 0.1327
Epoch [26/50] - Loss: 0.1232
Epoch [27/50] - Loss: 0.1190
Epoch [28/50] - Loss: 0.1114
Epoch [29/50] - Loss: 0.1054
Epoch [30/50] - Loss: 0.1021
Epoch [31/50] - Loss: 0.0987
Epoch [32/50] - Loss: 0.0959
Epoch [33/50] - Loss: 0.0902
Epoch [34/50] - Loss: 0.0888
Epoch [35/50] - Loss: 0.0849
Epoch [36/50] - Loss: 0.0832
Epoch [37/50] - Loss: 0.0816
Epoch [38/50] - Loss: 0.0792
Epoch [39/50] - Loss: 0.0762
Epoch [40/50] - Loss: 0.0759
Epoch [41/50] - Loss: 0.0748
Epoch [42/50] - Loss: 0.0724
Epoch [43/50] - Loss: 0.0712
Epoch [44/50] - Loss: 0.0714
Epoch [45/50] - Loss: 0.0700
Epoch [46/50] - Loss: 0.0697
Epoch [47/50] - Loss: 0.0694
Epoch [48/50] - Loss: 0.0685
Epoch [49/50] - Loss: 0.0671
Epoch [50/50] - Loss: 0.0680
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3617
Epoch [2/50] - Loss: 0.9722
Epoch [3/50] - Loss: 0.6593
Epoch [4/50] - Loss: 0.4653
Epoch [5/50] - Loss: 0.3725
Epoch [6/50] - Loss: 0.3468
Epoch [7/50] - Loss: 0.3352
Epoch [8/50] - Loss: 0.3389
Epoch [9/50] - Loss: 0.3412
Epoch [10/50] - Loss: 0.3319
Epoch [11/50] - Loss: 0.3125
Epoch [12/50] - Loss: 0.2817
Epoch [13/50] - Loss: 0.2612
Epoch [14/50] - Loss: 0.2387
Epoch [15/50] - Loss: 0.2169
Epoch [16/50] - Loss: 0.1993
Epoch [17/50] - Loss: 0.1887
Epoch [18/50] - Loss: 0.1842
Epoch [19/50] - Loss: 0.1755
Epoch [20/50] - Loss: 0.1731
Epoch [21/50] - Loss: 0.1662
Epoch [22/50] - Loss: 0.1572
Epoch [23/50] - Loss: 0.1501
Epoch [24/50] - Loss: 0.1421
Epoch [25/50] - Loss: 0.1297
Epoch [26/50] - Loss: 0.1262
Epoch [27/50] - Loss: 0.1177
Epoch [28/50] - Loss: 0.1117
Epoch [29/50] - Loss: 0.1077
Epoch [30/50] - Loss: 0.1037
Epoch [31/50] - Loss: 0.0978
Epoch [32/50] - Loss: 0.0933
Epoch [33/50] - Loss: 0.0914
Epoch [34/50] - Loss: 0.0878
Epoch [35/50] - Loss: 0.0879
Epoch [36/50] - Loss: 0.0822
Epoch [37/50] - Loss: 0.0829
Epoch [38/50] - Loss: 0.0786
Epoch [39/50] - Loss: 0.0790
Epoch [40/50] - Loss: 0.0766
Epoch [41/50] - Loss: 0.0759
Epoch [42/50] - Loss: 0.0735
Epoch [43/50] - Loss: 0.0744
Epoch [44/50] - Loss: 0.0722
Epoch [45/50] - Loss: 0.0692
Epoch [46/50] - Loss: 0.0717
Epoch [47/50] - Loss: 0.0701
Epoch [48/50] - Loss: 0.0696
Epoch [49/50] - Loss: 0.0680
Epoch [50/50] - Loss: 0.0689
sum preds 1
sum labels 561
 - Test Metrics: Accuracy=0.8243, F1=0.0036, Recall=0.0018, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_naive_naive_1804085454.csv.
Average F1 over valid seeds: 0.0012 ± 0.0017
___________________________________________________________________________________
Avg F1 for citeseer with SAR and naive, MLP,0.2: 0.0012 ± 0.0017
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2171
Epoch [2/50] - Loss: 0.6387
Epoch [3/50] - Loss: 0.4055
Epoch [4/50] - Loss: 0.3384
Epoch [5/50] - Loss: 0.3444
Epoch [6/50] - Loss: 0.3521
Epoch [7/50] - Loss: 0.3608
Epoch [8/50] - Loss: 0.3476
Epoch [9/50] - Loss: 0.3306
Epoch [10/50] - Loss: 0.3075
Epoch [11/50] - Loss: 0.2801
Epoch [12/50] - Loss: 0.2582
Epoch [13/50] - Loss: 0.2408
Epoch [14/50] - Loss: 0.2311
Epoch [15/50] - Loss: 0.2239
Epoch [16/50] - Loss: 0.2236
Epoch [17/50] - Loss: 0.2207
Epoch [18/50] - Loss: 0.2138
Epoch [19/50] - Loss: 0.2091
Epoch [20/50] - Loss: 0.2000
Epoch [21/50] - Loss: 0.1982
Epoch [22/50] - Loss: 0.1905
Epoch [23/50] - Loss: 0.1842
Epoch [24/50] - Loss: 0.1766
Epoch [25/50] - Loss: 0.1729
Epoch [26/50] - Loss: 0.1741
Epoch [27/50] - Loss: 0.1656
Epoch [28/50] - Loss: 0.1622
Epoch [29/50] - Loss: 0.1614
Epoch [30/50] - Loss: 0.1555
Epoch [31/50] - Loss: 0.1517
Epoch [32/50] - Loss: 0.1485
Epoch [33/50] - Loss: 0.1468
Epoch [34/50] - Loss: 0.1459
Epoch [35/50] - Loss: 0.1432
Epoch [36/50] - Loss: 0.1430
Epoch [37/50] - Loss: 0.1404
Epoch [38/50] - Loss: 0.1381
Epoch [39/50] - Loss: 0.1342
Epoch [40/50] - Loss: 0.1362
Epoch [41/50] - Loss: 0.1337
Epoch [42/50] - Loss: 0.1297
Epoch [43/50] - Loss: 0.1313
Epoch [44/50] - Loss: 0.1287
Epoch [45/50] - Loss: 0.1254
Epoch [46/50] - Loss: 0.1295
Epoch [47/50] - Loss: 0.1272
Epoch [48/50] - Loss: 0.1234
Epoch [49/50] - Loss: 0.1225
Epoch [50/50] - Loss: 0.1245
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1179
Epoch [2/50] - Loss: 0.4956
Epoch [3/50] - Loss: 0.3425
Epoch [4/50] - Loss: 0.3462
Epoch [5/50] - Loss: 0.3663
Epoch [6/50] - Loss: 0.3677
Epoch [7/50] - Loss: 0.3382
Epoch [8/50] - Loss: 0.3123
Epoch [9/50] - Loss: 0.2745
Epoch [10/50] - Loss: 0.2418
Epoch [11/50] - Loss: 0.2203
Epoch [12/50] - Loss: 0.2105
Epoch [13/50] - Loss: 0.2121
Epoch [14/50] - Loss: 0.2082
Epoch [15/50] - Loss: 0.2064
Epoch [16/50] - Loss: 0.2026
Epoch [17/50] - Loss: 0.1917
Epoch [18/50] - Loss: 0.1863
Epoch [19/50] - Loss: 0.1795
Epoch [20/50] - Loss: 0.1733
Epoch [21/50] - Loss: 0.1692
Epoch [22/50] - Loss: 0.1681
Epoch [23/50] - Loss: 0.1618
Epoch [24/50] - Loss: 0.1592
Epoch [25/50] - Loss: 0.1562
Epoch [26/50] - Loss: 0.1501
Epoch [27/50] - Loss: 0.1473
Epoch [28/50] - Loss: 0.1487
Epoch [29/50] - Loss: 0.1387
Epoch [30/50] - Loss: 0.1411
Epoch [31/50] - Loss: 0.1353
Epoch [32/50] - Loss: 0.1318
Epoch [33/50] - Loss: 0.1307
Epoch [34/50] - Loss: 0.1263
Epoch [35/50] - Loss: 0.1266
Epoch [36/50] - Loss: 0.1215
Epoch [37/50] - Loss: 0.1256
Epoch [38/50] - Loss: 0.1175
Epoch [39/50] - Loss: 0.1163
Epoch [40/50] - Loss: 0.1185
Epoch [41/50] - Loss: 0.1164
Epoch [42/50] - Loss: 0.1118
Epoch [43/50] - Loss: 0.1130
Epoch [44/50] - Loss: 0.1118
Epoch [45/50] - Loss: 0.1106
Epoch [46/50] - Loss: 0.1067
Epoch [47/50] - Loss: 0.1085
Epoch [48/50] - Loss: 0.1070
Epoch [49/50] - Loss: 0.1017
Epoch [50/50] - Loss: 0.0960
sum preds 19
sum labels 561
 - Test Metrics: Accuracy=0.8262, F1=0.0448, Recall=0.0232, Precision=0.6842
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1678
Epoch [2/50] - Loss: 0.5644
Epoch [3/50] - Loss: 0.3596
Epoch [4/50] - Loss: 0.3556
Epoch [5/50] - Loss: 0.3677
Epoch [6/50] - Loss: 0.3551
Epoch [7/50] - Loss: 0.3627
Epoch [8/50] - Loss: 0.3353
Epoch [9/50] - Loss: 0.2958
Epoch [10/50] - Loss: 0.2672
Epoch [11/50] - Loss: 0.2436
Epoch [12/50] - Loss: 0.2276
Epoch [13/50] - Loss: 0.2251
Epoch [14/50] - Loss: 0.2228
Epoch [15/50] - Loss: 0.2240
Epoch [16/50] - Loss: 0.2195
Epoch [17/50] - Loss: 0.2140
Epoch [18/50] - Loss: 0.2050
Epoch [19/50] - Loss: 0.1969
Epoch [20/50] - Loss: 0.1948
Epoch [21/50] - Loss: 0.1848
Epoch [22/50] - Loss: 0.1851
Epoch [23/50] - Loss: 0.1797
Epoch [24/50] - Loss: 0.1768
Epoch [25/50] - Loss: 0.1764
Epoch [26/50] - Loss: 0.1688
Epoch [27/50] - Loss: 0.1683
Epoch [28/50] - Loss: 0.1621
Epoch [29/50] - Loss: 0.1637
Epoch [30/50] - Loss: 0.1619
Epoch [31/50] - Loss: 0.1566
Epoch [32/50] - Loss: 0.1568
Epoch [33/50] - Loss: 0.1539
Epoch [34/50] - Loss: 0.1523
Epoch [35/50] - Loss: 0.1482
Epoch [36/50] - Loss: 0.1461
Epoch [37/50] - Loss: 0.1449
Epoch [38/50] - Loss: 0.1420
Epoch [39/50] - Loss: 0.1455
Epoch [40/50] - Loss: 0.1418
Epoch [41/50] - Loss: 0.1389
Epoch [42/50] - Loss: 0.1391
Epoch [43/50] - Loss: 0.1414
Epoch [44/50] - Loss: 0.1340
Epoch [45/50] - Loss: 0.1350
Epoch [46/50] - Loss: 0.1307
Epoch [47/50] - Loss: 0.1317
Epoch [48/50] - Loss: 0.1266
Epoch [49/50] - Loss: 0.1286
Epoch [50/50] - Loss: 0.1250
sum preds 18
sum labels 561
 - Test Metrics: Accuracy=0.8296, F1=0.0622, Recall=0.0321, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_naive_naive_1804085547.csv.
Average F1 over valid seeds: 0.0357 ± 0.0262
___________________________________________________________________________________
Avg F1 for citeseer with SAR and naive, GATConv,0.2: 0.0357 ± 0.0262
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1924
Epoch [2/50] - Loss: 0.6221
Epoch [3/50] - Loss: 0.4052
Epoch [4/50] - Loss: 0.3563
Epoch [5/50] - Loss: 0.3610
Epoch [6/50] - Loss: 0.3691
Epoch [7/50] - Loss: 0.3654
Epoch [8/50] - Loss: 0.3540
Epoch [9/50] - Loss: 0.3440
Epoch [10/50] - Loss: 0.3106
Epoch [11/50] - Loss: 0.2873
Epoch [12/50] - Loss: 0.2611
Epoch [13/50] - Loss: 0.2463
Epoch [14/50] - Loss: 0.2376
Epoch [15/50] - Loss: 0.2370
Epoch [16/50] - Loss: 0.2357
Epoch [17/50] - Loss: 0.2298
Epoch [18/50] - Loss: 0.2300
Epoch [19/50] - Loss: 0.2217
Epoch [20/50] - Loss: 0.2212
Epoch [21/50] - Loss: 0.2156
Epoch [22/50] - Loss: 0.2114
Epoch [23/50] - Loss: 0.2022
Epoch [24/50] - Loss: 0.2016
Epoch [25/50] - Loss: 0.1933
Epoch [26/50] - Loss: 0.1962
Epoch [27/50] - Loss: 0.1946
Epoch [28/50] - Loss: 0.1915
Epoch [29/50] - Loss: 0.1901
Epoch [30/50] - Loss: 0.1860
Epoch [31/50] - Loss: 0.1825
Epoch [32/50] - Loss: 0.1788
Epoch [33/50] - Loss: 0.1810
Epoch [34/50] - Loss: 0.1811
Epoch [35/50] - Loss: 0.1757
Epoch [36/50] - Loss: 0.1703
Epoch [37/50] - Loss: 0.1725
Epoch [38/50] - Loss: 0.1711
Epoch [39/50] - Loss: 0.1704
Epoch [40/50] - Loss: 0.1688
Epoch [41/50] - Loss: 0.1657
Epoch [42/50] - Loss: 0.1627
Epoch [43/50] - Loss: 0.1639
Epoch [44/50] - Loss: 0.1607
Epoch [45/50] - Loss: 0.1607
Epoch [46/50] - Loss: 0.1643
Epoch [47/50] - Loss: 0.1603
Epoch [48/50] - Loss: 0.1565
Epoch [49/50] - Loss: 0.1618
Epoch [50/50] - Loss: 0.1579
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0754
Epoch [2/50] - Loss: 0.4556
Epoch [3/50] - Loss: 0.3625
Epoch [4/50] - Loss: 0.3748
Epoch [5/50] - Loss: 0.3791
Epoch [6/50] - Loss: 0.3661
Epoch [7/50] - Loss: 0.3412
Epoch [8/50] - Loss: 0.2948
Epoch [9/50] - Loss: 0.2618
Epoch [10/50] - Loss: 0.2335
Epoch [11/50] - Loss: 0.2182
Epoch [12/50] - Loss: 0.2160
Epoch [13/50] - Loss: 0.2180
Epoch [14/50] - Loss: 0.2224
Epoch [15/50] - Loss: 0.2188
Epoch [16/50] - Loss: 0.2061
Epoch [17/50] - Loss: 0.1993
Epoch [18/50] - Loss: 0.1940
Epoch [19/50] - Loss: 0.1884
Epoch [20/50] - Loss: 0.1825
Epoch [21/50] - Loss: 0.1809
Epoch [22/50] - Loss: 0.1809
Epoch [23/50] - Loss: 0.1789
Epoch [24/50] - Loss: 0.1730
Epoch [25/50] - Loss: 0.1733
Epoch [26/50] - Loss: 0.1704
Epoch [27/50] - Loss: 0.1662
Epoch [28/50] - Loss: 0.1650
Epoch [29/50] - Loss: 0.1659
Epoch [30/50] - Loss: 0.1632
Epoch [31/50] - Loss: 0.1589
Epoch [32/50] - Loss: 0.1556
Epoch [33/50] - Loss: 0.1551
Epoch [34/50] - Loss: 0.1530
Epoch [35/50] - Loss: 0.1490
Epoch [36/50] - Loss: 0.1528
Epoch [37/50] - Loss: 0.1476
Epoch [38/50] - Loss: 0.1514
Epoch [39/50] - Loss: 0.1528
Epoch [40/50] - Loss: 0.1456
Epoch [41/50] - Loss: 0.1458
Epoch [42/50] - Loss: 0.1483
Epoch [43/50] - Loss: 0.1466
Epoch [44/50] - Loss: 0.1449
Epoch [45/50] - Loss: 0.1421
Epoch [46/50] - Loss: 0.1401
Epoch [47/50] - Loss: 0.1398
Epoch [48/50] - Loss: 0.1431
Epoch [49/50] - Loss: 0.1405
Epoch [50/50] - Loss: 0.1454
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0680
Epoch [2/50] - Loss: 0.4374
Epoch [3/50] - Loss: 0.3668
Epoch [4/50] - Loss: 0.3807
Epoch [5/50] - Loss: 0.3846
Epoch [6/50] - Loss: 0.3754
Epoch [7/50] - Loss: 0.3416
Epoch [8/50] - Loss: 0.3007
Epoch [9/50] - Loss: 0.2664
Epoch [10/50] - Loss: 0.2435
Epoch [11/50] - Loss: 0.2312
Epoch [12/50] - Loss: 0.2282
Epoch [13/50] - Loss: 0.2326
Epoch [14/50] - Loss: 0.2312
Epoch [15/50] - Loss: 0.2218
Epoch [16/50] - Loss: 0.2162
Epoch [17/50] - Loss: 0.2054
Epoch [18/50] - Loss: 0.1981
Epoch [19/50] - Loss: 0.1928
Epoch [20/50] - Loss: 0.1911
Epoch [21/50] - Loss: 0.1862
Epoch [22/50] - Loss: 0.1881
Epoch [23/50] - Loss: 0.1831
Epoch [24/50] - Loss: 0.1760
Epoch [25/50] - Loss: 0.1742
Epoch [26/50] - Loss: 0.1759
Epoch [27/50] - Loss: 0.1714
Epoch [28/50] - Loss: 0.1676
Epoch [29/50] - Loss: 0.1652
Epoch [30/50] - Loss: 0.1649
Epoch [31/50] - Loss: 0.1631
Epoch [32/50] - Loss: 0.1617
Epoch [33/50] - Loss: 0.1564
Epoch [34/50] - Loss: 0.1576
Epoch [35/50] - Loss: 0.1577
Epoch [36/50] - Loss: 0.1591
Epoch [37/50] - Loss: 0.1546
Epoch [38/50] - Loss: 0.1545
Epoch [39/50] - Loss: 0.1505
Epoch [40/50] - Loss: 0.1510
Epoch [41/50] - Loss: 0.1517
Epoch [42/50] - Loss: 0.1546
Epoch [43/50] - Loss: 0.1502
Epoch [44/50] - Loss: 0.1488
Epoch [45/50] - Loss: 0.1463
Epoch [46/50] - Loss: 0.1453
Epoch [47/50] - Loss: 0.1491
Epoch [48/50] - Loss: 0.1484
Epoch [49/50] - Loss: 0.1437
Epoch [50/50] - Loss: 0.1431
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_naive_naive_1804085642.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for citeseer with SAR and naive, GCNConv,0.2: 0.0000 ± 0.0000
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8776, F1=0.2309, Recall=0.1330, Precision=0.8750
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8707, F1=0.1435, Recall=0.0784, Precision=0.8462
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8782, F1=0.2351, Recall=0.1354, Precision=0.8906
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_NNIF_NNIF_1804085736.csv.
Average F1 over valid seeds: 0.2032 ± 0.0422
___________________________________________________________________________________
Avg F1 for citeseer with SAR and NNIF, MLP,0.4: 0.2032 ± 0.0422
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8572, F1=0.1982, Recall=0.1120, Precision=0.8594
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8527, F1=0.1356, Recall=0.0733, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8553, F1=0.1664, Recall=0.0916, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_NNIF_NNIF_1804085824.csv.
Average F1 over valid seeds: 0.1667 ± 0.0256
___________________________________________________________________________________
Avg F1 for citeseer with SAR and NNIF, MLP,0.3: 0.1667 ± 0.0256
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8350, F1=0.1233, Recall=0.0660, Precision=0.9487
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8246, F1=0.0278, Recall=0.0143, Precision=0.5714
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8331, F1=0.1104, Recall=0.0588, Precision=0.8919
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_NNIF_NNIF_1804085855.csv.
Average F1 over valid seeds: 0.0872 ± 0.0423
___________________________________________________________________________________
Avg F1 for citeseer with SAR and NNIF, MLP,0.2: 0.0872 ± 0.0423
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1117
Epoch [2/50] - Loss: 0.8852
Epoch [3/50] - Loss: 0.7064
Epoch [4/50] - Loss: 0.5793
Epoch [5/50] - Loss: 0.5232
Epoch [6/50] - Loss: 0.5078
Epoch [7/50] - Loss: 0.4969
Epoch [8/50] - Loss: 0.4615
Epoch [9/50] - Loss: 0.4385
Epoch [10/50] - Loss: 0.3937
Epoch [11/50] - Loss: 0.3598
Epoch [12/50] - Loss: 0.3297
Epoch [13/50] - Loss: 0.3185
Epoch [14/50] - Loss: 0.3040
Epoch [15/50] - Loss: 0.2959
Epoch [16/50] - Loss: 0.2830
Epoch [17/50] - Loss: 0.2707
Epoch [18/50] - Loss: 0.2578
Epoch [19/50] - Loss: 0.2446
Epoch [20/50] - Loss: 0.2322
Epoch [21/50] - Loss: 0.2224
Epoch [22/50] - Loss: 0.2119
Epoch [23/50] - Loss: 0.2108
Epoch [24/50] - Loss: 0.1958
Epoch [25/50] - Loss: 0.1895
Epoch [26/50] - Loss: 0.1842
Epoch [27/50] - Loss: 0.1789
Epoch [28/50] - Loss: 0.1740
Epoch [29/50] - Loss: 0.1659
Epoch [30/50] - Loss: 0.1639
Epoch [31/50] - Loss: 0.1491
Epoch [32/50] - Loss: 0.1389
Epoch [33/50] - Loss: 0.1272
Epoch [34/50] - Loss: 0.1148
Epoch [35/50] - Loss: 0.1000
Epoch [36/50] - Loss: 0.0889
Epoch [37/50] - Loss: 0.0765
Epoch [38/50] - Loss: 0.0701
Epoch [39/50] - Loss: 0.0622
Epoch [40/50] - Loss: 0.0585
Epoch [41/50] - Loss: 0.0524
Epoch [42/50] - Loss: 0.0470
Epoch [43/50] - Loss: 0.0425
Epoch [44/50] - Loss: 0.0396
Epoch [45/50] - Loss: 0.0359
Epoch [46/50] - Loss: 0.0320
Epoch [47/50] - Loss: 0.0302
Epoch [48/50] - Loss: 0.0274
Epoch [49/50] - Loss: 0.0259
Epoch [50/50] - Loss: 0.0243
sum preds 65
sum labels 421
 - Test Metrics: Accuracy=0.8792, F1=0.2428, Recall=0.1401, Precision=0.9077
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4026
Epoch [2/50] - Loss: 1.0104
Epoch [3/50] - Loss: 0.7363
Epoch [4/50] - Loss: 0.5905
Epoch [5/50] - Loss: 0.5390
Epoch [6/50] - Loss: 0.5281
Epoch [7/50] - Loss: 0.5166
Epoch [8/50] - Loss: 0.5053
Epoch [9/50] - Loss: 0.4624
Epoch [10/50] - Loss: 0.4259
Epoch [11/50] - Loss: 0.3742
Epoch [12/50] - Loss: 0.3503
Epoch [13/50] - Loss: 0.3251
Epoch [14/50] - Loss: 0.3095
Epoch [15/50] - Loss: 0.2925
Epoch [16/50] - Loss: 0.2900
Epoch [17/50] - Loss: 0.2822
Epoch [18/50] - Loss: 0.2646
Epoch [19/50] - Loss: 0.2573
Epoch [20/50] - Loss: 0.2416
Epoch [21/50] - Loss: 0.2288
Epoch [22/50] - Loss: 0.2183
Epoch [23/50] - Loss: 0.2060
Epoch [24/50] - Loss: 0.1976
Epoch [25/50] - Loss: 0.1880
Epoch [26/50] - Loss: 0.1855
Epoch [27/50] - Loss: 0.1742
Epoch [28/50] - Loss: 0.1688
Epoch [29/50] - Loss: 0.1667
Epoch [30/50] - Loss: 0.1584
Epoch [31/50] - Loss: 0.1565
Epoch [32/50] - Loss: 0.1537
Epoch [33/50] - Loss: 0.1502
Epoch [34/50] - Loss: 0.1451
Epoch [35/50] - Loss: 0.1437
Epoch [36/50] - Loss: 0.1395
Epoch [37/50] - Loss: 0.1364
Epoch [38/50] - Loss: 0.1342
Epoch [39/50] - Loss: 0.1329
Epoch [40/50] - Loss: 0.1300
Epoch [41/50] - Loss: 0.1310
Epoch [42/50] - Loss: 0.1282
Epoch [43/50] - Loss: 0.1277
Epoch [44/50] - Loss: 0.1235
Epoch [45/50] - Loss: 0.1237
Epoch [46/50] - Loss: 0.1252
Epoch [47/50] - Loss: 0.1228
Epoch [48/50] - Loss: 0.1201
Epoch [49/50] - Loss: 0.1208
Epoch [50/50] - Loss: 0.1179
sum preds 31
sum labels 421
 - Test Metrics: Accuracy=0.8707, F1=0.1283, Recall=0.0689, Precision=0.9355
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3654
Epoch [2/50] - Loss: 1.0207
Epoch [3/50] - Loss: 0.7529
Epoch [4/50] - Loss: 0.6003
Epoch [5/50] - Loss: 0.5320
Epoch [6/50] - Loss: 0.5227
Epoch [7/50] - Loss: 0.5177
Epoch [8/50] - Loss: 0.4891
Epoch [9/50] - Loss: 0.4631
Epoch [10/50] - Loss: 0.4233
Epoch [11/50] - Loss: 0.3753
Epoch [12/50] - Loss: 0.3465
Epoch [13/50] - Loss: 0.3192
Epoch [14/50] - Loss: 0.3088
Epoch [15/50] - Loss: 0.2891
Epoch [16/50] - Loss: 0.2821
Epoch [17/50] - Loss: 0.2718
Epoch [18/50] - Loss: 0.2652
Epoch [19/50] - Loss: 0.2455
Epoch [20/50] - Loss: 0.2338
Epoch [21/50] - Loss: 0.2134
Epoch [22/50] - Loss: 0.2087
Epoch [23/50] - Loss: 0.1974
Epoch [24/50] - Loss: 0.1919
Epoch [25/50] - Loss: 0.1825
Epoch [26/50] - Loss: 0.1749
Epoch [27/50] - Loss: 0.1705
Epoch [28/50] - Loss: 0.1636
Epoch [29/50] - Loss: 0.1604
Epoch [30/50] - Loss: 0.1571
Epoch [31/50] - Loss: 0.1489
Epoch [32/50] - Loss: 0.1504
Epoch [33/50] - Loss: 0.1466
Epoch [34/50] - Loss: 0.1430
Epoch [35/50] - Loss: 0.1425
Epoch [36/50] - Loss: 0.1413
Epoch [37/50] - Loss: 0.1375
Epoch [38/50] - Loss: 0.1352
Epoch [39/50] - Loss: 0.1297
Epoch [40/50] - Loss: 0.1320
Epoch [41/50] - Loss: 0.1309
Epoch [42/50] - Loss: 0.1337
Epoch [43/50] - Loss: 0.1313
Epoch [44/50] - Loss: 0.1256
Epoch [45/50] - Loss: 0.1277
Epoch [46/50] - Loss: 0.1226
Epoch [47/50] - Loss: 0.1242
Epoch [48/50] - Loss: 0.1230
Epoch [49/50] - Loss: 0.1208
Epoch [50/50] - Loss: 0.1230
sum preds 30
sum labels 421
 - Test Metrics: Accuracy=0.8697, F1=0.1197, Recall=0.0641, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_two_nnif_two_nnif_1804085927.csv.
Average F1 over valid seeds: 0.1636 ± 0.0561
___________________________________________________________________________________
Avg F1 for citeseer with SAR and two_nnif, MLP,0.4: 0.1636 ± 0.0561
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2397
Epoch [2/50] - Loss: 0.7436
Epoch [3/50] - Loss: 0.5661
Epoch [4/50] - Loss: 0.5400
Epoch [5/50] - Loss: 0.5310
Epoch [6/50] - Loss: 0.5058
Epoch [7/50] - Loss: 0.4698
Epoch [8/50] - Loss: 0.4263
Epoch [9/50] - Loss: 0.3749
Epoch [10/50] - Loss: 0.3540
Epoch [11/50] - Loss: 0.3397
Epoch [12/50] - Loss: 0.3325
Epoch [13/50] - Loss: 0.3275
Epoch [14/50] - Loss: 0.3219
Epoch [15/50] - Loss: 0.3068
Epoch [16/50] - Loss: 0.2964
Epoch [17/50] - Loss: 0.2883
Epoch [18/50] - Loss: 0.2755
Epoch [19/50] - Loss: 0.2664
Epoch [20/50] - Loss: 0.2674
Epoch [21/50] - Loss: 0.2523
Epoch [22/50] - Loss: 0.2464
Epoch [23/50] - Loss: 0.2444
Epoch [24/50] - Loss: 0.2367
Epoch [25/50] - Loss: 0.2308
Epoch [26/50] - Loss: 0.2263
Epoch [27/50] - Loss: 0.2199
Epoch [28/50] - Loss: 0.2111
Epoch [29/50] - Loss: 0.2129
Epoch [30/50] - Loss: 0.2056
Epoch [31/50] - Loss: 0.2010
Epoch [32/50] - Loss: 0.1956
Epoch [33/50] - Loss: 0.1966
Epoch [34/50] - Loss: 0.1876
Epoch [35/50] - Loss: 0.1910
Epoch [36/50] - Loss: 0.1789
Epoch [37/50] - Loss: 0.1807
Epoch [38/50] - Loss: 0.1763
Epoch [39/50] - Loss: 0.1753
Epoch [40/50] - Loss: 0.1686
Epoch [41/50] - Loss: 0.1708
Epoch [42/50] - Loss: 0.1595
Epoch [43/50] - Loss: 0.1539
Epoch [44/50] - Loss: 0.1605
Epoch [45/50] - Loss: 0.1511
Epoch [46/50] - Loss: 0.1483
Epoch [47/50] - Loss: 0.1524
Epoch [48/50] - Loss: 0.1404
Epoch [49/50] - Loss: 0.1475
Epoch [50/50] - Loss: 0.1418
sum preds 95
sum labels 421
 - Test Metrics: Accuracy=0.8825, F1=0.3062, Recall=0.1876, Precision=0.8316
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1479
Epoch [2/50] - Loss: 0.6305
Epoch [3/50] - Loss: 0.5433
Epoch [4/50] - Loss: 0.5438
Epoch [5/50] - Loss: 0.5033
Epoch [6/50] - Loss: 0.4515
Epoch [7/50] - Loss: 0.3781
Epoch [8/50] - Loss: 0.3471
Epoch [9/50] - Loss: 0.3404
Epoch [10/50] - Loss: 0.3364
Epoch [11/50] - Loss: 0.3305
Epoch [12/50] - Loss: 0.3186
Epoch [13/50] - Loss: 0.3110
Epoch [14/50] - Loss: 0.2961
Epoch [15/50] - Loss: 0.2850
Epoch [16/50] - Loss: 0.2758
Epoch [17/50] - Loss: 0.2612
Epoch [18/50] - Loss: 0.2612
Epoch [19/50] - Loss: 0.2442
Epoch [20/50] - Loss: 0.2416
Epoch [21/50] - Loss: 0.2357
Epoch [22/50] - Loss: 0.2240
Epoch [23/50] - Loss: 0.2222
Epoch [24/50] - Loss: 0.2186
Epoch [25/50] - Loss: 0.2007
Epoch [26/50] - Loss: 0.2067
Epoch [27/50] - Loss: 0.1927
Epoch [28/50] - Loss: 0.1925
Epoch [29/50] - Loss: 0.1867
Epoch [30/50] - Loss: 0.1787
Epoch [31/50] - Loss: 0.1842
Epoch [32/50] - Loss: 0.1735
Epoch [33/50] - Loss: 0.1746
Epoch [34/50] - Loss: 0.1703
Epoch [35/50] - Loss: 0.1626
Epoch [36/50] - Loss: 0.1543
Epoch [37/50] - Loss: 0.1563
Epoch [38/50] - Loss: 0.1585
Epoch [39/50] - Loss: 0.1551
Epoch [40/50] - Loss: 0.1494
Epoch [41/50] - Loss: 0.1500
Epoch [42/50] - Loss: 0.1435
Epoch [43/50] - Loss: 0.1481
Epoch [44/50] - Loss: 0.1475
Epoch [45/50] - Loss: 0.1455
Epoch [46/50] - Loss: 0.1432
Epoch [47/50] - Loss: 0.1405
Epoch [48/50] - Loss: 0.1322
Epoch [49/50] - Loss: 0.1360
Epoch [50/50] - Loss: 0.1324
sum preds 99
sum labels 421
 - Test Metrics: Accuracy=0.8812, F1=0.3038, Recall=0.1876, Precision=0.7980
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1900
Epoch [2/50] - Loss: 0.6744
Epoch [3/50] - Loss: 0.5385
Epoch [4/50] - Loss: 0.5353
Epoch [5/50] - Loss: 0.5425
Epoch [6/50] - Loss: 0.4733
Epoch [7/50] - Loss: 0.4070
Epoch [8/50] - Loss: 0.3688
Epoch [9/50] - Loss: 0.3429
Epoch [10/50] - Loss: 0.3360
Epoch [11/50] - Loss: 0.3333
Epoch [12/50] - Loss: 0.3221
Epoch [13/50] - Loss: 0.3205
Epoch [14/50] - Loss: 0.3091
Epoch [15/50] - Loss: 0.2975
Epoch [16/50] - Loss: 0.2907
Epoch [17/50] - Loss: 0.2814
Epoch [18/50] - Loss: 0.2816
Epoch [19/50] - Loss: 0.2733
Epoch [20/50] - Loss: 0.2619
Epoch [21/50] - Loss: 0.2595
Epoch [22/50] - Loss: 0.2554
Epoch [23/50] - Loss: 0.2448
Epoch [24/50] - Loss: 0.2425
Epoch [25/50] - Loss: 0.2439
Epoch [26/50] - Loss: 0.2388
Epoch [27/50] - Loss: 0.2306
Epoch [28/50] - Loss: 0.2241
Epoch [29/50] - Loss: 0.2247
Epoch [30/50] - Loss: 0.2210
Epoch [31/50] - Loss: 0.2185
Epoch [32/50] - Loss: 0.2042
Epoch [33/50] - Loss: 0.2140
Epoch [34/50] - Loss: 0.2019
Epoch [35/50] - Loss: 0.1936
Epoch [36/50] - Loss: 0.2000
Epoch [37/50] - Loss: 0.1927
Epoch [38/50] - Loss: 0.1885
Epoch [39/50] - Loss: 0.1894
Epoch [40/50] - Loss: 0.1790
Epoch [41/50] - Loss: 0.1703
Epoch [42/50] - Loss: 0.1804
Epoch [43/50] - Loss: 0.1686
Epoch [44/50] - Loss: 0.1635
Epoch [45/50] - Loss: 0.1587
Epoch [46/50] - Loss: 0.1621
Epoch [47/50] - Loss: 0.1630
Epoch [48/50] - Loss: 0.1544
Epoch [49/50] - Loss: 0.1583
Epoch [50/50] - Loss: 0.1519
sum preds 108
sum labels 421
 - Test Metrics: Accuracy=0.8894, F1=0.3629, Recall=0.2280, Precision=0.8889
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_two_nnif_two_nnif_1804090028.csv.
Average F1 over valid seeds: 0.3243 ± 0.0273
___________________________________________________________________________________
Avg F1 for citeseer with SAR and two_nnif, GATConv,0.4: 0.3243 ± 0.0273
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2171
Epoch [2/50] - Loss: 0.7297
Epoch [3/50] - Loss: 0.5833
Epoch [4/50] - Loss: 0.5494
Epoch [5/50] - Loss: 0.5413
Epoch [6/50] - Loss: 0.5102
Epoch [7/50] - Loss: 0.4769
Epoch [8/50] - Loss: 0.4235
Epoch [9/50] - Loss: 0.3798
Epoch [10/50] - Loss: 0.3569
Epoch [11/50] - Loss: 0.3524
Epoch [12/50] - Loss: 0.3454
Epoch [13/50] - Loss: 0.3402
Epoch [14/50] - Loss: 0.3329
Epoch [15/50] - Loss: 0.3228
Epoch [16/50] - Loss: 0.3139
Epoch [17/50] - Loss: 0.3066
Epoch [18/50] - Loss: 0.2995
Epoch [19/50] - Loss: 0.2912
Epoch [20/50] - Loss: 0.2850
Epoch [21/50] - Loss: 0.2823
Epoch [22/50] - Loss: 0.2819
Epoch [23/50] - Loss: 0.2791
Epoch [24/50] - Loss: 0.2756
Epoch [25/50] - Loss: 0.2644
Epoch [26/50] - Loss: 0.2699
Epoch [27/50] - Loss: 0.2670
Epoch [28/50] - Loss: 0.2633
Epoch [29/50] - Loss: 0.2632
Epoch [30/50] - Loss: 0.2538
Epoch [31/50] - Loss: 0.2576
Epoch [32/50] - Loss: 0.2509
Epoch [33/50] - Loss: 0.2503
Epoch [34/50] - Loss: 0.2462
Epoch [35/50] - Loss: 0.2453
Epoch [36/50] - Loss: 0.2430
Epoch [37/50] - Loss: 0.2422
Epoch [38/50] - Loss: 0.2423
Epoch [39/50] - Loss: 0.2386
Epoch [40/50] - Loss: 0.2386
Epoch [41/50] - Loss: 0.2320
Epoch [42/50] - Loss: 0.2355
Epoch [43/50] - Loss: 0.2347
Epoch [44/50] - Loss: 0.2327
Epoch [45/50] - Loss: 0.2311
Epoch [46/50] - Loss: 0.2284
Epoch [47/50] - Loss: 0.2323
Epoch [48/50] - Loss: 0.2238
Epoch [49/50] - Loss: 0.2248
Epoch [50/50] - Loss: 0.2279
sum preds 82
sum labels 421
 - Test Metrics: Accuracy=0.8828, F1=0.2903, Recall=0.1734, Precision=0.8902
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1045
Epoch [2/50] - Loss: 0.5981
Epoch [3/50] - Loss: 0.5547
Epoch [4/50] - Loss: 0.5530
Epoch [5/50] - Loss: 0.4926
Epoch [6/50] - Loss: 0.4105
Epoch [7/50] - Loss: 0.3663
Epoch [8/50] - Loss: 0.3441
Epoch [9/50] - Loss: 0.3352
Epoch [10/50] - Loss: 0.3355
Epoch [11/50] - Loss: 0.3334
Epoch [12/50] - Loss: 0.3191
Epoch [13/50] - Loss: 0.3166
Epoch [14/50] - Loss: 0.3046
Epoch [15/50] - Loss: 0.2921
Epoch [16/50] - Loss: 0.2855
Epoch [17/50] - Loss: 0.2882
Epoch [18/50] - Loss: 0.2771
Epoch [19/50] - Loss: 0.2738
Epoch [20/50] - Loss: 0.2738
Epoch [21/50] - Loss: 0.2697
Epoch [22/50] - Loss: 0.2655
Epoch [23/50] - Loss: 0.2565
Epoch [24/50] - Loss: 0.2537
Epoch [25/50] - Loss: 0.2532
Epoch [26/50] - Loss: 0.2473
Epoch [27/50] - Loss: 0.2499
Epoch [28/50] - Loss: 0.2496
Epoch [29/50] - Loss: 0.2401
Epoch [30/50] - Loss: 0.2367
Epoch [31/50] - Loss: 0.2395
Epoch [32/50] - Loss: 0.2354
Epoch [33/50] - Loss: 0.2283
Epoch [34/50] - Loss: 0.2267
Epoch [35/50] - Loss: 0.2327
Epoch [36/50] - Loss: 0.2249
Epoch [37/50] - Loss: 0.2237
Epoch [38/50] - Loss: 0.2212
Epoch [39/50] - Loss: 0.2182
Epoch [40/50] - Loss: 0.2121
Epoch [41/50] - Loss: 0.2134
Epoch [42/50] - Loss: 0.2091
Epoch [43/50] - Loss: 0.2091
Epoch [44/50] - Loss: 0.2007
Epoch [45/50] - Loss: 0.2011
Epoch [46/50] - Loss: 0.2025
Epoch [47/50] - Loss: 0.1992
Epoch [48/50] - Loss: 0.1954
Epoch [49/50] - Loss: 0.1898
Epoch [50/50] - Loss: 0.1891
sum preds 119
sum labels 421
 - Test Metrics: Accuracy=0.8943, F1=0.4037, Recall=0.2589, Precision=0.9160
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1099
Epoch [2/50] - Loss: 0.5940
Epoch [3/50] - Loss: 0.5700
Epoch [4/50] - Loss: 0.5457
Epoch [5/50] - Loss: 0.4793
Epoch [6/50] - Loss: 0.4170
Epoch [7/50] - Loss: 0.3679
Epoch [8/50] - Loss: 0.3490
Epoch [9/50] - Loss: 0.3491
Epoch [10/50] - Loss: 0.3396
Epoch [11/50] - Loss: 0.3355
Epoch [12/50] - Loss: 0.3223
Epoch [13/50] - Loss: 0.3183
Epoch [14/50] - Loss: 0.3006
Epoch [15/50] - Loss: 0.3025
Epoch [16/50] - Loss: 0.2856
Epoch [17/50] - Loss: 0.2877
Epoch [18/50] - Loss: 0.2898
Epoch [19/50] - Loss: 0.2745
Epoch [20/50] - Loss: 0.2724
Epoch [21/50] - Loss: 0.2696
Epoch [22/50] - Loss: 0.2663
Epoch [23/50] - Loss: 0.2629
Epoch [24/50] - Loss: 0.2603
Epoch [25/50] - Loss: 0.2533
Epoch [26/50] - Loss: 0.2524
Epoch [27/50] - Loss: 0.2503
Epoch [28/50] - Loss: 0.2509
Epoch [29/50] - Loss: 0.2438
Epoch [30/50] - Loss: 0.2484
Epoch [31/50] - Loss: 0.2439
Epoch [32/50] - Loss: 0.2381
Epoch [33/50] - Loss: 0.2406
Epoch [34/50] - Loss: 0.2351
Epoch [35/50] - Loss: 0.2402
Epoch [36/50] - Loss: 0.2363
Epoch [37/50] - Loss: 0.2312
Epoch [38/50] - Loss: 0.2312
Epoch [39/50] - Loss: 0.2272
Epoch [40/50] - Loss: 0.2317
Epoch [41/50] - Loss: 0.2260
Epoch [42/50] - Loss: 0.2248
Epoch [43/50] - Loss: 0.2266
Epoch [44/50] - Loss: 0.2235
Epoch [45/50] - Loss: 0.2222
Epoch [46/50] - Loss: 0.2142
Epoch [47/50] - Loss: 0.2110
Epoch [48/50] - Loss: 0.2072
Epoch [49/50] - Loss: 0.2057
Epoch [50/50] - Loss: 0.1997
sum preds 135
sum labels 421
 - Test Metrics: Accuracy=0.8897, F1=0.3957, Recall=0.2613, Precision=0.8148
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_two_nnif_two_nnif_1804090133.csv.
Average F1 over valid seeds: 0.3632 ± 0.0517
___________________________________________________________________________________
Avg F1 for citeseer with SAR and two_nnif, GCNConv,0.4: 0.3632 ± 0.0517
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0977
Epoch [2/50] - Loss: 0.8548
Epoch [3/50] - Loss: 0.6565
Epoch [4/50] - Loss: 0.5237
Epoch [5/50] - Loss: 0.4557
Epoch [6/50] - Loss: 0.4396
Epoch [7/50] - Loss: 0.4252
Epoch [8/50] - Loss: 0.4192
Epoch [9/50] - Loss: 0.3824
Epoch [10/50] - Loss: 0.3599
Epoch [11/50] - Loss: 0.3216
Epoch [12/50] - Loss: 0.2907
Epoch [13/50] - Loss: 0.2727
Epoch [14/50] - Loss: 0.2530
Epoch [15/50] - Loss: 0.2427
Epoch [16/50] - Loss: 0.2340
Epoch [17/50] - Loss: 0.2244
Epoch [18/50] - Loss: 0.2198
Epoch [19/50] - Loss: 0.2083
Epoch [20/50] - Loss: 0.1953
Epoch [21/50] - Loss: 0.1915
Epoch [22/50] - Loss: 0.1799
Epoch [23/50] - Loss: 0.1685
Epoch [24/50] - Loss: 0.1621
Epoch [25/50] - Loss: 0.1592
Epoch [26/50] - Loss: 0.1529
Epoch [27/50] - Loss: 0.1478
Epoch [28/50] - Loss: 0.1432
Epoch [29/50] - Loss: 0.1396
Epoch [30/50] - Loss: 0.1343
Epoch [31/50] - Loss: 0.1385
Epoch [32/50] - Loss: 0.1358
Epoch [33/50] - Loss: 0.1305
Epoch [34/50] - Loss: 0.1313
Epoch [35/50] - Loss: 0.1296
Epoch [36/50] - Loss: 0.1259
Epoch [37/50] - Loss: 0.1247
Epoch [38/50] - Loss: 0.1258
Epoch [39/50] - Loss: 0.1217
Epoch [40/50] - Loss: 0.1242
Epoch [41/50] - Loss: 0.1199
Epoch [42/50] - Loss: 0.1200
Epoch [43/50] - Loss: 0.1210
Epoch [44/50] - Loss: 0.1145
Epoch [45/50] - Loss: 0.1172
Epoch [46/50] - Loss: 0.1166
Epoch [47/50] - Loss: 0.1173
Epoch [48/50] - Loss: 0.1154
Epoch [49/50] - Loss: 0.1124
Epoch [50/50] - Loss: 0.1106
sum preds 5
sum labels 491
 - Test Metrics: Accuracy=0.8441, F1=0.0202, Recall=0.0102, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4039
Epoch [2/50] - Loss: 0.9865
Epoch [3/50] - Loss: 0.6875
Epoch [4/50] - Loss: 0.5279
Epoch [5/50] - Loss: 0.4657
Epoch [6/50] - Loss: 0.4580
Epoch [7/50] - Loss: 0.4509
Epoch [8/50] - Loss: 0.4412
Epoch [9/50] - Loss: 0.4201
Epoch [10/50] - Loss: 0.3793
Epoch [11/50] - Loss: 0.3493
Epoch [12/50] - Loss: 0.3112
Epoch [13/50] - Loss: 0.2849
Epoch [14/50] - Loss: 0.2617
Epoch [15/50] - Loss: 0.2513
Epoch [16/50] - Loss: 0.2384
Epoch [17/50] - Loss: 0.2298
Epoch [18/50] - Loss: 0.2265
Epoch [19/50] - Loss: 0.2180
Epoch [20/50] - Loss: 0.1998
Epoch [21/50] - Loss: 0.1926
Epoch [22/50] - Loss: 0.1833
Epoch [23/50] - Loss: 0.1729
Epoch [24/50] - Loss: 0.1627
Epoch [25/50] - Loss: 0.1561
Epoch [26/50] - Loss: 0.1520
Epoch [27/50] - Loss: 0.1471
Epoch [28/50] - Loss: 0.1407
Epoch [29/50] - Loss: 0.1364
Epoch [30/50] - Loss: 0.1308
Epoch [31/50] - Loss: 0.1284
Epoch [32/50] - Loss: 0.1216
Epoch [33/50] - Loss: 0.1215
Epoch [34/50] - Loss: 0.1195
Epoch [35/50] - Loss: 0.1173
Epoch [36/50] - Loss: 0.1151
Epoch [37/50] - Loss: 0.1153
Epoch [38/50] - Loss: 0.1119
Epoch [39/50] - Loss: 0.1059
Epoch [40/50] - Loss: 0.1073
Epoch [41/50] - Loss: 0.1040
Epoch [42/50] - Loss: 0.1015
Epoch [43/50] - Loss: 0.1034
Epoch [44/50] - Loss: 0.1034
Epoch [45/50] - Loss: 0.1013
Epoch [46/50] - Loss: 0.1017
Epoch [47/50] - Loss: 0.1013
Epoch [48/50] - Loss: 0.0986
Epoch [49/50] - Loss: 0.0981
Epoch [50/50] - Loss: 0.0993
sum preds 21
sum labels 491
 - Test Metrics: Accuracy=0.8486, F1=0.0781, Recall=0.0407, Precision=0.9524
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3636
Epoch [2/50] - Loss: 0.9996
Epoch [3/50] - Loss: 0.7161
Epoch [4/50] - Loss: 0.5373
Epoch [5/50] - Loss: 0.4636
Epoch [6/50] - Loss: 0.4487
Epoch [7/50] - Loss: 0.4444
Epoch [8/50] - Loss: 0.4307
Epoch [9/50] - Loss: 0.4099
Epoch [10/50] - Loss: 0.3726
Epoch [11/50] - Loss: 0.3488
Epoch [12/50] - Loss: 0.3131
Epoch [13/50] - Loss: 0.2879
Epoch [14/50] - Loss: 0.2562
Epoch [15/50] - Loss: 0.2442
Epoch [16/50] - Loss: 0.2308
Epoch [17/50] - Loss: 0.2289
Epoch [18/50] - Loss: 0.2269
Epoch [19/50] - Loss: 0.2119
Epoch [20/50] - Loss: 0.2036
Epoch [21/50] - Loss: 0.1902
Epoch [22/50] - Loss: 0.1797
Epoch [23/50] - Loss: 0.1675
Epoch [24/50] - Loss: 0.1564
Epoch [25/50] - Loss: 0.1546
Epoch [26/50] - Loss: 0.1453
Epoch [27/50] - Loss: 0.1416
Epoch [28/50] - Loss: 0.1359
Epoch [29/50] - Loss: 0.1284
Epoch [30/50] - Loss: 0.1257
Epoch [31/50] - Loss: 0.1218
Epoch [32/50] - Loss: 0.1158
Epoch [33/50] - Loss: 0.1171
Epoch [34/50] - Loss: 0.1119
Epoch [35/50] - Loss: 0.1103
Epoch [36/50] - Loss: 0.1104
Epoch [37/50] - Loss: 0.1105
Epoch [38/50] - Loss: 0.1098
Epoch [39/50] - Loss: 0.1070
Epoch [40/50] - Loss: 0.0994
Epoch [41/50] - Loss: 0.1026
Epoch [42/50] - Loss: 0.1038
Epoch [43/50] - Loss: 0.1035
Epoch [44/50] - Loss: 0.0995
Epoch [45/50] - Loss: 0.1010
Epoch [46/50] - Loss: 0.1014
Epoch [47/50] - Loss: 0.0993
Epoch [48/50] - Loss: 0.0985
Epoch [49/50] - Loss: 0.0945
Epoch [50/50] - Loss: 0.0992
sum preds 21
sum labels 491
 - Test Metrics: Accuracy=0.8479, F1=0.0742, Recall=0.0387, Precision=0.9048
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_two_nnif_two_nnif_1804090235.csv.
Average F1 over valid seeds: 0.0575 ± 0.0265
___________________________________________________________________________________
Avg F1 for citeseer with SAR and two_nnif, MLP,0.3: 0.0575 ± 0.0265
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2304
Epoch [2/50] - Loss: 0.6979
Epoch [3/50] - Loss: 0.4983
Epoch [4/50] - Loss: 0.4561
Epoch [5/50] - Loss: 0.4517
Epoch [6/50] - Loss: 0.4381
Epoch [7/50] - Loss: 0.4261
Epoch [8/50] - Loss: 0.3824
Epoch [9/50] - Loss: 0.3463
Epoch [10/50] - Loss: 0.3204
Epoch [11/50] - Loss: 0.2879
Epoch [12/50] - Loss: 0.2817
Epoch [13/50] - Loss: 0.2707
Epoch [14/50] - Loss: 0.2708
Epoch [15/50] - Loss: 0.2727
Epoch [16/50] - Loss: 0.2592
Epoch [17/50] - Loss: 0.2521
Epoch [18/50] - Loss: 0.2384
Epoch [19/50] - Loss: 0.2255
Epoch [20/50] - Loss: 0.2259
Epoch [21/50] - Loss: 0.2176
Epoch [22/50] - Loss: 0.2098
Epoch [23/50] - Loss: 0.2033
Epoch [24/50] - Loss: 0.2037
Epoch [25/50] - Loss: 0.1943
Epoch [26/50] - Loss: 0.1874
Epoch [27/50] - Loss: 0.1861
Epoch [28/50] - Loss: 0.1821
Epoch [29/50] - Loss: 0.1810
Epoch [30/50] - Loss: 0.1859
Epoch [31/50] - Loss: 0.1739
Epoch [32/50] - Loss: 0.1718
Epoch [33/50] - Loss: 0.1624
Epoch [34/50] - Loss: 0.1686
Epoch [35/50] - Loss: 0.1600
Epoch [36/50] - Loss: 0.1603
Epoch [37/50] - Loss: 0.1577
Epoch [38/50] - Loss: 0.1563
Epoch [39/50] - Loss: 0.1584
Epoch [40/50] - Loss: 0.1498
Epoch [41/50] - Loss: 0.1439
Epoch [42/50] - Loss: 0.1497
Epoch [43/50] - Loss: 0.1486
Epoch [44/50] - Loss: 0.1538
Epoch [45/50] - Loss: 0.1469
Epoch [46/50] - Loss: 0.1442
Epoch [47/50] - Loss: 0.1407
Epoch [48/50] - Loss: 0.1394
Epoch [49/50] - Loss: 0.1415
Epoch [50/50] - Loss: 0.1424
sum preds 73
sum labels 491
 - Test Metrics: Accuracy=0.8633, F1=0.2447, Recall=0.1405, Precision=0.9452
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1380
Epoch [2/50] - Loss: 0.5754
Epoch [3/50] - Loss: 0.4697
Epoch [4/50] - Loss: 0.4730
Epoch [5/50] - Loss: 0.4625
Epoch [6/50] - Loss: 0.4292
Epoch [7/50] - Loss: 0.3747
Epoch [8/50] - Loss: 0.3324
Epoch [9/50] - Loss: 0.2961
Epoch [10/50] - Loss: 0.2842
Epoch [11/50] - Loss: 0.2838
Epoch [12/50] - Loss: 0.2795
Epoch [13/50] - Loss: 0.2737
Epoch [14/50] - Loss: 0.2679
Epoch [15/50] - Loss: 0.2603
Epoch [16/50] - Loss: 0.2440
Epoch [17/50] - Loss: 0.2380
Epoch [18/50] - Loss: 0.2300
Epoch [19/50] - Loss: 0.2241
Epoch [20/50] - Loss: 0.2214
Epoch [21/50] - Loss: 0.2112
Epoch [22/50] - Loss: 0.2083
Epoch [23/50] - Loss: 0.1984
Epoch [24/50] - Loss: 0.1904
Epoch [25/50] - Loss: 0.1879
Epoch [26/50] - Loss: 0.1790
Epoch [27/50] - Loss: 0.1752
Epoch [28/50] - Loss: 0.1753
Epoch [29/50] - Loss: 0.1693
Epoch [30/50] - Loss: 0.1628
Epoch [31/50] - Loss: 0.1674
Epoch [32/50] - Loss: 0.1617
Epoch [33/50] - Loss: 0.1516
Epoch [34/50] - Loss: 0.1499
Epoch [35/50] - Loss: 0.1541
Epoch [36/50] - Loss: 0.1451
Epoch [37/50] - Loss: 0.1380
Epoch [38/50] - Loss: 0.1418
Epoch [39/50] - Loss: 0.1447
Epoch [40/50] - Loss: 0.1366
Epoch [41/50] - Loss: 0.1438
Epoch [42/50] - Loss: 0.1324
Epoch [43/50] - Loss: 0.1367
Epoch [44/50] - Loss: 0.1388
Epoch [45/50] - Loss: 0.1324
Epoch [46/50] - Loss: 0.1365
Epoch [47/50] - Loss: 0.1346
Epoch [48/50] - Loss: 0.1264
Epoch [49/50] - Loss: 0.1205
Epoch [50/50] - Loss: 0.1276
sum preds 70
sum labels 491
 - Test Metrics: Accuracy=0.8604, F1=0.2246, Recall=0.1283, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1800
Epoch [2/50] - Loss: 0.6330
Epoch [3/50] - Loss: 0.4690
Epoch [4/50] - Loss: 0.4630
Epoch [5/50] - Loss: 0.4749
Epoch [6/50] - Loss: 0.4447
Epoch [7/50] - Loss: 0.4042
Epoch [8/50] - Loss: 0.3580
Epoch [9/50] - Loss: 0.3114
Epoch [10/50] - Loss: 0.3032
Epoch [11/50] - Loss: 0.2781
Epoch [12/50] - Loss: 0.2902
Epoch [13/50] - Loss: 0.2830
Epoch [14/50] - Loss: 0.2798
Epoch [15/50] - Loss: 0.2679
Epoch [16/50] - Loss: 0.2597
Epoch [17/50] - Loss: 0.2475
Epoch [18/50] - Loss: 0.2430
Epoch [19/50] - Loss: 0.2384
Epoch [20/50] - Loss: 0.2267
Epoch [21/50] - Loss: 0.2356
Epoch [22/50] - Loss: 0.2246
Epoch [23/50] - Loss: 0.2152
Epoch [24/50] - Loss: 0.2112
Epoch [25/50] - Loss: 0.2144
Epoch [26/50] - Loss: 0.2035
Epoch [27/50] - Loss: 0.1990
Epoch [28/50] - Loss: 0.1946
Epoch [29/50] - Loss: 0.1952
Epoch [30/50] - Loss: 0.1976
Epoch [31/50] - Loss: 0.1867
Epoch [32/50] - Loss: 0.1910
Epoch [33/50] - Loss: 0.1849
Epoch [34/50] - Loss: 0.1876
Epoch [35/50] - Loss: 0.1761
Epoch [36/50] - Loss: 0.1798
Epoch [37/50] - Loss: 0.1770
Epoch [38/50] - Loss: 0.1778
Epoch [39/50] - Loss: 0.1738
Epoch [40/50] - Loss: 0.1723
Epoch [41/50] - Loss: 0.1732
Epoch [42/50] - Loss: 0.1651
Epoch [43/50] - Loss: 0.1676
Epoch [44/50] - Loss: 0.1655
Epoch [45/50] - Loss: 0.1691
Epoch [46/50] - Loss: 0.1537
Epoch [47/50] - Loss: 0.1609
Epoch [48/50] - Loss: 0.1547
Epoch [49/50] - Loss: 0.1547
Epoch [50/50] - Loss: 0.1528
sum preds 85
sum labels 491
 - Test Metrics: Accuracy=0.8627, F1=0.2569, Recall=0.1507, Precision=0.8706
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_two_nnif_two_nnif_1804090338.csv.
Average F1 over valid seeds: 0.2421 ± 0.0133
___________________________________________________________________________________
Avg F1 for citeseer with SAR and two_nnif, GATConv,0.3: 0.2421 ± 0.0133
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2035
Epoch [2/50] - Loss: 0.6813
Epoch [3/50] - Loss: 0.5023
Epoch [4/50] - Loss: 0.4729
Epoch [5/50] - Loss: 0.4629
Epoch [6/50] - Loss: 0.4609
Epoch [7/50] - Loss: 0.4343
Epoch [8/50] - Loss: 0.3950
Epoch [9/50] - Loss: 0.3480
Epoch [10/50] - Loss: 0.3181
Epoch [11/50] - Loss: 0.3017
Epoch [12/50] - Loss: 0.2942
Epoch [13/50] - Loss: 0.2868
Epoch [14/50] - Loss: 0.2777
Epoch [15/50] - Loss: 0.2827
Epoch [16/50] - Loss: 0.2721
Epoch [17/50] - Loss: 0.2682
Epoch [18/50] - Loss: 0.2558
Epoch [19/50] - Loss: 0.2542
Epoch [20/50] - Loss: 0.2451
Epoch [21/50] - Loss: 0.2373
Epoch [22/50] - Loss: 0.2312
Epoch [23/50] - Loss: 0.2324
Epoch [24/50] - Loss: 0.2316
Epoch [25/50] - Loss: 0.2265
Epoch [26/50] - Loss: 0.2274
Epoch [27/50] - Loss: 0.2276
Epoch [28/50] - Loss: 0.2182
Epoch [29/50] - Loss: 0.2177
Epoch [30/50] - Loss: 0.2179
Epoch [31/50] - Loss: 0.2098
Epoch [32/50] - Loss: 0.2089
Epoch [33/50] - Loss: 0.2057
Epoch [34/50] - Loss: 0.2035
Epoch [35/50] - Loss: 0.2042
Epoch [36/50] - Loss: 0.2076
Epoch [37/50] - Loss: 0.1995
Epoch [38/50] - Loss: 0.2004
Epoch [39/50] - Loss: 0.2014
Epoch [40/50] - Loss: 0.1989
Epoch [41/50] - Loss: 0.1978
Epoch [42/50] - Loss: 0.2003
Epoch [43/50] - Loss: 0.1943
Epoch [44/50] - Loss: 0.1949
Epoch [45/50] - Loss: 0.1942
Epoch [46/50] - Loss: 0.1887
Epoch [47/50] - Loss: 0.1915
Epoch [48/50] - Loss: 0.1884
Epoch [49/50] - Loss: 0.1870
Epoch [50/50] - Loss: 0.1892
sum preds 0
sum labels 491
 - Test Metrics: Accuracy=0.8425, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0977
Epoch [2/50] - Loss: 0.5444
Epoch [3/50] - Loss: 0.4837
Epoch [4/50] - Loss: 0.4716
Epoch [5/50] - Loss: 0.4535
Epoch [6/50] - Loss: 0.4025
Epoch [7/50] - Loss: 0.3488
Epoch [8/50] - Loss: 0.3051
Epoch [9/50] - Loss: 0.2916
Epoch [10/50] - Loss: 0.2901
Epoch [11/50] - Loss: 0.2878
Epoch [12/50] - Loss: 0.2883
Epoch [13/50] - Loss: 0.2755
Epoch [14/50] - Loss: 0.2731
Epoch [15/50] - Loss: 0.2547
Epoch [16/50] - Loss: 0.2527
Epoch [17/50] - Loss: 0.2400
Epoch [18/50] - Loss: 0.2414
Epoch [19/50] - Loss: 0.2334
Epoch [20/50] - Loss: 0.2266
Epoch [21/50] - Loss: 0.2290
Epoch [22/50] - Loss: 0.2256
Epoch [23/50] - Loss: 0.2242
Epoch [24/50] - Loss: 0.2196
Epoch [25/50] - Loss: 0.2148
Epoch [26/50] - Loss: 0.2139
Epoch [27/50] - Loss: 0.2138
Epoch [28/50] - Loss: 0.2133
Epoch [29/50] - Loss: 0.2103
Epoch [30/50] - Loss: 0.2093
Epoch [31/50] - Loss: 0.2053
Epoch [32/50] - Loss: 0.2020
Epoch [33/50] - Loss: 0.2006
Epoch [34/50] - Loss: 0.1981
Epoch [35/50] - Loss: 0.1992
Epoch [36/50] - Loss: 0.2006
Epoch [37/50] - Loss: 0.1968
Epoch [38/50] - Loss: 0.1941
Epoch [39/50] - Loss: 0.1951
Epoch [40/50] - Loss: 0.1925
Epoch [41/50] - Loss: 0.1964
Epoch [42/50] - Loss: 0.1906
Epoch [43/50] - Loss: 0.1870
Epoch [44/50] - Loss: 0.1883
Epoch [45/50] - Loss: 0.1896
Epoch [46/50] - Loss: 0.1901
Epoch [47/50] - Loss: 0.1871
Epoch [48/50] - Loss: 0.1834
Epoch [49/50] - Loss: 0.1894
Epoch [50/50] - Loss: 0.1888
sum preds 51
sum labels 491
 - Test Metrics: Accuracy=0.8563, F1=0.1734, Recall=0.0957, Precision=0.9216
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0915
Epoch [2/50] - Loss: 0.5314
Epoch [3/50] - Loss: 0.4815
Epoch [4/50] - Loss: 0.4974
Epoch [5/50] - Loss: 0.4689
Epoch [6/50] - Loss: 0.4212
Epoch [7/50] - Loss: 0.3538
Epoch [8/50] - Loss: 0.3151
Epoch [9/50] - Loss: 0.2974
Epoch [10/50] - Loss: 0.2990
Epoch [11/50] - Loss: 0.2980
Epoch [12/50] - Loss: 0.2987
Epoch [13/50] - Loss: 0.2916
Epoch [14/50] - Loss: 0.2714
Epoch [15/50] - Loss: 0.2645
Epoch [16/50] - Loss: 0.2536
Epoch [17/50] - Loss: 0.2521
Epoch [18/50] - Loss: 0.2442
Epoch [19/50] - Loss: 0.2403
Epoch [20/50] - Loss: 0.2304
Epoch [21/50] - Loss: 0.2332
Epoch [22/50] - Loss: 0.2322
Epoch [23/50] - Loss: 0.2283
Epoch [24/50] - Loss: 0.2189
Epoch [25/50] - Loss: 0.2222
Epoch [26/50] - Loss: 0.2198
Epoch [27/50] - Loss: 0.2167
Epoch [28/50] - Loss: 0.2110
Epoch [29/50] - Loss: 0.2141
Epoch [30/50] - Loss: 0.2094
Epoch [31/50] - Loss: 0.2090
Epoch [32/50] - Loss: 0.2075
Epoch [33/50] - Loss: 0.2044
Epoch [34/50] - Loss: 0.2038
Epoch [35/50] - Loss: 0.2075
Epoch [36/50] - Loss: 0.2022
Epoch [37/50] - Loss: 0.1956
Epoch [38/50] - Loss: 0.1942
Epoch [39/50] - Loss: 0.1993
Epoch [40/50] - Loss: 0.1942
Epoch [41/50] - Loss: 0.1958
Epoch [42/50] - Loss: 0.1949
Epoch [43/50] - Loss: 0.1951
Epoch [44/50] - Loss: 0.1922
Epoch [45/50] - Loss: 0.1901
Epoch [46/50] - Loss: 0.1930
Epoch [47/50] - Loss: 0.1899
Epoch [48/50] - Loss: 0.1891
Epoch [49/50] - Loss: 0.1904
Epoch [50/50] - Loss: 0.1906
sum preds 61
sum labels 491
 - Test Metrics: Accuracy=0.8582, F1=0.1993, Recall=0.1120, Precision=0.9016
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_two_nnif_two_nnif_1804090442.csv.
Average F1 over valid seeds: 0.1242 ± 0.0885
___________________________________________________________________________________
Avg F1 for citeseer with SAR and two_nnif, GCNConv,0.3: 0.1242 ± 0.0885
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0816
Epoch [2/50] - Loss: 0.8244
Epoch [3/50] - Loss: 0.6035
Epoch [4/50] - Loss: 0.4511
Epoch [5/50] - Loss: 0.3773
Epoch [6/50] - Loss: 0.3319
Epoch [7/50] - Loss: 0.3387
Epoch [8/50] - Loss: 0.3273
Epoch [9/50] - Loss: 0.3213
Epoch [10/50] - Loss: 0.3051
Epoch [11/50] - Loss: 0.2849
Epoch [12/50] - Loss: 0.2554
Epoch [13/50] - Loss: 0.2273
Epoch [14/50] - Loss: 0.2080
Epoch [15/50] - Loss: 0.1962
Epoch [16/50] - Loss: 0.1827
Epoch [17/50] - Loss: 0.1740
Epoch [18/50] - Loss: 0.1684
Epoch [19/50] - Loss: 0.1613
Epoch [20/50] - Loss: 0.1595
Epoch [21/50] - Loss: 0.1502
Epoch [22/50] - Loss: 0.1473
Epoch [23/50] - Loss: 0.1308
Epoch [24/50] - Loss: 0.1312
Epoch [25/50] - Loss: 0.1197
Epoch [26/50] - Loss: 0.1184
Epoch [27/50] - Loss: 0.1114
Epoch [28/50] - Loss: 0.1098
Epoch [29/50] - Loss: 0.1098
Epoch [30/50] - Loss: 0.1057
Epoch [31/50] - Loss: 0.1019
Epoch [32/50] - Loss: 0.1010
Epoch [33/50] - Loss: 0.0966
Epoch [34/50] - Loss: 0.0948
Epoch [35/50] - Loss: 0.0927
Epoch [36/50] - Loss: 0.0892
Epoch [37/50] - Loss: 0.0902
Epoch [38/50] - Loss: 0.0905
Epoch [39/50] - Loss: 0.0900
Epoch [40/50] - Loss: 0.0915
Epoch [41/50] - Loss: 0.0917
Epoch [42/50] - Loss: 0.0886
Epoch [43/50] - Loss: 0.0873
Epoch [44/50] - Loss: 0.0864
Epoch [45/50] - Loss: 0.0865
Epoch [46/50] - Loss: 0.0883
Epoch [47/50] - Loss: 0.0857
Epoch [48/50] - Loss: 0.0860
Epoch [49/50] - Loss: 0.0841
Epoch [50/50] - Loss: 0.0822
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4053
Epoch [2/50] - Loss: 0.9632
Epoch [3/50] - Loss: 0.6469
Epoch [4/50] - Loss: 0.4627
Epoch [5/50] - Loss: 0.3773
Epoch [6/50] - Loss: 0.3438
Epoch [7/50] - Loss: 0.3575
Epoch [8/50] - Loss: 0.3507
Epoch [9/50] - Loss: 0.3441
Epoch [10/50] - Loss: 0.3217
Epoch [11/50] - Loss: 0.3025
Epoch [12/50] - Loss: 0.2826
Epoch [13/50] - Loss: 0.2473
Epoch [14/50] - Loss: 0.2212
Epoch [15/50] - Loss: 0.2064
Epoch [16/50] - Loss: 0.1890
Epoch [17/50] - Loss: 0.1749
Epoch [18/50] - Loss: 0.1683
Epoch [19/50] - Loss: 0.1629
Epoch [20/50] - Loss: 0.1556
Epoch [21/50] - Loss: 0.1514
Epoch [22/50] - Loss: 0.1433
Epoch [23/50] - Loss: 0.1376
Epoch [24/50] - Loss: 0.1337
Epoch [25/50] - Loss: 0.1255
Epoch [26/50] - Loss: 0.1192
Epoch [27/50] - Loss: 0.1138
Epoch [28/50] - Loss: 0.1081
Epoch [29/50] - Loss: 0.1014
Epoch [30/50] - Loss: 0.0975
Epoch [31/50] - Loss: 0.0943
Epoch [32/50] - Loss: 0.0946
Epoch [33/50] - Loss: 0.0895
Epoch [34/50] - Loss: 0.0880
Epoch [35/50] - Loss: 0.0861
Epoch [36/50] - Loss: 0.0804
Epoch [37/50] - Loss: 0.0824
Epoch [38/50] - Loss: 0.0810
Epoch [39/50] - Loss: 0.0773
Epoch [40/50] - Loss: 0.0769
Epoch [41/50] - Loss: 0.0768
Epoch [42/50] - Loss: 0.0772
Epoch [43/50] - Loss: 0.0753
Epoch [44/50] - Loss: 0.0752
Epoch [45/50] - Loss: 0.0733
Epoch [46/50] - Loss: 0.0710
Epoch [47/50] - Loss: 0.0737
Epoch [48/50] - Loss: 0.0709
Epoch [49/50] - Loss: 0.0670
Epoch [50/50] - Loss: 0.0699
sum preds 7
sum labels 561
 - Test Metrics: Accuracy=0.8262, F1=0.0246, Recall=0.0125, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3635
Epoch [2/50] - Loss: 0.9799
Epoch [3/50] - Loss: 0.6683
Epoch [4/50] - Loss: 0.4756
Epoch [5/50] - Loss: 0.3827
Epoch [6/50] - Loss: 0.3512
Epoch [7/50] - Loss: 0.3537
Epoch [8/50] - Loss: 0.3415
Epoch [9/50] - Loss: 0.3383
Epoch [10/50] - Loss: 0.3201
Epoch [11/50] - Loss: 0.2916
Epoch [12/50] - Loss: 0.2755
Epoch [13/50] - Loss: 0.2431
Epoch [14/50] - Loss: 0.2178
Epoch [15/50] - Loss: 0.2010
Epoch [16/50] - Loss: 0.1884
Epoch [17/50] - Loss: 0.1714
Epoch [18/50] - Loss: 0.1638
Epoch [19/50] - Loss: 0.1659
Epoch [20/50] - Loss: 0.1567
Epoch [21/50] - Loss: 0.1534
Epoch [22/50] - Loss: 0.1457
Epoch [23/50] - Loss: 0.1372
Epoch [24/50] - Loss: 0.1294
Epoch [25/50] - Loss: 0.1223
Epoch [26/50] - Loss: 0.1143
Epoch [27/50] - Loss: 0.1083
Epoch [28/50] - Loss: 0.1044
Epoch [29/50] - Loss: 0.1010
Epoch [30/50] - Loss: 0.0997
Epoch [31/50] - Loss: 0.0951
Epoch [32/50] - Loss: 0.0926
Epoch [33/50] - Loss: 0.0876
Epoch [34/50] - Loss: 0.0854
Epoch [35/50] - Loss: 0.0831
Epoch [36/50] - Loss: 0.0816
Epoch [37/50] - Loss: 0.0806
Epoch [38/50] - Loss: 0.0778
Epoch [39/50] - Loss: 0.0774
Epoch [40/50] - Loss: 0.0783
Epoch [41/50] - Loss: 0.0750
Epoch [42/50] - Loss: 0.0744
Epoch [43/50] - Loss: 0.0751
Epoch [44/50] - Loss: 0.0756
Epoch [45/50] - Loss: 0.0750
Epoch [46/50] - Loss: 0.0727
Epoch [47/50] - Loss: 0.0714
Epoch [48/50] - Loss: 0.0718
Epoch [49/50] - Loss: 0.0708
Epoch [50/50] - Loss: 0.0711
sum preds 10
sum labels 561
 - Test Metrics: Accuracy=0.8265, F1=0.0315, Recall=0.0160, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_two_nnif_two_nnif_1804090550.csv.
Average F1 over valid seeds: 0.0187 ± 0.0135
___________________________________________________________________________________
Avg F1 for citeseer with SAR and two_nnif, MLP,0.2: 0.0187 ± 0.0135
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2185
Epoch [2/50] - Loss: 0.6480
Epoch [3/50] - Loss: 0.4104
Epoch [4/50] - Loss: 0.3535
Epoch [5/50] - Loss: 0.3491
Epoch [6/50] - Loss: 0.3680
Epoch [7/50] - Loss: 0.3524
Epoch [8/50] - Loss: 0.3424
Epoch [9/50] - Loss: 0.3164
Epoch [10/50] - Loss: 0.3035
Epoch [11/50] - Loss: 0.2780
Epoch [12/50] - Loss: 0.2514
Epoch [13/50] - Loss: 0.2252
Epoch [14/50] - Loss: 0.2194
Epoch [15/50] - Loss: 0.2177
Epoch [16/50] - Loss: 0.2099
Epoch [17/50] - Loss: 0.2069
Epoch [18/50] - Loss: 0.2081
Epoch [19/50] - Loss: 0.1977
Epoch [20/50] - Loss: 0.1932
Epoch [21/50] - Loss: 0.1865
Epoch [22/50] - Loss: 0.1750
Epoch [23/50] - Loss: 0.1739
Epoch [24/50] - Loss: 0.1660
Epoch [25/50] - Loss: 0.1657
Epoch [26/50] - Loss: 0.1567
Epoch [27/50] - Loss: 0.1577
Epoch [28/50] - Loss: 0.1509
Epoch [29/50] - Loss: 0.1468
Epoch [30/50] - Loss: 0.1458
Epoch [31/50] - Loss: 0.1418
Epoch [32/50] - Loss: 0.1389
Epoch [33/50] - Loss: 0.1380
Epoch [34/50] - Loss: 0.1306
Epoch [35/50] - Loss: 0.1299
Epoch [36/50] - Loss: 0.1300
Epoch [37/50] - Loss: 0.1353
Epoch [38/50] - Loss: 0.1284
Epoch [39/50] - Loss: 0.1310
Epoch [40/50] - Loss: 0.1237
Epoch [41/50] - Loss: 0.1182
Epoch [42/50] - Loss: 0.1247
Epoch [43/50] - Loss: 0.1218
Epoch [44/50] - Loss: 0.1232
Epoch [45/50] - Loss: 0.1189
Epoch [46/50] - Loss: 0.1135
Epoch [47/50] - Loss: 0.1192
Epoch [48/50] - Loss: 0.1183
Epoch [49/50] - Loss: 0.1154
Epoch [50/50] - Loss: 0.1074
sum preds 10
sum labels 561
 - Test Metrics: Accuracy=0.8265, F1=0.0315, Recall=0.0160, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1181
Epoch [2/50] - Loss: 0.5053
Epoch [3/50] - Loss: 0.3503
Epoch [4/50] - Loss: 0.3695
Epoch [5/50] - Loss: 0.3804
Epoch [6/50] - Loss: 0.3514
Epoch [7/50] - Loss: 0.3399
Epoch [8/50] - Loss: 0.3064
Epoch [9/50] - Loss: 0.2606
Epoch [10/50] - Loss: 0.2305
Epoch [11/50] - Loss: 0.2119
Epoch [12/50] - Loss: 0.2069
Epoch [13/50] - Loss: 0.2058
Epoch [14/50] - Loss: 0.2052
Epoch [15/50] - Loss: 0.1979
Epoch [16/50] - Loss: 0.1925
Epoch [17/50] - Loss: 0.1843
Epoch [18/50] - Loss: 0.1752
Epoch [19/50] - Loss: 0.1724
Epoch [20/50] - Loss: 0.1652
Epoch [21/50] - Loss: 0.1579
Epoch [22/50] - Loss: 0.1581
Epoch [23/50] - Loss: 0.1533
Epoch [24/50] - Loss: 0.1504
Epoch [25/50] - Loss: 0.1405
Epoch [26/50] - Loss: 0.1448
Epoch [27/50] - Loss: 0.1361
Epoch [28/50] - Loss: 0.1385
Epoch [29/50] - Loss: 0.1311
Epoch [30/50] - Loss: 0.1243
Epoch [31/50] - Loss: 0.1267
Epoch [32/50] - Loss: 0.1202
Epoch [33/50] - Loss: 0.1242
Epoch [34/50] - Loss: 0.1166
Epoch [35/50] - Loss: 0.1150
Epoch [36/50] - Loss: 0.1151
Epoch [37/50] - Loss: 0.1090
Epoch [38/50] - Loss: 0.1071
Epoch [39/50] - Loss: 0.1050
Epoch [40/50] - Loss: 0.1005
Epoch [41/50] - Loss: 0.1048
Epoch [42/50] - Loss: 0.1041
Epoch [43/50] - Loss: 0.1036
Epoch [44/50] - Loss: 0.0993
Epoch [45/50] - Loss: 0.1089
Epoch [46/50] - Loss: 0.0988
Epoch [47/50] - Loss: 0.0977
Epoch [48/50] - Loss: 0.0960
Epoch [49/50] - Loss: 0.0986
Epoch [50/50] - Loss: 0.0949
sum preds 66
sum labels 561
 - Test Metrics: Accuracy=0.8372, F1=0.1722, Recall=0.0963, Precision=0.8182
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1703
Epoch [2/50] - Loss: 0.5764
Epoch [3/50] - Loss: 0.3743
Epoch [4/50] - Loss: 0.3563
Epoch [5/50] - Loss: 0.3810
Epoch [6/50] - Loss: 0.3811
Epoch [7/50] - Loss: 0.3626
Epoch [8/50] - Loss: 0.3321
Epoch [9/50] - Loss: 0.2948
Epoch [10/50] - Loss: 0.2562
Epoch [11/50] - Loss: 0.2360
Epoch [12/50] - Loss: 0.2235
Epoch [13/50] - Loss: 0.2194
Epoch [14/50] - Loss: 0.2240
Epoch [15/50] - Loss: 0.2263
Epoch [16/50] - Loss: 0.2104
Epoch [17/50] - Loss: 0.2107
Epoch [18/50] - Loss: 0.2009
Epoch [19/50] - Loss: 0.1937
Epoch [20/50] - Loss: 0.1849
Epoch [21/50] - Loss: 0.1829
Epoch [22/50] - Loss: 0.1806
Epoch [23/50] - Loss: 0.1744
Epoch [24/50] - Loss: 0.1749
Epoch [25/50] - Loss: 0.1706
Epoch [26/50] - Loss: 0.1651
Epoch [27/50] - Loss: 0.1600
Epoch [28/50] - Loss: 0.1613
Epoch [29/50] - Loss: 0.1567
Epoch [30/50] - Loss: 0.1505
Epoch [31/50] - Loss: 0.1571
Epoch [32/50] - Loss: 0.1553
Epoch [33/50] - Loss: 0.1448
Epoch [34/50] - Loss: 0.1484
Epoch [35/50] - Loss: 0.1430
Epoch [36/50] - Loss: 0.1440
Epoch [37/50] - Loss: 0.1373
Epoch [38/50] - Loss: 0.1360
Epoch [39/50] - Loss: 0.1362
Epoch [40/50] - Loss: 0.1375
Epoch [41/50] - Loss: 0.1371
Epoch [42/50] - Loss: 0.1285
Epoch [43/50] - Loss: 0.1229
Epoch [44/50] - Loss: 0.1254
Epoch [45/50] - Loss: 0.1268
Epoch [46/50] - Loss: 0.1299
Epoch [47/50] - Loss: 0.1240
Epoch [48/50] - Loss: 0.1276
Epoch [49/50] - Loss: 0.1160
Epoch [50/50] - Loss: 0.1181
sum preds 56
sum labels 561
 - Test Metrics: Accuracy=0.8378, F1=0.1621, Recall=0.0891, Precision=0.8929
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_two_nnif_two_nnif_1804090651.csv.
Average F1 over valid seeds: 0.1219 ± 0.0641
___________________________________________________________________________________
Avg F1 for citeseer with SAR and two_nnif, GATConv,0.2: 0.1219 ± 0.0641
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1953
Epoch [2/50] - Loss: 0.6306
Epoch [3/50] - Loss: 0.4180
Epoch [4/50] - Loss: 0.3627
Epoch [5/50] - Loss: 0.3632
Epoch [6/50] - Loss: 0.3839
Epoch [7/50] - Loss: 0.3771
Epoch [8/50] - Loss: 0.3551
Epoch [9/50] - Loss: 0.3238
Epoch [10/50] - Loss: 0.2950
Epoch [11/50] - Loss: 0.2708
Epoch [12/50] - Loss: 0.2547
Epoch [13/50] - Loss: 0.2369
Epoch [14/50] - Loss: 0.2279
Epoch [15/50] - Loss: 0.2267
Epoch [16/50] - Loss: 0.2234
Epoch [17/50] - Loss: 0.2240
Epoch [18/50] - Loss: 0.2188
Epoch [19/50] - Loss: 0.2140
Epoch [20/50] - Loss: 0.2132
Epoch [21/50] - Loss: 0.2009
Epoch [22/50] - Loss: 0.1981
Epoch [23/50] - Loss: 0.1931
Epoch [24/50] - Loss: 0.1867
Epoch [25/50] - Loss: 0.1853
Epoch [26/50] - Loss: 0.1888
Epoch [27/50] - Loss: 0.1825
Epoch [28/50] - Loss: 0.1803
Epoch [29/50] - Loss: 0.1747
Epoch [30/50] - Loss: 0.1730
Epoch [31/50] - Loss: 0.1751
Epoch [32/50] - Loss: 0.1707
Epoch [33/50] - Loss: 0.1641
Epoch [34/50] - Loss: 0.1680
Epoch [35/50] - Loss: 0.1642
Epoch [36/50] - Loss: 0.1623
Epoch [37/50] - Loss: 0.1601
Epoch [38/50] - Loss: 0.1633
Epoch [39/50] - Loss: 0.1615
Epoch [40/50] - Loss: 0.1586
Epoch [41/50] - Loss: 0.1556
Epoch [42/50] - Loss: 0.1556
Epoch [43/50] - Loss: 0.1532
Epoch [44/50] - Loss: 0.1530
Epoch [45/50] - Loss: 0.1536
Epoch [46/50] - Loss: 0.1530
Epoch [47/50] - Loss: 0.1494
Epoch [48/50] - Loss: 0.1497
Epoch [49/50] - Loss: 0.1507
Epoch [50/50] - Loss: 0.1516
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0798
Epoch [2/50] - Loss: 0.4631
Epoch [3/50] - Loss: 0.3729
Epoch [4/50] - Loss: 0.3628
Epoch [5/50] - Loss: 0.3801
Epoch [6/50] - Loss: 0.3448
Epoch [7/50] - Loss: 0.3290
Epoch [8/50] - Loss: 0.2879
Epoch [9/50] - Loss: 0.2484
Epoch [10/50] - Loss: 0.2328
Epoch [11/50] - Loss: 0.2096
Epoch [12/50] - Loss: 0.2102
Epoch [13/50] - Loss: 0.2111
Epoch [14/50] - Loss: 0.2168
Epoch [15/50] - Loss: 0.2089
Epoch [16/50] - Loss: 0.1985
Epoch [17/50] - Loss: 0.1939
Epoch [18/50] - Loss: 0.1864
Epoch [19/50] - Loss: 0.1787
Epoch [20/50] - Loss: 0.1729
Epoch [21/50] - Loss: 0.1676
Epoch [22/50] - Loss: 0.1681
Epoch [23/50] - Loss: 0.1669
Epoch [24/50] - Loss: 0.1595
Epoch [25/50] - Loss: 0.1622
Epoch [26/50] - Loss: 0.1547
Epoch [27/50] - Loss: 0.1501
Epoch [28/50] - Loss: 0.1565
Epoch [29/50] - Loss: 0.1507
Epoch [30/50] - Loss: 0.1476
Epoch [31/50] - Loss: 0.1463
Epoch [32/50] - Loss: 0.1458
Epoch [33/50] - Loss: 0.1502
Epoch [34/50] - Loss: 0.1445
Epoch [35/50] - Loss: 0.1402
Epoch [36/50] - Loss: 0.1384
Epoch [37/50] - Loss: 0.1393
Epoch [38/50] - Loss: 0.1434
Epoch [39/50] - Loss: 0.1411
Epoch [40/50] - Loss: 0.1348
Epoch [41/50] - Loss: 0.1369
Epoch [42/50] - Loss: 0.1392
Epoch [43/50] - Loss: 0.1340
Epoch [44/50] - Loss: 0.1391
Epoch [45/50] - Loss: 0.1341
Epoch [46/50] - Loss: 0.1320
Epoch [47/50] - Loss: 0.1307
Epoch [48/50] - Loss: 0.1305
Epoch [49/50] - Loss: 0.1302
Epoch [50/50] - Loss: 0.1335
sum preds 7
sum labels 561
 - Test Metrics: Accuracy=0.8262, F1=0.0246, Recall=0.0125, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0756
Epoch [2/50] - Loss: 0.4559
Epoch [3/50] - Loss: 0.3692
Epoch [4/50] - Loss: 0.3983
Epoch [5/50] - Loss: 0.4070
Epoch [6/50] - Loss: 0.3770
Epoch [7/50] - Loss: 0.3419
Epoch [8/50] - Loss: 0.2952
Epoch [9/50] - Loss: 0.2555
Epoch [10/50] - Loss: 0.2356
Epoch [11/50] - Loss: 0.2266
Epoch [12/50] - Loss: 0.2250
Epoch [13/50] - Loss: 0.2287
Epoch [14/50] - Loss: 0.2281
Epoch [15/50] - Loss: 0.2202
Epoch [16/50] - Loss: 0.2058
Epoch [17/50] - Loss: 0.1981
Epoch [18/50] - Loss: 0.1936
Epoch [19/50] - Loss: 0.1867
Epoch [20/50] - Loss: 0.1864
Epoch [21/50] - Loss: 0.1780
Epoch [22/50] - Loss: 0.1768
Epoch [23/50] - Loss: 0.1750
Epoch [24/50] - Loss: 0.1732
Epoch [25/50] - Loss: 0.1649
Epoch [26/50] - Loss: 0.1665
Epoch [27/50] - Loss: 0.1649
Epoch [28/50] - Loss: 0.1625
Epoch [29/50] - Loss: 0.1574
Epoch [30/50] - Loss: 0.1559
Epoch [31/50] - Loss: 0.1615
Epoch [32/50] - Loss: 0.1550
Epoch [33/50] - Loss: 0.1573
Epoch [34/50] - Loss: 0.1517
Epoch [35/50] - Loss: 0.1475
Epoch [36/50] - Loss: 0.1518
Epoch [37/50] - Loss: 0.1491
Epoch [38/50] - Loss: 0.1478
Epoch [39/50] - Loss: 0.1473
Epoch [40/50] - Loss: 0.1440
Epoch [41/50] - Loss: 0.1440
Epoch [42/50] - Loss: 0.1448
Epoch [43/50] - Loss: 0.1455
Epoch [44/50] - Loss: 0.1454
Epoch [45/50] - Loss: 0.1424
Epoch [46/50] - Loss: 0.1426
Epoch [47/50] - Loss: 0.1444
Epoch [48/50] - Loss: 0.1465
Epoch [49/50] - Loss: 0.1428
Epoch [50/50] - Loss: 0.1438
sum preds 0
sum labels 561
 - Test Metrics: Accuracy=0.8240, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_two_nnif_two_nnif_1804090753.csv.
Average F1 over valid seeds: 0.0082 ± 0.0116
___________________________________________________________________________________
Avg F1 for citeseer with SAR and two_nnif, GCNConv,0.2: 0.0082 ± 0.0116
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6683
Epoch [2/50] - Loss: 0.6367
Epoch [3/50] - Loss: 0.5960
Epoch [4/50] - Loss: 0.5508
Epoch [5/50] - Loss: 0.5037
Epoch [6/50] - Loss: 0.4559
Epoch [7/50] - Loss: 0.4087
Epoch [8/50] - Loss: 0.3632
Epoch [9/50] - Loss: 0.3202
Epoch [10/50] - Loss: 0.2804
Epoch [11/50] - Loss: 0.2443
Epoch [12/50] - Loss: 0.2119
Epoch [13/50] - Loss: 0.1831
Epoch [14/50] - Loss: 0.1576
Epoch [15/50] - Loss: 0.1352
Epoch [16/50] - Loss: 0.1156
Epoch [17/50] - Loss: 0.0985
Epoch [18/50] - Loss: 0.0836
Epoch [19/50] - Loss: 0.0707
Epoch [20/50] - Loss: 0.0597
Epoch [21/50] - Loss: 0.0504
Epoch [22/50] - Loss: 0.0425
Epoch [23/50] - Loss: 0.0359
Epoch [24/50] - Loss: 0.0304
Epoch [25/50] - Loss: 0.0258
Epoch [26/50] - Loss: 0.0220
Epoch [27/50] - Loss: 0.0188
Epoch [28/50] - Loss: 0.0162
Epoch [29/50] - Loss: 0.0140
Epoch [30/50] - Loss: 0.0122
Epoch [31/50] - Loss: 0.0107
Epoch [32/50] - Loss: 0.0094
Epoch [33/50] - Loss: 0.0083
Epoch [34/50] - Loss: 0.0074
Epoch [35/50] - Loss: 0.0066
Epoch [36/50] - Loss: 0.0060
Epoch [37/50] - Loss: 0.0055
Epoch [38/50] - Loss: 0.0050
Epoch [39/50] - Loss: 0.0046
Epoch [40/50] - Loss: 0.0042
Epoch [41/50] - Loss: 0.0039
Epoch [42/50] - Loss: 0.0037
Epoch [43/50] - Loss: 0.0035
Epoch [44/50] - Loss: 0.0033
Epoch [45/50] - Loss: 0.0031
Epoch [46/50] - Loss: 0.0029
Epoch [47/50] - Loss: 0.0028
Epoch [48/50] - Loss: 0.0027
Epoch [49/50] - Loss: 0.0026
Epoch [50/50] - Loss: 0.0025
sum preds 423
sum labels 421
 - Test Metrics: Accuracy=0.8740, F1=0.5450, Recall=0.5463, Precision=0.5437
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6852
Epoch [2/50] - Loss: 0.6488
Epoch [3/50] - Loss: 0.6048
Epoch [4/50] - Loss: 0.5562
Epoch [5/50] - Loss: 0.5053
Epoch [6/50] - Loss: 0.4545
Epoch [7/50] - Loss: 0.4059
Epoch [8/50] - Loss: 0.3597
Epoch [9/50] - Loss: 0.3167
Epoch [10/50] - Loss: 0.2774
Epoch [11/50] - Loss: 0.2419
Epoch [12/50] - Loss: 0.2103
Epoch [13/50] - Loss: 0.1824
Epoch [14/50] - Loss: 0.1578
Epoch [15/50] - Loss: 0.1362
Epoch [16/50] - Loss: 0.1171
Epoch [17/50] - Loss: 0.1005
Epoch [18/50] - Loss: 0.0859
Epoch [19/50] - Loss: 0.0733
Epoch [20/50] - Loss: 0.0623
Epoch [21/50] - Loss: 0.0530
Epoch [22/50] - Loss: 0.0451
Epoch [23/50] - Loss: 0.0385
Epoch [24/50] - Loss: 0.0329
Epoch [25/50] - Loss: 0.0283
Epoch [26/50] - Loss: 0.0244
Epoch [27/50] - Loss: 0.0211
Epoch [28/50] - Loss: 0.0183
Epoch [29/50] - Loss: 0.0160
Epoch [30/50] - Loss: 0.0140
Epoch [31/50] - Loss: 0.0123
Epoch [32/50] - Loss: 0.0109
Epoch [33/50] - Loss: 0.0097
Epoch [34/50] - Loss: 0.0087
Epoch [35/50] - Loss: 0.0078
Epoch [36/50] - Loss: 0.0070
Epoch [37/50] - Loss: 0.0064
Epoch [38/50] - Loss: 0.0058
Epoch [39/50] - Loss: 0.0053
Epoch [40/50] - Loss: 0.0049
Epoch [41/50] - Loss: 0.0045
Epoch [42/50] - Loss: 0.0042
Epoch [43/50] - Loss: 0.0039
Epoch [44/50] - Loss: 0.0036
Epoch [45/50] - Loss: 0.0034
Epoch [46/50] - Loss: 0.0032
Epoch [47/50] - Loss: 0.0030
Epoch [48/50] - Loss: 0.0028
Epoch [49/50] - Loss: 0.0027
Epoch [50/50] - Loss: 0.0026
sum preds 396
sum labels 421
 - Test Metrics: Accuracy=0.8618, F1=0.4847, Recall=0.4703, Precision=0.5000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7053
Epoch [2/50] - Loss: 0.6805
Epoch [3/50] - Loss: 0.6571
Epoch [4/50] - Loss: 0.6236
Epoch [5/50] - Loss: 0.5831
Epoch [6/50] - Loss: 0.5435
Epoch [7/50] - Loss: 0.5066
Epoch [8/50] - Loss: 0.4689
Epoch [9/50] - Loss: 0.4285
Epoch [10/50] - Loss: 0.3879
Epoch [11/50] - Loss: 0.3496
Epoch [12/50] - Loss: 0.3139
Epoch [13/50] - Loss: 0.2800
Epoch [14/50] - Loss: 0.2475
Epoch [15/50] - Loss: 0.2168
Epoch [16/50] - Loss: 0.1884
Epoch [17/50] - Loss: 0.1630
Epoch [18/50] - Loss: 0.1403
Epoch [19/50] - Loss: 0.1203
Epoch [20/50] - Loss: 0.1027
Epoch [21/50] - Loss: 0.0875
Epoch [22/50] - Loss: 0.0746
Epoch [23/50] - Loss: 0.0636
Epoch [24/50] - Loss: 0.0542
Epoch [25/50] - Loss: 0.0464
Epoch [26/50] - Loss: 0.0397
Epoch [27/50] - Loss: 0.0341
Epoch [28/50] - Loss: 0.0294
Epoch [29/50] - Loss: 0.0254
Epoch [30/50] - Loss: 0.0221
Epoch [31/50] - Loss: 0.0192
Epoch [32/50] - Loss: 0.0169
Epoch [33/50] - Loss: 0.0148
Epoch [34/50] - Loss: 0.0132
Epoch [35/50] - Loss: 0.0117
Epoch [36/50] - Loss: 0.0105
Epoch [37/50] - Loss: 0.0095
Epoch [38/50] - Loss: 0.0086
Epoch [39/50] - Loss: 0.0078
Epoch [40/50] - Loss: 0.0072
Epoch [41/50] - Loss: 0.0067
Epoch [42/50] - Loss: 0.0062
Epoch [43/50] - Loss: 0.0058
Epoch [44/50] - Loss: 0.0054
Epoch [45/50] - Loss: 0.0051
Epoch [46/50] - Loss: 0.0048
Epoch [47/50] - Loss: 0.0045
Epoch [48/50] - Loss: 0.0043
Epoch [49/50] - Loss: 0.0041
Epoch [50/50] - Loss: 0.0040
sum preds 543
sum labels 421
 - Test Metrics: Accuracy=0.8431, F1=0.5041, Recall=0.5772, Precision=0.4475
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_spy_spy_1804090856.csv.
Average F1 over valid seeds: 0.5113 ± 0.0251
___________________________________________________________________________________
Avg F1 for citeseer with SAR and spy, MLP,0.4: 0.5113 ± 0.0251
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7052
Epoch [2/50] - Loss: 0.6225
Epoch [3/50] - Loss: 0.5498
Epoch [4/50] - Loss: 0.4785
Epoch [5/50] - Loss: 0.4128
Epoch [6/50] - Loss: 0.3584
Epoch [7/50] - Loss: 0.3175
Epoch [8/50] - Loss: 0.2866
Epoch [9/50] - Loss: 0.2607
Epoch [10/50] - Loss: 0.2374
Epoch [11/50] - Loss: 0.2165
Epoch [12/50] - Loss: 0.1981
Epoch [13/50] - Loss: 0.1821
Epoch [14/50] - Loss: 0.1678
Epoch [15/50] - Loss: 0.1540
Epoch [16/50] - Loss: 0.1406
Epoch [17/50] - Loss: 0.1282
Epoch [18/50] - Loss: 0.1177
Epoch [19/50] - Loss: 0.1086
Epoch [20/50] - Loss: 0.1006
Epoch [21/50] - Loss: 0.0933
Epoch [22/50] - Loss: 0.0866
Epoch [23/50] - Loss: 0.0805
Epoch [24/50] - Loss: 0.0753
Epoch [25/50] - Loss: 0.0713
Epoch [26/50] - Loss: 0.0681
Epoch [27/50] - Loss: 0.0652
Epoch [28/50] - Loss: 0.0621
Epoch [29/50] - Loss: 0.0589
Epoch [30/50] - Loss: 0.0558
Epoch [31/50] - Loss: 0.0527
Epoch [32/50] - Loss: 0.0499
Epoch [33/50] - Loss: 0.0476
Epoch [34/50] - Loss: 0.0458
Epoch [35/50] - Loss: 0.0445
Epoch [36/50] - Loss: 0.0434
Epoch [37/50] - Loss: 0.0421
Epoch [38/50] - Loss: 0.0407
Epoch [39/50] - Loss: 0.0396
Epoch [40/50] - Loss: 0.0386
Epoch [41/50] - Loss: 0.0377
Epoch [42/50] - Loss: 0.0368
Epoch [43/50] - Loss: 0.0360
Epoch [44/50] - Loss: 0.0354
Epoch [45/50] - Loss: 0.0347
Epoch [46/50] - Loss: 0.0339
Epoch [47/50] - Loss: 0.0333
Epoch [48/50] - Loss: 0.0323
Epoch [49/50] - Loss: 0.0316
Epoch [50/50] - Loss: 0.0310
sum preds 443
sum labels 421
 - Test Metrics: Accuracy=0.8878, F1=0.6042, Recall=0.6200, Precision=0.5892
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6980
Epoch [2/50] - Loss: 0.6070
Epoch [3/50] - Loss: 0.5294
Epoch [4/50] - Loss: 0.4567
Epoch [5/50] - Loss: 0.3875
Epoch [6/50] - Loss: 0.3296
Epoch [7/50] - Loss: 0.2892
Epoch [8/50] - Loss: 0.2615
Epoch [9/50] - Loss: 0.2373
Epoch [10/50] - Loss: 0.2134
Epoch [11/50] - Loss: 0.1919
Epoch [12/50] - Loss: 0.1744
Epoch [13/50] - Loss: 0.1601
Epoch [14/50] - Loss: 0.1470
Epoch [15/50] - Loss: 0.1341
Epoch [16/50] - Loss: 0.1219
Epoch [17/50] - Loss: 0.1114
Epoch [18/50] - Loss: 0.1031
Epoch [19/50] - Loss: 0.0966
Epoch [20/50] - Loss: 0.0905
Epoch [21/50] - Loss: 0.0842
Epoch [22/50] - Loss: 0.0782
Epoch [23/50] - Loss: 0.0733
Epoch [24/50] - Loss: 0.0697
Epoch [25/50] - Loss: 0.0669
Epoch [26/50] - Loss: 0.0641
Epoch [27/50] - Loss: 0.0613
Epoch [28/50] - Loss: 0.0586
Epoch [29/50] - Loss: 0.0563
Epoch [30/50] - Loss: 0.0542
Epoch [31/50] - Loss: 0.0526
Epoch [32/50] - Loss: 0.0514
Epoch [33/50] - Loss: 0.0504
Epoch [34/50] - Loss: 0.0493
Epoch [35/50] - Loss: 0.0480
Epoch [36/50] - Loss: 0.0467
Epoch [37/50] - Loss: 0.0455
Epoch [38/50] - Loss: 0.0442
Epoch [39/50] - Loss: 0.0430
Epoch [40/50] - Loss: 0.0419
Epoch [41/50] - Loss: 0.0409
Epoch [42/50] - Loss: 0.0399
Epoch [43/50] - Loss: 0.0389
Epoch [44/50] - Loss: 0.0378
Epoch [45/50] - Loss: 0.0368
Epoch [46/50] - Loss: 0.0360
Epoch [47/50] - Loss: 0.0353
Epoch [48/50] - Loss: 0.0345
Epoch [49/50] - Loss: 0.0339
Epoch [50/50] - Loss: 0.0334
sum preds 408
sum labels 421
 - Test Metrics: Accuracy=0.8914, F1=0.6007, Recall=0.5914, Precision=0.6103
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6960
Epoch [2/50] - Loss: 0.6086
Epoch [3/50] - Loss: 0.5401
Epoch [4/50] - Loss: 0.4779
Epoch [5/50] - Loss: 0.4212
Epoch [6/50] - Loss: 0.3754
Epoch [7/50] - Loss: 0.3412
Epoch [8/50] - Loss: 0.3149
Epoch [9/50] - Loss: 0.2916
Epoch [10/50] - Loss: 0.2691
Epoch [11/50] - Loss: 0.2481
Epoch [12/50] - Loss: 0.2297
Epoch [13/50] - Loss: 0.2134
Epoch [14/50] - Loss: 0.1976
Epoch [15/50] - Loss: 0.1816
Epoch [16/50] - Loss: 0.1668
Epoch [17/50] - Loss: 0.1537
Epoch [18/50] - Loss: 0.1423
Epoch [19/50] - Loss: 0.1316
Epoch [20/50] - Loss: 0.1216
Epoch [21/50] - Loss: 0.1127
Epoch [22/50] - Loss: 0.1052
Epoch [23/50] - Loss: 0.0989
Epoch [24/50] - Loss: 0.0933
Epoch [25/50] - Loss: 0.0881
Epoch [26/50] - Loss: 0.0836
Epoch [27/50] - Loss: 0.0798
Epoch [28/50] - Loss: 0.0763
Epoch [29/50] - Loss: 0.0731
Epoch [30/50] - Loss: 0.0699
Epoch [31/50] - Loss: 0.0668
Epoch [32/50] - Loss: 0.0641
Epoch [33/50] - Loss: 0.0620
Epoch [34/50] - Loss: 0.0600
Epoch [35/50] - Loss: 0.0583
Epoch [36/50] - Loss: 0.0569
Epoch [37/50] - Loss: 0.0554
Epoch [38/50] - Loss: 0.0541
Epoch [39/50] - Loss: 0.0529
Epoch [40/50] - Loss: 0.0517
Epoch [41/50] - Loss: 0.0510
Epoch [42/50] - Loss: 0.0501
Epoch [43/50] - Loss: 0.0495
Epoch [44/50] - Loss: 0.0488
Epoch [45/50] - Loss: 0.0481
Epoch [46/50] - Loss: 0.0477
Epoch [47/50] - Loss: 0.0472
Epoch [48/50] - Loss: 0.0466
Epoch [49/50] - Loss: 0.0460
Epoch [50/50] - Loss: 0.0452
sum preds 400
sum labels 421
 - Test Metrics: Accuracy=0.8809, F1=0.5579, Recall=0.5439, Precision=0.5725
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_spy_spy_1804090916.csv.
Average F1 over valid seeds: 0.5876 ± 0.0211
___________________________________________________________________________________
Avg F1 for citeseer with SAR and spy, GATConv,0.4: 0.5876 ± 0.0211
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6953
Epoch [2/50] - Loss: 0.6101
Epoch [3/50] - Loss: 0.5315
Epoch [4/50] - Loss: 0.4578
Epoch [5/50] - Loss: 0.3939
Epoch [6/50] - Loss: 0.3442
Epoch [7/50] - Loss: 0.3073
Epoch [8/50] - Loss: 0.2783
Epoch [9/50] - Loss: 0.2537
Epoch [10/50] - Loss: 0.2324
Epoch [11/50] - Loss: 0.2141
Epoch [12/50] - Loss: 0.1983
Epoch [13/50] - Loss: 0.1843
Epoch [14/50] - Loss: 0.1714
Epoch [15/50] - Loss: 0.1597
Epoch [16/50] - Loss: 0.1493
Epoch [17/50] - Loss: 0.1404
Epoch [18/50] - Loss: 0.1326
Epoch [19/50] - Loss: 0.1257
Epoch [20/50] - Loss: 0.1194
Epoch [21/50] - Loss: 0.1136
Epoch [22/50] - Loss: 0.1082
Epoch [23/50] - Loss: 0.1033
Epoch [24/50] - Loss: 0.0987
Epoch [25/50] - Loss: 0.0943
Epoch [26/50] - Loss: 0.0904
Epoch [27/50] - Loss: 0.0868
Epoch [28/50] - Loss: 0.0835
Epoch [29/50] - Loss: 0.0804
Epoch [30/50] - Loss: 0.0776
Epoch [31/50] - Loss: 0.0749
Epoch [32/50] - Loss: 0.0725
Epoch [33/50] - Loss: 0.0702
Epoch [34/50] - Loss: 0.0681
Epoch [35/50] - Loss: 0.0660
Epoch [36/50] - Loss: 0.0641
Epoch [37/50] - Loss: 0.0623
Epoch [38/50] - Loss: 0.0605
Epoch [39/50] - Loss: 0.0589
Epoch [40/50] - Loss: 0.0573
Epoch [41/50] - Loss: 0.0558
Epoch [42/50] - Loss: 0.0544
Epoch [43/50] - Loss: 0.0530
Epoch [44/50] - Loss: 0.0518
Epoch [45/50] - Loss: 0.0506
Epoch [46/50] - Loss: 0.0494
Epoch [47/50] - Loss: 0.0483
Epoch [48/50] - Loss: 0.0473
Epoch [49/50] - Loss: 0.0463
Epoch [50/50] - Loss: 0.0453
sum preds 423
sum labels 421
 - Test Metrics: Accuracy=0.8937, F1=0.6161, Recall=0.6176, Precision=0.6147
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6817
Epoch [2/50] - Loss: 0.5992
Epoch [3/50] - Loss: 0.5181
Epoch [4/50] - Loss: 0.4515
Epoch [5/50] - Loss: 0.3959
Epoch [6/50] - Loss: 0.3522
Epoch [7/50] - Loss: 0.3187
Epoch [8/50] - Loss: 0.2918
Epoch [9/50] - Loss: 0.2691
Epoch [10/50] - Loss: 0.2497
Epoch [11/50] - Loss: 0.2329
Epoch [12/50] - Loss: 0.2179
Epoch [13/50] - Loss: 0.2044
Epoch [14/50] - Loss: 0.1920
Epoch [15/50] - Loss: 0.1805
Epoch [16/50] - Loss: 0.1701
Epoch [17/50] - Loss: 0.1609
Epoch [18/50] - Loss: 0.1529
Epoch [19/50] - Loss: 0.1459
Epoch [20/50] - Loss: 0.1398
Epoch [21/50] - Loss: 0.1343
Epoch [22/50] - Loss: 0.1291
Epoch [23/50] - Loss: 0.1241
Epoch [24/50] - Loss: 0.1192
Epoch [25/50] - Loss: 0.1145
Epoch [26/50] - Loss: 0.1101
Epoch [27/50] - Loss: 0.1061
Epoch [28/50] - Loss: 0.1024
Epoch [29/50] - Loss: 0.0990
Epoch [30/50] - Loss: 0.0958
Epoch [31/50] - Loss: 0.0927
Epoch [32/50] - Loss: 0.0896
Epoch [33/50] - Loss: 0.0866
Epoch [34/50] - Loss: 0.0837
Epoch [35/50] - Loss: 0.0810
Epoch [36/50] - Loss: 0.0784
Epoch [37/50] - Loss: 0.0761
Epoch [38/50] - Loss: 0.0739
Epoch [39/50] - Loss: 0.0719
Epoch [40/50] - Loss: 0.0700
Epoch [41/50] - Loss: 0.0682
Epoch [42/50] - Loss: 0.0664
Epoch [43/50] - Loss: 0.0647
Epoch [44/50] - Loss: 0.0631
Epoch [45/50] - Loss: 0.0615
Epoch [46/50] - Loss: 0.0600
Epoch [47/50] - Loss: 0.0585
Epoch [48/50] - Loss: 0.0571
Epoch [49/50] - Loss: 0.0558
Epoch [50/50] - Loss: 0.0545
sum preds 428
sum labels 421
 - Test Metrics: Accuracy=0.8933, F1=0.6172, Recall=0.6223, Precision=0.6121
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7005
Epoch [2/50] - Loss: 0.6354
Epoch [3/50] - Loss: 0.5710
Epoch [4/50] - Loss: 0.5054
Epoch [5/50] - Loss: 0.4453
Epoch [6/50] - Loss: 0.3945
Epoch [7/50] - Loss: 0.3549
Epoch [8/50] - Loss: 0.3237
Epoch [9/50] - Loss: 0.2975
Epoch [10/50] - Loss: 0.2748
Epoch [11/50] - Loss: 0.2552
Epoch [12/50] - Loss: 0.2384
Epoch [13/50] - Loss: 0.2235
Epoch [14/50] - Loss: 0.2098
Epoch [15/50] - Loss: 0.1968
Epoch [16/50] - Loss: 0.1848
Epoch [17/50] - Loss: 0.1741
Epoch [18/50] - Loss: 0.1647
Epoch [19/50] - Loss: 0.1563
Epoch [20/50] - Loss: 0.1486
Epoch [21/50] - Loss: 0.1416
Epoch [22/50] - Loss: 0.1356
Epoch [23/50] - Loss: 0.1302
Epoch [24/50] - Loss: 0.1250
Epoch [25/50] - Loss: 0.1201
Epoch [26/50] - Loss: 0.1154
Epoch [27/50] - Loss: 0.1110
Epoch [28/50] - Loss: 0.1069
Epoch [29/50] - Loss: 0.1028
Epoch [30/50] - Loss: 0.0989
Epoch [31/50] - Loss: 0.0954
Epoch [32/50] - Loss: 0.0921
Epoch [33/50] - Loss: 0.0890
Epoch [34/50] - Loss: 0.0860
Epoch [35/50] - Loss: 0.0832
Epoch [36/50] - Loss: 0.0807
Epoch [37/50] - Loss: 0.0783
Epoch [38/50] - Loss: 0.0760
Epoch [39/50] - Loss: 0.0739
Epoch [40/50] - Loss: 0.0719
Epoch [41/50] - Loss: 0.0700
Epoch [42/50] - Loss: 0.0682
Epoch [43/50] - Loss: 0.0664
Epoch [44/50] - Loss: 0.0648
Epoch [45/50] - Loss: 0.0634
Epoch [46/50] - Loss: 0.0620
Epoch [47/50] - Loss: 0.0606
Epoch [48/50] - Loss: 0.0593
Epoch [49/50] - Loss: 0.0580
Epoch [50/50] - Loss: 0.0568
sum preds 419
sum labels 421
 - Test Metrics: Accuracy=0.8727, F1=0.5381, Recall=0.5368, Precision=0.5394
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_spy_spy_1804090939.csv.
Average F1 over valid seeds: 0.5905 ± 0.0370
___________________________________________________________________________________
Avg F1 for citeseer with SAR and spy, GCNConv,0.4: 0.5905 ± 0.0370
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6494
Epoch [2/50] - Loss: 0.6158
Epoch [3/50] - Loss: 0.5757
Epoch [4/50] - Loss: 0.5303
Epoch [5/50] - Loss: 0.4824
Epoch [6/50] - Loss: 0.4350
Epoch [7/50] - Loss: 0.3891
Epoch [8/50] - Loss: 0.3454
Epoch [9/50] - Loss: 0.3042
Epoch [10/50] - Loss: 0.2660
Epoch [11/50] - Loss: 0.2313
Epoch [12/50] - Loss: 0.2001
Epoch [13/50] - Loss: 0.1724
Epoch [14/50] - Loss: 0.1481
Epoch [15/50] - Loss: 0.1267
Epoch [16/50] - Loss: 0.1081
Epoch [17/50] - Loss: 0.0918
Epoch [18/50] - Loss: 0.0777
Epoch [19/50] - Loss: 0.0655
Epoch [20/50] - Loss: 0.0551
Epoch [21/50] - Loss: 0.0463
Epoch [22/50] - Loss: 0.0389
Epoch [23/50] - Loss: 0.0327
Epoch [24/50] - Loss: 0.0276
Epoch [25/50] - Loss: 0.0233
Epoch [26/50] - Loss: 0.0199
Epoch [27/50] - Loss: 0.0170
Epoch [28/50] - Loss: 0.0146
Epoch [29/50] - Loss: 0.0127
Epoch [30/50] - Loss: 0.0111
Epoch [31/50] - Loss: 0.0097
Epoch [32/50] - Loss: 0.0086
Epoch [33/50] - Loss: 0.0077
Epoch [34/50] - Loss: 0.0069
Epoch [35/50] - Loss: 0.0062
Epoch [36/50] - Loss: 0.0056
Epoch [37/50] - Loss: 0.0051
Epoch [38/50] - Loss: 0.0047
Epoch [39/50] - Loss: 0.0043
Epoch [40/50] - Loss: 0.0040
Epoch [41/50] - Loss: 0.0038
Epoch [42/50] - Loss: 0.0035
Epoch [43/50] - Loss: 0.0033
Epoch [44/50] - Loss: 0.0031
Epoch [45/50] - Loss: 0.0030
Epoch [46/50] - Loss: 0.0028
Epoch [47/50] - Loss: 0.0027
Epoch [48/50] - Loss: 0.0026
Epoch [49/50] - Loss: 0.0025
Epoch [50/50] - Loss: 0.0024
sum preds 348
sum labels 491
 - Test Metrics: Accuracy=0.8868, F1=0.5793, Recall=0.4949, Precision=0.6983
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6787
Epoch [2/50] - Loss: 0.6358
Epoch [3/50] - Loss: 0.5887
Epoch [4/50] - Loss: 0.5406
Epoch [5/50] - Loss: 0.4930
Epoch [6/50] - Loss: 0.4464
Epoch [7/50] - Loss: 0.4013
Epoch [8/50] - Loss: 0.3579
Epoch [9/50] - Loss: 0.3172
Epoch [10/50] - Loss: 0.2796
Epoch [11/50] - Loss: 0.2453
Epoch [12/50] - Loss: 0.2143
Epoch [13/50] - Loss: 0.1863
Epoch [14/50] - Loss: 0.1611
Epoch [15/50] - Loss: 0.1388
Epoch [16/50] - Loss: 0.1189
Epoch [17/50] - Loss: 0.1014
Epoch [18/50] - Loss: 0.0861
Epoch [19/50] - Loss: 0.0729
Epoch [20/50] - Loss: 0.0616
Epoch [21/50] - Loss: 0.0520
Epoch [22/50] - Loss: 0.0438
Epoch [23/50] - Loss: 0.0370
Epoch [24/50] - Loss: 0.0313
Epoch [25/50] - Loss: 0.0266
Epoch [26/50] - Loss: 0.0227
Epoch [27/50] - Loss: 0.0196
Epoch [28/50] - Loss: 0.0169
Epoch [29/50] - Loss: 0.0148
Epoch [30/50] - Loss: 0.0130
Epoch [31/50] - Loss: 0.0114
Epoch [32/50] - Loss: 0.0101
Epoch [33/50] - Loss: 0.0090
Epoch [34/50] - Loss: 0.0081
Epoch [35/50] - Loss: 0.0073
Epoch [36/50] - Loss: 0.0066
Epoch [37/50] - Loss: 0.0061
Epoch [38/50] - Loss: 0.0056
Epoch [39/50] - Loss: 0.0052
Epoch [40/50] - Loss: 0.0048
Epoch [41/50] - Loss: 0.0044
Epoch [42/50] - Loss: 0.0042
Epoch [43/50] - Loss: 0.0039
Epoch [44/50] - Loss: 0.0037
Epoch [45/50] - Loss: 0.0035
Epoch [46/50] - Loss: 0.0033
Epoch [47/50] - Loss: 0.0031
Epoch [48/50] - Loss: 0.0030
Epoch [49/50] - Loss: 0.0029
Epoch [50/50] - Loss: 0.0027
sum preds 294
sum labels 491
 - Test Metrics: Accuracy=0.8752, F1=0.5045, Recall=0.4033, Precision=0.6735
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7106
Epoch [2/50] - Loss: 0.6839
Epoch [3/50] - Loss: 0.6660
Epoch [4/50] - Loss: 0.6437
Epoch [5/50] - Loss: 0.6167
Epoch [6/50] - Loss: 0.5849
Epoch [7/50] - Loss: 0.5494
Epoch [8/50] - Loss: 0.5125
Epoch [9/50] - Loss: 0.4754
Epoch [10/50] - Loss: 0.4388
Epoch [11/50] - Loss: 0.4017
Epoch [12/50] - Loss: 0.3641
Epoch [13/50] - Loss: 0.3267
Epoch [14/50] - Loss: 0.2910
Epoch [15/50] - Loss: 0.2575
Epoch [16/50] - Loss: 0.2267
Epoch [17/50] - Loss: 0.1983
Epoch [18/50] - Loss: 0.1724
Epoch [19/50] - Loss: 0.1487
Epoch [20/50] - Loss: 0.1276
Epoch [21/50] - Loss: 0.1089
Epoch [22/50] - Loss: 0.0926
Epoch [23/50] - Loss: 0.0786
Epoch [24/50] - Loss: 0.0666
Epoch [25/50] - Loss: 0.0564
Epoch [26/50] - Loss: 0.0478
Epoch [27/50] - Loss: 0.0406
Epoch [28/50] - Loss: 0.0345
Epoch [29/50] - Loss: 0.0294
Epoch [30/50] - Loss: 0.0252
Epoch [31/50] - Loss: 0.0217
Epoch [32/50] - Loss: 0.0188
Epoch [33/50] - Loss: 0.0164
Epoch [34/50] - Loss: 0.0144
Epoch [35/50] - Loss: 0.0127
Epoch [36/50] - Loss: 0.0113
Epoch [37/50] - Loss: 0.0101
Epoch [38/50] - Loss: 0.0091
Epoch [39/50] - Loss: 0.0082
Epoch [40/50] - Loss: 0.0075
Epoch [41/50] - Loss: 0.0069
Epoch [42/50] - Loss: 0.0063
Epoch [43/50] - Loss: 0.0059
Epoch [44/50] - Loss: 0.0055
Epoch [45/50] - Loss: 0.0051
Epoch [46/50] - Loss: 0.0048
Epoch [47/50] - Loss: 0.0045
Epoch [48/50] - Loss: 0.0043
Epoch [49/50] - Loss: 0.0041
Epoch [50/50] - Loss: 0.0039
sum preds 392
sum labels 491
 - Test Metrics: Accuracy=0.8495, F1=0.4689, Recall=0.4216, Precision=0.5281
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_spy_spy_1804091001.csv.
Average F1 over valid seeds: 0.5175 ± 0.0460
___________________________________________________________________________________
Avg F1 for citeseer with SAR and spy, MLP,0.3: 0.5175 ± 0.0460
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7051
Epoch [2/50] - Loss: 0.6076
Epoch [3/50] - Loss: 0.5350
Epoch [4/50] - Loss: 0.4723
Epoch [5/50] - Loss: 0.4149
Epoch [6/50] - Loss: 0.3618
Epoch [7/50] - Loss: 0.3170
Epoch [8/50] - Loss: 0.2832
Epoch [9/50] - Loss: 0.2595
Epoch [10/50] - Loss: 0.2411
Epoch [11/50] - Loss: 0.2246
Epoch [12/50] - Loss: 0.2078
Epoch [13/50] - Loss: 0.1913
Epoch [14/50] - Loss: 0.1757
Epoch [15/50] - Loss: 0.1617
Epoch [16/50] - Loss: 0.1491
Epoch [17/50] - Loss: 0.1382
Epoch [18/50] - Loss: 0.1279
Epoch [19/50] - Loss: 0.1180
Epoch [20/50] - Loss: 0.1087
Epoch [21/50] - Loss: 0.1008
Epoch [22/50] - Loss: 0.0945
Epoch [23/50] - Loss: 0.0892
Epoch [24/50] - Loss: 0.0837
Epoch [25/50] - Loss: 0.0781
Epoch [26/50] - Loss: 0.0728
Epoch [27/50] - Loss: 0.0681
Epoch [28/50] - Loss: 0.0642
Epoch [29/50] - Loss: 0.0610
Epoch [30/50] - Loss: 0.0578
Epoch [31/50] - Loss: 0.0546
Epoch [32/50] - Loss: 0.0514
Epoch [33/50] - Loss: 0.0485
Epoch [34/50] - Loss: 0.0466
Epoch [35/50] - Loss: 0.0451
Epoch [36/50] - Loss: 0.0431
Epoch [37/50] - Loss: 0.0414
Epoch [38/50] - Loss: 0.0402
Epoch [39/50] - Loss: 0.0391
Epoch [40/50] - Loss: 0.0377
Epoch [41/50] - Loss: 0.0364
Epoch [42/50] - Loss: 0.0354
Epoch [43/50] - Loss: 0.0345
Epoch [44/50] - Loss: 0.0336
Epoch [45/50] - Loss: 0.0329
Epoch [46/50] - Loss: 0.0323
Epoch [47/50] - Loss: 0.0315
Epoch [48/50] - Loss: 0.0308
Epoch [49/50] - Loss: 0.0301
Epoch [50/50] - Loss: 0.0296
sum preds 387
sum labels 491
 - Test Metrics: Accuracy=0.8871, F1=0.5991, Recall=0.5356, Precision=0.6796
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6967
Epoch [2/50] - Loss: 0.5941
Epoch [3/50] - Loss: 0.5230
Epoch [4/50] - Loss: 0.4680
Epoch [5/50] - Loss: 0.4151
Epoch [6/50] - Loss: 0.3641
Epoch [7/50] - Loss: 0.3210
Epoch [8/50] - Loss: 0.2878
Epoch [9/50] - Loss: 0.2646
Epoch [10/50] - Loss: 0.2464
Epoch [11/50] - Loss: 0.2275
Epoch [12/50] - Loss: 0.2062
Epoch [13/50] - Loss: 0.1850
Epoch [14/50] - Loss: 0.1675
Epoch [15/50] - Loss: 0.1547
Epoch [16/50] - Loss: 0.1444
Epoch [17/50] - Loss: 0.1343
Epoch [18/50] - Loss: 0.1239
Epoch [19/50] - Loss: 0.1143
Epoch [20/50] - Loss: 0.1062
Epoch [21/50] - Loss: 0.0993
Epoch [22/50] - Loss: 0.0930
Epoch [23/50] - Loss: 0.0868
Epoch [24/50] - Loss: 0.0805
Epoch [25/50] - Loss: 0.0748
Epoch [26/50] - Loss: 0.0701
Epoch [27/50] - Loss: 0.0662
Epoch [28/50] - Loss: 0.0624
Epoch [29/50] - Loss: 0.0587
Epoch [30/50] - Loss: 0.0552
Epoch [31/50] - Loss: 0.0524
Epoch [32/50] - Loss: 0.0502
Epoch [33/50] - Loss: 0.0482
Epoch [34/50] - Loss: 0.0461
Epoch [35/50] - Loss: 0.0438
Epoch [36/50] - Loss: 0.0417
Epoch [37/50] - Loss: 0.0399
Epoch [38/50] - Loss: 0.0380
Epoch [39/50] - Loss: 0.0361
Epoch [40/50] - Loss: 0.0343
Epoch [41/50] - Loss: 0.0330
Epoch [42/50] - Loss: 0.0321
Epoch [43/50] - Loss: 0.0311
Epoch [44/50] - Loss: 0.0299
Epoch [45/50] - Loss: 0.0288
Epoch [46/50] - Loss: 0.0280
Epoch [47/50] - Loss: 0.0272
Epoch [48/50] - Loss: 0.0264
Epoch [49/50] - Loss: 0.0257
Epoch [50/50] - Loss: 0.0248
sum preds 378
sum labels 491
 - Test Metrics: Accuracy=0.8855, F1=0.5892, Recall=0.5214, Precision=0.6772
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6949
Epoch [2/50] - Loss: 0.5870
Epoch [3/50] - Loss: 0.5171
Epoch [4/50] - Loss: 0.4625
Epoch [5/50] - Loss: 0.4090
Epoch [6/50] - Loss: 0.3590
Epoch [7/50] - Loss: 0.3190
Epoch [8/50] - Loss: 0.2891
Epoch [9/50] - Loss: 0.2659
Epoch [10/50] - Loss: 0.2464
Epoch [11/50] - Loss: 0.2280
Epoch [12/50] - Loss: 0.2091
Epoch [13/50] - Loss: 0.1904
Epoch [14/50] - Loss: 0.1732
Epoch [15/50] - Loss: 0.1585
Epoch [16/50] - Loss: 0.1464
Epoch [17/50] - Loss: 0.1363
Epoch [18/50] - Loss: 0.1270
Epoch [19/50] - Loss: 0.1180
Epoch [20/50] - Loss: 0.1094
Epoch [21/50] - Loss: 0.1020
Epoch [22/50] - Loss: 0.0949
Epoch [23/50] - Loss: 0.0878
Epoch [24/50] - Loss: 0.0801
Epoch [25/50] - Loss: 0.0726
Epoch [26/50] - Loss: 0.0658
Epoch [27/50] - Loss: 0.0604
Epoch [28/50] - Loss: 0.0564
Epoch [29/50] - Loss: 0.0534
Epoch [30/50] - Loss: 0.0507
Epoch [31/50] - Loss: 0.0476
Epoch [32/50] - Loss: 0.0448
Epoch [33/50] - Loss: 0.0424
Epoch [34/50] - Loss: 0.0399
Epoch [35/50] - Loss: 0.0377
Epoch [36/50] - Loss: 0.0360
Epoch [37/50] - Loss: 0.0344
Epoch [38/50] - Loss: 0.0330
Epoch [39/50] - Loss: 0.0315
Epoch [40/50] - Loss: 0.0300
Epoch [41/50] - Loss: 0.0286
Epoch [42/50] - Loss: 0.0274
Epoch [43/50] - Loss: 0.0261
Epoch [44/50] - Loss: 0.0249
Epoch [45/50] - Loss: 0.0239
Epoch [46/50] - Loss: 0.0228
Epoch [47/50] - Loss: 0.0218
Epoch [48/50] - Loss: 0.0208
Epoch [49/50] - Loss: 0.0199
Epoch [50/50] - Loss: 0.0191
sum preds 355
sum labels 491
 - Test Metrics: Accuracy=0.8819, F1=0.5650, Recall=0.4868, Precision=0.6732
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_spy_spy_1804091022.csv.
Average F1 over valid seeds: 0.5844 ± 0.0143
___________________________________________________________________________________
Avg F1 for citeseer with SAR and spy, GATConv,0.3: 0.5844 ± 0.0143
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6956
Epoch [2/50] - Loss: 0.5932
Epoch [3/50] - Loss: 0.5147
Epoch [4/50] - Loss: 0.4485
Epoch [5/50] - Loss: 0.3884
Epoch [6/50] - Loss: 0.3361
Epoch [7/50] - Loss: 0.2964
Epoch [8/50] - Loss: 0.2686
Epoch [9/50] - Loss: 0.2480
Epoch [10/50] - Loss: 0.2301
Epoch [11/50] - Loss: 0.2130
Epoch [12/50] - Loss: 0.1968
Epoch [13/50] - Loss: 0.1826
Epoch [14/50] - Loss: 0.1707
Epoch [15/50] - Loss: 0.1606
Epoch [16/50] - Loss: 0.1516
Epoch [17/50] - Loss: 0.1428
Epoch [18/50] - Loss: 0.1343
Epoch [19/50] - Loss: 0.1264
Epoch [20/50] - Loss: 0.1195
Epoch [21/50] - Loss: 0.1139
Epoch [22/50] - Loss: 0.1092
Epoch [23/50] - Loss: 0.1049
Epoch [24/50] - Loss: 0.1007
Epoch [25/50] - Loss: 0.0965
Epoch [26/50] - Loss: 0.0926
Epoch [27/50] - Loss: 0.0890
Epoch [28/50] - Loss: 0.0856
Epoch [29/50] - Loss: 0.0822
Epoch [30/50] - Loss: 0.0788
Epoch [31/50] - Loss: 0.0756
Epoch [32/50] - Loss: 0.0727
Epoch [33/50] - Loss: 0.0702
Epoch [34/50] - Loss: 0.0679
Epoch [35/50] - Loss: 0.0656
Epoch [36/50] - Loss: 0.0633
Epoch [37/50] - Loss: 0.0611
Epoch [38/50] - Loss: 0.0591
Epoch [39/50] - Loss: 0.0571
Epoch [40/50] - Loss: 0.0553
Epoch [41/50] - Loss: 0.0535
Epoch [42/50] - Loss: 0.0518
Epoch [43/50] - Loss: 0.0502
Epoch [44/50] - Loss: 0.0487
Epoch [45/50] - Loss: 0.0473
Epoch [46/50] - Loss: 0.0459
Epoch [47/50] - Loss: 0.0446
Epoch [48/50] - Loss: 0.0433
Epoch [49/50] - Loss: 0.0421
Epoch [50/50] - Loss: 0.0410
sum preds 367
sum labels 491
 - Test Metrics: Accuracy=0.8890, F1=0.5967, Recall=0.5214, Precision=0.6975
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6769
Epoch [2/50] - Loss: 0.5801
Epoch [3/50] - Loss: 0.5022
Epoch [4/50] - Loss: 0.4424
Epoch [5/50] - Loss: 0.3867
Epoch [6/50] - Loss: 0.3409
Epoch [7/50] - Loss: 0.3079
Epoch [8/50] - Loss: 0.2829
Epoch [9/50] - Loss: 0.2614
Epoch [10/50] - Loss: 0.2420
Epoch [11/50] - Loss: 0.2243
Epoch [12/50] - Loss: 0.2085
Epoch [13/50] - Loss: 0.1950
Epoch [14/50] - Loss: 0.1833
Epoch [15/50] - Loss: 0.1732
Epoch [16/50] - Loss: 0.1638
Epoch [17/50] - Loss: 0.1550
Epoch [18/50] - Loss: 0.1469
Epoch [19/50] - Loss: 0.1398
Epoch [20/50] - Loss: 0.1335
Epoch [21/50] - Loss: 0.1279
Epoch [22/50] - Loss: 0.1226
Epoch [23/50] - Loss: 0.1176
Epoch [24/50] - Loss: 0.1130
Epoch [25/50] - Loss: 0.1090
Epoch [26/50] - Loss: 0.1055
Epoch [27/50] - Loss: 0.1022
Epoch [28/50] - Loss: 0.0989
Epoch [29/50] - Loss: 0.0956
Epoch [30/50] - Loss: 0.0925
Epoch [31/50] - Loss: 0.0895
Epoch [32/50] - Loss: 0.0865
Epoch [33/50] - Loss: 0.0836
Epoch [34/50] - Loss: 0.0807
Epoch [35/50] - Loss: 0.0782
Epoch [36/50] - Loss: 0.0759
Epoch [37/50] - Loss: 0.0737
Epoch [38/50] - Loss: 0.0716
Epoch [39/50] - Loss: 0.0696
Epoch [40/50] - Loss: 0.0676
Epoch [41/50] - Loss: 0.0658
Epoch [42/50] - Loss: 0.0640
Epoch [43/50] - Loss: 0.0622
Epoch [44/50] - Loss: 0.0605
Epoch [45/50] - Loss: 0.0590
Epoch [46/50] - Loss: 0.0575
Epoch [47/50] - Loss: 0.0560
Epoch [48/50] - Loss: 0.0546
Epoch [49/50] - Loss: 0.0533
Epoch [50/50] - Loss: 0.0520
sum preds 349
sum labels 491
 - Test Metrics: Accuracy=0.8813, F1=0.5595, Recall=0.4786, Precision=0.6734
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7031
Epoch [2/50] - Loss: 0.6260
Epoch [3/50] - Loss: 0.5612
Epoch [4/50] - Loss: 0.5028
Epoch [5/50] - Loss: 0.4498
Epoch [6/50] - Loss: 0.4001
Epoch [7/50] - Loss: 0.3542
Epoch [8/50] - Loss: 0.3151
Epoch [9/50] - Loss: 0.2856
Epoch [10/50] - Loss: 0.2639
Epoch [11/50] - Loss: 0.2458
Epoch [12/50] - Loss: 0.2279
Epoch [13/50] - Loss: 0.2101
Epoch [14/50] - Loss: 0.1935
Epoch [15/50] - Loss: 0.1794
Epoch [16/50] - Loss: 0.1676
Epoch [17/50] - Loss: 0.1573
Epoch [18/50] - Loss: 0.1474
Epoch [19/50] - Loss: 0.1376
Epoch [20/50] - Loss: 0.1281
Epoch [21/50] - Loss: 0.1198
Epoch [22/50] - Loss: 0.1130
Epoch [23/50] - Loss: 0.1074
Epoch [24/50] - Loss: 0.1023
Epoch [25/50] - Loss: 0.0973
Epoch [26/50] - Loss: 0.0924
Epoch [27/50] - Loss: 0.0879
Epoch [28/50] - Loss: 0.0840
Epoch [29/50] - Loss: 0.0803
Epoch [30/50] - Loss: 0.0767
Epoch [31/50] - Loss: 0.0730
Epoch [32/50] - Loss: 0.0694
Epoch [33/50] - Loss: 0.0663
Epoch [34/50] - Loss: 0.0636
Epoch [35/50] - Loss: 0.0614
Epoch [36/50] - Loss: 0.0593
Epoch [37/50] - Loss: 0.0573
Epoch [38/50] - Loss: 0.0554
Epoch [39/50] - Loss: 0.0537
Epoch [40/50] - Loss: 0.0521
Epoch [41/50] - Loss: 0.0505
Epoch [42/50] - Loss: 0.0489
Epoch [43/50] - Loss: 0.0472
Epoch [44/50] - Loss: 0.0457
Epoch [45/50] - Loss: 0.0444
Epoch [46/50] - Loss: 0.0432
Epoch [47/50] - Loss: 0.0421
Epoch [48/50] - Loss: 0.0410
Epoch [49/50] - Loss: 0.0400
Epoch [50/50] - Loss: 0.0391
sum preds 360
sum labels 491
 - Test Metrics: Accuracy=0.8835, F1=0.5734, Recall=0.4969, Precision=0.6778
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_spy_spy_1804091043.csv.
Average F1 over valid seeds: 0.5766 ± 0.0154
___________________________________________________________________________________
Avg F1 for citeseer with SAR and spy, GCNConv,0.3: 0.5766 ± 0.0154
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6264
Epoch [2/50] - Loss: 0.5876
Epoch [3/50] - Loss: 0.5469
Epoch [4/50] - Loss: 0.5037
Epoch [5/50] - Loss: 0.4603
Epoch [6/50] - Loss: 0.4174
Epoch [7/50] - Loss: 0.3757
Epoch [8/50] - Loss: 0.3359
Epoch [9/50] - Loss: 0.2985
Epoch [10/50] - Loss: 0.2637
Epoch [11/50] - Loss: 0.2316
Epoch [12/50] - Loss: 0.2024
Epoch [13/50] - Loss: 0.1760
Epoch [14/50] - Loss: 0.1522
Epoch [15/50] - Loss: 0.1309
Epoch [16/50] - Loss: 0.1118
Epoch [17/50] - Loss: 0.0947
Epoch [18/50] - Loss: 0.0798
Epoch [19/50] - Loss: 0.0668
Epoch [20/50] - Loss: 0.0557
Epoch [21/50] - Loss: 0.0463
Epoch [22/50] - Loss: 0.0386
Epoch [23/50] - Loss: 0.0322
Epoch [24/50] - Loss: 0.0270
Epoch [25/50] - Loss: 0.0228
Epoch [26/50] - Loss: 0.0194
Epoch [27/50] - Loss: 0.0166
Epoch [28/50] - Loss: 0.0144
Epoch [29/50] - Loss: 0.0125
Epoch [30/50] - Loss: 0.0110
Epoch [31/50] - Loss: 0.0098
Epoch [32/50] - Loss: 0.0088
Epoch [33/50] - Loss: 0.0079
Epoch [34/50] - Loss: 0.0072
Epoch [35/50] - Loss: 0.0066
Epoch [36/50] - Loss: 0.0061
Epoch [37/50] - Loss: 0.0057
Epoch [38/50] - Loss: 0.0053
Epoch [39/50] - Loss: 0.0050
Epoch [40/50] - Loss: 0.0047
Epoch [41/50] - Loss: 0.0045
Epoch [42/50] - Loss: 0.0043
Epoch [43/50] - Loss: 0.0041
Epoch [44/50] - Loss: 0.0040
Epoch [45/50] - Loss: 0.0038
Epoch [46/50] - Loss: 0.0037
Epoch [47/50] - Loss: 0.0036
Epoch [48/50] - Loss: 0.0035
Epoch [49/50] - Loss: 0.0034
Epoch [50/50] - Loss: 0.0033
sum preds 202
sum labels 561
 - Test Metrics: Accuracy=0.8654, F1=0.4377, Recall=0.2977, Precision=0.8267
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6720
Epoch [2/50] - Loss: 0.6175
Epoch [3/50] - Loss: 0.5613
Epoch [4/50] - Loss: 0.5080
Epoch [5/50] - Loss: 0.4594
Epoch [6/50] - Loss: 0.4155
Epoch [7/50] - Loss: 0.3755
Epoch [8/50] - Loss: 0.3380
Epoch [9/50] - Loss: 0.3023
Epoch [10/50] - Loss: 0.2681
Epoch [11/50] - Loss: 0.2358
Epoch [12/50] - Loss: 0.2061
Epoch [13/50] - Loss: 0.1797
Epoch [14/50] - Loss: 0.1568
Epoch [15/50] - Loss: 0.1368
Epoch [16/50] - Loss: 0.1189
Epoch [17/50] - Loss: 0.1024
Epoch [18/50] - Loss: 0.0872
Epoch [19/50] - Loss: 0.0732
Epoch [20/50] - Loss: 0.0608
Epoch [21/50] - Loss: 0.0502
Epoch [22/50] - Loss: 0.0415
Epoch [23/50] - Loss: 0.0345
Epoch [24/50] - Loss: 0.0290
Epoch [25/50] - Loss: 0.0246
Epoch [26/50] - Loss: 0.0211
Epoch [27/50] - Loss: 0.0182
Epoch [28/50] - Loss: 0.0158
Epoch [29/50] - Loss: 0.0137
Epoch [30/50] - Loss: 0.0120
Epoch [31/50] - Loss: 0.0105
Epoch [32/50] - Loss: 0.0093
Epoch [33/50] - Loss: 0.0082
Epoch [34/50] - Loss: 0.0074
Epoch [35/50] - Loss: 0.0067
Epoch [36/50] - Loss: 0.0061
Epoch [37/50] - Loss: 0.0056
Epoch [38/50] - Loss: 0.0052
Epoch [39/50] - Loss: 0.0048
Epoch [40/50] - Loss: 0.0045
Epoch [41/50] - Loss: 0.0043
Epoch [42/50] - Loss: 0.0041
Epoch [43/50] - Loss: 0.0039
Epoch [44/50] - Loss: 0.0037
Epoch [45/50] - Loss: 0.0035
Epoch [46/50] - Loss: 0.0034
Epoch [47/50] - Loss: 0.0033
Epoch [48/50] - Loss: 0.0032
Epoch [49/50] - Loss: 0.0031
Epoch [50/50] - Loss: 0.0030
sum preds 192
sum labels 561
 - Test Metrics: Accuracy=0.8497, F1=0.3639, Recall=0.2442, Precision=0.7135
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7178
Epoch [2/50] - Loss: 0.6840
Epoch [3/50] - Loss: 0.6649
Epoch [4/50] - Loss: 0.6434
Epoch [5/50] - Loss: 0.6203
Epoch [6/50] - Loss: 0.5958
Epoch [7/50] - Loss: 0.5703
Epoch [8/50] - Loss: 0.5442
Epoch [9/50] - Loss: 0.5175
Epoch [10/50] - Loss: 0.4905
Epoch [11/50] - Loss: 0.4632
Epoch [12/50] - Loss: 0.4360
Epoch [13/50] - Loss: 0.4088
Epoch [14/50] - Loss: 0.3816
Epoch [15/50] - Loss: 0.3545
Epoch [16/50] - Loss: 0.3273
Epoch [17/50] - Loss: 0.3003
Epoch [18/50] - Loss: 0.2739
Epoch [19/50] - Loss: 0.2481
Epoch [20/50] - Loss: 0.2238
Epoch [21/50] - Loss: 0.2012
Epoch [22/50] - Loss: 0.1803
Epoch [23/50] - Loss: 0.1613
Epoch [24/50] - Loss: 0.1436
Epoch [25/50] - Loss: 0.1267
Epoch [26/50] - Loss: 0.1106
Epoch [27/50] - Loss: 0.0957
Epoch [28/50] - Loss: 0.0823
Epoch [29/50] - Loss: 0.0707
Epoch [30/50] - Loss: 0.0607
Epoch [31/50] - Loss: 0.0524
Epoch [32/50] - Loss: 0.0453
Epoch [33/50] - Loss: 0.0392
Epoch [34/50] - Loss: 0.0341
Epoch [35/50] - Loss: 0.0296
Epoch [36/50] - Loss: 0.0258
Epoch [37/50] - Loss: 0.0226
Epoch [38/50] - Loss: 0.0199
Epoch [39/50] - Loss: 0.0176
Epoch [40/50] - Loss: 0.0156
Epoch [41/50] - Loss: 0.0139
Epoch [42/50] - Loss: 0.0125
Epoch [43/50] - Loss: 0.0113
Epoch [44/50] - Loss: 0.0102
Epoch [45/50] - Loss: 0.0093
Epoch [46/50] - Loss: 0.0085
Epoch [47/50] - Loss: 0.0078
Epoch [48/50] - Loss: 0.0072
Epoch [49/50] - Loss: 0.0067
Epoch [50/50] - Loss: 0.0063
sum preds 226
sum labels 561
 - Test Metrics: Accuracy=0.8685, F1=0.4676, Recall=0.3280, Precision=0.8142
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_spy_spy_1804091105.csv.
Average F1 over valid seeds: 0.4231 ± 0.0436
___________________________________________________________________________________
Avg F1 for citeseer with SAR and spy, MLP,0.2: 0.4231 ± 0.0436
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7070
Epoch [2/50] - Loss: 0.5881
Epoch [3/50] - Loss: 0.5129
Epoch [4/50] - Loss: 0.4612
Epoch [5/50] - Loss: 0.4234
Epoch [6/50] - Loss: 0.3903
Epoch [7/50] - Loss: 0.3576
Epoch [8/50] - Loss: 0.3258
Epoch [9/50] - Loss: 0.2960
Epoch [10/50] - Loss: 0.2705
Epoch [11/50] - Loss: 0.2501
Epoch [12/50] - Loss: 0.2338
Epoch [13/50] - Loss: 0.2205
Epoch [14/50] - Loss: 0.2083
Epoch [15/50] - Loss: 0.1962
Epoch [16/50] - Loss: 0.1826
Epoch [17/50] - Loss: 0.1681
Epoch [18/50] - Loss: 0.1530
Epoch [19/50] - Loss: 0.1382
Epoch [20/50] - Loss: 0.1245
Epoch [21/50] - Loss: 0.1124
Epoch [22/50] - Loss: 0.1020
Epoch [23/50] - Loss: 0.0929
Epoch [24/50] - Loss: 0.0844
Epoch [25/50] - Loss: 0.0765
Epoch [26/50] - Loss: 0.0687
Epoch [27/50] - Loss: 0.0621
Epoch [28/50] - Loss: 0.0572
Epoch [29/50] - Loss: 0.0535
Epoch [30/50] - Loss: 0.0500
Epoch [31/50] - Loss: 0.0466
Epoch [32/50] - Loss: 0.0433
Epoch [33/50] - Loss: 0.0401
Epoch [34/50] - Loss: 0.0374
Epoch [35/50] - Loss: 0.0353
Epoch [36/50] - Loss: 0.0333
Epoch [37/50] - Loss: 0.0311
Epoch [38/50] - Loss: 0.0290
Epoch [39/50] - Loss: 0.0272
Epoch [40/50] - Loss: 0.0257
Epoch [41/50] - Loss: 0.0245
Epoch [42/50] - Loss: 0.0229
Epoch [43/50] - Loss: 0.0214
Epoch [44/50] - Loss: 0.0204
Epoch [45/50] - Loss: 0.0196
Epoch [46/50] - Loss: 0.0187
Epoch [47/50] - Loss: 0.0179
Epoch [48/50] - Loss: 0.0171
Epoch [49/50] - Loss: 0.0162
Epoch [50/50] - Loss: 0.0156
sum preds 307
sum labels 561
 - Test Metrics: Accuracy=0.8789, F1=0.5553, Recall=0.4296, Precision=0.7850
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6978
Epoch [2/50] - Loss: 0.5674
Epoch [3/50] - Loss: 0.4861
Epoch [4/50] - Loss: 0.4385
Epoch [5/50] - Loss: 0.4051
Epoch [6/50] - Loss: 0.3725
Epoch [7/50] - Loss: 0.3376
Epoch [8/50] - Loss: 0.3040
Epoch [9/50] - Loss: 0.2758
Epoch [10/50] - Loss: 0.2541
Epoch [11/50] - Loss: 0.2375
Epoch [12/50] - Loss: 0.2236
Epoch [13/50] - Loss: 0.2114
Epoch [14/50] - Loss: 0.2001
Epoch [15/50] - Loss: 0.1884
Epoch [16/50] - Loss: 0.1761
Epoch [17/50] - Loss: 0.1635
Epoch [18/50] - Loss: 0.1514
Epoch [19/50] - Loss: 0.1403
Epoch [20/50] - Loss: 0.1302
Epoch [21/50] - Loss: 0.1212
Epoch [22/50] - Loss: 0.1135
Epoch [23/50] - Loss: 0.1071
Epoch [24/50] - Loss: 0.1018
Epoch [25/50] - Loss: 0.0970
Epoch [26/50] - Loss: 0.0924
Epoch [27/50] - Loss: 0.0876
Epoch [28/50] - Loss: 0.0829
Epoch [29/50] - Loss: 0.0783
Epoch [30/50] - Loss: 0.0742
Epoch [31/50] - Loss: 0.0704
Epoch [32/50] - Loss: 0.0671
Epoch [33/50] - Loss: 0.0644
Epoch [34/50] - Loss: 0.0622
Epoch [35/50] - Loss: 0.0599
Epoch [36/50] - Loss: 0.0577
Epoch [37/50] - Loss: 0.0555
Epoch [38/50] - Loss: 0.0534
Epoch [39/50] - Loss: 0.0511
Epoch [40/50] - Loss: 0.0489
Epoch [41/50] - Loss: 0.0469
Epoch [42/50] - Loss: 0.0450
Epoch [43/50] - Loss: 0.0434
Epoch [44/50] - Loss: 0.0419
Epoch [45/50] - Loss: 0.0408
Epoch [46/50] - Loss: 0.0399
Epoch [47/50] - Loss: 0.0390
Epoch [48/50] - Loss: 0.0382
Epoch [49/50] - Loss: 0.0375
Epoch [50/50] - Loss: 0.0370
sum preds 313
sum labels 561
 - Test Metrics: Accuracy=0.8776, F1=0.5538, Recall=0.4314, Precision=0.7732
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6961
Epoch [2/50] - Loss: 0.5588
Epoch [3/50] - Loss: 0.4824
Epoch [4/50] - Loss: 0.4424
Epoch [5/50] - Loss: 0.4131
Epoch [6/50] - Loss: 0.3813
Epoch [7/50] - Loss: 0.3469
Epoch [8/50] - Loss: 0.3150
Epoch [9/50] - Loss: 0.2890
Epoch [10/50] - Loss: 0.2694
Epoch [11/50] - Loss: 0.2540
Epoch [12/50] - Loss: 0.2406
Epoch [13/50] - Loss: 0.2281
Epoch [14/50] - Loss: 0.2158
Epoch [15/50] - Loss: 0.2034
Epoch [16/50] - Loss: 0.1911
Epoch [17/50] - Loss: 0.1788
Epoch [18/50] - Loss: 0.1669
Epoch [19/50] - Loss: 0.1556
Epoch [20/50] - Loss: 0.1451
Epoch [21/50] - Loss: 0.1357
Epoch [22/50] - Loss: 0.1270
Epoch [23/50] - Loss: 0.1191
Epoch [24/50] - Loss: 0.1117
Epoch [25/50] - Loss: 0.1046
Epoch [26/50] - Loss: 0.0976
Epoch [27/50] - Loss: 0.0905
Epoch [28/50] - Loss: 0.0834
Epoch [29/50] - Loss: 0.0763
Epoch [30/50] - Loss: 0.0697
Epoch [31/50] - Loss: 0.0636
Epoch [32/50] - Loss: 0.0582
Epoch [33/50] - Loss: 0.0541
Epoch [34/50] - Loss: 0.0510
Epoch [35/50] - Loss: 0.0484
Epoch [36/50] - Loss: 0.0457
Epoch [37/50] - Loss: 0.0428
Epoch [38/50] - Loss: 0.0399
Epoch [39/50] - Loss: 0.0374
Epoch [40/50] - Loss: 0.0353
Epoch [41/50] - Loss: 0.0333
Epoch [42/50] - Loss: 0.0314
Epoch [43/50] - Loss: 0.0296
Epoch [44/50] - Loss: 0.0281
Epoch [45/50] - Loss: 0.0268
Epoch [46/50] - Loss: 0.0256
Epoch [47/50] - Loss: 0.0245
Epoch [48/50] - Loss: 0.0234
Epoch [49/50] - Loss: 0.0223
Epoch [50/50] - Loss: 0.0214
sum preds 268
sum labels 561
 - Test Metrics: Accuracy=0.8679, F1=0.4922, Recall=0.3636, Precision=0.7612
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_spy_spy_1804091126.csv.
Average F1 over valid seeds: 0.5337 ± 0.0294
___________________________________________________________________________________
Avg F1 for citeseer with SAR and spy, GATConv,0.2: 0.5337 ± 0.0294
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6954
Epoch [2/50] - Loss: 0.5745
Epoch [3/50] - Loss: 0.4979
Epoch [4/50] - Loss: 0.4474
Epoch [5/50] - Loss: 0.4081
Epoch [6/50] - Loss: 0.3701
Epoch [7/50] - Loss: 0.3323
Epoch [8/50] - Loss: 0.2975
Epoch [9/50] - Loss: 0.2689
Epoch [10/50] - Loss: 0.2476
Epoch [11/50] - Loss: 0.2320
Epoch [12/50] - Loss: 0.2198
Epoch [13/50] - Loss: 0.2085
Epoch [14/50] - Loss: 0.1968
Epoch [15/50] - Loss: 0.1841
Epoch [16/50] - Loss: 0.1711
Epoch [17/50] - Loss: 0.1588
Epoch [18/50] - Loss: 0.1478
Epoch [19/50] - Loss: 0.1384
Epoch [20/50] - Loss: 0.1303
Epoch [21/50] - Loss: 0.1228
Epoch [22/50] - Loss: 0.1156
Epoch [23/50] - Loss: 0.1084
Epoch [24/50] - Loss: 0.1015
Epoch [25/50] - Loss: 0.0953
Epoch [26/50] - Loss: 0.0899
Epoch [27/50] - Loss: 0.0854
Epoch [28/50] - Loss: 0.0816
Epoch [29/50] - Loss: 0.0781
Epoch [30/50] - Loss: 0.0748
Epoch [31/50] - Loss: 0.0716
Epoch [32/50] - Loss: 0.0684
Epoch [33/50] - Loss: 0.0655
Epoch [34/50] - Loss: 0.0629
Epoch [35/50] - Loss: 0.0607
Epoch [36/50] - Loss: 0.0586
Epoch [37/50] - Loss: 0.0564
Epoch [38/50] - Loss: 0.0542
Epoch [39/50] - Loss: 0.0521
Epoch [40/50] - Loss: 0.0501
Epoch [41/50] - Loss: 0.0484
Epoch [42/50] - Loss: 0.0468
Epoch [43/50] - Loss: 0.0454
Epoch [44/50] - Loss: 0.0439
Epoch [45/50] - Loss: 0.0425
Epoch [46/50] - Loss: 0.0412
Epoch [47/50] - Loss: 0.0400
Epoch [48/50] - Loss: 0.0388
Epoch [49/50] - Loss: 0.0378
Epoch [50/50] - Loss: 0.0368
sum preds 266
sum labels 561
 - Test Metrics: Accuracy=0.8786, F1=0.5320, Recall=0.3922, Precision=0.8271
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6714
Epoch [2/50] - Loss: 0.5556
Epoch [3/50] - Loss: 0.4737
Epoch [4/50] - Loss: 0.4283
Epoch [5/50] - Loss: 0.3890
Epoch [6/50] - Loss: 0.3459
Epoch [7/50] - Loss: 0.3049
Epoch [8/50] - Loss: 0.2739
Epoch [9/50] - Loss: 0.2531
Epoch [10/50] - Loss: 0.2379
Epoch [11/50] - Loss: 0.2245
Epoch [12/50] - Loss: 0.2109
Epoch [13/50] - Loss: 0.1969
Epoch [14/50] - Loss: 0.1829
Epoch [15/50] - Loss: 0.1696
Epoch [16/50] - Loss: 0.1579
Epoch [17/50] - Loss: 0.1485
Epoch [18/50] - Loss: 0.1411
Epoch [19/50] - Loss: 0.1352
Epoch [20/50] - Loss: 0.1297
Epoch [21/50] - Loss: 0.1239
Epoch [22/50] - Loss: 0.1178
Epoch [23/50] - Loss: 0.1117
Epoch [24/50] - Loss: 0.1064
Epoch [25/50] - Loss: 0.1022
Epoch [26/50] - Loss: 0.0986
Epoch [27/50] - Loss: 0.0952
Epoch [28/50] - Loss: 0.0917
Epoch [29/50] - Loss: 0.0881
Epoch [30/50] - Loss: 0.0848
Epoch [31/50] - Loss: 0.0820
Epoch [32/50] - Loss: 0.0796
Epoch [33/50] - Loss: 0.0772
Epoch [34/50] - Loss: 0.0746
Epoch [35/50] - Loss: 0.0721
Epoch [36/50] - Loss: 0.0698
Epoch [37/50] - Loss: 0.0679
Epoch [38/50] - Loss: 0.0663
Epoch [39/50] - Loss: 0.0646
Epoch [40/50] - Loss: 0.0629
Epoch [41/50] - Loss: 0.0612
Epoch [42/50] - Loss: 0.0595
Epoch [43/50] - Loss: 0.0580
Epoch [44/50] - Loss: 0.0565
Epoch [45/50] - Loss: 0.0550
Epoch [46/50] - Loss: 0.0536
Epoch [47/50] - Loss: 0.0523
Epoch [48/50] - Loss: 0.0511
Epoch [49/50] - Loss: 0.0501
Epoch [50/50] - Loss: 0.0490
sum preds 263
sum labels 561
 - Test Metrics: Accuracy=0.8701, F1=0.4976, Recall=0.3654, Precision=0.7795
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7057
Epoch [2/50] - Loss: 0.6085
Epoch [3/50] - Loss: 0.5401
Epoch [4/50] - Loss: 0.4906
Epoch [5/50] - Loss: 0.4566
Epoch [6/50] - Loss: 0.4305
Epoch [7/50] - Loss: 0.4061
Epoch [8/50] - Loss: 0.3801
Epoch [9/50] - Loss: 0.3527
Epoch [10/50] - Loss: 0.3261
Epoch [11/50] - Loss: 0.3023
Epoch [12/50] - Loss: 0.2831
Epoch [13/50] - Loss: 0.2679
Epoch [14/50] - Loss: 0.2552
Epoch [15/50] - Loss: 0.2438
Epoch [16/50] - Loss: 0.2327
Epoch [17/50] - Loss: 0.2217
Epoch [18/50] - Loss: 0.2105
Epoch [19/50] - Loss: 0.1993
Epoch [20/50] - Loss: 0.1883
Epoch [21/50] - Loss: 0.1777
Epoch [22/50] - Loss: 0.1677
Epoch [23/50] - Loss: 0.1585
Epoch [24/50] - Loss: 0.1502
Epoch [25/50] - Loss: 0.1428
Epoch [26/50] - Loss: 0.1360
Epoch [27/50] - Loss: 0.1296
Epoch [28/50] - Loss: 0.1236
Epoch [29/50] - Loss: 0.1178
Epoch [30/50] - Loss: 0.1124
Epoch [31/50] - Loss: 0.1075
Epoch [32/50] - Loss: 0.1031
Epoch [33/50] - Loss: 0.0992
Epoch [34/50] - Loss: 0.0956
Epoch [35/50] - Loss: 0.0920
Epoch [36/50] - Loss: 0.0886
Epoch [37/50] - Loss: 0.0852
Epoch [38/50] - Loss: 0.0820
Epoch [39/50] - Loss: 0.0790
Epoch [40/50] - Loss: 0.0763
Epoch [41/50] - Loss: 0.0736
Epoch [42/50] - Loss: 0.0711
Epoch [43/50] - Loss: 0.0687
Epoch [44/50] - Loss: 0.0663
Epoch [45/50] - Loss: 0.0641
Epoch [46/50] - Loss: 0.0620
Epoch [47/50] - Loss: 0.0600
Epoch [48/50] - Loss: 0.0580
Epoch [49/50] - Loss: 0.0560
Epoch [50/50] - Loss: 0.0542
sum preds 244
sum labels 561
 - Test Metrics: Accuracy=0.8604, F1=0.4472, Recall=0.3209, Precision=0.7377
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_spy_spy_1804091149.csv.
Average F1 over valid seeds: 0.4923 ± 0.0348
___________________________________________________________________________________
Avg F1 for citeseer with SAR and spy, GCNConv,0.2: 0.4923 ± 0.0348
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4801
Epoch [2/50] - Loss: 0.4575
Epoch [3/50] - Loss: 0.4329
Epoch [4/50] - Loss: 0.4060
Epoch [5/50] - Loss: 0.3773
Epoch [6/50] - Loss: 0.3476
Epoch [7/50] - Loss: 0.3176
Epoch [8/50] - Loss: 0.2883
Epoch [9/50] - Loss: 0.2604
Epoch [10/50] - Loss: 0.2345
Epoch [11/50] - Loss: 0.2107
Epoch [12/50] - Loss: 0.1886
Epoch [13/50] - Loss: 0.1680
Epoch [14/50] - Loss: 0.1486
Epoch [15/50] - Loss: 0.1298
Epoch [16/50] - Loss: 0.1150
Epoch [17/50] - Loss: 0.1074
Epoch [18/50] - Loss: 0.0984
Epoch [19/50] - Loss: 0.0886
Epoch [20/50] - Loss: 0.0783
Epoch [21/50] - Loss: 0.0679
Epoch [22/50] - Loss: 0.0579
Epoch [23/50] - Loss: 0.0484
Epoch [24/50] - Loss: 0.0399
Epoch [25/50] - Loss: 0.0330
Epoch [26/50] - Loss: 0.0336
Epoch [27/50] - Loss: 0.0283
Epoch [28/50] - Loss: 0.0236
Epoch [29/50] - Loss: 0.0220
Epoch [30/50] - Loss: 0.0203
Epoch [31/50] - Loss: 0.0185
Epoch [32/50] - Loss: 0.0166
Epoch [33/50] - Loss: 0.0149
Epoch [34/50] - Loss: 0.0132
Epoch [35/50] - Loss: 0.0117
Epoch [36/50] - Loss: 0.0103
Epoch [37/50] - Loss: 0.0091
Epoch [38/50] - Loss: 0.0080
Epoch [39/50] - Loss: 0.0076
Epoch [40/50] - Loss: 0.0068
Epoch [41/50] - Loss: 0.0066
Epoch [42/50] - Loss: 0.0063
Epoch [43/50] - Loss: 0.0060
Epoch [44/50] - Loss: 0.0057
Epoch [45/50] - Loss: 0.0054
Epoch [46/50] - Loss: 0.0051
Epoch [47/50] - Loss: 0.0049
Epoch [48/50] - Loss: 0.0046
Epoch [49/50] - Loss: 0.0043
Epoch [50/50] - Loss: 0.0041
sum preds 434
sum labels 421
 - Test Metrics: Accuracy=0.9189, F1=0.7111, Recall=0.7221, Precision=0.7005
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4741
Epoch [2/50] - Loss: 0.4430
Epoch [3/50] - Loss: 0.4089
Epoch [4/50] - Loss: 0.3730
Epoch [5/50] - Loss: 0.3370
Epoch [6/50] - Loss: 0.3020
Epoch [7/50] - Loss: 0.2692
Epoch [8/50] - Loss: 0.2392
Epoch [9/50] - Loss: 0.2123
Epoch [10/50] - Loss: 0.1882
Epoch [11/50] - Loss: 0.1662
Epoch [12/50] - Loss: 0.1457
Epoch [13/50] - Loss: 0.1259
Epoch [14/50] - Loss: 0.1123
Epoch [15/50] - Loss: 0.1040
Epoch [16/50] - Loss: 0.0944
Epoch [17/50] - Loss: 0.0840
Epoch [18/50] - Loss: 0.0734
Epoch [19/50] - Loss: 0.0631
Epoch [20/50] - Loss: 0.0534
Epoch [21/50] - Loss: 0.0446
Epoch [22/50] - Loss: 0.0370
Epoch [23/50] - Loss: 0.0339
Epoch [24/50] - Loss: 0.0343
Epoch [25/50] - Loss: 0.0275
Epoch [26/50] - Loss: 0.0240
Epoch [27/50] - Loss: 0.0230
Epoch [28/50] - Loss: 0.0219
Epoch [29/50] - Loss: 0.0206
Epoch [30/50] - Loss: 0.0192
Epoch [31/50] - Loss: 0.0178
Epoch [32/50] - Loss: 0.0165
Epoch [33/50] - Loss: 0.0152
Epoch [34/50] - Loss: 0.0139
Epoch [35/50] - Loss: 0.0128
Epoch [36/50] - Loss: 0.0117
Epoch [37/50] - Loss: 0.0107
Epoch [38/50] - Loss: 0.0099
Epoch [39/50] - Loss: 0.0090
Epoch [40/50] - Loss: 0.0083
Epoch [41/50] - Loss: 0.0076
Epoch [42/50] - Loss: 0.0070
Epoch [43/50] - Loss: 0.0097
Epoch [44/50] - Loss: 0.0063
Epoch [45/50] - Loss: 0.0061
Epoch [46/50] - Loss: 0.0059
Epoch [47/50] - Loss: 0.0057
Epoch [48/50] - Loss: 0.0055
Epoch [49/50] - Loss: 0.0053
Epoch [50/50] - Loss: 0.0050
sum preds 409
sum labels 421
 - Test Metrics: Accuracy=0.9088, F1=0.6651, Recall=0.6556, Precision=0.6748
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5182
Epoch [2/50] - Loss: 0.5005
Epoch [3/50] - Loss: 0.4821
Epoch [4/50] - Loss: 0.4614
Epoch [5/50] - Loss: 0.4383
Epoch [6/50] - Loss: 0.4133
Epoch [7/50] - Loss: 0.3866
Epoch [8/50] - Loss: 0.3589
Epoch [9/50] - Loss: 0.3307
Epoch [10/50] - Loss: 0.3026
Epoch [11/50] - Loss: 0.2745
Epoch [12/50] - Loss: 0.2464
Epoch [13/50] - Loss: 0.2187
Epoch [14/50] - Loss: 0.1920
Epoch [15/50] - Loss: 0.1664
Epoch [16/50] - Loss: 0.1423
Epoch [17/50] - Loss: 0.1195
Epoch [18/50] - Loss: 0.0980
Epoch [19/50] - Loss: 0.0779
Epoch [20/50] - Loss: 0.0653
Epoch [21/50] - Loss: 0.0586
Epoch [22/50] - Loss: 0.0513
Epoch [23/50] - Loss: 0.0438
Epoch [24/50] - Loss: 0.0367
Epoch [25/50] - Loss: 0.0302
Epoch [26/50] - Loss: 0.0246
Epoch [27/50] - Loss: 0.0199
Epoch [28/50] - Loss: 0.0205
Epoch [29/50] - Loss: 0.0184
Epoch [30/50] - Loss: 0.0137
Epoch [31/50] - Loss: 0.0130
Epoch [32/50] - Loss: 0.0122
Epoch [33/50] - Loss: 0.0114
Epoch [34/50] - Loss: 0.0105
Epoch [35/50] - Loss: 0.0096
Epoch [36/50] - Loss: 0.0088
Epoch [37/50] - Loss: 0.0079
Epoch [38/50] - Loss: 0.0072
Epoch [39/50] - Loss: 0.0064
Epoch [40/50] - Loss: 0.0058
Epoch [41/50] - Loss: 0.0052
Epoch [42/50] - Loss: 0.0047
Epoch [43/50] - Loss: 0.0042
Epoch [44/50] - Loss: 0.0038
Epoch [45/50] - Loss: 0.0034
Epoch [46/50] - Loss: 0.0031
Epoch [47/50] - Loss: 0.0063
Epoch [48/50] - Loss: 0.0028
Epoch [49/50] - Loss: 0.0027
Epoch [50/50] - Loss: 0.0027
sum preds 427
sum labels 421
 - Test Metrics: Accuracy=0.9061, F1=0.6627, Recall=0.6675, Precision=0.6581
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_nnpu_nnpu_1804091212.csv.
Average F1 over valid seeds: 0.6796 ± 0.0223
___________________________________________________________________________________
Avg F1 for citeseer with SAR and nnpu, MLP,0.4: 0.6796 ± 0.0223
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4973
Epoch [2/50] - Loss: 0.4335
Epoch [3/50] - Loss: 0.3716
Epoch [4/50] - Loss: 0.3147
Epoch [5/50] - Loss: 0.2666
Epoch [6/50] - Loss: 0.2279
Epoch [7/50] - Loss: 0.1967
Epoch [8/50] - Loss: 0.1704
Epoch [9/50] - Loss: 0.1464
Epoch [10/50] - Loss: 0.1290
Epoch [11/50] - Loss: 0.1167
Epoch [12/50] - Loss: 0.1031
Epoch [13/50] - Loss: 0.0889
Epoch [14/50] - Loss: 0.0755
Epoch [15/50] - Loss: 0.0638
Epoch [16/50] - Loss: 0.0536
Epoch [17/50] - Loss: 0.0448
Epoch [18/50] - Loss: 0.0424
Epoch [19/50] - Loss: 0.0430
Epoch [20/50] - Loss: 0.0374
Epoch [21/50] - Loss: 0.0285
Epoch [22/50] - Loss: 0.0270
Epoch [23/50] - Loss: 0.0253
Epoch [24/50] - Loss: 0.0237
Epoch [25/50] - Loss: 0.0220
Epoch [26/50] - Loss: 0.0204
Epoch [27/50] - Loss: 0.0188
Epoch [28/50] - Loss: 0.0173
Epoch [29/50] - Loss: 0.0159
Epoch [30/50] - Loss: 0.0146
Epoch [31/50] - Loss: 0.0133
Epoch [32/50] - Loss: 0.0134
Epoch [33/50] - Loss: 0.0118
Epoch [34/50] - Loss: 0.0114
Epoch [35/50] - Loss: 0.0110
Epoch [36/50] - Loss: 0.0106
Epoch [37/50] - Loss: 0.0101
Epoch [38/50] - Loss: 0.0097
Epoch [39/50] - Loss: 0.0093
Epoch [40/50] - Loss: 0.0088
Epoch [41/50] - Loss: 0.0084
Epoch [42/50] - Loss: 0.0079
Epoch [43/50] - Loss: 0.0075
Epoch [44/50] - Loss: 0.0070
Epoch [45/50] - Loss: 0.0066
Epoch [46/50] - Loss: 0.0073
Epoch [47/50] - Loss: 0.0062
Epoch [48/50] - Loss: 0.0062
Epoch [49/50] - Loss: 0.0061
Epoch [50/50] - Loss: 0.0060
sum preds 489
sum labels 421
 - Test Metrics: Accuracy=0.9206, F1=0.7341, Recall=0.7933, Precision=0.6830
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4897
Epoch [2/50] - Loss: 0.4174
Epoch [3/50] - Loss: 0.3459
Epoch [4/50] - Loss: 0.2881
Epoch [5/50] - Loss: 0.2472
Epoch [6/50] - Loss: 0.2209
Epoch [7/50] - Loss: 0.2047
Epoch [8/50] - Loss: 0.1943
Epoch [9/50] - Loss: 0.1865
Epoch [10/50] - Loss: 0.1805
Epoch [11/50] - Loss: 0.1778
Epoch [12/50] - Loss: 0.1735
Epoch [13/50] - Loss: 0.1678
Epoch [14/50] - Loss: 0.1609
Epoch [15/50] - Loss: 0.1533
Epoch [16/50] - Loss: 0.1448
Epoch [17/50] - Loss: 0.1358
Epoch [18/50] - Loss: 0.1267
Epoch [19/50] - Loss: 0.1175
Epoch [20/50] - Loss: 0.1079
Epoch [21/50] - Loss: 0.0981
Epoch [22/50] - Loss: 0.0882
Epoch [23/50] - Loss: 0.0780
Epoch [24/50] - Loss: 0.0681
Epoch [25/50] - Loss: 0.0582
Epoch [26/50] - Loss: 0.0487
Epoch [27/50] - Loss: 0.0486
Epoch [28/50] - Loss: 0.0515
Epoch [29/50] - Loss: 0.0491
Epoch [30/50] - Loss: 0.0411
Epoch [31/50] - Loss: 0.0290
Epoch [32/50] - Loss: 0.0281
Epoch [33/50] - Loss: 0.0275
Epoch [34/50] - Loss: 0.0266
Epoch [35/50] - Loss: 0.0254
Epoch [36/50] - Loss: 0.0242
Epoch [37/50] - Loss: 0.0229
Epoch [38/50] - Loss: 0.0217
Epoch [39/50] - Loss: 0.0205
Epoch [40/50] - Loss: 0.0194
Epoch [41/50] - Loss: 0.0184
Epoch [42/50] - Loss: 0.0175
Epoch [43/50] - Loss: 0.0167
Epoch [44/50] - Loss: 0.0160
Epoch [45/50] - Loss: 0.0154
Epoch [46/50] - Loss: 0.0148
Epoch [47/50] - Loss: 0.0142
Epoch [48/50] - Loss: 0.0137
Epoch [49/50] - Loss: 0.0132
Epoch [50/50] - Loss: 0.0127
sum preds 472
sum labels 421
 - Test Metrics: Accuracy=0.9235, F1=0.7391, Recall=0.7838, Precision=0.6992
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5038
Epoch [2/50] - Loss: 0.4482
Epoch [3/50] - Loss: 0.3941
Epoch [4/50] - Loss: 0.3412
Epoch [5/50] - Loss: 0.2934
Epoch [6/50] - Loss: 0.2531
Epoch [7/50] - Loss: 0.2206
Epoch [8/50] - Loss: 0.1942
Epoch [9/50] - Loss: 0.1710
Epoch [10/50] - Loss: 0.1483
Epoch [11/50] - Loss: 0.1266
Epoch [12/50] - Loss: 0.1112
Epoch [13/50] - Loss: 0.0938
Epoch [14/50] - Loss: 0.0773
Epoch [15/50] - Loss: 0.0628
Epoch [16/50] - Loss: 0.0510
Epoch [17/50] - Loss: 0.0511
Epoch [18/50] - Loss: 0.0529
Epoch [19/50] - Loss: 0.0478
Epoch [20/50] - Loss: 0.0371
Epoch [21/50] - Loss: 0.0311
Epoch [22/50] - Loss: 0.0304
Epoch [23/50] - Loss: 0.0293
Epoch [24/50] - Loss: 0.0279
Epoch [25/50] - Loss: 0.0263
Epoch [26/50] - Loss: 0.0246
Epoch [27/50] - Loss: 0.0230
Epoch [28/50] - Loss: 0.0215
Epoch [29/50] - Loss: 0.0201
Epoch [30/50] - Loss: 0.0188
Epoch [31/50] - Loss: 0.0177
Epoch [32/50] - Loss: 0.0168
Epoch [33/50] - Loss: 0.0159
Epoch [34/50] - Loss: 0.0150
Epoch [35/50] - Loss: 0.0142
Epoch [36/50] - Loss: 0.0134
Epoch [37/50] - Loss: 0.0137
Epoch [38/50] - Loss: 0.0123
Epoch [39/50] - Loss: 0.0120
Epoch [40/50] - Loss: 0.0116
Epoch [41/50] - Loss: 0.0111
Epoch [42/50] - Loss: 0.0107
Epoch [43/50] - Loss: 0.0102
Epoch [44/50] - Loss: 0.0097
Epoch [45/50] - Loss: 0.0093
Epoch [46/50] - Loss: 0.0089
Epoch [47/50] - Loss: 0.0085
Epoch [48/50] - Loss: 0.0082
Epoch [49/50] - Loss: 0.0079
Epoch [50/50] - Loss: 0.0083
sum preds 532
sum labels 421
 - Test Metrics: Accuracy=0.9065, F1=0.7009, Recall=0.7933, Precision=0.6278
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_nnpu_nnpu_1804091214.csv.
Average F1 over valid seeds: 0.7247 ± 0.0169
___________________________________________________________________________________
Avg F1 for citeseer with SAR and nnpu, GATConv,0.4: 0.7247 ± 0.0169
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4945
Epoch [2/50] - Loss: 0.4093
Epoch [3/50] - Loss: 0.3324
Epoch [4/50] - Loss: 0.2733
Epoch [5/50] - Loss: 0.2326
Epoch [6/50] - Loss: 0.2051
Epoch [7/50] - Loss: 0.1851
Epoch [8/50] - Loss: 0.1679
Epoch [9/50] - Loss: 0.1541
Epoch [10/50] - Loss: 0.1445
Epoch [11/50] - Loss: 0.1323
Epoch [12/50] - Loss: 0.1181
Epoch [13/50] - Loss: 0.1031
Epoch [14/50] - Loss: 0.0883
Epoch [15/50] - Loss: 0.0745
Epoch [16/50] - Loss: 0.0624
Epoch [17/50] - Loss: 0.0520
Epoch [18/50] - Loss: 0.0432
Epoch [19/50] - Loss: 0.0474
Epoch [20/50] - Loss: 0.0520
Epoch [21/50] - Loss: 0.0506
Epoch [22/50] - Loss: 0.0435
Epoch [23/50] - Loss: 0.0328
Epoch [24/50] - Loss: 0.0291
Epoch [25/50] - Loss: 0.0295
Epoch [26/50] - Loss: 0.0294
Epoch [27/50] - Loss: 0.0290
Epoch [28/50] - Loss: 0.0284
Epoch [29/50] - Loss: 0.0276
Epoch [30/50] - Loss: 0.0266
Epoch [31/50] - Loss: 0.0255
Epoch [32/50] - Loss: 0.0243
Epoch [33/50] - Loss: 0.0231
Epoch [34/50] - Loss: 0.0218
Epoch [35/50] - Loss: 0.0205
Epoch [36/50] - Loss: 0.0193
Epoch [37/50] - Loss: 0.0180
Epoch [38/50] - Loss: 0.0167
Epoch [39/50] - Loss: 0.0155
Epoch [40/50] - Loss: 0.0143
Epoch [41/50] - Loss: 0.0133
Epoch [42/50] - Loss: 0.0155
Epoch [43/50] - Loss: 0.0138
Epoch [44/50] - Loss: 0.0123
Epoch [45/50] - Loss: 0.0124
Epoch [46/50] - Loss: 0.0124
Epoch [47/50] - Loss: 0.0124
Epoch [48/50] - Loss: 0.0122
Epoch [49/50] - Loss: 0.0120
Epoch [50/50] - Loss: 0.0117
sum preds 484
sum labels 421
 - Test Metrics: Accuracy=0.9183, F1=0.7249, Recall=0.7791, Precision=0.6777
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4471
Epoch [3/50] - Loss: 0.3935
Epoch [4/50] - Loss: 0.3415
Epoch [5/50] - Loss: 0.2944
Epoch [6/50] - Loss: 0.2535
Epoch [7/50] - Loss: 0.2187
Epoch [8/50] - Loss: 0.1888
Epoch [9/50] - Loss: 0.1623
Epoch [10/50] - Loss: 0.1381
Epoch [11/50] - Loss: 0.1161
Epoch [12/50] - Loss: 0.0989
Epoch [13/50] - Loss: 0.0867
Epoch [14/50] - Loss: 0.0742
Epoch [15/50] - Loss: 0.0624
Epoch [16/50] - Loss: 0.0571
Epoch [17/50] - Loss: 0.0549
Epoch [18/50] - Loss: 0.0499
Epoch [19/50] - Loss: 0.0418
Epoch [20/50] - Loss: 0.0382
Epoch [21/50] - Loss: 0.0369
Epoch [22/50] - Loss: 0.0353
Epoch [23/50] - Loss: 0.0334
Epoch [24/50] - Loss: 0.0313
Epoch [25/50] - Loss: 0.0292
Epoch [26/50] - Loss: 0.0271
Epoch [27/50] - Loss: 0.0252
Epoch [28/50] - Loss: 0.0233
Epoch [29/50] - Loss: 0.0216
Epoch [30/50] - Loss: 0.0247
Epoch [31/50] - Loss: 0.0226
Epoch [32/50] - Loss: 0.0197
Epoch [33/50] - Loss: 0.0197
Epoch [34/50] - Loss: 0.0196
Epoch [35/50] - Loss: 0.0194
Epoch [36/50] - Loss: 0.0190
Epoch [37/50] - Loss: 0.0186
Epoch [38/50] - Loss: 0.0181
Epoch [39/50] - Loss: 0.0175
Epoch [40/50] - Loss: 0.0170
Epoch [41/50] - Loss: 0.0164
Epoch [42/50] - Loss: 0.0159
Epoch [43/50] - Loss: 0.0154
Epoch [44/50] - Loss: 0.0149
Epoch [45/50] - Loss: 0.0144
Epoch [46/50] - Loss: 0.0139
Epoch [47/50] - Loss: 0.0135
Epoch [48/50] - Loss: 0.0141
Epoch [49/50] - Loss: 0.0130
Epoch [50/50] - Loss: 0.0130
sum preds 503
sum labels 421
 - Test Metrics: Accuracy=0.9199, F1=0.7359, Recall=0.8076, Precision=0.6759
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4956
Epoch [2/50] - Loss: 0.4338
Epoch [3/50] - Loss: 0.3760
Epoch [4/50] - Loss: 0.3228
Epoch [5/50] - Loss: 0.2772
Epoch [6/50] - Loss: 0.2395
Epoch [7/50] - Loss: 0.2084
Epoch [8/50] - Loss: 0.1820
Epoch [9/50] - Loss: 0.1585
Epoch [10/50] - Loss: 0.1362
Epoch [11/50] - Loss: 0.1178
Epoch [12/50] - Loss: 0.1048
Epoch [13/50] - Loss: 0.0904
Epoch [14/50] - Loss: 0.0757
Epoch [15/50] - Loss: 0.0619
Epoch [16/50] - Loss: 0.0500
Epoch [17/50] - Loss: 0.0433
Epoch [18/50] - Loss: 0.0442
Epoch [19/50] - Loss: 0.0403
Epoch [20/50] - Loss: 0.0315
Epoch [21/50] - Loss: 0.0295
Epoch [22/50] - Loss: 0.0290
Epoch [23/50] - Loss: 0.0280
Epoch [24/50] - Loss: 0.0267
Epoch [25/50] - Loss: 0.0252
Epoch [26/50] - Loss: 0.0236
Epoch [27/50] - Loss: 0.0219
Epoch [28/50] - Loss: 0.0203
Epoch [29/50] - Loss: 0.0187
Epoch [30/50] - Loss: 0.0172
Epoch [31/50] - Loss: 0.0158
Epoch [32/50] - Loss: 0.0145
Epoch [33/50] - Loss: 0.0133
Epoch [34/50] - Loss: 0.0123
Epoch [35/50] - Loss: 0.0149
Epoch [36/50] - Loss: 0.0119
Epoch [37/50] - Loss: 0.0114
Epoch [38/50] - Loss: 0.0116
Epoch [39/50] - Loss: 0.0117
Epoch [40/50] - Loss: 0.0117
Epoch [41/50] - Loss: 0.0116
Epoch [42/50] - Loss: 0.0115
Epoch [43/50] - Loss: 0.0113
Epoch [44/50] - Loss: 0.0111
Epoch [45/50] - Loss: 0.0108
Epoch [46/50] - Loss: 0.0105
Epoch [47/50] - Loss: 0.0102
Epoch [48/50] - Loss: 0.0099
Epoch [49/50] - Loss: 0.0095
Epoch [50/50] - Loss: 0.0092
sum preds 459
sum labels 421
 - Test Metrics: Accuracy=0.9180, F1=0.7159, Recall=0.7482, Precision=0.6863
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_nnpu_nnpu_1804091217.csv.
Average F1 over valid seeds: 0.7256 ± 0.0082
___________________________________________________________________________________
Avg F1 for citeseer with SAR and nnpu, GCNConv,0.4: 0.7256 ± 0.0082
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4800
Epoch [2/50] - Loss: 0.4571
Epoch [3/50] - Loss: 0.4318
Epoch [4/50] - Loss: 0.4039
Epoch [5/50] - Loss: 0.3740
Epoch [6/50] - Loss: 0.3430
Epoch [7/50] - Loss: 0.3117
Epoch [8/50] - Loss: 0.2811
Epoch [9/50] - Loss: 0.2517
Epoch [10/50] - Loss: 0.2241
Epoch [11/50] - Loss: 0.1982
Epoch [12/50] - Loss: 0.1739
Epoch [13/50] - Loss: 0.1509
Epoch [14/50] - Loss: 0.1289
Epoch [15/50] - Loss: 0.1077
Epoch [16/50] - Loss: 0.0995
Epoch [17/50] - Loss: 0.0908
Epoch [18/50] - Loss: 0.0811
Epoch [19/50] - Loss: 0.0711
Epoch [20/50] - Loss: 0.0610
Epoch [21/50] - Loss: 0.0514
Epoch [22/50] - Loss: 0.0426
Epoch [23/50] - Loss: 0.0349
Epoch [24/50] - Loss: 0.0285
Epoch [25/50] - Loss: 0.0232
Epoch [26/50] - Loss: 0.0228
Epoch [27/50] - Loss: 0.0227
Epoch [28/50] - Loss: 0.0156
Epoch [29/50] - Loss: 0.0146
Epoch [30/50] - Loss: 0.0135
Epoch [31/50] - Loss: 0.0125
Epoch [32/50] - Loss: 0.0115
Epoch [33/50] - Loss: 0.0105
Epoch [34/50] - Loss: 0.0096
Epoch [35/50] - Loss: 0.0088
Epoch [36/50] - Loss: 0.0079
Epoch [37/50] - Loss: 0.0072
Epoch [38/50] - Loss: 0.0065
Epoch [39/50] - Loss: 0.0059
Epoch [40/50] - Loss: 0.0053
Epoch [41/50] - Loss: 0.0048
Epoch [42/50] - Loss: 0.0048
Epoch [43/50] - Loss: 0.0042
Epoch [44/50] - Loss: 0.0041
Epoch [45/50] - Loss: 0.0040
Epoch [46/50] - Loss: 0.0039
Epoch [47/50] - Loss: 0.0037
Epoch [48/50] - Loss: 0.0036
Epoch [49/50] - Loss: 0.0035
Epoch [50/50] - Loss: 0.0033
sum preds 403
sum labels 491
 - Test Metrics: Accuracy=0.9115, F1=0.6913, Recall=0.6293, Precision=0.7667
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4740
Epoch [2/50] - Loss: 0.4425
Epoch [3/50] - Loss: 0.4076
Epoch [4/50] - Loss: 0.3708
Epoch [5/50] - Loss: 0.3337
Epoch [6/50] - Loss: 0.2979
Epoch [7/50] - Loss: 0.2643
Epoch [8/50] - Loss: 0.2335
Epoch [9/50] - Loss: 0.2056
Epoch [10/50] - Loss: 0.1801
Epoch [11/50] - Loss: 0.1564
Epoch [12/50] - Loss: 0.1339
Epoch [13/50] - Loss: 0.1123
Epoch [14/50] - Loss: 0.1036
Epoch [15/50] - Loss: 0.0948
Epoch [16/50] - Loss: 0.0848
Epoch [17/50] - Loss: 0.0744
Epoch [18/50] - Loss: 0.0641
Epoch [19/50] - Loss: 0.0543
Epoch [20/50] - Loss: 0.0453
Epoch [21/50] - Loss: 0.0373
Epoch [22/50] - Loss: 0.0305
Epoch [23/50] - Loss: 0.0248
Epoch [24/50] - Loss: 0.0346
Epoch [25/50] - Loss: 0.0339
Epoch [26/50] - Loss: 0.0231
Epoch [27/50] - Loss: 0.0170
Epoch [28/50] - Loss: 0.0168
Epoch [29/50] - Loss: 0.0164
Epoch [30/50] - Loss: 0.0158
Epoch [31/50] - Loss: 0.0151
Epoch [32/50] - Loss: 0.0143
Epoch [33/50] - Loss: 0.0135
Epoch [34/50] - Loss: 0.0126
Epoch [35/50] - Loss: 0.0117
Epoch [36/50] - Loss: 0.0108
Epoch [37/50] - Loss: 0.0100
Epoch [38/50] - Loss: 0.0092
Epoch [39/50] - Loss: 0.0085
Epoch [40/50] - Loss: 0.0078
Epoch [41/50] - Loss: 0.0072
Epoch [42/50] - Loss: 0.0066
Epoch [43/50] - Loss: 0.0061
Epoch [44/50] - Loss: 0.0056
Epoch [45/50] - Loss: 0.0051
Epoch [46/50] - Loss: 0.0047
Epoch [47/50] - Loss: 0.0044
Epoch [48/50] - Loss: 0.0041
Epoch [49/50] - Loss: 0.0038
Epoch [50/50] - Loss: 0.0036
sum preds 432
sum labels 491
 - Test Metrics: Accuracy=0.9079, F1=0.6891, Recall=0.6477, Precision=0.7361
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5183
Epoch [2/50] - Loss: 0.5002
Epoch [3/50] - Loss: 0.4811
Epoch [4/50] - Loss: 0.4592
Epoch [5/50] - Loss: 0.4348
Epoch [6/50] - Loss: 0.4084
Epoch [7/50] - Loss: 0.3804
Epoch [8/50] - Loss: 0.3515
Epoch [9/50] - Loss: 0.3220
Epoch [10/50] - Loss: 0.2923
Epoch [11/50] - Loss: 0.2622
Epoch [12/50] - Loss: 0.2324
Epoch [13/50] - Loss: 0.2032
Epoch [14/50] - Loss: 0.1748
Epoch [15/50] - Loss: 0.1477
Epoch [16/50] - Loss: 0.1218
Epoch [17/50] - Loss: 0.0975
Epoch [18/50] - Loss: 0.0747
Epoch [19/50] - Loss: 0.0590
Epoch [20/50] - Loss: 0.0526
Epoch [21/50] - Loss: 0.0456
Epoch [22/50] - Loss: 0.0385
Epoch [23/50] - Loss: 0.0318
Epoch [24/50] - Loss: 0.0258
Epoch [25/50] - Loss: 0.0207
Epoch [26/50] - Loss: 0.0164
Epoch [27/50] - Loss: 0.0129
Epoch [28/50] - Loss: 0.0101
Epoch [29/50] - Loss: 0.0195
Epoch [30/50] - Loss: 0.0150
Epoch [31/50] - Loss: 0.0070
Epoch [32/50] - Loss: 0.0068
Epoch [33/50] - Loss: 0.0065
Epoch [34/50] - Loss: 0.0062
Epoch [35/50] - Loss: 0.0059
Epoch [36/50] - Loss: 0.0055
Epoch [37/50] - Loss: 0.0051
Epoch [38/50] - Loss: 0.0047
Epoch [39/50] - Loss: 0.0044
Epoch [40/50] - Loss: 0.0040
Epoch [41/50] - Loss: 0.0037
Epoch [42/50] - Loss: 0.0034
Epoch [43/50] - Loss: 0.0032
Epoch [44/50] - Loss: 0.0029
Epoch [45/50] - Loss: 0.0027
Epoch [46/50] - Loss: 0.0025
Epoch [47/50] - Loss: 0.0023
Epoch [48/50] - Loss: 0.0021
Epoch [49/50] - Loss: 0.0019
Epoch [50/50] - Loss: 0.0018
sum preds 403
sum labels 491
 - Test Metrics: Accuracy=0.9012, F1=0.6555, Recall=0.5967, Precision=0.7270
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_nnpu_nnpu_1804091219.csv.
Average F1 over valid seeds: 0.6786 ± 0.0164
___________________________________________________________________________________
Avg F1 for citeseer with SAR and nnpu, MLP,0.3: 0.6786 ± 0.0164
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4969
Epoch [2/50] - Loss: 0.4325
Epoch [3/50] - Loss: 0.3699
Epoch [4/50] - Loss: 0.3121
Epoch [5/50] - Loss: 0.2632
Epoch [6/50] - Loss: 0.2236
Epoch [7/50] - Loss: 0.1914
Epoch [8/50] - Loss: 0.1641
Epoch [9/50] - Loss: 0.1393
Epoch [10/50] - Loss: 0.1242
Epoch [11/50] - Loss: 0.1117
Epoch [12/50] - Loss: 0.0975
Epoch [13/50] - Loss: 0.0832
Epoch [14/50] - Loss: 0.0700
Epoch [15/50] - Loss: 0.0585
Epoch [16/50] - Loss: 0.0484
Epoch [17/50] - Loss: 0.0399
Epoch [18/50] - Loss: 0.0395
Epoch [19/50] - Loss: 0.0402
Epoch [20/50] - Loss: 0.0340
Epoch [21/50] - Loss: 0.0256
Epoch [22/50] - Loss: 0.0243
Epoch [23/50] - Loss: 0.0231
Epoch [24/50] - Loss: 0.0218
Epoch [25/50] - Loss: 0.0205
Epoch [26/50] - Loss: 0.0193
Epoch [27/50] - Loss: 0.0181
Epoch [28/50] - Loss: 0.0170
Epoch [29/50] - Loss: 0.0160
Epoch [30/50] - Loss: 0.0151
Epoch [31/50] - Loss: 0.0142
Epoch [32/50] - Loss: 0.0134
Epoch [33/50] - Loss: 0.0126
Epoch [34/50] - Loss: 0.0118
Epoch [35/50] - Loss: 0.0110
Epoch [36/50] - Loss: 0.0101
Epoch [37/50] - Loss: 0.0124
Epoch [38/50] - Loss: 0.0089
Epoch [39/50] - Loss: 0.0085
Epoch [40/50] - Loss: 0.0082
Epoch [41/50] - Loss: 0.0079
Epoch [42/50] - Loss: 0.0076
Epoch [43/50] - Loss: 0.0073
Epoch [44/50] - Loss: 0.0071
Epoch [45/50] - Loss: 0.0068
Epoch [46/50] - Loss: 0.0066
Epoch [47/50] - Loss: 0.0064
Epoch [48/50] - Loss: 0.0063
Epoch [49/50] - Loss: 0.0061
Epoch [50/50] - Loss: 0.0059
sum preds 533
sum labels 491
 - Test Metrics: Accuracy=0.9127, F1=0.7344, Recall=0.7658, Precision=0.7054
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4893
Epoch [2/50] - Loss: 0.4173
Epoch [3/50] - Loss: 0.3464
Epoch [4/50] - Loss: 0.2890
Epoch [5/50] - Loss: 0.2483
Epoch [6/50] - Loss: 0.2221
Epoch [7/50] - Loss: 0.2059
Epoch [8/50] - Loss: 0.1954
Epoch [9/50] - Loss: 0.1876
Epoch [10/50] - Loss: 0.1813
Epoch [11/50] - Loss: 0.1787
Epoch [12/50] - Loss: 0.1746
Epoch [13/50] - Loss: 0.1693
Epoch [14/50] - Loss: 0.1629
Epoch [15/50] - Loss: 0.1556
Epoch [16/50] - Loss: 0.1475
Epoch [17/50] - Loss: 0.1388
Epoch [18/50] - Loss: 0.1296
Epoch [19/50] - Loss: 0.1198
Epoch [20/50] - Loss: 0.1094
Epoch [21/50] - Loss: 0.0988
Epoch [22/50] - Loss: 0.0883
Epoch [23/50] - Loss: 0.0780
Epoch [24/50] - Loss: 0.0679
Epoch [25/50] - Loss: 0.0580
Epoch [26/50] - Loss: 0.0483
Epoch [27/50] - Loss: 0.0515
Epoch [28/50] - Loss: 0.0546
Epoch [29/50] - Loss: 0.0520
Epoch [30/50] - Loss: 0.0436
Epoch [31/50] - Loss: 0.0314
Epoch [32/50] - Loss: 0.0269
Epoch [33/50] - Loss: 0.0261
Epoch [34/50] - Loss: 0.0251
Epoch [35/50] - Loss: 0.0239
Epoch [36/50] - Loss: 0.0227
Epoch [37/50] - Loss: 0.0214
Epoch [38/50] - Loss: 0.0203
Epoch [39/50] - Loss: 0.0192
Epoch [40/50] - Loss: 0.0182
Epoch [41/50] - Loss: 0.0174
Epoch [42/50] - Loss: 0.0167
Epoch [43/50] - Loss: 0.0161
Epoch [44/50] - Loss: 0.0155
Epoch [45/50] - Loss: 0.0150
Epoch [46/50] - Loss: 0.0145
Epoch [47/50] - Loss: 0.0139
Epoch [48/50] - Loss: 0.0134
Epoch [49/50] - Loss: 0.0127
Epoch [50/50] - Loss: 0.0119
sum preds 492
sum labels 491
 - Test Metrics: Accuracy=0.9214, F1=0.7508, Recall=0.7515, Precision=0.7500
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5034
Epoch [2/50] - Loss: 0.4483
Epoch [3/50] - Loss: 0.3947
Epoch [4/50] - Loss: 0.3418
Epoch [5/50] - Loss: 0.2940
Epoch [6/50] - Loss: 0.2535
Epoch [7/50] - Loss: 0.2206
Epoch [8/50] - Loss: 0.1938
Epoch [9/50] - Loss: 0.1704
Epoch [10/50] - Loss: 0.1481
Epoch [11/50] - Loss: 0.1262
Epoch [12/50] - Loss: 0.1119
Epoch [13/50] - Loss: 0.0960
Epoch [14/50] - Loss: 0.0800
Epoch [15/50] - Loss: 0.0657
Epoch [16/50] - Loss: 0.0554
Epoch [17/50] - Loss: 0.0535
Epoch [18/50] - Loss: 0.0489
Epoch [19/50] - Loss: 0.0406
Epoch [20/50] - Loss: 0.0350
Epoch [21/50] - Loss: 0.0333
Epoch [22/50] - Loss: 0.0313
Epoch [23/50] - Loss: 0.0293
Epoch [24/50] - Loss: 0.0273
Epoch [25/50] - Loss: 0.0253
Epoch [26/50] - Loss: 0.0234
Epoch [27/50] - Loss: 0.0216
Epoch [28/50] - Loss: 0.0198
Epoch [29/50] - Loss: 0.0182
Epoch [30/50] - Loss: 0.0189
Epoch [31/50] - Loss: 0.0162
Epoch [32/50] - Loss: 0.0155
Epoch [33/50] - Loss: 0.0147
Epoch [34/50] - Loss: 0.0139
Epoch [35/50] - Loss: 0.0131
Epoch [36/50] - Loss: 0.0122
Epoch [37/50] - Loss: 0.0114
Epoch [38/50] - Loss: 0.0106
Epoch [39/50] - Loss: 0.0103
Epoch [40/50] - Loss: 0.0096
Epoch [41/50] - Loss: 0.0093
Epoch [42/50] - Loss: 0.0089
Epoch [43/50] - Loss: 0.0085
Epoch [44/50] - Loss: 0.0081
Epoch [45/50] - Loss: 0.0076
Epoch [46/50] - Loss: 0.0072
Epoch [47/50] - Loss: 0.0068
Epoch [48/50] - Loss: 0.0064
Epoch [49/50] - Loss: 0.0061
Epoch [50/50] - Loss: 0.0058
sum preds 512
sum labels 491
 - Test Metrics: Accuracy=0.9054, F1=0.7059, Recall=0.7210, Precision=0.6914
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_nnpu_nnpu_1804091221.csv.
Average F1 over valid seeds: 0.7303 ± 0.0185
___________________________________________________________________________________
Avg F1 for citeseer with SAR and nnpu, GATConv,0.3: 0.7303 ± 0.0185
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4940
Epoch [2/50] - Loss: 0.4086
Epoch [3/50] - Loss: 0.3313
Epoch [4/50] - Loss: 0.2716
Epoch [5/50] - Loss: 0.2301
Epoch [6/50] - Loss: 0.2016
Epoch [7/50] - Loss: 0.1803
Epoch [8/50] - Loss: 0.1614
Epoch [9/50] - Loss: 0.1488
Epoch [10/50] - Loss: 0.1381
Epoch [11/50] - Loss: 0.1247
Epoch [12/50] - Loss: 0.1095
Epoch [13/50] - Loss: 0.0937
Epoch [14/50] - Loss: 0.0785
Epoch [15/50] - Loss: 0.0647
Epoch [16/50] - Loss: 0.0530
Epoch [17/50] - Loss: 0.0434
Epoch [18/50] - Loss: 0.0366
Epoch [19/50] - Loss: 0.0407
Epoch [20/50] - Loss: 0.0398
Epoch [21/50] - Loss: 0.0338
Epoch [22/50] - Loss: 0.0268
Epoch [23/50] - Loss: 0.0262
Epoch [24/50] - Loss: 0.0255
Epoch [25/50] - Loss: 0.0246
Epoch [26/50] - Loss: 0.0236
Epoch [27/50] - Loss: 0.0225
Epoch [28/50] - Loss: 0.0213
Epoch [29/50] - Loss: 0.0201
Epoch [30/50] - Loss: 0.0188
Epoch [31/50] - Loss: 0.0175
Epoch [32/50] - Loss: 0.0163
Epoch [33/50] - Loss: 0.0150
Epoch [34/50] - Loss: 0.0139
Epoch [35/50] - Loss: 0.0138
Epoch [36/50] - Loss: 0.0125
Epoch [37/50] - Loss: 0.0121
Epoch [38/50] - Loss: 0.0117
Epoch [39/50] - Loss: 0.0113
Epoch [40/50] - Loss: 0.0108
Epoch [41/50] - Loss: 0.0104
Epoch [42/50] - Loss: 0.0100
Epoch [43/50] - Loss: 0.0100
Epoch [44/50] - Loss: 0.0096
Epoch [45/50] - Loss: 0.0097
Epoch [46/50] - Loss: 0.0096
Epoch [47/50] - Loss: 0.0095
Epoch [48/50] - Loss: 0.0094
Epoch [49/50] - Loss: 0.0093
Epoch [50/50] - Loss: 0.0092
sum preds 523
sum labels 491
 - Test Metrics: Accuracy=0.9095, F1=0.7219, Recall=0.7454, Precision=0.6998
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4468
Epoch [3/50] - Loss: 0.3926
Epoch [4/50] - Loss: 0.3398
Epoch [5/50] - Loss: 0.2920
Epoch [6/50] - Loss: 0.2504
Epoch [7/50] - Loss: 0.2148
Epoch [8/50] - Loss: 0.1840
Epoch [9/50] - Loss: 0.1564
Epoch [10/50] - Loss: 0.1313
Epoch [11/50] - Loss: 0.1083
Epoch [12/50] - Loss: 0.0912
Epoch [13/50] - Loss: 0.0784
Epoch [14/50] - Loss: 0.0655
Epoch [15/50] - Loss: 0.0536
Epoch [16/50] - Loss: 0.0494
Epoch [17/50] - Loss: 0.0472
Epoch [18/50] - Loss: 0.0416
Epoch [19/50] - Loss: 0.0326
Epoch [20/50] - Loss: 0.0312
Epoch [21/50] - Loss: 0.0303
Epoch [22/50] - Loss: 0.0290
Epoch [23/50] - Loss: 0.0274
Epoch [24/50] - Loss: 0.0257
Epoch [25/50] - Loss: 0.0239
Epoch [26/50] - Loss: 0.0221
Epoch [27/50] - Loss: 0.0203
Epoch [28/50] - Loss: 0.0186
Epoch [29/50] - Loss: 0.0170
Epoch [30/50] - Loss: 0.0156
Epoch [31/50] - Loss: 0.0142
Epoch [32/50] - Loss: 0.0137
Epoch [33/50] - Loss: 0.0126
Epoch [34/50] - Loss: 0.0122
Epoch [35/50] - Loss: 0.0118
Epoch [36/50] - Loss: 0.0114
Epoch [37/50] - Loss: 0.0109
Epoch [38/50] - Loss: 0.0105
Epoch [39/50] - Loss: 0.0102
Epoch [40/50] - Loss: 0.0111
Epoch [41/50] - Loss: 0.0099
Epoch [42/50] - Loss: 0.0099
Epoch [43/50] - Loss: 0.0098
Epoch [44/50] - Loss: 0.0098
Epoch [45/50] - Loss: 0.0097
Epoch [46/50] - Loss: 0.0095
Epoch [47/50] - Loss: 0.0093
Epoch [48/50] - Loss: 0.0091
Epoch [49/50] - Loss: 0.0089
Epoch [50/50] - Loss: 0.0086
sum preds 500
sum labels 491
 - Test Metrics: Accuracy=0.9195, F1=0.7467, Recall=0.7536, Precision=0.7400
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4958
Epoch [2/50] - Loss: 0.4338
Epoch [3/50] - Loss: 0.3753
Epoch [4/50] - Loss: 0.3215
Epoch [5/50] - Loss: 0.2749
Epoch [6/50] - Loss: 0.2360
Epoch [7/50] - Loss: 0.2034
Epoch [8/50] - Loss: 0.1752
Epoch [9/50] - Loss: 0.1497
Epoch [10/50] - Loss: 0.1257
Epoch [11/50] - Loss: 0.1088
Epoch [12/50] - Loss: 0.0949
Epoch [13/50] - Loss: 0.0798
Epoch [14/50] - Loss: 0.0650
Epoch [15/50] - Loss: 0.0517
Epoch [16/50] - Loss: 0.0406
Epoch [17/50] - Loss: 0.0429
Epoch [18/50] - Loss: 0.0443
Epoch [19/50] - Loss: 0.0386
Epoch [20/50] - Loss: 0.0275
Epoch [21/50] - Loss: 0.0246
Epoch [22/50] - Loss: 0.0246
Epoch [23/50] - Loss: 0.0241
Epoch [24/50] - Loss: 0.0234
Epoch [25/50] - Loss: 0.0224
Epoch [26/50] - Loss: 0.0213
Epoch [27/50] - Loss: 0.0202
Epoch [28/50] - Loss: 0.0189
Epoch [29/50] - Loss: 0.0177
Epoch [30/50] - Loss: 0.0165
Epoch [31/50] - Loss: 0.0153
Epoch [32/50] - Loss: 0.0142
Epoch [33/50] - Loss: 0.0131
Epoch [34/50] - Loss: 0.0121
Epoch [35/50] - Loss: 0.0112
Epoch [36/50] - Loss: 0.0104
Epoch [37/50] - Loss: 0.0096
Epoch [38/50] - Loss: 0.0089
Epoch [39/50] - Loss: 0.0108
Epoch [40/50] - Loss: 0.0081
Epoch [41/50] - Loss: 0.0080
Epoch [42/50] - Loss: 0.0078
Epoch [43/50] - Loss: 0.0076
Epoch [44/50] - Loss: 0.0074
Epoch [45/50] - Loss: 0.0072
Epoch [46/50] - Loss: 0.0070
Epoch [47/50] - Loss: 0.0067
Epoch [48/50] - Loss: 0.0065
Epoch [49/50] - Loss: 0.0063
Epoch [50/50] - Loss: 0.0061
sum preds 523
sum labels 491
 - Test Metrics: Accuracy=0.9159, F1=0.7416, Recall=0.7658, Precision=0.7189
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_nnpu_nnpu_1804091224.csv.
Average F1 over valid seeds: 0.7367 ± 0.0107
___________________________________________________________________________________
Avg F1 for citeseer with SAR and nnpu, GCNConv,0.3: 0.7367 ± 0.0107
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4801
Epoch [2/50] - Loss: 0.4564
Epoch [3/50] - Loss: 0.4302
Epoch [4/50] - Loss: 0.4011
Epoch [5/50] - Loss: 0.3702
Epoch [6/50] - Loss: 0.3380
Epoch [7/50] - Loss: 0.3054
Epoch [8/50] - Loss: 0.2733
Epoch [9/50] - Loss: 0.2421
Epoch [10/50] - Loss: 0.2123
Epoch [11/50] - Loss: 0.1840
Epoch [12/50] - Loss: 0.1572
Epoch [13/50] - Loss: 0.1316
Epoch [14/50] - Loss: 0.1072
Epoch [15/50] - Loss: 0.0950
Epoch [16/50] - Loss: 0.0868
Epoch [17/50] - Loss: 0.0777
Epoch [18/50] - Loss: 0.0683
Epoch [19/50] - Loss: 0.0590
Epoch [20/50] - Loss: 0.0502
Epoch [21/50] - Loss: 0.0422
Epoch [22/50] - Loss: 0.0352
Epoch [23/50] - Loss: 0.0291
Epoch [24/50] - Loss: 0.0238
Epoch [25/50] - Loss: 0.0194
Epoch [26/50] - Loss: 0.0158
Epoch [27/50] - Loss: 0.0174
Epoch [28/50] - Loss: 0.0143
Epoch [29/50] - Loss: 0.0105
Epoch [30/50] - Loss: 0.0098
Epoch [31/50] - Loss: 0.0091
Epoch [32/50] - Loss: 0.0083
Epoch [33/50] - Loss: 0.0076
Epoch [34/50] - Loss: 0.0068
Epoch [35/50] - Loss: 0.0061
Epoch [36/50] - Loss: 0.0055
Epoch [37/50] - Loss: 0.0049
Epoch [38/50] - Loss: 0.0044
Epoch [39/50] - Loss: 0.0039
Epoch [40/50] - Loss: 0.0035
Epoch [41/50] - Loss: 0.0031
Epoch [42/50] - Loss: 0.0028
Epoch [43/50] - Loss: 0.0026
Epoch [44/50] - Loss: 0.0023
Epoch [45/50] - Loss: 0.0021
Epoch [46/50] - Loss: 0.0020
Epoch [47/50] - Loss: 0.0018
Epoch [48/50] - Loss: 0.0017
Epoch [49/50] - Loss: 0.0016
Epoch [50/50] - Loss: 0.0015
sum preds 408
sum labels 561
 - Test Metrics: Accuracy=0.8892, F1=0.6357, Recall=0.5490, Precision=0.7549
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4740
Epoch [2/50] - Loss: 0.4420
Epoch [3/50] - Loss: 0.4059
Epoch [4/50] - Loss: 0.3678
Epoch [5/50] - Loss: 0.3294
Epoch [6/50] - Loss: 0.2923
Epoch [7/50] - Loss: 0.2572
Epoch [8/50] - Loss: 0.2247
Epoch [9/50] - Loss: 0.1947
Epoch [10/50] - Loss: 0.1669
Epoch [11/50] - Loss: 0.1408
Epoch [12/50] - Loss: 0.1161
Epoch [13/50] - Loss: 0.1016
Epoch [14/50] - Loss: 0.0932
Epoch [15/50] - Loss: 0.0838
Epoch [16/50] - Loss: 0.0739
Epoch [17/50] - Loss: 0.0640
Epoch [18/50] - Loss: 0.0546
Epoch [19/50] - Loss: 0.0459
Epoch [20/50] - Loss: 0.0380
Epoch [21/50] - Loss: 0.0310
Epoch [22/50] - Loss: 0.0250
Epoch [23/50] - Loss: 0.0198
Epoch [24/50] - Loss: 0.0251
Epoch [25/50] - Loss: 0.0218
Epoch [26/50] - Loss: 0.0125
Epoch [27/50] - Loss: 0.0115
Epoch [28/50] - Loss: 0.0105
Epoch [29/50] - Loss: 0.0095
Epoch [30/50] - Loss: 0.0085
Epoch [31/50] - Loss: 0.0076
Epoch [32/50] - Loss: 0.0067
Epoch [33/50] - Loss: 0.0059
Epoch [34/50] - Loss: 0.0052
Epoch [35/50] - Loss: 0.0046
Epoch [36/50] - Loss: 0.0041
Epoch [37/50] - Loss: 0.0037
Epoch [38/50] - Loss: 0.0033
Epoch [39/50] - Loss: 0.0030
Epoch [40/50] - Loss: 0.0027
Epoch [41/50] - Loss: 0.0024
Epoch [42/50] - Loss: 0.0022
Epoch [43/50] - Loss: 0.0020
Epoch [44/50] - Loss: 0.0019
Epoch [45/50] - Loss: 0.0017
Epoch [46/50] - Loss: 0.0016
Epoch [47/50] - Loss: 0.0015
Epoch [48/50] - Loss: 0.0014
Epoch [49/50] - Loss: 0.0013
Epoch [50/50] - Loss: 0.0012
sum preds 466
sum labels 561
 - Test Metrics: Accuracy=0.8817, F1=0.6329, Recall=0.5793, Precision=0.6974
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5183
Epoch [2/50] - Loss: 0.5000
Epoch [3/50] - Loss: 0.4804
Epoch [4/50] - Loss: 0.4579
Epoch [5/50] - Loss: 0.4328
Epoch [6/50] - Loss: 0.4057
Epoch [7/50] - Loss: 0.3772
Epoch [8/50] - Loss: 0.3475
Epoch [9/50] - Loss: 0.3173
Epoch [10/50] - Loss: 0.2868
Epoch [11/50] - Loss: 0.2561
Epoch [12/50] - Loss: 0.2254
Epoch [13/50] - Loss: 0.1950
Epoch [14/50] - Loss: 0.1653
Epoch [15/50] - Loss: 0.1368
Epoch [16/50] - Loss: 0.1096
Epoch [17/50] - Loss: 0.0840
Epoch [18/50] - Loss: 0.0607
Epoch [19/50] - Loss: 0.0543
Epoch [20/50] - Loss: 0.0473
Epoch [21/50] - Loss: 0.0403
Epoch [22/50] - Loss: 0.0336
Epoch [23/50] - Loss: 0.0276
Epoch [24/50] - Loss: 0.0225
Epoch [25/50] - Loss: 0.0181
Epoch [26/50] - Loss: 0.0145
Epoch [27/50] - Loss: 0.0115
Epoch [28/50] - Loss: 0.0092
Epoch [29/50] - Loss: 0.0155
Epoch [30/50] - Loss: 0.0091
Epoch [31/50] - Loss: 0.0064
Epoch [32/50] - Loss: 0.0061
Epoch [33/50] - Loss: 0.0058
Epoch [34/50] - Loss: 0.0055
Epoch [35/50] - Loss: 0.0051
Epoch [36/50] - Loss: 0.0048
Epoch [37/50] - Loss: 0.0044
Epoch [38/50] - Loss: 0.0040
Epoch [39/50] - Loss: 0.0036
Epoch [40/50] - Loss: 0.0033
Epoch [41/50] - Loss: 0.0030
Epoch [42/50] - Loss: 0.0027
Epoch [43/50] - Loss: 0.0025
Epoch [44/50] - Loss: 0.0023
Epoch [45/50] - Loss: 0.0021
Epoch [46/50] - Loss: 0.0019
Epoch [47/50] - Loss: 0.0017
Epoch [48/50] - Loss: 0.0016
Epoch [49/50] - Loss: 0.0015
Epoch [50/50] - Loss: 0.0014
sum preds 298
sum labels 561
 - Test Metrics: Accuracy=0.8823, F1=0.5634, Recall=0.4314, Precision=0.8121
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_nnpu_nnpu_1804091227.csv.
Average F1 over valid seeds: 0.6107 ± 0.0334
___________________________________________________________________________________
Avg F1 for citeseer with SAR and nnpu, MLP,0.2: 0.6107 ± 0.0334
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4969
Epoch [2/50] - Loss: 0.4323
Epoch [3/50] - Loss: 0.3695
Epoch [4/50] - Loss: 0.3111
Epoch [5/50] - Loss: 0.2611
Epoch [6/50] - Loss: 0.2201
Epoch [7/50] - Loss: 0.1865
Epoch [8/50] - Loss: 0.1574
Epoch [9/50] - Loss: 0.1306
Epoch [10/50] - Loss: 0.1179
Epoch [11/50] - Loss: 0.1053
Epoch [12/50] - Loss: 0.0918
Epoch [13/50] - Loss: 0.0792
Epoch [14/50] - Loss: 0.0676
Epoch [15/50] - Loss: 0.0576
Epoch [16/50] - Loss: 0.0486
Epoch [17/50] - Loss: 0.0414
Epoch [18/50] - Loss: 0.0358
Epoch [19/50] - Loss: 0.0351
Epoch [20/50] - Loss: 0.0296
Epoch [21/50] - Loss: 0.0276
Epoch [22/50] - Loss: 0.0256
Epoch [23/50] - Loss: 0.0238
Epoch [24/50] - Loss: 0.0220
Epoch [25/50] - Loss: 0.0203
Epoch [26/50] - Loss: 0.0191
Epoch [27/50] - Loss: 0.0179
Epoch [28/50] - Loss: 0.0170
Epoch [29/50] - Loss: 0.0160
Epoch [30/50] - Loss: 0.0150
Epoch [31/50] - Loss: 0.0139
Epoch [32/50] - Loss: 0.0127
Epoch [33/50] - Loss: 0.0115
Epoch [34/50] - Loss: 0.0104
Epoch [35/50] - Loss: 0.0094
Epoch [36/50] - Loss: 0.0085
Epoch [37/50] - Loss: 0.0078
Epoch [38/50] - Loss: 0.0071
Epoch [39/50] - Loss: 0.0066
Epoch [40/50] - Loss: 0.0088
Epoch [41/50] - Loss: 0.0060
Epoch [42/50] - Loss: 0.0058
Epoch [43/50] - Loss: 0.0057
Epoch [44/50] - Loss: 0.0055
Epoch [45/50] - Loss: 0.0053
Epoch [46/50] - Loss: 0.0050
Epoch [47/50] - Loss: 0.0048
Epoch [48/50] - Loss: 0.0046
Epoch [49/50] - Loss: 0.0044
Epoch [50/50] - Loss: 0.0042
sum preds 483
sum labels 561
 - Test Metrics: Accuracy=0.9134, F1=0.7356, Recall=0.6845, Precision=0.7950
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4892
Epoch [2/50] - Loss: 0.4182
Epoch [3/50] - Loss: 0.3475
Epoch [4/50] - Loss: 0.2900
Epoch [5/50] - Loss: 0.2491
Epoch [6/50] - Loss: 0.2223
Epoch [7/50] - Loss: 0.2054
Epoch [8/50] - Loss: 0.1942
Epoch [9/50] - Loss: 0.1854
Epoch [10/50] - Loss: 0.1797
Epoch [11/50] - Loss: 0.1766
Epoch [12/50] - Loss: 0.1718
Epoch [13/50] - Loss: 0.1656
Epoch [14/50] - Loss: 0.1580
Epoch [15/50] - Loss: 0.1492
Epoch [16/50] - Loss: 0.1392
Epoch [17/50] - Loss: 0.1286
Epoch [18/50] - Loss: 0.1179
Epoch [19/50] - Loss: 0.1072
Epoch [20/50] - Loss: 0.0962
Epoch [21/50] - Loss: 0.0848
Epoch [22/50] - Loss: 0.0741
Epoch [23/50] - Loss: 0.0645
Epoch [24/50] - Loss: 0.0557
Epoch [25/50] - Loss: 0.0472
Epoch [26/50] - Loss: 0.0483
Epoch [27/50] - Loss: 0.0494
Epoch [28/50] - Loss: 0.0445
Epoch [29/50] - Loss: 0.0343
Epoch [30/50] - Loss: 0.0269
Epoch [31/50] - Loss: 0.0255
Epoch [32/50] - Loss: 0.0239
Epoch [33/50] - Loss: 0.0223
Epoch [34/50] - Loss: 0.0206
Epoch [35/50] - Loss: 0.0190
Epoch [36/50] - Loss: 0.0177
Epoch [37/50] - Loss: 0.0162
Epoch [38/50] - Loss: 0.0151
Epoch [39/50] - Loss: 0.0141
Epoch [40/50] - Loss: 0.0133
Epoch [41/50] - Loss: 0.0126
Epoch [42/50] - Loss: 0.0119
Epoch [43/50] - Loss: 0.0113
Epoch [44/50] - Loss: 0.0107
Epoch [45/50] - Loss: 0.0102
Epoch [46/50] - Loss: 0.0097
Epoch [47/50] - Loss: 0.0093
Epoch [48/50] - Loss: 0.0090
Epoch [49/50] - Loss: 0.0087
Epoch [50/50] - Loss: 0.0084
sum preds 551
sum labels 561
 - Test Metrics: Accuracy=0.9065, F1=0.7320, Recall=0.7255, Precision=0.7387
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5029
Epoch [2/50] - Loss: 0.4466
Epoch [3/50] - Loss: 0.3915
Epoch [4/50] - Loss: 0.3372
Epoch [5/50] - Loss: 0.2880
Epoch [6/50] - Loss: 0.2461
Epoch [7/50] - Loss: 0.2114
Epoch [8/50] - Loss: 0.1823
Epoch [9/50] - Loss: 0.1564
Epoch [10/50] - Loss: 0.1314
Epoch [11/50] - Loss: 0.1144
Epoch [12/50] - Loss: 0.0982
Epoch [13/50] - Loss: 0.0808
Epoch [14/50] - Loss: 0.0641
Epoch [15/50] - Loss: 0.0496
Epoch [16/50] - Loss: 0.0435
Epoch [17/50] - Loss: 0.0436
Epoch [18/50] - Loss: 0.0369
Epoch [19/50] - Loss: 0.0270
Epoch [20/50] - Loss: 0.0255
Epoch [21/50] - Loss: 0.0238
Epoch [22/50] - Loss: 0.0220
Epoch [23/50] - Loss: 0.0203
Epoch [24/50] - Loss: 0.0186
Epoch [25/50] - Loss: 0.0169
Epoch [26/50] - Loss: 0.0152
Epoch [27/50] - Loss: 0.0135
Epoch [28/50] - Loss: 0.0120
Epoch [29/50] - Loss: 0.0105
Epoch [30/50] - Loss: 0.0101
Epoch [31/50] - Loss: 0.0086
Epoch [32/50] - Loss: 0.0079
Epoch [33/50] - Loss: 0.0072
Epoch [34/50] - Loss: 0.0065
Epoch [35/50] - Loss: 0.0059
Epoch [36/50] - Loss: 0.0053
Epoch [37/50] - Loss: 0.0048
Epoch [38/50] - Loss: 0.0044
Epoch [39/50] - Loss: 0.0041
Epoch [40/50] - Loss: 0.0038
Epoch [41/50] - Loss: 0.0035
Epoch [42/50] - Loss: 0.0033
Epoch [43/50] - Loss: 0.0031
Epoch [44/50] - Loss: 0.0029
Epoch [45/50] - Loss: 0.0027
Epoch [46/50] - Loss: 0.0025
Epoch [47/50] - Loss: 0.0023
Epoch [48/50] - Loss: 0.0022
Epoch [49/50] - Loss: 0.0021
Epoch [50/50] - Loss: 0.0019
sum preds 590
sum labels 561
 - Test Metrics: Accuracy=0.8867, F1=0.6864, Recall=0.7041, Precision=0.6695
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_nnpu_nnpu_1804091229.csv.
Average F1 over valid seeds: 0.7180 ± 0.0224
___________________________________________________________________________________
Avg F1 for citeseer with SAR and nnpu, GATConv,0.2: 0.7180 ± 0.0224
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4939
Epoch [2/50] - Loss: 0.4082
Epoch [3/50] - Loss: 0.3304
Epoch [4/50] - Loss: 0.2696
Epoch [5/50] - Loss: 0.2266
Epoch [6/50] - Loss: 0.1961
Epoch [7/50] - Loss: 0.1724
Epoch [8/50] - Loss: 0.1509
Epoch [9/50] - Loss: 0.1402
Epoch [10/50] - Loss: 0.1285
Epoch [11/50] - Loss: 0.1150
Epoch [12/50] - Loss: 0.1005
Epoch [13/50] - Loss: 0.0862
Epoch [14/50] - Loss: 0.0726
Epoch [15/50] - Loss: 0.0609
Epoch [16/50] - Loss: 0.0511
Epoch [17/50] - Loss: 0.0433
Epoch [18/50] - Loss: 0.0401
Epoch [19/50] - Loss: 0.0436
Epoch [20/50] - Loss: 0.0414
Epoch [21/50] - Loss: 0.0342
Epoch [22/50] - Loss: 0.0296
Epoch [23/50] - Loss: 0.0291
Epoch [24/50] - Loss: 0.0283
Epoch [25/50] - Loss: 0.0273
Epoch [26/50] - Loss: 0.0261
Epoch [27/50] - Loss: 0.0248
Epoch [28/50] - Loss: 0.0234
Epoch [29/50] - Loss: 0.0220
Epoch [30/50] - Loss: 0.0205
Epoch [31/50] - Loss: 0.0191
Epoch [32/50] - Loss: 0.0177
Epoch [33/50] - Loss: 0.0164
Epoch [34/50] - Loss: 0.0151
Epoch [35/50] - Loss: 0.0140
Epoch [36/50] - Loss: 0.0134
Epoch [37/50] - Loss: 0.0126
Epoch [38/50] - Loss: 0.0122
Epoch [39/50] - Loss: 0.0117
Epoch [40/50] - Loss: 0.0112
Epoch [41/50] - Loss: 0.0107
Epoch [42/50] - Loss: 0.0101
Epoch [43/50] - Loss: 0.0095
Epoch [44/50] - Loss: 0.0089
Epoch [45/50] - Loss: 0.0087
Epoch [46/50] - Loss: 0.0080
Epoch [47/50] - Loss: 0.0078
Epoch [48/50] - Loss: 0.0075
Epoch [49/50] - Loss: 0.0072
Epoch [50/50] - Loss: 0.0069
sum preds 524
sum labels 561
 - Test Metrics: Accuracy=0.9043, F1=0.7189, Recall=0.6952, Precision=0.7443
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4995
Epoch [2/50] - Loss: 0.4462
Epoch [3/50] - Loss: 0.3908
Epoch [4/50] - Loss: 0.3360
Epoch [5/50] - Loss: 0.2860
Epoch [6/50] - Loss: 0.2424
Epoch [7/50] - Loss: 0.2044
Epoch [8/50] - Loss: 0.1712
Epoch [9/50] - Loss: 0.1414
Epoch [10/50] - Loss: 0.1145
Epoch [11/50] - Loss: 0.0905
Epoch [12/50] - Loss: 0.0775
Epoch [13/50] - Loss: 0.0651
Epoch [14/50] - Loss: 0.0530
Epoch [15/50] - Loss: 0.0422
Epoch [16/50] - Loss: 0.0352
Epoch [17/50] - Loss: 0.0326
Epoch [18/50] - Loss: 0.0254
Epoch [19/50] - Loss: 0.0236
Epoch [20/50] - Loss: 0.0221
Epoch [21/50] - Loss: 0.0202
Epoch [22/50] - Loss: 0.0182
Epoch [23/50] - Loss: 0.0162
Epoch [24/50] - Loss: 0.0142
Epoch [25/50] - Loss: 0.0124
Epoch [26/50] - Loss: 0.0106
Epoch [27/50] - Loss: 0.0091
Epoch [28/50] - Loss: 0.0077
Epoch [29/50] - Loss: 0.0065
Epoch [30/50] - Loss: 0.0083
Epoch [31/50] - Loss: 0.0050
Epoch [32/50] - Loss: 0.0046
Epoch [33/50] - Loss: 0.0042
Epoch [34/50] - Loss: 0.0038
Epoch [35/50] - Loss: 0.0034
Epoch [36/50] - Loss: 0.0030
Epoch [37/50] - Loss: 0.0026
Epoch [38/50] - Loss: 0.0023
Epoch [39/50] - Loss: 0.0020
Epoch [40/50] - Loss: 0.0018
Epoch [41/50] - Loss: 0.0016
Epoch [42/50] - Loss: 0.0014
Epoch [43/50] - Loss: 0.0023
Epoch [44/50] - Loss: 0.0013
Epoch [45/50] - Loss: 0.0013
Epoch [46/50] - Loss: 0.0014
Epoch [47/50] - Loss: 0.0014
Epoch [48/50] - Loss: 0.0014
Epoch [49/50] - Loss: 0.0014
Epoch [50/50] - Loss: 0.0014
sum preds 519
sum labels 561
 - Test Metrics: Accuracy=0.9147, F1=0.7481, Recall=0.7201, Precision=0.7784
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4958
Epoch [2/50] - Loss: 0.4331
Epoch [3/50] - Loss: 0.3735
Epoch [4/50] - Loss: 0.3180
Epoch [5/50] - Loss: 0.2696
Epoch [6/50] - Loss: 0.2286
Epoch [7/50] - Loss: 0.1933
Epoch [8/50] - Loss: 0.1620
Epoch [9/50] - Loss: 0.1335
Epoch [10/50] - Loss: 0.1079
Epoch [11/50] - Loss: 0.0943
Epoch [12/50] - Loss: 0.0794
Epoch [13/50] - Loss: 0.0646
Epoch [14/50] - Loss: 0.0511
Epoch [15/50] - Loss: 0.0397
Epoch [16/50] - Loss: 0.0360
Epoch [17/50] - Loss: 0.0358
Epoch [18/50] - Loss: 0.0290
Epoch [19/50] - Loss: 0.0216
Epoch [20/50] - Loss: 0.0203
Epoch [21/50] - Loss: 0.0187
Epoch [22/50] - Loss: 0.0170
Epoch [23/50] - Loss: 0.0153
Epoch [24/50] - Loss: 0.0135
Epoch [25/50] - Loss: 0.0118
Epoch [26/50] - Loss: 0.0102
Epoch [27/50] - Loss: 0.0087
Epoch [28/50] - Loss: 0.0073
Epoch [29/50] - Loss: 0.0062
Epoch [30/50] - Loss: 0.0096
Epoch [31/50] - Loss: 0.0050
Epoch [32/50] - Loss: 0.0047
Epoch [33/50] - Loss: 0.0044
Epoch [34/50] - Loss: 0.0041
Epoch [35/50] - Loss: 0.0038
Epoch [36/50] - Loss: 0.0035
Epoch [37/50] - Loss: 0.0032
Epoch [38/50] - Loss: 0.0029
Epoch [39/50] - Loss: 0.0027
Epoch [40/50] - Loss: 0.0024
Epoch [41/50] - Loss: 0.0022
Epoch [42/50] - Loss: 0.0020
Epoch [43/50] - Loss: 0.0017
Epoch [44/50] - Loss: 0.0015
Epoch [45/50] - Loss: 0.0013
Epoch [46/50] - Loss: 0.0012
Epoch [47/50] - Loss: 0.0010
Epoch [48/50] - Loss: 0.0009
Epoch [49/50] - Loss: 0.0019
Epoch [50/50] - Loss: 0.0009
sum preds 524
sum labels 561
 - Test Metrics: Accuracy=0.9018, F1=0.7115, Recall=0.6881, Precision=0.7366
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_nnpu_nnpu_1804091232.csv.
Average F1 over valid seeds: 0.7262 ± 0.0158
___________________________________________________________________________________
Avg F1 for citeseer with SAR and nnpu, GCNConv,0.2: 0.7262 ± 0.0158
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4884
Epoch [3/50] - Loss: 0.4705
Epoch [4/50] - Loss: 0.4493
Epoch [5/50] - Loss: 0.4266
Epoch [6/50] - Loss: 0.4020
Epoch [7/50] - Loss: 0.3754
Epoch [8/50] - Loss: 0.3475
Epoch [9/50] - Loss: 0.3187
Epoch [10/50] - Loss: 0.2894
Epoch [11/50] - Loss: 0.2600
Epoch [12/50] - Loss: 0.2310
Epoch [13/50] - Loss: 0.2029
Epoch [14/50] - Loss: 0.1761
Epoch [15/50] - Loss: 0.1509
Epoch [16/50] - Loss: 0.1274
Epoch [17/50] - Loss: 0.1059
Epoch [18/50] - Loss: 0.0862
Epoch [19/50] - Loss: 0.0685
Epoch [20/50] - Loss: 0.0525
Epoch [21/50] - Loss: 0.0381
Epoch [22/50] - Loss: 0.0252
Epoch [23/50] - Loss: 0.0137
Epoch [24/50] - Loss: 0.0033
Epoch [25/50] - Loss: -0.0060
Epoch [26/50] - Loss: -0.0144
Epoch [27/50] - Loss: -0.0219
Epoch [28/50] - Loss: -0.0288
Epoch [29/50] - Loss: -0.0350
Epoch [30/50] - Loss: -0.0406
Epoch [31/50] - Loss: -0.0457
Epoch [32/50] - Loss: -0.0503
Epoch [33/50] - Loss: -0.0545
Epoch [34/50] - Loss: -0.0583
Epoch [35/50] - Loss: -0.0617
Epoch [36/50] - Loss: -0.0648
Epoch [37/50] - Loss: -0.0677
Epoch [38/50] - Loss: -0.0703
Epoch [39/50] - Loss: -0.0727
Epoch [40/50] - Loss: -0.0749
Epoch [41/50] - Loss: -0.0770
Epoch [42/50] - Loss: -0.0789
Epoch [43/50] - Loss: -0.0807
Epoch [44/50] - Loss: -0.0824
Epoch [45/50] - Loss: -0.0840
Epoch [46/50] - Loss: -0.0855
Epoch [47/50] - Loss: -0.0869
Epoch [48/50] - Loss: -0.0882
Epoch [49/50] - Loss: -0.0894
Epoch [50/50] - Loss: -0.0906
sum preds 125
sum labels 421
 - Test Metrics: Accuracy=0.8956, F1=0.4176, Recall=0.2708, Precision=0.9120
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5002
Epoch [2/50] - Loss: 0.4839
Epoch [3/50] - Loss: 0.4588
Epoch [4/50] - Loss: 0.4302
Epoch [5/50] - Loss: 0.4006
Epoch [6/50] - Loss: 0.3692
Epoch [7/50] - Loss: 0.3365
Epoch [8/50] - Loss: 0.3033
Epoch [9/50] - Loss: 0.2703
Epoch [10/50] - Loss: 0.2381
Epoch [11/50] - Loss: 0.2072
Epoch [12/50] - Loss: 0.1780
Epoch [13/50] - Loss: 0.1507
Epoch [14/50] - Loss: 0.1258
Epoch [15/50] - Loss: 0.1031
Epoch [16/50] - Loss: 0.0828
Epoch [17/50] - Loss: 0.0647
Epoch [18/50] - Loss: 0.0485
Epoch [19/50] - Loss: 0.0342
Epoch [20/50] - Loss: 0.0214
Epoch [21/50] - Loss: 0.0100
Epoch [22/50] - Loss: -0.0001
Epoch [23/50] - Loss: -0.0093
Epoch [24/50] - Loss: -0.0175
Epoch [25/50] - Loss: -0.0250
Epoch [26/50] - Loss: -0.0317
Epoch [27/50] - Loss: -0.0379
Epoch [28/50] - Loss: -0.0435
Epoch [29/50] - Loss: -0.0487
Epoch [30/50] - Loss: -0.0534
Epoch [31/50] - Loss: -0.0577
Epoch [32/50] - Loss: -0.0617
Epoch [33/50] - Loss: -0.0653
Epoch [34/50] - Loss: -0.0686
Epoch [35/50] - Loss: -0.0716
Epoch [36/50] - Loss: -0.0743
Epoch [37/50] - Loss: -0.0768
Epoch [38/50] - Loss: -0.0790
Epoch [39/50] - Loss: -0.0811
Epoch [40/50] - Loss: -0.0830
Epoch [41/50] - Loss: -0.0848
Epoch [42/50] - Loss: -0.0864
Epoch [43/50] - Loss: -0.0880
Epoch [44/50] - Loss: -0.0894
Epoch [45/50] - Loss: -0.0908
Epoch [46/50] - Loss: -0.0921
Epoch [47/50] - Loss: -0.0933
Epoch [48/50] - Loss: -0.0945
Epoch [49/50] - Loss: -0.0956
Epoch [50/50] - Loss: -0.0966
sum preds 112
sum labels 421
 - Test Metrics: Accuracy=0.8907, F1=0.3752, Recall=0.2375, Precision=0.8929
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4861
Epoch [3/50] - Loss: 0.4664
Epoch [4/50] - Loss: 0.4435
Epoch [5/50] - Loss: 0.4187
Epoch [6/50] - Loss: 0.3926
Epoch [7/50] - Loss: 0.3656
Epoch [8/50] - Loss: 0.3381
Epoch [9/50] - Loss: 0.3104
Epoch [10/50] - Loss: 0.2829
Epoch [11/50] - Loss: 0.2558
Epoch [12/50] - Loss: 0.2293
Epoch [13/50] - Loss: 0.2037
Epoch [14/50] - Loss: 0.1792
Epoch [15/50] - Loss: 0.1558
Epoch [16/50] - Loss: 0.1338
Epoch [17/50] - Loss: 0.1132
Epoch [18/50] - Loss: 0.0941
Epoch [19/50] - Loss: 0.0764
Epoch [20/50] - Loss: 0.0602
Epoch [21/50] - Loss: 0.0455
Epoch [22/50] - Loss: 0.0320
Epoch [23/50] - Loss: 0.0198
Epoch [24/50] - Loss: 0.0088
Epoch [25/50] - Loss: -0.0012
Epoch [26/50] - Loss: -0.0102
Epoch [27/50] - Loss: -0.0183
Epoch [28/50] - Loss: -0.0256
Epoch [29/50] - Loss: -0.0322
Epoch [30/50] - Loss: -0.0381
Epoch [31/50] - Loss: -0.0435
Epoch [32/50] - Loss: -0.0483
Epoch [33/50] - Loss: -0.0527
Epoch [34/50] - Loss: -0.0566
Epoch [35/50] - Loss: -0.0603
Epoch [36/50] - Loss: -0.0636
Epoch [37/50] - Loss: -0.0666
Epoch [38/50] - Loss: -0.0693
Epoch [39/50] - Loss: -0.0719
Epoch [40/50] - Loss: -0.0743
Epoch [41/50] - Loss: -0.0765
Epoch [42/50] - Loss: -0.0785
Epoch [43/50] - Loss: -0.0805
Epoch [44/50] - Loss: -0.0823
Epoch [45/50] - Loss: -0.0840
Epoch [46/50] - Loss: -0.0856
Epoch [47/50] - Loss: -0.0871
Epoch [48/50] - Loss: -0.0885
Epoch [49/50] - Loss: -0.0899
Epoch [50/50] - Loss: -0.0911
sum preds 132
sum labels 421
 - Test Metrics: Accuracy=0.8927, F1=0.4087, Recall=0.2684, Precision=0.8561
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_imbnnpu_imbnnpu_1804091235.csv.
Average F1 over valid seeds: 0.4005 ± 0.0182
___________________________________________________________________________________
Avg F1 for citeseer with SAR and imbnnpu, MLP,0.4: 0.4005 ± 0.0182
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4994
Epoch [2/50] - Loss: 0.4615
Epoch [3/50] - Loss: 0.4139
Epoch [4/50] - Loss: 0.3614
Epoch [5/50] - Loss: 0.3112
Epoch [6/50] - Loss: 0.2642
Epoch [7/50] - Loss: 0.2207
Epoch [8/50] - Loss: 0.1821
Epoch [9/50] - Loss: 0.1490
Epoch [10/50] - Loss: 0.1212
Epoch [11/50] - Loss: 0.0979
Epoch [12/50] - Loss: 0.0786
Epoch [13/50] - Loss: 0.0626
Epoch [14/50] - Loss: 0.0492
Epoch [15/50] - Loss: 0.0380
Epoch [16/50] - Loss: 0.0285
Epoch [17/50] - Loss: 0.0203
Epoch [18/50] - Loss: 0.0131
Epoch [19/50] - Loss: 0.0068
Epoch [20/50] - Loss: 0.0012
Epoch [21/50] - Loss: -0.0037
Epoch [22/50] - Loss: -0.0081
Epoch [23/50] - Loss: -0.0119
Epoch [24/50] - Loss: -0.0153
Epoch [25/50] - Loss: -0.0182
Epoch [26/50] - Loss: -0.0208
Epoch [27/50] - Loss: -0.0230
Epoch [28/50] - Loss: -0.0249
Epoch [29/50] - Loss: -0.0267
Epoch [30/50] - Loss: -0.0283
Epoch [31/50] - Loss: -0.0298
Epoch [32/50] - Loss: -0.0312
Epoch [33/50] - Loss: -0.0326
Epoch [34/50] - Loss: -0.0340
Epoch [35/50] - Loss: -0.0355
Epoch [36/50] - Loss: -0.0369
Epoch [37/50] - Loss: -0.0381
Epoch [38/50] - Loss: -0.0392
Epoch [39/50] - Loss: -0.0402
Epoch [40/50] - Loss: -0.0411
Epoch [41/50] - Loss: -0.0420
Epoch [42/50] - Loss: -0.0429
Epoch [43/50] - Loss: -0.0438
Epoch [44/50] - Loss: -0.0447
Epoch [45/50] - Loss: -0.0455
Epoch [46/50] - Loss: -0.0464
Epoch [47/50] - Loss: -0.0473
Epoch [48/50] - Loss: -0.0481
Epoch [49/50] - Loss: -0.0489
Epoch [50/50] - Loss: -0.0497
sum preds 262
sum labels 421
 - Test Metrics: Accuracy=0.9216, F1=0.6501, Recall=0.5273, Precision=0.8473
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5015
Epoch [2/50] - Loss: 0.4716
Epoch [3/50] - Loss: 0.4319
Epoch [4/50] - Loss: 0.3871
Epoch [5/50] - Loss: 0.3454
Epoch [6/50] - Loss: 0.3057
Epoch [7/50] - Loss: 0.2671
Epoch [8/50] - Loss: 0.2310
Epoch [9/50] - Loss: 0.1980
Epoch [10/50] - Loss: 0.1683
Epoch [11/50] - Loss: 0.1415
Epoch [12/50] - Loss: 0.1178
Epoch [13/50] - Loss: 0.0973
Epoch [14/50] - Loss: 0.0797
Epoch [15/50] - Loss: 0.0648
Epoch [16/50] - Loss: 0.0524
Epoch [17/50] - Loss: 0.0418
Epoch [18/50] - Loss: 0.0324
Epoch [19/50] - Loss: 0.0240
Epoch [20/50] - Loss: 0.0169
Epoch [21/50] - Loss: 0.0110
Epoch [22/50] - Loss: 0.0061
Epoch [23/50] - Loss: 0.0019
Epoch [24/50] - Loss: -0.0018
Epoch [25/50] - Loss: -0.0051
Epoch [26/50] - Loss: -0.0082
Epoch [27/50] - Loss: -0.0110
Epoch [28/50] - Loss: -0.0136
Epoch [29/50] - Loss: -0.0161
Epoch [30/50] - Loss: -0.0183
Epoch [31/50] - Loss: -0.0203
Epoch [32/50] - Loss: -0.0221
Epoch [33/50] - Loss: -0.0237
Epoch [34/50] - Loss: -0.0252
Epoch [35/50] - Loss: -0.0265
Epoch [36/50] - Loss: -0.0277
Epoch [37/50] - Loss: -0.0287
Epoch [38/50] - Loss: -0.0296
Epoch [39/50] - Loss: -0.0305
Epoch [40/50] - Loss: -0.0313
Epoch [41/50] - Loss: -0.0320
Epoch [42/50] - Loss: -0.0326
Epoch [43/50] - Loss: -0.0333
Epoch [44/50] - Loss: -0.0339
Epoch [45/50] - Loss: -0.0345
Epoch [46/50] - Loss: -0.0352
Epoch [47/50] - Loss: -0.0359
Epoch [48/50] - Loss: -0.0365
Epoch [49/50] - Loss: -0.0371
Epoch [50/50] - Loss: -0.0377
sum preds 340
sum labels 421
 - Test Metrics: Accuracy=0.9242, F1=0.6965, Recall=0.6295, Precision=0.7794
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4993
Epoch [2/50] - Loss: 0.4592
Epoch [3/50] - Loss: 0.4082
Epoch [4/50] - Loss: 0.3511
Epoch [5/50] - Loss: 0.2976
Epoch [6/50] - Loss: 0.2498
Epoch [7/50] - Loss: 0.2071
Epoch [8/50] - Loss: 0.1698
Epoch [9/50] - Loss: 0.1384
Epoch [10/50] - Loss: 0.1123
Epoch [11/50] - Loss: 0.0907
Epoch [12/50] - Loss: 0.0729
Epoch [13/50] - Loss: 0.0579
Epoch [14/50] - Loss: 0.0454
Epoch [15/50] - Loss: 0.0347
Epoch [16/50] - Loss: 0.0254
Epoch [17/50] - Loss: 0.0174
Epoch [18/50] - Loss: 0.0104
Epoch [19/50] - Loss: 0.0043
Epoch [20/50] - Loss: -0.0011
Epoch [21/50] - Loss: -0.0059
Epoch [22/50] - Loss: -0.0100
Epoch [23/50] - Loss: -0.0136
Epoch [24/50] - Loss: -0.0169
Epoch [25/50] - Loss: -0.0199
Epoch [26/50] - Loss: -0.0226
Epoch [27/50] - Loss: -0.0251
Epoch [28/50] - Loss: -0.0272
Epoch [29/50] - Loss: -0.0291
Epoch [30/50] - Loss: -0.0308
Epoch [31/50] - Loss: -0.0322
Epoch [32/50] - Loss: -0.0335
Epoch [33/50] - Loss: -0.0348
Epoch [34/50] - Loss: -0.0359
Epoch [35/50] - Loss: -0.0370
Epoch [36/50] - Loss: -0.0382
Epoch [37/50] - Loss: -0.0392
Epoch [38/50] - Loss: -0.0400
Epoch [39/50] - Loss: -0.0408
Epoch [40/50] - Loss: -0.0415
Epoch [41/50] - Loss: -0.0421
Epoch [42/50] - Loss: -0.0428
Epoch [43/50] - Loss: -0.0434
Epoch [44/50] - Loss: -0.0439
Epoch [45/50] - Loss: -0.0447
Epoch [46/50] - Loss: -0.0454
Epoch [47/50] - Loss: -0.0460
Epoch [48/50] - Loss: -0.0465
Epoch [49/50] - Loss: -0.0470
Epoch [50/50] - Loss: -0.0474
sum preds 319
sum labels 421
 - Test Metrics: Accuracy=0.9173, F1=0.6595, Recall=0.5796, Precision=0.7649
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_imbnnpu_imbnnpu_1804091237.csv.
Average F1 over valid seeds: 0.6687 ± 0.0200
___________________________________________________________________________________
Avg F1 for citeseer with SAR and imbnnpu, GATConv,0.4: 0.6687 ± 0.0200
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4996
Epoch [2/50] - Loss: 0.4540
Epoch [3/50] - Loss: 0.3972
Epoch [4/50] - Loss: 0.3379
Epoch [5/50] - Loss: 0.2846
Epoch [6/50] - Loss: 0.2372
Epoch [7/50] - Loss: 0.1959
Epoch [8/50] - Loss: 0.1613
Epoch [9/50] - Loss: 0.1330
Epoch [10/50] - Loss: 0.1100
Epoch [11/50] - Loss: 0.0911
Epoch [12/50] - Loss: 0.0755
Epoch [13/50] - Loss: 0.0626
Epoch [14/50] - Loss: 0.0518
Epoch [15/50] - Loss: 0.0428
Epoch [16/50] - Loss: 0.0350
Epoch [17/50] - Loss: 0.0283
Epoch [18/50] - Loss: 0.0225
Epoch [19/50] - Loss: 0.0173
Epoch [20/50] - Loss: 0.0126
Epoch [21/50] - Loss: 0.0084
Epoch [22/50] - Loss: 0.0046
Epoch [23/50] - Loss: 0.0012
Epoch [24/50] - Loss: -0.0019
Epoch [25/50] - Loss: -0.0047
Epoch [26/50] - Loss: -0.0073
Epoch [27/50] - Loss: -0.0096
Epoch [28/50] - Loss: -0.0118
Epoch [29/50] - Loss: -0.0137
Epoch [30/50] - Loss: -0.0155
Epoch [31/50] - Loss: -0.0172
Epoch [32/50] - Loss: -0.0187
Epoch [33/50] - Loss: -0.0201
Epoch [34/50] - Loss: -0.0214
Epoch [35/50] - Loss: -0.0226
Epoch [36/50] - Loss: -0.0237
Epoch [37/50] - Loss: -0.0247
Epoch [38/50] - Loss: -0.0257
Epoch [39/50] - Loss: -0.0267
Epoch [40/50] - Loss: -0.0276
Epoch [41/50] - Loss: -0.0285
Epoch [42/50] - Loss: -0.0294
Epoch [43/50] - Loss: -0.0303
Epoch [44/50] - Loss: -0.0312
Epoch [45/50] - Loss: -0.0321
Epoch [46/50] - Loss: -0.0329
Epoch [47/50] - Loss: -0.0337
Epoch [48/50] - Loss: -0.0343
Epoch [49/50] - Loss: -0.0350
Epoch [50/50] - Loss: -0.0355
sum preds 340
sum labels 421
 - Test Metrics: Accuracy=0.9222, F1=0.6886, Recall=0.6223, Precision=0.7706
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4971
Epoch [2/50] - Loss: 0.4602
Epoch [3/50] - Loss: 0.4121
Epoch [4/50] - Loss: 0.3610
Epoch [5/50] - Loss: 0.3131
Epoch [6/50] - Loss: 0.2694
Epoch [7/50] - Loss: 0.2303
Epoch [8/50] - Loss: 0.1960
Epoch [9/50] - Loss: 0.1665
Epoch [10/50] - Loss: 0.1416
Epoch [11/50] - Loss: 0.1206
Epoch [12/50] - Loss: 0.1030
Epoch [13/50] - Loss: 0.0882
Epoch [14/50] - Loss: 0.0757
Epoch [15/50] - Loss: 0.0650
Epoch [16/50] - Loss: 0.0558
Epoch [17/50] - Loss: 0.0479
Epoch [18/50] - Loss: 0.0409
Epoch [19/50] - Loss: 0.0349
Epoch [20/50] - Loss: 0.0295
Epoch [21/50] - Loss: 0.0247
Epoch [22/50] - Loss: 0.0205
Epoch [23/50] - Loss: 0.0167
Epoch [24/50] - Loss: 0.0133
Epoch [25/50] - Loss: 0.0102
Epoch [26/50] - Loss: 0.0073
Epoch [27/50] - Loss: 0.0047
Epoch [28/50] - Loss: 0.0023
Epoch [29/50] - Loss: 0.0001
Epoch [30/50] - Loss: -0.0019
Epoch [31/50] - Loss: -0.0037
Epoch [32/50] - Loss: -0.0054
Epoch [33/50] - Loss: -0.0069
Epoch [34/50] - Loss: -0.0084
Epoch [35/50] - Loss: -0.0097
Epoch [36/50] - Loss: -0.0109
Epoch [37/50] - Loss: -0.0120
Epoch [38/50] - Loss: -0.0130
Epoch [39/50] - Loss: -0.0140
Epoch [40/50] - Loss: -0.0149
Epoch [41/50] - Loss: -0.0158
Epoch [42/50] - Loss: -0.0166
Epoch [43/50] - Loss: -0.0174
Epoch [44/50] - Loss: -0.0182
Epoch [45/50] - Loss: -0.0189
Epoch [46/50] - Loss: -0.0196
Epoch [47/50] - Loss: -0.0203
Epoch [48/50] - Loss: -0.0210
Epoch [49/50] - Loss: -0.0217
Epoch [50/50] - Loss: -0.0224
sum preds 367
sum labels 421
 - Test Metrics: Accuracy=0.9258, F1=0.7132, Recall=0.6675, Precision=0.7657
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4989
Epoch [2/50] - Loss: 0.4606
Epoch [3/50] - Loss: 0.4113
Epoch [4/50] - Loss: 0.3567
Epoch [5/50] - Loss: 0.3042
Epoch [6/50] - Loss: 0.2561
Epoch [7/50] - Loss: 0.2136
Epoch [8/50] - Loss: 0.1772
Epoch [9/50] - Loss: 0.1461
Epoch [10/50] - Loss: 0.1199
Epoch [11/50] - Loss: 0.0981
Epoch [12/50] - Loss: 0.0801
Epoch [13/50] - Loss: 0.0652
Epoch [14/50] - Loss: 0.0529
Epoch [15/50] - Loss: 0.0426
Epoch [16/50] - Loss: 0.0340
Epoch [17/50] - Loss: 0.0266
Epoch [18/50] - Loss: 0.0202
Epoch [19/50] - Loss: 0.0147
Epoch [20/50] - Loss: 0.0099
Epoch [21/50] - Loss: 0.0056
Epoch [22/50] - Loss: 0.0018
Epoch [23/50] - Loss: -0.0016
Epoch [24/50] - Loss: -0.0047
Epoch [25/50] - Loss: -0.0075
Epoch [26/50] - Loss: -0.0101
Epoch [27/50] - Loss: -0.0125
Epoch [28/50] - Loss: -0.0148
Epoch [29/50] - Loss: -0.0168
Epoch [30/50] - Loss: -0.0187
Epoch [31/50] - Loss: -0.0205
Epoch [32/50] - Loss: -0.0221
Epoch [33/50] - Loss: -0.0236
Epoch [34/50] - Loss: -0.0249
Epoch [35/50] - Loss: -0.0261
Epoch [36/50] - Loss: -0.0272
Epoch [37/50] - Loss: -0.0282
Epoch [38/50] - Loss: -0.0291
Epoch [39/50] - Loss: -0.0300
Epoch [40/50] - Loss: -0.0308
Epoch [41/50] - Loss: -0.0315
Epoch [42/50] - Loss: -0.0321
Epoch [43/50] - Loss: -0.0327
Epoch [44/50] - Loss: -0.0333
Epoch [45/50] - Loss: -0.0339
Epoch [46/50] - Loss: -0.0344
Epoch [47/50] - Loss: -0.0348
Epoch [48/50] - Loss: -0.0353
Epoch [49/50] - Loss: -0.0357
Epoch [50/50] - Loss: -0.0361
sum preds 354
sum labels 421
 - Test Metrics: Accuracy=0.9176, F1=0.6761, Recall=0.6223, Precision=0.7401
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_imbnnpu_imbnnpu_1804091240.csv.
Average F1 over valid seeds: 0.6926 ± 0.0154
___________________________________________________________________________________
Avg F1 for citeseer with SAR and imbnnpu, GCNConv,0.4: 0.6926 ± 0.0154
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5003
Epoch [2/50] - Loss: 0.4875
Epoch [3/50] - Loss: 0.4687
Epoch [4/50] - Loss: 0.4462
Epoch [5/50] - Loss: 0.4221
Epoch [6/50] - Loss: 0.3958
Epoch [7/50] - Loss: 0.3676
Epoch [8/50] - Loss: 0.3380
Epoch [9/50] - Loss: 0.3076
Epoch [10/50] - Loss: 0.2767
Epoch [11/50] - Loss: 0.2459
Epoch [12/50] - Loss: 0.2156
Epoch [13/50] - Loss: 0.1865
Epoch [14/50] - Loss: 0.1589
Epoch [15/50] - Loss: 0.1331
Epoch [16/50] - Loss: 0.1094
Epoch [17/50] - Loss: 0.0877
Epoch [18/50] - Loss: 0.0681
Epoch [19/50] - Loss: 0.0506
Epoch [20/50] - Loss: 0.0349
Epoch [21/50] - Loss: 0.0210
Epoch [22/50] - Loss: 0.0086
Epoch [23/50] - Loss: -0.0024
Epoch [24/50] - Loss: -0.0122
Epoch [25/50] - Loss: -0.0209
Epoch [26/50] - Loss: -0.0287
Epoch [27/50] - Loss: -0.0355
Epoch [28/50] - Loss: -0.0417
Epoch [29/50] - Loss: -0.0472
Epoch [30/50] - Loss: -0.0522
Epoch [31/50] - Loss: -0.0566
Epoch [32/50] - Loss: -0.0607
Epoch [33/50] - Loss: -0.0643
Epoch [34/50] - Loss: -0.0677
Epoch [35/50] - Loss: -0.0708
Epoch [36/50] - Loss: -0.0737
Epoch [37/50] - Loss: -0.0764
Epoch [38/50] - Loss: -0.0789
Epoch [39/50] - Loss: -0.0812
Epoch [40/50] - Loss: -0.0834
Epoch [41/50] - Loss: -0.0854
Epoch [42/50] - Loss: -0.0874
Epoch [43/50] - Loss: -0.0892
Epoch [44/50] - Loss: -0.0909
Epoch [45/50] - Loss: -0.0924
Epoch [46/50] - Loss: -0.0938
Epoch [47/50] - Loss: -0.0951
Epoch [48/50] - Loss: -0.0963
Epoch [49/50] - Loss: -0.0974
Epoch [50/50] - Loss: -0.0984
sum preds 107
sum labels 491
 - Test Metrics: Accuracy=0.8717, F1=0.3311, Recall=0.2016, Precision=0.9252
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4824
Epoch [3/50] - Loss: 0.4569
Epoch [4/50] - Loss: 0.4276
Epoch [5/50] - Loss: 0.3966
Epoch [6/50] - Loss: 0.3638
Epoch [7/50] - Loss: 0.3297
Epoch [8/50] - Loss: 0.2953
Epoch [9/50] - Loss: 0.2612
Epoch [10/50] - Loss: 0.2280
Epoch [11/50] - Loss: 0.1961
Epoch [12/50] - Loss: 0.1661
Epoch [13/50] - Loss: 0.1382
Epoch [14/50] - Loss: 0.1128
Epoch [15/50] - Loss: 0.0897
Epoch [16/50] - Loss: 0.0690
Epoch [17/50] - Loss: 0.0506
Epoch [18/50] - Loss: 0.0341
Epoch [19/50] - Loss: 0.0196
Epoch [20/50] - Loss: 0.0066
Epoch [21/50] - Loss: -0.0050
Epoch [22/50] - Loss: -0.0153
Epoch [23/50] - Loss: -0.0246
Epoch [24/50] - Loss: -0.0329
Epoch [25/50] - Loss: -0.0403
Epoch [26/50] - Loss: -0.0470
Epoch [27/50] - Loss: -0.0530
Epoch [28/50] - Loss: -0.0584
Epoch [29/50] - Loss: -0.0632
Epoch [30/50] - Loss: -0.0675
Epoch [31/50] - Loss: -0.0714
Epoch [32/50] - Loss: -0.0749
Epoch [33/50] - Loss: -0.0780
Epoch [34/50] - Loss: -0.0809
Epoch [35/50] - Loss: -0.0835
Epoch [36/50] - Loss: -0.0859
Epoch [37/50] - Loss: -0.0880
Epoch [38/50] - Loss: -0.0900
Epoch [39/50] - Loss: -0.0919
Epoch [40/50] - Loss: -0.0936
Epoch [41/50] - Loss: -0.0952
Epoch [42/50] - Loss: -0.0967
Epoch [43/50] - Loss: -0.0980
Epoch [44/50] - Loss: -0.0993
Epoch [45/50] - Loss: -0.1005
Epoch [46/50] - Loss: -0.1016
Epoch [47/50] - Loss: -0.1027
Epoch [48/50] - Loss: -0.1036
Epoch [49/50] - Loss: -0.1046
Epoch [50/50] - Loss: -0.1054
sum preds 79
sum labels 491
 - Test Metrics: Accuracy=0.8627, F1=0.2491, Recall=0.1446, Precision=0.8987
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4857
Epoch [3/50] - Loss: 0.4661
Epoch [4/50] - Loss: 0.4428
Epoch [5/50] - Loss: 0.4173
Epoch [6/50] - Loss: 0.3901
Epoch [7/50] - Loss: 0.3618
Epoch [8/50] - Loss: 0.3331
Epoch [9/50] - Loss: 0.3042
Epoch [10/50] - Loss: 0.2755
Epoch [11/50] - Loss: 0.2473
Epoch [12/50] - Loss: 0.2197
Epoch [13/50] - Loss: 0.1932
Epoch [14/50] - Loss: 0.1677
Epoch [15/50] - Loss: 0.1436
Epoch [16/50] - Loss: 0.1210
Epoch [17/50] - Loss: 0.0999
Epoch [18/50] - Loss: 0.0803
Epoch [19/50] - Loss: 0.0624
Epoch [20/50] - Loss: 0.0459
Epoch [21/50] - Loss: 0.0310
Epoch [22/50] - Loss: 0.0175
Epoch [23/50] - Loss: 0.0053
Epoch [24/50] - Loss: -0.0057
Epoch [25/50] - Loss: -0.0156
Epoch [26/50] - Loss: -0.0245
Epoch [27/50] - Loss: -0.0324
Epoch [28/50] - Loss: -0.0395
Epoch [29/50] - Loss: -0.0459
Epoch [30/50] - Loss: -0.0516
Epoch [31/50] - Loss: -0.0567
Epoch [32/50] - Loss: -0.0613
Epoch [33/50] - Loss: -0.0655
Epoch [34/50] - Loss: -0.0692
Epoch [35/50] - Loss: -0.0726
Epoch [36/50] - Loss: -0.0757
Epoch [37/50] - Loss: -0.0785
Epoch [38/50] - Loss: -0.0810
Epoch [39/50] - Loss: -0.0833
Epoch [40/50] - Loss: -0.0855
Epoch [41/50] - Loss: -0.0874
Epoch [42/50] - Loss: -0.0893
Epoch [43/50] - Loss: -0.0910
Epoch [44/50] - Loss: -0.0926
Epoch [45/50] - Loss: -0.0940
Epoch [46/50] - Loss: -0.0955
Epoch [47/50] - Loss: -0.0968
Epoch [48/50] - Loss: -0.0980
Epoch [49/50] - Loss: -0.0992
Epoch [50/50] - Loss: -0.1003
sum preds 97
sum labels 491
 - Test Metrics: Accuracy=0.8691, F1=0.3061, Recall=0.1833, Precision=0.9278
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_imbnnpu_imbnnpu_1804091243.csv.
Average F1 over valid seeds: 0.2954 ± 0.0343
___________________________________________________________________________________
Avg F1 for citeseer with SAR and imbnnpu, MLP,0.3: 0.2954 ± 0.0343
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4987
Epoch [2/50] - Loss: 0.4597
Epoch [3/50] - Loss: 0.4107
Epoch [4/50] - Loss: 0.3572
Epoch [5/50] - Loss: 0.3063
Epoch [6/50] - Loss: 0.2583
Epoch [7/50] - Loss: 0.2140
Epoch [8/50] - Loss: 0.1749
Epoch [9/50] - Loss: 0.1412
Epoch [10/50] - Loss: 0.1129
Epoch [11/50] - Loss: 0.0892
Epoch [12/50] - Loss: 0.0695
Epoch [13/50] - Loss: 0.0530
Epoch [14/50] - Loss: 0.0391
Epoch [15/50] - Loss: 0.0275
Epoch [16/50] - Loss: 0.0176
Epoch [17/50] - Loss: 0.0092
Epoch [18/50] - Loss: 0.0018
Epoch [19/50] - Loss: -0.0046
Epoch [20/50] - Loss: -0.0103
Epoch [21/50] - Loss: -0.0154
Epoch [22/50] - Loss: -0.0199
Epoch [23/50] - Loss: -0.0240
Epoch [24/50] - Loss: -0.0276
Epoch [25/50] - Loss: -0.0308
Epoch [26/50] - Loss: -0.0336
Epoch [27/50] - Loss: -0.0360
Epoch [28/50] - Loss: -0.0381
Epoch [29/50] - Loss: -0.0400
Epoch [30/50] - Loss: -0.0417
Epoch [31/50] - Loss: -0.0432
Epoch [32/50] - Loss: -0.0446
Epoch [33/50] - Loss: -0.0458
Epoch [34/50] - Loss: -0.0469
Epoch [35/50] - Loss: -0.0478
Epoch [36/50] - Loss: -0.0487
Epoch [37/50] - Loss: -0.0495
Epoch [38/50] - Loss: -0.0503
Epoch [39/50] - Loss: -0.0511
Epoch [40/50] - Loss: -0.0519
Epoch [41/50] - Loss: -0.0525
Epoch [42/50] - Loss: -0.0531
Epoch [43/50] - Loss: -0.0538
Epoch [44/50] - Loss: -0.0544
Epoch [45/50] - Loss: -0.0549
Epoch [46/50] - Loss: -0.0554
Epoch [47/50] - Loss: -0.0559
Epoch [48/50] - Loss: -0.0563
Epoch [49/50] - Loss: -0.0568
Epoch [50/50] - Loss: -0.0572
sum preds 258
sum labels 491
 - Test Metrics: Accuracy=0.9060, F1=0.6088, Recall=0.4644, Precision=0.8837
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5009
Epoch [2/50] - Loss: 0.4706
Epoch [3/50] - Loss: 0.4303
Epoch [4/50] - Loss: 0.3859
Epoch [5/50] - Loss: 0.3441
Epoch [6/50] - Loss: 0.3041
Epoch [7/50] - Loss: 0.2652
Epoch [8/50] - Loss: 0.2286
Epoch [9/50] - Loss: 0.1953
Epoch [10/50] - Loss: 0.1648
Epoch [11/50] - Loss: 0.1374
Epoch [12/50] - Loss: 0.1132
Epoch [13/50] - Loss: 0.0921
Epoch [14/50] - Loss: 0.0739
Epoch [15/50] - Loss: 0.0581
Epoch [16/50] - Loss: 0.0448
Epoch [17/50] - Loss: 0.0334
Epoch [18/50] - Loss: 0.0237
Epoch [19/50] - Loss: 0.0151
Epoch [20/50] - Loss: 0.0070
Epoch [21/50] - Loss: 0.0003
Epoch [22/50] - Loss: -0.0057
Epoch [23/50] - Loss: -0.0110
Epoch [24/50] - Loss: -0.0153
Epoch [25/50] - Loss: -0.0191
Epoch [26/50] - Loss: -0.0227
Epoch [27/50] - Loss: -0.0258
Epoch [28/50] - Loss: -0.0284
Epoch [29/50] - Loss: -0.0305
Epoch [30/50] - Loss: -0.0324
Epoch [31/50] - Loss: -0.0342
Epoch [32/50] - Loss: -0.0359
Epoch [33/50] - Loss: -0.0376
Epoch [34/50] - Loss: -0.0395
Epoch [35/50] - Loss: -0.0409
Epoch [36/50] - Loss: -0.0423
Epoch [37/50] - Loss: -0.0436
Epoch [38/50] - Loss: -0.0449
Epoch [39/50] - Loss: -0.0463
Epoch [40/50] - Loss: -0.0475
Epoch [41/50] - Loss: -0.0486
Epoch [42/50] - Loss: -0.0497
Epoch [43/50] - Loss: -0.0507
Epoch [44/50] - Loss: -0.0517
Epoch [45/50] - Loss: -0.0526
Epoch [46/50] - Loss: -0.0535
Epoch [47/50] - Loss: -0.0542
Epoch [48/50] - Loss: -0.0549
Epoch [49/50] - Loss: -0.0556
Epoch [50/50] - Loss: -0.0561
sum preds 323
sum labels 491
 - Test Metrics: Accuracy=0.9025, F1=0.6265, Recall=0.5193, Precision=0.7895
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4987
Epoch [2/50] - Loss: 0.4587
Epoch [3/50] - Loss: 0.4089
Epoch [4/50] - Loss: 0.3533
Epoch [5/50] - Loss: 0.3010
Epoch [6/50] - Loss: 0.2539
Epoch [7/50] - Loss: 0.2115
Epoch [8/50] - Loss: 0.1741
Epoch [9/50] - Loss: 0.1421
Epoch [10/50] - Loss: 0.1152
Epoch [11/50] - Loss: 0.0925
Epoch [12/50] - Loss: 0.0734
Epoch [13/50] - Loss: 0.0573
Epoch [14/50] - Loss: 0.0437
Epoch [15/50] - Loss: 0.0322
Epoch [16/50] - Loss: 0.0222
Epoch [17/50] - Loss: 0.0137
Epoch [18/50] - Loss: 0.0065
Epoch [19/50] - Loss: 0.0001
Epoch [20/50] - Loss: -0.0054
Epoch [21/50] - Loss: -0.0104
Epoch [22/50] - Loss: -0.0148
Epoch [23/50] - Loss: -0.0188
Epoch [24/50] - Loss: -0.0223
Epoch [25/50] - Loss: -0.0253
Epoch [26/50] - Loss: -0.0281
Epoch [27/50] - Loss: -0.0305
Epoch [28/50] - Loss: -0.0325
Epoch [29/50] - Loss: -0.0343
Epoch [30/50] - Loss: -0.0358
Epoch [31/50] - Loss: -0.0372
Epoch [32/50] - Loss: -0.0385
Epoch [33/50] - Loss: -0.0398
Epoch [34/50] - Loss: -0.0410
Epoch [35/50] - Loss: -0.0421
Epoch [36/50] - Loss: -0.0431
Epoch [37/50] - Loss: -0.0440
Epoch [38/50] - Loss: -0.0449
Epoch [39/50] - Loss: -0.0458
Epoch [40/50] - Loss: -0.0467
Epoch [41/50] - Loss: -0.0477
Epoch [42/50] - Loss: -0.0487
Epoch [43/50] - Loss: -0.0496
Epoch [44/50] - Loss: -0.0504
Epoch [45/50] - Loss: -0.0511
Epoch [46/50] - Loss: -0.0516
Epoch [47/50] - Loss: -0.0521
Epoch [48/50] - Loss: -0.0527
Epoch [49/50] - Loss: -0.0532
Epoch [50/50] - Loss: -0.0537
sum preds 318
sum labels 491
 - Test Metrics: Accuracy=0.9015, F1=0.6205, Recall=0.5112, Precision=0.7893
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_imbnnpu_imbnnpu_1804091245.csv.
Average F1 over valid seeds: 0.6186 ± 0.0074
___________________________________________________________________________________
Avg F1 for citeseer with SAR and imbnnpu, GATConv,0.3: 0.6186 ± 0.0074
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4989
Epoch [2/50] - Loss: 0.4524
Epoch [3/50] - Loss: 0.3938
Epoch [4/50] - Loss: 0.3331
Epoch [5/50] - Loss: 0.2788
Epoch [6/50] - Loss: 0.2299
Epoch [7/50] - Loss: 0.1875
Epoch [8/50] - Loss: 0.1524
Epoch [9/50] - Loss: 0.1240
Epoch [10/50] - Loss: 0.1009
Epoch [11/50] - Loss: 0.0820
Epoch [12/50] - Loss: 0.0665
Epoch [13/50] - Loss: 0.0538
Epoch [14/50] - Loss: 0.0432
Epoch [15/50] - Loss: 0.0343
Epoch [16/50] - Loss: 0.0266
Epoch [17/50] - Loss: 0.0200
Epoch [18/50] - Loss: 0.0142
Epoch [19/50] - Loss: 0.0090
Epoch [20/50] - Loss: 0.0043
Epoch [21/50] - Loss: 0.0001
Epoch [22/50] - Loss: -0.0038
Epoch [23/50] - Loss: -0.0073
Epoch [24/50] - Loss: -0.0105
Epoch [25/50] - Loss: -0.0135
Epoch [26/50] - Loss: -0.0163
Epoch [27/50] - Loss: -0.0189
Epoch [28/50] - Loss: -0.0212
Epoch [29/50] - Loss: -0.0235
Epoch [30/50] - Loss: -0.0255
Epoch [31/50] - Loss: -0.0274
Epoch [32/50] - Loss: -0.0291
Epoch [33/50] - Loss: -0.0307
Epoch [34/50] - Loss: -0.0322
Epoch [35/50] - Loss: -0.0335
Epoch [36/50] - Loss: -0.0348
Epoch [37/50] - Loss: -0.0359
Epoch [38/50] - Loss: -0.0369
Epoch [39/50] - Loss: -0.0378
Epoch [40/50] - Loss: -0.0387
Epoch [41/50] - Loss: -0.0394
Epoch [42/50] - Loss: -0.0402
Epoch [43/50] - Loss: -0.0409
Epoch [44/50] - Loss: -0.0415
Epoch [45/50] - Loss: -0.0421
Epoch [46/50] - Loss: -0.0427
Epoch [47/50] - Loss: -0.0433
Epoch [48/50] - Loss: -0.0438
Epoch [49/50] - Loss: -0.0444
Epoch [50/50] - Loss: -0.0449
sum preds 322
sum labels 491
 - Test Metrics: Accuracy=0.9111, F1=0.6593, Recall=0.5458, Precision=0.8323
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4972
Epoch [2/50] - Loss: 0.4587
Epoch [3/50] - Loss: 0.4092
Epoch [4/50] - Loss: 0.3566
Epoch [5/50] - Loss: 0.3071
Epoch [6/50] - Loss: 0.2617
Epoch [7/50] - Loss: 0.2210
Epoch [8/50] - Loss: 0.1852
Epoch [9/50] - Loss: 0.1546
Epoch [10/50] - Loss: 0.1286
Epoch [11/50] - Loss: 0.1069
Epoch [12/50] - Loss: 0.0888
Epoch [13/50] - Loss: 0.0736
Epoch [14/50] - Loss: 0.0608
Epoch [15/50] - Loss: 0.0500
Epoch [16/50] - Loss: 0.0408
Epoch [17/50] - Loss: 0.0328
Epoch [18/50] - Loss: 0.0259
Epoch [19/50] - Loss: 0.0200
Epoch [20/50] - Loss: 0.0147
Epoch [21/50] - Loss: 0.0101
Epoch [22/50] - Loss: 0.0061
Epoch [23/50] - Loss: 0.0025
Epoch [24/50] - Loss: -0.0008
Epoch [25/50] - Loss: -0.0036
Epoch [26/50] - Loss: -0.0062
Epoch [27/50] - Loss: -0.0085
Epoch [28/50] - Loss: -0.0107
Epoch [29/50] - Loss: -0.0126
Epoch [30/50] - Loss: -0.0144
Epoch [31/50] - Loss: -0.0161
Epoch [32/50] - Loss: -0.0177
Epoch [33/50] - Loss: -0.0192
Epoch [34/50] - Loss: -0.0206
Epoch [35/50] - Loss: -0.0219
Epoch [36/50] - Loss: -0.0232
Epoch [37/50] - Loss: -0.0245
Epoch [38/50] - Loss: -0.0256
Epoch [39/50] - Loss: -0.0267
Epoch [40/50] - Loss: -0.0277
Epoch [41/50] - Loss: -0.0287
Epoch [42/50] - Loss: -0.0295
Epoch [43/50] - Loss: -0.0303
Epoch [44/50] - Loss: -0.0311
Epoch [45/50] - Loss: -0.0318
Epoch [46/50] - Loss: -0.0324
Epoch [47/50] - Loss: -0.0330
Epoch [48/50] - Loss: -0.0336
Epoch [49/50] - Loss: -0.0342
Epoch [50/50] - Loss: -0.0347
sum preds 367
sum labels 491
 - Test Metrics: Accuracy=0.9153, F1=0.6923, Recall=0.6049, Precision=0.8093
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4992
Epoch [2/50] - Loss: 0.4586
Epoch [3/50] - Loss: 0.4076
Epoch [4/50] - Loss: 0.3515
Epoch [5/50] - Loss: 0.2978
Epoch [6/50] - Loss: 0.2486
Epoch [7/50] - Loss: 0.2054
Epoch [8/50] - Loss: 0.1685
Epoch [9/50] - Loss: 0.1372
Epoch [10/50] - Loss: 0.1110
Epoch [11/50] - Loss: 0.0893
Epoch [12/50] - Loss: 0.0715
Epoch [13/50] - Loss: 0.0569
Epoch [14/50] - Loss: 0.0448
Epoch [15/50] - Loss: 0.0347
Epoch [16/50] - Loss: 0.0261
Epoch [17/50] - Loss: 0.0187
Epoch [18/50] - Loss: 0.0123
Epoch [19/50] - Loss: 0.0066
Epoch [20/50] - Loss: 0.0014
Epoch [21/50] - Loss: -0.0032
Epoch [22/50] - Loss: -0.0074
Epoch [23/50] - Loss: -0.0112
Epoch [24/50] - Loss: -0.0146
Epoch [25/50] - Loss: -0.0177
Epoch [26/50] - Loss: -0.0204
Epoch [27/50] - Loss: -0.0229
Epoch [28/50] - Loss: -0.0252
Epoch [29/50] - Loss: -0.0272
Epoch [30/50] - Loss: -0.0291
Epoch [31/50] - Loss: -0.0308
Epoch [32/50] - Loss: -0.0324
Epoch [33/50] - Loss: -0.0339
Epoch [34/50] - Loss: -0.0352
Epoch [35/50] - Loss: -0.0364
Epoch [36/50] - Loss: -0.0375
Epoch [37/50] - Loss: -0.0384
Epoch [38/50] - Loss: -0.0393
Epoch [39/50] - Loss: -0.0402
Epoch [40/50] - Loss: -0.0410
Epoch [41/50] - Loss: -0.0418
Epoch [42/50] - Loss: -0.0425
Epoch [43/50] - Loss: -0.0433
Epoch [44/50] - Loss: -0.0440
Epoch [45/50] - Loss: -0.0447
Epoch [46/50] - Loss: -0.0454
Epoch [47/50] - Loss: -0.0460
Epoch [48/50] - Loss: -0.0466
Epoch [49/50] - Loss: -0.0472
Epoch [50/50] - Loss: -0.0477
sum preds 348
sum labels 491
 - Test Metrics: Accuracy=0.9086, F1=0.6603, Recall=0.5642, Precision=0.7960
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_imbnnpu_imbnnpu_1804091249.csv.
Average F1 over valid seeds: 0.6706 ± 0.0153
___________________________________________________________________________________
Avg F1 for citeseer with SAR and imbnnpu, GCNConv,0.3: 0.6706 ± 0.0153
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4870
Epoch [3/50] - Loss: 0.4687
Epoch [4/50] - Loss: 0.4461
Epoch [5/50] - Loss: 0.4210
Epoch [6/50] - Loss: 0.3937
Epoch [7/50] - Loss: 0.3641
Epoch [8/50] - Loss: 0.3330
Epoch [9/50] - Loss: 0.3011
Epoch [10/50] - Loss: 0.2687
Epoch [11/50] - Loss: 0.2363
Epoch [12/50] - Loss: 0.2045
Epoch [13/50] - Loss: 0.1740
Epoch [14/50] - Loss: 0.1451
Epoch [15/50] - Loss: 0.1181
Epoch [16/50] - Loss: 0.0933
Epoch [17/50] - Loss: 0.0708
Epoch [18/50] - Loss: 0.0506
Epoch [19/50] - Loss: 0.0326
Epoch [20/50] - Loss: 0.0166
Epoch [21/50] - Loss: 0.0024
Epoch [22/50] - Loss: -0.0102
Epoch [23/50] - Loss: -0.0212
Epoch [24/50] - Loss: -0.0310
Epoch [25/50] - Loss: -0.0396
Epoch [26/50] - Loss: -0.0471
Epoch [27/50] - Loss: -0.0538
Epoch [28/50] - Loss: -0.0597
Epoch [29/50] - Loss: -0.0649
Epoch [30/50] - Loss: -0.0696
Epoch [31/50] - Loss: -0.0737
Epoch [32/50] - Loss: -0.0774
Epoch [33/50] - Loss: -0.0808
Epoch [34/50] - Loss: -0.0837
Epoch [35/50] - Loss: -0.0864
Epoch [36/50] - Loss: -0.0889
Epoch [37/50] - Loss: -0.0912
Epoch [38/50] - Loss: -0.0933
Epoch [39/50] - Loss: -0.0952
Epoch [40/50] - Loss: -0.0970
Epoch [41/50] - Loss: -0.0986
Epoch [42/50] - Loss: -0.1002
Epoch [43/50] - Loss: -0.1016
Epoch [44/50] - Loss: -0.1029
Epoch [45/50] - Loss: -0.1042
Epoch [46/50] - Loss: -0.1053
Epoch [47/50] - Loss: -0.1064
Epoch [48/50] - Loss: -0.1074
Epoch [49/50] - Loss: -0.1084
Epoch [50/50] - Loss: -0.1092
sum preds 59
sum labels 561
 - Test Metrics: Accuracy=0.8393, F1=0.1742, Recall=0.0963, Precision=0.9153
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4820
Epoch [3/50] - Loss: 0.4568
Epoch [4/50] - Loss: 0.4270
Epoch [5/50] - Loss: 0.3952
Epoch [6/50] - Loss: 0.3615
Epoch [7/50] - Loss: 0.3265
Epoch [8/50] - Loss: 0.2909
Epoch [9/50] - Loss: 0.2555
Epoch [10/50] - Loss: 0.2208
Epoch [11/50] - Loss: 0.1873
Epoch [12/50] - Loss: 0.1557
Epoch [13/50] - Loss: 0.1262
Epoch [14/50] - Loss: 0.0992
Epoch [15/50] - Loss: 0.0748
Epoch [16/50] - Loss: 0.0529
Epoch [17/50] - Loss: 0.0335
Epoch [18/50] - Loss: 0.0163
Epoch [19/50] - Loss: 0.0012
Epoch [20/50] - Loss: -0.0120
Epoch [21/50] - Loss: -0.0237
Epoch [22/50] - Loss: -0.0340
Epoch [23/50] - Loss: -0.0430
Epoch [24/50] - Loss: -0.0510
Epoch [25/50] - Loss: -0.0581
Epoch [26/50] - Loss: -0.0644
Epoch [27/50] - Loss: -0.0699
Epoch [28/50] - Loss: -0.0748
Epoch [29/50] - Loss: -0.0791
Epoch [30/50] - Loss: -0.0830
Epoch [31/50] - Loss: -0.0864
Epoch [32/50] - Loss: -0.0894
Epoch [33/50] - Loss: -0.0922
Epoch [34/50] - Loss: -0.0946
Epoch [35/50] - Loss: -0.0969
Epoch [36/50] - Loss: -0.0989
Epoch [37/50] - Loss: -0.1007
Epoch [38/50] - Loss: -0.1024
Epoch [39/50] - Loss: -0.1039
Epoch [40/50] - Loss: -0.1053
Epoch [41/50] - Loss: -0.1066
Epoch [42/50] - Loss: -0.1078
Epoch [43/50] - Loss: -0.1090
Epoch [44/50] - Loss: -0.1100
Epoch [45/50] - Loss: -0.1110
Epoch [46/50] - Loss: -0.1119
Epoch [47/50] - Loss: -0.1127
Epoch [48/50] - Loss: -0.1135
Epoch [49/50] - Loss: -0.1143
Epoch [50/50] - Loss: -0.1150
sum preds 40
sum labels 561
 - Test Metrics: Accuracy=0.8340, F1=0.1198, Recall=0.0642, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4853
Epoch [3/50] - Loss: 0.4657
Epoch [4/50] - Loss: 0.4424
Epoch [5/50] - Loss: 0.4166
Epoch [6/50] - Loss: 0.3888
Epoch [7/50] - Loss: 0.3596
Epoch [8/50] - Loss: 0.3298
Epoch [9/50] - Loss: 0.2999
Epoch [10/50] - Loss: 0.2703
Epoch [11/50] - Loss: 0.2412
Epoch [12/50] - Loss: 0.2129
Epoch [13/50] - Loss: 0.1856
Epoch [14/50] - Loss: 0.1594
Epoch [15/50] - Loss: 0.1345
Epoch [16/50] - Loss: 0.1110
Epoch [17/50] - Loss: 0.0890
Epoch [18/50] - Loss: 0.0687
Epoch [19/50] - Loss: 0.0500
Epoch [20/50] - Loss: 0.0329
Epoch [21/50] - Loss: 0.0174
Epoch [22/50] - Loss: 0.0035
Epoch [23/50] - Loss: -0.0091
Epoch [24/50] - Loss: -0.0203
Epoch [25/50] - Loss: -0.0304
Epoch [26/50] - Loss: -0.0393
Epoch [27/50] - Loss: -0.0473
Epoch [28/50] - Loss: -0.0544
Epoch [29/50] - Loss: -0.0607
Epoch [30/50] - Loss: -0.0663
Epoch [31/50] - Loss: -0.0713
Epoch [32/50] - Loss: -0.0757
Epoch [33/50] - Loss: -0.0797
Epoch [34/50] - Loss: -0.0833
Epoch [35/50] - Loss: -0.0865
Epoch [36/50] - Loss: -0.0893
Epoch [37/50] - Loss: -0.0919
Epoch [38/50] - Loss: -0.0943
Epoch [39/50] - Loss: -0.0964
Epoch [40/50] - Loss: -0.0983
Epoch [41/50] - Loss: -0.1001
Epoch [42/50] - Loss: -0.1017
Epoch [43/50] - Loss: -0.1032
Epoch [44/50] - Loss: -0.1045
Epoch [45/50] - Loss: -0.1058
Epoch [46/50] - Loss: -0.1070
Epoch [47/50] - Loss: -0.1080
Epoch [48/50] - Loss: -0.1091
Epoch [49/50] - Loss: -0.1100
Epoch [50/50] - Loss: -0.1109
sum preds 56
sum labels 561
 - Test Metrics: Accuracy=0.8390, F1=0.1686, Recall=0.0927, Precision=0.9286
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_imbnnpu_imbnnpu_1804091251.csv.
Average F1 over valid seeds: 0.1542 ± 0.0244
___________________________________________________________________________________
Avg F1 for citeseer with SAR and imbnnpu, MLP,0.2: 0.1542 ± 0.0244
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4987
Epoch [2/50] - Loss: 0.4597
Epoch [3/50] - Loss: 0.4116
Epoch [4/50] - Loss: 0.3584
Epoch [5/50] - Loss: 0.3070
Epoch [6/50] - Loss: 0.2587
Epoch [7/50] - Loss: 0.2140
Epoch [8/50] - Loss: 0.1745
Epoch [9/50] - Loss: 0.1407
Epoch [10/50] - Loss: 0.1121
Epoch [11/50] - Loss: 0.0880
Epoch [12/50] - Loss: 0.0678
Epoch [13/50] - Loss: 0.0511
Epoch [14/50] - Loss: 0.0370
Epoch [15/50] - Loss: 0.0249
Epoch [16/50] - Loss: 0.0145
Epoch [17/50] - Loss: 0.0052
Epoch [18/50] - Loss: -0.0031
Epoch [19/50] - Loss: -0.0106
Epoch [20/50] - Loss: -0.0178
Epoch [21/50] - Loss: -0.0243
Epoch [22/50] - Loss: -0.0300
Epoch [23/50] - Loss: -0.0347
Epoch [24/50] - Loss: -0.0389
Epoch [25/50] - Loss: -0.0426
Epoch [26/50] - Loss: -0.0458
Epoch [27/50] - Loss: -0.0487
Epoch [28/50] - Loss: -0.0514
Epoch [29/50] - Loss: -0.0539
Epoch [30/50] - Loss: -0.0561
Epoch [31/50] - Loss: -0.0582
Epoch [32/50] - Loss: -0.0599
Epoch [33/50] - Loss: -0.0614
Epoch [34/50] - Loss: -0.0627
Epoch [35/50] - Loss: -0.0639
Epoch [36/50] - Loss: -0.0650
Epoch [37/50] - Loss: -0.0661
Epoch [38/50] - Loss: -0.0671
Epoch [39/50] - Loss: -0.0679
Epoch [40/50] - Loss: -0.0687
Epoch [41/50] - Loss: -0.0694
Epoch [42/50] - Loss: -0.0701
Epoch [43/50] - Loss: -0.0708
Epoch [44/50] - Loss: -0.0715
Epoch [45/50] - Loss: -0.0721
Epoch [46/50] - Loss: -0.0726
Epoch [47/50] - Loss: -0.0731
Epoch [48/50] - Loss: -0.0735
Epoch [49/50] - Loss: -0.0739
Epoch [50/50] - Loss: -0.0743
sum preds 214
sum labels 561
 - Test Metrics: Accuracy=0.8735, F1=0.4800, Recall=0.3316, Precision=0.8692
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5009
Epoch [2/50] - Loss: 0.4692
Epoch [3/50] - Loss: 0.4289
Epoch [4/50] - Loss: 0.3848
Epoch [5/50] - Loss: 0.3425
Epoch [6/50] - Loss: 0.3011
Epoch [7/50] - Loss: 0.2608
Epoch [8/50] - Loss: 0.2227
Epoch [9/50] - Loss: 0.1877
Epoch [10/50] - Loss: 0.1561
Epoch [11/50] - Loss: 0.1276
Epoch [12/50] - Loss: 0.1019
Epoch [13/50] - Loss: 0.0793
Epoch [14/50] - Loss: 0.0598
Epoch [15/50] - Loss: 0.0428
Epoch [16/50] - Loss: 0.0275
Epoch [17/50] - Loss: 0.0131
Epoch [18/50] - Loss: 0.0011
Epoch [19/50] - Loss: -0.0088
Epoch [20/50] - Loss: -0.0169
Epoch [21/50] - Loss: -0.0239
Epoch [22/50] - Loss: -0.0299
Epoch [23/50] - Loss: -0.0351
Epoch [24/50] - Loss: -0.0397
Epoch [25/50] - Loss: -0.0439
Epoch [26/50] - Loss: -0.0476
Epoch [27/50] - Loss: -0.0507
Epoch [28/50] - Loss: -0.0532
Epoch [29/50] - Loss: -0.0556
Epoch [30/50] - Loss: -0.0579
Epoch [31/50] - Loss: -0.0600
Epoch [32/50] - Loss: -0.0618
Epoch [33/50] - Loss: -0.0634
Epoch [34/50] - Loss: -0.0650
Epoch [35/50] - Loss: -0.0664
Epoch [36/50] - Loss: -0.0677
Epoch [37/50] - Loss: -0.0688
Epoch [38/50] - Loss: -0.0699
Epoch [39/50] - Loss: -0.0708
Epoch [40/50] - Loss: -0.0718
Epoch [41/50] - Loss: -0.0728
Epoch [42/50] - Loss: -0.0736
Epoch [43/50] - Loss: -0.0742
Epoch [44/50] - Loss: -0.0747
Epoch [45/50] - Loss: -0.0752
Epoch [46/50] - Loss: -0.0758
Epoch [47/50] - Loss: -0.0764
Epoch [48/50] - Loss: -0.0768
Epoch [49/50] - Loss: -0.0772
Epoch [50/50] - Loss: -0.0776
sum preds 247
sum labels 561
 - Test Metrics: Accuracy=0.8739, F1=0.5025, Recall=0.3619, Precision=0.8219
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4979
Epoch [2/50] - Loss: 0.4548
Epoch [3/50] - Loss: 0.4017
Epoch [4/50] - Loss: 0.3443
Epoch [5/50] - Loss: 0.2905
Epoch [6/50] - Loss: 0.2416
Epoch [7/50] - Loss: 0.1975
Epoch [8/50] - Loss: 0.1585
Epoch [9/50] - Loss: 0.1251
Epoch [10/50] - Loss: 0.0967
Epoch [11/50] - Loss: 0.0729
Epoch [12/50] - Loss: 0.0530
Epoch [13/50] - Loss: 0.0363
Epoch [14/50] - Loss: 0.0224
Epoch [15/50] - Loss: 0.0107
Epoch [16/50] - Loss: 0.0007
Epoch [17/50] - Loss: -0.0078
Epoch [18/50] - Loss: -0.0152
Epoch [19/50] - Loss: -0.0216
Epoch [20/50] - Loss: -0.0272
Epoch [21/50] - Loss: -0.0321
Epoch [22/50] - Loss: -0.0366
Epoch [23/50] - Loss: -0.0405
Epoch [24/50] - Loss: -0.0440
Epoch [25/50] - Loss: -0.0470
Epoch [26/50] - Loss: -0.0497
Epoch [27/50] - Loss: -0.0520
Epoch [28/50] - Loss: -0.0540
Epoch [29/50] - Loss: -0.0559
Epoch [30/50] - Loss: -0.0575
Epoch [31/50] - Loss: -0.0590
Epoch [32/50] - Loss: -0.0604
Epoch [33/50] - Loss: -0.0617
Epoch [34/50] - Loss: -0.0629
Epoch [35/50] - Loss: -0.0640
Epoch [36/50] - Loss: -0.0650
Epoch [37/50] - Loss: -0.0660
Epoch [38/50] - Loss: -0.0669
Epoch [39/50] - Loss: -0.0678
Epoch [40/50] - Loss: -0.0686
Epoch [41/50] - Loss: -0.0693
Epoch [42/50] - Loss: -0.0701
Epoch [43/50] - Loss: -0.0708
Epoch [44/50] - Loss: -0.0713
Epoch [45/50] - Loss: -0.0719
Epoch [46/50] - Loss: -0.0725
Epoch [47/50] - Loss: -0.0730
Epoch [48/50] - Loss: -0.0735
Epoch [49/50] - Loss: -0.0741
Epoch [50/50] - Loss: -0.0746
sum preds 255
sum labels 561
 - Test Metrics: Accuracy=0.8770, F1=0.5196, Recall=0.3779, Precision=0.8314
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_imbnnpu_imbnnpu_1804091253.csv.
Average F1 over valid seeds: 0.5007 ± 0.0162
___________________________________________________________________________________
Avg F1 for citeseer with SAR and imbnnpu, GATConv,0.2: 0.5007 ± 0.0162
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4987
Epoch [2/50] - Loss: 0.4508
Epoch [3/50] - Loss: 0.3923
Epoch [4/50] - Loss: 0.3315
Epoch [5/50] - Loss: 0.2763
Epoch [6/50] - Loss: 0.2275
Epoch [7/50] - Loss: 0.1856
Epoch [8/50] - Loss: 0.1508
Epoch [9/50] - Loss: 0.1224
Epoch [10/50] - Loss: 0.0992
Epoch [11/50] - Loss: 0.0801
Epoch [12/50] - Loss: 0.0644
Epoch [13/50] - Loss: 0.0512
Epoch [14/50] - Loss: 0.0401
Epoch [15/50] - Loss: 0.0305
Epoch [16/50] - Loss: 0.0221
Epoch [17/50] - Loss: 0.0146
Epoch [18/50] - Loss: 0.0080
Epoch [19/50] - Loss: 0.0019
Epoch [20/50] - Loss: -0.0036
Epoch [21/50] - Loss: -0.0086
Epoch [22/50] - Loss: -0.0133
Epoch [23/50] - Loss: -0.0177
Epoch [24/50] - Loss: -0.0217
Epoch [25/50] - Loss: -0.0254
Epoch [26/50] - Loss: -0.0288
Epoch [27/50] - Loss: -0.0319
Epoch [28/50] - Loss: -0.0348
Epoch [29/50] - Loss: -0.0374
Epoch [30/50] - Loss: -0.0397
Epoch [31/50] - Loss: -0.0418
Epoch [32/50] - Loss: -0.0436
Epoch [33/50] - Loss: -0.0453
Epoch [34/50] - Loss: -0.0467
Epoch [35/50] - Loss: -0.0480
Epoch [36/50] - Loss: -0.0492
Epoch [37/50] - Loss: -0.0502
Epoch [38/50] - Loss: -0.0512
Epoch [39/50] - Loss: -0.0521
Epoch [40/50] - Loss: -0.0529
Epoch [41/50] - Loss: -0.0537
Epoch [42/50] - Loss: -0.0545
Epoch [43/50] - Loss: -0.0553
Epoch [44/50] - Loss: -0.0560
Epoch [45/50] - Loss: -0.0567
Epoch [46/50] - Loss: -0.0574
Epoch [47/50] - Loss: -0.0581
Epoch [48/50] - Loss: -0.0587
Epoch [49/50] - Loss: -0.0593
Epoch [50/50] - Loss: -0.0599
sum preds 279
sum labels 561
 - Test Metrics: Accuracy=0.8864, F1=0.5690, Recall=0.4260, Precision=0.8566
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4967
Epoch [2/50] - Loss: 0.4565
Epoch [3/50] - Loss: 0.4051
Epoch [4/50] - Loss: 0.3502
Epoch [5/50] - Loss: 0.2983
Epoch [6/50] - Loss: 0.2506
Epoch [7/50] - Loss: 0.2078
Epoch [8/50] - Loss: 0.1702
Epoch [9/50] - Loss: 0.1378
Epoch [10/50] - Loss: 0.1103
Epoch [11/50] - Loss: 0.0872
Epoch [12/50] - Loss: 0.0679
Epoch [13/50] - Loss: 0.0517
Epoch [14/50] - Loss: 0.0380
Epoch [15/50] - Loss: 0.0265
Epoch [16/50] - Loss: 0.0167
Epoch [17/50] - Loss: 0.0083
Epoch [18/50] - Loss: 0.0011
Epoch [19/50] - Loss: -0.0051
Epoch [20/50] - Loss: -0.0105
Epoch [21/50] - Loss: -0.0153
Epoch [22/50] - Loss: -0.0196
Epoch [23/50] - Loss: -0.0234
Epoch [24/50] - Loss: -0.0267
Epoch [25/50] - Loss: -0.0298
Epoch [26/50] - Loss: -0.0326
Epoch [27/50] - Loss: -0.0351
Epoch [28/50] - Loss: -0.0374
Epoch [29/50] - Loss: -0.0394
Epoch [30/50] - Loss: -0.0413
Epoch [31/50] - Loss: -0.0430
Epoch [32/50] - Loss: -0.0445
Epoch [33/50] - Loss: -0.0460
Epoch [34/50] - Loss: -0.0473
Epoch [35/50] - Loss: -0.0485
Epoch [36/50] - Loss: -0.0497
Epoch [37/50] - Loss: -0.0507
Epoch [38/50] - Loss: -0.0517
Epoch [39/50] - Loss: -0.0527
Epoch [40/50] - Loss: -0.0536
Epoch [41/50] - Loss: -0.0544
Epoch [42/50] - Loss: -0.0553
Epoch [43/50] - Loss: -0.0560
Epoch [44/50] - Loss: -0.0568
Epoch [45/50] - Loss: -0.0575
Epoch [46/50] - Loss: -0.0582
Epoch [47/50] - Loss: -0.0588
Epoch [48/50] - Loss: -0.0595
Epoch [49/50] - Loss: -0.0601
Epoch [50/50] - Loss: -0.0607
sum preds 329
sum labels 561
 - Test Metrics: Accuracy=0.8902, F1=0.6067, Recall=0.4813, Precision=0.8207
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4992
Epoch [2/50] - Loss: 0.4576
Epoch [3/50] - Loss: 0.4061
Epoch [4/50] - Loss: 0.3483
Epoch [5/50] - Loss: 0.2925
Epoch [6/50] - Loss: 0.2412
Epoch [7/50] - Loss: 0.1962
Epoch [8/50] - Loss: 0.1578
Epoch [9/50] - Loss: 0.1252
Epoch [10/50] - Loss: 0.0979
Epoch [11/50] - Loss: 0.0752
Epoch [12/50] - Loss: 0.0565
Epoch [13/50] - Loss: 0.0411
Epoch [14/50] - Loss: 0.0283
Epoch [15/50] - Loss: 0.0176
Epoch [16/50] - Loss: 0.0085
Epoch [17/50] - Loss: 0.0006
Epoch [18/50] - Loss: -0.0062
Epoch [19/50] - Loss: -0.0121
Epoch [20/50] - Loss: -0.0174
Epoch [21/50] - Loss: -0.0221
Epoch [22/50] - Loss: -0.0263
Epoch [23/50] - Loss: -0.0301
Epoch [24/50] - Loss: -0.0334
Epoch [25/50] - Loss: -0.0364
Epoch [26/50] - Loss: -0.0391
Epoch [27/50] - Loss: -0.0415
Epoch [28/50] - Loss: -0.0438
Epoch [29/50] - Loss: -0.0458
Epoch [30/50] - Loss: -0.0477
Epoch [31/50] - Loss: -0.0494
Epoch [32/50] - Loss: -0.0511
Epoch [33/50] - Loss: -0.0526
Epoch [34/50] - Loss: -0.0541
Epoch [35/50] - Loss: -0.0555
Epoch [36/50] - Loss: -0.0569
Epoch [37/50] - Loss: -0.0583
Epoch [38/50] - Loss: -0.0597
Epoch [39/50] - Loss: -0.0611
Epoch [40/50] - Loss: -0.0623
Epoch [41/50] - Loss: -0.0634
Epoch [42/50] - Loss: -0.0644
Epoch [43/50] - Loss: -0.0653
Epoch [44/50] - Loss: -0.0660
Epoch [45/50] - Loss: -0.0668
Epoch [46/50] - Loss: -0.0674
Epoch [47/50] - Loss: -0.0681
Epoch [48/50] - Loss: -0.0687
Epoch [49/50] - Loss: -0.0693
Epoch [50/50] - Loss: -0.0698
sum preds 291
sum labels 561
 - Test Metrics: Accuracy=0.8801, F1=0.5516, Recall=0.4189, Precision=0.8076
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_imbnnpu_imbnnpu_1804091257.csv.
Average F1 over valid seeds: 0.5758 ± 0.0230
___________________________________________________________________________________
Avg F1 for citeseer with SAR and imbnnpu, GCNConv,0.2: 0.5758 ± 0.0230
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 5.9719
Epoch 10 / 50, Loss: 5.3514
Epoch 20 / 50, Loss: 5.3094
Epoch 30 / 50, Loss: 5.0593
Epoch 40 / 50, Loss: 4.8439
sum preds 130.0
sum labels 421
 - Test Metrics: Accuracy=0.8986, F1=0.4392, Recall=0.2874, Precision=0.9308
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 5.9975
Epoch 10 / 50, Loss: 5.4993
Epoch 20 / 50, Loss: 5.4406
Epoch 30 / 50, Loss: 5.1538
Epoch 40 / 50, Loss: 4.8167
sum preds 136.0
sum labels 421
 - Test Metrics: Accuracy=0.8920, F1=0.4093, Recall=0.2708, Precision=0.8382
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.052992235084594844, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.2820
Epoch 10 / 50, Loss: 5.8494
Epoch 20 / 50, Loss: 5.4824
Epoch 30 / 50, Loss: 5.2486
Epoch 40 / 50, Loss: 4.9731
sum preds 153.0
sum labels 421
 - Test Metrics: Accuracy=0.9002, F1=0.4704, Recall=0.3207, Precision=0.8824
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_ours_1804091300.csv.
Average F1 over valid seeds: 0.4396 ± 0.0249
___________________________________________________________________________________
Avg F1 for citeseer with SAR and ours, GATConv,0.4: 0.4396 ± 0.0249
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.4034
Epoch 10 / 50, Loss: 5.8430
Epoch 20 / 50, Loss: 5.7082
Epoch 30 / 50, Loss: 5.5449
Epoch 40 / 50, Loss: 5.2368
sum preds 202.0
sum labels 491
 - Test Metrics: Accuracy=0.8938, F1=0.5224, Recall=0.3686, Precision=0.8960
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.5973
Epoch 10 / 50, Loss: 6.1881
Epoch 20 / 50, Loss: 6.0715
Epoch 30 / 50, Loss: 5.7159
Epoch 40 / 50, Loss: 5.4443
sum preds 165.0
sum labels 491
 - Test Metrics: Accuracy=0.8826, F1=0.4421, Recall=0.2953, Precision=0.8788
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.07703213712302019, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.6654
Epoch 10 / 50, Loss: 6.3849
Epoch 20 / 50, Loss: 5.9415
Epoch 30 / 50, Loss: 5.7388
Epoch 40 / 50, Loss: 5.3842
sum preds 197.0
sum labels 491
 - Test Metrics: Accuracy=0.8916, F1=0.5087, Recall=0.3564, Precision=0.8883
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_ours_1804091348.csv.
Average F1 over valid seeds: 0.4911 ± 0.0351
___________________________________________________________________________________
Avg F1 for citeseer with SAR and ours, GATConv,0.3: 0.4911 ± 0.0351
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.2189
Epoch 10 / 50, Loss: 6.7224
Epoch 20 / 50, Loss: 6.5699
Epoch 30 / 50, Loss: 6.2782
Epoch 40 / 50, Loss: 5.9716
sum preds 191.0
sum labels 561
 - Test Metrics: Accuracy=0.8776, F1=0.4814, Recall=0.3226, Precision=0.9476
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.6916
Epoch 10 / 50, Loss: 7.2677
Epoch 20 / 50, Loss: 7.0664
Epoch 30 / 50, Loss: 6.6126
Epoch 40 / 50, Loss: 6.3431
sum preds 139.0
sum labels 561
 - Test Metrics: Accuracy=0.8601, F1=0.3629, Recall=0.2264, Precision=0.9137
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=4, layers=1, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.09988174354633943, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.3159
Epoch 10 / 50, Loss: 7.1013
Epoch 20 / 50, Loss: 6.5018
Epoch 30 / 50, Loss: 6.3535
Epoch 40 / 50, Loss: 5.9354
sum preds 200.0
sum labels 561
 - Test Metrics: Accuracy=0.8735, F1=0.4704, Recall=0.3191, Precision=0.8950
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to citeseer_experimentations\citeseer_SAR_ours_1804091436.csv.
Average F1 over valid seeds: 0.4382 ± 0.0535
___________________________________________________________________________________
Avg F1 for citeseer with SAR and ours, GATConv,0.2: 0.4382 ± 0.0535
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2217
Epoch [2/50] - Loss: 1.0875
Epoch [3/50] - Loss: 0.9642
Epoch [4/50] - Loss: 0.8585
Epoch [5/50] - Loss: 0.7771
Epoch [6/50] - Loss: 0.7244
Epoch [7/50] - Loss: 0.6934
Epoch [8/50] - Loss: 0.6887
Epoch [9/50] - Loss: 0.6745
Epoch [10/50] - Loss: 0.6667
Epoch [11/50] - Loss: 0.6372
Epoch [12/50] - Loss: 0.6114
Epoch [13/50] - Loss: 0.5820
Epoch [14/50] - Loss: 0.5627
Epoch [15/50] - Loss: 0.5330
Epoch [16/50] - Loss: 0.5196
Epoch [17/50] - Loss: 0.5014
Epoch [18/50] - Loss: 0.4857
Epoch [19/50] - Loss: 0.4758
Epoch [20/50] - Loss: 0.4621
Epoch [21/50] - Loss: 0.4443
Epoch [22/50] - Loss: 0.4317
Epoch [23/50] - Loss: 0.4080
Epoch [24/50] - Loss: 0.3919
Epoch [25/50] - Loss: 0.3764
Epoch [26/50] - Loss: 0.3630
Epoch [27/50] - Loss: 0.3501
Epoch [28/50] - Loss: 0.3288
Epoch [29/50] - Loss: 0.3126
Epoch [30/50] - Loss: 0.2990
Epoch [31/50] - Loss: 0.2851
Epoch [32/50] - Loss: 0.2694
Epoch [33/50] - Loss: 0.2534
Epoch [34/50] - Loss: 0.2423
Epoch [35/50] - Loss: 0.2274
Epoch [36/50] - Loss: 0.2150
Epoch [37/50] - Loss: 0.1983
Epoch [38/50] - Loss: 0.1872
Epoch [39/50] - Loss: 0.1753
Epoch [40/50] - Loss: 0.1702
Epoch [41/50] - Loss: 0.1548
Epoch [42/50] - Loss: 0.1469
Epoch [43/50] - Loss: 0.1399
Epoch [44/50] - Loss: 0.1314
Epoch [45/50] - Loss: 0.1245
Epoch [46/50] - Loss: 0.1174
Epoch [47/50] - Loss: 0.1097
Epoch [48/50] - Loss: 0.1020
Epoch [49/50] - Loss: 0.0979
Epoch [50/50] - Loss: 0.0940
sum preds 3
sum labels 491
 - Test Metrics: Accuracy=0.7950, F1=0.0121, Recall=0.0061, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2119
Epoch [2/50] - Loss: 1.0190
Epoch [3/50] - Loss: 0.8669
Epoch [4/50] - Loss: 0.7641
Epoch [5/50] - Loss: 0.7038
Epoch [6/50] - Loss: 0.6894
Epoch [7/50] - Loss: 0.6766
Epoch [8/50] - Loss: 0.6554
Epoch [9/50] - Loss: 0.6315
Epoch [10/50] - Loss: 0.5979
Epoch [11/50] - Loss: 0.5589
Epoch [12/50] - Loss: 0.5392
Epoch [13/50] - Loss: 0.5177
Epoch [14/50] - Loss: 0.4942
Epoch [15/50] - Loss: 0.4865
Epoch [16/50] - Loss: 0.4749
Epoch [17/50] - Loss: 0.4584
Epoch [18/50] - Loss: 0.4418
Epoch [19/50] - Loss: 0.4264
Epoch [20/50] - Loss: 0.4118
Epoch [21/50] - Loss: 0.3958
Epoch [22/50] - Loss: 0.3867
Epoch [23/50] - Loss: 0.3757
Epoch [24/50] - Loss: 0.3643
Epoch [25/50] - Loss: 0.3570
Epoch [26/50] - Loss: 0.3428
Epoch [27/50] - Loss: 0.3317
Epoch [28/50] - Loss: 0.3247
Epoch [29/50] - Loss: 0.3146
Epoch [30/50] - Loss: 0.3042
Epoch [31/50] - Loss: 0.2927
Epoch [32/50] - Loss: 0.2778
Epoch [33/50] - Loss: 0.2653
Epoch [34/50] - Loss: 0.2522
Epoch [35/50] - Loss: 0.2412
Epoch [36/50] - Loss: 0.2279
Epoch [37/50] - Loss: 0.2177
Epoch [38/50] - Loss: 0.2051
Epoch [39/50] - Loss: 0.1948
Epoch [40/50] - Loss: 0.1827
Epoch [41/50] - Loss: 0.1740
Epoch [42/50] - Loss: 0.1638
Epoch [43/50] - Loss: 0.1557
Epoch [44/50] - Loss: 0.1496
Epoch [45/50] - Loss: 0.1410
Epoch [46/50] - Loss: 0.1349
Epoch [47/50] - Loss: 0.1259
Epoch [48/50] - Loss: 0.1202
Epoch [49/50] - Loss: 0.1172
Epoch [50/50] - Loss: 0.1108
sum preds 7
sum labels 491
 - Test Metrics: Accuracy=0.7959, F1=0.0241, Recall=0.0122, Precision=0.8571
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1026
Epoch [2/50] - Loss: 0.9585
Epoch [3/50] - Loss: 0.8421
Epoch [4/50] - Loss: 0.7595
Epoch [5/50] - Loss: 0.7024
Epoch [6/50] - Loss: 0.6743
Epoch [7/50] - Loss: 0.6681
Epoch [8/50] - Loss: 0.6468
Epoch [9/50] - Loss: 0.6232
Epoch [10/50] - Loss: 0.5879
Epoch [11/50] - Loss: 0.5598
Epoch [12/50] - Loss: 0.5343
Epoch [13/50] - Loss: 0.5098
Epoch [14/50] - Loss: 0.4919
Epoch [15/50] - Loss: 0.4750
Epoch [16/50] - Loss: 0.4626
Epoch [17/50] - Loss: 0.4486
Epoch [18/50] - Loss: 0.4316
Epoch [19/50] - Loss: 0.4040
Epoch [20/50] - Loss: 0.3879
Epoch [21/50] - Loss: 0.3646
Epoch [22/50] - Loss: 0.3488
Epoch [23/50] - Loss: 0.3294
Epoch [24/50] - Loss: 0.3106
Epoch [25/50] - Loss: 0.2939
Epoch [26/50] - Loss: 0.2745
Epoch [27/50] - Loss: 0.2563
Epoch [28/50] - Loss: 0.2402
Epoch [29/50] - Loss: 0.2252
Epoch [30/50] - Loss: 0.2108
Epoch [31/50] - Loss: 0.1952
Epoch [32/50] - Loss: 0.1786
Epoch [33/50] - Loss: 0.1664
Epoch [34/50] - Loss: 0.1532
Epoch [35/50] - Loss: 0.1426
Epoch [36/50] - Loss: 0.1316
Epoch [37/50] - Loss: 0.1223
Epoch [38/50] - Loss: 0.1138
Epoch [39/50] - Loss: 0.1036
Epoch [40/50] - Loss: 0.0941
Epoch [41/50] - Loss: 0.0890
Epoch [42/50] - Loss: 0.0824
Epoch [43/50] - Loss: 0.0770
Epoch [44/50] - Loss: 0.0721
Epoch [45/50] - Loss: 0.0684
Epoch [46/50] - Loss: 0.0645
Epoch [47/50] - Loss: 0.0610
Epoch [48/50] - Loss: 0.0569
Epoch [49/50] - Loss: 0.0542
Epoch [50/50] - Loss: 0.0502
sum preds 2
sum labels 491
 - Test Metrics: Accuracy=0.7946, F1=0.0081, Recall=0.0041, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_naive_naive_1804091521.csv.
Average F1 over valid seeds: 0.0148 ± 0.0068
___________________________________________________________________________________
Avg F1 for cora with SCAR and naive, MLP,0.4: 0.0148 ± 0.0068
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3283
Epoch [2/50] - Loss: 0.9743
Epoch [3/50] - Loss: 0.7857
Epoch [4/50] - Loss: 0.7061
Epoch [5/50] - Loss: 0.6926
Epoch [6/50] - Loss: 0.6956
Epoch [7/50] - Loss: 0.6819
Epoch [8/50] - Loss: 0.6571
Epoch [9/50] - Loss: 0.6308
Epoch [10/50] - Loss: 0.5869
Epoch [11/50] - Loss: 0.5607
Epoch [12/50] - Loss: 0.5450
Epoch [13/50] - Loss: 0.5369
Epoch [14/50] - Loss: 0.5246
Epoch [15/50] - Loss: 0.5200
Epoch [16/50] - Loss: 0.5063
Epoch [17/50] - Loss: 0.4981
Epoch [18/50] - Loss: 0.4793
Epoch [19/50] - Loss: 0.4745
Epoch [20/50] - Loss: 0.4680
Epoch [21/50] - Loss: 0.4530
Epoch [22/50] - Loss: 0.4462
Epoch [23/50] - Loss: 0.4379
Epoch [24/50] - Loss: 0.4326
Epoch [25/50] - Loss: 0.4182
Epoch [26/50] - Loss: 0.4110
Epoch [27/50] - Loss: 0.4094
Epoch [28/50] - Loss: 0.4026
Epoch [29/50] - Loss: 0.4015
Epoch [30/50] - Loss: 0.3888
Epoch [31/50] - Loss: 0.3908
Epoch [32/50] - Loss: 0.3840
Epoch [33/50] - Loss: 0.3813
Epoch [34/50] - Loss: 0.3668
Epoch [35/50] - Loss: 0.3624
Epoch [36/50] - Loss: 0.3554
Epoch [37/50] - Loss: 0.3563
Epoch [38/50] - Loss: 0.3564
Epoch [39/50] - Loss: 0.3600
Epoch [40/50] - Loss: 0.3544
Epoch [41/50] - Loss: 0.3421
Epoch [42/50] - Loss: 0.3367
Epoch [43/50] - Loss: 0.3334
Epoch [44/50] - Loss: 0.3357
Epoch [45/50] - Loss: 0.3333
Epoch [46/50] - Loss: 0.3397
Epoch [47/50] - Loss: 0.3254
Epoch [48/50] - Loss: 0.3263
Epoch [49/50] - Loss: 0.3210
Epoch [50/50] - Loss: 0.3147
sum preds 68
sum labels 491
 - Test Metrics: Accuracy=0.8156, F1=0.2147, Recall=0.1222, Precision=0.8824
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1885
Epoch [2/50] - Loss: 0.8373
Epoch [3/50] - Loss: 0.6910
Epoch [4/50] - Loss: 0.6888
Epoch [5/50] - Loss: 0.7027
Epoch [6/50] - Loss: 0.6649
Epoch [7/50] - Loss: 0.6223
Epoch [8/50] - Loss: 0.5671
Epoch [9/50] - Loss: 0.5408
Epoch [10/50] - Loss: 0.5233
Epoch [11/50] - Loss: 0.5186
Epoch [12/50] - Loss: 0.5116
Epoch [13/50] - Loss: 0.4992
Epoch [14/50] - Loss: 0.4881
Epoch [15/50] - Loss: 0.4669
Epoch [16/50] - Loss: 0.4633
Epoch [17/50] - Loss: 0.4501
Epoch [18/50] - Loss: 0.4439
Epoch [19/50] - Loss: 0.4342
Epoch [20/50] - Loss: 0.4266
Epoch [21/50] - Loss: 0.4103
Epoch [22/50] - Loss: 0.4016
Epoch [23/50] - Loss: 0.3919
Epoch [24/50] - Loss: 0.3887
Epoch [25/50] - Loss: 0.3840
Epoch [26/50] - Loss: 0.3710
Epoch [27/50] - Loss: 0.3678
Epoch [28/50] - Loss: 0.3610
Epoch [29/50] - Loss: 0.3560
Epoch [30/50] - Loss: 0.3465
Epoch [31/50] - Loss: 0.3407
Epoch [32/50] - Loss: 0.3441
Epoch [33/50] - Loss: 0.3384
Epoch [34/50] - Loss: 0.3291
Epoch [35/50] - Loss: 0.3287
Epoch [36/50] - Loss: 0.3260
Epoch [37/50] - Loss: 0.3157
Epoch [38/50] - Loss: 0.3190
Epoch [39/50] - Loss: 0.3065
Epoch [40/50] - Loss: 0.3049
Epoch [41/50] - Loss: 0.3017
Epoch [42/50] - Loss: 0.2988
Epoch [43/50] - Loss: 0.3077
Epoch [44/50] - Loss: 0.2972
Epoch [45/50] - Loss: 0.2904
Epoch [46/50] - Loss: 0.2900
Epoch [47/50] - Loss: 0.2823
Epoch [48/50] - Loss: 0.2841
Epoch [49/50] - Loss: 0.2766
Epoch [50/50] - Loss: 0.2760
sum preds 74
sum labels 491
 - Test Metrics: Accuracy=0.8198, F1=0.2407, Recall=0.1385, Precision=0.9189
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2245
Epoch [2/50] - Loss: 0.8094
Epoch [3/50] - Loss: 0.7089
Epoch [4/50] - Loss: 0.7135
Epoch [5/50] - Loss: 0.6945
Epoch [6/50] - Loss: 0.6591
Epoch [7/50] - Loss: 0.5979
Epoch [8/50] - Loss: 0.5487
Epoch [9/50] - Loss: 0.5356
Epoch [10/50] - Loss: 0.5230
Epoch [11/50] - Loss: 0.5243
Epoch [12/50] - Loss: 0.5118
Epoch [13/50] - Loss: 0.4957
Epoch [14/50] - Loss: 0.4807
Epoch [15/50] - Loss: 0.4670
Epoch [16/50] - Loss: 0.4690
Epoch [17/50] - Loss: 0.4587
Epoch [18/50] - Loss: 0.4595
Epoch [19/50] - Loss: 0.4516
Epoch [20/50] - Loss: 0.4423
Epoch [21/50] - Loss: 0.4388
Epoch [22/50] - Loss: 0.4291
Epoch [23/50] - Loss: 0.4299
Epoch [24/50] - Loss: 0.4235
Epoch [25/50] - Loss: 0.4200
Epoch [26/50] - Loss: 0.4131
Epoch [27/50] - Loss: 0.4092
Epoch [28/50] - Loss: 0.4083
Epoch [29/50] - Loss: 0.4030
Epoch [30/50] - Loss: 0.3940
Epoch [31/50] - Loss: 0.3991
Epoch [32/50] - Loss: 0.3917
Epoch [33/50] - Loss: 0.3913
Epoch [34/50] - Loss: 0.3864
Epoch [35/50] - Loss: 0.3805
Epoch [36/50] - Loss: 0.3805
Epoch [37/50] - Loss: 0.3712
Epoch [38/50] - Loss: 0.3723
Epoch [39/50] - Loss: 0.3636
Epoch [40/50] - Loss: 0.3653
Epoch [41/50] - Loss: 0.3551
Epoch [42/50] - Loss: 0.3579
Epoch [43/50] - Loss: 0.3454
Epoch [44/50] - Loss: 0.3437
Epoch [45/50] - Loss: 0.3425
Epoch [46/50] - Loss: 0.3282
Epoch [47/50] - Loss: 0.3284
Epoch [48/50] - Loss: 0.3243
Epoch [49/50] - Loss: 0.3164
Epoch [50/50] - Loss: 0.3133
sum preds 72
sum labels 491
 - Test Metrics: Accuracy=0.8198, F1=0.2380, Recall=0.1365, Precision=0.9306
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_naive_naive_1804091605.csv.
Average F1 over valid seeds: 0.2311 ± 0.0117
___________________________________________________________________________________
Avg F1 for cora with SCAR and naive, GATConv,0.4: 0.2311 ± 0.0117
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2329
Epoch [2/50] - Loss: 0.9248
Epoch [3/50] - Loss: 0.7667
Epoch [4/50] - Loss: 0.7097
Epoch [5/50] - Loss: 0.7005
Epoch [6/50] - Loss: 0.7081
Epoch [7/50] - Loss: 0.6990
Epoch [8/50] - Loss: 0.6652
Epoch [9/50] - Loss: 0.6294
Epoch [10/50] - Loss: 0.5990
Epoch [11/50] - Loss: 0.5764
Epoch [12/50] - Loss: 0.5641
Epoch [13/50] - Loss: 0.5455
Epoch [14/50] - Loss: 0.5406
Epoch [15/50] - Loss: 0.5393
Epoch [16/50] - Loss: 0.5279
Epoch [17/50] - Loss: 0.5185
Epoch [18/50] - Loss: 0.5064
Epoch [19/50] - Loss: 0.4979
Epoch [20/50] - Loss: 0.4874
Epoch [21/50] - Loss: 0.4822
Epoch [22/50] - Loss: 0.4740
Epoch [23/50] - Loss: 0.4682
Epoch [24/50] - Loss: 0.4639
Epoch [25/50] - Loss: 0.4619
Epoch [26/50] - Loss: 0.4576
Epoch [27/50] - Loss: 0.4488
Epoch [28/50] - Loss: 0.4524
Epoch [29/50] - Loss: 0.4428
Epoch [30/50] - Loss: 0.4389
Epoch [31/50] - Loss: 0.4414
Epoch [32/50] - Loss: 0.4342
Epoch [33/50] - Loss: 0.4275
Epoch [34/50] - Loss: 0.4269
Epoch [35/50] - Loss: 0.4200
Epoch [36/50] - Loss: 0.4177
Epoch [37/50] - Loss: 0.4179
Epoch [38/50] - Loss: 0.4141
Epoch [39/50] - Loss: 0.4140
Epoch [40/50] - Loss: 0.4043
Epoch [41/50] - Loss: 0.4033
Epoch [42/50] - Loss: 0.4031
Epoch [43/50] - Loss: 0.4055
Epoch [44/50] - Loss: 0.4012
Epoch [45/50] - Loss: 0.3952
Epoch [46/50] - Loss: 0.3983
Epoch [47/50] - Loss: 0.3940
Epoch [48/50] - Loss: 0.3910
Epoch [49/50] - Loss: 0.3909
Epoch [50/50] - Loss: 0.3878
sum preds 8
sum labels 491
 - Test Metrics: Accuracy=0.7971, F1=0.0321, Recall=0.0163, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3289
Epoch [2/50] - Loss: 1.0693
Epoch [3/50] - Loss: 0.8789
Epoch [4/50] - Loss: 0.7672
Epoch [5/50] - Loss: 0.7249
Epoch [6/50] - Loss: 0.7088
Epoch [7/50] - Loss: 0.6925
Epoch [8/50] - Loss: 0.6960
Epoch [9/50] - Loss: 0.6756
Epoch [10/50] - Loss: 0.6530
Epoch [11/50] - Loss: 0.6248
Epoch [12/50] - Loss: 0.6066
Epoch [13/50] - Loss: 0.5793
Epoch [14/50] - Loss: 0.5662
Epoch [15/50] - Loss: 0.5532
Epoch [16/50] - Loss: 0.5488
Epoch [17/50] - Loss: 0.5299
Epoch [18/50] - Loss: 0.5187
Epoch [19/50] - Loss: 0.5090
Epoch [20/50] - Loss: 0.5027
Epoch [21/50] - Loss: 0.4877
Epoch [22/50] - Loss: 0.4801
Epoch [23/50] - Loss: 0.4747
Epoch [24/50] - Loss: 0.4696
Epoch [25/50] - Loss: 0.4623
Epoch [26/50] - Loss: 0.4601
Epoch [27/50] - Loss: 0.4471
Epoch [28/50] - Loss: 0.4491
Epoch [29/50] - Loss: 0.4466
Epoch [30/50] - Loss: 0.4379
Epoch [31/50] - Loss: 0.4368
Epoch [32/50] - Loss: 0.4294
Epoch [33/50] - Loss: 0.4243
Epoch [34/50] - Loss: 0.4230
Epoch [35/50] - Loss: 0.4180
Epoch [36/50] - Loss: 0.4137
Epoch [37/50] - Loss: 0.4136
Epoch [38/50] - Loss: 0.4071
Epoch [39/50] - Loss: 0.4014
Epoch [40/50] - Loss: 0.3975
Epoch [41/50] - Loss: 0.3935
Epoch [42/50] - Loss: 0.3910
Epoch [43/50] - Loss: 0.3830
Epoch [44/50] - Loss: 0.3821
Epoch [45/50] - Loss: 0.3722
Epoch [46/50] - Loss: 0.3721
Epoch [47/50] - Loss: 0.3648
Epoch [48/50] - Loss: 0.3558
Epoch [49/50] - Loss: 0.3534
Epoch [50/50] - Loss: 0.3518
sum preds 83
sum labels 491
 - Test Metrics: Accuracy=0.8236, F1=0.2683, Recall=0.1568, Precision=0.9277
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4203
Epoch [2/50] - Loss: 1.1712
Epoch [3/50] - Loss: 1.0193
Epoch [4/50] - Loss: 0.8953
Epoch [5/50] - Loss: 0.8015
Epoch [6/50] - Loss: 0.7486
Epoch [7/50] - Loss: 0.7240
Epoch [8/50] - Loss: 0.7161
Epoch [9/50] - Loss: 0.7137
Epoch [10/50] - Loss: 0.7088
Epoch [11/50] - Loss: 0.7032
Epoch [12/50] - Loss: 0.6756
Epoch [13/50] - Loss: 0.6576
Epoch [14/50] - Loss: 0.6419
Epoch [15/50] - Loss: 0.6257
Epoch [16/50] - Loss: 0.6073
Epoch [17/50] - Loss: 0.5905
Epoch [18/50] - Loss: 0.5848
Epoch [19/50] - Loss: 0.5719
Epoch [20/50] - Loss: 0.5633
Epoch [21/50] - Loss: 0.5552
Epoch [22/50] - Loss: 0.5494
Epoch [23/50] - Loss: 0.5386
Epoch [24/50] - Loss: 0.5273
Epoch [25/50] - Loss: 0.5232
Epoch [26/50] - Loss: 0.5152
Epoch [27/50] - Loss: 0.5079
Epoch [28/50] - Loss: 0.5041
Epoch [29/50] - Loss: 0.4895
Epoch [30/50] - Loss: 0.4912
Epoch [31/50] - Loss: 0.4813
Epoch [32/50] - Loss: 0.4786
Epoch [33/50] - Loss: 0.4720
Epoch [34/50] - Loss: 0.4712
Epoch [35/50] - Loss: 0.4650
Epoch [36/50] - Loss: 0.4589
Epoch [37/50] - Loss: 0.4621
Epoch [38/50] - Loss: 0.4540
Epoch [39/50] - Loss: 0.4485
Epoch [40/50] - Loss: 0.4480
Epoch [41/50] - Loss: 0.4472
Epoch [42/50] - Loss: 0.4498
Epoch [43/50] - Loss: 0.4403
Epoch [44/50] - Loss: 0.4381
Epoch [45/50] - Loss: 0.4365
Epoch [46/50] - Loss: 0.4366
Epoch [47/50] - Loss: 0.4348
Epoch [48/50] - Loss: 0.4318
Epoch [49/50] - Loss: 0.4249
Epoch [50/50] - Loss: 0.4228
sum preds 15
sum labels 491
 - Test Metrics: Accuracy=0.8001, F1=0.0593, Recall=0.0305, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_naive_naive_1804091646.csv.
Average F1 over valid seeds: 0.1199 ± 0.1055
___________________________________________________________________________________
Avg F1 for cora with SCAR and naive, GCNConv,0.4: 0.1199 ± 0.1055
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2082
Epoch [2/50] - Loss: 1.0614
Epoch [3/50] - Loss: 0.9255
Epoch [4/50] - Loss: 0.8039
Epoch [5/50] - Loss: 0.7062
Epoch [6/50] - Loss: 0.6401
Epoch [7/50] - Loss: 0.6039
Epoch [8/50] - Loss: 0.5957
Epoch [9/50] - Loss: 0.5867
Epoch [10/50] - Loss: 0.5858
Epoch [11/50] - Loss: 0.5678
Epoch [12/50] - Loss: 0.5453
Epoch [13/50] - Loss: 0.5256
Epoch [14/50] - Loss: 0.5084
Epoch [15/50] - Loss: 0.4808
Epoch [16/50] - Loss: 0.4648
Epoch [17/50] - Loss: 0.4486
Epoch [18/50] - Loss: 0.4284
Epoch [19/50] - Loss: 0.4233
Epoch [20/50] - Loss: 0.4140
Epoch [21/50] - Loss: 0.4008
Epoch [22/50] - Loss: 0.3916
Epoch [23/50] - Loss: 0.3747
Epoch [24/50] - Loss: 0.3642
Epoch [25/50] - Loss: 0.3523
Epoch [26/50] - Loss: 0.3441
Epoch [27/50] - Loss: 0.3333
Epoch [28/50] - Loss: 0.3203
Epoch [29/50] - Loss: 0.3085
Epoch [30/50] - Loss: 0.3012
Epoch [31/50] - Loss: 0.2950
Epoch [32/50] - Loss: 0.2831
Epoch [33/50] - Loss: 0.2770
Epoch [34/50] - Loss: 0.2695
Epoch [35/50] - Loss: 0.2615
Epoch [36/50] - Loss: 0.2516
Epoch [37/50] - Loss: 0.2421
Epoch [38/50] - Loss: 0.2374
Epoch [39/50] - Loss: 0.2303
Epoch [40/50] - Loss: 0.2247
Epoch [41/50] - Loss: 0.2140
Epoch [42/50] - Loss: 0.2069
Epoch [43/50] - Loss: 0.1981
Epoch [44/50] - Loss: 0.1896
Epoch [45/50] - Loss: 0.1806
Epoch [46/50] - Loss: 0.1703
Epoch [47/50] - Loss: 0.1565
Epoch [48/50] - Loss: 0.1460
Epoch [49/50] - Loss: 0.1362
Epoch [50/50] - Loss: 0.1292
sum preds 9
sum labels 573
 - Test Metrics: Accuracy=0.7710, F1=0.0309, Recall=0.0157, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1976
Epoch [2/50] - Loss: 0.9887
Epoch [3/50] - Loss: 0.8133
Epoch [4/50] - Loss: 0.6958
Epoch [5/50] - Loss: 0.6204
Epoch [6/50] - Loss: 0.5986
Epoch [7/50] - Loss: 0.5911
Epoch [8/50] - Loss: 0.5783
Epoch [9/50] - Loss: 0.5651
Epoch [10/50] - Loss: 0.5387
Epoch [11/50] - Loss: 0.5064
Epoch [12/50] - Loss: 0.4888
Epoch [13/50] - Loss: 0.4625
Epoch [14/50] - Loss: 0.4351
Epoch [15/50] - Loss: 0.4232
Epoch [16/50] - Loss: 0.4119
Epoch [17/50] - Loss: 0.3969
Epoch [18/50] - Loss: 0.3858
Epoch [19/50] - Loss: 0.3764
Epoch [20/50] - Loss: 0.3628
Epoch [21/50] - Loss: 0.3479
Epoch [22/50] - Loss: 0.3352
Epoch [23/50] - Loss: 0.3267
Epoch [24/50] - Loss: 0.3148
Epoch [25/50] - Loss: 0.3086
Epoch [26/50] - Loss: 0.2977
Epoch [27/50] - Loss: 0.2860
Epoch [28/50] - Loss: 0.2822
Epoch [29/50] - Loss: 0.2741
Epoch [30/50] - Loss: 0.2666
Epoch [31/50] - Loss: 0.2602
Epoch [32/50] - Loss: 0.2527
Epoch [33/50] - Loss: 0.2470
Epoch [34/50] - Loss: 0.2403
Epoch [35/50] - Loss: 0.2387
Epoch [36/50] - Loss: 0.2285
Epoch [37/50] - Loss: 0.2260
Epoch [38/50] - Loss: 0.2200
Epoch [39/50] - Loss: 0.2141
Epoch [40/50] - Loss: 0.2085
Epoch [41/50] - Loss: 0.2054
Epoch [42/50] - Loss: 0.2012
Epoch [43/50] - Loss: 0.1979
Epoch [44/50] - Loss: 0.1977
Epoch [45/50] - Loss: 0.1928
Epoch [46/50] - Loss: 0.1893
Epoch [47/50] - Loss: 0.1814
Epoch [48/50] - Loss: 0.1784
Epoch [49/50] - Loss: 0.1740
Epoch [50/50] - Loss: 0.1646
sum preds 9
sum labels 573
 - Test Metrics: Accuracy=0.7702, F1=0.0275, Recall=0.0140, Precision=0.8889
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0773
Epoch [2/50] - Loss: 0.9173
Epoch [3/50] - Loss: 0.7823
Epoch [4/50] - Loss: 0.6839
Epoch [5/50] - Loss: 0.6159
Epoch [6/50] - Loss: 0.5859
Epoch [7/50] - Loss: 0.5803
Epoch [8/50] - Loss: 0.5696
Epoch [9/50] - Loss: 0.5605
Epoch [10/50] - Loss: 0.5322
Epoch [11/50] - Loss: 0.5136
Epoch [12/50] - Loss: 0.4874
Epoch [13/50] - Loss: 0.4630
Epoch [14/50] - Loss: 0.4458
Epoch [15/50] - Loss: 0.4236
Epoch [16/50] - Loss: 0.4155
Epoch [17/50] - Loss: 0.4049
Epoch [18/50] - Loss: 0.3941
Epoch [19/50] - Loss: 0.3764
Epoch [20/50] - Loss: 0.3647
Epoch [21/50] - Loss: 0.3484
Epoch [22/50] - Loss: 0.3360
Epoch [23/50] - Loss: 0.3232
Epoch [24/50] - Loss: 0.3153
Epoch [25/50] - Loss: 0.3082
Epoch [26/50] - Loss: 0.2928
Epoch [27/50] - Loss: 0.2841
Epoch [28/50] - Loss: 0.2760
Epoch [29/50] - Loss: 0.2713
Epoch [30/50] - Loss: 0.2631
Epoch [31/50] - Loss: 0.2540
Epoch [32/50] - Loss: 0.2424
Epoch [33/50] - Loss: 0.2361
Epoch [34/50] - Loss: 0.2249
Epoch [35/50] - Loss: 0.2187
Epoch [36/50] - Loss: 0.2117
Epoch [37/50] - Loss: 0.2031
Epoch [38/50] - Loss: 0.1979
Epoch [39/50] - Loss: 0.1834
Epoch [40/50] - Loss: 0.1741
Epoch [41/50] - Loss: 0.1643
Epoch [42/50] - Loss: 0.1524
Epoch [43/50] - Loss: 0.1400
Epoch [44/50] - Loss: 0.1284
Epoch [45/50] - Loss: 0.1175
Epoch [46/50] - Loss: 0.1072
Epoch [47/50] - Loss: 0.0994
Epoch [48/50] - Loss: 0.0895
Epoch [49/50] - Loss: 0.0830
Epoch [50/50] - Loss: 0.0738
sum preds 2
sum labels 573
 - Test Metrics: Accuracy=0.7682, F1=0.0070, Recall=0.0035, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_naive_naive_1804091727.csv.
Average F1 over valid seeds: 0.0218 ± 0.0106
___________________________________________________________________________________
Avg F1 for cora with SCAR and naive, MLP,0.3: 0.0218 ± 0.0106
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3232
Epoch [2/50] - Loss: 0.9365
Epoch [3/50] - Loss: 0.7152
Epoch [4/50] - Loss: 0.6091
Epoch [5/50] - Loss: 0.5837
Epoch [6/50] - Loss: 0.5963
Epoch [7/50] - Loss: 0.5974
Epoch [8/50] - Loss: 0.5922
Epoch [9/50] - Loss: 0.5801
Epoch [10/50] - Loss: 0.5401
Epoch [11/50] - Loss: 0.5160
Epoch [12/50] - Loss: 0.4910
Epoch [13/50] - Loss: 0.4717
Epoch [14/50] - Loss: 0.4595
Epoch [15/50] - Loss: 0.4596
Epoch [16/50] - Loss: 0.4492
Epoch [17/50] - Loss: 0.4479
Epoch [18/50] - Loss: 0.4347
Epoch [19/50] - Loss: 0.4302
Epoch [20/50] - Loss: 0.4184
Epoch [21/50] - Loss: 0.4078
Epoch [22/50] - Loss: 0.3975
Epoch [23/50] - Loss: 0.3922
Epoch [24/50] - Loss: 0.3870
Epoch [25/50] - Loss: 0.3738
Epoch [26/50] - Loss: 0.3705
Epoch [27/50] - Loss: 0.3646
Epoch [28/50] - Loss: 0.3580
Epoch [29/50] - Loss: 0.3575
Epoch [30/50] - Loss: 0.3424
Epoch [31/50] - Loss: 0.3450
Epoch [32/50] - Loss: 0.3370
Epoch [33/50] - Loss: 0.3340
Epoch [34/50] - Loss: 0.3206
Epoch [35/50] - Loss: 0.3149
Epoch [36/50] - Loss: 0.3130
Epoch [37/50] - Loss: 0.3063
Epoch [38/50] - Loss: 0.3065
Epoch [39/50] - Loss: 0.3085
Epoch [40/50] - Loss: 0.3003
Epoch [41/50] - Loss: 0.2931
Epoch [42/50] - Loss: 0.2841
Epoch [43/50] - Loss: 0.2851
Epoch [44/50] - Loss: 0.2846
Epoch [45/50] - Loss: 0.2802
Epoch [46/50] - Loss: 0.2842
Epoch [47/50] - Loss: 0.2789
Epoch [48/50] - Loss: 0.2751
Epoch [49/50] - Loss: 0.2863
Epoch [50/50] - Loss: 0.2710
sum preds 20
sum labels 573
 - Test Metrics: Accuracy=0.7730, F1=0.0573, Recall=0.0297, Precision=0.8500
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1730
Epoch [2/50] - Loss: 0.7798
Epoch [3/50] - Loss: 0.5929
Epoch [4/50] - Loss: 0.5774
Epoch [5/50] - Loss: 0.6074
Epoch [6/50] - Loss: 0.5956
Epoch [7/50] - Loss: 0.5715
Epoch [8/50] - Loss: 0.5284
Epoch [9/50] - Loss: 0.4982
Epoch [10/50] - Loss: 0.4708
Epoch [11/50] - Loss: 0.4536
Epoch [12/50] - Loss: 0.4457
Epoch [13/50] - Loss: 0.4435
Epoch [14/50] - Loss: 0.4410
Epoch [15/50] - Loss: 0.4276
Epoch [16/50] - Loss: 0.4197
Epoch [17/50] - Loss: 0.4076
Epoch [18/50] - Loss: 0.3966
Epoch [19/50] - Loss: 0.3895
Epoch [20/50] - Loss: 0.3825
Epoch [21/50] - Loss: 0.3666
Epoch [22/50] - Loss: 0.3566
Epoch [23/50] - Loss: 0.3520
Epoch [24/50] - Loss: 0.3443
Epoch [25/50] - Loss: 0.3436
Epoch [26/50] - Loss: 0.3343
Epoch [27/50] - Loss: 0.3345
Epoch [28/50] - Loss: 0.3263
Epoch [29/50] - Loss: 0.3182
Epoch [30/50] - Loss: 0.3095
Epoch [31/50] - Loss: 0.3016
Epoch [32/50] - Loss: 0.3049
Epoch [33/50] - Loss: 0.2979
Epoch [34/50] - Loss: 0.2961
Epoch [35/50] - Loss: 0.2924
Epoch [36/50] - Loss: 0.2888
Epoch [37/50] - Loss: 0.2783
Epoch [38/50] - Loss: 0.2773
Epoch [39/50] - Loss: 0.2654
Epoch [40/50] - Loss: 0.2642
Epoch [41/50] - Loss: 0.2617
Epoch [42/50] - Loss: 0.2573
Epoch [43/50] - Loss: 0.2685
Epoch [44/50] - Loss: 0.2489
Epoch [45/50] - Loss: 0.2484
Epoch [46/50] - Loss: 0.2435
Epoch [47/50] - Loss: 0.2453
Epoch [48/50] - Loss: 0.2397
Epoch [49/50] - Loss: 0.2287
Epoch [50/50] - Loss: 0.2298
sum preds 49
sum labels 573
 - Test Metrics: Accuracy=0.7856, F1=0.1511, Recall=0.0820, Precision=0.9592
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2080
Epoch [2/50] - Loss: 0.7384
Epoch [3/50] - Loss: 0.5960
Epoch [4/50] - Loss: 0.6059
Epoch [5/50] - Loss: 0.6118
Epoch [6/50] - Loss: 0.6046
Epoch [7/50] - Loss: 0.5623
Epoch [8/50] - Loss: 0.5123
Epoch [9/50] - Loss: 0.4840
Epoch [10/50] - Loss: 0.4560
Epoch [11/50] - Loss: 0.4564
Epoch [12/50] - Loss: 0.4509
Epoch [13/50] - Loss: 0.4497
Epoch [14/50] - Loss: 0.4388
Epoch [15/50] - Loss: 0.4233
Epoch [16/50] - Loss: 0.4173
Epoch [17/50] - Loss: 0.4052
Epoch [18/50] - Loss: 0.4050
Epoch [19/50] - Loss: 0.3985
Epoch [20/50] - Loss: 0.3923
Epoch [21/50] - Loss: 0.3907
Epoch [22/50] - Loss: 0.3811
Epoch [23/50] - Loss: 0.3796
Epoch [24/50] - Loss: 0.3737
Epoch [25/50] - Loss: 0.3691
Epoch [26/50] - Loss: 0.3634
Epoch [27/50] - Loss: 0.3608
Epoch [28/50] - Loss: 0.3607
Epoch [29/50] - Loss: 0.3537
Epoch [30/50] - Loss: 0.3479
Epoch [31/50] - Loss: 0.3511
Epoch [32/50] - Loss: 0.3470
Epoch [33/50] - Loss: 0.3456
Epoch [34/50] - Loss: 0.3406
Epoch [35/50] - Loss: 0.3360
Epoch [36/50] - Loss: 0.3374
Epoch [37/50] - Loss: 0.3285
Epoch [38/50] - Loss: 0.3345
Epoch [39/50] - Loss: 0.3257
Epoch [40/50] - Loss: 0.3263
Epoch [41/50] - Loss: 0.3184
Epoch [42/50] - Loss: 0.3227
Epoch [43/50] - Loss: 0.3157
Epoch [44/50] - Loss: 0.3148
Epoch [45/50] - Loss: 0.3116
Epoch [46/50] - Loss: 0.3025
Epoch [47/50] - Loss: 0.3061
Epoch [48/50] - Loss: 0.3007
Epoch [49/50] - Loss: 0.2930
Epoch [50/50] - Loss: 0.2946
sum preds 38
sum labels 573
 - Test Metrics: Accuracy=0.7812, F1=0.1178, Recall=0.0628, Precision=0.9474
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_naive_naive_1804091806.csv.
Average F1 over valid seeds: 0.1088 ± 0.0388
___________________________________________________________________________________
Avg F1 for cora with SCAR and naive, GATConv,0.3: 0.1088 ± 0.0388
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2218
Epoch [2/50] - Loss: 0.8816
Epoch [3/50] - Loss: 0.6922
Epoch [4/50] - Loss: 0.6122
Epoch [5/50] - Loss: 0.5969
Epoch [6/50] - Loss: 0.6119
Epoch [7/50] - Loss: 0.6096
Epoch [8/50] - Loss: 0.5950
Epoch [9/50] - Loss: 0.5751
Epoch [10/50] - Loss: 0.5483
Epoch [11/50] - Loss: 0.5268
Epoch [12/50] - Loss: 0.5119
Epoch [13/50] - Loss: 0.4825
Epoch [14/50] - Loss: 0.4776
Epoch [15/50] - Loss: 0.4774
Epoch [16/50] - Loss: 0.4709
Epoch [17/50] - Loss: 0.4664
Epoch [18/50] - Loss: 0.4575
Epoch [19/50] - Loss: 0.4469
Epoch [20/50] - Loss: 0.4381
Epoch [21/50] - Loss: 0.4299
Epoch [22/50] - Loss: 0.4238
Epoch [23/50] - Loss: 0.4170
Epoch [24/50] - Loss: 0.4122
Epoch [25/50] - Loss: 0.4082
Epoch [26/50] - Loss: 0.4063
Epoch [27/50] - Loss: 0.3958
Epoch [28/50] - Loss: 0.3985
Epoch [29/50] - Loss: 0.3927
Epoch [30/50] - Loss: 0.3885
Epoch [31/50] - Loss: 0.3893
Epoch [32/50] - Loss: 0.3832
Epoch [33/50] - Loss: 0.3780
Epoch [34/50] - Loss: 0.3759
Epoch [35/50] - Loss: 0.3686
Epoch [36/50] - Loss: 0.3653
Epoch [37/50] - Loss: 0.3675
Epoch [38/50] - Loss: 0.3628
Epoch [39/50] - Loss: 0.3625
Epoch [40/50] - Loss: 0.3556
Epoch [41/50] - Loss: 0.3541
Epoch [42/50] - Loss: 0.3533
Epoch [43/50] - Loss: 0.3529
Epoch [44/50] - Loss: 0.3497
Epoch [45/50] - Loss: 0.3432
Epoch [46/50] - Loss: 0.3485
Epoch [47/50] - Loss: 0.3416
Epoch [48/50] - Loss: 0.3408
Epoch [49/50] - Loss: 0.3396
Epoch [50/50] - Loss: 0.3367
sum preds 2
sum labels 573
 - Test Metrics: Accuracy=0.7682, F1=0.0070, Recall=0.0035, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3245
Epoch [2/50] - Loss: 1.0429
Epoch [3/50] - Loss: 0.8266
Epoch [4/50] - Loss: 0.6883
Epoch [5/50] - Loss: 0.6255
Epoch [6/50] - Loss: 0.6071
Epoch [7/50] - Loss: 0.5906
Epoch [8/50] - Loss: 0.5992
Epoch [9/50] - Loss: 0.5998
Epoch [10/50] - Loss: 0.5839
Epoch [11/50] - Loss: 0.5662
Epoch [12/50] - Loss: 0.5534
Epoch [13/50] - Loss: 0.5257
Epoch [14/50] - Loss: 0.5125
Epoch [15/50] - Loss: 0.5022
Epoch [16/50] - Loss: 0.4941
Epoch [17/50] - Loss: 0.4761
Epoch [18/50] - Loss: 0.4697
Epoch [19/50] - Loss: 0.4656
Epoch [20/50] - Loss: 0.4588
Epoch [21/50] - Loss: 0.4467
Epoch [22/50] - Loss: 0.4368
Epoch [23/50] - Loss: 0.4295
Epoch [24/50] - Loss: 0.4229
Epoch [25/50] - Loss: 0.4165
Epoch [26/50] - Loss: 0.4155
Epoch [27/50] - Loss: 0.4006
Epoch [28/50] - Loss: 0.4015
Epoch [29/50] - Loss: 0.3993
Epoch [30/50] - Loss: 0.3905
Epoch [31/50] - Loss: 0.3877
Epoch [32/50] - Loss: 0.3813
Epoch [33/50] - Loss: 0.3764
Epoch [34/50] - Loss: 0.3750
Epoch [35/50] - Loss: 0.3719
Epoch [36/50] - Loss: 0.3647
Epoch [37/50] - Loss: 0.3659
Epoch [38/50] - Loss: 0.3584
Epoch [39/50] - Loss: 0.3528
Epoch [40/50] - Loss: 0.3482
Epoch [41/50] - Loss: 0.3492
Epoch [42/50] - Loss: 0.3490
Epoch [43/50] - Loss: 0.3410
Epoch [44/50] - Loss: 0.3461
Epoch [45/50] - Loss: 0.3383
Epoch [46/50] - Loss: 0.3406
Epoch [47/50] - Loss: 0.3362
Epoch [48/50] - Loss: 0.3270
Epoch [49/50] - Loss: 0.3234
Epoch [50/50] - Loss: 0.3224
sum preds 48
sum labels 573
 - Test Metrics: Accuracy=0.7860, F1=0.1514, Recall=0.0820, Precision=0.9792
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4218
Epoch [2/50] - Loss: 1.1517
Epoch [3/50] - Loss: 0.9824
Epoch [4/50] - Loss: 0.8396
Epoch [5/50] - Loss: 0.7283
Epoch [6/50] - Loss: 0.6596
Epoch [7/50] - Loss: 0.6178
Epoch [8/50] - Loss: 0.6057
Epoch [9/50] - Loss: 0.6043
Epoch [10/50] - Loss: 0.6056
Epoch [11/50] - Loss: 0.6109
Epoch [12/50] - Loss: 0.5936
Epoch [13/50] - Loss: 0.5893
Epoch [14/50] - Loss: 0.5769
Epoch [15/50] - Loss: 0.5601
Epoch [16/50] - Loss: 0.5458
Epoch [17/50] - Loss: 0.5271
Epoch [18/50] - Loss: 0.5181
Epoch [19/50] - Loss: 0.5057
Epoch [20/50] - Loss: 0.5028
Epoch [21/50] - Loss: 0.4953
Epoch [22/50] - Loss: 0.4936
Epoch [23/50] - Loss: 0.4885
Epoch [24/50] - Loss: 0.4799
Epoch [25/50] - Loss: 0.4764
Epoch [26/50] - Loss: 0.4698
Epoch [27/50] - Loss: 0.4613
Epoch [28/50] - Loss: 0.4567
Epoch [29/50] - Loss: 0.4427
Epoch [30/50] - Loss: 0.4446
Epoch [31/50] - Loss: 0.4380
Epoch [32/50] - Loss: 0.4359
Epoch [33/50] - Loss: 0.4256
Epoch [34/50] - Loss: 0.4266
Epoch [35/50] - Loss: 0.4198
Epoch [36/50] - Loss: 0.4155
Epoch [37/50] - Loss: 0.4164
Epoch [38/50] - Loss: 0.4096
Epoch [39/50] - Loss: 0.4036
Epoch [40/50] - Loss: 0.4045
Epoch [41/50] - Loss: 0.4034
Epoch [42/50] - Loss: 0.4051
Epoch [43/50] - Loss: 0.3961
Epoch [44/50] - Loss: 0.3966
Epoch [45/50] - Loss: 0.3945
Epoch [46/50] - Loss: 0.3939
Epoch [47/50] - Loss: 0.3912
Epoch [48/50] - Loss: 0.3877
Epoch [49/50] - Loss: 0.3838
Epoch [50/50] - Loss: 0.3807
sum preds 0
sum labels 573
 - Test Metrics: Accuracy=0.7674, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_naive_naive_1804091850.csv.
Average F1 over valid seeds: 0.0528 ± 0.0698
___________________________________________________________________________________
Avg F1 for cora with SCAR and naive, GCNConv,0.3: 0.0528 ± 0.0698
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1949
Epoch [2/50] - Loss: 1.0347
Epoch [3/50] - Loss: 0.8848
Epoch [4/50] - Loss: 0.7451
Epoch [5/50] - Loss: 0.6343
Epoch [6/50] - Loss: 0.5508
Epoch [7/50] - Loss: 0.4992
Epoch [8/50] - Loss: 0.4775
Epoch [9/50] - Loss: 0.4659
Epoch [10/50] - Loss: 0.4691
Epoch [11/50] - Loss: 0.4591
Epoch [12/50] - Loss: 0.4414
Epoch [13/50] - Loss: 0.4293
Epoch [14/50] - Loss: 0.4210
Epoch [15/50] - Loss: 0.4040
Epoch [16/50] - Loss: 0.3957
Epoch [17/50] - Loss: 0.3723
Epoch [18/50] - Loss: 0.3527
Epoch [19/50] - Loss: 0.3465
Epoch [20/50] - Loss: 0.3348
Epoch [21/50] - Loss: 0.3198
Epoch [22/50] - Loss: 0.3144
Epoch [23/50] - Loss: 0.2987
Epoch [24/50] - Loss: 0.2935
Epoch [25/50] - Loss: 0.2826
Epoch [26/50] - Loss: 0.2783
Epoch [27/50] - Loss: 0.2691
Epoch [28/50] - Loss: 0.2580
Epoch [29/50] - Loss: 0.2462
Epoch [30/50] - Loss: 0.2403
Epoch [31/50] - Loss: 0.2323
Epoch [32/50] - Loss: 0.2215
Epoch [33/50] - Loss: 0.2177
Epoch [34/50] - Loss: 0.2094
Epoch [35/50] - Loss: 0.2020
Epoch [36/50] - Loss: 0.1966
Epoch [37/50] - Loss: 0.1875
Epoch [38/50] - Loss: 0.1851
Epoch [39/50] - Loss: 0.1794
Epoch [40/50] - Loss: 0.1758
Epoch [41/50] - Loss: 0.1692
Epoch [42/50] - Loss: 0.1658
Epoch [43/50] - Loss: 0.1633
Epoch [44/50] - Loss: 0.1605
Epoch [45/50] - Loss: 0.1592
Epoch [46/50] - Loss: 0.1566
Epoch [47/50] - Loss: 0.1509
Epoch [48/50] - Loss: 0.1482
Epoch [49/50] - Loss: 0.1451
Epoch [50/50] - Loss: 0.1430
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1831
Epoch [2/50] - Loss: 0.9550
Epoch [3/50] - Loss: 0.7545
Epoch [4/50] - Loss: 0.6126
Epoch [5/50] - Loss: 0.5140
Epoch [6/50] - Loss: 0.4792
Epoch [7/50] - Loss: 0.4684
Epoch [8/50] - Loss: 0.4587
Epoch [9/50] - Loss: 0.4569
Epoch [10/50] - Loss: 0.4469
Epoch [11/50] - Loss: 0.4277
Epoch [12/50] - Loss: 0.4184
Epoch [13/50] - Loss: 0.3956
Epoch [14/50] - Loss: 0.3670
Epoch [15/50] - Loss: 0.3507
Epoch [16/50] - Loss: 0.3365
Epoch [17/50] - Loss: 0.3217
Epoch [18/50] - Loss: 0.3099
Epoch [19/50] - Loss: 0.2987
Epoch [20/50] - Loss: 0.2924
Epoch [21/50] - Loss: 0.2833
Epoch [22/50] - Loss: 0.2759
Epoch [23/50] - Loss: 0.2652
Epoch [24/50] - Loss: 0.2551
Epoch [25/50] - Loss: 0.2479
Epoch [26/50] - Loss: 0.2364
Epoch [27/50] - Loss: 0.2251
Epoch [28/50] - Loss: 0.2204
Epoch [29/50] - Loss: 0.2158
Epoch [30/50] - Loss: 0.2085
Epoch [31/50] - Loss: 0.2034
Epoch [32/50] - Loss: 0.1940
Epoch [33/50] - Loss: 0.1901
Epoch [34/50] - Loss: 0.1845
Epoch [35/50] - Loss: 0.1821
Epoch [36/50] - Loss: 0.1735
Epoch [37/50] - Loss: 0.1711
Epoch [38/50] - Loss: 0.1645
Epoch [39/50] - Loss: 0.1610
Epoch [40/50] - Loss: 0.1551
Epoch [41/50] - Loss: 0.1532
Epoch [42/50] - Loss: 0.1489
Epoch [43/50] - Loss: 0.1477
Epoch [44/50] - Loss: 0.1448
Epoch [45/50] - Loss: 0.1439
Epoch [46/50] - Loss: 0.1410
Epoch [47/50] - Loss: 0.1370
Epoch [48/50] - Loss: 0.1342
Epoch [49/50] - Loss: 0.1336
Epoch [50/50] - Loss: 0.1323
sum preds 1
sum labels 654
 - Test Metrics: Accuracy=0.7433, F1=0.0031, Recall=0.0015, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0523
Epoch [2/50] - Loss: 0.8737
Epoch [3/50] - Loss: 0.7205
Epoch [4/50] - Loss: 0.6000
Epoch [5/50] - Loss: 0.5139
Epoch [6/50] - Loss: 0.4757
Epoch [7/50] - Loss: 0.4593
Epoch [8/50] - Loss: 0.4515
Epoch [9/50] - Loss: 0.4484
Epoch [10/50] - Loss: 0.4333
Epoch [11/50] - Loss: 0.4276
Epoch [12/50] - Loss: 0.4117
Epoch [13/50] - Loss: 0.3888
Epoch [14/50] - Loss: 0.3754
Epoch [15/50] - Loss: 0.3535
Epoch [16/50] - Loss: 0.3429
Epoch [17/50] - Loss: 0.3287
Epoch [18/50] - Loss: 0.3184
Epoch [19/50] - Loss: 0.3079
Epoch [20/50] - Loss: 0.2988
Epoch [21/50] - Loss: 0.2897
Epoch [22/50] - Loss: 0.2809
Epoch [23/50] - Loss: 0.2693
Epoch [24/50] - Loss: 0.2632
Epoch [25/50] - Loss: 0.2556
Epoch [26/50] - Loss: 0.2429
Epoch [27/50] - Loss: 0.2335
Epoch [28/50] - Loss: 0.2262
Epoch [29/50] - Loss: 0.2227
Epoch [30/50] - Loss: 0.2154
Epoch [31/50] - Loss: 0.2081
Epoch [32/50] - Loss: 0.1993
Epoch [33/50] - Loss: 0.1936
Epoch [34/50] - Loss: 0.1851
Epoch [35/50] - Loss: 0.1817
Epoch [36/50] - Loss: 0.1808
Epoch [37/50] - Loss: 0.1757
Epoch [38/50] - Loss: 0.1740
Epoch [39/50] - Loss: 0.1626
Epoch [40/50] - Loss: 0.1589
Epoch [41/50] - Loss: 0.1577
Epoch [42/50] - Loss: 0.1516
Epoch [43/50] - Loss: 0.1510
Epoch [44/50] - Loss: 0.1465
Epoch [45/50] - Loss: 0.1424
Epoch [46/50] - Loss: 0.1405
Epoch [47/50] - Loss: 0.1373
Epoch [48/50] - Loss: 0.1332
Epoch [49/50] - Loss: 0.1309
Epoch [50/50] - Loss: 0.1232
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_naive_naive_1804091934.csv.
Average F1 over valid seeds: 0.0010 ± 0.0014
___________________________________________________________________________________
Avg F1 for cora with SCAR and naive, MLP,0.2: 0.0010 ± 0.0014
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3164
Epoch [2/50] - Loss: 0.8963
Epoch [3/50] - Loss: 0.6387
Epoch [4/50] - Loss: 0.5017
Epoch [5/50] - Loss: 0.4505
Epoch [6/50] - Loss: 0.4538
Epoch [7/50] - Loss: 0.4605
Epoch [8/50] - Loss: 0.4676
Epoch [9/50] - Loss: 0.4756
Epoch [10/50] - Loss: 0.4525
Epoch [11/50] - Loss: 0.4445
Epoch [12/50] - Loss: 0.4214
Epoch [13/50] - Loss: 0.3951
Epoch [14/50] - Loss: 0.3797
Epoch [15/50] - Loss: 0.3713
Epoch [16/50] - Loss: 0.3609
Epoch [17/50] - Loss: 0.3597
Epoch [18/50] - Loss: 0.3492
Epoch [19/50] - Loss: 0.3502
Epoch [20/50] - Loss: 0.3418
Epoch [21/50] - Loss: 0.3331
Epoch [22/50] - Loss: 0.3263
Epoch [23/50] - Loss: 0.3197
Epoch [24/50] - Loss: 0.3163
Epoch [25/50] - Loss: 0.3039
Epoch [26/50] - Loss: 0.3020
Epoch [27/50] - Loss: 0.2959
Epoch [28/50] - Loss: 0.2883
Epoch [29/50] - Loss: 0.2840
Epoch [30/50] - Loss: 0.2757
Epoch [31/50] - Loss: 0.2731
Epoch [32/50] - Loss: 0.2667
Epoch [33/50] - Loss: 0.2643
Epoch [34/50] - Loss: 0.2540
Epoch [35/50] - Loss: 0.2500
Epoch [36/50] - Loss: 0.2453
Epoch [37/50] - Loss: 0.2429
Epoch [38/50] - Loss: 0.2402
Epoch [39/50] - Loss: 0.2394
Epoch [40/50] - Loss: 0.2329
Epoch [41/50] - Loss: 0.2290
Epoch [42/50] - Loss: 0.2186
Epoch [43/50] - Loss: 0.2171
Epoch [44/50] - Loss: 0.2186
Epoch [45/50] - Loss: 0.2149
Epoch [46/50] - Loss: 0.2181
Epoch [47/50] - Loss: 0.2156
Epoch [48/50] - Loss: 0.2129
Epoch [49/50] - Loss: 0.2135
Epoch [50/50] - Loss: 0.1978
sum preds 1
sum labels 654
 - Test Metrics: Accuracy=0.7425, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1583
Epoch [2/50] - Loss: 0.7169
Epoch [3/50] - Loss: 0.4832
Epoch [4/50] - Loss: 0.4374
Epoch [5/50] - Loss: 0.4616
Epoch [6/50] - Loss: 0.4782
Epoch [7/50] - Loss: 0.4660
Epoch [8/50] - Loss: 0.4527
Epoch [9/50] - Loss: 0.4342
Epoch [10/50] - Loss: 0.4069
Epoch [11/50] - Loss: 0.3835
Epoch [12/50] - Loss: 0.3583
Epoch [13/50] - Loss: 0.3490
Epoch [14/50] - Loss: 0.3427
Epoch [15/50] - Loss: 0.3411
Epoch [16/50] - Loss: 0.3422
Epoch [17/50] - Loss: 0.3346
Epoch [18/50] - Loss: 0.3276
Epoch [19/50] - Loss: 0.3171
Epoch [20/50] - Loss: 0.3102
Epoch [21/50] - Loss: 0.2968
Epoch [22/50] - Loss: 0.2817
Epoch [23/50] - Loss: 0.2789
Epoch [24/50] - Loss: 0.2796
Epoch [25/50] - Loss: 0.2754
Epoch [26/50] - Loss: 0.2631
Epoch [27/50] - Loss: 0.2626
Epoch [28/50] - Loss: 0.2556
Epoch [29/50] - Loss: 0.2486
Epoch [30/50] - Loss: 0.2394
Epoch [31/50] - Loss: 0.2329
Epoch [32/50] - Loss: 0.2326
Epoch [33/50] - Loss: 0.2276
Epoch [34/50] - Loss: 0.2292
Epoch [35/50] - Loss: 0.2213
Epoch [36/50] - Loss: 0.2174
Epoch [37/50] - Loss: 0.2101
Epoch [38/50] - Loss: 0.2097
Epoch [39/50] - Loss: 0.1992
Epoch [40/50] - Loss: 0.1934
Epoch [41/50] - Loss: 0.1904
Epoch [42/50] - Loss: 0.1922
Epoch [43/50] - Loss: 0.1966
Epoch [44/50] - Loss: 0.1835
Epoch [45/50] - Loss: 0.1855
Epoch [46/50] - Loss: 0.1778
Epoch [47/50] - Loss: 0.1853
Epoch [48/50] - Loss: 0.1819
Epoch [49/50] - Loss: 0.1716
Epoch [50/50] - Loss: 0.1645
sum preds 31
sum labels 654
 - Test Metrics: Accuracy=0.7543, F1=0.0876, Recall=0.0459, Precision=0.9677
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1925
Epoch [2/50] - Loss: 0.6700
Epoch [3/50] - Loss: 0.4707
Epoch [4/50] - Loss: 0.4566
Epoch [5/50] - Loss: 0.4683
Epoch [6/50] - Loss: 0.4908
Epoch [7/50] - Loss: 0.4803
Epoch [8/50] - Loss: 0.4523
Epoch [9/50] - Loss: 0.4333
Epoch [10/50] - Loss: 0.3921
Epoch [11/50] - Loss: 0.3781
Epoch [12/50] - Loss: 0.3565
Epoch [13/50] - Loss: 0.3559
Epoch [14/50] - Loss: 0.3531
Epoch [15/50] - Loss: 0.3503
Epoch [16/50] - Loss: 0.3501
Epoch [17/50] - Loss: 0.3390
Epoch [18/50] - Loss: 0.3326
Epoch [19/50] - Loss: 0.3227
Epoch [20/50] - Loss: 0.3198
Epoch [21/50] - Loss: 0.3176
Epoch [22/50] - Loss: 0.3101
Epoch [23/50] - Loss: 0.3090
Epoch [24/50] - Loss: 0.3035
Epoch [25/50] - Loss: 0.2990
Epoch [26/50] - Loss: 0.2940
Epoch [27/50] - Loss: 0.2919
Epoch [28/50] - Loss: 0.2927
Epoch [29/50] - Loss: 0.2863
Epoch [30/50] - Loss: 0.2794
Epoch [31/50] - Loss: 0.2821
Epoch [32/50] - Loss: 0.2785
Epoch [33/50] - Loss: 0.2766
Epoch [34/50] - Loss: 0.2713
Epoch [35/50] - Loss: 0.2682
Epoch [36/50] - Loss: 0.2706
Epoch [37/50] - Loss: 0.2612
Epoch [38/50] - Loss: 0.2650
Epoch [39/50] - Loss: 0.2594
Epoch [40/50] - Loss: 0.2577
Epoch [41/50] - Loss: 0.2526
Epoch [42/50] - Loss: 0.2554
Epoch [43/50] - Loss: 0.2510
Epoch [44/50] - Loss: 0.2479
Epoch [45/50] - Loss: 0.2460
Epoch [46/50] - Loss: 0.2399
Epoch [47/50] - Loss: 0.2411
Epoch [48/50] - Loss: 0.2375
Epoch [49/50] - Loss: 0.2330
Epoch [50/50] - Loss: 0.2329
sum preds 6
sum labels 654
 - Test Metrics: Accuracy=0.7453, F1=0.0182, Recall=0.0092, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_naive_naive_1804092013.csv.
Average F1 over valid seeds: 0.0353 ± 0.0377
___________________________________________________________________________________
Avg F1 for cora with SCAR and naive, GATConv,0.2: 0.0353 ± 0.0377
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2099
Epoch [2/50] - Loss: 0.8349
Epoch [3/50] - Loss: 0.6109
Epoch [4/50] - Loss: 0.5010
Epoch [5/50] - Loss: 0.4658
Epoch [6/50] - Loss: 0.4721
Epoch [7/50] - Loss: 0.4807
Epoch [8/50] - Loss: 0.4789
Epoch [9/50] - Loss: 0.4728
Epoch [10/50] - Loss: 0.4628
Epoch [11/50] - Loss: 0.4449
Epoch [12/50] - Loss: 0.4408
Epoch [13/50] - Loss: 0.4040
Epoch [14/50] - Loss: 0.3960
Epoch [15/50] - Loss: 0.3895
Epoch [16/50] - Loss: 0.3798
Epoch [17/50] - Loss: 0.3772
Epoch [18/50] - Loss: 0.3724
Epoch [19/50] - Loss: 0.3676
Epoch [20/50] - Loss: 0.3653
Epoch [21/50] - Loss: 0.3590
Epoch [22/50] - Loss: 0.3517
Epoch [23/50] - Loss: 0.3457
Epoch [24/50] - Loss: 0.3407
Epoch [25/50] - Loss: 0.3361
Epoch [26/50] - Loss: 0.3348
Epoch [27/50] - Loss: 0.3227
Epoch [28/50] - Loss: 0.3236
Epoch [29/50] - Loss: 0.3245
Epoch [30/50] - Loss: 0.3209
Epoch [31/50] - Loss: 0.3197
Epoch [32/50] - Loss: 0.3140
Epoch [33/50] - Loss: 0.3096
Epoch [34/50] - Loss: 0.3067
Epoch [35/50] - Loss: 0.3024
Epoch [36/50] - Loss: 0.2978
Epoch [37/50] - Loss: 0.2993
Epoch [38/50] - Loss: 0.2959
Epoch [39/50] - Loss: 0.2955
Epoch [40/50] - Loss: 0.2869
Epoch [41/50] - Loss: 0.2882
Epoch [42/50] - Loss: 0.2859
Epoch [43/50] - Loss: 0.2870
Epoch [44/50] - Loss: 0.2832
Epoch [45/50] - Loss: 0.2787
Epoch [46/50] - Loss: 0.2799
Epoch [47/50] - Loss: 0.2750
Epoch [48/50] - Loss: 0.2763
Epoch [49/50] - Loss: 0.2731
Epoch [50/50] - Loss: 0.2723
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3205
Epoch [2/50] - Loss: 1.0143
Epoch [3/50] - Loss: 0.7693
Epoch [4/50] - Loss: 0.6013
Epoch [5/50] - Loss: 0.5138
Epoch [6/50] - Loss: 0.4694
Epoch [7/50] - Loss: 0.4541
Epoch [8/50] - Loss: 0.4525
Epoch [9/50] - Loss: 0.4668
Epoch [10/50] - Loss: 0.4600
Epoch [11/50] - Loss: 0.4573
Epoch [12/50] - Loss: 0.4549
Epoch [13/50] - Loss: 0.4359
Epoch [14/50] - Loss: 0.4281
Epoch [15/50] - Loss: 0.4164
Epoch [16/50] - Loss: 0.4093
Epoch [17/50] - Loss: 0.3889
Epoch [18/50] - Loss: 0.3832
Epoch [19/50] - Loss: 0.3776
Epoch [20/50] - Loss: 0.3725
Epoch [21/50] - Loss: 0.3652
Epoch [22/50] - Loss: 0.3590
Epoch [23/50] - Loss: 0.3538
Epoch [24/50] - Loss: 0.3472
Epoch [25/50] - Loss: 0.3388
Epoch [26/50] - Loss: 0.3393
Epoch [27/50] - Loss: 0.3234
Epoch [28/50] - Loss: 0.3263
Epoch [29/50] - Loss: 0.3238
Epoch [30/50] - Loss: 0.3145
Epoch [31/50] - Loss: 0.3112
Epoch [32/50] - Loss: 0.3038
Epoch [33/50] - Loss: 0.3015
Epoch [34/50] - Loss: 0.2990
Epoch [35/50] - Loss: 0.2968
Epoch [36/50] - Loss: 0.2913
Epoch [37/50] - Loss: 0.2900
Epoch [38/50] - Loss: 0.2833
Epoch [39/50] - Loss: 0.2757
Epoch [40/50] - Loss: 0.2729
Epoch [41/50] - Loss: 0.2739
Epoch [42/50] - Loss: 0.2731
Epoch [43/50] - Loss: 0.2655
Epoch [44/50] - Loss: 0.2688
Epoch [45/50] - Loss: 0.2627
Epoch [46/50] - Loss: 0.2646
Epoch [47/50] - Loss: 0.2622
Epoch [48/50] - Loss: 0.2542
Epoch [49/50] - Loss: 0.2548
Epoch [50/50] - Loss: 0.2516
sum preds 1
sum labels 654
 - Test Metrics: Accuracy=0.7433, F1=0.0031, Recall=0.0015, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4234
Epoch [2/50] - Loss: 1.1332
Epoch [3/50] - Loss: 0.9460
Epoch [4/50] - Loss: 0.7855
Epoch [5/50] - Loss: 0.6531
Epoch [6/50] - Loss: 0.5614
Epoch [7/50] - Loss: 0.5002
Epoch [8/50] - Loss: 0.4765
Epoch [9/50] - Loss: 0.4629
Epoch [10/50] - Loss: 0.4662
Epoch [11/50] - Loss: 0.4771
Epoch [12/50] - Loss: 0.4634
Epoch [13/50] - Loss: 0.4695
Epoch [14/50] - Loss: 0.4695
Epoch [15/50] - Loss: 0.4619
Epoch [16/50] - Loss: 0.4541
Epoch [17/50] - Loss: 0.4360
Epoch [18/50] - Loss: 0.4227
Epoch [19/50] - Loss: 0.4135
Epoch [20/50] - Loss: 0.4077
Epoch [21/50] - Loss: 0.4034
Epoch [22/50] - Loss: 0.4000
Epoch [23/50] - Loss: 0.3952
Epoch [24/50] - Loss: 0.3917
Epoch [25/50] - Loss: 0.3928
Epoch [26/50] - Loss: 0.3876
Epoch [27/50] - Loss: 0.3802
Epoch [28/50] - Loss: 0.3796
Epoch [29/50] - Loss: 0.3682
Epoch [30/50] - Loss: 0.3675
Epoch [31/50] - Loss: 0.3615
Epoch [32/50] - Loss: 0.3609
Epoch [33/50] - Loss: 0.3536
Epoch [34/50] - Loss: 0.3562
Epoch [35/50] - Loss: 0.3485
Epoch [36/50] - Loss: 0.3446
Epoch [37/50] - Loss: 0.3452
Epoch [38/50] - Loss: 0.3401
Epoch [39/50] - Loss: 0.3327
Epoch [40/50] - Loss: 0.3369
Epoch [41/50] - Loss: 0.3335
Epoch [42/50] - Loss: 0.3345
Epoch [43/50] - Loss: 0.3266
Epoch [44/50] - Loss: 0.3276
Epoch [45/50] - Loss: 0.3259
Epoch [46/50] - Loss: 0.3257
Epoch [47/50] - Loss: 0.3226
Epoch [48/50] - Loss: 0.3207
Epoch [49/50] - Loss: 0.3153
Epoch [50/50] - Loss: 0.3136
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_naive_naive_1804092057.csv.
Average F1 over valid seeds: 0.0010 ± 0.0014
___________________________________________________________________________________
Avg F1 for cora with SCAR and naive, GCNConv,0.2: 0.0010 ± 0.0014
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8316, F1=0.3458, Recall=0.2159, Precision=0.8689
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8085, F1=0.1648, Recall=0.0916, Precision=0.8182
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8148, F1=0.1938, Recall=0.1079, Precision=0.9464
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_NNIF_NNIF_1804092140.csv.
Average F1 over valid seeds: 0.2348 ± 0.0794
___________________________________________________________________________________
Avg F1 for cora with SCAR and NNIF, MLP,0.4: 0.2348 ± 0.0794
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7933, F1=0.2109, Recall=0.1187, Precision=0.9444
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7812, F1=0.1348, Recall=0.0733, Precision=0.8400
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7864, F1=0.1624, Recall=0.0890, Precision=0.9273
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_NNIF_NNIF_1804092209.csv.
Average F1 over valid seeds: 0.1694 ± 0.0314
___________________________________________________________________________________
Avg F1 for cora with SCAR and NNIF, MLP,0.3: 0.1694 ± 0.0314
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7602, F1=0.1360, Recall=0.0734, Precision=0.9231
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7555, F1=0.1037, Recall=0.0550, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7488, F1=0.0533, Recall=0.0275, Precision=0.8571
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_NNIF_NNIF_1804092219.csv.
Average F1 over valid seeds: 0.0977 ± 0.0340
___________________________________________________________________________________
Avg F1 for cora with SCAR and NNIF, MLP,0.2: 0.0977 ± 0.0340
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2279
Epoch [2/50] - Loss: 1.1027
Epoch [3/50] - Loss: 0.9778
Epoch [4/50] - Loss: 0.8739
Epoch [5/50] - Loss: 0.7923
Epoch [6/50] - Loss: 0.7309
Epoch [7/50] - Loss: 0.7018
Epoch [8/50] - Loss: 0.6654
Epoch [9/50] - Loss: 0.6715
Epoch [10/50] - Loss: 0.6262
Epoch [11/50] - Loss: 0.6112
Epoch [12/50] - Loss: 0.5646
Epoch [13/50] - Loss: 0.5130
Epoch [14/50] - Loss: 0.4775
Epoch [15/50] - Loss: 0.4542
Epoch [16/50] - Loss: 0.4319
Epoch [17/50] - Loss: 0.4153
Epoch [18/50] - Loss: 0.3772
Epoch [19/50] - Loss: 0.3486
Epoch [20/50] - Loss: 0.3245
Epoch [21/50] - Loss: 0.3037
Epoch [22/50] - Loss: 0.2825
Epoch [23/50] - Loss: 0.2623
Epoch [24/50] - Loss: 0.2426
Epoch [25/50] - Loss: 0.2191
Epoch [26/50] - Loss: 0.2006
Epoch [27/50] - Loss: 0.1895
Epoch [28/50] - Loss: 0.1703
Epoch [29/50] - Loss: 0.1618
Epoch [30/50] - Loss: 0.1467
Epoch [31/50] - Loss: 0.1375
Epoch [32/50] - Loss: 0.1232
Epoch [33/50] - Loss: 0.1101
Epoch [34/50] - Loss: 0.1040
Epoch [35/50] - Loss: 0.0951
Epoch [36/50] - Loss: 0.0843
Epoch [37/50] - Loss: 0.0780
Epoch [38/50] - Loss: 0.0716
Epoch [39/50] - Loss: 0.0701
Epoch [40/50] - Loss: 0.0632
Epoch [41/50] - Loss: 0.0576
Epoch [42/50] - Loss: 0.0530
Epoch [43/50] - Loss: 0.0499
Epoch [44/50] - Loss: 0.0451
Epoch [45/50] - Loss: 0.0432
Epoch [46/50] - Loss: 0.0399
Epoch [47/50] - Loss: 0.0355
Epoch [48/50] - Loss: 0.0348
Epoch [49/50] - Loss: 0.0330
Epoch [50/50] - Loss: 0.0298
sum preds 80
sum labels 491
 - Test Metrics: Accuracy=0.8190, F1=0.2452, Recall=0.1426, Precision=0.8750
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2171
Epoch [2/50] - Loss: 1.0378
Epoch [3/50] - Loss: 0.8851
Epoch [4/50] - Loss: 0.7872
Epoch [5/50] - Loss: 0.7366
Epoch [6/50] - Loss: 0.7104
Epoch [7/50] - Loss: 0.6886
Epoch [8/50] - Loss: 0.6736
Epoch [9/50] - Loss: 0.6307
Epoch [10/50] - Loss: 0.5889
Epoch [11/50] - Loss: 0.5540
Epoch [12/50] - Loss: 0.5288
Epoch [13/50] - Loss: 0.5025
Epoch [14/50] - Loss: 0.4917
Epoch [15/50] - Loss: 0.4742
Epoch [16/50] - Loss: 0.4616
Epoch [17/50] - Loss: 0.4440
Epoch [18/50] - Loss: 0.4209
Epoch [19/50] - Loss: 0.4036
Epoch [20/50] - Loss: 0.3818
Epoch [21/50] - Loss: 0.3559
Epoch [22/50] - Loss: 0.3482
Epoch [23/50] - Loss: 0.3192
Epoch [24/50] - Loss: 0.2975
Epoch [25/50] - Loss: 0.2852
Epoch [26/50] - Loss: 0.2689
Epoch [27/50] - Loss: 0.2510
Epoch [28/50] - Loss: 0.2340
Epoch [29/50] - Loss: 0.2187
Epoch [30/50] - Loss: 0.2100
Epoch [31/50] - Loss: 0.1985
Epoch [32/50] - Loss: 0.1842
Epoch [33/50] - Loss: 0.1747
Epoch [34/50] - Loss: 0.1664
Epoch [35/50] - Loss: 0.1564
Epoch [36/50] - Loss: 0.1451
Epoch [37/50] - Loss: 0.1395
Epoch [38/50] - Loss: 0.1315
Epoch [39/50] - Loss: 0.1240
Epoch [40/50] - Loss: 0.1187
Epoch [41/50] - Loss: 0.1101
Epoch [42/50] - Loss: 0.1041
Epoch [43/50] - Loss: 0.0993
Epoch [44/50] - Loss: 0.0946
Epoch [45/50] - Loss: 0.0912
Epoch [46/50] - Loss: 0.0827
Epoch [47/50] - Loss: 0.0815
Epoch [48/50] - Loss: 0.0771
Epoch [49/50] - Loss: 0.0729
Epoch [50/50] - Loss: 0.0705
sum preds 62
sum labels 491
 - Test Metrics: Accuracy=0.8097, F1=0.1808, Recall=0.1018, Precision=0.8065
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1171
Epoch [2/50] - Loss: 0.9780
Epoch [3/50] - Loss: 0.8625
Epoch [4/50] - Loss: 0.7881
Epoch [5/50] - Loss: 0.7333
Epoch [6/50] - Loss: 0.7044
Epoch [7/50] - Loss: 0.6836
Epoch [8/50] - Loss: 0.6553
Epoch [9/50] - Loss: 0.6235
Epoch [10/50] - Loss: 0.5847
Epoch [11/50] - Loss: 0.5617
Epoch [12/50] - Loss: 0.5179
Epoch [13/50] - Loss: 0.5030
Epoch [14/50] - Loss: 0.4834
Epoch [15/50] - Loss: 0.4549
Epoch [16/50] - Loss: 0.4461
Epoch [17/50] - Loss: 0.4084
Epoch [18/50] - Loss: 0.3833
Epoch [19/50] - Loss: 0.3497
Epoch [20/50] - Loss: 0.3253
Epoch [21/50] - Loss: 0.2987
Epoch [22/50] - Loss: 0.2772
Epoch [23/50] - Loss: 0.2581
Epoch [24/50] - Loss: 0.2370
Epoch [25/50] - Loss: 0.2181
Epoch [26/50] - Loss: 0.2006
Epoch [27/50] - Loss: 0.1843
Epoch [28/50] - Loss: 0.1666
Epoch [29/50] - Loss: 0.1550
Epoch [30/50] - Loss: 0.1396
Epoch [31/50] - Loss: 0.1280
Epoch [32/50] - Loss: 0.1178
Epoch [33/50] - Loss: 0.1071
Epoch [34/50] - Loss: 0.0982
Epoch [35/50] - Loss: 0.0880
Epoch [36/50] - Loss: 0.0844
Epoch [37/50] - Loss: 0.0773
Epoch [38/50] - Loss: 0.0702
Epoch [39/50] - Loss: 0.0654
Epoch [40/50] - Loss: 0.0609
Epoch [41/50] - Loss: 0.0577
Epoch [42/50] - Loss: 0.0529
Epoch [43/50] - Loss: 0.0505
Epoch [44/50] - Loss: 0.0454
Epoch [45/50] - Loss: 0.0443
Epoch [46/50] - Loss: 0.0420
Epoch [47/50] - Loss: 0.0401
Epoch [48/50] - Loss: 0.0360
Epoch [49/50] - Loss: 0.0362
Epoch [50/50] - Loss: 0.0337
sum preds 54
sum labels 491
 - Test Metrics: Accuracy=0.8097, F1=0.1688, Recall=0.0937, Precision=0.8519
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_two_nnif_two_nnif_1804092229.csv.
Average F1 over valid seeds: 0.1983 ± 0.0335
___________________________________________________________________________________
Avg F1 for cora with SCAR and two_nnif, MLP,0.4: 0.1983 ± 0.0335
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3309
Epoch [2/50] - Loss: 0.9923
Epoch [3/50] - Loss: 0.7993
Epoch [4/50] - Loss: 0.7359
Epoch [5/50] - Loss: 0.7170
Epoch [6/50] - Loss: 0.7040
Epoch [7/50] - Loss: 0.6861
Epoch [8/50] - Loss: 0.6494
Epoch [9/50] - Loss: 0.6262
Epoch [10/50] - Loss: 0.5790
Epoch [11/50] - Loss: 0.5520
Epoch [12/50] - Loss: 0.5322
Epoch [13/50] - Loss: 0.5252
Epoch [14/50] - Loss: 0.5140
Epoch [15/50] - Loss: 0.5001
Epoch [16/50] - Loss: 0.4923
Epoch [17/50] - Loss: 0.4744
Epoch [18/50] - Loss: 0.4608
Epoch [19/50] - Loss: 0.4565
Epoch [20/50] - Loss: 0.4418
Epoch [21/50] - Loss: 0.4328
Epoch [22/50] - Loss: 0.4296
Epoch [23/50] - Loss: 0.4219
Epoch [24/50] - Loss: 0.4089
Epoch [25/50] - Loss: 0.4037
Epoch [26/50] - Loss: 0.4030
Epoch [27/50] - Loss: 0.3961
Epoch [28/50] - Loss: 0.3745
Epoch [29/50] - Loss: 0.3756
Epoch [30/50] - Loss: 0.3788
Epoch [31/50] - Loss: 0.3674
Epoch [32/50] - Loss: 0.3594
Epoch [33/50] - Loss: 0.3518
Epoch [34/50] - Loss: 0.3438
Epoch [35/50] - Loss: 0.3456
Epoch [36/50] - Loss: 0.3373
Epoch [37/50] - Loss: 0.3336
Epoch [38/50] - Loss: 0.3311
Epoch [39/50] - Loss: 0.3206
Epoch [40/50] - Loss: 0.3268
Epoch [41/50] - Loss: 0.3302
Epoch [42/50] - Loss: 0.3225
Epoch [43/50] - Loss: 0.3071
Epoch [44/50] - Loss: 0.3114
Epoch [45/50] - Loss: 0.3052
Epoch [46/50] - Loss: 0.2976
Epoch [47/50] - Loss: 0.2904
Epoch [48/50] - Loss: 0.2975
Epoch [49/50] - Loss: 0.3009
Epoch [50/50] - Loss: 0.2833
sum preds 198
sum labels 491
 - Test Metrics: Accuracy=0.8627, F1=0.5254, Recall=0.3686, Precision=0.9141
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1864
Epoch [2/50] - Loss: 0.8436
Epoch [3/50] - Loss: 0.7153
Epoch [4/50] - Loss: 0.7145
Epoch [5/50] - Loss: 0.7057
Epoch [6/50] - Loss: 0.6712
Epoch [7/50] - Loss: 0.6319
Epoch [8/50] - Loss: 0.5698
Epoch [9/50] - Loss: 0.5503
Epoch [10/50] - Loss: 0.5301
Epoch [11/50] - Loss: 0.5264
Epoch [12/50] - Loss: 0.5059
Epoch [13/50] - Loss: 0.4876
Epoch [14/50] - Loss: 0.4785
Epoch [15/50] - Loss: 0.4597
Epoch [16/50] - Loss: 0.4505
Epoch [17/50] - Loss: 0.4455
Epoch [18/50] - Loss: 0.4388
Epoch [19/50] - Loss: 0.4200
Epoch [20/50] - Loss: 0.4308
Epoch [21/50] - Loss: 0.4007
Epoch [22/50] - Loss: 0.3983
Epoch [23/50] - Loss: 0.3919
Epoch [24/50] - Loss: 0.3796
Epoch [25/50] - Loss: 0.3689
Epoch [26/50] - Loss: 0.3611
Epoch [27/50] - Loss: 0.3599
Epoch [28/50] - Loss: 0.3500
Epoch [29/50] - Loss: 0.3513
Epoch [30/50] - Loss: 0.3515
Epoch [31/50] - Loss: 0.3392
Epoch [32/50] - Loss: 0.3441
Epoch [33/50] - Loss: 0.3289
Epoch [34/50] - Loss: 0.3208
Epoch [35/50] - Loss: 0.3286
Epoch [36/50] - Loss: 0.3219
Epoch [37/50] - Loss: 0.3023
Epoch [38/50] - Loss: 0.3156
Epoch [39/50] - Loss: 0.3068
Epoch [40/50] - Loss: 0.3020
Epoch [41/50] - Loss: 0.3161
Epoch [42/50] - Loss: 0.3079
Epoch [43/50] - Loss: 0.2956
Epoch [44/50] - Loss: 0.2902
Epoch [45/50] - Loss: 0.2962
Epoch [46/50] - Loss: 0.2836
Epoch [47/50] - Loss: 0.2981
Epoch [48/50] - Loss: 0.2786
Epoch [49/50] - Loss: 0.2829
Epoch [50/50] - Loss: 0.2750
sum preds 127
sum labels 491
 - Test Metrics: Accuracy=0.8412, F1=0.3883, Recall=0.2444, Precision=0.9449
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2276
Epoch [2/50] - Loss: 0.8389
Epoch [3/50] - Loss: 0.7484
Epoch [4/50] - Loss: 0.7353
Epoch [5/50] - Loss: 0.7156
Epoch [6/50] - Loss: 0.6549
Epoch [7/50] - Loss: 0.6109
Epoch [8/50] - Loss: 0.5606
Epoch [9/50] - Loss: 0.5366
Epoch [10/50] - Loss: 0.5302
Epoch [11/50] - Loss: 0.5288
Epoch [12/50] - Loss: 0.5179
Epoch [13/50] - Loss: 0.4991
Epoch [14/50] - Loss: 0.4934
Epoch [15/50] - Loss: 0.4733
Epoch [16/50] - Loss: 0.4785
Epoch [17/50] - Loss: 0.4672
Epoch [18/50] - Loss: 0.4623
Epoch [19/50] - Loss: 0.4537
Epoch [20/50] - Loss: 0.4367
Epoch [21/50] - Loss: 0.4387
Epoch [22/50] - Loss: 0.4405
Epoch [23/50] - Loss: 0.4321
Epoch [24/50] - Loss: 0.4264
Epoch [25/50] - Loss: 0.4207
Epoch [26/50] - Loss: 0.4171
Epoch [27/50] - Loss: 0.4117
Epoch [28/50] - Loss: 0.3945
Epoch [29/50] - Loss: 0.3978
Epoch [30/50] - Loss: 0.3990
Epoch [31/50] - Loss: 0.3911
Epoch [32/50] - Loss: 0.3868
Epoch [33/50] - Loss: 0.3816
Epoch [34/50] - Loss: 0.3688
Epoch [35/50] - Loss: 0.3678
Epoch [36/50] - Loss: 0.3596
Epoch [37/50] - Loss: 0.3506
Epoch [38/50] - Loss: 0.3484
Epoch [39/50] - Loss: 0.3541
Epoch [40/50] - Loss: 0.3369
Epoch [41/50] - Loss: 0.3284
Epoch [42/50] - Loss: 0.3343
Epoch [43/50] - Loss: 0.3302
Epoch [44/50] - Loss: 0.3192
Epoch [45/50] - Loss: 0.3116
Epoch [46/50] - Loss: 0.3069
Epoch [47/50] - Loss: 0.2901
Epoch [48/50] - Loss: 0.2913
Epoch [49/50] - Loss: 0.2847
Epoch [50/50] - Loss: 0.2955
sum preds 113
sum labels 491
 - Test Metrics: Accuracy=0.8362, F1=0.3543, Recall=0.2179, Precision=0.9469
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_two_nnif_two_nnif_1804092311.csv.
Average F1 over valid seeds: 0.4227 ± 0.0739
___________________________________________________________________________________
Avg F1 for cora with SCAR and two_nnif, GATConv,0.4: 0.4227 ± 0.0739
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2385
Epoch [2/50] - Loss: 0.9395
Epoch [3/50] - Loss: 0.7947
Epoch [4/50] - Loss: 0.7185
Epoch [5/50] - Loss: 0.7326
Epoch [6/50] - Loss: 0.7134
Epoch [7/50] - Loss: 0.6898
Epoch [8/50] - Loss: 0.6737
Epoch [9/50] - Loss: 0.6232
Epoch [10/50] - Loss: 0.5949
Epoch [11/50] - Loss: 0.5694
Epoch [12/50] - Loss: 0.5571
Epoch [13/50] - Loss: 0.5433
Epoch [14/50] - Loss: 0.5256
Epoch [15/50] - Loss: 0.5253
Epoch [16/50] - Loss: 0.5184
Epoch [17/50] - Loss: 0.5059
Epoch [18/50] - Loss: 0.4788
Epoch [19/50] - Loss: 0.4795
Epoch [20/50] - Loss: 0.4676
Epoch [21/50] - Loss: 0.4609
Epoch [22/50] - Loss: 0.4617
Epoch [23/50] - Loss: 0.4509
Epoch [24/50] - Loss: 0.4492
Epoch [25/50] - Loss: 0.4435
Epoch [26/50] - Loss: 0.4348
Epoch [27/50] - Loss: 0.4282
Epoch [28/50] - Loss: 0.4334
Epoch [29/50] - Loss: 0.4168
Epoch [30/50] - Loss: 0.4222
Epoch [31/50] - Loss: 0.4194
Epoch [32/50] - Loss: 0.4092
Epoch [33/50] - Loss: 0.4013
Epoch [34/50] - Loss: 0.4040
Epoch [35/50] - Loss: 0.4013
Epoch [36/50] - Loss: 0.3896
Epoch [37/50] - Loss: 0.3859
Epoch [38/50] - Loss: 0.3853
Epoch [39/50] - Loss: 0.3844
Epoch [40/50] - Loss: 0.3777
Epoch [41/50] - Loss: 0.3706
Epoch [42/50] - Loss: 0.3686
Epoch [43/50] - Loss: 0.3569
Epoch [44/50] - Loss: 0.3544
Epoch [45/50] - Loss: 0.3558
Epoch [46/50] - Loss: 0.3418
Epoch [47/50] - Loss: 0.3447
Epoch [48/50] - Loss: 0.3357
Epoch [49/50] - Loss: 0.3342
Epoch [50/50] - Loss: 0.3298
sum preds 145
sum labels 491
 - Test Metrics: Accuracy=0.8471, F1=0.4277, Recall=0.2770, Precision=0.9379
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3318
Epoch [2/50] - Loss: 1.0820
Epoch [3/50] - Loss: 0.8978
Epoch [4/50] - Loss: 0.7959
Epoch [5/50] - Loss: 0.7389
Epoch [6/50] - Loss: 0.7245
Epoch [7/50] - Loss: 0.7248
Epoch [8/50] - Loss: 0.7094
Epoch [9/50] - Loss: 0.6912
Epoch [10/50] - Loss: 0.6709
Epoch [11/50] - Loss: 0.6373
Epoch [12/50] - Loss: 0.6115
Epoch [13/50] - Loss: 0.5908
Epoch [14/50] - Loss: 0.5757
Epoch [15/50] - Loss: 0.5479
Epoch [16/50] - Loss: 0.5437
Epoch [17/50] - Loss: 0.5272
Epoch [18/50] - Loss: 0.5130
Epoch [19/50] - Loss: 0.5162
Epoch [20/50] - Loss: 0.4992
Epoch [21/50] - Loss: 0.4853
Epoch [22/50] - Loss: 0.4844
Epoch [23/50] - Loss: 0.4672
Epoch [24/50] - Loss: 0.4701
Epoch [25/50] - Loss: 0.4471
Epoch [26/50] - Loss: 0.4528
Epoch [27/50] - Loss: 0.4430
Epoch [28/50] - Loss: 0.4462
Epoch [29/50] - Loss: 0.4498
Epoch [30/50] - Loss: 0.4457
Epoch [31/50] - Loss: 0.4230
Epoch [32/50] - Loss: 0.4234
Epoch [33/50] - Loss: 0.4263
Epoch [34/50] - Loss: 0.4153
Epoch [35/50] - Loss: 0.4062
Epoch [36/50] - Loss: 0.3944
Epoch [37/50] - Loss: 0.3923
Epoch [38/50] - Loss: 0.3801
Epoch [39/50] - Loss: 0.3736
Epoch [40/50] - Loss: 0.3771
Epoch [41/50] - Loss: 0.3654
Epoch [42/50] - Loss: 0.3637
Epoch [43/50] - Loss: 0.3542
Epoch [44/50] - Loss: 0.3554
Epoch [45/50] - Loss: 0.3457
Epoch [46/50] - Loss: 0.3421
Epoch [47/50] - Loss: 0.3406
Epoch [48/50] - Loss: 0.3391
Epoch [49/50] - Loss: 0.3320
Epoch [50/50] - Loss: 0.3219
sum preds 120
sum labels 491
 - Test Metrics: Accuracy=0.8391, F1=0.3732, Recall=0.2322, Precision=0.9500
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4204
Epoch [2/50] - Loss: 1.1837
Epoch [3/50] - Loss: 1.0373
Epoch [4/50] - Loss: 0.9169
Epoch [5/50] - Loss: 0.8335
Epoch [6/50] - Loss: 0.7787
Epoch [7/50] - Loss: 0.7590
Epoch [8/50] - Loss: 0.7387
Epoch [9/50] - Loss: 0.7534
Epoch [10/50] - Loss: 0.7312
Epoch [11/50] - Loss: 0.7070
Epoch [12/50] - Loss: 0.7037
Epoch [13/50] - Loss: 0.6933
Epoch [14/50] - Loss: 0.6589
Epoch [15/50] - Loss: 0.6287
Epoch [16/50] - Loss: 0.6242
Epoch [17/50] - Loss: 0.5978
Epoch [18/50] - Loss: 0.5990
Epoch [19/50] - Loss: 0.5812
Epoch [20/50] - Loss: 0.5767
Epoch [21/50] - Loss: 0.5580
Epoch [22/50] - Loss: 0.5468
Epoch [23/50] - Loss: 0.5341
Epoch [24/50] - Loss: 0.5268
Epoch [25/50] - Loss: 0.5207
Epoch [26/50] - Loss: 0.5145
Epoch [27/50] - Loss: 0.4990
Epoch [28/50] - Loss: 0.4827
Epoch [29/50] - Loss: 0.4765
Epoch [30/50] - Loss: 0.4645
Epoch [31/50] - Loss: 0.4600
Epoch [32/50] - Loss: 0.4554
Epoch [33/50] - Loss: 0.4494
Epoch [34/50] - Loss: 0.4483
Epoch [35/50] - Loss: 0.4419
Epoch [36/50] - Loss: 0.4256
Epoch [37/50] - Loss: 0.4290
Epoch [38/50] - Loss: 0.4172
Epoch [39/50] - Loss: 0.4168
Epoch [40/50] - Loss: 0.4117
Epoch [41/50] - Loss: 0.4002
Epoch [42/50] - Loss: 0.4084
Epoch [43/50] - Loss: 0.3942
Epoch [44/50] - Loss: 0.3943
Epoch [45/50] - Loss: 0.3873
Epoch [46/50] - Loss: 0.3777
Epoch [47/50] - Loss: 0.3831
Epoch [48/50] - Loss: 0.3775
Epoch [49/50] - Loss: 0.3805
Epoch [50/50] - Loss: 0.3650
sum preds 140
sum labels 491
 - Test Metrics: Accuracy=0.8459, F1=0.4184, Recall=0.2688, Precision=0.9429
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_two_nnif_two_nnif_1804092357.csv.
Average F1 over valid seeds: 0.4064 ± 0.0238
___________________________________________________________________________________
Avg F1 for cora with SCAR and two_nnif, GCNConv,0.4: 0.4064 ± 0.0238
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2161
Epoch [2/50] - Loss: 1.0799
Epoch [3/50] - Loss: 0.9448
Epoch [4/50] - Loss: 0.8316
Epoch [5/50] - Loss: 0.7446
Epoch [6/50] - Loss: 0.6850
Epoch [7/50] - Loss: 0.6481
Epoch [8/50] - Loss: 0.6214
Epoch [9/50] - Loss: 0.6126
Epoch [10/50] - Loss: 0.5918
Epoch [11/50] - Loss: 0.5875
Epoch [12/50] - Loss: 0.5532
Epoch [13/50] - Loss: 0.5370
Epoch [14/50] - Loss: 0.5078
Epoch [15/50] - Loss: 0.4879
Epoch [16/50] - Loss: 0.4663
Epoch [17/50] - Loss: 0.4404
Epoch [18/50] - Loss: 0.4358
Epoch [19/50] - Loss: 0.4140
Epoch [20/50] - Loss: 0.4012
Epoch [21/50] - Loss: 0.3841
Epoch [22/50] - Loss: 0.3828
Epoch [23/50] - Loss: 0.3616
Epoch [24/50] - Loss: 0.3511
Epoch [25/50] - Loss: 0.3363
Epoch [26/50] - Loss: 0.3123
Epoch [27/50] - Loss: 0.3107
Epoch [28/50] - Loss: 0.2936
Epoch [29/50] - Loss: 0.2795
Epoch [30/50] - Loss: 0.2734
Epoch [31/50] - Loss: 0.2583
Epoch [32/50] - Loss: 0.2423
Epoch [33/50] - Loss: 0.2171
Epoch [34/50] - Loss: 0.2051
Epoch [35/50] - Loss: 0.1793
Epoch [36/50] - Loss: 0.1664
Epoch [37/50] - Loss: 0.1543
Epoch [38/50] - Loss: 0.1366
Epoch [39/50] - Loss: 0.1298
Epoch [40/50] - Loss: 0.1168
Epoch [41/50] - Loss: 0.1049
Epoch [42/50] - Loss: 0.0979
Epoch [43/50] - Loss: 0.0885
Epoch [44/50] - Loss: 0.0846
Epoch [45/50] - Loss: 0.0738
Epoch [46/50] - Loss: 0.0687
Epoch [47/50] - Loss: 0.0630
Epoch [48/50] - Loss: 0.0610
Epoch [49/50] - Loss: 0.0521
Epoch [50/50] - Loss: 0.0505
sum preds 64
sum labels 573
 - Test Metrics: Accuracy=0.7860, F1=0.1727, Recall=0.0960, Precision=0.8594
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2042
Epoch [2/50] - Loss: 1.0065
Epoch [3/50] - Loss: 0.8406
Epoch [4/50] - Loss: 0.7239
Epoch [5/50] - Loss: 0.6619
Epoch [6/50] - Loss: 0.6336
Epoch [7/50] - Loss: 0.6234
Epoch [8/50] - Loss: 0.6183
Epoch [9/50] - Loss: 0.5862
Epoch [10/50] - Loss: 0.5509
Epoch [11/50] - Loss: 0.5154
Epoch [12/50] - Loss: 0.4971
Epoch [13/50] - Loss: 0.4625
Epoch [14/50] - Loss: 0.4531
Epoch [15/50] - Loss: 0.4240
Epoch [16/50] - Loss: 0.4132
Epoch [17/50] - Loss: 0.4196
Epoch [18/50] - Loss: 0.3941
Epoch [19/50] - Loss: 0.3689
Epoch [20/50] - Loss: 0.3566
Epoch [21/50] - Loss: 0.3508
Epoch [22/50] - Loss: 0.3385
Epoch [23/50] - Loss: 0.3270
Epoch [24/50] - Loss: 0.3053
Epoch [25/50] - Loss: 0.3034
Epoch [26/50] - Loss: 0.2926
Epoch [27/50] - Loss: 0.2855
Epoch [28/50] - Loss: 0.2683
Epoch [29/50] - Loss: 0.2623
Epoch [30/50] - Loss: 0.2406
Epoch [31/50] - Loss: 0.2372
Epoch [32/50] - Loss: 0.2185
Epoch [33/50] - Loss: 0.2108
Epoch [34/50] - Loss: 0.1950
Epoch [35/50] - Loss: 0.1862
Epoch [36/50] - Loss: 0.1703
Epoch [37/50] - Loss: 0.1556
Epoch [38/50] - Loss: 0.1469
Epoch [39/50] - Loss: 0.1392
Epoch [40/50] - Loss: 0.1308
Epoch [41/50] - Loss: 0.1169
Epoch [42/50] - Loss: 0.1076
Epoch [43/50] - Loss: 0.1086
Epoch [44/50] - Loss: 0.0982
Epoch [45/50] - Loss: 0.0898
Epoch [46/50] - Loss: 0.0839
Epoch [47/50] - Loss: 0.0827
Epoch [48/50] - Loss: 0.0763
Epoch [49/50] - Loss: 0.0720
Epoch [50/50] - Loss: 0.0658
sum preds 47
sum labels 573
 - Test Metrics: Accuracy=0.7799, F1=0.1258, Recall=0.0681, Precision=0.8298
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0889
Epoch [2/50] - Loss: 0.9410
Epoch [3/50] - Loss: 0.8093
Epoch [4/50] - Loss: 0.7197
Epoch [5/50] - Loss: 0.6491
Epoch [6/50] - Loss: 0.6337
Epoch [7/50] - Loss: 0.6041
Epoch [8/50] - Loss: 0.5738
Epoch [9/50] - Loss: 0.5795
Epoch [10/50] - Loss: 0.5566
Epoch [11/50] - Loss: 0.5280
Epoch [12/50] - Loss: 0.4933
Epoch [13/50] - Loss: 0.4709
Epoch [14/50] - Loss: 0.4492
Epoch [15/50] - Loss: 0.4370
Epoch [16/50] - Loss: 0.4055
Epoch [17/50] - Loss: 0.3972
Epoch [18/50] - Loss: 0.3844
Epoch [19/50] - Loss: 0.3683
Epoch [20/50] - Loss: 0.3588
Epoch [21/50] - Loss: 0.3402
Epoch [22/50] - Loss: 0.3155
Epoch [23/50] - Loss: 0.3089
Epoch [24/50] - Loss: 0.2862
Epoch [25/50] - Loss: 0.2706
Epoch [26/50] - Loss: 0.2581
Epoch [27/50] - Loss: 0.2359
Epoch [28/50] - Loss: 0.2188
Epoch [29/50] - Loss: 0.2025
Epoch [30/50] - Loss: 0.1892
Epoch [31/50] - Loss: 0.1667
Epoch [32/50] - Loss: 0.1583
Epoch [33/50] - Loss: 0.1434
Epoch [34/50] - Loss: 0.1265
Epoch [35/50] - Loss: 0.1218
Epoch [36/50] - Loss: 0.1110
Epoch [37/50] - Loss: 0.1026
Epoch [38/50] - Loss: 0.0939
Epoch [39/50] - Loss: 0.0770
Epoch [40/50] - Loss: 0.0771
Epoch [41/50] - Loss: 0.0703
Epoch [42/50] - Loss: 0.0668
Epoch [43/50] - Loss: 0.0582
Epoch [44/50] - Loss: 0.0543
Epoch [45/50] - Loss: 0.0499
Epoch [46/50] - Loss: 0.0466
Epoch [47/50] - Loss: 0.0433
Epoch [48/50] - Loss: 0.0416
Epoch [49/50] - Loss: 0.0391
Epoch [50/50] - Loss: 0.0370
sum preds 47
sum labels 573
 - Test Metrics: Accuracy=0.7816, F1=0.1323, Recall=0.0716, Precision=0.8723
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_two_nnif_two_nnif_1804092441.csv.
Average F1 over valid seeds: 0.1436 ± 0.0207
___________________________________________________________________________________
Avg F1 for cora with SCAR and two_nnif, MLP,0.3: 0.1436 ± 0.0207
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3246
Epoch [2/50] - Loss: 0.9601
Epoch [3/50] - Loss: 0.7455
Epoch [4/50] - Loss: 0.6551
Epoch [5/50] - Loss: 0.6423
Epoch [6/50] - Loss: 0.6341
Epoch [7/50] - Loss: 0.6245
Epoch [8/50] - Loss: 0.6271
Epoch [9/50] - Loss: 0.5837
Epoch [10/50] - Loss: 0.5470
Epoch [11/50] - Loss: 0.5157
Epoch [12/50] - Loss: 0.4943
Epoch [13/50] - Loss: 0.4876
Epoch [14/50] - Loss: 0.4888
Epoch [15/50] - Loss: 0.4804
Epoch [16/50] - Loss: 0.4768
Epoch [17/50] - Loss: 0.4620
Epoch [18/50] - Loss: 0.4557
Epoch [19/50] - Loss: 0.4442
Epoch [20/50] - Loss: 0.4469
Epoch [21/50] - Loss: 0.4251
Epoch [22/50] - Loss: 0.4113
Epoch [23/50] - Loss: 0.4091
Epoch [24/50] - Loss: 0.3872
Epoch [25/50] - Loss: 0.3804
Epoch [26/50] - Loss: 0.3896
Epoch [27/50] - Loss: 0.3748
Epoch [28/50] - Loss: 0.3736
Epoch [29/50] - Loss: 0.3544
Epoch [30/50] - Loss: 0.3695
Epoch [31/50] - Loss: 0.3521
Epoch [32/50] - Loss: 0.3537
Epoch [33/50] - Loss: 0.3494
Epoch [34/50] - Loss: 0.3353
Epoch [35/50] - Loss: 0.3358
Epoch [36/50] - Loss: 0.3389
Epoch [37/50] - Loss: 0.3224
Epoch [38/50] - Loss: 0.3304
Epoch [39/50] - Loss: 0.3298
Epoch [40/50] - Loss: 0.3198
Epoch [41/50] - Loss: 0.3130
Epoch [42/50] - Loss: 0.3143
Epoch [43/50] - Loss: 0.3155
Epoch [44/50] - Loss: 0.3049
Epoch [45/50] - Loss: 0.3094
Epoch [46/50] - Loss: 0.3072
Epoch [47/50] - Loss: 0.2978
Epoch [48/50] - Loss: 0.3076
Epoch [49/50] - Loss: 0.2875
Epoch [50/50] - Loss: 0.3000
sum preds 86
sum labels 573
 - Test Metrics: Accuracy=0.7958, F1=0.2367, Recall=0.1361, Precision=0.9070
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1714
Epoch [2/50] - Loss: 0.8006
Epoch [3/50] - Loss: 0.6428
Epoch [4/50] - Loss: 0.6378
Epoch [5/50] - Loss: 0.6363
Epoch [6/50] - Loss: 0.6093
Epoch [7/50] - Loss: 0.5923
Epoch [8/50] - Loss: 0.5503
Epoch [9/50] - Loss: 0.5044
Epoch [10/50] - Loss: 0.4772
Epoch [11/50] - Loss: 0.4811
Epoch [12/50] - Loss: 0.4804
Epoch [13/50] - Loss: 0.4587
Epoch [14/50] - Loss: 0.4627
Epoch [15/50] - Loss: 0.4380
Epoch [16/50] - Loss: 0.4210
Epoch [17/50] - Loss: 0.4163
Epoch [18/50] - Loss: 0.4075
Epoch [19/50] - Loss: 0.4057
Epoch [20/50] - Loss: 0.3933
Epoch [21/50] - Loss: 0.3866
Epoch [22/50] - Loss: 0.3699
Epoch [23/50] - Loss: 0.3770
Epoch [24/50] - Loss: 0.3585
Epoch [25/50] - Loss: 0.3583
Epoch [26/50] - Loss: 0.3385
Epoch [27/50] - Loss: 0.3400
Epoch [28/50] - Loss: 0.3317
Epoch [29/50] - Loss: 0.3345
Epoch [30/50] - Loss: 0.3303
Epoch [31/50] - Loss: 0.3263
Epoch [32/50] - Loss: 0.3158
Epoch [33/50] - Loss: 0.2995
Epoch [34/50] - Loss: 0.3074
Epoch [35/50] - Loss: 0.2985
Epoch [36/50] - Loss: 0.3045
Epoch [37/50] - Loss: 0.2838
Epoch [38/50] - Loss: 0.2825
Epoch [39/50] - Loss: 0.2733
Epoch [40/50] - Loss: 0.2777
Epoch [41/50] - Loss: 0.2634
Epoch [42/50] - Loss: 0.2713
Epoch [43/50] - Loss: 0.2657
Epoch [44/50] - Loss: 0.2718
Epoch [45/50] - Loss: 0.2708
Epoch [46/50] - Loss: 0.2570
Epoch [47/50] - Loss: 0.2687
Epoch [48/50] - Loss: 0.2635
Epoch [49/50] - Loss: 0.2464
Epoch [50/50] - Loss: 0.2495
sum preds 98
sum labels 573
 - Test Metrics: Accuracy=0.8039, F1=0.2802, Recall=0.1640, Precision=0.9592
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2174
Epoch [2/50] - Loss: 0.7665
Epoch [3/50] - Loss: 0.6420
Epoch [4/50] - Loss: 0.6476
Epoch [5/50] - Loss: 0.6514
Epoch [6/50] - Loss: 0.6203
Epoch [7/50] - Loss: 0.5840
Epoch [8/50] - Loss: 0.5306
Epoch [9/50] - Loss: 0.4912
Epoch [10/50] - Loss: 0.4829
Epoch [11/50] - Loss: 0.4745
Epoch [12/50] - Loss: 0.4840
Epoch [13/50] - Loss: 0.4593
Epoch [14/50] - Loss: 0.4465
Epoch [15/50] - Loss: 0.4269
Epoch [16/50] - Loss: 0.4314
Epoch [17/50] - Loss: 0.4239
Epoch [18/50] - Loss: 0.4161
Epoch [19/50] - Loss: 0.4137
Epoch [20/50] - Loss: 0.3980
Epoch [21/50] - Loss: 0.3973
Epoch [22/50] - Loss: 0.3867
Epoch [23/50] - Loss: 0.3879
Epoch [24/50] - Loss: 0.3843
Epoch [25/50] - Loss: 0.3777
Epoch [26/50] - Loss: 0.3762
Epoch [27/50] - Loss: 0.3738
Epoch [28/50] - Loss: 0.3649
Epoch [29/50] - Loss: 0.3648
Epoch [30/50] - Loss: 0.3537
Epoch [31/50] - Loss: 0.3571
Epoch [32/50] - Loss: 0.3511
Epoch [33/50] - Loss: 0.3495
Epoch [34/50] - Loss: 0.3388
Epoch [35/50] - Loss: 0.3398
Epoch [36/50] - Loss: 0.3344
Epoch [37/50] - Loss: 0.3213
Epoch [38/50] - Loss: 0.3340
Epoch [39/50] - Loss: 0.3157
Epoch [40/50] - Loss: 0.3142
Epoch [41/50] - Loss: 0.3079
Epoch [42/50] - Loss: 0.3090
Epoch [43/50] - Loss: 0.2984
Epoch [44/50] - Loss: 0.2935
Epoch [45/50] - Loss: 0.2983
Epoch [46/50] - Loss: 0.2879
Epoch [47/50] - Loss: 0.2831
Epoch [48/50] - Loss: 0.2761
Epoch [49/50] - Loss: 0.2908
Epoch [50/50] - Loss: 0.2788
sum preds 64
sum labels 573
 - Test Metrics: Accuracy=0.7925, F1=0.1978, Recall=0.1099, Precision=0.9844
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_two_nnif_two_nnif_1804092520.csv.
Average F1 over valid seeds: 0.2382 ± 0.0336
___________________________________________________________________________________
Avg F1 for cora with SCAR and two_nnif, GATConv,0.3: 0.2382 ± 0.0336
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2294
Epoch [2/50] - Loss: 0.9070
Epoch [3/50] - Loss: 0.7348
Epoch [4/50] - Loss: 0.6592
Epoch [5/50] - Loss: 0.6346
Epoch [6/50] - Loss: 0.6755
Epoch [7/50] - Loss: 0.6445
Epoch [8/50] - Loss: 0.6248
Epoch [9/50] - Loss: 0.5925
Epoch [10/50] - Loss: 0.5809
Epoch [11/50] - Loss: 0.5448
Epoch [12/50] - Loss: 0.5303
Epoch [13/50] - Loss: 0.5018
Epoch [14/50] - Loss: 0.5036
Epoch [15/50] - Loss: 0.5014
Epoch [16/50] - Loss: 0.4868
Epoch [17/50] - Loss: 0.4799
Epoch [18/50] - Loss: 0.4740
Epoch [19/50] - Loss: 0.4480
Epoch [20/50] - Loss: 0.4457
Epoch [21/50] - Loss: 0.4373
Epoch [22/50] - Loss: 0.4437
Epoch [23/50] - Loss: 0.4396
Epoch [24/50] - Loss: 0.4315
Epoch [25/50] - Loss: 0.4234
Epoch [26/50] - Loss: 0.4155
Epoch [27/50] - Loss: 0.4025
Epoch [28/50] - Loss: 0.4132
Epoch [29/50] - Loss: 0.4015
Epoch [30/50] - Loss: 0.3940
Epoch [31/50] - Loss: 0.3853
Epoch [32/50] - Loss: 0.3900
Epoch [33/50] - Loss: 0.3896
Epoch [34/50] - Loss: 0.3923
Epoch [35/50] - Loss: 0.3841
Epoch [36/50] - Loss: 0.3765
Epoch [37/50] - Loss: 0.3687
Epoch [38/50] - Loss: 0.3690
Epoch [39/50] - Loss: 0.3724
Epoch [40/50] - Loss: 0.3652
Epoch [41/50] - Loss: 0.3628
Epoch [42/50] - Loss: 0.3603
Epoch [43/50] - Loss: 0.3616
Epoch [44/50] - Loss: 0.3475
Epoch [45/50] - Loss: 0.3514
Epoch [46/50] - Loss: 0.3583
Epoch [47/50] - Loss: 0.3486
Epoch [48/50] - Loss: 0.3359
Epoch [49/50] - Loss: 0.3396
Epoch [50/50] - Loss: 0.3416
sum preds 37
sum labels 573
 - Test Metrics: Accuracy=0.7824, F1=0.1213, Recall=0.0646, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3285
Epoch [2/50] - Loss: 1.0652
Epoch [3/50] - Loss: 0.8560
Epoch [4/50] - Loss: 0.7190
Epoch [5/50] - Loss: 0.6584
Epoch [6/50] - Loss: 0.6378
Epoch [7/50] - Loss: 0.6419
Epoch [8/50] - Loss: 0.6503
Epoch [9/50] - Loss: 0.6348
Epoch [10/50] - Loss: 0.6324
Epoch [11/50] - Loss: 0.5762
Epoch [12/50] - Loss: 0.5790
Epoch [13/50] - Loss: 0.5529
Epoch [14/50] - Loss: 0.5350
Epoch [15/50] - Loss: 0.5276
Epoch [16/50] - Loss: 0.5080
Epoch [17/50] - Loss: 0.4955
Epoch [18/50] - Loss: 0.4874
Epoch [19/50] - Loss: 0.4726
Epoch [20/50] - Loss: 0.4567
Epoch [21/50] - Loss: 0.4634
Epoch [22/50] - Loss: 0.4488
Epoch [23/50] - Loss: 0.4481
Epoch [24/50] - Loss: 0.4310
Epoch [25/50] - Loss: 0.4330
Epoch [26/50] - Loss: 0.4200
Epoch [27/50] - Loss: 0.4141
Epoch [28/50] - Loss: 0.4164
Epoch [29/50] - Loss: 0.4121
Epoch [30/50] - Loss: 0.3967
Epoch [31/50] - Loss: 0.4146
Epoch [32/50] - Loss: 0.3954
Epoch [33/50] - Loss: 0.3945
Epoch [34/50] - Loss: 0.3875
Epoch [35/50] - Loss: 0.3853
Epoch [36/50] - Loss: 0.3729
Epoch [37/50] - Loss: 0.3657
Epoch [38/50] - Loss: 0.3720
Epoch [39/50] - Loss: 0.3567
Epoch [40/50] - Loss: 0.3569
Epoch [41/50] - Loss: 0.3583
Epoch [42/50] - Loss: 0.3536
Epoch [43/50] - Loss: 0.3510
Epoch [44/50] - Loss: 0.3382
Epoch [45/50] - Loss: 0.3306
Epoch [46/50] - Loss: 0.3262
Epoch [47/50] - Loss: 0.3163
Epoch [48/50] - Loss: 0.3138
Epoch [49/50] - Loss: 0.3084
Epoch [50/50] - Loss: 0.3088
sum preds 81
sum labels 573
 - Test Metrics: Accuracy=0.7994, F1=0.2446, Recall=0.1396, Precision=0.9877
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4224
Epoch [2/50] - Loss: 1.1658
Epoch [3/50] - Loss: 1.0039
Epoch [4/50] - Loss: 0.8674
Epoch [5/50] - Loss: 0.7683
Epoch [6/50] - Loss: 0.6971
Epoch [7/50] - Loss: 0.6663
Epoch [8/50] - Loss: 0.6421
Epoch [9/50] - Loss: 0.6583
Epoch [10/50] - Loss: 0.6505
Epoch [11/50] - Loss: 0.6286
Epoch [12/50] - Loss: 0.6314
Epoch [13/50] - Loss: 0.6297
Epoch [14/50] - Loss: 0.6195
Epoch [15/50] - Loss: 0.5891
Epoch [16/50] - Loss: 0.5666
Epoch [17/50] - Loss: 0.5520
Epoch [18/50] - Loss: 0.5461
Epoch [19/50] - Loss: 0.5299
Epoch [20/50] - Loss: 0.5132
Epoch [21/50] - Loss: 0.5259
Epoch [22/50] - Loss: 0.5073
Epoch [23/50] - Loss: 0.4981
Epoch [24/50] - Loss: 0.4899
Epoch [25/50] - Loss: 0.4952
Epoch [26/50] - Loss: 0.4752
Epoch [27/50] - Loss: 0.4727
Epoch [28/50] - Loss: 0.4559
Epoch [29/50] - Loss: 0.4642
Epoch [30/50] - Loss: 0.4460
Epoch [31/50] - Loss: 0.4503
Epoch [32/50] - Loss: 0.4342
Epoch [33/50] - Loss: 0.4220
Epoch [34/50] - Loss: 0.4381
Epoch [35/50] - Loss: 0.4349
Epoch [36/50] - Loss: 0.4149
Epoch [37/50] - Loss: 0.4109
Epoch [38/50] - Loss: 0.4146
Epoch [39/50] - Loss: 0.4171
Epoch [40/50] - Loss: 0.4097
Epoch [41/50] - Loss: 0.4022
Epoch [42/50] - Loss: 0.4169
Epoch [43/50] - Loss: 0.4038
Epoch [44/50] - Loss: 0.3944
Epoch [45/50] - Loss: 0.3909
Epoch [46/50] - Loss: 0.3916
Epoch [47/50] - Loss: 0.3960
Epoch [48/50] - Loss: 0.4003
Epoch [49/50] - Loss: 0.3822
Epoch [50/50] - Loss: 0.3785
sum preds 19
sum labels 573
 - Test Metrics: Accuracy=0.7751, F1=0.0642, Recall=0.0332, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_two_nnif_two_nnif_1804092605.csv.
Average F1 over valid seeds: 0.1434 ± 0.0753
___________________________________________________________________________________
Avg F1 for cora with SCAR and two_nnif, GCNConv,0.3: 0.1434 ± 0.0753
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1999
Epoch [2/50] - Loss: 1.0544
Epoch [3/50] - Loss: 0.9054
Epoch [4/50] - Loss: 0.7713
Epoch [5/50] - Loss: 0.6617
Epoch [6/50] - Loss: 0.5951
Epoch [7/50] - Loss: 0.5577
Epoch [8/50] - Loss: 0.5038
Epoch [9/50] - Loss: 0.4989
Epoch [10/50] - Loss: 0.5096
Epoch [11/50] - Loss: 0.5097
Epoch [12/50] - Loss: 0.4771
Epoch [13/50] - Loss: 0.4483
Epoch [14/50] - Loss: 0.4273
Epoch [15/50] - Loss: 0.4196
Epoch [16/50] - Loss: 0.4044
Epoch [17/50] - Loss: 0.3722
Epoch [18/50] - Loss: 0.3679
Epoch [19/50] - Loss: 0.3498
Epoch [20/50] - Loss: 0.3318
Epoch [21/50] - Loss: 0.3221
Epoch [22/50] - Loss: 0.3152
Epoch [23/50] - Loss: 0.3044
Epoch [24/50] - Loss: 0.2881
Epoch [25/50] - Loss: 0.2793
Epoch [26/50] - Loss: 0.2743
Epoch [27/50] - Loss: 0.2596
Epoch [28/50] - Loss: 0.2416
Epoch [29/50] - Loss: 0.2352
Epoch [30/50] - Loss: 0.2206
Epoch [31/50] - Loss: 0.2225
Epoch [32/50] - Loss: 0.2181
Epoch [33/50] - Loss: 0.2086
Epoch [34/50] - Loss: 0.2003
Epoch [35/50] - Loss: 0.1848
Epoch [36/50] - Loss: 0.1839
Epoch [37/50] - Loss: 0.1760
Epoch [38/50] - Loss: 0.1635
Epoch [39/50] - Loss: 0.1632
Epoch [40/50] - Loss: 0.1491
Epoch [41/50] - Loss: 0.1403
Epoch [42/50] - Loss: 0.1464
Epoch [43/50] - Loss: 0.1452
Epoch [44/50] - Loss: 0.1307
Epoch [45/50] - Loss: 0.1238
Epoch [46/50] - Loss: 0.1201
Epoch [47/50] - Loss: 0.1064
Epoch [48/50] - Loss: 0.1047
Epoch [49/50] - Loss: 0.0960
Epoch [50/50] - Loss: 0.0924
sum preds 29
sum labels 654
 - Test Metrics: Accuracy=0.7520, F1=0.0761, Recall=0.0398, Precision=0.8966
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1906
Epoch [2/50] - Loss: 0.9777
Epoch [3/50] - Loss: 0.7819
Epoch [4/50] - Loss: 0.6551
Epoch [5/50] - Loss: 0.5555
Epoch [6/50] - Loss: 0.5202
Epoch [7/50] - Loss: 0.5085
Epoch [8/50] - Loss: 0.4789
Epoch [9/50] - Loss: 0.4808
Epoch [10/50] - Loss: 0.4896
Epoch [11/50] - Loss: 0.4734
Epoch [12/50] - Loss: 0.4198
Epoch [13/50] - Loss: 0.4158
Epoch [14/50] - Loss: 0.3847
Epoch [15/50] - Loss: 0.3556
Epoch [16/50] - Loss: 0.3440
Epoch [17/50] - Loss: 0.3215
Epoch [18/50] - Loss: 0.3152
Epoch [19/50] - Loss: 0.3111
Epoch [20/50] - Loss: 0.3015
Epoch [21/50] - Loss: 0.2925
Epoch [22/50] - Loss: 0.2777
Epoch [23/50] - Loss: 0.2682
Epoch [24/50] - Loss: 0.2532
Epoch [25/50] - Loss: 0.2494
Epoch [26/50] - Loss: 0.2320
Epoch [27/50] - Loss: 0.2265
Epoch [28/50] - Loss: 0.2152
Epoch [29/50] - Loss: 0.2152
Epoch [30/50] - Loss: 0.2026
Epoch [31/50] - Loss: 0.1916
Epoch [32/50] - Loss: 0.1893
Epoch [33/50] - Loss: 0.1740
Epoch [34/50] - Loss: 0.1711
Epoch [35/50] - Loss: 0.1632
Epoch [36/50] - Loss: 0.1602
Epoch [37/50] - Loss: 0.1535
Epoch [38/50] - Loss: 0.1452
Epoch [39/50] - Loss: 0.1437
Epoch [40/50] - Loss: 0.1326
Epoch [41/50] - Loss: 0.1277
Epoch [42/50] - Loss: 0.1225
Epoch [43/50] - Loss: 0.1183
Epoch [44/50] - Loss: 0.1120
Epoch [45/50] - Loss: 0.1097
Epoch [46/50] - Loss: 0.1061
Epoch [47/50] - Loss: 0.1017
Epoch [48/50] - Loss: 0.0979
Epoch [49/50] - Loss: 0.0941
Epoch [50/50] - Loss: 0.0916
sum preds 31
sum labels 654
 - Test Metrics: Accuracy=0.7496, F1=0.0701, Recall=0.0367, Precision=0.7742
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.0628
Epoch [2/50] - Loss: 0.8980
Epoch [3/50] - Loss: 0.7508
Epoch [4/50] - Loss: 0.6341
Epoch [5/50] - Loss: 0.5624
Epoch [6/50] - Loss: 0.5260
Epoch [7/50] - Loss: 0.4865
Epoch [8/50] - Loss: 0.5001
Epoch [9/50] - Loss: 0.4934
Epoch [10/50] - Loss: 0.4740
Epoch [11/50] - Loss: 0.4855
Epoch [12/50] - Loss: 0.4431
Epoch [13/50] - Loss: 0.4167
Epoch [14/50] - Loss: 0.3995
Epoch [15/50] - Loss: 0.3757
Epoch [16/50] - Loss: 0.3557
Epoch [17/50] - Loss: 0.3433
Epoch [18/50] - Loss: 0.3319
Epoch [19/50] - Loss: 0.3323
Epoch [20/50] - Loss: 0.3065
Epoch [21/50] - Loss: 0.3073
Epoch [22/50] - Loss: 0.2954
Epoch [23/50] - Loss: 0.2806
Epoch [24/50] - Loss: 0.2613
Epoch [25/50] - Loss: 0.2487
Epoch [26/50] - Loss: 0.2556
Epoch [27/50] - Loss: 0.2436
Epoch [28/50] - Loss: 0.2409
Epoch [29/50] - Loss: 0.2268
Epoch [30/50] - Loss: 0.2162
Epoch [31/50] - Loss: 0.2144
Epoch [32/50] - Loss: 0.2155
Epoch [33/50] - Loss: 0.2109
Epoch [34/50] - Loss: 0.1954
Epoch [35/50] - Loss: 0.1869
Epoch [36/50] - Loss: 0.1846
Epoch [37/50] - Loss: 0.1782
Epoch [38/50] - Loss: 0.1667
Epoch [39/50] - Loss: 0.1584
Epoch [40/50] - Loss: 0.1603
Epoch [41/50] - Loss: 0.1506
Epoch [42/50] - Loss: 0.1391
Epoch [43/50] - Loss: 0.1328
Epoch [44/50] - Loss: 0.1189
Epoch [45/50] - Loss: 0.1141
Epoch [46/50] - Loss: 0.1010
Epoch [47/50] - Loss: 0.0973
Epoch [48/50] - Loss: 0.0837
Epoch [49/50] - Loss: 0.0790
Epoch [50/50] - Loss: 0.0735
sum preds 22
sum labels 654
 - Test Metrics: Accuracy=0.7484, F1=0.0533, Recall=0.0275, Precision=0.8182
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_two_nnif_two_nnif_1804092649.csv.
Average F1 over valid seeds: 0.0665 ± 0.0097
___________________________________________________________________________________
Avg F1 for cora with SCAR and two_nnif, MLP,0.2: 0.0665 ± 0.0097
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3190
Epoch [2/50] - Loss: 0.9136
Epoch [3/50] - Loss: 0.6645
Epoch [4/50] - Loss: 0.5562
Epoch [5/50] - Loss: 0.4888
Epoch [6/50] - Loss: 0.4931
Epoch [7/50] - Loss: 0.5240
Epoch [8/50] - Loss: 0.5083
Epoch [9/50] - Loss: 0.5083
Epoch [10/50] - Loss: 0.4928
Epoch [11/50] - Loss: 0.4776
Epoch [12/50] - Loss: 0.4610
Epoch [13/50] - Loss: 0.4282
Epoch [14/50] - Loss: 0.4039
Epoch [15/50] - Loss: 0.3880
Epoch [16/50] - Loss: 0.3889
Epoch [17/50] - Loss: 0.3885
Epoch [18/50] - Loss: 0.3801
Epoch [19/50] - Loss: 0.3822
Epoch [20/50] - Loss: 0.3689
Epoch [21/50] - Loss: 0.3628
Epoch [22/50] - Loss: 0.3551
Epoch [23/50] - Loss: 0.3499
Epoch [24/50] - Loss: 0.3356
Epoch [25/50] - Loss: 0.3271
Epoch [26/50] - Loss: 0.3319
Epoch [27/50] - Loss: 0.3091
Epoch [28/50] - Loss: 0.3114
Epoch [29/50] - Loss: 0.3103
Epoch [30/50] - Loss: 0.2937
Epoch [31/50] - Loss: 0.2969
Epoch [32/50] - Loss: 0.2968
Epoch [33/50] - Loss: 0.2886
Epoch [34/50] - Loss: 0.2754
Epoch [35/50] - Loss: 0.2705
Epoch [36/50] - Loss: 0.2769
Epoch [37/50] - Loss: 0.2707
Epoch [38/50] - Loss: 0.2645
Epoch [39/50] - Loss: 0.2682
Epoch [40/50] - Loss: 0.2580
Epoch [41/50] - Loss: 0.2628
Epoch [42/50] - Loss: 0.2644
Epoch [43/50] - Loss: 0.2389
Epoch [44/50] - Loss: 0.2528
Epoch [45/50] - Loss: 0.2430
Epoch [46/50] - Loss: 0.2467
Epoch [47/50] - Loss: 0.2491
Epoch [48/50] - Loss: 0.2522
Epoch [49/50] - Loss: 0.2374
Epoch [50/50] - Loss: 0.2326
sum preds 33
sum labels 654
 - Test Metrics: Accuracy=0.7543, F1=0.0902, Recall=0.0474, Precision=0.9394
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1593
Epoch [2/50] - Loss: 0.7387
Epoch [3/50] - Loss: 0.5363
Epoch [4/50] - Loss: 0.4824
Epoch [5/50] - Loss: 0.5072
Epoch [6/50] - Loss: 0.5169
Epoch [7/50] - Loss: 0.5027
Epoch [8/50] - Loss: 0.4793
Epoch [9/50] - Loss: 0.4644
Epoch [10/50] - Loss: 0.4308
Epoch [11/50] - Loss: 0.3918
Epoch [12/50] - Loss: 0.3724
Epoch [13/50] - Loss: 0.3726
Epoch [14/50] - Loss: 0.3715
Epoch [15/50] - Loss: 0.3555
Epoch [16/50] - Loss: 0.3558
Epoch [17/50] - Loss: 0.3546
Epoch [18/50] - Loss: 0.3467
Epoch [19/50] - Loss: 0.3269
Epoch [20/50] - Loss: 0.3173
Epoch [21/50] - Loss: 0.3230
Epoch [22/50] - Loss: 0.3088
Epoch [23/50] - Loss: 0.2998
Epoch [24/50] - Loss: 0.2918
Epoch [25/50] - Loss: 0.2978
Epoch [26/50] - Loss: 0.2878
Epoch [27/50] - Loss: 0.2817
Epoch [28/50] - Loss: 0.2735
Epoch [29/50] - Loss: 0.2773
Epoch [30/50] - Loss: 0.2561
Epoch [31/50] - Loss: 0.2636
Epoch [32/50] - Loss: 0.2630
Epoch [33/50] - Loss: 0.2422
Epoch [34/50] - Loss: 0.2432
Epoch [35/50] - Loss: 0.2414
Epoch [36/50] - Loss: 0.2345
Epoch [37/50] - Loss: 0.2349
Epoch [38/50] - Loss: 0.2188
Epoch [39/50] - Loss: 0.2204
Epoch [40/50] - Loss: 0.2535
Epoch [41/50] - Loss: 0.2266
Epoch [42/50] - Loss: 0.2167
Epoch [43/50] - Loss: 0.2082
Epoch [44/50] - Loss: 0.2055
Epoch [45/50] - Loss: 0.2182
Epoch [46/50] - Loss: 0.1931
Epoch [47/50] - Loss: 0.2035
Epoch [48/50] - Loss: 0.1835
Epoch [49/50] - Loss: 0.2110
Epoch [50/50] - Loss: 0.2035
sum preds 63
sum labels 654
 - Test Metrics: Accuracy=0.7653, F1=0.1674, Recall=0.0917, Precision=0.9524
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1966
Epoch [2/50] - Loss: 0.6975
Epoch [3/50] - Loss: 0.5094
Epoch [4/50] - Loss: 0.5132
Epoch [5/50] - Loss: 0.5529
Epoch [6/50] - Loss: 0.5483
Epoch [7/50] - Loss: 0.5215
Epoch [8/50] - Loss: 0.4782
Epoch [9/50] - Loss: 0.4474
Epoch [10/50] - Loss: 0.4108
Epoch [11/50] - Loss: 0.3948
Epoch [12/50] - Loss: 0.3854
Epoch [13/50] - Loss: 0.3923
Epoch [14/50] - Loss: 0.3978
Epoch [15/50] - Loss: 0.3822
Epoch [16/50] - Loss: 0.3847
Epoch [17/50] - Loss: 0.3642
Epoch [18/50] - Loss: 0.3565
Epoch [19/50] - Loss: 0.3539
Epoch [20/50] - Loss: 0.3507
Epoch [21/50] - Loss: 0.3471
Epoch [22/50] - Loss: 0.3359
Epoch [23/50] - Loss: 0.3350
Epoch [24/50] - Loss: 0.3291
Epoch [25/50] - Loss: 0.3241
Epoch [26/50] - Loss: 0.3330
Epoch [27/50] - Loss: 0.3166
Epoch [28/50] - Loss: 0.3085
Epoch [29/50] - Loss: 0.3098
Epoch [30/50] - Loss: 0.3106
Epoch [31/50] - Loss: 0.3104
Epoch [32/50] - Loss: 0.3048
Epoch [33/50] - Loss: 0.2834
Epoch [34/50] - Loss: 0.2843
Epoch [35/50] - Loss: 0.2932
Epoch [36/50] - Loss: 0.2881
Epoch [37/50] - Loss: 0.2943
Epoch [38/50] - Loss: 0.2878
Epoch [39/50] - Loss: 0.2818
Epoch [40/50] - Loss: 0.2918
Epoch [41/50] - Loss: 0.2854
Epoch [42/50] - Loss: 0.2850
Epoch [43/50] - Loss: 0.2631
Epoch [44/50] - Loss: 0.2764
Epoch [45/50] - Loss: 0.2707
Epoch [46/50] - Loss: 0.2681
Epoch [47/50] - Loss: 0.2798
Epoch [48/50] - Loss: 0.2619
Epoch [49/50] - Loss: 0.2593
Epoch [50/50] - Loss: 0.2520
sum preds 19
sum labels 654
 - Test Metrics: Accuracy=0.7496, F1=0.0535, Recall=0.0275, Precision=0.9474
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_two_nnif_two_nnif_1804092727.csv.
Average F1 over valid seeds: 0.1037 ± 0.0475
___________________________________________________________________________________
Avg F1 for cora with SCAR and two_nnif, GATConv,0.2: 0.1037 ± 0.0475
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2144
Epoch [2/50] - Loss: 0.8661
Epoch [3/50] - Loss: 0.6596
Epoch [4/50] - Loss: 0.5644
Epoch [5/50] - Loss: 0.5208
Epoch [6/50] - Loss: 0.5004
Epoch [7/50] - Loss: 0.5221
Epoch [8/50] - Loss: 0.5016
Epoch [9/50] - Loss: 0.5282
Epoch [10/50] - Loss: 0.4986
Epoch [11/50] - Loss: 0.4778
Epoch [12/50] - Loss: 0.4602
Epoch [13/50] - Loss: 0.4347
Epoch [14/50] - Loss: 0.4284
Epoch [15/50] - Loss: 0.4160
Epoch [16/50] - Loss: 0.4016
Epoch [17/50] - Loss: 0.3985
Epoch [18/50] - Loss: 0.4081
Epoch [19/50] - Loss: 0.3981
Epoch [20/50] - Loss: 0.3955
Epoch [21/50] - Loss: 0.3781
Epoch [22/50] - Loss: 0.3664
Epoch [23/50] - Loss: 0.3643
Epoch [24/50] - Loss: 0.3416
Epoch [25/50] - Loss: 0.3611
Epoch [26/50] - Loss: 0.3517
Epoch [27/50] - Loss: 0.3401
Epoch [28/50] - Loss: 0.3379
Epoch [29/50] - Loss: 0.3307
Epoch [30/50] - Loss: 0.3277
Epoch [31/50] - Loss: 0.3357
Epoch [32/50] - Loss: 0.3293
Epoch [33/50] - Loss: 0.3323
Epoch [34/50] - Loss: 0.3248
Epoch [35/50] - Loss: 0.3043
Epoch [36/50] - Loss: 0.3121
Epoch [37/50] - Loss: 0.3097
Epoch [38/50] - Loss: 0.3130
Epoch [39/50] - Loss: 0.3024
Epoch [40/50] - Loss: 0.3064
Epoch [41/50] - Loss: 0.3063
Epoch [42/50] - Loss: 0.2989
Epoch [43/50] - Loss: 0.2972
Epoch [44/50] - Loss: 0.3005
Epoch [45/50] - Loss: 0.2979
Epoch [46/50] - Loss: 0.2878
Epoch [47/50] - Loss: 0.2946
Epoch [48/50] - Loss: 0.2952
Epoch [49/50] - Loss: 0.2880
Epoch [50/50] - Loss: 0.2877
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3274
Epoch [2/50] - Loss: 1.0314
Epoch [3/50] - Loss: 0.7987
Epoch [4/50] - Loss: 0.6260
Epoch [5/50] - Loss: 0.5374
Epoch [6/50] - Loss: 0.5230
Epoch [7/50] - Loss: 0.5039
Epoch [8/50] - Loss: 0.5162
Epoch [9/50] - Loss: 0.5129
Epoch [10/50] - Loss: 0.5329
Epoch [11/50] - Loss: 0.5143
Epoch [12/50] - Loss: 0.5009
Epoch [13/50] - Loss: 0.4837
Epoch [14/50] - Loss: 0.4581
Epoch [15/50] - Loss: 0.4423
Epoch [16/50] - Loss: 0.4496
Epoch [17/50] - Loss: 0.4243
Epoch [18/50] - Loss: 0.3996
Epoch [19/50] - Loss: 0.3966
Epoch [20/50] - Loss: 0.3950
Epoch [21/50] - Loss: 0.3860
Epoch [22/50] - Loss: 0.3792
Epoch [23/50] - Loss: 0.3806
Epoch [24/50] - Loss: 0.3577
Epoch [25/50] - Loss: 0.3506
Epoch [26/50] - Loss: 0.3465
Epoch [27/50] - Loss: 0.3433
Epoch [28/50] - Loss: 0.3342
Epoch [29/50] - Loss: 0.3359
Epoch [30/50] - Loss: 0.3398
Epoch [31/50] - Loss: 0.3225
Epoch [32/50] - Loss: 0.3259
Epoch [33/50] - Loss: 0.3298
Epoch [34/50] - Loss: 0.3083
Epoch [35/50] - Loss: 0.3160
Epoch [36/50] - Loss: 0.3067
Epoch [37/50] - Loss: 0.3053
Epoch [38/50] - Loss: 0.3070
Epoch [39/50] - Loss: 0.3019
Epoch [40/50] - Loss: 0.2862
Epoch [41/50] - Loss: 0.2965
Epoch [42/50] - Loss: 0.2841
Epoch [43/50] - Loss: 0.2789
Epoch [44/50] - Loss: 0.2866
Epoch [45/50] - Loss: 0.2869
Epoch [46/50] - Loss: 0.2762
Epoch [47/50] - Loss: 0.2584
Epoch [48/50] - Loss: 0.2729
Epoch [49/50] - Loss: 0.2751
Epoch [50/50] - Loss: 0.2666
sum preds 28
sum labels 654
 - Test Metrics: Accuracy=0.7539, F1=0.0821, Recall=0.0428, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4263
Epoch [2/50] - Loss: 1.1521
Epoch [3/50] - Loss: 0.9744
Epoch [4/50] - Loss: 0.8238
Epoch [5/50] - Loss: 0.7017
Epoch [6/50] - Loss: 0.6048
Epoch [7/50] - Loss: 0.5448
Epoch [8/50] - Loss: 0.5306
Epoch [9/50] - Loss: 0.5307
Epoch [10/50] - Loss: 0.5275
Epoch [11/50] - Loss: 0.5233
Epoch [12/50] - Loss: 0.5329
Epoch [13/50] - Loss: 0.5076
Epoch [14/50] - Loss: 0.5039
Epoch [15/50] - Loss: 0.5112
Epoch [16/50] - Loss: 0.4890
Epoch [17/50] - Loss: 0.4822
Epoch [18/50] - Loss: 0.4597
Epoch [19/50] - Loss: 0.4768
Epoch [20/50] - Loss: 0.4490
Epoch [21/50] - Loss: 0.4336
Epoch [22/50] - Loss: 0.4354
Epoch [23/50] - Loss: 0.4461
Epoch [24/50] - Loss: 0.4367
Epoch [25/50] - Loss: 0.4226
Epoch [26/50] - Loss: 0.4262
Epoch [27/50] - Loss: 0.4163
Epoch [28/50] - Loss: 0.4312
Epoch [29/50] - Loss: 0.3993
Epoch [30/50] - Loss: 0.4043
Epoch [31/50] - Loss: 0.3985
Epoch [32/50] - Loss: 0.3909
Epoch [33/50] - Loss: 0.3969
Epoch [34/50] - Loss: 0.3831
Epoch [35/50] - Loss: 0.3866
Epoch [36/50] - Loss: 0.3810
Epoch [37/50] - Loss: 0.3799
Epoch [38/50] - Loss: 0.3578
Epoch [39/50] - Loss: 0.3680
Epoch [40/50] - Loss: 0.3606
Epoch [41/50] - Loss: 0.3623
Epoch [42/50] - Loss: 0.3617
Epoch [43/50] - Loss: 0.3580
Epoch [44/50] - Loss: 0.3520
Epoch [45/50] - Loss: 0.3606
Epoch [46/50] - Loss: 0.3282
Epoch [47/50] - Loss: 0.3393
Epoch [48/50] - Loss: 0.3439
Epoch [49/50] - Loss: 0.3505
Epoch [50/50] - Loss: 0.3407
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_two_nnif_two_nnif_1804092810.csv.
Average F1 over valid seeds: 0.0274 ± 0.0387
___________________________________________________________________________________
Avg F1 for cora with SCAR and two_nnif, GCNConv,0.2: 0.0274 ± 0.0387
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6920
Epoch [2/50] - Loss: 0.6711
Epoch [3/50] - Loss: 0.6470
Epoch [4/50] - Loss: 0.6191
Epoch [5/50] - Loss: 0.5892
Epoch [6/50] - Loss: 0.5583
Epoch [7/50] - Loss: 0.5265
Epoch [8/50] - Loss: 0.4946
Epoch [9/50] - Loss: 0.4629
Epoch [10/50] - Loss: 0.4319
Epoch [11/50] - Loss: 0.4019
Epoch [12/50] - Loss: 0.3733
Epoch [13/50] - Loss: 0.3461
Epoch [14/50] - Loss: 0.3206
Epoch [15/50] - Loss: 0.2967
Epoch [16/50] - Loss: 0.2744
Epoch [17/50] - Loss: 0.2536
Epoch [18/50] - Loss: 0.2343
Epoch [19/50] - Loss: 0.2164
Epoch [20/50] - Loss: 0.1997
Epoch [21/50] - Loss: 0.1842
Epoch [22/50] - Loss: 0.1697
Epoch [23/50] - Loss: 0.1563
Epoch [24/50] - Loss: 0.1438
Epoch [25/50] - Loss: 0.1323
Epoch [26/50] - Loss: 0.1217
Epoch [27/50] - Loss: 0.1119
Epoch [28/50] - Loss: 0.1030
Epoch [29/50] - Loss: 0.0949
Epoch [30/50] - Loss: 0.0875
Epoch [31/50] - Loss: 0.0808
Epoch [32/50] - Loss: 0.0748
Epoch [33/50] - Loss: 0.0693
Epoch [34/50] - Loss: 0.0644
Epoch [35/50] - Loss: 0.0600
Epoch [36/50] - Loss: 0.0560
Epoch [37/50] - Loss: 0.0524
Epoch [38/50] - Loss: 0.0491
Epoch [39/50] - Loss: 0.0461
Epoch [40/50] - Loss: 0.0434
Epoch [41/50] - Loss: 0.0408
Epoch [42/50] - Loss: 0.0385
Epoch [43/50] - Loss: 0.0364
Epoch [44/50] - Loss: 0.0344
Epoch [45/50] - Loss: 0.0326
Epoch [46/50] - Loss: 0.0310
Epoch [47/50] - Loss: 0.0295
Epoch [48/50] - Loss: 0.0281
Epoch [49/50] - Loss: 0.0268
Epoch [50/50] - Loss: 0.0256
sum preds 573
sum labels 491
 - Test Metrics: Accuracy=0.7816, F1=0.5113, Recall=0.5540, Precision=0.4747
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6957
Epoch [2/50] - Loss: 0.6710
Epoch [3/50] - Loss: 0.6428
Epoch [4/50] - Loss: 0.6104
Epoch [5/50] - Loss: 0.5764
Epoch [6/50] - Loss: 0.5420
Epoch [7/50] - Loss: 0.5074
Epoch [8/50] - Loss: 0.4731
Epoch [9/50] - Loss: 0.4397
Epoch [10/50] - Loss: 0.4078
Epoch [11/50] - Loss: 0.3777
Epoch [12/50] - Loss: 0.3495
Epoch [13/50] - Loss: 0.3233
Epoch [14/50] - Loss: 0.2990
Epoch [15/50] - Loss: 0.2766
Epoch [16/50] - Loss: 0.2560
Epoch [17/50] - Loss: 0.2370
Epoch [18/50] - Loss: 0.2194
Epoch [19/50] - Loss: 0.2031
Epoch [20/50] - Loss: 0.1881
Epoch [21/50] - Loss: 0.1741
Epoch [22/50] - Loss: 0.1611
Epoch [23/50] - Loss: 0.1491
Epoch [24/50] - Loss: 0.1380
Epoch [25/50] - Loss: 0.1278
Epoch [26/50] - Loss: 0.1184
Epoch [27/50] - Loss: 0.1098
Epoch [28/50] - Loss: 0.1019
Epoch [29/50] - Loss: 0.0948
Epoch [30/50] - Loss: 0.0882
Epoch [31/50] - Loss: 0.0823
Epoch [32/50] - Loss: 0.0769
Epoch [33/50] - Loss: 0.0720
Epoch [34/50] - Loss: 0.0675
Epoch [35/50] - Loss: 0.0633
Epoch [36/50] - Loss: 0.0595
Epoch [37/50] - Loss: 0.0560
Epoch [38/50] - Loss: 0.0528
Epoch [39/50] - Loss: 0.0498
Epoch [40/50] - Loss: 0.0470
Epoch [41/50] - Loss: 0.0445
Epoch [42/50] - Loss: 0.0421
Epoch [43/50] - Loss: 0.0399
Epoch [44/50] - Loss: 0.0379
Epoch [45/50] - Loss: 0.0361
Epoch [46/50] - Loss: 0.0343
Epoch [47/50] - Loss: 0.0327
Epoch [48/50] - Loss: 0.0312
Epoch [49/50] - Loss: 0.0298
Epoch [50/50] - Loss: 0.0285
sum preds 560
sum labels 491
 - Test Metrics: Accuracy=0.7955, F1=0.5366, Recall=0.5743, Precision=0.5036
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7002
Epoch [2/50] - Loss: 0.6852
Epoch [3/50] - Loss: 0.6695
Epoch [4/50] - Loss: 0.6490
Epoch [5/50] - Loss: 0.6248
Epoch [6/50] - Loss: 0.5982
Epoch [7/50] - Loss: 0.5701
Epoch [8/50] - Loss: 0.5408
Epoch [9/50] - Loss: 0.5106
Epoch [10/50] - Loss: 0.4799
Epoch [11/50] - Loss: 0.4493
Epoch [12/50] - Loss: 0.4193
Epoch [13/50] - Loss: 0.3903
Epoch [14/50] - Loss: 0.3627
Epoch [15/50] - Loss: 0.3365
Epoch [16/50] - Loss: 0.3119
Epoch [17/50] - Loss: 0.2889
Epoch [18/50] - Loss: 0.2675
Epoch [19/50] - Loss: 0.2476
Epoch [20/50] - Loss: 0.2291
Epoch [21/50] - Loss: 0.2118
Epoch [22/50] - Loss: 0.1957
Epoch [23/50] - Loss: 0.1807
Epoch [24/50] - Loss: 0.1667
Epoch [25/50] - Loss: 0.1536
Epoch [26/50] - Loss: 0.1414
Epoch [27/50] - Loss: 0.1301
Epoch [28/50] - Loss: 0.1196
Epoch [29/50] - Loss: 0.1098
Epoch [30/50] - Loss: 0.1009
Epoch [31/50] - Loss: 0.0926
Epoch [32/50] - Loss: 0.0850
Epoch [33/50] - Loss: 0.0781
Epoch [34/50] - Loss: 0.0718
Epoch [35/50] - Loss: 0.0662
Epoch [36/50] - Loss: 0.0610
Epoch [37/50] - Loss: 0.0564
Epoch [38/50] - Loss: 0.0522
Epoch [39/50] - Loss: 0.0484
Epoch [40/50] - Loss: 0.0450
Epoch [41/50] - Loss: 0.0419
Epoch [42/50] - Loss: 0.0390
Epoch [43/50] - Loss: 0.0364
Epoch [44/50] - Loss: 0.0341
Epoch [45/50] - Loss: 0.0319
Epoch [46/50] - Loss: 0.0300
Epoch [47/50] - Loss: 0.0282
Epoch [48/50] - Loss: 0.0266
Epoch [49/50] - Loss: 0.0252
Epoch [50/50] - Loss: 0.0238
sum preds 573
sum labels 491
 - Test Metrics: Accuracy=0.7892, F1=0.5282, Recall=0.5723, Precision=0.4904
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_spy_spy_1804092854.csv.
Average F1 over valid seeds: 0.5254 ± 0.0105
___________________________________________________________________________________
Avg F1 for cora with SCAR and spy, MLP,0.4: 0.5254 ± 0.0105
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7011
Epoch [2/50] - Loss: 0.6590
Epoch [3/50] - Loss: 0.6205
Epoch [4/50] - Loss: 0.5796
Epoch [5/50] - Loss: 0.5382
Epoch [6/50] - Loss: 0.5002
Epoch [7/50] - Loss: 0.4676
Epoch [8/50] - Loss: 0.4396
Epoch [9/50] - Loss: 0.4145
Epoch [10/50] - Loss: 0.3919
Epoch [11/50] - Loss: 0.3714
Epoch [12/50] - Loss: 0.3529
Epoch [13/50] - Loss: 0.3359
Epoch [14/50] - Loss: 0.3196
Epoch [15/50] - Loss: 0.3039
Epoch [16/50] - Loss: 0.2888
Epoch [17/50] - Loss: 0.2743
Epoch [18/50] - Loss: 0.2606
Epoch [19/50] - Loss: 0.2477
Epoch [20/50] - Loss: 0.2356
Epoch [21/50] - Loss: 0.2245
Epoch [22/50] - Loss: 0.2142
Epoch [23/50] - Loss: 0.2042
Epoch [24/50] - Loss: 0.1943
Epoch [25/50] - Loss: 0.1851
Epoch [26/50] - Loss: 0.1769
Epoch [27/50] - Loss: 0.1691
Epoch [28/50] - Loss: 0.1617
Epoch [29/50] - Loss: 0.1546
Epoch [30/50] - Loss: 0.1478
Epoch [31/50] - Loss: 0.1408
Epoch [32/50] - Loss: 0.1335
Epoch [33/50] - Loss: 0.1273
Epoch [34/50] - Loss: 0.1219
Epoch [35/50] - Loss: 0.1174
Epoch [36/50] - Loss: 0.1131
Epoch [37/50] - Loss: 0.1088
Epoch [38/50] - Loss: 0.1049
Epoch [39/50] - Loss: 0.1012
Epoch [40/50] - Loss: 0.0968
Epoch [41/50] - Loss: 0.0923
Epoch [42/50] - Loss: 0.0876
Epoch [43/50] - Loss: 0.0827
Epoch [44/50] - Loss: 0.0779
Epoch [45/50] - Loss: 0.0741
Epoch [46/50] - Loss: 0.0705
Epoch [47/50] - Loss: 0.0669
Epoch [48/50] - Loss: 0.0637
Epoch [49/50] - Loss: 0.0614
Epoch [50/50] - Loss: 0.0588
sum preds 490
sum labels 491
 - Test Metrics: Accuracy=0.8559, F1=0.6504, Recall=0.6497, Precision=0.6510
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7041
Epoch [2/50] - Loss: 0.6690
Epoch [3/50] - Loss: 0.6395
Epoch [4/50] - Loss: 0.6049
Epoch [5/50] - Loss: 0.5667
Epoch [6/50] - Loss: 0.5288
Epoch [7/50] - Loss: 0.4928
Epoch [8/50] - Loss: 0.4593
Epoch [9/50] - Loss: 0.4286
Epoch [10/50] - Loss: 0.4005
Epoch [11/50] - Loss: 0.3750
Epoch [12/50] - Loss: 0.3514
Epoch [13/50] - Loss: 0.3299
Epoch [14/50] - Loss: 0.3102
Epoch [15/50] - Loss: 0.2918
Epoch [16/50] - Loss: 0.2743
Epoch [17/50] - Loss: 0.2575
Epoch [18/50] - Loss: 0.2414
Epoch [19/50] - Loss: 0.2262
Epoch [20/50] - Loss: 0.2119
Epoch [21/50] - Loss: 0.1983
Epoch [22/50] - Loss: 0.1851
Epoch [23/50] - Loss: 0.1726
Epoch [24/50] - Loss: 0.1607
Epoch [25/50] - Loss: 0.1494
Epoch [26/50] - Loss: 0.1388
Epoch [27/50] - Loss: 0.1293
Epoch [28/50] - Loss: 0.1209
Epoch [29/50] - Loss: 0.1132
Epoch [30/50] - Loss: 0.1056
Epoch [31/50] - Loss: 0.0982
Epoch [32/50] - Loss: 0.0910
Epoch [33/50] - Loss: 0.0847
Epoch [34/50] - Loss: 0.0791
Epoch [35/50] - Loss: 0.0743
Epoch [36/50] - Loss: 0.0693
Epoch [37/50] - Loss: 0.0653
Epoch [38/50] - Loss: 0.0615
Epoch [39/50] - Loss: 0.0582
Epoch [40/50] - Loss: 0.0552
Epoch [41/50] - Loss: 0.0524
Epoch [42/50] - Loss: 0.0500
Epoch [43/50] - Loss: 0.0477
Epoch [44/50] - Loss: 0.0457
Epoch [45/50] - Loss: 0.0435
Epoch [46/50] - Loss: 0.0417
Epoch [47/50] - Loss: 0.0399
Epoch [48/50] - Loss: 0.0382
Epoch [49/50] - Loss: 0.0368
Epoch [50/50] - Loss: 0.0354
sum preds 476
sum labels 491
 - Test Metrics: Accuracy=0.8601, F1=0.6556, Recall=0.6456, Precision=0.6660
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6847
Epoch [2/50] - Loss: 0.6251
Epoch [3/50] - Loss: 0.5660
Epoch [4/50] - Loss: 0.5083
Epoch [5/50] - Loss: 0.4556
Epoch [6/50] - Loss: 0.4103
Epoch [7/50] - Loss: 0.3728
Epoch [8/50] - Loss: 0.3421
Epoch [9/50] - Loss: 0.3169
Epoch [10/50] - Loss: 0.2958
Epoch [11/50] - Loss: 0.2774
Epoch [12/50] - Loss: 0.2611
Epoch [13/50] - Loss: 0.2460
Epoch [14/50] - Loss: 0.2319
Epoch [15/50] - Loss: 0.2186
Epoch [16/50] - Loss: 0.2058
Epoch [17/50] - Loss: 0.1937
Epoch [18/50] - Loss: 0.1827
Epoch [19/50] - Loss: 0.1728
Epoch [20/50] - Loss: 0.1635
Epoch [21/50] - Loss: 0.1547
Epoch [22/50] - Loss: 0.1461
Epoch [23/50] - Loss: 0.1375
Epoch [24/50] - Loss: 0.1295
Epoch [25/50] - Loss: 0.1221
Epoch [26/50] - Loss: 0.1152
Epoch [27/50] - Loss: 0.1085
Epoch [28/50] - Loss: 0.1023
Epoch [29/50] - Loss: 0.0966
Epoch [30/50] - Loss: 0.0913
Epoch [31/50] - Loss: 0.0866
Epoch [32/50] - Loss: 0.0825
Epoch [33/50] - Loss: 0.0785
Epoch [34/50] - Loss: 0.0745
Epoch [35/50] - Loss: 0.0711
Epoch [36/50] - Loss: 0.0680
Epoch [37/50] - Loss: 0.0651
Epoch [38/50] - Loss: 0.0626
Epoch [39/50] - Loss: 0.0602
Epoch [40/50] - Loss: 0.0579
Epoch [41/50] - Loss: 0.0558
Epoch [42/50] - Loss: 0.0536
Epoch [43/50] - Loss: 0.0518
Epoch [44/50] - Loss: 0.0500
Epoch [45/50] - Loss: 0.0486
Epoch [46/50] - Loss: 0.0472
Epoch [47/50] - Loss: 0.0456
Epoch [48/50] - Loss: 0.0442
Epoch [49/50] - Loss: 0.0430
Epoch [50/50] - Loss: 0.0417
sum preds 421
sum labels 491
 - Test Metrics: Accuracy=0.8874, F1=0.7061, Recall=0.6558, Precision=0.7648
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_spy_spy_1804092911.csv.
Average F1 over valid seeds: 0.6707 ± 0.0251
___________________________________________________________________________________
Avg F1 for cora with SCAR and spy, GATConv,0.4: 0.6707 ± 0.0251
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6888
Epoch [2/50] - Loss: 0.6500
Epoch [3/50] - Loss: 0.6116
Epoch [4/50] - Loss: 0.5725
Epoch [5/50] - Loss: 0.5349
Epoch [6/50] - Loss: 0.5003
Epoch [7/50] - Loss: 0.4692
Epoch [8/50] - Loss: 0.4416
Epoch [9/50] - Loss: 0.4173
Epoch [10/50] - Loss: 0.3961
Epoch [11/50] - Loss: 0.3775
Epoch [12/50] - Loss: 0.3611
Epoch [13/50] - Loss: 0.3463
Epoch [14/50] - Loss: 0.3329
Epoch [15/50] - Loss: 0.3205
Epoch [16/50] - Loss: 0.3090
Epoch [17/50] - Loss: 0.2981
Epoch [18/50] - Loss: 0.2877
Epoch [19/50] - Loss: 0.2777
Epoch [20/50] - Loss: 0.2681
Epoch [21/50] - Loss: 0.2589
Epoch [22/50] - Loss: 0.2501
Epoch [23/50] - Loss: 0.2417
Epoch [24/50] - Loss: 0.2337
Epoch [25/50] - Loss: 0.2262
Epoch [26/50] - Loss: 0.2190
Epoch [27/50] - Loss: 0.2123
Epoch [28/50] - Loss: 0.2061
Epoch [29/50] - Loss: 0.2002
Epoch [30/50] - Loss: 0.1946
Epoch [31/50] - Loss: 0.1893
Epoch [32/50] - Loss: 0.1842
Epoch [33/50] - Loss: 0.1793
Epoch [34/50] - Loss: 0.1745
Epoch [35/50] - Loss: 0.1700
Epoch [36/50] - Loss: 0.1656
Epoch [37/50] - Loss: 0.1614
Epoch [38/50] - Loss: 0.1575
Epoch [39/50] - Loss: 0.1537
Epoch [40/50] - Loss: 0.1501
Epoch [41/50] - Loss: 0.1466
Epoch [42/50] - Loss: 0.1433
Epoch [43/50] - Loss: 0.1401
Epoch [44/50] - Loss: 0.1369
Epoch [45/50] - Loss: 0.1339
Epoch [46/50] - Loss: 0.1310
Epoch [47/50] - Loss: 0.1281
Epoch [48/50] - Loss: 0.1253
Epoch [49/50] - Loss: 0.1227
Epoch [50/50] - Loss: 0.1201
sum preds 449
sum labels 491
 - Test Metrics: Accuracy=0.8832, F1=0.7043, Recall=0.6741, Precision=0.7372
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6925
Epoch [2/50] - Loss: 0.6673
Epoch [3/50] - Loss: 0.6407
Epoch [4/50] - Loss: 0.6091
Epoch [5/50] - Loss: 0.5749
Epoch [6/50] - Loss: 0.5412
Epoch [7/50] - Loss: 0.5099
Epoch [8/50] - Loss: 0.4815
Epoch [9/50] - Loss: 0.4554
Epoch [10/50] - Loss: 0.4312
Epoch [11/50] - Loss: 0.4091
Epoch [12/50] - Loss: 0.3894
Epoch [13/50] - Loss: 0.3721
Epoch [14/50] - Loss: 0.3566
Epoch [15/50] - Loss: 0.3427
Epoch [16/50] - Loss: 0.3299
Epoch [17/50] - Loss: 0.3183
Epoch [18/50] - Loss: 0.3075
Epoch [19/50] - Loss: 0.2973
Epoch [20/50] - Loss: 0.2876
Epoch [21/50] - Loss: 0.2780
Epoch [22/50] - Loss: 0.2688
Epoch [23/50] - Loss: 0.2599
Epoch [24/50] - Loss: 0.2512
Epoch [25/50] - Loss: 0.2428
Epoch [26/50] - Loss: 0.2346
Epoch [27/50] - Loss: 0.2267
Epoch [28/50] - Loss: 0.2192
Epoch [29/50] - Loss: 0.2121
Epoch [30/50] - Loss: 0.2054
Epoch [31/50] - Loss: 0.1991
Epoch [32/50] - Loss: 0.1931
Epoch [33/50] - Loss: 0.1875
Epoch [34/50] - Loss: 0.1821
Epoch [35/50] - Loss: 0.1770
Epoch [36/50] - Loss: 0.1720
Epoch [37/50] - Loss: 0.1672
Epoch [38/50] - Loss: 0.1626
Epoch [39/50] - Loss: 0.1581
Epoch [40/50] - Loss: 0.1538
Epoch [41/50] - Loss: 0.1496
Epoch [42/50] - Loss: 0.1456
Epoch [43/50] - Loss: 0.1417
Epoch [44/50] - Loss: 0.1380
Epoch [45/50] - Loss: 0.1343
Epoch [46/50] - Loss: 0.1308
Epoch [47/50] - Loss: 0.1275
Epoch [48/50] - Loss: 0.1243
Epoch [49/50] - Loss: 0.1212
Epoch [50/50] - Loss: 0.1183
sum preds 457
sum labels 491
 - Test Metrics: Accuracy=0.8816, F1=0.7025, Recall=0.6782, Precision=0.7287
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6940
Epoch [2/50] - Loss: 0.6551
Epoch [3/50] - Loss: 0.6155
Epoch [4/50] - Loss: 0.5742
Epoch [5/50] - Loss: 0.5332
Epoch [6/50] - Loss: 0.4940
Epoch [7/50] - Loss: 0.4582
Epoch [8/50] - Loss: 0.4269
Epoch [9/50] - Loss: 0.4000
Epoch [10/50] - Loss: 0.3765
Epoch [11/50] - Loss: 0.3558
Epoch [12/50] - Loss: 0.3375
Epoch [13/50] - Loss: 0.3217
Epoch [14/50] - Loss: 0.3079
Epoch [15/50] - Loss: 0.2955
Epoch [16/50] - Loss: 0.2843
Epoch [17/50] - Loss: 0.2740
Epoch [18/50] - Loss: 0.2644
Epoch [19/50] - Loss: 0.2555
Epoch [20/50] - Loss: 0.2471
Epoch [21/50] - Loss: 0.2391
Epoch [22/50] - Loss: 0.2314
Epoch [23/50] - Loss: 0.2240
Epoch [24/50] - Loss: 0.2171
Epoch [25/50] - Loss: 0.2104
Epoch [26/50] - Loss: 0.2041
Epoch [27/50] - Loss: 0.1980
Epoch [28/50] - Loss: 0.1922
Epoch [29/50] - Loss: 0.1866
Epoch [30/50] - Loss: 0.1812
Epoch [31/50] - Loss: 0.1760
Epoch [32/50] - Loss: 0.1711
Epoch [33/50] - Loss: 0.1663
Epoch [34/50] - Loss: 0.1617
Epoch [35/50] - Loss: 0.1574
Epoch [36/50] - Loss: 0.1533
Epoch [37/50] - Loss: 0.1493
Epoch [38/50] - Loss: 0.1455
Epoch [39/50] - Loss: 0.1418
Epoch [40/50] - Loss: 0.1382
Epoch [41/50] - Loss: 0.1347
Epoch [42/50] - Loss: 0.1313
Epoch [43/50] - Loss: 0.1279
Epoch [44/50] - Loss: 0.1248
Epoch [45/50] - Loss: 0.1217
Epoch [46/50] - Loss: 0.1188
Epoch [47/50] - Loss: 0.1159
Epoch [48/50] - Loss: 0.1132
Epoch [49/50] - Loss: 0.1106
Epoch [50/50] - Loss: 0.1081
sum preds 462
sum labels 491
 - Test Metrics: Accuracy=0.8895, F1=0.7240, Recall=0.7026, Precision=0.7468
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_spy_spy_1804092929.csv.
Average F1 over valid seeds: 0.7103 ± 0.0098
___________________________________________________________________________________
Avg F1 for cora with SCAR and spy, GCNConv,0.4: 0.7103 ± 0.0098
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6786
Epoch [2/50] - Loss: 0.6585
Epoch [3/50] - Loss: 0.6372
Epoch [4/50] - Loss: 0.6123
Epoch [5/50] - Loss: 0.5849
Epoch [6/50] - Loss: 0.5557
Epoch [7/50] - Loss: 0.5254
Epoch [8/50] - Loss: 0.4943
Epoch [9/50] - Loss: 0.4632
Epoch [10/50] - Loss: 0.4323
Epoch [11/50] - Loss: 0.4022
Epoch [12/50] - Loss: 0.3732
Epoch [13/50] - Loss: 0.3455
Epoch [14/50] - Loss: 0.3194
Epoch [15/50] - Loss: 0.2948
Epoch [16/50] - Loss: 0.2718
Epoch [17/50] - Loss: 0.2504
Epoch [18/50] - Loss: 0.2303
Epoch [19/50] - Loss: 0.2117
Epoch [20/50] - Loss: 0.1944
Epoch [21/50] - Loss: 0.1783
Epoch [22/50] - Loss: 0.1634
Epoch [23/50] - Loss: 0.1497
Epoch [24/50] - Loss: 0.1372
Epoch [25/50] - Loss: 0.1257
Epoch [26/50] - Loss: 0.1152
Epoch [27/50] - Loss: 0.1057
Epoch [28/50] - Loss: 0.0971
Epoch [29/50] - Loss: 0.0892
Epoch [30/50] - Loss: 0.0822
Epoch [31/50] - Loss: 0.0757
Epoch [32/50] - Loss: 0.0699
Epoch [33/50] - Loss: 0.0646
Epoch [34/50] - Loss: 0.0598
Epoch [35/50] - Loss: 0.0554
Epoch [36/50] - Loss: 0.0515
Epoch [37/50] - Loss: 0.0479
Epoch [38/50] - Loss: 0.0447
Epoch [39/50] - Loss: 0.0417
Epoch [40/50] - Loss: 0.0391
Epoch [41/50] - Loss: 0.0367
Epoch [42/50] - Loss: 0.0344
Epoch [43/50] - Loss: 0.0324
Epoch [44/50] - Loss: 0.0305
Epoch [45/50] - Loss: 0.0288
Epoch [46/50] - Loss: 0.0273
Epoch [47/50] - Loss: 0.0258
Epoch [48/50] - Loss: 0.0245
Epoch [49/50] - Loss: 0.0233
Epoch [50/50] - Loss: 0.0221
sum preds 473
sum labels 573
 - Test Metrics: Accuracy=0.7921, F1=0.5105, Recall=0.4660, Precision=0.5645
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6718
Epoch [2/50] - Loss: 0.6450
Epoch [3/50] - Loss: 0.6147
Epoch [4/50] - Loss: 0.5815
Epoch [5/50] - Loss: 0.5472
Epoch [6/50] - Loss: 0.5128
Epoch [7/50] - Loss: 0.4784
Epoch [8/50] - Loss: 0.4444
Epoch [9/50] - Loss: 0.4115
Epoch [10/50] - Loss: 0.3800
Epoch [11/50] - Loss: 0.3500
Epoch [12/50] - Loss: 0.3220
Epoch [13/50] - Loss: 0.2958
Epoch [14/50] - Loss: 0.2716
Epoch [15/50] - Loss: 0.2492
Epoch [16/50] - Loss: 0.2286
Epoch [17/50] - Loss: 0.2096
Epoch [18/50] - Loss: 0.1921
Epoch [19/50] - Loss: 0.1760
Epoch [20/50] - Loss: 0.1612
Epoch [21/50] - Loss: 0.1475
Epoch [22/50] - Loss: 0.1350
Epoch [23/50] - Loss: 0.1235
Epoch [24/50] - Loss: 0.1131
Epoch [25/50] - Loss: 0.1035
Epoch [26/50] - Loss: 0.0948
Epoch [27/50] - Loss: 0.0870
Epoch [28/50] - Loss: 0.0799
Epoch [29/50] - Loss: 0.0734
Epoch [30/50] - Loss: 0.0676
Epoch [31/50] - Loss: 0.0624
Epoch [32/50] - Loss: 0.0576
Epoch [33/50] - Loss: 0.0534
Epoch [34/50] - Loss: 0.0495
Epoch [35/50] - Loss: 0.0461
Epoch [36/50] - Loss: 0.0429
Epoch [37/50] - Loss: 0.0401
Epoch [38/50] - Loss: 0.0375
Epoch [39/50] - Loss: 0.0351
Epoch [40/50] - Loss: 0.0329
Epoch [41/50] - Loss: 0.0309
Epoch [42/50] - Loss: 0.0291
Epoch [43/50] - Loss: 0.0274
Epoch [44/50] - Loss: 0.0259
Epoch [45/50] - Loss: 0.0245
Epoch [46/50] - Loss: 0.0232
Epoch [47/50] - Loss: 0.0221
Epoch [48/50] - Loss: 0.0210
Epoch [49/50] - Loss: 0.0199
Epoch [50/50] - Loss: 0.0190
sum preds 477
sum labels 573
 - Test Metrics: Accuracy=0.7970, F1=0.5238, Recall=0.4799, Precision=0.5765
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7102
Epoch [2/50] - Loss: 0.6914
Epoch [3/50] - Loss: 0.6730
Epoch [4/50] - Loss: 0.6519
Epoch [5/50] - Loss: 0.6283
Epoch [6/50] - Loss: 0.6025
Epoch [7/50] - Loss: 0.5751
Epoch [8/50] - Loss: 0.5467
Epoch [9/50] - Loss: 0.5181
Epoch [10/50] - Loss: 0.4891
Epoch [11/50] - Loss: 0.4600
Epoch [12/50] - Loss: 0.4311
Epoch [13/50] - Loss: 0.4027
Epoch [14/50] - Loss: 0.3750
Epoch [15/50] - Loss: 0.3484
Epoch [16/50] - Loss: 0.3231
Epoch [17/50] - Loss: 0.2992
Epoch [18/50] - Loss: 0.2767
Epoch [19/50] - Loss: 0.2556
Epoch [20/50] - Loss: 0.2359
Epoch [21/50] - Loss: 0.2175
Epoch [22/50] - Loss: 0.2004
Epoch [23/50] - Loss: 0.1845
Epoch [24/50] - Loss: 0.1696
Epoch [25/50] - Loss: 0.1559
Epoch [26/50] - Loss: 0.1431
Epoch [27/50] - Loss: 0.1313
Epoch [28/50] - Loss: 0.1204
Epoch [29/50] - Loss: 0.1105
Epoch [30/50] - Loss: 0.1014
Epoch [31/50] - Loss: 0.0931
Epoch [32/50] - Loss: 0.0856
Epoch [33/50] - Loss: 0.0787
Epoch [34/50] - Loss: 0.0724
Epoch [35/50] - Loss: 0.0667
Epoch [36/50] - Loss: 0.0616
Epoch [37/50] - Loss: 0.0569
Epoch [38/50] - Loss: 0.0527
Epoch [39/50] - Loss: 0.0488
Epoch [40/50] - Loss: 0.0453
Epoch [41/50] - Loss: 0.0421
Epoch [42/50] - Loss: 0.0392
Epoch [43/50] - Loss: 0.0365
Epoch [44/50] - Loss: 0.0341
Epoch [45/50] - Loss: 0.0319
Epoch [46/50] - Loss: 0.0299
Epoch [47/50] - Loss: 0.0281
Epoch [48/50] - Loss: 0.0264
Epoch [49/50] - Loss: 0.0249
Epoch [50/50] - Loss: 0.0235
sum preds 440
sum labels 573
 - Test Metrics: Accuracy=0.8047, F1=0.5252, Recall=0.4642, Precision=0.6045
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_spy_spy_1804092948.csv.
Average F1 over valid seeds: 0.5198 ± 0.0066
___________________________________________________________________________________
Avg F1 for cora with SCAR and spy, MLP,0.3: 0.5198 ± 0.0066
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7059
Epoch [2/50] - Loss: 0.6577
Epoch [3/50] - Loss: 0.6241
Epoch [4/50] - Loss: 0.5930
Epoch [5/50] - Loss: 0.5614
Epoch [6/50] - Loss: 0.5284
Epoch [7/50] - Loss: 0.4951
Epoch [8/50] - Loss: 0.4636
Epoch [9/50] - Loss: 0.4365
Epoch [10/50] - Loss: 0.4141
Epoch [11/50] - Loss: 0.3940
Epoch [12/50] - Loss: 0.3741
Epoch [13/50] - Loss: 0.3540
Epoch [14/50] - Loss: 0.3350
Epoch [15/50] - Loss: 0.3182
Epoch [16/50] - Loss: 0.3026
Epoch [17/50] - Loss: 0.2867
Epoch [18/50] - Loss: 0.2706
Epoch [19/50] - Loss: 0.2557
Epoch [20/50] - Loss: 0.2429
Epoch [21/50] - Loss: 0.2312
Epoch [22/50] - Loss: 0.2196
Epoch [23/50] - Loss: 0.2082
Epoch [24/50] - Loss: 0.1970
Epoch [25/50] - Loss: 0.1860
Epoch [26/50] - Loss: 0.1755
Epoch [27/50] - Loss: 0.1659
Epoch [28/50] - Loss: 0.1576
Epoch [29/50] - Loss: 0.1498
Epoch [30/50] - Loss: 0.1424
Epoch [31/50] - Loss: 0.1357
Epoch [32/50] - Loss: 0.1296
Epoch [33/50] - Loss: 0.1239
Epoch [34/50] - Loss: 0.1188
Epoch [35/50] - Loss: 0.1141
Epoch [36/50] - Loss: 0.1097
Epoch [37/50] - Loss: 0.1054
Epoch [38/50] - Loss: 0.1014
Epoch [39/50] - Loss: 0.0980
Epoch [40/50] - Loss: 0.0945
Epoch [41/50] - Loss: 0.0903
Epoch [42/50] - Loss: 0.0860
Epoch [43/50] - Loss: 0.0822
Epoch [44/50] - Loss: 0.0791
Epoch [45/50] - Loss: 0.0764
Epoch [46/50] - Loss: 0.0736
Epoch [47/50] - Loss: 0.0704
Epoch [48/50] - Loss: 0.0673
Epoch [49/50] - Loss: 0.0647
Epoch [50/50] - Loss: 0.0618
sum preds 415
sum labels 573
 - Test Metrics: Accuracy=0.8473, F1=0.6194, Recall=0.5340, Precision=0.7373
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7050
Epoch [2/50] - Loss: 0.6631
Epoch [3/50] - Loss: 0.6310
Epoch [4/50] - Loss: 0.5988
Epoch [5/50] - Loss: 0.5649
Epoch [6/50] - Loss: 0.5298
Epoch [7/50] - Loss: 0.4948
Epoch [8/50] - Loss: 0.4622
Epoch [9/50] - Loss: 0.4332
Epoch [10/50] - Loss: 0.4077
Epoch [11/50] - Loss: 0.3843
Epoch [12/50] - Loss: 0.3622
Epoch [13/50] - Loss: 0.3409
Epoch [14/50] - Loss: 0.3206
Epoch [15/50] - Loss: 0.3017
Epoch [16/50] - Loss: 0.2841
Epoch [17/50] - Loss: 0.2673
Epoch [18/50] - Loss: 0.2511
Epoch [19/50] - Loss: 0.2353
Epoch [20/50] - Loss: 0.2206
Epoch [21/50] - Loss: 0.2072
Epoch [22/50] - Loss: 0.1945
Epoch [23/50] - Loss: 0.1825
Epoch [24/50] - Loss: 0.1713
Epoch [25/50] - Loss: 0.1609
Epoch [26/50] - Loss: 0.1510
Epoch [27/50] - Loss: 0.1415
Epoch [28/50] - Loss: 0.1326
Epoch [29/50] - Loss: 0.1243
Epoch [30/50] - Loss: 0.1163
Epoch [31/50] - Loss: 0.1085
Epoch [32/50] - Loss: 0.1011
Epoch [33/50] - Loss: 0.0944
Epoch [34/50] - Loss: 0.0879
Epoch [35/50] - Loss: 0.0817
Epoch [36/50] - Loss: 0.0760
Epoch [37/50] - Loss: 0.0705
Epoch [38/50] - Loss: 0.0652
Epoch [39/50] - Loss: 0.0602
Epoch [40/50] - Loss: 0.0556
Epoch [41/50] - Loss: 0.0514
Epoch [42/50] - Loss: 0.0476
Epoch [43/50] - Loss: 0.0443
Epoch [44/50] - Loss: 0.0415
Epoch [45/50] - Loss: 0.0389
Epoch [46/50] - Loss: 0.0369
Epoch [47/50] - Loss: 0.0353
Epoch [48/50] - Loss: 0.0338
Epoch [49/50] - Loss: 0.0325
Epoch [50/50] - Loss: 0.0313
sum preds 403
sum labels 573
 - Test Metrics: Accuracy=0.8611, F1=0.6496, Recall=0.5532, Precision=0.7866
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6824
Epoch [2/50] - Loss: 0.6243
Epoch [3/50] - Loss: 0.5727
Epoch [4/50] - Loss: 0.5237
Epoch [5/50] - Loss: 0.4768
Epoch [6/50] - Loss: 0.4343
Epoch [7/50] - Loss: 0.3998
Epoch [8/50] - Loss: 0.3719
Epoch [9/50] - Loss: 0.3474
Epoch [10/50] - Loss: 0.3251
Epoch [11/50] - Loss: 0.3055
Epoch [12/50] - Loss: 0.2886
Epoch [13/50] - Loss: 0.2729
Epoch [14/50] - Loss: 0.2571
Epoch [15/50] - Loss: 0.2415
Epoch [16/50] - Loss: 0.2267
Epoch [17/50] - Loss: 0.2127
Epoch [18/50] - Loss: 0.1994
Epoch [19/50] - Loss: 0.1869
Epoch [20/50] - Loss: 0.1751
Epoch [21/50] - Loss: 0.1640
Epoch [22/50] - Loss: 0.1529
Epoch [23/50] - Loss: 0.1424
Epoch [24/50] - Loss: 0.1330
Epoch [25/50] - Loss: 0.1251
Epoch [26/50] - Loss: 0.1182
Epoch [27/50] - Loss: 0.1121
Epoch [28/50] - Loss: 0.1068
Epoch [29/50] - Loss: 0.1018
Epoch [30/50] - Loss: 0.0969
Epoch [31/50] - Loss: 0.0920
Epoch [32/50] - Loss: 0.0876
Epoch [33/50] - Loss: 0.0839
Epoch [34/50] - Loss: 0.0802
Epoch [35/50] - Loss: 0.0767
Epoch [36/50] - Loss: 0.0733
Epoch [37/50] - Loss: 0.0703
Epoch [38/50] - Loss: 0.0678
Epoch [39/50] - Loss: 0.0653
Epoch [40/50] - Loss: 0.0628
Epoch [41/50] - Loss: 0.0606
Epoch [42/50] - Loss: 0.0588
Epoch [43/50] - Loss: 0.0569
Epoch [44/50] - Loss: 0.0551
Epoch [45/50] - Loss: 0.0537
Epoch [46/50] - Loss: 0.0525
Epoch [47/50] - Loss: 0.0513
Epoch [48/50] - Loss: 0.0500
Epoch [49/50] - Loss: 0.0491
Epoch [50/50] - Loss: 0.0480
sum preds 405
sum labels 573
 - Test Metrics: Accuracy=0.8611, F1=0.6503, Recall=0.5550, Precision=0.7852
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_spy_spy_1804093006.csv.
Average F1 over valid seeds: 0.6398 ± 0.0144
___________________________________________________________________________________
Avg F1 for cora with SCAR and spy, GATConv,0.3: 0.6398 ± 0.0144
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6836
Epoch [2/50] - Loss: 0.6417
Epoch [3/50] - Loss: 0.6072
Epoch [4/50] - Loss: 0.5733
Epoch [5/50] - Loss: 0.5387
Epoch [6/50] - Loss: 0.5045
Epoch [7/50] - Loss: 0.4737
Epoch [8/50] - Loss: 0.4471
Epoch [9/50] - Loss: 0.4243
Epoch [10/50] - Loss: 0.4037
Epoch [11/50] - Loss: 0.3845
Epoch [12/50] - Loss: 0.3668
Epoch [13/50] - Loss: 0.3513
Epoch [14/50] - Loss: 0.3377
Epoch [15/50] - Loss: 0.3252
Epoch [16/50] - Loss: 0.3131
Epoch [17/50] - Loss: 0.3013
Epoch [18/50] - Loss: 0.2901
Epoch [19/50] - Loss: 0.2797
Epoch [20/50] - Loss: 0.2699
Epoch [21/50] - Loss: 0.2604
Epoch [22/50] - Loss: 0.2512
Epoch [23/50] - Loss: 0.2425
Epoch [24/50] - Loss: 0.2345
Epoch [25/50] - Loss: 0.2271
Epoch [26/50] - Loss: 0.2201
Epoch [27/50] - Loss: 0.2134
Epoch [28/50] - Loss: 0.2071
Epoch [29/50] - Loss: 0.2014
Epoch [30/50] - Loss: 0.1959
Epoch [31/50] - Loss: 0.1907
Epoch [32/50] - Loss: 0.1856
Epoch [33/50] - Loss: 0.1806
Epoch [34/50] - Loss: 0.1759
Epoch [35/50] - Loss: 0.1714
Epoch [36/50] - Loss: 0.1669
Epoch [37/50] - Loss: 0.1626
Epoch [38/50] - Loss: 0.1585
Epoch [39/50] - Loss: 0.1547
Epoch [40/50] - Loss: 0.1509
Epoch [41/50] - Loss: 0.1473
Epoch [42/50] - Loss: 0.1439
Epoch [43/50] - Loss: 0.1406
Epoch [44/50] - Loss: 0.1373
Epoch [45/50] - Loss: 0.1342
Epoch [46/50] - Loss: 0.1311
Epoch [47/50] - Loss: 0.1281
Epoch [48/50] - Loss: 0.1252
Epoch [49/50] - Loss: 0.1223
Epoch [50/50] - Loss: 0.1196
sum preds 387
sum labels 573
 - Test Metrics: Accuracy=0.8514, F1=0.6188, Recall=0.5183, Precision=0.7674
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6916
Epoch [2/50] - Loss: 0.6613
Epoch [3/50] - Loss: 0.6344
Epoch [4/50] - Loss: 0.6075
Epoch [5/50] - Loss: 0.5799
Epoch [6/50] - Loss: 0.5502
Epoch [7/50] - Loss: 0.5189
Epoch [8/50] - Loss: 0.4891
Epoch [9/50] - Loss: 0.4629
Epoch [10/50] - Loss: 0.4405
Epoch [11/50] - Loss: 0.4203
Epoch [12/50] - Loss: 0.4012
Epoch [13/50] - Loss: 0.3830
Epoch [14/50] - Loss: 0.3663
Epoch [15/50] - Loss: 0.3514
Epoch [16/50] - Loss: 0.3384
Epoch [17/50] - Loss: 0.3266
Epoch [18/50] - Loss: 0.3156
Epoch [19/50] - Loss: 0.3049
Epoch [20/50] - Loss: 0.2946
Epoch [21/50] - Loss: 0.2848
Epoch [22/50] - Loss: 0.2755
Epoch [23/50] - Loss: 0.2665
Epoch [24/50] - Loss: 0.2577
Epoch [25/50] - Loss: 0.2490
Epoch [26/50] - Loss: 0.2405
Epoch [27/50] - Loss: 0.2324
Epoch [28/50] - Loss: 0.2248
Epoch [29/50] - Loss: 0.2175
Epoch [30/50] - Loss: 0.2105
Epoch [31/50] - Loss: 0.2039
Epoch [32/50] - Loss: 0.1975
Epoch [33/50] - Loss: 0.1917
Epoch [34/50] - Loss: 0.1862
Epoch [35/50] - Loss: 0.1810
Epoch [36/50] - Loss: 0.1760
Epoch [37/50] - Loss: 0.1711
Epoch [38/50] - Loss: 0.1665
Epoch [39/50] - Loss: 0.1621
Epoch [40/50] - Loss: 0.1578
Epoch [41/50] - Loss: 0.1536
Epoch [42/50] - Loss: 0.1495
Epoch [43/50] - Loss: 0.1456
Epoch [44/50] - Loss: 0.1419
Epoch [45/50] - Loss: 0.1383
Epoch [46/50] - Loss: 0.1348
Epoch [47/50] - Loss: 0.1314
Epoch [48/50] - Loss: 0.1283
Epoch [49/50] - Loss: 0.1252
Epoch [50/50] - Loss: 0.1223
sum preds 412
sum labels 573
 - Test Metrics: Accuracy=0.8745, F1=0.6863, Recall=0.5899, Precision=0.8204
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6990
Epoch [2/50] - Loss: 0.6508
Epoch [3/50] - Loss: 0.6115
Epoch [4/50] - Loss: 0.5776
Epoch [5/50] - Loss: 0.5453
Epoch [6/50] - Loss: 0.5120
Epoch [7/50] - Loss: 0.4792
Epoch [8/50] - Loss: 0.4494
Epoch [9/50] - Loss: 0.4242
Epoch [10/50] - Loss: 0.4029
Epoch [11/50] - Loss: 0.3839
Epoch [12/50] - Loss: 0.3664
Epoch [13/50] - Loss: 0.3503
Epoch [14/50] - Loss: 0.3360
Epoch [15/50] - Loss: 0.3236
Epoch [16/50] - Loss: 0.3127
Epoch [17/50] - Loss: 0.3026
Epoch [18/50] - Loss: 0.2931
Epoch [19/50] - Loss: 0.2839
Epoch [20/50] - Loss: 0.2753
Epoch [21/50] - Loss: 0.2673
Epoch [22/50] - Loss: 0.2597
Epoch [23/50] - Loss: 0.2523
Epoch [24/50] - Loss: 0.2451
Epoch [25/50] - Loss: 0.2380
Epoch [26/50] - Loss: 0.2312
Epoch [27/50] - Loss: 0.2248
Epoch [28/50] - Loss: 0.2187
Epoch [29/50] - Loss: 0.2127
Epoch [30/50] - Loss: 0.2069
Epoch [31/50] - Loss: 0.2015
Epoch [32/50] - Loss: 0.1963
Epoch [33/50] - Loss: 0.1914
Epoch [34/50] - Loss: 0.1866
Epoch [35/50] - Loss: 0.1819
Epoch [36/50] - Loss: 0.1773
Epoch [37/50] - Loss: 0.1729
Epoch [38/50] - Loss: 0.1687
Epoch [39/50] - Loss: 0.1644
Epoch [40/50] - Loss: 0.1603
Epoch [41/50] - Loss: 0.1563
Epoch [42/50] - Loss: 0.1525
Epoch [43/50] - Loss: 0.1487
Epoch [44/50] - Loss: 0.1451
Epoch [45/50] - Loss: 0.1416
Epoch [46/50] - Loss: 0.1383
Epoch [47/50] - Loss: 0.1351
Epoch [48/50] - Loss: 0.1320
Epoch [49/50] - Loss: 0.1290
Epoch [50/50] - Loss: 0.1261
sum preds 423
sum labels 573
 - Test Metrics: Accuracy=0.8725, F1=0.6847, Recall=0.5951, Precision=0.8061
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_spy_spy_1804093026.csv.
Average F1 over valid seeds: 0.6633 ± 0.0315
___________________________________________________________________________________
Avg F1 for cora with SCAR and spy, GCNConv,0.3: 0.6633 ± 0.0315
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6611
Epoch [2/50] - Loss: 0.6378
Epoch [3/50] - Loss: 0.6147
Epoch [4/50] - Loss: 0.5886
Epoch [5/50] - Loss: 0.5602
Epoch [6/50] - Loss: 0.5304
Epoch [7/50] - Loss: 0.5001
Epoch [8/50] - Loss: 0.4696
Epoch [9/50] - Loss: 0.4390
Epoch [10/50] - Loss: 0.4085
Epoch [11/50] - Loss: 0.3784
Epoch [12/50] - Loss: 0.3492
Epoch [13/50] - Loss: 0.3212
Epoch [14/50] - Loss: 0.2946
Epoch [15/50] - Loss: 0.2695
Epoch [16/50] - Loss: 0.2461
Epoch [17/50] - Loss: 0.2243
Epoch [18/50] - Loss: 0.2043
Epoch [19/50] - Loss: 0.1859
Epoch [20/50] - Loss: 0.1691
Epoch [21/50] - Loss: 0.1538
Epoch [22/50] - Loss: 0.1399
Epoch [23/50] - Loss: 0.1273
Epoch [24/50] - Loss: 0.1158
Epoch [25/50] - Loss: 0.1055
Epoch [26/50] - Loss: 0.0962
Epoch [27/50] - Loss: 0.0878
Epoch [28/50] - Loss: 0.0802
Epoch [29/50] - Loss: 0.0733
Epoch [30/50] - Loss: 0.0671
Epoch [31/50] - Loss: 0.0615
Epoch [32/50] - Loss: 0.0564
Epoch [33/50] - Loss: 0.0518
Epoch [34/50] - Loss: 0.0477
Epoch [35/50] - Loss: 0.0439
Epoch [36/50] - Loss: 0.0406
Epoch [37/50] - Loss: 0.0377
Epoch [38/50] - Loss: 0.0350
Epoch [39/50] - Loss: 0.0327
Epoch [40/50] - Loss: 0.0305
Epoch [41/50] - Loss: 0.0286
Epoch [42/50] - Loss: 0.0268
Epoch [43/50] - Loss: 0.0251
Epoch [44/50] - Loss: 0.0236
Epoch [45/50] - Loss: 0.0222
Epoch [46/50] - Loss: 0.0209
Epoch [47/50] - Loss: 0.0198
Epoch [48/50] - Loss: 0.0187
Epoch [49/50] - Loss: 0.0177
Epoch [50/50] - Loss: 0.0168
sum preds 333
sum labels 654
 - Test Metrics: Accuracy=0.8086, F1=0.5066, Recall=0.3823, Precision=0.7508
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6432
Epoch [2/50] - Loss: 0.6129
Epoch [3/50] - Loss: 0.5804
Epoch [4/50] - Loss: 0.5463
Epoch [5/50] - Loss: 0.5126
Epoch [6/50] - Loss: 0.4796
Epoch [7/50] - Loss: 0.4472
Epoch [8/50] - Loss: 0.4156
Epoch [9/50] - Loss: 0.3851
Epoch [10/50] - Loss: 0.3557
Epoch [11/50] - Loss: 0.3276
Epoch [12/50] - Loss: 0.3008
Epoch [13/50] - Loss: 0.2756
Epoch [14/50] - Loss: 0.2520
Epoch [15/50] - Loss: 0.2301
Epoch [16/50] - Loss: 0.2100
Epoch [17/50] - Loss: 0.1915
Epoch [18/50] - Loss: 0.1746
Epoch [19/50] - Loss: 0.1593
Epoch [20/50] - Loss: 0.1454
Epoch [21/50] - Loss: 0.1328
Epoch [22/50] - Loss: 0.1214
Epoch [23/50] - Loss: 0.1111
Epoch [24/50] - Loss: 0.1018
Epoch [25/50] - Loss: 0.0935
Epoch [26/50] - Loss: 0.0860
Epoch [27/50] - Loss: 0.0792
Epoch [28/50] - Loss: 0.0732
Epoch [29/50] - Loss: 0.0678
Epoch [30/50] - Loss: 0.0629
Epoch [31/50] - Loss: 0.0585
Epoch [32/50] - Loss: 0.0545
Epoch [33/50] - Loss: 0.0509
Epoch [34/50] - Loss: 0.0476
Epoch [35/50] - Loss: 0.0446
Epoch [36/50] - Loss: 0.0419
Epoch [37/50] - Loss: 0.0394
Epoch [38/50] - Loss: 0.0372
Epoch [39/50] - Loss: 0.0351
Epoch [40/50] - Loss: 0.0331
Epoch [41/50] - Loss: 0.0313
Epoch [42/50] - Loss: 0.0297
Epoch [43/50] - Loss: 0.0282
Epoch [44/50] - Loss: 0.0268
Epoch [45/50] - Loss: 0.0255
Epoch [46/50] - Loss: 0.0242
Epoch [47/50] - Loss: 0.0231
Epoch [48/50] - Loss: 0.0221
Epoch [49/50] - Loss: 0.0211
Epoch [50/50] - Loss: 0.0202
sum preds 380
sum labels 654
 - Test Metrics: Accuracy=0.7830, F1=0.4662, Recall=0.3685, Precision=0.6342
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7240
Epoch [2/50] - Loss: 0.6980
Epoch [3/50] - Loss: 0.6746
Epoch [4/50] - Loss: 0.6499
Epoch [5/50] - Loss: 0.6246
Epoch [6/50] - Loss: 0.5993
Epoch [7/50] - Loss: 0.5745
Epoch [8/50] - Loss: 0.5503
Epoch [9/50] - Loss: 0.5267
Epoch [10/50] - Loss: 0.5037
Epoch [11/50] - Loss: 0.4811
Epoch [12/50] - Loss: 0.4585
Epoch [13/50] - Loss: 0.4354
Epoch [14/50] - Loss: 0.4116
Epoch [15/50] - Loss: 0.3875
Epoch [16/50] - Loss: 0.3634
Epoch [17/50] - Loss: 0.3396
Epoch [18/50] - Loss: 0.3168
Epoch [19/50] - Loss: 0.2953
Epoch [20/50] - Loss: 0.2752
Epoch [21/50] - Loss: 0.2563
Epoch [22/50] - Loss: 0.2382
Epoch [23/50] - Loss: 0.2206
Epoch [24/50] - Loss: 0.2034
Epoch [25/50] - Loss: 0.1867
Epoch [26/50] - Loss: 0.1709
Epoch [27/50] - Loss: 0.1563
Epoch [28/50] - Loss: 0.1430
Epoch [29/50] - Loss: 0.1309
Epoch [30/50] - Loss: 0.1200
Epoch [31/50] - Loss: 0.1099
Epoch [32/50] - Loss: 0.1006
Epoch [33/50] - Loss: 0.0920
Epoch [34/50] - Loss: 0.0841
Epoch [35/50] - Loss: 0.0768
Epoch [36/50] - Loss: 0.0703
Epoch [37/50] - Loss: 0.0644
Epoch [38/50] - Loss: 0.0591
Epoch [39/50] - Loss: 0.0543
Epoch [40/50] - Loss: 0.0500
Epoch [41/50] - Loss: 0.0461
Epoch [42/50] - Loss: 0.0425
Epoch [43/50] - Loss: 0.0393
Epoch [44/50] - Loss: 0.0364
Epoch [45/50] - Loss: 0.0338
Epoch [46/50] - Loss: 0.0314
Epoch [47/50] - Loss: 0.0293
Epoch [48/50] - Loss: 0.0273
Epoch [49/50] - Loss: 0.0256
Epoch [50/50] - Loss: 0.0240
sum preds 373
sum labels 654
 - Test Metrics: Accuracy=0.7638, F1=0.4148, Recall=0.3257, Precision=0.5710
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_spy_spy_1804093047.csv.
Average F1 over valid seeds: 0.4625 ± 0.0376
___________________________________________________________________________________
Avg F1 for cora with SCAR and spy, MLP,0.2: 0.4625 ± 0.0376
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7115
Epoch [2/50] - Loss: 0.6443
Epoch [3/50] - Loss: 0.6021
Epoch [4/50] - Loss: 0.5703
Epoch [5/50] - Loss: 0.5456
Epoch [6/50] - Loss: 0.5252
Epoch [7/50] - Loss: 0.5059
Epoch [8/50] - Loss: 0.4856
Epoch [9/50] - Loss: 0.4632
Epoch [10/50] - Loss: 0.4394
Epoch [11/50] - Loss: 0.4159
Epoch [12/50] - Loss: 0.3941
Epoch [13/50] - Loss: 0.3746
Epoch [14/50] - Loss: 0.3579
Epoch [15/50] - Loss: 0.3426
Epoch [16/50] - Loss: 0.3275
Epoch [17/50] - Loss: 0.3116
Epoch [18/50] - Loss: 0.2946
Epoch [19/50] - Loss: 0.2769
Epoch [20/50] - Loss: 0.2594
Epoch [21/50] - Loss: 0.2428
Epoch [22/50] - Loss: 0.2274
Epoch [23/50] - Loss: 0.2135
Epoch [24/50] - Loss: 0.2003
Epoch [25/50] - Loss: 0.1875
Epoch [26/50] - Loss: 0.1754
Epoch [27/50] - Loss: 0.1644
Epoch [28/50] - Loss: 0.1545
Epoch [29/50] - Loss: 0.1452
Epoch [30/50] - Loss: 0.1359
Epoch [31/50] - Loss: 0.1280
Epoch [32/50] - Loss: 0.1208
Epoch [33/50] - Loss: 0.1137
Epoch [34/50] - Loss: 0.1068
Epoch [35/50] - Loss: 0.1003
Epoch [36/50] - Loss: 0.0952
Epoch [37/50] - Loss: 0.0902
Epoch [38/50] - Loss: 0.0854
Epoch [39/50] - Loss: 0.0815
Epoch [40/50] - Loss: 0.0781
Epoch [41/50] - Loss: 0.0749
Epoch [42/50] - Loss: 0.0724
Epoch [43/50] - Loss: 0.0703
Epoch [44/50] - Loss: 0.0680
Epoch [45/50] - Loss: 0.0653
Epoch [46/50] - Loss: 0.0625
Epoch [47/50] - Loss: 0.0596
Epoch [48/50] - Loss: 0.0570
Epoch [49/50] - Loss: 0.0548
Epoch [50/50] - Loss: 0.0532
sum preds 345
sum labels 654
 - Test Metrics: Accuracy=0.8416, F1=0.5966, Recall=0.4557, Precision=0.8638
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7117
Epoch [2/50] - Loss: 0.6520
Epoch [3/50] - Loss: 0.6123
Epoch [4/50] - Loss: 0.5800
Epoch [5/50] - Loss: 0.5534
Epoch [6/50] - Loss: 0.5309
Epoch [7/50] - Loss: 0.5101
Epoch [8/50] - Loss: 0.4884
Epoch [9/50] - Loss: 0.4639
Epoch [10/50] - Loss: 0.4364
Epoch [11/50] - Loss: 0.4078
Epoch [12/50] - Loss: 0.3800
Epoch [13/50] - Loss: 0.3561
Epoch [14/50] - Loss: 0.3370
Epoch [15/50] - Loss: 0.3212
Epoch [16/50] - Loss: 0.3060
Epoch [17/50] - Loss: 0.2890
Epoch [18/50] - Loss: 0.2698
Epoch [19/50] - Loss: 0.2499
Epoch [20/50] - Loss: 0.2315
Epoch [21/50] - Loss: 0.2158
Epoch [22/50] - Loss: 0.2026
Epoch [23/50] - Loss: 0.1903
Epoch [24/50] - Loss: 0.1780
Epoch [25/50] - Loss: 0.1657
Epoch [26/50] - Loss: 0.1542
Epoch [27/50] - Loss: 0.1440
Epoch [28/50] - Loss: 0.1352
Epoch [29/50] - Loss: 0.1274
Epoch [30/50] - Loss: 0.1200
Epoch [31/50] - Loss: 0.1126
Epoch [32/50] - Loss: 0.1053
Epoch [33/50] - Loss: 0.0987
Epoch [34/50] - Loss: 0.0927
Epoch [35/50] - Loss: 0.0872
Epoch [36/50] - Loss: 0.0817
Epoch [37/50] - Loss: 0.0765
Epoch [38/50] - Loss: 0.0718
Epoch [39/50] - Loss: 0.0674
Epoch [40/50] - Loss: 0.0634
Epoch [41/50] - Loss: 0.0597
Epoch [42/50] - Loss: 0.0560
Epoch [43/50] - Loss: 0.0524
Epoch [44/50] - Loss: 0.0490
Epoch [45/50] - Loss: 0.0459
Epoch [46/50] - Loss: 0.0430
Epoch [47/50] - Loss: 0.0405
Epoch [48/50] - Loss: 0.0384
Epoch [49/50] - Loss: 0.0365
Epoch [50/50] - Loss: 0.0346
sum preds 325
sum labels 654
 - Test Metrics: Accuracy=0.8424, F1=0.5904, Recall=0.4419, Precision=0.8892
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6785
Epoch [2/50] - Loss: 0.6019
Epoch [3/50] - Loss: 0.5549
Epoch [4/50] - Loss: 0.5258
Epoch [5/50] - Loss: 0.4994
Epoch [6/50] - Loss: 0.4692
Epoch [7/50] - Loss: 0.4375
Epoch [8/50] - Loss: 0.4089
Epoch [9/50] - Loss: 0.3856
Epoch [10/50] - Loss: 0.3665
Epoch [11/50] - Loss: 0.3501
Epoch [12/50] - Loss: 0.3341
Epoch [13/50] - Loss: 0.3174
Epoch [14/50] - Loss: 0.3001
Epoch [15/50] - Loss: 0.2830
Epoch [16/50] - Loss: 0.2675
Epoch [17/50] - Loss: 0.2540
Epoch [18/50] - Loss: 0.2419
Epoch [19/50] - Loss: 0.2303
Epoch [20/50] - Loss: 0.2186
Epoch [21/50] - Loss: 0.2067
Epoch [22/50] - Loss: 0.1955
Epoch [23/50] - Loss: 0.1858
Epoch [24/50] - Loss: 0.1771
Epoch [25/50] - Loss: 0.1681
Epoch [26/50] - Loss: 0.1589
Epoch [27/50] - Loss: 0.1507
Epoch [28/50] - Loss: 0.1433
Epoch [29/50] - Loss: 0.1365
Epoch [30/50] - Loss: 0.1297
Epoch [31/50] - Loss: 0.1233
Epoch [32/50] - Loss: 0.1177
Epoch [33/50] - Loss: 0.1126
Epoch [34/50] - Loss: 0.1071
Epoch [35/50] - Loss: 0.1014
Epoch [36/50] - Loss: 0.0957
Epoch [37/50] - Loss: 0.0905
Epoch [38/50] - Loss: 0.0863
Epoch [39/50] - Loss: 0.0825
Epoch [40/50] - Loss: 0.0788
Epoch [41/50] - Loss: 0.0754
Epoch [42/50] - Loss: 0.0724
Epoch [43/50] - Loss: 0.0696
Epoch [44/50] - Loss: 0.0669
Epoch [45/50] - Loss: 0.0644
Epoch [46/50] - Loss: 0.0623
Epoch [47/50] - Loss: 0.0606
Epoch [48/50] - Loss: 0.0590
Epoch [49/50] - Loss: 0.0573
Epoch [50/50] - Loss: 0.0558
sum preds 352
sum labels 654
 - Test Metrics: Accuracy=0.8255, F1=0.5586, Recall=0.4297, Precision=0.7983
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_spy_spy_1804093105.csv.
Average F1 over valid seeds: 0.5819 ± 0.0166
___________________________________________________________________________________
Avg F1 for cora with SCAR and spy, GATConv,0.2: 0.5819 ± 0.0166
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6760
Epoch [2/50] - Loss: 0.6185
Epoch [3/50] - Loss: 0.5801
Epoch [4/50] - Loss: 0.5508
Epoch [5/50] - Loss: 0.5266
Epoch [6/50] - Loss: 0.5037
Epoch [7/50] - Loss: 0.4798
Epoch [8/50] - Loss: 0.4538
Epoch [9/50] - Loss: 0.4270
Epoch [10/50] - Loss: 0.4018
Epoch [11/50] - Loss: 0.3805
Epoch [12/50] - Loss: 0.3640
Epoch [13/50] - Loss: 0.3508
Epoch [14/50] - Loss: 0.3382
Epoch [15/50] - Loss: 0.3245
Epoch [16/50] - Loss: 0.3098
Epoch [17/50] - Loss: 0.2954
Epoch [18/50] - Loss: 0.2829
Epoch [19/50] - Loss: 0.2727
Epoch [20/50] - Loss: 0.2639
Epoch [21/50] - Loss: 0.2553
Epoch [22/50] - Loss: 0.2463
Epoch [23/50] - Loss: 0.2369
Epoch [24/50] - Loss: 0.2280
Epoch [25/50] - Loss: 0.2201
Epoch [26/50] - Loss: 0.2132
Epoch [27/50] - Loss: 0.2068
Epoch [28/50] - Loss: 0.2002
Epoch [29/50] - Loss: 0.1934
Epoch [30/50] - Loss: 0.1867
Epoch [31/50] - Loss: 0.1808
Epoch [32/50] - Loss: 0.1755
Epoch [33/50] - Loss: 0.1705
Epoch [34/50] - Loss: 0.1655
Epoch [35/50] - Loss: 0.1603
Epoch [36/50] - Loss: 0.1553
Epoch [37/50] - Loss: 0.1507
Epoch [38/50] - Loss: 0.1465
Epoch [39/50] - Loss: 0.1424
Epoch [40/50] - Loss: 0.1383
Epoch [41/50] - Loss: 0.1343
Epoch [42/50] - Loss: 0.1306
Epoch [43/50] - Loss: 0.1273
Epoch [44/50] - Loss: 0.1241
Epoch [45/50] - Loss: 0.1210
Epoch [46/50] - Loss: 0.1178
Epoch [47/50] - Loss: 0.1147
Epoch [48/50] - Loss: 0.1119
Epoch [49/50] - Loss: 0.1091
Epoch [50/50] - Loss: 0.1064
sum preds 341
sum labels 654
 - Test Metrics: Accuracy=0.8502, F1=0.6171, Recall=0.4694, Precision=0.9003
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6917
Epoch [2/50] - Loss: 0.6489
Epoch [3/50] - Loss: 0.6139
Epoch [4/50] - Loss: 0.5843
Epoch [5/50] - Loss: 0.5605
Epoch [6/50] - Loss: 0.5419
Epoch [7/50] - Loss: 0.5261
Epoch [8/50] - Loss: 0.5109
Epoch [9/50] - Loss: 0.4943
Epoch [10/50] - Loss: 0.4754
Epoch [11/50] - Loss: 0.4538
Epoch [12/50] - Loss: 0.4306
Epoch [13/50] - Loss: 0.4070
Epoch [14/50] - Loss: 0.3857
Epoch [15/50] - Loss: 0.3689
Epoch [16/50] - Loss: 0.3569
Epoch [17/50] - Loss: 0.3470
Epoch [18/50] - Loss: 0.3362
Epoch [19/50] - Loss: 0.3228
Epoch [20/50] - Loss: 0.3077
Epoch [21/50] - Loss: 0.2930
Epoch [22/50] - Loss: 0.2802
Epoch [23/50] - Loss: 0.2698
Epoch [24/50] - Loss: 0.2611
Epoch [25/50] - Loss: 0.2530
Epoch [26/50] - Loss: 0.2444
Epoch [27/50] - Loss: 0.2351
Epoch [28/50] - Loss: 0.2256
Epoch [29/50] - Loss: 0.2168
Epoch [30/50] - Loss: 0.2092
Epoch [31/50] - Loss: 0.2025
Epoch [32/50] - Loss: 0.1962
Epoch [33/50] - Loss: 0.1896
Epoch [34/50] - Loss: 0.1826
Epoch [35/50] - Loss: 0.1758
Epoch [36/50] - Loss: 0.1696
Epoch [37/50] - Loss: 0.1643
Epoch [38/50] - Loss: 0.1593
Epoch [39/50] - Loss: 0.1544
Epoch [40/50] - Loss: 0.1493
Epoch [41/50] - Loss: 0.1443
Epoch [42/50] - Loss: 0.1396
Epoch [43/50] - Loss: 0.1355
Epoch [44/50] - Loss: 0.1317
Epoch [45/50] - Loss: 0.1278
Epoch [46/50] - Loss: 0.1240
Epoch [47/50] - Loss: 0.1202
Epoch [48/50] - Loss: 0.1168
Epoch [49/50] - Loss: 0.1137
Epoch [50/50] - Loss: 0.1108
sum preds 332
sum labels 654
 - Test Metrics: Accuracy=0.8436, F1=0.5963, Recall=0.4495, Precision=0.8855
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6994
Epoch [2/50] - Loss: 0.6335
Epoch [3/50] - Loss: 0.5854
Epoch [4/50] - Loss: 0.5543
Epoch [5/50] - Loss: 0.5339
Epoch [6/50] - Loss: 0.5156
Epoch [7/50] - Loss: 0.4949
Epoch [8/50] - Loss: 0.4714
Epoch [9/50] - Loss: 0.4472
Epoch [10/50] - Loss: 0.4250
Epoch [11/50] - Loss: 0.4061
Epoch [12/50] - Loss: 0.3906
Epoch [13/50] - Loss: 0.3769
Epoch [14/50] - Loss: 0.3639
Epoch [15/50] - Loss: 0.3511
Epoch [16/50] - Loss: 0.3382
Epoch [17/50] - Loss: 0.3255
Epoch [18/50] - Loss: 0.3133
Epoch [19/50] - Loss: 0.3021
Epoch [20/50] - Loss: 0.2920
Epoch [21/50] - Loss: 0.2830
Epoch [22/50] - Loss: 0.2747
Epoch [23/50] - Loss: 0.2666
Epoch [24/50] - Loss: 0.2586
Epoch [25/50] - Loss: 0.2505
Epoch [26/50] - Loss: 0.2427
Epoch [27/50] - Loss: 0.2353
Epoch [28/50] - Loss: 0.2285
Epoch [29/50] - Loss: 0.2222
Epoch [30/50] - Loss: 0.2160
Epoch [31/50] - Loss: 0.2100
Epoch [32/50] - Loss: 0.2041
Epoch [33/50] - Loss: 0.1984
Epoch [34/50] - Loss: 0.1931
Epoch [35/50] - Loss: 0.1881
Epoch [36/50] - Loss: 0.1833
Epoch [37/50] - Loss: 0.1785
Epoch [38/50] - Loss: 0.1737
Epoch [39/50] - Loss: 0.1691
Epoch [40/50] - Loss: 0.1647
Epoch [41/50] - Loss: 0.1606
Epoch [42/50] - Loss: 0.1565
Epoch [43/50] - Loss: 0.1525
Epoch [44/50] - Loss: 0.1486
Epoch [45/50] - Loss: 0.1450
Epoch [46/50] - Loss: 0.1415
Epoch [47/50] - Loss: 0.1382
Epoch [48/50] - Loss: 0.1351
Epoch [49/50] - Loss: 0.1320
Epoch [50/50] - Loss: 0.1290
sum preds 421
sum labels 654
 - Test Metrics: Accuracy=0.8597, F1=0.6679, Recall=0.5489, Precision=0.8527
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_spy_spy_1804093124.csv.
Average F1 over valid seeds: 0.6271 ± 0.0301
___________________________________________________________________________________
Avg F1 for cora with SCAR and spy, GCNConv,0.2: 0.6271 ± 0.0301
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4867
Epoch [3/50] - Loss: 0.4724
Epoch [4/50] - Loss: 0.4557
Epoch [5/50] - Loss: 0.4372
Epoch [6/50] - Loss: 0.4173
Epoch [7/50] - Loss: 0.3966
Epoch [8/50] - Loss: 0.3754
Epoch [9/50] - Loss: 0.3537
Epoch [10/50] - Loss: 0.3316
Epoch [11/50] - Loss: 0.3094
Epoch [12/50] - Loss: 0.2871
Epoch [13/50] - Loss: 0.2651
Epoch [14/50] - Loss: 0.2434
Epoch [15/50] - Loss: 0.2222
Epoch [16/50] - Loss: 0.2016
Epoch [17/50] - Loss: 0.1817
Epoch [18/50] - Loss: 0.1625
Epoch [19/50] - Loss: 0.1440
Epoch [20/50] - Loss: 0.1263
Epoch [21/50] - Loss: 0.1110
Epoch [22/50] - Loss: 0.1032
Epoch [23/50] - Loss: 0.0942
Epoch [24/50] - Loss: 0.0846
Epoch [25/50] - Loss: 0.0749
Epoch [26/50] - Loss: 0.0655
Epoch [27/50] - Loss: 0.0639
Epoch [28/50] - Loss: 0.0623
Epoch [29/50] - Loss: 0.0563
Epoch [30/50] - Loss: 0.0462
Epoch [31/50] - Loss: 0.0457
Epoch [32/50] - Loss: 0.0447
Epoch [33/50] - Loss: 0.0431
Epoch [34/50] - Loss: 0.0410
Epoch [35/50] - Loss: 0.0385
Epoch [36/50] - Loss: 0.0357
Epoch [37/50] - Loss: 0.0329
Epoch [38/50] - Loss: 0.0300
Epoch [39/50] - Loss: 0.0273
Epoch [40/50] - Loss: 0.0247
Epoch [41/50] - Loss: 0.0224
Epoch [42/50] - Loss: 0.0210
Epoch [43/50] - Loss: 0.0195
Epoch [44/50] - Loss: 0.0186
Epoch [45/50] - Loss: 0.0178
Epoch [46/50] - Loss: 0.0169
Epoch [47/50] - Loss: 0.0163
Epoch [48/50] - Loss: 0.0160
Epoch [49/50] - Loss: 0.0159
Epoch [50/50] - Loss: 0.0157
sum preds 526
sum labels 491
 - Test Metrics: Accuracy=0.8526, F1=0.6549, Recall=0.6782, Precision=0.6331
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5017
Epoch [2/50] - Loss: 0.4844
Epoch [3/50] - Loss: 0.4665
Epoch [4/50] - Loss: 0.4467
Epoch [5/50] - Loss: 0.4256
Epoch [6/50] - Loss: 0.4034
Epoch [7/50] - Loss: 0.3806
Epoch [8/50] - Loss: 0.3576
Epoch [9/50] - Loss: 0.3346
Epoch [10/50] - Loss: 0.3119
Epoch [11/50] - Loss: 0.2896
Epoch [12/50] - Loss: 0.2678
Epoch [13/50] - Loss: 0.2466
Epoch [14/50] - Loss: 0.2260
Epoch [15/50] - Loss: 0.2059
Epoch [16/50] - Loss: 0.1863
Epoch [17/50] - Loss: 0.1673
Epoch [18/50] - Loss: 0.1489
Epoch [19/50] - Loss: 0.1312
Epoch [20/50] - Loss: 0.1150
Epoch [21/50] - Loss: 0.1063
Epoch [22/50] - Loss: 0.0965
Epoch [23/50] - Loss: 0.0863
Epoch [24/50] - Loss: 0.0761
Epoch [25/50] - Loss: 0.0666
Epoch [26/50] - Loss: 0.0631
Epoch [27/50] - Loss: 0.0571
Epoch [28/50] - Loss: 0.0522
Epoch [29/50] - Loss: 0.0490
Epoch [30/50] - Loss: 0.0455
Epoch [31/50] - Loss: 0.0417
Epoch [32/50] - Loss: 0.0379
Epoch [33/50] - Loss: 0.0367
Epoch [34/50] - Loss: 0.0324
Epoch [35/50] - Loss: 0.0304
Epoch [36/50] - Loss: 0.0285
Epoch [37/50] - Loss: 0.0275
Epoch [38/50] - Loss: 0.0265
Epoch [39/50] - Loss: 0.0253
Epoch [40/50] - Loss: 0.0240
Epoch [41/50] - Loss: 0.0225
Epoch [42/50] - Loss: 0.0210
Epoch [43/50] - Loss: 0.0195
Epoch [44/50] - Loss: 0.0181
Epoch [45/50] - Loss: 0.0167
Epoch [46/50] - Loss: 0.0176
Epoch [47/50] - Loss: 0.0151
Epoch [48/50] - Loss: 0.0147
Epoch [49/50] - Loss: 0.0142
Epoch [50/50] - Loss: 0.0137
sum preds 556
sum labels 491
 - Test Metrics: Accuracy=0.8635, F1=0.6896, Recall=0.7352, Precision=0.6493
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5130
Epoch [2/50] - Loss: 0.4992
Epoch [3/50] - Loss: 0.4858
Epoch [4/50] - Loss: 0.4704
Epoch [5/50] - Loss: 0.4530
Epoch [6/50] - Loss: 0.4339
Epoch [7/50] - Loss: 0.4136
Epoch [8/50] - Loss: 0.3926
Epoch [9/50] - Loss: 0.3709
Epoch [10/50] - Loss: 0.3484
Epoch [11/50] - Loss: 0.3253
Epoch [12/50] - Loss: 0.3018
Epoch [13/50] - Loss: 0.2782
Epoch [14/50] - Loss: 0.2548
Epoch [15/50] - Loss: 0.2319
Epoch [16/50] - Loss: 0.2096
Epoch [17/50] - Loss: 0.1880
Epoch [18/50] - Loss: 0.1671
Epoch [19/50] - Loss: 0.1470
Epoch [20/50] - Loss: 0.1278
Epoch [21/50] - Loss: 0.1094
Epoch [22/50] - Loss: 0.0979
Epoch [23/50] - Loss: 0.0906
Epoch [24/50] - Loss: 0.0821
Epoch [25/50] - Loss: 0.0732
Epoch [26/50] - Loss: 0.0643
Epoch [27/50] - Loss: 0.0558
Epoch [28/50] - Loss: 0.0480
Epoch [29/50] - Loss: 0.0538
Epoch [30/50] - Loss: 0.0534
Epoch [31/50] - Loss: 0.0459
Epoch [32/50] - Loss: 0.0355
Epoch [33/50] - Loss: 0.0348
Epoch [34/50] - Loss: 0.0338
Epoch [35/50] - Loss: 0.0325
Epoch [36/50] - Loss: 0.0309
Epoch [37/50] - Loss: 0.0292
Epoch [38/50] - Loss: 0.0274
Epoch [39/50] - Loss: 0.0257
Epoch [40/50] - Loss: 0.0239
Epoch [41/50] - Loss: 0.0222
Epoch [42/50] - Loss: 0.0206
Epoch [43/50] - Loss: 0.0192
Epoch [44/50] - Loss: 0.0214
Epoch [45/50] - Loss: 0.0173
Epoch [46/50] - Loss: 0.0169
Epoch [47/50] - Loss: 0.0163
Epoch [48/50] - Loss: 0.0157
Epoch [49/50] - Loss: 0.0150
Epoch [50/50] - Loss: 0.0143
sum preds 573
sum labels 491
 - Test Metrics: Accuracy=0.8513, F1=0.6673, Recall=0.7230, Precision=0.6195
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_nnpu_nnpu_1804093143.csv.
Average F1 over valid seeds: 0.6706 ± 0.0144
___________________________________________________________________________________
Avg F1 for cora with SCAR and nnpu, MLP,0.4: 0.6706 ± 0.0144
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4982
Epoch [2/50] - Loss: 0.4586
Epoch [3/50] - Loss: 0.4221
Epoch [4/50] - Loss: 0.3877
Epoch [5/50] - Loss: 0.3559
Epoch [6/50] - Loss: 0.3271
Epoch [7/50] - Loss: 0.3018
Epoch [8/50] - Loss: 0.2797
Epoch [9/50] - Loss: 0.2601
Epoch [10/50] - Loss: 0.2419
Epoch [11/50] - Loss: 0.2244
Epoch [12/50] - Loss: 0.2067
Epoch [13/50] - Loss: 0.1881
Epoch [14/50] - Loss: 0.1744
Epoch [15/50] - Loss: 0.1591
Epoch [16/50] - Loss: 0.1414
Epoch [17/50] - Loss: 0.1226
Epoch [18/50] - Loss: 0.1116
Epoch [19/50] - Loss: 0.1067
Epoch [20/50] - Loss: 0.1002
Epoch [21/50] - Loss: 0.0899
Epoch [22/50] - Loss: 0.0762
Epoch [23/50] - Loss: 0.0690
Epoch [24/50] - Loss: 0.0664
Epoch [25/50] - Loss: 0.0629
Epoch [26/50] - Loss: 0.0586
Epoch [27/50] - Loss: 0.0540
Epoch [28/50] - Loss: 0.0493
Epoch [29/50] - Loss: 0.0447
Epoch [30/50] - Loss: 0.0405
Epoch [31/50] - Loss: 0.0415
Epoch [32/50] - Loss: 0.0395
Epoch [33/50] - Loss: 0.0350
Epoch [34/50] - Loss: 0.0346
Epoch [35/50] - Loss: 0.0339
Epoch [36/50] - Loss: 0.0331
Epoch [37/50] - Loss: 0.0321
Epoch [38/50] - Loss: 0.0310
Epoch [39/50] - Loss: 0.0298
Epoch [40/50] - Loss: 0.0286
Epoch [41/50] - Loss: 0.0274
Epoch [42/50] - Loss: 0.0261
Epoch [43/50] - Loss: 0.0250
Epoch [44/50] - Loss: 0.0286
Epoch [45/50] - Loss: 0.0239
Epoch [46/50] - Loss: 0.0237
Epoch [47/50] - Loss: 0.0235
Epoch [48/50] - Loss: 0.0232
Epoch [49/50] - Loss: 0.0228
Epoch [50/50] - Loss: 0.0225
sum preds 607
sum labels 491
 - Test Metrics: Accuracy=0.8849, F1=0.7505, Recall=0.8391, Precision=0.6787
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4985
Epoch [2/50] - Loss: 0.4779
Epoch [3/50] - Loss: 0.4574
Epoch [4/50] - Loss: 0.4358
Epoch [5/50] - Loss: 0.4130
Epoch [6/50] - Loss: 0.3897
Epoch [7/50] - Loss: 0.3665
Epoch [8/50] - Loss: 0.3433
Epoch [9/50] - Loss: 0.3204
Epoch [10/50] - Loss: 0.2976
Epoch [11/50] - Loss: 0.2748
Epoch [12/50] - Loss: 0.2524
Epoch [13/50] - Loss: 0.2305
Epoch [14/50] - Loss: 0.2090
Epoch [15/50] - Loss: 0.1878
Epoch [16/50] - Loss: 0.1668
Epoch [17/50] - Loss: 0.1466
Epoch [18/50] - Loss: 0.1278
Epoch [19/50] - Loss: 0.1107
Epoch [20/50] - Loss: 0.0952
Epoch [21/50] - Loss: 0.0843
Epoch [22/50] - Loss: 0.0755
Epoch [23/50] - Loss: 0.0661
Epoch [24/50] - Loss: 0.0570
Epoch [25/50] - Loss: 0.0514
Epoch [26/50] - Loss: 0.0458
Epoch [27/50] - Loss: 0.0410
Epoch [28/50] - Loss: 0.0365
Epoch [29/50] - Loss: 0.0333
Epoch [30/50] - Loss: 0.0302
Epoch [31/50] - Loss: 0.0271
Epoch [32/50] - Loss: 0.0261
Epoch [33/50] - Loss: 0.0227
Epoch [34/50] - Loss: 0.0211
Epoch [35/50] - Loss: 0.0196
Epoch [36/50] - Loss: 0.0182
Epoch [37/50] - Loss: 0.0189
Epoch [38/50] - Loss: 0.0163
Epoch [39/50] - Loss: 0.0157
Epoch [40/50] - Loss: 0.0151
Epoch [41/50] - Loss: 0.0144
Epoch [42/50] - Loss: 0.0136
Epoch [43/50] - Loss: 0.0129
Epoch [44/50] - Loss: 0.0122
Epoch [45/50] - Loss: 0.0115
Epoch [46/50] - Loss: 0.0132
Epoch [47/50] - Loss: 0.0108
Epoch [48/50] - Loss: 0.0106
Epoch [49/50] - Loss: 0.0104
Epoch [50/50] - Loss: 0.0102
sum preds 612
sum labels 491
 - Test Metrics: Accuracy=0.8963, F1=0.7761, Recall=0.8717, Precision=0.6993
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4975
Epoch [2/50] - Loss: 0.4663
Epoch [3/50] - Loss: 0.4354
Epoch [4/50] - Loss: 0.4031
Epoch [5/50] - Loss: 0.3705
Epoch [6/50] - Loss: 0.3388
Epoch [7/50] - Loss: 0.3087
Epoch [8/50] - Loss: 0.2804
Epoch [9/50] - Loss: 0.2540
Epoch [10/50] - Loss: 0.2292
Epoch [11/50] - Loss: 0.2054
Epoch [12/50] - Loss: 0.1822
Epoch [13/50] - Loss: 0.1596
Epoch [14/50] - Loss: 0.1379
Epoch [15/50] - Loss: 0.1182
Epoch [16/50] - Loss: 0.1045
Epoch [17/50] - Loss: 0.0900
Epoch [18/50] - Loss: 0.0814
Epoch [19/50] - Loss: 0.0753
Epoch [20/50] - Loss: 0.0673
Epoch [21/50] - Loss: 0.0567
Epoch [22/50] - Loss: 0.0536
Epoch [23/50] - Loss: 0.0509
Epoch [24/50] - Loss: 0.0474
Epoch [25/50] - Loss: 0.0434
Epoch [26/50] - Loss: 0.0392
Epoch [27/50] - Loss: 0.0349
Epoch [28/50] - Loss: 0.0306
Epoch [29/50] - Loss: 0.0315
Epoch [30/50] - Loss: 0.0288
Epoch [31/50] - Loss: 0.0243
Epoch [32/50] - Loss: 0.0236
Epoch [33/50] - Loss: 0.0225
Epoch [34/50] - Loss: 0.0212
Epoch [35/50] - Loss: 0.0196
Epoch [36/50] - Loss: 0.0181
Epoch [37/50] - Loss: 0.0165
Epoch [38/50] - Loss: 0.0150
Epoch [39/50] - Loss: 0.0136
Epoch [40/50] - Loss: 0.0150
Epoch [41/50] - Loss: 0.0120
Epoch [42/50] - Loss: 0.0117
Epoch [43/50] - Loss: 0.0113
Epoch [44/50] - Loss: 0.0107
Epoch [45/50] - Loss: 0.0101
Epoch [46/50] - Loss: 0.0095
Epoch [47/50] - Loss: 0.0088
Epoch [48/50] - Loss: 0.0081
Epoch [49/50] - Loss: 0.0075
Epoch [50/50] - Loss: 0.0092
sum preds 577
sum labels 491
 - Test Metrics: Accuracy=0.9168, F1=0.8146, Recall=0.8859, Precision=0.7539
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_nnpu_nnpu_1804093144.csv.
Average F1 over valid seeds: 0.7804 ± 0.0264
___________________________________________________________________________________
Avg F1 for cora with SCAR and nnpu, GATConv,0.4: 0.7804 ± 0.0264
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5020
Epoch [2/50] - Loss: 0.4694
Epoch [3/50] - Loss: 0.4403
Epoch [4/50] - Loss: 0.4123
Epoch [5/50] - Loss: 0.3850
Epoch [6/50] - Loss: 0.3588
Epoch [7/50] - Loss: 0.3340
Epoch [8/50] - Loss: 0.3109
Epoch [9/50] - Loss: 0.2896
Epoch [10/50] - Loss: 0.2698
Epoch [11/50] - Loss: 0.2510
Epoch [12/50] - Loss: 0.2327
Epoch [13/50] - Loss: 0.2149
Epoch [14/50] - Loss: 0.1973
Epoch [15/50] - Loss: 0.1800
Epoch [16/50] - Loss: 0.1630
Epoch [17/50] - Loss: 0.1466
Epoch [18/50] - Loss: 0.1311
Epoch [19/50] - Loss: 0.1168
Epoch [20/50] - Loss: 0.1037
Epoch [21/50] - Loss: 0.0940
Epoch [22/50] - Loss: 0.0838
Epoch [23/50] - Loss: 0.0771
Epoch [24/50] - Loss: 0.0718
Epoch [25/50] - Loss: 0.0654
Epoch [26/50] - Loss: 0.0577
Epoch [27/50] - Loss: 0.0562
Epoch [28/50] - Loss: 0.0539
Epoch [29/50] - Loss: 0.0505
Epoch [30/50] - Loss: 0.0465
Epoch [31/50] - Loss: 0.0421
Epoch [32/50] - Loss: 0.0384
Epoch [33/50] - Loss: 0.0367
Epoch [34/50] - Loss: 0.0349
Epoch [35/50] - Loss: 0.0338
Epoch [36/50] - Loss: 0.0323
Epoch [37/50] - Loss: 0.0304
Epoch [38/50] - Loss: 0.0283
Epoch [39/50] - Loss: 0.0301
Epoch [40/50] - Loss: 0.0273
Epoch [41/50] - Loss: 0.0261
Epoch [42/50] - Loss: 0.0263
Epoch [43/50] - Loss: 0.0261
Epoch [44/50] - Loss: 0.0256
Epoch [45/50] - Loss: 0.0248
Epoch [46/50] - Loss: 0.0237
Epoch [47/50] - Loss: 0.0224
Epoch [48/50] - Loss: 0.0211
Epoch [49/50] - Loss: 0.0197
Epoch [50/50] - Loss: 0.0206
sum preds 584
sum labels 491
 - Test Metrics: Accuracy=0.9156, F1=0.8130, Recall=0.8900, Precision=0.7483
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4945
Epoch [2/50] - Loss: 0.4609
Epoch [3/50] - Loss: 0.4258
Epoch [4/50] - Loss: 0.3901
Epoch [5/50] - Loss: 0.3562
Epoch [6/50] - Loss: 0.3255
Epoch [7/50] - Loss: 0.2983
Epoch [8/50] - Loss: 0.2741
Epoch [9/50] - Loss: 0.2522
Epoch [10/50] - Loss: 0.2316
Epoch [11/50] - Loss: 0.2118
Epoch [12/50] - Loss: 0.1921
Epoch [13/50] - Loss: 0.1726
Epoch [14/50] - Loss: 0.1536
Epoch [15/50] - Loss: 0.1355
Epoch [16/50] - Loss: 0.1188
Epoch [17/50] - Loss: 0.1059
Epoch [18/50] - Loss: 0.0930
Epoch [19/50] - Loss: 0.0848
Epoch [20/50] - Loss: 0.0786
Epoch [21/50] - Loss: 0.0717
Epoch [22/50] - Loss: 0.0633
Epoch [23/50] - Loss: 0.0576
Epoch [24/50] - Loss: 0.0544
Epoch [25/50] - Loss: 0.0505
Epoch [26/50] - Loss: 0.0460
Epoch [27/50] - Loss: 0.0413
Epoch [28/50] - Loss: 0.0425
Epoch [29/50] - Loss: 0.0403
Epoch [30/50] - Loss: 0.0338
Epoch [31/50] - Loss: 0.0327
Epoch [32/50] - Loss: 0.0312
Epoch [33/50] - Loss: 0.0294
Epoch [34/50] - Loss: 0.0273
Epoch [35/50] - Loss: 0.0287
Epoch [36/50] - Loss: 0.0251
Epoch [37/50] - Loss: 0.0252
Epoch [38/50] - Loss: 0.0254
Epoch [39/50] - Loss: 0.0253
Epoch [40/50] - Loss: 0.0247
Epoch [41/50] - Loss: 0.0239
Epoch [42/50] - Loss: 0.0228
Epoch [43/50] - Loss: 0.0216
Epoch [44/50] - Loss: 0.0202
Epoch [45/50] - Loss: 0.0188
Epoch [46/50] - Loss: 0.0173
Epoch [47/50] - Loss: 0.0175
Epoch [48/50] - Loss: 0.0156
Epoch [49/50] - Loss: 0.0152
Epoch [50/50] - Loss: 0.0147
sum preds 591
sum labels 491
 - Test Metrics: Accuracy=0.9227, F1=0.8299, Recall=0.9145, Precision=0.7597
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5021
Epoch [2/50] - Loss: 0.4779
Epoch [3/50] - Loss: 0.4516
Epoch [4/50] - Loss: 0.4228
Epoch [5/50] - Loss: 0.3932
Epoch [6/50] - Loss: 0.3645
Epoch [7/50] - Loss: 0.3374
Epoch [8/50] - Loss: 0.3126
Epoch [9/50] - Loss: 0.2902
Epoch [10/50] - Loss: 0.2700
Epoch [11/50] - Loss: 0.2514
Epoch [12/50] - Loss: 0.2340
Epoch [13/50] - Loss: 0.2172
Epoch [14/50] - Loss: 0.2009
Epoch [15/50] - Loss: 0.1849
Epoch [16/50] - Loss: 0.1687
Epoch [17/50] - Loss: 0.1527
Epoch [18/50] - Loss: 0.1370
Epoch [19/50] - Loss: 0.1237
Epoch [20/50] - Loss: 0.1109
Epoch [21/50] - Loss: 0.0974
Epoch [22/50] - Loss: 0.0887
Epoch [23/50] - Loss: 0.0812
Epoch [24/50] - Loss: 0.0740
Epoch [25/50] - Loss: 0.0662
Epoch [26/50] - Loss: 0.0625
Epoch [27/50] - Loss: 0.0585
Epoch [28/50] - Loss: 0.0539
Epoch [29/50] - Loss: 0.0489
Epoch [30/50] - Loss: 0.0462
Epoch [31/50] - Loss: 0.0436
Epoch [32/50] - Loss: 0.0400
Epoch [33/50] - Loss: 0.0383
Epoch [34/50] - Loss: 0.0363
Epoch [35/50] - Loss: 0.0340
Epoch [36/50] - Loss: 0.0318
Epoch [37/50] - Loss: 0.0307
Epoch [38/50] - Loss: 0.0295
Epoch [39/50] - Loss: 0.0280
Epoch [40/50] - Loss: 0.0265
Epoch [41/50] - Loss: 0.0262
Epoch [42/50] - Loss: 0.0256
Epoch [43/50] - Loss: 0.0247
Epoch [44/50] - Loss: 0.0237
Epoch [45/50] - Loss: 0.0226
Epoch [46/50] - Loss: 0.0213
Epoch [47/50] - Loss: 0.0241
Epoch [48/50] - Loss: 0.0207
Epoch [49/50] - Loss: 0.0207
Epoch [50/50] - Loss: 0.0212
sum preds 535
sum labels 491
 - Test Metrics: Accuracy=0.9362, F1=0.8519, Recall=0.8900, Precision=0.8168
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_nnpu_nnpu_1804093146.csv.
Average F1 over valid seeds: 0.8316 ± 0.0159
___________________________________________________________________________________
Avg F1 for cora with SCAR and nnpu, GCNConv,0.4: 0.8316 ± 0.0159
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4862
Epoch [3/50] - Loss: 0.4713
Epoch [4/50] - Loss: 0.4540
Epoch [5/50] - Loss: 0.4350
Epoch [6/50] - Loss: 0.4147
Epoch [7/50] - Loss: 0.3935
Epoch [8/50] - Loss: 0.3716
Epoch [9/50] - Loss: 0.3492
Epoch [10/50] - Loss: 0.3262
Epoch [11/50] - Loss: 0.3029
Epoch [12/50] - Loss: 0.2796
Epoch [13/50] - Loss: 0.2563
Epoch [14/50] - Loss: 0.2334
Epoch [15/50] - Loss: 0.2109
Epoch [16/50] - Loss: 0.1890
Epoch [17/50] - Loss: 0.1677
Epoch [18/50] - Loss: 0.1471
Epoch [19/50] - Loss: 0.1272
Epoch [20/50] - Loss: 0.1083
Epoch [21/50] - Loss: 0.1007
Epoch [22/50] - Loss: 0.0929
Epoch [23/50] - Loss: 0.0842
Epoch [24/50] - Loss: 0.0751
Epoch [25/50] - Loss: 0.0662
Epoch [26/50] - Loss: 0.0578
Epoch [27/50] - Loss: 0.0501
Epoch [28/50] - Loss: 0.0499
Epoch [29/50] - Loss: 0.0488
Epoch [30/50] - Loss: 0.0412
Epoch [31/50] - Loss: 0.0370
Epoch [32/50] - Loss: 0.0361
Epoch [33/50] - Loss: 0.0349
Epoch [34/50] - Loss: 0.0333
Epoch [35/50] - Loss: 0.0316
Epoch [36/50] - Loss: 0.0297
Epoch [37/50] - Loss: 0.0278
Epoch [38/50] - Loss: 0.0259
Epoch [39/50] - Loss: 0.0239
Epoch [40/50] - Loss: 0.0221
Epoch [41/50] - Loss: 0.0203
Epoch [42/50] - Loss: 0.0187
Epoch [43/50] - Loss: 0.0171
Epoch [44/50] - Loss: 0.0192
Epoch [45/50] - Loss: 0.0152
Epoch [46/50] - Loss: 0.0147
Epoch [47/50] - Loss: 0.0141
Epoch [48/50] - Loss: 0.0135
Epoch [49/50] - Loss: 0.0129
Epoch [50/50] - Loss: 0.0123
sum preds 582
sum labels 573
 - Test Metrics: Accuracy=0.8242, F1=0.6251, Recall=0.6300, Precision=0.6203
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5019
Epoch [2/50] - Loss: 0.4843
Epoch [3/50] - Loss: 0.4657
Epoch [4/50] - Loss: 0.4451
Epoch [5/50] - Loss: 0.4230
Epoch [6/50] - Loss: 0.3998
Epoch [7/50] - Loss: 0.3761
Epoch [8/50] - Loss: 0.3520
Epoch [9/50] - Loss: 0.3280
Epoch [10/50] - Loss: 0.3039
Epoch [11/50] - Loss: 0.2799
Epoch [12/50] - Loss: 0.2564
Epoch [13/50] - Loss: 0.2333
Epoch [14/50] - Loss: 0.2108
Epoch [15/50] - Loss: 0.1889
Epoch [16/50] - Loss: 0.1677
Epoch [17/50] - Loss: 0.1474
Epoch [18/50] - Loss: 0.1278
Epoch [19/50] - Loss: 0.1092
Epoch [20/50] - Loss: 0.1026
Epoch [21/50] - Loss: 0.0946
Epoch [22/50] - Loss: 0.0858
Epoch [23/50] - Loss: 0.0767
Epoch [24/50] - Loss: 0.0677
Epoch [25/50] - Loss: 0.0591
Epoch [26/50] - Loss: 0.0512
Epoch [27/50] - Loss: 0.0510
Epoch [28/50] - Loss: 0.0503
Epoch [29/50] - Loss: 0.0437
Epoch [30/50] - Loss: 0.0368
Epoch [31/50] - Loss: 0.0356
Epoch [32/50] - Loss: 0.0340
Epoch [33/50] - Loss: 0.0321
Epoch [34/50] - Loss: 0.0301
Epoch [35/50] - Loss: 0.0279
Epoch [36/50] - Loss: 0.0256
Epoch [37/50] - Loss: 0.0234
Epoch [38/50] - Loss: 0.0213
Epoch [39/50] - Loss: 0.0192
Epoch [40/50] - Loss: 0.0173
Epoch [41/50] - Loss: 0.0220
Epoch [42/50] - Loss: 0.0172
Epoch [43/50] - Loss: 0.0151
Epoch [44/50] - Loss: 0.0151
Epoch [45/50] - Loss: 0.0149
Epoch [46/50] - Loss: 0.0147
Epoch [47/50] - Loss: 0.0143
Epoch [48/50] - Loss: 0.0139
Epoch [49/50] - Loss: 0.0134
Epoch [50/50] - Loss: 0.0129
sum preds 506
sum labels 573
 - Test Metrics: Accuracy=0.8567, F1=0.6728, Recall=0.6335, Precision=0.7174
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5131
Epoch [2/50] - Loss: 0.4990
Epoch [3/50] - Loss: 0.4853
Epoch [4/50] - Loss: 0.4695
Epoch [5/50] - Loss: 0.4519
Epoch [6/50] - Loss: 0.4326
Epoch [7/50] - Loss: 0.4122
Epoch [8/50] - Loss: 0.3909
Epoch [9/50] - Loss: 0.3689
Epoch [10/50] - Loss: 0.3460
Epoch [11/50] - Loss: 0.3224
Epoch [12/50] - Loss: 0.2984
Epoch [13/50] - Loss: 0.2742
Epoch [14/50] - Loss: 0.2502
Epoch [15/50] - Loss: 0.2266
Epoch [16/50] - Loss: 0.2034
Epoch [17/50] - Loss: 0.1809
Epoch [18/50] - Loss: 0.1591
Epoch [19/50] - Loss: 0.1382
Epoch [20/50] - Loss: 0.1180
Epoch [21/50] - Loss: 0.0989
Epoch [22/50] - Loss: 0.0925
Epoch [23/50] - Loss: 0.0853
Epoch [24/50] - Loss: 0.0772
Epoch [25/50] - Loss: 0.0687
Epoch [26/50] - Loss: 0.0603
Epoch [27/50] - Loss: 0.0525
Epoch [28/50] - Loss: 0.0454
Epoch [29/50] - Loss: 0.0397
Epoch [30/50] - Loss: 0.0383
Epoch [31/50] - Loss: 0.0341
Epoch [32/50] - Loss: 0.0323
Epoch [33/50] - Loss: 0.0303
Epoch [34/50] - Loss: 0.0283
Epoch [35/50] - Loss: 0.0262
Epoch [36/50] - Loss: 0.0242
Epoch [37/50] - Loss: 0.0222
Epoch [38/50] - Loss: 0.0237
Epoch [39/50] - Loss: 0.0197
Epoch [40/50] - Loss: 0.0190
Epoch [41/50] - Loss: 0.0182
Epoch [42/50] - Loss: 0.0173
Epoch [43/50] - Loss: 0.0164
Epoch [44/50] - Loss: 0.0155
Epoch [45/50] - Loss: 0.0146
Epoch [46/50] - Loss: 0.0137
Epoch [47/50] - Loss: 0.0129
Epoch [48/50] - Loss: 0.0121
Epoch [49/50] - Loss: 0.0140
Epoch [50/50] - Loss: 0.0113
sum preds 555
sum labels 573
 - Test Metrics: Accuracy=0.8449, F1=0.6613, Recall=0.6510, Precision=0.6721
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_nnpu_nnpu_1804093148.csv.
Average F1 over valid seeds: 0.6531 ± 0.0203
___________________________________________________________________________________
Avg F1 for cora with SCAR and nnpu, MLP,0.3: 0.6531 ± 0.0203
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4980
Epoch [2/50] - Loss: 0.4593
Epoch [3/50] - Loss: 0.4236
Epoch [4/50] - Loss: 0.3898
Epoch [5/50] - Loss: 0.3584
Epoch [6/50] - Loss: 0.3301
Epoch [7/50] - Loss: 0.3052
Epoch [8/50] - Loss: 0.2833
Epoch [9/50] - Loss: 0.2641
Epoch [10/50] - Loss: 0.2464
Epoch [11/50] - Loss: 0.2296
Epoch [12/50] - Loss: 0.2128
Epoch [13/50] - Loss: 0.1954
Epoch [14/50] - Loss: 0.1788
Epoch [15/50] - Loss: 0.1640
Epoch [16/50] - Loss: 0.1464
Epoch [17/50] - Loss: 0.1291
Epoch [18/50] - Loss: 0.1191
Epoch [19/50] - Loss: 0.1100
Epoch [20/50] - Loss: 0.1001
Epoch [21/50] - Loss: 0.0885
Epoch [22/50] - Loss: 0.0803
Epoch [23/50] - Loss: 0.0754
Epoch [24/50] - Loss: 0.0696
Epoch [25/50] - Loss: 0.0635
Epoch [26/50] - Loss: 0.0573
Epoch [27/50] - Loss: 0.0579
Epoch [28/50] - Loss: 0.0546
Epoch [29/50] - Loss: 0.0479
Epoch [30/50] - Loss: 0.0466
Epoch [31/50] - Loss: 0.0451
Epoch [32/50] - Loss: 0.0433
Epoch [33/50] - Loss: 0.0413
Epoch [34/50] - Loss: 0.0391
Epoch [35/50] - Loss: 0.0368
Epoch [36/50] - Loss: 0.0393
Epoch [37/50] - Loss: 0.0355
Epoch [38/50] - Loss: 0.0337
Epoch [39/50] - Loss: 0.0336
Epoch [40/50] - Loss: 0.0331
Epoch [41/50] - Loss: 0.0322
Epoch [42/50] - Loss: 0.0311
Epoch [43/50] - Loss: 0.0298
Epoch [44/50] - Loss: 0.0285
Epoch [45/50] - Loss: 0.0270
Epoch [46/50] - Loss: 0.0255
Epoch [47/50] - Loss: 0.0238
Epoch [48/50] - Loss: 0.0222
Epoch [49/50] - Loss: 0.0285
Epoch [50/50] - Loss: 0.0241
sum preds 618
sum labels 573
 - Test Metrics: Accuracy=0.8762, F1=0.7439, Recall=0.7731, Precision=0.7168
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4985
Epoch [2/50] - Loss: 0.4780
Epoch [3/50] - Loss: 0.4577
Epoch [4/50] - Loss: 0.4363
Epoch [5/50] - Loss: 0.4140
Epoch [6/50] - Loss: 0.3914
Epoch [7/50] - Loss: 0.3687
Epoch [8/50] - Loss: 0.3463
Epoch [9/50] - Loss: 0.3241
Epoch [10/50] - Loss: 0.3023
Epoch [11/50] - Loss: 0.2809
Epoch [12/50] - Loss: 0.2599
Epoch [13/50] - Loss: 0.2393
Epoch [14/50] - Loss: 0.2189
Epoch [15/50] - Loss: 0.1988
Epoch [16/50] - Loss: 0.1789
Epoch [17/50] - Loss: 0.1595
Epoch [18/50] - Loss: 0.1410
Epoch [19/50] - Loss: 0.1239
Epoch [20/50] - Loss: 0.1082
Epoch [21/50] - Loss: 0.0935
Epoch [22/50] - Loss: 0.0797
Epoch [23/50] - Loss: 0.0735
Epoch [24/50] - Loss: 0.0656
Epoch [25/50] - Loss: 0.0571
Epoch [26/50] - Loss: 0.0489
Epoch [27/50] - Loss: 0.0449
Epoch [28/50] - Loss: 0.0417
Epoch [29/50] - Loss: 0.0358
Epoch [30/50] - Loss: 0.0321
Epoch [31/50] - Loss: 0.0302
Epoch [32/50] - Loss: 0.0282
Epoch [33/50] - Loss: 0.0260
Epoch [34/50] - Loss: 0.0240
Epoch [35/50] - Loss: 0.0220
Epoch [36/50] - Loss: 0.0202
Epoch [37/50] - Loss: 0.0185
Epoch [38/50] - Loss: 0.0193
Epoch [39/50] - Loss: 0.0168
Epoch [40/50] - Loss: 0.0159
Epoch [41/50] - Loss: 0.0155
Epoch [42/50] - Loss: 0.0150
Epoch [43/50] - Loss: 0.0144
Epoch [44/50] - Loss: 0.0137
Epoch [45/50] - Loss: 0.0129
Epoch [46/50] - Loss: 0.0121
Epoch [47/50] - Loss: 0.0113
Epoch [48/50] - Loss: 0.0106
Epoch [49/50] - Loss: 0.0100
Epoch [50/50] - Loss: 0.0094
sum preds 649
sum labels 573
 - Test Metrics: Accuracy=0.9034, F1=0.8052, Recall=0.8586, Precision=0.7581
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4978
Epoch [2/50] - Loss: 0.4670
Epoch [3/50] - Loss: 0.4369
Epoch [4/50] - Loss: 0.4055
Epoch [5/50] - Loss: 0.3744
Epoch [6/50] - Loss: 0.3445
Epoch [7/50] - Loss: 0.3164
Epoch [8/50] - Loss: 0.2901
Epoch [9/50] - Loss: 0.2656
Epoch [10/50] - Loss: 0.2425
Epoch [11/50] - Loss: 0.2202
Epoch [12/50] - Loss: 0.1981
Epoch [13/50] - Loss: 0.1764
Epoch [14/50] - Loss: 0.1553
Epoch [15/50] - Loss: 0.1352
Epoch [16/50] - Loss: 0.1167
Epoch [17/50] - Loss: 0.1048
Epoch [18/50] - Loss: 0.0921
Epoch [19/50] - Loss: 0.0791
Epoch [20/50] - Loss: 0.0749
Epoch [21/50] - Loss: 0.0709
Epoch [22/50] - Loss: 0.0639
Epoch [23/50] - Loss: 0.0537
Epoch [24/50] - Loss: 0.0493
Epoch [25/50] - Loss: 0.0473
Epoch [26/50] - Loss: 0.0444
Epoch [27/50] - Loss: 0.0408
Epoch [28/50] - Loss: 0.0368
Epoch [29/50] - Loss: 0.0327
Epoch [30/50] - Loss: 0.0286
Epoch [31/50] - Loss: 0.0248
Epoch [32/50] - Loss: 0.0308
Epoch [33/50] - Loss: 0.0283
Epoch [34/50] - Loss: 0.0195
Epoch [35/50] - Loss: 0.0190
Epoch [36/50] - Loss: 0.0182
Epoch [37/50] - Loss: 0.0172
Epoch [38/50] - Loss: 0.0160
Epoch [39/50] - Loss: 0.0148
Epoch [40/50] - Loss: 0.0136
Epoch [41/50] - Loss: 0.0125
Epoch [42/50] - Loss: 0.0115
Epoch [43/50] - Loss: 0.0106
Epoch [44/50] - Loss: 0.0098
Epoch [45/50] - Loss: 0.0102
Epoch [46/50] - Loss: 0.0090
Epoch [47/50] - Loss: 0.0089
Epoch [48/50] - Loss: 0.0087
Epoch [49/50] - Loss: 0.0085
Epoch [50/50] - Loss: 0.0083
sum preds 590
sum labels 573
 - Test Metrics: Accuracy=0.9176, F1=0.8255, Recall=0.8377, Precision=0.8136
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_nnpu_nnpu_1804093149.csv.
Average F1 over valid seeds: 0.7915 ± 0.0347
___________________________________________________________________________________
Avg F1 for cora with SCAR and nnpu, GATConv,0.3: 0.7915 ± 0.0347
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5015
Epoch [2/50] - Loss: 0.4698
Epoch [3/50] - Loss: 0.4412
Epoch [4/50] - Loss: 0.4136
Epoch [5/50] - Loss: 0.3864
Epoch [6/50] - Loss: 0.3600
Epoch [7/50] - Loss: 0.3350
Epoch [8/50] - Loss: 0.3115
Epoch [9/50] - Loss: 0.2896
Epoch [10/50] - Loss: 0.2691
Epoch [11/50] - Loss: 0.2496
Epoch [12/50] - Loss: 0.2305
Epoch [13/50] - Loss: 0.2121
Epoch [14/50] - Loss: 0.1942
Epoch [15/50] - Loss: 0.1768
Epoch [16/50] - Loss: 0.1601
Epoch [17/50] - Loss: 0.1443
Epoch [18/50] - Loss: 0.1295
Epoch [19/50] - Loss: 0.1157
Epoch [20/50] - Loss: 0.1030
Epoch [21/50] - Loss: 0.0920
Epoch [22/50] - Loss: 0.0826
Epoch [23/50] - Loss: 0.0767
Epoch [24/50] - Loss: 0.0714
Epoch [25/50] - Loss: 0.0649
Epoch [26/50] - Loss: 0.0582
Epoch [27/50] - Loss: 0.0545
Epoch [28/50] - Loss: 0.0500
Epoch [29/50] - Loss: 0.0486
Epoch [30/50] - Loss: 0.0451
Epoch [31/50] - Loss: 0.0418
Epoch [32/50] - Loss: 0.0403
Epoch [33/50] - Loss: 0.0382
Epoch [34/50] - Loss: 0.0357
Epoch [35/50] - Loss: 0.0332
Epoch [36/50] - Loss: 0.0318
Epoch [37/50] - Loss: 0.0304
Epoch [38/50] - Loss: 0.0293
Epoch [39/50] - Loss: 0.0284
Epoch [40/50] - Loss: 0.0278
Epoch [41/50] - Loss: 0.0268
Epoch [42/50] - Loss: 0.0255
Epoch [43/50] - Loss: 0.0241
Epoch [44/50] - Loss: 0.0257
Epoch [45/50] - Loss: 0.0226
Epoch [46/50] - Loss: 0.0231
Epoch [47/50] - Loss: 0.0237
Epoch [48/50] - Loss: 0.0238
Epoch [49/50] - Loss: 0.0236
Epoch [50/50] - Loss: 0.0231
sum preds 579
sum labels 573
 - Test Metrics: Accuracy=0.9131, F1=0.8142, Recall=0.8185, Precision=0.8100
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4944
Epoch [2/50] - Loss: 0.4616
Epoch [3/50] - Loss: 0.4273
Epoch [4/50] - Loss: 0.3924
Epoch [5/50] - Loss: 0.3592
Epoch [6/50] - Loss: 0.3290
Epoch [7/50] - Loss: 0.3022
Epoch [8/50] - Loss: 0.2783
Epoch [9/50] - Loss: 0.2564
Epoch [10/50] - Loss: 0.2360
Epoch [11/50] - Loss: 0.2163
Epoch [12/50] - Loss: 0.1971
Epoch [13/50] - Loss: 0.1783
Epoch [14/50] - Loss: 0.1601
Epoch [15/50] - Loss: 0.1429
Epoch [16/50] - Loss: 0.1270
Epoch [17/50] - Loss: 0.1126
Epoch [18/50] - Loss: 0.0996
Epoch [19/50] - Loss: 0.0896
Epoch [20/50] - Loss: 0.0797
Epoch [21/50] - Loss: 0.0740
Epoch [22/50] - Loss: 0.0689
Epoch [23/50] - Loss: 0.0627
Epoch [24/50] - Loss: 0.0551
Epoch [25/50] - Loss: 0.0538
Epoch [26/50] - Loss: 0.0516
Epoch [27/50] - Loss: 0.0484
Epoch [28/50] - Loss: 0.0446
Epoch [29/50] - Loss: 0.0405
Epoch [30/50] - Loss: 0.0362
Epoch [31/50] - Loss: 0.0384
Epoch [32/50] - Loss: 0.0376
Epoch [33/50] - Loss: 0.0326
Epoch [34/50] - Loss: 0.0301
Epoch [35/50] - Loss: 0.0303
Epoch [36/50] - Loss: 0.0298
Epoch [37/50] - Loss: 0.0289
Epoch [38/50] - Loss: 0.0276
Epoch [39/50] - Loss: 0.0261
Epoch [40/50] - Loss: 0.0243
Epoch [41/50] - Loss: 0.0223
Epoch [42/50] - Loss: 0.0204
Epoch [43/50] - Loss: 0.0216
Epoch [44/50] - Loss: 0.0205
Epoch [45/50] - Loss: 0.0181
Epoch [46/50] - Loss: 0.0182
Epoch [47/50] - Loss: 0.0180
Epoch [48/50] - Loss: 0.0175
Epoch [49/50] - Loss: 0.0169
Epoch [50/50] - Loss: 0.0161
sum preds 621
sum labels 573
 - Test Metrics: Accuracy=0.9310, F1=0.8576, Recall=0.8935, Precision=0.8245
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5022
Epoch [2/50] - Loss: 0.4784
Epoch [3/50] - Loss: 0.4525
Epoch [4/50] - Loss: 0.4245
Epoch [5/50] - Loss: 0.3959
Epoch [6/50] - Loss: 0.3681
Epoch [7/50] - Loss: 0.3422
Epoch [8/50] - Loss: 0.3185
Epoch [9/50] - Loss: 0.2971
Epoch [10/50] - Loss: 0.2777
Epoch [11/50] - Loss: 0.2599
Epoch [12/50] - Loss: 0.2433
Epoch [13/50] - Loss: 0.2275
Epoch [14/50] - Loss: 0.2120
Epoch [15/50] - Loss: 0.1967
Epoch [16/50] - Loss: 0.1813
Epoch [17/50] - Loss: 0.1661
Epoch [18/50] - Loss: 0.1512
Epoch [19/50] - Loss: 0.1368
Epoch [20/50] - Loss: 0.1232
Epoch [21/50] - Loss: 0.1107
Epoch [22/50] - Loss: 0.0997
Epoch [23/50] - Loss: 0.0905
Epoch [24/50] - Loss: 0.0824
Epoch [25/50] - Loss: 0.0747
Epoch [26/50] - Loss: 0.0687
Epoch [27/50] - Loss: 0.0628
Epoch [28/50] - Loss: 0.0590
Epoch [29/50] - Loss: 0.0548
Epoch [30/50] - Loss: 0.0503
Epoch [31/50] - Loss: 0.0474
Epoch [32/50] - Loss: 0.0440
Epoch [33/50] - Loss: 0.0432
Epoch [34/50] - Loss: 0.0400
Epoch [35/50] - Loss: 0.0381
Epoch [36/50] - Loss: 0.0371
Epoch [37/50] - Loss: 0.0357
Epoch [38/50] - Loss: 0.0339
Epoch [39/50] - Loss: 0.0319
Epoch [40/50] - Loss: 0.0297
Epoch [41/50] - Loss: 0.0310
Epoch [42/50] - Loss: 0.0290
Epoch [43/50] - Loss: 0.0271
Epoch [44/50] - Loss: 0.0271
Epoch [45/50] - Loss: 0.0267
Epoch [46/50] - Loss: 0.0261
Epoch [47/50] - Loss: 0.0253
Epoch [48/50] - Loss: 0.0243
Epoch [49/50] - Loss: 0.0231
Epoch [50/50] - Loss: 0.0219
sum preds 607
sum labels 573
 - Test Metrics: Accuracy=0.9359, F1=0.8661, Recall=0.8918, Precision=0.8418
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_nnpu_nnpu_1804093150.csv.
Average F1 over valid seeds: 0.8460 ± 0.0227
___________________________________________________________________________________
Avg F1 for cora with SCAR and nnpu, GCNConv,0.3: 0.8460 ± 0.0227
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4996
Epoch [2/50] - Loss: 0.4851
Epoch [3/50] - Loss: 0.4689
Epoch [4/50] - Loss: 0.4503
Epoch [5/50] - Loss: 0.4300
Epoch [6/50] - Loss: 0.4083
Epoch [7/50] - Loss: 0.3855
Epoch [8/50] - Loss: 0.3617
Epoch [9/50] - Loss: 0.3371
Epoch [10/50] - Loss: 0.3118
Epoch [11/50] - Loss: 0.2860
Epoch [12/50] - Loss: 0.2600
Epoch [13/50] - Loss: 0.2339
Epoch [14/50] - Loss: 0.2081
Epoch [15/50] - Loss: 0.1827
Epoch [16/50] - Loss: 0.1579
Epoch [17/50] - Loss: 0.1339
Epoch [18/50] - Loss: 0.1108
Epoch [19/50] - Loss: 0.0920
Epoch [20/50] - Loss: 0.0844
Epoch [21/50] - Loss: 0.0759
Epoch [22/50] - Loss: 0.0672
Epoch [23/50] - Loss: 0.0587
Epoch [24/50] - Loss: 0.0508
Epoch [25/50] - Loss: 0.0437
Epoch [26/50] - Loss: 0.0374
Epoch [27/50] - Loss: 0.0330
Epoch [28/50] - Loss: 0.0301
Epoch [29/50] - Loss: 0.0278
Epoch [30/50] - Loss: 0.0263
Epoch [31/50] - Loss: 0.0247
Epoch [32/50] - Loss: 0.0231
Epoch [33/50] - Loss: 0.0216
Epoch [34/50] - Loss: 0.0201
Epoch [35/50] - Loss: 0.0186
Epoch [36/50] - Loss: 0.0172
Epoch [37/50] - Loss: 0.0159
Epoch [38/50] - Loss: 0.0147
Epoch [39/50] - Loss: 0.0136
Epoch [40/50] - Loss: 0.0126
Epoch [41/50] - Loss: 0.0116
Epoch [42/50] - Loss: 0.0128
Epoch [43/50] - Loss: 0.0104
Epoch [44/50] - Loss: 0.0101
Epoch [45/50] - Loss: 0.0098
Epoch [46/50] - Loss: 0.0095
Epoch [47/50] - Loss: 0.0091
Epoch [48/50] - Loss: 0.0088
Epoch [49/50] - Loss: 0.0084
Epoch [50/50] - Loss: 0.0081
sum preds 560
sum labels 654
 - Test Metrics: Accuracy=0.8153, F1=0.6129, Recall=0.5688, Precision=0.6643
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5022
Epoch [2/50] - Loss: 0.4839
Epoch [3/50] - Loss: 0.4646
Epoch [4/50] - Loss: 0.4432
Epoch [5/50] - Loss: 0.4203
Epoch [6/50] - Loss: 0.3961
Epoch [7/50] - Loss: 0.3714
Epoch [8/50] - Loss: 0.3462
Epoch [9/50] - Loss: 0.3208
Epoch [10/50] - Loss: 0.2955
Epoch [11/50] - Loss: 0.2703
Epoch [12/50] - Loss: 0.2453
Epoch [13/50] - Loss: 0.2207
Epoch [14/50] - Loss: 0.1967
Epoch [15/50] - Loss: 0.1733
Epoch [16/50] - Loss: 0.1506
Epoch [17/50] - Loss: 0.1287
Epoch [18/50] - Loss: 0.1080
Epoch [19/50] - Loss: 0.0999
Epoch [20/50] - Loss: 0.0908
Epoch [21/50] - Loss: 0.0813
Epoch [22/50] - Loss: 0.0718
Epoch [23/50] - Loss: 0.0627
Epoch [24/50] - Loss: 0.0542
Epoch [25/50] - Loss: 0.0465
Epoch [26/50] - Loss: 0.0497
Epoch [27/50] - Loss: 0.0481
Epoch [28/50] - Loss: 0.0395
Epoch [29/50] - Loss: 0.0323
Epoch [30/50] - Loss: 0.0311
Epoch [31/50] - Loss: 0.0295
Epoch [32/50] - Loss: 0.0278
Epoch [33/50] - Loss: 0.0260
Epoch [34/50] - Loss: 0.0241
Epoch [35/50] - Loss: 0.0222
Epoch [36/50] - Loss: 0.0204
Epoch [37/50] - Loss: 0.0187
Epoch [38/50] - Loss: 0.0172
Epoch [39/50] - Loss: 0.0158
Epoch [40/50] - Loss: 0.0145
Epoch [41/50] - Loss: 0.0133
Epoch [42/50] - Loss: 0.0123
Epoch [43/50] - Loss: 0.0114
Epoch [44/50] - Loss: 0.0126
Epoch [45/50] - Loss: 0.0104
Epoch [46/50] - Loss: 0.0102
Epoch [47/50] - Loss: 0.0100
Epoch [48/50] - Loss: 0.0098
Epoch [49/50] - Loss: 0.0095
Epoch [50/50] - Loss: 0.0092
sum preds 582
sum labels 654
 - Test Metrics: Accuracy=0.8294, F1=0.6489, Recall=0.6131, Precision=0.6890
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5129
Epoch [2/50] - Loss: 0.4980
Epoch [3/50] - Loss: 0.4833
Epoch [4/50] - Loss: 0.4667
Epoch [5/50] - Loss: 0.4482
Epoch [6/50] - Loss: 0.4283
Epoch [7/50] - Loss: 0.4072
Epoch [8/50] - Loss: 0.3850
Epoch [9/50] - Loss: 0.3620
Epoch [10/50] - Loss: 0.3381
Epoch [11/50] - Loss: 0.3136
Epoch [12/50] - Loss: 0.2885
Epoch [13/50] - Loss: 0.2633
Epoch [14/50] - Loss: 0.2383
Epoch [15/50] - Loss: 0.2135
Epoch [16/50] - Loss: 0.1893
Epoch [17/50] - Loss: 0.1658
Epoch [18/50] - Loss: 0.1432
Epoch [19/50] - Loss: 0.1215
Epoch [20/50] - Loss: 0.1007
Epoch [21/50] - Loss: 0.0952
Epoch [22/50] - Loss: 0.0889
Epoch [23/50] - Loss: 0.0817
Epoch [24/50] - Loss: 0.0741
Epoch [25/50] - Loss: 0.0665
Epoch [26/50] - Loss: 0.0591
Epoch [27/50] - Loss: 0.0522
Epoch [28/50] - Loss: 0.0459
Epoch [29/50] - Loss: 0.0402
Epoch [30/50] - Loss: 0.0358
Epoch [31/50] - Loss: 0.0337
Epoch [32/50] - Loss: 0.0314
Epoch [33/50] - Loss: 0.0301
Epoch [34/50] - Loss: 0.0286
Epoch [35/50] - Loss: 0.0271
Epoch [36/50] - Loss: 0.0255
Epoch [37/50] - Loss: 0.0239
Epoch [38/50] - Loss: 0.0224
Epoch [39/50] - Loss: 0.0209
Epoch [40/50] - Loss: 0.0195
Epoch [41/50] - Loss: 0.0181
Epoch [42/50] - Loss: 0.0169
Epoch [43/50] - Loss: 0.0157
Epoch [44/50] - Loss: 0.0169
Epoch [45/50] - Loss: 0.0143
Epoch [46/50] - Loss: 0.0140
Epoch [47/50] - Loss: 0.0136
Epoch [48/50] - Loss: 0.0132
Epoch [49/50] - Loss: 0.0127
Epoch [50/50] - Loss: 0.0122
sum preds 530
sum labels 654
 - Test Metrics: Accuracy=0.8192, F1=0.6115, Recall=0.5535, Precision=0.6830
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_nnpu_nnpu_1804093152.csv.
Average F1 over valid seeds: 0.6244 ± 0.0173
___________________________________________________________________________________
Avg F1 for cora with SCAR and nnpu, MLP,0.2: 0.6244 ± 0.0173
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4980
Epoch [2/50] - Loss: 0.4596
Epoch [3/50] - Loss: 0.4241
Epoch [4/50] - Loss: 0.3904
Epoch [5/50] - Loss: 0.3589
Epoch [6/50] - Loss: 0.3304
Epoch [7/50] - Loss: 0.3051
Epoch [8/50] - Loss: 0.2827
Epoch [9/50] - Loss: 0.2630
Epoch [10/50] - Loss: 0.2449
Epoch [11/50] - Loss: 0.2276
Epoch [12/50] - Loss: 0.2103
Epoch [13/50] - Loss: 0.1927
Epoch [14/50] - Loss: 0.1782
Epoch [15/50] - Loss: 0.1642
Epoch [16/50] - Loss: 0.1474
Epoch [17/50] - Loss: 0.1292
Epoch [18/50] - Loss: 0.1209
Epoch [19/50] - Loss: 0.1169
Epoch [20/50] - Loss: 0.1116
Epoch [21/50] - Loss: 0.1030
Epoch [22/50] - Loss: 0.0910
Epoch [23/50] - Loss: 0.0786
Epoch [24/50] - Loss: 0.0764
Epoch [25/50] - Loss: 0.0728
Epoch [26/50] - Loss: 0.0681
Epoch [27/50] - Loss: 0.0628
Epoch [28/50] - Loss: 0.0572
Epoch [29/50] - Loss: 0.0538
Epoch [30/50] - Loss: 0.0510
Epoch [31/50] - Loss: 0.0482
Epoch [32/50] - Loss: 0.0469
Epoch [33/50] - Loss: 0.0452
Epoch [34/50] - Loss: 0.0432
Epoch [35/50] - Loss: 0.0411
Epoch [36/50] - Loss: 0.0389
Epoch [37/50] - Loss: 0.0370
Epoch [38/50] - Loss: 0.0358
Epoch [39/50] - Loss: 0.0348
Epoch [40/50] - Loss: 0.0335
Epoch [41/50] - Loss: 0.0320
Epoch [42/50] - Loss: 0.0304
Epoch [43/50] - Loss: 0.0324
Epoch [44/50] - Loss: 0.0286
Epoch [45/50] - Loss: 0.0283
Epoch [46/50] - Loss: 0.0279
Epoch [47/50] - Loss: 0.0274
Epoch [48/50] - Loss: 0.0268
Epoch [49/50] - Loss: 0.0262
Epoch [50/50] - Loss: 0.0256
sum preds 628
sum labels 654
 - Test Metrics: Accuracy=0.8750, F1=0.7520, Recall=0.7370, Precision=0.7675
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4982
Epoch [2/50] - Loss: 0.4776
Epoch [3/50] - Loss: 0.4571
Epoch [4/50] - Loss: 0.4353
Epoch [5/50] - Loss: 0.4128
Epoch [6/50] - Loss: 0.3898
Epoch [7/50] - Loss: 0.3667
Epoch [8/50] - Loss: 0.3438
Epoch [9/50] - Loss: 0.3210
Epoch [10/50] - Loss: 0.2987
Epoch [11/50] - Loss: 0.2767
Epoch [12/50] - Loss: 0.2551
Epoch [13/50] - Loss: 0.2338
Epoch [14/50] - Loss: 0.2128
Epoch [15/50] - Loss: 0.1919
Epoch [16/50] - Loss: 0.1713
Epoch [17/50] - Loss: 0.1512
Epoch [18/50] - Loss: 0.1319
Epoch [19/50] - Loss: 0.1140
Epoch [20/50] - Loss: 0.0981
Epoch [21/50] - Loss: 0.0874
Epoch [22/50] - Loss: 0.0767
Epoch [23/50] - Loss: 0.0683
Epoch [24/50] - Loss: 0.0608
Epoch [25/50] - Loss: 0.0537
Epoch [26/50] - Loss: 0.0491
Epoch [27/50] - Loss: 0.0428
Epoch [28/50] - Loss: 0.0383
Epoch [29/50] - Loss: 0.0347
Epoch [30/50] - Loss: 0.0307
Epoch [31/50] - Loss: 0.0268
Epoch [32/50] - Loss: 0.0232
Epoch [33/50] - Loss: 0.0253
Epoch [34/50] - Loss: 0.0220
Epoch [35/50] - Loss: 0.0178
Epoch [36/50] - Loss: 0.0171
Epoch [37/50] - Loss: 0.0162
Epoch [38/50] - Loss: 0.0152
Epoch [39/50] - Loss: 0.0142
Epoch [40/50] - Loss: 0.0132
Epoch [41/50] - Loss: 0.0122
Epoch [42/50] - Loss: 0.0112
Epoch [43/50] - Loss: 0.0103
Epoch [44/50] - Loss: 0.0095
Epoch [45/50] - Loss: 0.0087
Epoch [46/50] - Loss: 0.0079
Epoch [47/50] - Loss: 0.0072
Epoch [48/50] - Loss: 0.0076
Epoch [49/50] - Loss: 0.0062
Epoch [50/50] - Loss: 0.0059
sum preds 680
sum labels 654
 - Test Metrics: Accuracy=0.8915, F1=0.7931, Recall=0.8089, Precision=0.7779
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4972
Epoch [2/50] - Loss: 0.4665
Epoch [3/50] - Loss: 0.4367
Epoch [4/50] - Loss: 0.4057
Epoch [5/50] - Loss: 0.3748
Epoch [6/50] - Loss: 0.3450
Epoch [7/50] - Loss: 0.3168
Epoch [8/50] - Loss: 0.2905
Epoch [9/50] - Loss: 0.2660
Epoch [10/50] - Loss: 0.2430
Epoch [11/50] - Loss: 0.2208
Epoch [12/50] - Loss: 0.1987
Epoch [13/50] - Loss: 0.1767
Epoch [14/50] - Loss: 0.1551
Epoch [15/50] - Loss: 0.1346
Epoch [16/50] - Loss: 0.1195
Epoch [17/50] - Loss: 0.1061
Epoch [18/50] - Loss: 0.0923
Epoch [19/50] - Loss: 0.0845
Epoch [20/50] - Loss: 0.0796
Epoch [21/50] - Loss: 0.0724
Epoch [22/50] - Loss: 0.0625
Epoch [23/50] - Loss: 0.0573
Epoch [24/50] - Loss: 0.0542
Epoch [25/50] - Loss: 0.0500
Epoch [26/50] - Loss: 0.0453
Epoch [27/50] - Loss: 0.0404
Epoch [28/50] - Loss: 0.0356
Epoch [29/50] - Loss: 0.0349
Epoch [30/50] - Loss: 0.0316
Epoch [31/50] - Loss: 0.0285
Epoch [32/50] - Loss: 0.0276
Epoch [33/50] - Loss: 0.0264
Epoch [34/50] - Loss: 0.0249
Epoch [35/50] - Loss: 0.0232
Epoch [36/50] - Loss: 0.0215
Epoch [37/50] - Loss: 0.0196
Epoch [38/50] - Loss: 0.0178
Epoch [39/50] - Loss: 0.0161
Epoch [40/50] - Loss: 0.0145
Epoch [41/50] - Loss: 0.0187
Epoch [42/50] - Loss: 0.0136
Epoch [43/50] - Loss: 0.0128
Epoch [44/50] - Loss: 0.0129
Epoch [45/50] - Loss: 0.0129
Epoch [46/50] - Loss: 0.0128
Epoch [47/50] - Loss: 0.0125
Epoch [48/50] - Loss: 0.0122
Epoch [49/50] - Loss: 0.0119
Epoch [50/50] - Loss: 0.0114
sum preds 556
sum labels 654
 - Test Metrics: Accuracy=0.8978, F1=0.7851, Recall=0.7263, Precision=0.8543
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_nnpu_nnpu_1804093153.csv.
Average F1 over valid seeds: 0.7767 ± 0.0178
___________________________________________________________________________________
Avg F1 for cora with SCAR and nnpu, GATConv,0.2: 0.7767 ± 0.0178
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5014
Epoch [2/50] - Loss: 0.4700
Epoch [3/50] - Loss: 0.4415
Epoch [4/50] - Loss: 0.4138
Epoch [5/50] - Loss: 0.3863
Epoch [6/50] - Loss: 0.3596
Epoch [7/50] - Loss: 0.3339
Epoch [8/50] - Loss: 0.3096
Epoch [9/50] - Loss: 0.2865
Epoch [10/50] - Loss: 0.2646
Epoch [11/50] - Loss: 0.2436
Epoch [12/50] - Loss: 0.2234
Epoch [13/50] - Loss: 0.2041
Epoch [14/50] - Loss: 0.1857
Epoch [15/50] - Loss: 0.1682
Epoch [16/50] - Loss: 0.1517
Epoch [17/50] - Loss: 0.1363
Epoch [18/50] - Loss: 0.1220
Epoch [19/50] - Loss: 0.1088
Epoch [20/50] - Loss: 0.0973
Epoch [21/50] - Loss: 0.0886
Epoch [22/50] - Loss: 0.0807
Epoch [23/50] - Loss: 0.0746
Epoch [24/50] - Loss: 0.0679
Epoch [25/50] - Loss: 0.0640
Epoch [26/50] - Loss: 0.0598
Epoch [27/50] - Loss: 0.0547
Epoch [28/50] - Loss: 0.0516
Epoch [29/50] - Loss: 0.0486
Epoch [30/50] - Loss: 0.0446
Epoch [31/50] - Loss: 0.0424
Epoch [32/50] - Loss: 0.0397
Epoch [33/50] - Loss: 0.0376
Epoch [34/50] - Loss: 0.0351
Epoch [35/50] - Loss: 0.0333
Epoch [36/50] - Loss: 0.0324
Epoch [37/50] - Loss: 0.0306
Epoch [38/50] - Loss: 0.0296
Epoch [39/50] - Loss: 0.0282
Epoch [40/50] - Loss: 0.0266
Epoch [41/50] - Loss: 0.0272
Epoch [42/50] - Loss: 0.0245
Epoch [43/50] - Loss: 0.0239
Epoch [44/50] - Loss: 0.0231
Epoch [45/50] - Loss: 0.0220
Epoch [46/50] - Loss: 0.0222
Epoch [47/50] - Loss: 0.0221
Epoch [48/50] - Loss: 0.0217
Epoch [49/50] - Loss: 0.0211
Epoch [50/50] - Loss: 0.0204
sum preds 625
sum labels 654
 - Test Metrics: Accuracy=0.9092, F1=0.8194, Recall=0.8012, Precision=0.8384
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4937
Epoch [2/50] - Loss: 0.4603
Epoch [3/50] - Loss: 0.4255
Epoch [4/50] - Loss: 0.3901
Epoch [5/50] - Loss: 0.3565
Epoch [6/50] - Loss: 0.3260
Epoch [7/50] - Loss: 0.2986
Epoch [8/50] - Loss: 0.2741
Epoch [9/50] - Loss: 0.2517
Epoch [10/50] - Loss: 0.2309
Epoch [11/50] - Loss: 0.2111
Epoch [12/50] - Loss: 0.1918
Epoch [13/50] - Loss: 0.1729
Epoch [14/50] - Loss: 0.1546
Epoch [15/50] - Loss: 0.1374
Epoch [16/50] - Loss: 0.1214
Epoch [17/50] - Loss: 0.1077
Epoch [18/50] - Loss: 0.0955
Epoch [19/50] - Loss: 0.0856
Epoch [20/50] - Loss: 0.0769
Epoch [21/50] - Loss: 0.0703
Epoch [22/50] - Loss: 0.0636
Epoch [23/50] - Loss: 0.0580
Epoch [24/50] - Loss: 0.0531
Epoch [25/50] - Loss: 0.0480
Epoch [26/50] - Loss: 0.0442
Epoch [27/50] - Loss: 0.0403
Epoch [28/50] - Loss: 0.0382
Epoch [29/50] - Loss: 0.0356
Epoch [30/50] - Loss: 0.0325
Epoch [31/50] - Loss: 0.0299
Epoch [32/50] - Loss: 0.0277
Epoch [33/50] - Loss: 0.0258
Epoch [34/50] - Loss: 0.0238
Epoch [35/50] - Loss: 0.0230
Epoch [36/50] - Loss: 0.0221
Epoch [37/50] - Loss: 0.0207
Epoch [38/50] - Loss: 0.0192
Epoch [39/50] - Loss: 0.0176
Epoch [40/50] - Loss: 0.0174
Epoch [41/50] - Loss: 0.0156
Epoch [42/50] - Loss: 0.0151
Epoch [43/50] - Loss: 0.0143
Epoch [44/50] - Loss: 0.0135
Epoch [45/50] - Loss: 0.0125
Epoch [46/50] - Loss: 0.0139
Epoch [47/50] - Loss: 0.0116
Epoch [48/50] - Loss: 0.0115
Epoch [49/50] - Loss: 0.0112
Epoch [50/50] - Loss: 0.0109
sum preds 659
sum labels 654
 - Test Metrics: Accuracy=0.9241, F1=0.8530, Recall=0.8563, Precision=0.8498
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5025
Epoch [2/50] - Loss: 0.4785
Epoch [3/50] - Loss: 0.4527
Epoch [4/50] - Loss: 0.4250
Epoch [5/50] - Loss: 0.3970
Epoch [6/50] - Loss: 0.3698
Epoch [7/50] - Loss: 0.3445
Epoch [8/50] - Loss: 0.3213
Epoch [9/50] - Loss: 0.3004
Epoch [10/50] - Loss: 0.2814
Epoch [11/50] - Loss: 0.2640
Epoch [12/50] - Loss: 0.2475
Epoch [13/50] - Loss: 0.2317
Epoch [14/50] - Loss: 0.2162
Epoch [15/50] - Loss: 0.2009
Epoch [16/50] - Loss: 0.1858
Epoch [17/50] - Loss: 0.1710
Epoch [18/50] - Loss: 0.1569
Epoch [19/50] - Loss: 0.1435
Epoch [20/50] - Loss: 0.1327
Epoch [21/50] - Loss: 0.1213
Epoch [22/50] - Loss: 0.1107
Epoch [23/50] - Loss: 0.1028
Epoch [24/50] - Loss: 0.0957
Epoch [25/50] - Loss: 0.0887
Epoch [26/50] - Loss: 0.0814
Epoch [27/50] - Loss: 0.0735
Epoch [28/50] - Loss: 0.0707
Epoch [29/50] - Loss: 0.0671
Epoch [30/50] - Loss: 0.0624
Epoch [31/50] - Loss: 0.0570
Epoch [32/50] - Loss: 0.0531
Epoch [33/50] - Loss: 0.0510
Epoch [34/50] - Loss: 0.0465
Epoch [35/50] - Loss: 0.0443
Epoch [36/50] - Loss: 0.0421
Epoch [37/50] - Loss: 0.0406
Epoch [38/50] - Loss: 0.0391
Epoch [39/50] - Loss: 0.0371
Epoch [40/50] - Loss: 0.0348
Epoch [41/50] - Loss: 0.0368
Epoch [42/50] - Loss: 0.0340
Epoch [43/50] - Loss: 0.0319
Epoch [44/50] - Loss: 0.0319
Epoch [45/50] - Loss: 0.0314
Epoch [46/50] - Loss: 0.0305
Epoch [47/50] - Loss: 0.0293
Epoch [48/50] - Loss: 0.0279
Epoch [49/50] - Loss: 0.0264
Epoch [50/50] - Loss: 0.0248
sum preds 643
sum labels 654
 - Test Metrics: Accuracy=0.9233, F1=0.8497, Recall=0.8425, Precision=0.8569
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_nnpu_nnpu_1804093155.csv.
Average F1 over valid seeds: 0.8407 ± 0.0151
___________________________________________________________________________________
Avg F1 for cora with SCAR and nnpu, GCNConv,0.2: 0.8407 ± 0.0151
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4901
Epoch [3/50] - Loss: 0.4778
Epoch [4/50] - Loss: 0.4629
Epoch [5/50] - Loss: 0.4466
Epoch [6/50] - Loss: 0.4290
Epoch [7/50] - Loss: 0.4102
Epoch [8/50] - Loss: 0.3904
Epoch [9/50] - Loss: 0.3698
Epoch [10/50] - Loss: 0.3486
Epoch [11/50] - Loss: 0.3271
Epoch [12/50] - Loss: 0.3053
Epoch [13/50] - Loss: 0.2835
Epoch [14/50] - Loss: 0.2620
Epoch [15/50] - Loss: 0.2408
Epoch [16/50] - Loss: 0.2202
Epoch [17/50] - Loss: 0.2003
Epoch [18/50] - Loss: 0.1813
Epoch [19/50] - Loss: 0.1631
Epoch [20/50] - Loss: 0.1459
Epoch [21/50] - Loss: 0.1296
Epoch [22/50] - Loss: 0.1142
Epoch [23/50] - Loss: 0.0998
Epoch [24/50] - Loss: 0.0862
Epoch [25/50] - Loss: 0.0734
Epoch [26/50] - Loss: 0.0614
Epoch [27/50] - Loss: 0.0501
Epoch [28/50] - Loss: 0.0395
Epoch [29/50] - Loss: 0.0295
Epoch [30/50] - Loss: 0.0200
Epoch [31/50] - Loss: 0.0111
Epoch [32/50] - Loss: 0.0027
Epoch [33/50] - Loss: -0.0053
Epoch [34/50] - Loss: -0.0129
Epoch [35/50] - Loss: -0.0200
Epoch [36/50] - Loss: -0.0268
Epoch [37/50] - Loss: -0.0332
Epoch [38/50] - Loss: -0.0392
Epoch [39/50] - Loss: -0.0449
Epoch [40/50] - Loss: -0.0503
Epoch [41/50] - Loss: -0.0554
Epoch [42/50] - Loss: -0.0602
Epoch [43/50] - Loss: -0.0648
Epoch [44/50] - Loss: -0.0691
Epoch [45/50] - Loss: -0.0732
Epoch [46/50] - Loss: -0.0771
Epoch [47/50] - Loss: -0.0808
Epoch [48/50] - Loss: -0.0843
Epoch [49/50] - Loss: -0.0876
Epoch [50/50] - Loss: -0.0908
sum preds 217
sum labels 491
 - Test Metrics: Accuracy=0.8463, F1=0.4831, Recall=0.3483, Precision=0.7880
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4884
Epoch [3/50] - Loss: 0.4744
Epoch [4/50] - Loss: 0.4580
Epoch [5/50] - Loss: 0.4402
Epoch [6/50] - Loss: 0.4212
Epoch [7/50] - Loss: 0.4011
Epoch [8/50] - Loss: 0.3802
Epoch [9/50] - Loss: 0.3585
Epoch [10/50] - Loss: 0.3363
Epoch [11/50] - Loss: 0.3138
Epoch [12/50] - Loss: 0.2913
Epoch [13/50] - Loss: 0.2689
Epoch [14/50] - Loss: 0.2470
Epoch [15/50] - Loss: 0.2257
Epoch [16/50] - Loss: 0.2051
Epoch [17/50] - Loss: 0.1854
Epoch [18/50] - Loss: 0.1666
Epoch [19/50] - Loss: 0.1489
Epoch [20/50] - Loss: 0.1322
Epoch [21/50] - Loss: 0.1166
Epoch [22/50] - Loss: 0.1019
Epoch [23/50] - Loss: 0.0882
Epoch [24/50] - Loss: 0.0754
Epoch [25/50] - Loss: 0.0635
Epoch [26/50] - Loss: 0.0523
Epoch [27/50] - Loss: 0.0418
Epoch [28/50] - Loss: 0.0320
Epoch [29/50] - Loss: 0.0228
Epoch [30/50] - Loss: 0.0142
Epoch [31/50] - Loss: 0.0060
Epoch [32/50] - Loss: -0.0016
Epoch [33/50] - Loss: -0.0088
Epoch [34/50] - Loss: -0.0156
Epoch [35/50] - Loss: -0.0220
Epoch [36/50] - Loss: -0.0280
Epoch [37/50] - Loss: -0.0337
Epoch [38/50] - Loss: -0.0390
Epoch [39/50] - Loss: -0.0440
Epoch [40/50] - Loss: -0.0488
Epoch [41/50] - Loss: -0.0533
Epoch [42/50] - Loss: -0.0576
Epoch [43/50] - Loss: -0.0616
Epoch [44/50] - Loss: -0.0655
Epoch [45/50] - Loss: -0.0691
Epoch [46/50] - Loss: -0.0727
Epoch [47/50] - Loss: -0.0760
Epoch [48/50] - Loss: -0.0793
Epoch [49/50] - Loss: -0.0824
Epoch [50/50] - Loss: -0.0853
sum preds 272
sum labels 491
 - Test Metrics: Accuracy=0.8593, F1=0.5609, Recall=0.4358, Precision=0.7868
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4897
Epoch [3/50] - Loss: 0.4776
Epoch [4/50] - Loss: 0.4629
Epoch [5/50] - Loss: 0.4467
Epoch [6/50] - Loss: 0.4293
Epoch [7/50] - Loss: 0.4109
Epoch [8/50] - Loss: 0.3916
Epoch [9/50] - Loss: 0.3714
Epoch [10/50] - Loss: 0.3505
Epoch [11/50] - Loss: 0.3291
Epoch [12/50] - Loss: 0.3074
Epoch [13/50] - Loss: 0.2857
Epoch [14/50] - Loss: 0.2639
Epoch [15/50] - Loss: 0.2424
Epoch [16/50] - Loss: 0.2214
Epoch [17/50] - Loss: 0.2010
Epoch [18/50] - Loss: 0.1813
Epoch [19/50] - Loss: 0.1624
Epoch [20/50] - Loss: 0.1445
Epoch [21/50] - Loss: 0.1275
Epoch [22/50] - Loss: 0.1115
Epoch [23/50] - Loss: 0.0964
Epoch [24/50] - Loss: 0.0823
Epoch [25/50] - Loss: 0.0691
Epoch [26/50] - Loss: 0.0567
Epoch [27/50] - Loss: 0.0452
Epoch [28/50] - Loss: 0.0344
Epoch [29/50] - Loss: 0.0243
Epoch [30/50] - Loss: 0.0148
Epoch [31/50] - Loss: 0.0059
Epoch [32/50] - Loss: -0.0024
Epoch [33/50] - Loss: -0.0102
Epoch [34/50] - Loss: -0.0176
Epoch [35/50] - Loss: -0.0246
Epoch [36/50] - Loss: -0.0311
Epoch [37/50] - Loss: -0.0374
Epoch [38/50] - Loss: -0.0432
Epoch [39/50] - Loss: -0.0488
Epoch [40/50] - Loss: -0.0541
Epoch [41/50] - Loss: -0.0590
Epoch [42/50] - Loss: -0.0637
Epoch [43/50] - Loss: -0.0682
Epoch [44/50] - Loss: -0.0724
Epoch [45/50] - Loss: -0.0764
Epoch [46/50] - Loss: -0.0801
Epoch [47/50] - Loss: -0.0837
Epoch [48/50] - Loss: -0.0870
Epoch [49/50] - Loss: -0.0902
Epoch [50/50] - Loss: -0.0933
sum preds 235
sum labels 491
 - Test Metrics: Accuracy=0.8522, F1=0.5152, Recall=0.3809, Precision=0.7957
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_imbnnpu_imbnnpu_1804093156.csv.
Average F1 over valid seeds: 0.5197 ± 0.0320
___________________________________________________________________________________
Avg F1 for cora with SCAR and imbnnpu, MLP,0.4: 0.5197 ± 0.0320
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5015
Epoch [2/50] - Loss: 0.4766
Epoch [3/50] - Loss: 0.4495
Epoch [4/50] - Loss: 0.4184
Epoch [5/50] - Loss: 0.3859
Epoch [6/50] - Loss: 0.3535
Epoch [7/50] - Loss: 0.3220
Epoch [8/50] - Loss: 0.2919
Epoch [9/50] - Loss: 0.2634
Epoch [10/50] - Loss: 0.2366
Epoch [11/50] - Loss: 0.2114
Epoch [12/50] - Loss: 0.1879
Epoch [13/50] - Loss: 0.1663
Epoch [14/50] - Loss: 0.1465
Epoch [15/50] - Loss: 0.1284
Epoch [16/50] - Loss: 0.1118
Epoch [17/50] - Loss: 0.0968
Epoch [18/50] - Loss: 0.0834
Epoch [19/50] - Loss: 0.0714
Epoch [20/50] - Loss: 0.0606
Epoch [21/50] - Loss: 0.0509
Epoch [22/50] - Loss: 0.0422
Epoch [23/50] - Loss: 0.0342
Epoch [24/50] - Loss: 0.0269
Epoch [25/50] - Loss: 0.0201
Epoch [26/50] - Loss: 0.0140
Epoch [27/50] - Loss: 0.0084
Epoch [28/50] - Loss: 0.0034
Epoch [29/50] - Loss: -0.0009
Epoch [30/50] - Loss: -0.0048
Epoch [31/50] - Loss: -0.0085
Epoch [32/50] - Loss: -0.0117
Epoch [33/50] - Loss: -0.0148
Epoch [34/50] - Loss: -0.0178
Epoch [35/50] - Loss: -0.0206
Epoch [36/50] - Loss: -0.0232
Epoch [37/50] - Loss: -0.0257
Epoch [38/50] - Loss: -0.0279
Epoch [39/50] - Loss: -0.0301
Epoch [40/50] - Loss: -0.0322
Epoch [41/50] - Loss: -0.0345
Epoch [42/50] - Loss: -0.0367
Epoch [43/50] - Loss: -0.0382
Epoch [44/50] - Loss: -0.0394
Epoch [45/50] - Loss: -0.0407
Epoch [46/50] - Loss: -0.0420
Epoch [47/50] - Loss: -0.0435
Epoch [48/50] - Loss: -0.0448
Epoch [49/50] - Loss: -0.0460
Epoch [50/50] - Loss: -0.0470
sum preds 398
sum labels 491
 - Test Metrics: Accuracy=0.9021, F1=0.7379, Recall=0.6680, Precision=0.8241
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4872
Epoch [3/50] - Loss: 0.4720
Epoch [4/50] - Loss: 0.4539
Epoch [5/50] - Loss: 0.4329
Epoch [6/50] - Loss: 0.4100
Epoch [7/50] - Loss: 0.3863
Epoch [8/50] - Loss: 0.3620
Epoch [9/50] - Loss: 0.3373
Epoch [10/50] - Loss: 0.3120
Epoch [11/50] - Loss: 0.2866
Epoch [12/50] - Loss: 0.2613
Epoch [13/50] - Loss: 0.2364
Epoch [14/50] - Loss: 0.2124
Epoch [15/50] - Loss: 0.1896
Epoch [16/50] - Loss: 0.1683
Epoch [17/50] - Loss: 0.1489
Epoch [18/50] - Loss: 0.1311
Epoch [19/50] - Loss: 0.1151
Epoch [20/50] - Loss: 0.1006
Epoch [21/50] - Loss: 0.0875
Epoch [22/50] - Loss: 0.0756
Epoch [23/50] - Loss: 0.0647
Epoch [24/50] - Loss: 0.0548
Epoch [25/50] - Loss: 0.0457
Epoch [26/50] - Loss: 0.0376
Epoch [27/50] - Loss: 0.0304
Epoch [28/50] - Loss: 0.0241
Epoch [29/50] - Loss: 0.0187
Epoch [30/50] - Loss: 0.0140
Epoch [31/50] - Loss: 0.0097
Epoch [32/50] - Loss: 0.0058
Epoch [33/50] - Loss: 0.0022
Epoch [34/50] - Loss: -0.0011
Epoch [35/50] - Loss: -0.0042
Epoch [36/50] - Loss: -0.0071
Epoch [37/50] - Loss: -0.0099
Epoch [38/50] - Loss: -0.0125
Epoch [39/50] - Loss: -0.0149
Epoch [40/50] - Loss: -0.0172
Epoch [41/50] - Loss: -0.0193
Epoch [42/50] - Loss: -0.0213
Epoch [43/50] - Loss: -0.0233
Epoch [44/50] - Loss: -0.0251
Epoch [45/50] - Loss: -0.0269
Epoch [46/50] - Loss: -0.0285
Epoch [47/50] - Loss: -0.0301
Epoch [48/50] - Loss: -0.0317
Epoch [49/50] - Loss: -0.0332
Epoch [50/50] - Loss: -0.0347
sum preds 493
sum labels 491
 - Test Metrics: Accuracy=0.9059, F1=0.7724, Recall=0.7739, Precision=0.7708
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4988
Epoch [2/50] - Loss: 0.4769
Epoch [3/50] - Loss: 0.4521
Epoch [4/50] - Loss: 0.4235
Epoch [5/50] - Loss: 0.3926
Epoch [6/50] - Loss: 0.3608
Epoch [7/50] - Loss: 0.3289
Epoch [8/50] - Loss: 0.2976
Epoch [9/50] - Loss: 0.2672
Epoch [10/50] - Loss: 0.2382
Epoch [11/50] - Loss: 0.2109
Epoch [12/50] - Loss: 0.1856
Epoch [13/50] - Loss: 0.1625
Epoch [14/50] - Loss: 0.1416
Epoch [15/50] - Loss: 0.1228
Epoch [16/50] - Loss: 0.1061
Epoch [17/50] - Loss: 0.0912
Epoch [18/50] - Loss: 0.0777
Epoch [19/50] - Loss: 0.0656
Epoch [20/50] - Loss: 0.0545
Epoch [21/50] - Loss: 0.0442
Epoch [22/50] - Loss: 0.0347
Epoch [23/50] - Loss: 0.0262
Epoch [24/50] - Loss: 0.0185
Epoch [25/50] - Loss: 0.0115
Epoch [26/50] - Loss: 0.0050
Epoch [27/50] - Loss: -0.0010
Epoch [28/50] - Loss: -0.0065
Epoch [29/50] - Loss: -0.0116
Epoch [30/50] - Loss: -0.0163
Epoch [31/50] - Loss: -0.0206
Epoch [32/50] - Loss: -0.0245
Epoch [33/50] - Loss: -0.0281
Epoch [34/50] - Loss: -0.0314
Epoch [35/50] - Loss: -0.0345
Epoch [36/50] - Loss: -0.0374
Epoch [37/50] - Loss: -0.0401
Epoch [38/50] - Loss: -0.0428
Epoch [39/50] - Loss: -0.0454
Epoch [40/50] - Loss: -0.0478
Epoch [41/50] - Loss: -0.0502
Epoch [42/50] - Loss: -0.0524
Epoch [43/50] - Loss: -0.0545
Epoch [44/50] - Loss: -0.0565
Epoch [45/50] - Loss: -0.0585
Epoch [46/50] - Loss: -0.0605
Epoch [47/50] - Loss: -0.0622
Epoch [48/50] - Loss: -0.0638
Epoch [49/50] - Loss: -0.0653
Epoch [50/50] - Loss: -0.0668
sum preds 401
sum labels 491
 - Test Metrics: Accuracy=0.9160, F1=0.7758, Recall=0.7047, Precision=0.8628
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_imbnnpu_imbnnpu_1804093157.csv.
Average F1 over valid seeds: 0.7620 ± 0.0171
___________________________________________________________________________________
Avg F1 for cora with SCAR and imbnnpu, GATConv,0.4: 0.7620 ± 0.0171
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4790
Epoch [3/50] - Loss: 0.4560
Epoch [4/50] - Loss: 0.4301
Epoch [5/50] - Loss: 0.4027
Epoch [6/50] - Loss: 0.3749
Epoch [7/50] - Loss: 0.3474
Epoch [8/50] - Loss: 0.3207
Epoch [9/50] - Loss: 0.2951
Epoch [10/50] - Loss: 0.2708
Epoch [11/50] - Loss: 0.2476
Epoch [12/50] - Loss: 0.2259
Epoch [13/50] - Loss: 0.2055
Epoch [14/50] - Loss: 0.1868
Epoch [15/50] - Loss: 0.1695
Epoch [16/50] - Loss: 0.1536
Epoch [17/50] - Loss: 0.1391
Epoch [18/50] - Loss: 0.1258
Epoch [19/50] - Loss: 0.1137
Epoch [20/50] - Loss: 0.1026
Epoch [21/50] - Loss: 0.0926
Epoch [22/50] - Loss: 0.0833
Epoch [23/50] - Loss: 0.0749
Epoch [24/50] - Loss: 0.0671
Epoch [25/50] - Loss: 0.0600
Epoch [26/50] - Loss: 0.0534
Epoch [27/50] - Loss: 0.0474
Epoch [28/50] - Loss: 0.0418
Epoch [29/50] - Loss: 0.0365
Epoch [30/50] - Loss: 0.0317
Epoch [31/50] - Loss: 0.0271
Epoch [32/50] - Loss: 0.0229
Epoch [33/50] - Loss: 0.0189
Epoch [34/50] - Loss: 0.0152
Epoch [35/50] - Loss: 0.0117
Epoch [36/50] - Loss: 0.0084
Epoch [37/50] - Loss: 0.0053
Epoch [38/50] - Loss: 0.0023
Epoch [39/50] - Loss: -0.0005
Epoch [40/50] - Loss: -0.0031
Epoch [41/50] - Loss: -0.0057
Epoch [42/50] - Loss: -0.0081
Epoch [43/50] - Loss: -0.0104
Epoch [44/50] - Loss: -0.0126
Epoch [45/50] - Loss: -0.0148
Epoch [46/50] - Loss: -0.0168
Epoch [47/50] - Loss: -0.0187
Epoch [48/50] - Loss: -0.0206
Epoch [49/50] - Loss: -0.0224
Epoch [50/50] - Loss: -0.0241
sum preds 458
sum labels 491
 - Test Metrics: Accuracy=0.9215, F1=0.8030, Recall=0.7760, Precision=0.8319
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5010
Epoch [2/50] - Loss: 0.4794
Epoch [3/50] - Loss: 0.4550
Epoch [4/50] - Loss: 0.4262
Epoch [5/50] - Loss: 0.3948
Epoch [6/50] - Loss: 0.3633
Epoch [7/50] - Loss: 0.3331
Epoch [8/50] - Loss: 0.3043
Epoch [9/50] - Loss: 0.2770
Epoch [10/50] - Loss: 0.2510
Epoch [11/50] - Loss: 0.2266
Epoch [12/50] - Loss: 0.2040
Epoch [13/50] - Loss: 0.1832
Epoch [14/50] - Loss: 0.1642
Epoch [15/50] - Loss: 0.1469
Epoch [16/50] - Loss: 0.1312
Epoch [17/50] - Loss: 0.1171
Epoch [18/50] - Loss: 0.1043
Epoch [19/50] - Loss: 0.0927
Epoch [20/50] - Loss: 0.0822
Epoch [21/50] - Loss: 0.0727
Epoch [22/50] - Loss: 0.0640
Epoch [23/50] - Loss: 0.0562
Epoch [24/50] - Loss: 0.0490
Epoch [25/50] - Loss: 0.0425
Epoch [26/50] - Loss: 0.0365
Epoch [27/50] - Loss: 0.0310
Epoch [28/50] - Loss: 0.0259
Epoch [29/50] - Loss: 0.0212
Epoch [30/50] - Loss: 0.0168
Epoch [31/50] - Loss: 0.0128
Epoch [32/50] - Loss: 0.0090
Epoch [33/50] - Loss: 0.0054
Epoch [34/50] - Loss: 0.0021
Epoch [35/50] - Loss: -0.0010
Epoch [36/50] - Loss: -0.0040
Epoch [37/50] - Loss: -0.0068
Epoch [38/50] - Loss: -0.0094
Epoch [39/50] - Loss: -0.0119
Epoch [40/50] - Loss: -0.0142
Epoch [41/50] - Loss: -0.0165
Epoch [42/50] - Loss: -0.0186
Epoch [43/50] - Loss: -0.0206
Epoch [44/50] - Loss: -0.0225
Epoch [45/50] - Loss: -0.0243
Epoch [46/50] - Loss: -0.0260
Epoch [47/50] - Loss: -0.0277
Epoch [48/50] - Loss: -0.0292
Epoch [49/50] - Loss: -0.0307
Epoch [50/50] - Loss: -0.0320
sum preds 449
sum labels 491
 - Test Metrics: Accuracy=0.9370, F1=0.8404, Recall=0.8045, Precision=0.8797
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5006
Epoch [2/50] - Loss: 0.4860
Epoch [3/50] - Loss: 0.4705
Epoch [4/50] - Loss: 0.4511
Epoch [5/50] - Loss: 0.4280
Epoch [6/50] - Loss: 0.4034
Epoch [7/50] - Loss: 0.3788
Epoch [8/50] - Loss: 0.3544
Epoch [9/50] - Loss: 0.3303
Epoch [10/50] - Loss: 0.3064
Epoch [11/50] - Loss: 0.2831
Epoch [12/50] - Loss: 0.2606
Epoch [13/50] - Loss: 0.2388
Epoch [14/50] - Loss: 0.2182
Epoch [15/50] - Loss: 0.1988
Epoch [16/50] - Loss: 0.1808
Epoch [17/50] - Loss: 0.1640
Epoch [18/50] - Loss: 0.1485
Epoch [19/50] - Loss: 0.1342
Epoch [20/50] - Loss: 0.1212
Epoch [21/50] - Loss: 0.1091
Epoch [22/50] - Loss: 0.0981
Epoch [23/50] - Loss: 0.0880
Epoch [24/50] - Loss: 0.0788
Epoch [25/50] - Loss: 0.0704
Epoch [26/50] - Loss: 0.0627
Epoch [27/50] - Loss: 0.0556
Epoch [28/50] - Loss: 0.0491
Epoch [29/50] - Loss: 0.0432
Epoch [30/50] - Loss: 0.0377
Epoch [31/50] - Loss: 0.0326
Epoch [32/50] - Loss: 0.0279
Epoch [33/50] - Loss: 0.0236
Epoch [34/50] - Loss: 0.0195
Epoch [35/50] - Loss: 0.0158
Epoch [36/50] - Loss: 0.0123
Epoch [37/50] - Loss: 0.0090
Epoch [38/50] - Loss: 0.0060
Epoch [39/50] - Loss: 0.0031
Epoch [40/50] - Loss: 0.0004
Epoch [41/50] - Loss: -0.0021
Epoch [42/50] - Loss: -0.0045
Epoch [43/50] - Loss: -0.0068
Epoch [44/50] - Loss: -0.0089
Epoch [45/50] - Loss: -0.0109
Epoch [46/50] - Loss: -0.0128
Epoch [47/50] - Loss: -0.0146
Epoch [48/50] - Loss: -0.0164
Epoch [49/50] - Loss: -0.0180
Epoch [50/50] - Loss: -0.0195
sum preds 459
sum labels 491
 - Test Metrics: Accuracy=0.9387, F1=0.8463, Recall=0.8187, Precision=0.8758
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_imbnnpu_imbnnpu_1804093159.csv.
Average F1 over valid seeds: 0.8299 ± 0.0192
___________________________________________________________________________________
Avg F1 for cora with SCAR and imbnnpu, GCNConv,0.4: 0.8299 ± 0.0192
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4893
Epoch [3/50] - Loss: 0.4763
Epoch [4/50] - Loss: 0.4609
Epoch [5/50] - Loss: 0.4439
Epoch [6/50] - Loss: 0.4255
Epoch [7/50] - Loss: 0.4058
Epoch [8/50] - Loss: 0.3851
Epoch [9/50] - Loss: 0.3635
Epoch [10/50] - Loss: 0.3414
Epoch [11/50] - Loss: 0.3188
Epoch [12/50] - Loss: 0.2960
Epoch [13/50] - Loss: 0.2732
Epoch [14/50] - Loss: 0.2507
Epoch [15/50] - Loss: 0.2285
Epoch [16/50] - Loss: 0.2071
Epoch [17/50] - Loss: 0.1863
Epoch [18/50] - Loss: 0.1664
Epoch [19/50] - Loss: 0.1474
Epoch [20/50] - Loss: 0.1294
Epoch [21/50] - Loss: 0.1123
Epoch [22/50] - Loss: 0.0963
Epoch [23/50] - Loss: 0.0812
Epoch [24/50] - Loss: 0.0670
Epoch [25/50] - Loss: 0.0537
Epoch [26/50] - Loss: 0.0412
Epoch [27/50] - Loss: 0.0295
Epoch [28/50] - Loss: 0.0184
Epoch [29/50] - Loss: 0.0080
Epoch [30/50] - Loss: -0.0018
Epoch [31/50] - Loss: -0.0109
Epoch [32/50] - Loss: -0.0196
Epoch [33/50] - Loss: -0.0277
Epoch [34/50] - Loss: -0.0354
Epoch [35/50] - Loss: -0.0426
Epoch [36/50] - Loss: -0.0494
Epoch [37/50] - Loss: -0.0559
Epoch [38/50] - Loss: -0.0619
Epoch [39/50] - Loss: -0.0675
Epoch [40/50] - Loss: -0.0728
Epoch [41/50] - Loss: -0.0778
Epoch [42/50] - Loss: -0.0824
Epoch [43/50] - Loss: -0.0868
Epoch [44/50] - Loss: -0.0908
Epoch [45/50] - Loss: -0.0946
Epoch [46/50] - Loss: -0.0982
Epoch [47/50] - Loss: -0.1015
Epoch [48/50] - Loss: -0.1047
Epoch [49/50] - Loss: -0.1077
Epoch [50/50] - Loss: -0.1105
sum preds 202
sum labels 573
 - Test Metrics: Accuracy=0.8185, F1=0.4232, Recall=0.2862, Precision=0.8119
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5003
Epoch [2/50] - Loss: 0.4880
Epoch [3/50] - Loss: 0.4732
Epoch [4/50] - Loss: 0.4560
Epoch [5/50] - Loss: 0.4375
Epoch [6/50] - Loss: 0.4177
Epoch [7/50] - Loss: 0.3966
Epoch [8/50] - Loss: 0.3746
Epoch [9/50] - Loss: 0.3518
Epoch [10/50] - Loss: 0.3284
Epoch [11/50] - Loss: 0.3048
Epoch [12/50] - Loss: 0.2812
Epoch [13/50] - Loss: 0.2578
Epoch [14/50] - Loss: 0.2349
Epoch [15/50] - Loss: 0.2126
Epoch [16/50] - Loss: 0.1912
Epoch [17/50] - Loss: 0.1708
Epoch [18/50] - Loss: 0.1514
Epoch [19/50] - Loss: 0.1331
Epoch [20/50] - Loss: 0.1159
Epoch [21/50] - Loss: 0.0998
Epoch [22/50] - Loss: 0.0848
Epoch [23/50] - Loss: 0.0708
Epoch [24/50] - Loss: 0.0577
Epoch [25/50] - Loss: 0.0454
Epoch [26/50] - Loss: 0.0340
Epoch [27/50] - Loss: 0.0233
Epoch [28/50] - Loss: 0.0133
Epoch [29/50] - Loss: 0.0039
Epoch [30/50] - Loss: -0.0049
Epoch [31/50] - Loss: -0.0131
Epoch [32/50] - Loss: -0.0209
Epoch [33/50] - Loss: -0.0281
Epoch [34/50] - Loss: -0.0349
Epoch [35/50] - Loss: -0.0413
Epoch [36/50] - Loss: -0.0473
Epoch [37/50] - Loss: -0.0529
Epoch [38/50] - Loss: -0.0581
Epoch [39/50] - Loss: -0.0630
Epoch [40/50] - Loss: -0.0676
Epoch [41/50] - Loss: -0.0719
Epoch [42/50] - Loss: -0.0760
Epoch [43/50] - Loss: -0.0798
Epoch [44/50] - Loss: -0.0834
Epoch [45/50] - Loss: -0.0868
Epoch [46/50] - Loss: -0.0901
Epoch [47/50] - Loss: -0.0932
Epoch [48/50] - Loss: -0.0961
Epoch [49/50] - Loss: -0.0989
Epoch [50/50] - Loss: -0.1016
sum preds 230
sum labels 573
 - Test Metrics: Accuracy=0.8258, F1=0.4658, Recall=0.3264, Precision=0.8130
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4892
Epoch [3/50] - Loss: 0.4767
Epoch [4/50] - Loss: 0.4619
Epoch [5/50] - Loss: 0.4456
Epoch [6/50] - Loss: 0.4280
Epoch [7/50] - Loss: 0.4093
Epoch [8/50] - Loss: 0.3896
Epoch [9/50] - Loss: 0.3690
Epoch [10/50] - Loss: 0.3477
Epoch [11/50] - Loss: 0.3260
Epoch [12/50] - Loss: 0.3038
Epoch [13/50] - Loss: 0.2816
Epoch [14/50] - Loss: 0.2594
Epoch [15/50] - Loss: 0.2374
Epoch [16/50] - Loss: 0.2159
Epoch [17/50] - Loss: 0.1949
Epoch [18/50] - Loss: 0.1747
Epoch [19/50] - Loss: 0.1553
Epoch [20/50] - Loss: 0.1367
Epoch [21/50] - Loss: 0.1192
Epoch [22/50] - Loss: 0.1026
Epoch [23/50] - Loss: 0.0870
Epoch [24/50] - Loss: 0.0724
Epoch [25/50] - Loss: 0.0588
Epoch [26/50] - Loss: 0.0460
Epoch [27/50] - Loss: 0.0341
Epoch [28/50] - Loss: 0.0230
Epoch [29/50] - Loss: 0.0126
Epoch [30/50] - Loss: 0.0029
Epoch [31/50] - Loss: -0.0062
Epoch [32/50] - Loss: -0.0147
Epoch [33/50] - Loss: -0.0227
Epoch [34/50] - Loss: -0.0302
Epoch [35/50] - Loss: -0.0373
Epoch [36/50] - Loss: -0.0440
Epoch [37/50] - Loss: -0.0502
Epoch [38/50] - Loss: -0.0561
Epoch [39/50] - Loss: -0.0617
Epoch [40/50] - Loss: -0.0670
Epoch [41/50] - Loss: -0.0720
Epoch [42/50] - Loss: -0.0767
Epoch [43/50] - Loss: -0.0811
Epoch [44/50] - Loss: -0.0853
Epoch [45/50] - Loss: -0.0893
Epoch [46/50] - Loss: -0.0930
Epoch [47/50] - Loss: -0.0965
Epoch [48/50] - Loss: -0.0999
Epoch [49/50] - Loss: -0.1031
Epoch [50/50] - Loss: -0.1061
sum preds 193
sum labels 573
 - Test Metrics: Accuracy=0.8222, F1=0.4282, Recall=0.2862, Precision=0.8497
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_imbnnpu_imbnnpu_1804093201.csv.
Average F1 over valid seeds: 0.4391 ± 0.0190
___________________________________________________________________________________
Avg F1 for cora with SCAR and imbnnpu, MLP,0.3: 0.4391 ± 0.0190
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5013
Epoch [2/50] - Loss: 0.4766
Epoch [3/50] - Loss: 0.4498
Epoch [4/50] - Loss: 0.4193
Epoch [5/50] - Loss: 0.3875
Epoch [6/50] - Loss: 0.3560
Epoch [7/50] - Loss: 0.3254
Epoch [8/50] - Loss: 0.2964
Epoch [9/50] - Loss: 0.2690
Epoch [10/50] - Loss: 0.2433
Epoch [11/50] - Loss: 0.2194
Epoch [12/50] - Loss: 0.1972
Epoch [13/50] - Loss: 0.1767
Epoch [14/50] - Loss: 0.1579
Epoch [15/50] - Loss: 0.1407
Epoch [16/50] - Loss: 0.1250
Epoch [17/50] - Loss: 0.1105
Epoch [18/50] - Loss: 0.0973
Epoch [19/50] - Loss: 0.0852
Epoch [20/50] - Loss: 0.0741
Epoch [21/50] - Loss: 0.0640
Epoch [22/50] - Loss: 0.0548
Epoch [23/50] - Loss: 0.0463
Epoch [24/50] - Loss: 0.0387
Epoch [25/50] - Loss: 0.0318
Epoch [26/50] - Loss: 0.0254
Epoch [27/50] - Loss: 0.0195
Epoch [28/50] - Loss: 0.0141
Epoch [29/50] - Loss: 0.0094
Epoch [30/50] - Loss: 0.0051
Epoch [31/50] - Loss: 0.0009
Epoch [32/50] - Loss: -0.0032
Epoch [33/50] - Loss: -0.0070
Epoch [34/50] - Loss: -0.0105
Epoch [35/50] - Loss: -0.0140
Epoch [36/50] - Loss: -0.0171
Epoch [37/50] - Loss: -0.0200
Epoch [38/50] - Loss: -0.0224
Epoch [39/50] - Loss: -0.0246
Epoch [40/50] - Loss: -0.0269
Epoch [41/50] - Loss: -0.0291
Epoch [42/50] - Loss: -0.0311
Epoch [43/50] - Loss: -0.0329
Epoch [44/50] - Loss: -0.0346
Epoch [45/50] - Loss: -0.0362
Epoch [46/50] - Loss: -0.0377
Epoch [47/50] - Loss: -0.0393
Epoch [48/50] - Loss: -0.0408
Epoch [49/50] - Loss: -0.0423
Epoch [50/50] - Loss: -0.0438
sum preds 419
sum labels 573
 - Test Metrics: Accuracy=0.8839, F1=0.7117, Recall=0.6161, Precision=0.8425
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4872
Epoch [3/50] - Loss: 0.4722
Epoch [4/50] - Loss: 0.4542
Epoch [5/50] - Loss: 0.4337
Epoch [6/50] - Loss: 0.4115
Epoch [7/50] - Loss: 0.3883
Epoch [8/50] - Loss: 0.3644
Epoch [9/50] - Loss: 0.3401
Epoch [10/50] - Loss: 0.3153
Epoch [11/50] - Loss: 0.2904
Epoch [12/50] - Loss: 0.2655
Epoch [13/50] - Loss: 0.2409
Epoch [14/50] - Loss: 0.2171
Epoch [15/50] - Loss: 0.1945
Epoch [16/50] - Loss: 0.1734
Epoch [17/50] - Loss: 0.1539
Epoch [18/50] - Loss: 0.1361
Epoch [19/50] - Loss: 0.1200
Epoch [20/50] - Loss: 0.1054
Epoch [21/50] - Loss: 0.0922
Epoch [22/50] - Loss: 0.0803
Epoch [23/50] - Loss: 0.0695
Epoch [24/50] - Loss: 0.0598
Epoch [25/50] - Loss: 0.0511
Epoch [26/50] - Loss: 0.0432
Epoch [27/50] - Loss: 0.0361
Epoch [28/50] - Loss: 0.0296
Epoch [29/50] - Loss: 0.0236
Epoch [30/50] - Loss: 0.0182
Epoch [31/50] - Loss: 0.0131
Epoch [32/50] - Loss: 0.0086
Epoch [33/50] - Loss: 0.0046
Epoch [34/50] - Loss: 0.0009
Epoch [35/50] - Loss: -0.0024
Epoch [36/50] - Loss: -0.0055
Epoch [37/50] - Loss: -0.0084
Epoch [38/50] - Loss: -0.0111
Epoch [39/50] - Loss: -0.0138
Epoch [40/50] - Loss: -0.0166
Epoch [41/50] - Loss: -0.0194
Epoch [42/50] - Loss: -0.0222
Epoch [43/50] - Loss: -0.0250
Epoch [44/50] - Loss: -0.0278
Epoch [45/50] - Loss: -0.0306
Epoch [46/50] - Loss: -0.0333
Epoch [47/50] - Loss: -0.0357
Epoch [48/50] - Loss: -0.0379
Epoch [49/50] - Loss: -0.0400
Epoch [50/50] - Loss: -0.0421
sum preds 486
sum labels 573
 - Test Metrics: Accuracy=0.8932, F1=0.7517, Recall=0.6946, Precision=0.8189
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4992
Epoch [2/50] - Loss: 0.4780
Epoch [3/50] - Loss: 0.4541
Epoch [4/50] - Loss: 0.4267
Epoch [5/50] - Loss: 0.3969
Epoch [6/50] - Loss: 0.3662
Epoch [7/50] - Loss: 0.3354
Epoch [8/50] - Loss: 0.3049
Epoch [9/50] - Loss: 0.2751
Epoch [10/50] - Loss: 0.2465
Epoch [11/50] - Loss: 0.2196
Epoch [12/50] - Loss: 0.1944
Epoch [13/50] - Loss: 0.1713
Epoch [14/50] - Loss: 0.1501
Epoch [15/50] - Loss: 0.1310
Epoch [16/50] - Loss: 0.1138
Epoch [17/50] - Loss: 0.0983
Epoch [18/50] - Loss: 0.0841
Epoch [19/50] - Loss: 0.0712
Epoch [20/50] - Loss: 0.0592
Epoch [21/50] - Loss: 0.0483
Epoch [22/50] - Loss: 0.0384
Epoch [23/50] - Loss: 0.0294
Epoch [24/50] - Loss: 0.0213
Epoch [25/50] - Loss: 0.0139
Epoch [26/50] - Loss: 0.0072
Epoch [27/50] - Loss: 0.0010
Epoch [28/50] - Loss: -0.0048
Epoch [29/50] - Loss: -0.0101
Epoch [30/50] - Loss: -0.0149
Epoch [31/50] - Loss: -0.0194
Epoch [32/50] - Loss: -0.0235
Epoch [33/50] - Loss: -0.0275
Epoch [34/50] - Loss: -0.0315
Epoch [35/50] - Loss: -0.0353
Epoch [36/50] - Loss: -0.0386
Epoch [37/50] - Loss: -0.0415
Epoch [38/50] - Loss: -0.0441
Epoch [39/50] - Loss: -0.0464
Epoch [40/50] - Loss: -0.0487
Epoch [41/50] - Loss: -0.0509
Epoch [42/50] - Loss: -0.0530
Epoch [43/50] - Loss: -0.0551
Epoch [44/50] - Loss: -0.0573
Epoch [45/50] - Loss: -0.0594
Epoch [46/50] - Loss: -0.0615
Epoch [47/50] - Loss: -0.0635
Epoch [48/50] - Loss: -0.0654
Epoch [49/50] - Loss: -0.0673
Epoch [50/50] - Loss: -0.0691
sum preds 402
sum labels 573
 - Test Metrics: Accuracy=0.8924, F1=0.7282, Recall=0.6195, Precision=0.8831
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_imbnnpu_imbnnpu_1804093202.csv.
Average F1 over valid seeds: 0.7305 ± 0.0164
___________________________________________________________________________________
Avg F1 for cora with SCAR and imbnnpu, GATConv,0.3: 0.7305 ± 0.0164
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4994
Epoch [2/50] - Loss: 0.4786
Epoch [3/50] - Loss: 0.4557
Epoch [4/50] - Loss: 0.4299
Epoch [5/50] - Loss: 0.4027
Epoch [6/50] - Loss: 0.3750
Epoch [7/50] - Loss: 0.3477
Epoch [8/50] - Loss: 0.3211
Epoch [9/50] - Loss: 0.2956
Epoch [10/50] - Loss: 0.2712
Epoch [11/50] - Loss: 0.2481
Epoch [12/50] - Loss: 0.2265
Epoch [13/50] - Loss: 0.2063
Epoch [14/50] - Loss: 0.1877
Epoch [15/50] - Loss: 0.1706
Epoch [16/50] - Loss: 0.1550
Epoch [17/50] - Loss: 0.1407
Epoch [18/50] - Loss: 0.1276
Epoch [19/50] - Loss: 0.1156
Epoch [20/50] - Loss: 0.1047
Epoch [21/50] - Loss: 0.0947
Epoch [22/50] - Loss: 0.0856
Epoch [23/50] - Loss: 0.0772
Epoch [24/50] - Loss: 0.0696
Epoch [25/50] - Loss: 0.0625
Epoch [26/50] - Loss: 0.0560
Epoch [27/50] - Loss: 0.0500
Epoch [28/50] - Loss: 0.0444
Epoch [29/50] - Loss: 0.0393
Epoch [30/50] - Loss: 0.0345
Epoch [31/50] - Loss: 0.0300
Epoch [32/50] - Loss: 0.0258
Epoch [33/50] - Loss: 0.0219
Epoch [34/50] - Loss: 0.0182
Epoch [35/50] - Loss: 0.0147
Epoch [36/50] - Loss: 0.0115
Epoch [37/50] - Loss: 0.0084
Epoch [38/50] - Loss: 0.0054
Epoch [39/50] - Loss: 0.0026
Epoch [40/50] - Loss: -0.0000
Epoch [41/50] - Loss: -0.0026
Epoch [42/50] - Loss: -0.0050
Epoch [43/50] - Loss: -0.0074
Epoch [44/50] - Loss: -0.0097
Epoch [45/50] - Loss: -0.0119
Epoch [46/50] - Loss: -0.0140
Epoch [47/50] - Loss: -0.0161
Epoch [48/50] - Loss: -0.0180
Epoch [49/50] - Loss: -0.0200
Epoch [50/50] - Loss: -0.0218
sum preds 457
sum labels 573
 - Test Metrics: Accuracy=0.9050, F1=0.7728, Recall=0.6946, Precision=0.8709
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5009
Epoch [2/50] - Loss: 0.4797
Epoch [3/50] - Loss: 0.4562
Epoch [4/50] - Loss: 0.4281
Epoch [5/50] - Loss: 0.3974
Epoch [6/50] - Loss: 0.3664
Epoch [7/50] - Loss: 0.3367
Epoch [8/50] - Loss: 0.3083
Epoch [9/50] - Loss: 0.2813
Epoch [10/50] - Loss: 0.2557
Epoch [11/50] - Loss: 0.2317
Epoch [12/50] - Loss: 0.2094
Epoch [13/50] - Loss: 0.1888
Epoch [14/50] - Loss: 0.1701
Epoch [15/50] - Loss: 0.1530
Epoch [16/50] - Loss: 0.1376
Epoch [17/50] - Loss: 0.1236
Epoch [18/50] - Loss: 0.1110
Epoch [19/50] - Loss: 0.0996
Epoch [20/50] - Loss: 0.0893
Epoch [21/50] - Loss: 0.0800
Epoch [22/50] - Loss: 0.0714
Epoch [23/50] - Loss: 0.0637
Epoch [24/50] - Loss: 0.0566
Epoch [25/50] - Loss: 0.0500
Epoch [26/50] - Loss: 0.0440
Epoch [27/50] - Loss: 0.0384
Epoch [28/50] - Loss: 0.0332
Epoch [29/50] - Loss: 0.0284
Epoch [30/50] - Loss: 0.0239
Epoch [31/50] - Loss: 0.0197
Epoch [32/50] - Loss: 0.0158
Epoch [33/50] - Loss: 0.0121
Epoch [34/50] - Loss: 0.0087
Epoch [35/50] - Loss: 0.0055
Epoch [36/50] - Loss: 0.0025
Epoch [37/50] - Loss: -0.0003
Epoch [38/50] - Loss: -0.0030
Epoch [39/50] - Loss: -0.0055
Epoch [40/50] - Loss: -0.0079
Epoch [41/50] - Loss: -0.0101
Epoch [42/50] - Loss: -0.0122
Epoch [43/50] - Loss: -0.0141
Epoch [44/50] - Loss: -0.0160
Epoch [45/50] - Loss: -0.0178
Epoch [46/50] - Loss: -0.0195
Epoch [47/50] - Loss: -0.0211
Epoch [48/50] - Loss: -0.0227
Epoch [49/50] - Loss: -0.0242
Epoch [50/50] - Loss: -0.0256
sum preds 488
sum labels 573
 - Test Metrics: Accuracy=0.9241, F1=0.8238, Recall=0.7627, Precision=0.8955
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5007
Epoch [2/50] - Loss: 0.4865
Epoch [3/50] - Loss: 0.4715
Epoch [4/50] - Loss: 0.4524
Epoch [5/50] - Loss: 0.4302
Epoch [6/50] - Loss: 0.4065
Epoch [7/50] - Loss: 0.3828
Epoch [8/50] - Loss: 0.3591
Epoch [9/50] - Loss: 0.3355
Epoch [10/50] - Loss: 0.3122
Epoch [11/50] - Loss: 0.2894
Epoch [12/50] - Loss: 0.2672
Epoch [13/50] - Loss: 0.2460
Epoch [14/50] - Loss: 0.2259
Epoch [15/50] - Loss: 0.2069
Epoch [16/50] - Loss: 0.1892
Epoch [17/50] - Loss: 0.1727
Epoch [18/50] - Loss: 0.1575
Epoch [19/50] - Loss: 0.1434
Epoch [20/50] - Loss: 0.1304
Epoch [21/50] - Loss: 0.1184
Epoch [22/50] - Loss: 0.1075
Epoch [23/50] - Loss: 0.0975
Epoch [24/50] - Loss: 0.0883
Epoch [25/50] - Loss: 0.0800
Epoch [26/50] - Loss: 0.0723
Epoch [27/50] - Loss: 0.0652
Epoch [28/50] - Loss: 0.0588
Epoch [29/50] - Loss: 0.0528
Epoch [30/50] - Loss: 0.0473
Epoch [31/50] - Loss: 0.0422
Epoch [32/50] - Loss: 0.0375
Epoch [33/50] - Loss: 0.0332
Epoch [34/50] - Loss: 0.0291
Epoch [35/50] - Loss: 0.0253
Epoch [36/50] - Loss: 0.0218
Epoch [37/50] - Loss: 0.0185
Epoch [38/50] - Loss: 0.0153
Epoch [39/50] - Loss: 0.0124
Epoch [40/50] - Loss: 0.0096
Epoch [41/50] - Loss: 0.0070
Epoch [42/50] - Loss: 0.0046
Epoch [43/50] - Loss: 0.0022
Epoch [44/50] - Loss: -0.0000
Epoch [45/50] - Loss: -0.0022
Epoch [46/50] - Loss: -0.0042
Epoch [47/50] - Loss: -0.0062
Epoch [48/50] - Loss: -0.0081
Epoch [49/50] - Loss: -0.0099
Epoch [50/50] - Loss: -0.0117
sum preds 501
sum labels 573
 - Test Metrics: Accuracy=0.9326, F1=0.8454, Recall=0.7923, Precision=0.9062
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_imbnnpu_imbnnpu_1804093204.csv.
Average F1 over valid seeds: 0.8140 ± 0.0304
___________________________________________________________________________________
Avg F1 for cora with SCAR and imbnnpu, GCNConv,0.3: 0.8140 ± 0.0304
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4879
Epoch [3/50] - Loss: 0.4734
Epoch [4/50] - Loss: 0.4564
Epoch [5/50] - Loss: 0.4376
Epoch [6/50] - Loss: 0.4173
Epoch [7/50] - Loss: 0.3955
Epoch [8/50] - Loss: 0.3725
Epoch [9/50] - Loss: 0.3486
Epoch [10/50] - Loss: 0.3241
Epoch [11/50] - Loss: 0.2991
Epoch [12/50] - Loss: 0.2740
Epoch [13/50] - Loss: 0.2491
Epoch [14/50] - Loss: 0.2245
Epoch [15/50] - Loss: 0.2005
Epoch [16/50] - Loss: 0.1772
Epoch [17/50] - Loss: 0.1549
Epoch [18/50] - Loss: 0.1336
Epoch [19/50] - Loss: 0.1133
Epoch [20/50] - Loss: 0.0942
Epoch [21/50] - Loss: 0.0763
Epoch [22/50] - Loss: 0.0595
Epoch [23/50] - Loss: 0.0437
Epoch [24/50] - Loss: 0.0291
Epoch [25/50] - Loss: 0.0155
Epoch [26/50] - Loss: 0.0027
Epoch [27/50] - Loss: -0.0090
Epoch [28/50] - Loss: -0.0201
Epoch [29/50] - Loss: -0.0303
Epoch [30/50] - Loss: -0.0398
Epoch [31/50] - Loss: -0.0486
Epoch [32/50] - Loss: -0.0569
Epoch [33/50] - Loss: -0.0645
Epoch [34/50] - Loss: -0.0716
Epoch [35/50] - Loss: -0.0781
Epoch [36/50] - Loss: -0.0842
Epoch [37/50] - Loss: -0.0899
Epoch [38/50] - Loss: -0.0952
Epoch [39/50] - Loss: -0.1001
Epoch [40/50] - Loss: -0.1047
Epoch [41/50] - Loss: -0.1090
Epoch [42/50] - Loss: -0.1129
Epoch [43/50] - Loss: -0.1167
Epoch [44/50] - Loss: -0.1203
Epoch [45/50] - Loss: -0.1237
Epoch [46/50] - Loss: -0.1268
Epoch [47/50] - Loss: -0.1298
Epoch [48/50] - Loss: -0.1327
Epoch [49/50] - Loss: -0.1354
Epoch [50/50] - Loss: -0.1380
sum preds 134
sum labels 654
 - Test Metrics: Accuracy=0.7830, F1=0.2995, Recall=0.1804, Precision=0.8806
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5006
Epoch [2/50] - Loss: 0.4876
Epoch [3/50] - Loss: 0.4724
Epoch [4/50] - Loss: 0.4546
Epoch [5/50] - Loss: 0.4353
Epoch [6/50] - Loss: 0.4147
Epoch [7/50] - Loss: 0.3927
Epoch [8/50] - Loss: 0.3697
Epoch [9/50] - Loss: 0.3457
Epoch [10/50] - Loss: 0.3211
Epoch [11/50] - Loss: 0.2960
Epoch [12/50] - Loss: 0.2709
Epoch [13/50] - Loss: 0.2459
Epoch [14/50] - Loss: 0.2214
Epoch [15/50] - Loss: 0.1977
Epoch [16/50] - Loss: 0.1748
Epoch [17/50] - Loss: 0.1530
Epoch [18/50] - Loss: 0.1323
Epoch [19/50] - Loss: 0.1129
Epoch [20/50] - Loss: 0.0946
Epoch [21/50] - Loss: 0.0775
Epoch [22/50] - Loss: 0.0616
Epoch [23/50] - Loss: 0.0468
Epoch [24/50] - Loss: 0.0330
Epoch [25/50] - Loss: 0.0203
Epoch [26/50] - Loss: 0.0084
Epoch [27/50] - Loss: -0.0026
Epoch [28/50] - Loss: -0.0128
Epoch [29/50] - Loss: -0.0223
Epoch [30/50] - Loss: -0.0311
Epoch [31/50] - Loss: -0.0393
Epoch [32/50] - Loss: -0.0468
Epoch [33/50] - Loss: -0.0538
Epoch [34/50] - Loss: -0.0604
Epoch [35/50] - Loss: -0.0664
Epoch [36/50] - Loss: -0.0720
Epoch [37/50] - Loss: -0.0773
Epoch [38/50] - Loss: -0.0821
Epoch [39/50] - Loss: -0.0867
Epoch [40/50] - Loss: -0.0909
Epoch [41/50] - Loss: -0.0949
Epoch [42/50] - Loss: -0.0987
Epoch [43/50] - Loss: -0.1022
Epoch [44/50] - Loss: -0.1055
Epoch [45/50] - Loss: -0.1087
Epoch [46/50] - Loss: -0.1117
Epoch [47/50] - Loss: -0.1145
Epoch [48/50] - Loss: -0.1172
Epoch [49/50] - Loss: -0.1198
Epoch [50/50] - Loss: -0.1222
sum preds 173
sum labels 654
 - Test Metrics: Accuracy=0.7850, F1=0.3386, Recall=0.2141, Precision=0.8092
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4881
Epoch [3/50] - Loss: 0.4749
Epoch [4/50] - Loss: 0.4598
Epoch [5/50] - Loss: 0.4431
Epoch [6/50] - Loss: 0.4250
Epoch [7/50] - Loss: 0.4057
Epoch [8/50] - Loss: 0.3852
Epoch [9/50] - Loss: 0.3637
Epoch [10/50] - Loss: 0.3416
Epoch [11/50] - Loss: 0.3190
Epoch [12/50] - Loss: 0.2960
Epoch [13/50] - Loss: 0.2729
Epoch [14/50] - Loss: 0.2499
Epoch [15/50] - Loss: 0.2272
Epoch [16/50] - Loss: 0.2049
Epoch [17/50] - Loss: 0.1832
Epoch [18/50] - Loss: 0.1623
Epoch [19/50] - Loss: 0.1422
Epoch [20/50] - Loss: 0.1230
Epoch [21/50] - Loss: 0.1048
Epoch [22/50] - Loss: 0.0877
Epoch [23/50] - Loss: 0.0715
Epoch [24/50] - Loss: 0.0563
Epoch [25/50] - Loss: 0.0422
Epoch [26/50] - Loss: 0.0289
Epoch [27/50] - Loss: 0.0165
Epoch [28/50] - Loss: 0.0049
Epoch [29/50] - Loss: -0.0059
Epoch [30/50] - Loss: -0.0160
Epoch [31/50] - Loss: -0.0253
Epoch [32/50] - Loss: -0.0341
Epoch [33/50] - Loss: -0.0422
Epoch [34/50] - Loss: -0.0499
Epoch [35/50] - Loss: -0.0570
Epoch [36/50] - Loss: -0.0637
Epoch [37/50] - Loss: -0.0701
Epoch [38/50] - Loss: -0.0760
Epoch [39/50] - Loss: -0.0816
Epoch [40/50] - Loss: -0.0869
Epoch [41/50] - Loss: -0.0919
Epoch [42/50] - Loss: -0.0967
Epoch [43/50] - Loss: -0.1012
Epoch [44/50] - Loss: -0.1054
Epoch [45/50] - Loss: -0.1094
Epoch [46/50] - Loss: -0.1132
Epoch [47/50] - Loss: -0.1168
Epoch [48/50] - Loss: -0.1202
Epoch [49/50] - Loss: -0.1235
Epoch [50/50] - Loss: -0.1265
sum preds 150
sum labels 654
 - Test Metrics: Accuracy=0.7830, F1=0.3134, Recall=0.1927, Precision=0.8400
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_imbnnpu_imbnnpu_1804093206.csv.
Average F1 over valid seeds: 0.3172 ± 0.0162
___________________________________________________________________________________
Avg F1 for cora with SCAR and imbnnpu, MLP,0.2: 0.3172 ± 0.0162
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5012
Epoch [2/50] - Loss: 0.4761
Epoch [3/50] - Loss: 0.4492
Epoch [4/50] - Loss: 0.4189
Epoch [5/50] - Loss: 0.3876
Epoch [6/50] - Loss: 0.3566
Epoch [7/50] - Loss: 0.3267
Epoch [8/50] - Loss: 0.2982
Epoch [9/50] - Loss: 0.2714
Epoch [10/50] - Loss: 0.2462
Epoch [11/50] - Loss: 0.2228
Epoch [12/50] - Loss: 0.2011
Epoch [13/50] - Loss: 0.1810
Epoch [14/50] - Loss: 0.1624
Epoch [15/50] - Loss: 0.1453
Epoch [16/50] - Loss: 0.1296
Epoch [17/50] - Loss: 0.1150
Epoch [18/50] - Loss: 0.1017
Epoch [19/50] - Loss: 0.0892
Epoch [20/50] - Loss: 0.0776
Epoch [21/50] - Loss: 0.0670
Epoch [22/50] - Loss: 0.0575
Epoch [23/50] - Loss: 0.0488
Epoch [24/50] - Loss: 0.0408
Epoch [25/50] - Loss: 0.0334
Epoch [26/50] - Loss: 0.0267
Epoch [27/50] - Loss: 0.0205
Epoch [28/50] - Loss: 0.0148
Epoch [29/50] - Loss: 0.0094
Epoch [30/50] - Loss: 0.0042
Epoch [31/50] - Loss: -0.0005
Epoch [32/50] - Loss: -0.0049
Epoch [33/50] - Loss: -0.0088
Epoch [34/50] - Loss: -0.0126
Epoch [35/50] - Loss: -0.0166
Epoch [36/50] - Loss: -0.0206
Epoch [37/50] - Loss: -0.0245
Epoch [38/50] - Loss: -0.0285
Epoch [39/50] - Loss: -0.0326
Epoch [40/50] - Loss: -0.0359
Epoch [41/50] - Loss: -0.0393
Epoch [42/50] - Loss: -0.0423
Epoch [43/50] - Loss: -0.0447
Epoch [44/50] - Loss: -0.0469
Epoch [45/50] - Loss: -0.0488
Epoch [46/50] - Loss: -0.0507
Epoch [47/50] - Loss: -0.0526
Epoch [48/50] - Loss: -0.0544
Epoch [49/50] - Loss: -0.0561
Epoch [50/50] - Loss: -0.0577
sum preds 383
sum labels 654
 - Test Metrics: Accuracy=0.8573, F1=0.6500, Recall=0.5153, Precision=0.8799
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5002
Epoch [2/50] - Loss: 0.4867
Epoch [3/50] - Loss: 0.4715
Epoch [4/50] - Loss: 0.4534
Epoch [5/50] - Loss: 0.4329
Epoch [6/50] - Loss: 0.4105
Epoch [7/50] - Loss: 0.3868
Epoch [8/50] - Loss: 0.3625
Epoch [9/50] - Loss: 0.3375
Epoch [10/50] - Loss: 0.3119
Epoch [11/50] - Loss: 0.2861
Epoch [12/50] - Loss: 0.2602
Epoch [13/50] - Loss: 0.2348
Epoch [14/50] - Loss: 0.2104
Epoch [15/50] - Loss: 0.1871
Epoch [16/50] - Loss: 0.1654
Epoch [17/50] - Loss: 0.1455
Epoch [18/50] - Loss: 0.1275
Epoch [19/50] - Loss: 0.1112
Epoch [20/50] - Loss: 0.0966
Epoch [21/50] - Loss: 0.0834
Epoch [22/50] - Loss: 0.0715
Epoch [23/50] - Loss: 0.0607
Epoch [24/50] - Loss: 0.0507
Epoch [25/50] - Loss: 0.0416
Epoch [26/50] - Loss: 0.0333
Epoch [27/50] - Loss: 0.0256
Epoch [28/50] - Loss: 0.0185
Epoch [29/50] - Loss: 0.0120
Epoch [30/50] - Loss: 0.0056
Epoch [31/50] - Loss: -0.0007
Epoch [32/50] - Loss: -0.0066
Epoch [33/50] - Loss: -0.0122
Epoch [34/50] - Loss: -0.0175
Epoch [35/50] - Loss: -0.0223
Epoch [36/50] - Loss: -0.0268
Epoch [37/50] - Loss: -0.0310
Epoch [38/50] - Loss: -0.0351
Epoch [39/50] - Loss: -0.0389
Epoch [40/50] - Loss: -0.0426
Epoch [41/50] - Loss: -0.0460
Epoch [42/50] - Loss: -0.0494
Epoch [43/50] - Loss: -0.0527
Epoch [44/50] - Loss: -0.0560
Epoch [45/50] - Loss: -0.0592
Epoch [46/50] - Loss: -0.0625
Epoch [47/50] - Loss: -0.0659
Epoch [48/50] - Loss: -0.0688
Epoch [49/50] - Loss: -0.0717
Epoch [50/50] - Loss: -0.0747
sum preds 380
sum labels 654
 - Test Metrics: Accuracy=0.8412, F1=0.6093, Recall=0.4817, Precision=0.8289
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4985
Epoch [2/50] - Loss: 0.4770
Epoch [3/50] - Loss: 0.4532
Epoch [4/50] - Loss: 0.4260
Epoch [5/50] - Loss: 0.3966
Epoch [6/50] - Loss: 0.3661
Epoch [7/50] - Loss: 0.3354
Epoch [8/50] - Loss: 0.3048
Epoch [9/50] - Loss: 0.2747
Epoch [10/50] - Loss: 0.2459
Epoch [11/50] - Loss: 0.2187
Epoch [12/50] - Loss: 0.1935
Epoch [13/50] - Loss: 0.1703
Epoch [14/50] - Loss: 0.1490
Epoch [15/50] - Loss: 0.1297
Epoch [16/50] - Loss: 0.1120
Epoch [17/50] - Loss: 0.0956
Epoch [18/50] - Loss: 0.0805
Epoch [19/50] - Loss: 0.0666
Epoch [20/50] - Loss: 0.0540
Epoch [21/50] - Loss: 0.0426
Epoch [22/50] - Loss: 0.0323
Epoch [23/50] - Loss: 0.0231
Epoch [24/50] - Loss: 0.0148
Epoch [25/50] - Loss: 0.0072
Epoch [26/50] - Loss: 0.0005
Epoch [27/50] - Loss: -0.0056
Epoch [28/50] - Loss: -0.0111
Epoch [29/50] - Loss: -0.0162
Epoch [30/50] - Loss: -0.0208
Epoch [31/50] - Loss: -0.0251
Epoch [32/50] - Loss: -0.0292
Epoch [33/50] - Loss: -0.0332
Epoch [34/50] - Loss: -0.0370
Epoch [35/50] - Loss: -0.0407
Epoch [36/50] - Loss: -0.0444
Epoch [37/50] - Loss: -0.0481
Epoch [38/50] - Loss: -0.0516
Epoch [39/50] - Loss: -0.0549
Epoch [40/50] - Loss: -0.0581
Epoch [41/50] - Loss: -0.0610
Epoch [42/50] - Loss: -0.0637
Epoch [43/50] - Loss: -0.0664
Epoch [44/50] - Loss: -0.0691
Epoch [45/50] - Loss: -0.0718
Epoch [46/50] - Loss: -0.0742
Epoch [47/50] - Loss: -0.0766
Epoch [48/50] - Loss: -0.0789
Epoch [49/50] - Loss: -0.0809
Epoch [50/50] - Loss: -0.0828
sum preds 333
sum labels 654
 - Test Metrics: Accuracy=0.8447, F1=0.5998, Recall=0.4526, Precision=0.8889
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_imbnnpu_imbnnpu_1804093207.csv.
Average F1 over valid seeds: 0.6197 ± 0.0218
___________________________________________________________________________________
Avg F1 for cora with SCAR and imbnnpu, GATConv,0.2: 0.6197 ± 0.0218
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4992
Epoch [2/50] - Loss: 0.4778
Epoch [3/50] - Loss: 0.4542
Epoch [4/50] - Loss: 0.4279
Epoch [5/50] - Loss: 0.4004
Epoch [6/50] - Loss: 0.3726
Epoch [7/50] - Loss: 0.3452
Epoch [8/50] - Loss: 0.3184
Epoch [9/50] - Loss: 0.2927
Epoch [10/50] - Loss: 0.2682
Epoch [11/50] - Loss: 0.2451
Epoch [12/50] - Loss: 0.2236
Epoch [13/50] - Loss: 0.2036
Epoch [14/50] - Loss: 0.1852
Epoch [15/50] - Loss: 0.1684
Epoch [16/50] - Loss: 0.1530
Epoch [17/50] - Loss: 0.1390
Epoch [18/50] - Loss: 0.1262
Epoch [19/50] - Loss: 0.1145
Epoch [20/50] - Loss: 0.1038
Epoch [21/50] - Loss: 0.0940
Epoch [22/50] - Loss: 0.0851
Epoch [23/50] - Loss: 0.0769
Epoch [24/50] - Loss: 0.0693
Epoch [25/50] - Loss: 0.0623
Epoch [26/50] - Loss: 0.0559
Epoch [27/50] - Loss: 0.0499
Epoch [28/50] - Loss: 0.0444
Epoch [29/50] - Loss: 0.0392
Epoch [30/50] - Loss: 0.0344
Epoch [31/50] - Loss: 0.0299
Epoch [32/50] - Loss: 0.0257
Epoch [33/50] - Loss: 0.0218
Epoch [34/50] - Loss: 0.0180
Epoch [35/50] - Loss: 0.0146
Epoch [36/50] - Loss: 0.0112
Epoch [37/50] - Loss: 0.0081
Epoch [38/50] - Loss: 0.0051
Epoch [39/50] - Loss: 0.0023
Epoch [40/50] - Loss: -0.0004
Epoch [41/50] - Loss: -0.0030
Epoch [42/50] - Loss: -0.0055
Epoch [43/50] - Loss: -0.0079
Epoch [44/50] - Loss: -0.0101
Epoch [45/50] - Loss: -0.0123
Epoch [46/50] - Loss: -0.0145
Epoch [47/50] - Loss: -0.0166
Epoch [48/50] - Loss: -0.0186
Epoch [49/50] - Loss: -0.0205
Epoch [50/50] - Loss: -0.0224
sum preds 453
sum labels 654
 - Test Metrics: Accuracy=0.8856, F1=0.7371, Recall=0.6239, Precision=0.9007
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4784
Epoch [3/50] - Loss: 0.4544
Epoch [4/50] - Loss: 0.4260
Epoch [5/50] - Loss: 0.3949
Epoch [6/50] - Loss: 0.3638
Epoch [7/50] - Loss: 0.3338
Epoch [8/50] - Loss: 0.3050
Epoch [9/50] - Loss: 0.2774
Epoch [10/50] - Loss: 0.2513
Epoch [11/50] - Loss: 0.2267
Epoch [12/50] - Loss: 0.2038
Epoch [13/50] - Loss: 0.1829
Epoch [14/50] - Loss: 0.1637
Epoch [15/50] - Loss: 0.1462
Epoch [16/50] - Loss: 0.1303
Epoch [17/50] - Loss: 0.1158
Epoch [18/50] - Loss: 0.1026
Epoch [19/50] - Loss: 0.0906
Epoch [20/50] - Loss: 0.0797
Epoch [21/50] - Loss: 0.0698
Epoch [22/50] - Loss: 0.0607
Epoch [23/50] - Loss: 0.0524
Epoch [24/50] - Loss: 0.0448
Epoch [25/50] - Loss: 0.0378
Epoch [26/50] - Loss: 0.0313
Epoch [27/50] - Loss: 0.0254
Epoch [28/50] - Loss: 0.0199
Epoch [29/50] - Loss: 0.0148
Epoch [30/50] - Loss: 0.0100
Epoch [31/50] - Loss: 0.0056
Epoch [32/50] - Loss: 0.0015
Epoch [33/50] - Loss: -0.0024
Epoch [34/50] - Loss: -0.0061
Epoch [35/50] - Loss: -0.0096
Epoch [36/50] - Loss: -0.0128
Epoch [37/50] - Loss: -0.0159
Epoch [38/50] - Loss: -0.0189
Epoch [39/50] - Loss: -0.0217
Epoch [40/50] - Loss: -0.0244
Epoch [41/50] - Loss: -0.0269
Epoch [42/50] - Loss: -0.0294
Epoch [43/50] - Loss: -0.0318
Epoch [44/50] - Loss: -0.0341
Epoch [45/50] - Loss: -0.0363
Epoch [46/50] - Loss: -0.0385
Epoch [47/50] - Loss: -0.0406
Epoch [48/50] - Loss: -0.0426
Epoch [49/50] - Loss: -0.0446
Epoch [50/50] - Loss: -0.0466
sum preds 466
sum labels 654
 - Test Metrics: Accuracy=0.8970, F1=0.7661, Recall=0.6560, Precision=0.9206
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5011
Epoch [2/50] - Loss: 0.4869
Epoch [3/50] - Loss: 0.4718
Epoch [4/50] - Loss: 0.4533
Epoch [5/50] - Loss: 0.4317
Epoch [6/50] - Loss: 0.4089
Epoch [7/50] - Loss: 0.3860
Epoch [8/50] - Loss: 0.3629
Epoch [9/50] - Loss: 0.3398
Epoch [10/50] - Loss: 0.3169
Epoch [11/50] - Loss: 0.2944
Epoch [12/50] - Loss: 0.2726
Epoch [13/50] - Loss: 0.2517
Epoch [14/50] - Loss: 0.2320
Epoch [15/50] - Loss: 0.2134
Epoch [16/50] - Loss: 0.1959
Epoch [17/50] - Loss: 0.1797
Epoch [18/50] - Loss: 0.1646
Epoch [19/50] - Loss: 0.1506
Epoch [20/50] - Loss: 0.1377
Epoch [21/50] - Loss: 0.1259
Epoch [22/50] - Loss: 0.1150
Epoch [23/50] - Loss: 0.1050
Epoch [24/50] - Loss: 0.0958
Epoch [25/50] - Loss: 0.0873
Epoch [26/50] - Loss: 0.0795
Epoch [27/50] - Loss: 0.0723
Epoch [28/50] - Loss: 0.0657
Epoch [29/50] - Loss: 0.0595
Epoch [30/50] - Loss: 0.0538
Epoch [31/50] - Loss: 0.0484
Epoch [32/50] - Loss: 0.0434
Epoch [33/50] - Loss: 0.0387
Epoch [34/50] - Loss: 0.0342
Epoch [35/50] - Loss: 0.0300
Epoch [36/50] - Loss: 0.0260
Epoch [37/50] - Loss: 0.0223
Epoch [38/50] - Loss: 0.0187
Epoch [39/50] - Loss: 0.0153
Epoch [40/50] - Loss: 0.0121
Epoch [41/50] - Loss: 0.0089
Epoch [42/50] - Loss: 0.0060
Epoch [43/50] - Loss: 0.0031
Epoch [44/50] - Loss: 0.0004
Epoch [45/50] - Loss: -0.0022
Epoch [46/50] - Loss: -0.0047
Epoch [47/50] - Loss: -0.0071
Epoch [48/50] - Loss: -0.0095
Epoch [49/50] - Loss: -0.0117
Epoch [50/50] - Loss: -0.0138
sum preds 476
sum labels 654
 - Test Metrics: Accuracy=0.8962, F1=0.7664, Recall=0.6621, Precision=0.9097
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_imbnnpu_imbnnpu_1804093210.csv.
Average F1 over valid seeds: 0.7565 ± 0.0137
___________________________________________________________________________________
Avg F1 for cora with SCAR and imbnnpu, GCNConv,0.2: 0.7565 ± 0.0137
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.6914
Epoch 10 / 50, Loss: 6.1803
Epoch 20 / 50, Loss: 6.4346
Epoch 30 / 50, Loss: 6.4415
Epoch 40 / 50, Loss: 5.9847
sum preds 230.0
sum labels 491
 - Test Metrics: Accuracy=0.8778, F1=0.5964, Recall=0.4379, Precision=0.9348
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 5.9485
Epoch 10 / 50, Loss: 6.0485
Epoch 20 / 50, Loss: 5.7953
Epoch 30 / 50, Loss: 5.7249
Epoch 40 / 50, Loss: 5.4936
sum preds 217.0
sum labels 491
 - Test Metrics: Accuracy=0.8723, F1=0.5706, Recall=0.4114, Precision=0.9309
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.2275
Epoch 10 / 50, Loss: 6.1000
Epoch 20 / 50, Loss: 6.0331
Epoch 30 / 50, Loss: 6.0940
Epoch 40 / 50, Loss: 5.6871
sum preds 219.0
sum labels 491
 - Test Metrics: Accuracy=0.8765, F1=0.5859, Recall=0.4236, Precision=0.9498
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_ours_1804093212.csv.
Average F1 over valid seeds: 0.5843 ± 0.0106
___________________________________________________________________________________
Avg F1 for cora with SCAR and ours, GCNConv,0.4: 0.5843 ± 0.0106
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.3711
Epoch 10 / 50, Loss: 6.9533
Epoch 20 / 50, Loss: 7.1761
Epoch 30 / 50, Loss: 6.9498
Epoch 40 / 50, Loss: 6.5957
sum preds 234.0
sum labels 573
 - Test Metrics: Accuracy=0.8526, F1=0.5502, Recall=0.3874, Precision=0.9487
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.7818
Epoch 10 / 50, Loss: 6.7625
Epoch 20 / 50, Loss: 6.6896
Epoch 30 / 50, Loss: 6.5066
Epoch 40 / 50, Loss: 6.2176
sum preds 239.0
sum labels 573
 - Test Metrics: Accuracy=0.8555, F1=0.5616, Recall=0.3979, Precision=0.9540
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.0665
Epoch 10 / 50, Loss: 6.9867
Epoch 20 / 50, Loss: 7.0373
Epoch 30 / 50, Loss: 7.1347
Epoch 40 / 50, Loss: 6.5585
sum preds 260.0
sum labels 573
 - Test Metrics: Accuracy=0.8616, F1=0.5906, Recall=0.4293, Precision=0.9462
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_ours_1804093252.csv.
Average F1 over valid seeds: 0.5675 ± 0.0170
___________________________________________________________________________________
Avg F1 for cora with SCAR and ours, GCNConv,0.3: 0.5675 ± 0.0170
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 8.1685
Epoch 10 / 50, Loss: 8.1645
Epoch 20 / 50, Loss: 8.1551
Epoch 30 / 50, Loss: 8.1026
Epoch 40 / 50, Loss: 7.7548
sum preds 139.0
sum labels 654
 - Test Metrics: Accuracy=0.7952, F1=0.3430, Recall=0.2080, Precision=0.9784
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.5417
Epoch 10 / 50, Loss: 7.6869
Epoch 20 / 50, Loss: 7.6551
Epoch 30 / 50, Loss: 7.3973
Epoch 40 / 50, Loss: 7.1858
sum preds 137.0
sum labels 654
 - Test Metrics: Accuracy=0.7928, F1=0.3338, Recall=0.2018, Precision=0.9635
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 8.3460
Epoch 10 / 50, Loss: 8.5156
Epoch 20 / 50, Loss: 8.2171
Epoch 30 / 50, Loss: 8.6327
Epoch 40 / 50, Loss: 7.5635
sum preds 219.0
sum labels 654
 - Test Metrics: Accuracy=0.8211, F1=0.4788, Recall=0.3196, Precision=0.9543
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SCAR_ours_1804093331.csv.
Average F1 over valid seeds: 0.3852 ± 0.0663
___________________________________________________________________________________
Avg F1 for cora with SCAR and ours, GCNConv,0.2: 0.3852 ± 0.0663
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3891
Epoch [2/50] - Loss: 1.2405
Epoch [3/50] - Loss: 1.1015
Epoch [4/50] - Loss: 0.9736
Epoch [5/50] - Loss: 0.8674
Epoch [6/50] - Loss: 0.7949
Epoch [7/50] - Loss: 0.7488
Epoch [8/50] - Loss: 0.7203
Epoch [9/50] - Loss: 0.7121
Epoch [10/50] - Loss: 0.7008
Epoch [11/50] - Loss: 0.6871
Epoch [12/50] - Loss: 0.6838
Epoch [13/50] - Loss: 0.6623
Epoch [14/50] - Loss: 0.6312
Epoch [15/50] - Loss: 0.6080
Epoch [16/50] - Loss: 0.5941
Epoch [17/50] - Loss: 0.5724
Epoch [18/50] - Loss: 0.5504
Epoch [19/50] - Loss: 0.5422
Epoch [20/50] - Loss: 0.5244
Epoch [21/50] - Loss: 0.5126
Epoch [22/50] - Loss: 0.5074
Epoch [23/50] - Loss: 0.4909
Epoch [24/50] - Loss: 0.4768
Epoch [25/50] - Loss: 0.4629
Epoch [26/50] - Loss: 0.4509
Epoch [27/50] - Loss: 0.4313
Epoch [28/50] - Loss: 0.4279
Epoch [29/50] - Loss: 0.4105
Epoch [30/50] - Loss: 0.4020
Epoch [31/50] - Loss: 0.3906
Epoch [32/50] - Loss: 0.3790
Epoch [33/50] - Loss: 0.3723
Epoch [34/50] - Loss: 0.3557
Epoch [35/50] - Loss: 0.3434
Epoch [36/50] - Loss: 0.3305
Epoch [37/50] - Loss: 0.3221
Epoch [38/50] - Loss: 0.3100
Epoch [39/50] - Loss: 0.2951
Epoch [40/50] - Loss: 0.2823
Epoch [41/50] - Loss: 0.2653
Epoch [42/50] - Loss: 0.2575
Epoch [43/50] - Loss: 0.2386
Epoch [44/50] - Loss: 0.2238
Epoch [45/50] - Loss: 0.2111
Epoch [46/50] - Loss: 0.1984
Epoch [47/50] - Loss: 0.1861
Epoch [48/50] - Loss: 0.1761
Epoch [49/50] - Loss: 0.1646
Epoch [50/50] - Loss: 0.1563
sum preds 1
sum labels 491
 - Test Metrics: Accuracy=0.7942, F1=0.0041, Recall=0.0020, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3203
Epoch [2/50] - Loss: 1.1094
Epoch [3/50] - Loss: 0.9298
Epoch [4/50] - Loss: 0.8014
Epoch [5/50] - Loss: 0.7313
Epoch [6/50] - Loss: 0.6971
Epoch [7/50] - Loss: 0.6897
Epoch [8/50] - Loss: 0.6762
Epoch [9/50] - Loss: 0.6571
Epoch [10/50] - Loss: 0.6264
Epoch [11/50] - Loss: 0.6020
Epoch [12/50] - Loss: 0.5683
Epoch [13/50] - Loss: 0.5424
Epoch [14/50] - Loss: 0.5172
Epoch [15/50] - Loss: 0.5016
Epoch [16/50] - Loss: 0.4861
Epoch [17/50] - Loss: 0.4752
Epoch [18/50] - Loss: 0.4614
Epoch [19/50] - Loss: 0.4472
Epoch [20/50] - Loss: 0.4326
Epoch [21/50] - Loss: 0.4134
Epoch [22/50] - Loss: 0.4033
Epoch [23/50] - Loss: 0.3903
Epoch [24/50] - Loss: 0.3790
Epoch [25/50] - Loss: 0.3655
Epoch [26/50] - Loss: 0.3569
Epoch [27/50] - Loss: 0.3450
Epoch [28/50] - Loss: 0.3336
Epoch [29/50] - Loss: 0.3254
Epoch [30/50] - Loss: 0.3226
Epoch [31/50] - Loss: 0.3093
Epoch [32/50] - Loss: 0.3004
Epoch [33/50] - Loss: 0.2963
Epoch [34/50] - Loss: 0.2912
Epoch [35/50] - Loss: 0.2802
Epoch [36/50] - Loss: 0.2718
Epoch [37/50] - Loss: 0.2688
Epoch [38/50] - Loss: 0.2614
Epoch [39/50] - Loss: 0.2594
Epoch [40/50] - Loss: 0.2516
Epoch [41/50] - Loss: 0.2471
Epoch [42/50] - Loss: 0.2397
Epoch [43/50] - Loss: 0.2374
Epoch [44/50] - Loss: 0.2318
Epoch [45/50] - Loss: 0.2183
Epoch [46/50] - Loss: 0.2166
Epoch [47/50] - Loss: 0.2047
Epoch [48/50] - Loss: 0.1951
Epoch [49/50] - Loss: 0.1840
Epoch [50/50] - Loss: 0.1730
sum preds 35
sum labels 491
 - Test Metrics: Accuracy=0.8060, F1=0.1217, Recall=0.0652, Precision=0.9143
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.5139
Epoch [2/50] - Loss: 1.3472
Epoch [3/50] - Loss: 1.1869
Epoch [4/50] - Loss: 1.0307
Epoch [5/50] - Loss: 0.8960
Epoch [6/50] - Loss: 0.8052
Epoch [7/50] - Loss: 0.7536
Epoch [8/50] - Loss: 0.7265
Epoch [9/50] - Loss: 0.7272
Epoch [10/50] - Loss: 0.7201
Epoch [11/50] - Loss: 0.7109
Epoch [12/50] - Loss: 0.6886
Epoch [13/50] - Loss: 0.6618
Epoch [14/50] - Loss: 0.6251
Epoch [15/50] - Loss: 0.6019
Epoch [16/50] - Loss: 0.5734
Epoch [17/50] - Loss: 0.5617
Epoch [18/50] - Loss: 0.5443
Epoch [19/50] - Loss: 0.5325
Epoch [20/50] - Loss: 0.5235
Epoch [21/50] - Loss: 0.5058
Epoch [22/50] - Loss: 0.4864
Epoch [23/50] - Loss: 0.4746
Epoch [24/50] - Loss: 0.4590
Epoch [25/50] - Loss: 0.4416
Epoch [26/50] - Loss: 0.4278
Epoch [27/50] - Loss: 0.4098
Epoch [28/50] - Loss: 0.4030
Epoch [29/50] - Loss: 0.3871
Epoch [30/50] - Loss: 0.3800
Epoch [31/50] - Loss: 0.3730
Epoch [32/50] - Loss: 0.3581
Epoch [33/50] - Loss: 0.3500
Epoch [34/50] - Loss: 0.3398
Epoch [35/50] - Loss: 0.3235
Epoch [36/50] - Loss: 0.3209
Epoch [37/50] - Loss: 0.3112
Epoch [38/50] - Loss: 0.2974
Epoch [39/50] - Loss: 0.2882
Epoch [40/50] - Loss: 0.2701
Epoch [41/50] - Loss: 0.2625
Epoch [42/50] - Loss: 0.2545
Epoch [43/50] - Loss: 0.2447
Epoch [44/50] - Loss: 0.2312
Epoch [45/50] - Loss: 0.2203
Epoch [46/50] - Loss: 0.2110
Epoch [47/50] - Loss: 0.1993
Epoch [48/50] - Loss: 0.1942
Epoch [49/50] - Loss: 0.1842
Epoch [50/50] - Loss: 0.1723
sum preds 8
sum labels 491
 - Test Metrics: Accuracy=0.7963, F1=0.0281, Recall=0.0143, Precision=0.8750
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_naive_naive_1804093409.csv.
Average F1 over valid seeds: 0.0513 ± 0.0507
___________________________________________________________________________________
Avg F1 for cora with SAR and naive, MLP,0.4: 0.0513 ± 0.0507
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3190
Epoch [2/50] - Loss: 0.9683
Epoch [3/50] - Loss: 0.7692
Epoch [4/50] - Loss: 0.6971
Epoch [5/50] - Loss: 0.6999
Epoch [6/50] - Loss: 0.6844
Epoch [7/50] - Loss: 0.6843
Epoch [8/50] - Loss: 0.6381
Epoch [9/50] - Loss: 0.6038
Epoch [10/50] - Loss: 0.5667
Epoch [11/50] - Loss: 0.5397
Epoch [12/50] - Loss: 0.5246
Epoch [13/50] - Loss: 0.5226
Epoch [14/50] - Loss: 0.5105
Epoch [15/50] - Loss: 0.5069
Epoch [16/50] - Loss: 0.4951
Epoch [17/50] - Loss: 0.4783
Epoch [18/50] - Loss: 0.4732
Epoch [19/50] - Loss: 0.4626
Epoch [20/50] - Loss: 0.4562
Epoch [21/50] - Loss: 0.4520
Epoch [22/50] - Loss: 0.4439
Epoch [23/50] - Loss: 0.4376
Epoch [24/50] - Loss: 0.4350
Epoch [25/50] - Loss: 0.4241
Epoch [26/50] - Loss: 0.4244
Epoch [27/50] - Loss: 0.4168
Epoch [28/50] - Loss: 0.4151
Epoch [29/50] - Loss: 0.4081
Epoch [30/50] - Loss: 0.4077
Epoch [31/50] - Loss: 0.4041
Epoch [32/50] - Loss: 0.3989
Epoch [33/50] - Loss: 0.3990
Epoch [34/50] - Loss: 0.3912
Epoch [35/50] - Loss: 0.3912
Epoch [36/50] - Loss: 0.3864
Epoch [37/50] - Loss: 0.3844
Epoch [38/50] - Loss: 0.3860
Epoch [39/50] - Loss: 0.3848
Epoch [40/50] - Loss: 0.3792
Epoch [41/50] - Loss: 0.3763
Epoch [42/50] - Loss: 0.3761
Epoch [43/50] - Loss: 0.3711
Epoch [44/50] - Loss: 0.3726
Epoch [45/50] - Loss: 0.3675
Epoch [46/50] - Loss: 0.3654
Epoch [47/50] - Loss: 0.3573
Epoch [48/50] - Loss: 0.3541
Epoch [49/50] - Loss: 0.3566
Epoch [50/50] - Loss: 0.3488
sum preds 40
sum labels 491
 - Test Metrics: Accuracy=0.8089, F1=0.1431, Recall=0.0774, Precision=0.9500
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2507
Epoch [2/50] - Loss: 0.9051
Epoch [3/50] - Loss: 0.7335
Epoch [4/50] - Loss: 0.6973
Epoch [5/50] - Loss: 0.7005
Epoch [6/50] - Loss: 0.6860
Epoch [7/50] - Loss: 0.6526
Epoch [8/50] - Loss: 0.6197
Epoch [9/50] - Loss: 0.5752
Epoch [10/50] - Loss: 0.5395
Epoch [11/50] - Loss: 0.5314
Epoch [12/50] - Loss: 0.5207
Epoch [13/50] - Loss: 0.5192
Epoch [14/50] - Loss: 0.5101
Epoch [15/50] - Loss: 0.4921
Epoch [16/50] - Loss: 0.4839
Epoch [17/50] - Loss: 0.4654
Epoch [18/50] - Loss: 0.4651
Epoch [19/50] - Loss: 0.4599
Epoch [20/50] - Loss: 0.4505
Epoch [21/50] - Loss: 0.4398
Epoch [22/50] - Loss: 0.4357
Epoch [23/50] - Loss: 0.4320
Epoch [24/50] - Loss: 0.4229
Epoch [25/50] - Loss: 0.4252
Epoch [26/50] - Loss: 0.4253
Epoch [27/50] - Loss: 0.4106
Epoch [28/50] - Loss: 0.4092
Epoch [29/50] - Loss: 0.4073
Epoch [30/50] - Loss: 0.4021
Epoch [31/50] - Loss: 0.4012
Epoch [32/50] - Loss: 0.4009
Epoch [33/50] - Loss: 0.3945
Epoch [34/50] - Loss: 0.3935
Epoch [35/50] - Loss: 0.3871
Epoch [36/50] - Loss: 0.3822
Epoch [37/50] - Loss: 0.3841
Epoch [38/50] - Loss: 0.3834
Epoch [39/50] - Loss: 0.3760
Epoch [40/50] - Loss: 0.3782
Epoch [41/50] - Loss: 0.3686
Epoch [42/50] - Loss: 0.3627
Epoch [43/50] - Loss: 0.3632
Epoch [44/50] - Loss: 0.3530
Epoch [45/50] - Loss: 0.3559
Epoch [46/50] - Loss: 0.3516
Epoch [47/50] - Loss: 0.3521
Epoch [48/50] - Loss: 0.3429
Epoch [49/50] - Loss: 0.3388
Epoch [50/50] - Loss: 0.3375
sum preds 73
sum labels 491
 - Test Metrics: Accuracy=0.8228, F1=0.2518, Recall=0.1446, Precision=0.9726
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2222
Epoch [2/50] - Loss: 0.8512
Epoch [3/50] - Loss: 0.7039
Epoch [4/50] - Loss: 0.6851
Epoch [5/50] - Loss: 0.7004
Epoch [6/50] - Loss: 0.6661
Epoch [7/50] - Loss: 0.6321
Epoch [8/50] - Loss: 0.5819
Epoch [9/50] - Loss: 0.5493
Epoch [10/50] - Loss: 0.5254
Epoch [11/50] - Loss: 0.5170
Epoch [12/50] - Loss: 0.5123
Epoch [13/50] - Loss: 0.5022
Epoch [14/50] - Loss: 0.4925
Epoch [15/50] - Loss: 0.4740
Epoch [16/50] - Loss: 0.4630
Epoch [17/50] - Loss: 0.4631
Epoch [18/50] - Loss: 0.4489
Epoch [19/50] - Loss: 0.4476
Epoch [20/50] - Loss: 0.4476
Epoch [21/50] - Loss: 0.4402
Epoch [22/50] - Loss: 0.4338
Epoch [23/50] - Loss: 0.4286
Epoch [24/50] - Loss: 0.4160
Epoch [25/50] - Loss: 0.4178
Epoch [26/50] - Loss: 0.4092
Epoch [27/50] - Loss: 0.4086
Epoch [28/50] - Loss: 0.4097
Epoch [29/50] - Loss: 0.3978
Epoch [30/50] - Loss: 0.4018
Epoch [31/50] - Loss: 0.3974
Epoch [32/50] - Loss: 0.3986
Epoch [33/50] - Loss: 0.3937
Epoch [34/50] - Loss: 0.3864
Epoch [35/50] - Loss: 0.3881
Epoch [36/50] - Loss: 0.3792
Epoch [37/50] - Loss: 0.3794
Epoch [38/50] - Loss: 0.3767
Epoch [39/50] - Loss: 0.3793
Epoch [40/50] - Loss: 0.3739
Epoch [41/50] - Loss: 0.3706
Epoch [42/50] - Loss: 0.3651
Epoch [43/50] - Loss: 0.3660
Epoch [44/50] - Loss: 0.3689
Epoch [45/50] - Loss: 0.3595
Epoch [46/50] - Loss: 0.3603
Epoch [47/50] - Loss: 0.3606
Epoch [48/50] - Loss: 0.3508
Epoch [49/50] - Loss: 0.3480
Epoch [50/50] - Loss: 0.3461
sum preds 52
sum labels 491
 - Test Metrics: Accuracy=0.8139, F1=0.1842, Recall=0.1018, Precision=0.9615
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_naive_naive_1804093452.csv.
Average F1 over valid seeds: 0.1930 ± 0.0448
___________________________________________________________________________________
Avg F1 for cora with SAR and naive, GATConv,0.4: 0.1930 ± 0.0448
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2633
Epoch [2/50] - Loss: 0.9513
Epoch [3/50] - Loss: 0.7754
Epoch [4/50] - Loss: 0.7069
Epoch [5/50] - Loss: 0.7180
Epoch [6/50] - Loss: 0.7224
Epoch [7/50] - Loss: 0.7091
Epoch [8/50] - Loss: 0.6777
Epoch [9/50] - Loss: 0.6460
Epoch [10/50] - Loss: 0.6092
Epoch [11/50] - Loss: 0.5874
Epoch [12/50] - Loss: 0.5707
Epoch [13/50] - Loss: 0.5621
Epoch [14/50] - Loss: 0.5551
Epoch [15/50] - Loss: 0.5434
Epoch [16/50] - Loss: 0.5398
Epoch [17/50] - Loss: 0.5264
Epoch [18/50] - Loss: 0.5111
Epoch [19/50] - Loss: 0.5018
Epoch [20/50] - Loss: 0.4946
Epoch [21/50] - Loss: 0.4922
Epoch [22/50] - Loss: 0.4869
Epoch [23/50] - Loss: 0.4713
Epoch [24/50] - Loss: 0.4778
Epoch [25/50] - Loss: 0.4638
Epoch [26/50] - Loss: 0.4649
Epoch [27/50] - Loss: 0.4606
Epoch [28/50] - Loss: 0.4530
Epoch [29/50] - Loss: 0.4468
Epoch [30/50] - Loss: 0.4407
Epoch [31/50] - Loss: 0.4446
Epoch [32/50] - Loss: 0.4355
Epoch [33/50] - Loss: 0.4319
Epoch [34/50] - Loss: 0.4353
Epoch [35/50] - Loss: 0.4318
Epoch [36/50] - Loss: 0.4301
Epoch [37/50] - Loss: 0.4262
Epoch [38/50] - Loss: 0.4206
Epoch [39/50] - Loss: 0.4208
Epoch [40/50] - Loss: 0.4157
Epoch [41/50] - Loss: 0.4130
Epoch [42/50] - Loss: 0.4119
Epoch [43/50] - Loss: 0.4068
Epoch [44/50] - Loss: 0.4105
Epoch [45/50] - Loss: 0.4008
Epoch [46/50] - Loss: 0.4036
Epoch [47/50] - Loss: 0.3958
Epoch [48/50] - Loss: 0.3971
Epoch [49/50] - Loss: 0.3955
Epoch [50/50] - Loss: 0.3953
sum preds 11
sum labels 491
 - Test Metrics: Accuracy=0.7984, F1=0.0438, Recall=0.0224, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3243
Epoch [2/50] - Loss: 1.0657
Epoch [3/50] - Loss: 0.8729
Epoch [4/50] - Loss: 0.7597
Epoch [5/50] - Loss: 0.7198
Epoch [6/50] - Loss: 0.6999
Epoch [7/50] - Loss: 0.7033
Epoch [8/50] - Loss: 0.6877
Epoch [9/50] - Loss: 0.6801
Epoch [10/50] - Loss: 0.6531
Epoch [11/50] - Loss: 0.6294
Epoch [12/50] - Loss: 0.5999
Epoch [13/50] - Loss: 0.5690
Epoch [14/50] - Loss: 0.5574
Epoch [15/50] - Loss: 0.5502
Epoch [16/50] - Loss: 0.5385
Epoch [17/50] - Loss: 0.5291
Epoch [18/50] - Loss: 0.5119
Epoch [19/50] - Loss: 0.5037
Epoch [20/50] - Loss: 0.4983
Epoch [21/50] - Loss: 0.4877
Epoch [22/50] - Loss: 0.4847
Epoch [23/50] - Loss: 0.4730
Epoch [24/50] - Loss: 0.4651
Epoch [25/50] - Loss: 0.4621
Epoch [26/50] - Loss: 0.4574
Epoch [27/50] - Loss: 0.4511
Epoch [28/50] - Loss: 0.4455
Epoch [29/50] - Loss: 0.4404
Epoch [30/50] - Loss: 0.4351
Epoch [31/50] - Loss: 0.4355
Epoch [32/50] - Loss: 0.4300
Epoch [33/50] - Loss: 0.4273
Epoch [34/50] - Loss: 0.4225
Epoch [35/50] - Loss: 0.4179
Epoch [36/50] - Loss: 0.4158
Epoch [37/50] - Loss: 0.4169
Epoch [38/50] - Loss: 0.4108
Epoch [39/50] - Loss: 0.4071
Epoch [40/50] - Loss: 0.4021
Epoch [41/50] - Loss: 0.3975
Epoch [42/50] - Loss: 0.3971
Epoch [43/50] - Loss: 0.3962
Epoch [44/50] - Loss: 0.3956
Epoch [45/50] - Loss: 0.3891
Epoch [46/50] - Loss: 0.3871
Epoch [47/50] - Loss: 0.3918
Epoch [48/50] - Loss: 0.3848
Epoch [49/50] - Loss: 0.3796
Epoch [50/50] - Loss: 0.3757
sum preds 74
sum labels 491
 - Test Metrics: Accuracy=0.8215, F1=0.2478, Recall=0.1426, Precision=0.9459
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4505
Epoch [2/50] - Loss: 1.2218
Epoch [3/50] - Loss: 1.0796
Epoch [4/50] - Loss: 0.9606
Epoch [5/50] - Loss: 0.8591
Epoch [6/50] - Loss: 0.7892
Epoch [7/50] - Loss: 0.7442
Epoch [8/50] - Loss: 0.7176
Epoch [9/50] - Loss: 0.7142
Epoch [10/50] - Loss: 0.7112
Epoch [11/50] - Loss: 0.7051
Epoch [12/50] - Loss: 0.6952
Epoch [13/50] - Loss: 0.6793
Epoch [14/50] - Loss: 0.6630
Epoch [15/50] - Loss: 0.6545
Epoch [16/50] - Loss: 0.6343
Epoch [17/50] - Loss: 0.6182
Epoch [18/50] - Loss: 0.6087
Epoch [19/50] - Loss: 0.5894
Epoch [20/50] - Loss: 0.5867
Epoch [21/50] - Loss: 0.5777
Epoch [22/50] - Loss: 0.5686
Epoch [23/50] - Loss: 0.5601
Epoch [24/50] - Loss: 0.5473
Epoch [25/50] - Loss: 0.5469
Epoch [26/50] - Loss: 0.5316
Epoch [27/50] - Loss: 0.5287
Epoch [28/50] - Loss: 0.5216
Epoch [29/50] - Loss: 0.5143
Epoch [30/50] - Loss: 0.5071
Epoch [31/50] - Loss: 0.5035
Epoch [32/50] - Loss: 0.4947
Epoch [33/50] - Loss: 0.4924
Epoch [34/50] - Loss: 0.4834
Epoch [35/50] - Loss: 0.4830
Epoch [36/50] - Loss: 0.4769
Epoch [37/50] - Loss: 0.4782
Epoch [38/50] - Loss: 0.4734
Epoch [39/50] - Loss: 0.4667
Epoch [40/50] - Loss: 0.4671
Epoch [41/50] - Loss: 0.4587
Epoch [42/50] - Loss: 0.4598
Epoch [43/50] - Loss: 0.4520
Epoch [44/50] - Loss: 0.4513
Epoch [45/50] - Loss: 0.4451
Epoch [46/50] - Loss: 0.4418
Epoch [47/50] - Loss: 0.4475
Epoch [48/50] - Loss: 0.4450
Epoch [49/50] - Loss: 0.4393
Epoch [50/50] - Loss: 0.4387
sum preds 19
sum labels 491
 - Test Metrics: Accuracy=0.7992, F1=0.0627, Recall=0.0326, Precision=0.8421
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_naive_naive_1804093533.csv.
Average F1 over valid seeds: 0.1181 ± 0.0920
___________________________________________________________________________________
Avg F1 for cora with SAR and naive, GCNConv,0.4: 0.1181 ± 0.0920
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3894
Epoch [2/50] - Loss: 1.2274
Epoch [3/50] - Loss: 1.0757
Epoch [4/50] - Loss: 0.9322
Epoch [5/50] - Loss: 0.8097
Epoch [6/50] - Loss: 0.7214
Epoch [7/50] - Loss: 0.6601
Epoch [8/50] - Loss: 0.6263
Epoch [9/50] - Loss: 0.6091
Epoch [10/50] - Loss: 0.6018
Epoch [11/50] - Loss: 0.5977
Epoch [12/50] - Loss: 0.5981
Epoch [13/50] - Loss: 0.5863
Epoch [14/50] - Loss: 0.5675
Epoch [15/50] - Loss: 0.5494
Epoch [16/50] - Loss: 0.5332
Epoch [17/50] - Loss: 0.5155
Epoch [18/50] - Loss: 0.4944
Epoch [19/50] - Loss: 0.4811
Epoch [20/50] - Loss: 0.4656
Epoch [21/50] - Loss: 0.4518
Epoch [22/50] - Loss: 0.4478
Epoch [23/50] - Loss: 0.4363
Epoch [24/50] - Loss: 0.4251
Epoch [25/50] - Loss: 0.4159
Epoch [26/50] - Loss: 0.4066
Epoch [27/50] - Loss: 0.3885
Epoch [28/50] - Loss: 0.3825
Epoch [29/50] - Loss: 0.3683
Epoch [30/50] - Loss: 0.3627
Epoch [31/50] - Loss: 0.3491
Epoch [32/50] - Loss: 0.3389
Epoch [33/50] - Loss: 0.3346
Epoch [34/50] - Loss: 0.3218
Epoch [35/50] - Loss: 0.3106
Epoch [36/50] - Loss: 0.3046
Epoch [37/50] - Loss: 0.2976
Epoch [38/50] - Loss: 0.2912
Epoch [39/50] - Loss: 0.2810
Epoch [40/50] - Loss: 0.2773
Epoch [41/50] - Loss: 0.2678
Epoch [42/50] - Loss: 0.2683
Epoch [43/50] - Loss: 0.2591
Epoch [44/50] - Loss: 0.2492
Epoch [45/50] - Loss: 0.2435
Epoch [46/50] - Loss: 0.2390
Epoch [47/50] - Loss: 0.2348
Epoch [48/50] - Loss: 0.2310
Epoch [49/50] - Loss: 0.2260
Epoch [50/50] - Loss: 0.2248
sum preds 0
sum labels 573
 - Test Metrics: Accuracy=0.7674, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3150
Epoch [2/50] - Loss: 1.0863
Epoch [3/50] - Loss: 0.8873
Epoch [4/50] - Loss: 0.7382
Epoch [5/50] - Loss: 0.6522
Epoch [6/50] - Loss: 0.6081
Epoch [7/50] - Loss: 0.5993
Epoch [8/50] - Loss: 0.5921
Epoch [9/50] - Loss: 0.5850
Epoch [10/50] - Loss: 0.5629
Epoch [11/50] - Loss: 0.5482
Epoch [12/50] - Loss: 0.5180
Epoch [13/50] - Loss: 0.4904
Epoch [14/50] - Loss: 0.4658
Epoch [15/50] - Loss: 0.4438
Epoch [16/50] - Loss: 0.4252
Epoch [17/50] - Loss: 0.4164
Epoch [18/50] - Loss: 0.4031
Epoch [19/50] - Loss: 0.3939
Epoch [20/50] - Loss: 0.3813
Epoch [21/50] - Loss: 0.3662
Epoch [22/50] - Loss: 0.3542
Epoch [23/50] - Loss: 0.3409
Epoch [24/50] - Loss: 0.3299
Epoch [25/50] - Loss: 0.3154
Epoch [26/50] - Loss: 0.3065
Epoch [27/50] - Loss: 0.2957
Epoch [28/50] - Loss: 0.2858
Epoch [29/50] - Loss: 0.2760
Epoch [30/50] - Loss: 0.2718
Epoch [31/50] - Loss: 0.2617
Epoch [32/50] - Loss: 0.2540
Epoch [33/50] - Loss: 0.2493
Epoch [34/50] - Loss: 0.2440
Epoch [35/50] - Loss: 0.2330
Epoch [36/50] - Loss: 0.2258
Epoch [37/50] - Loss: 0.2235
Epoch [38/50] - Loss: 0.2182
Epoch [39/50] - Loss: 0.2155
Epoch [40/50] - Loss: 0.2114
Epoch [41/50] - Loss: 0.2061
Epoch [42/50] - Loss: 0.2026
Epoch [43/50] - Loss: 0.2009
Epoch [44/50] - Loss: 0.1986
Epoch [45/50] - Loss: 0.1883
Epoch [46/50] - Loss: 0.1903
Epoch [47/50] - Loss: 0.1860
Epoch [48/50] - Loss: 0.1836
Epoch [49/50] - Loss: 0.1795
Epoch [50/50] - Loss: 0.1792
sum preds 0
sum labels 573
 - Test Metrics: Accuracy=0.7674, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.5230
Epoch [2/50] - Loss: 1.3436
Epoch [3/50] - Loss: 1.1684
Epoch [4/50] - Loss: 0.9953
Epoch [5/50] - Loss: 0.8422
Epoch [6/50] - Loss: 0.7330
Epoch [7/50] - Loss: 0.6641
Epoch [8/50] - Loss: 0.6282
Epoch [9/50] - Loss: 0.6230
Epoch [10/50] - Loss: 0.6218
Epoch [11/50] - Loss: 0.6211
Epoch [12/50] - Loss: 0.6118
Epoch [13/50] - Loss: 0.5903
Epoch [14/50] - Loss: 0.5658
Epoch [15/50] - Loss: 0.5422
Epoch [16/50] - Loss: 0.5137
Epoch [17/50] - Loss: 0.4981
Epoch [18/50] - Loss: 0.4777
Epoch [19/50] - Loss: 0.4639
Epoch [20/50] - Loss: 0.4544
Epoch [21/50] - Loss: 0.4378
Epoch [22/50] - Loss: 0.4258
Epoch [23/50] - Loss: 0.4161
Epoch [24/50] - Loss: 0.4048
Epoch [25/50] - Loss: 0.3903
Epoch [26/50] - Loss: 0.3779
Epoch [27/50] - Loss: 0.3600
Epoch [28/50] - Loss: 0.3516
Epoch [29/50] - Loss: 0.3362
Epoch [30/50] - Loss: 0.3283
Epoch [31/50] - Loss: 0.3220
Epoch [32/50] - Loss: 0.3104
Epoch [33/50] - Loss: 0.3025
Epoch [34/50] - Loss: 0.2932
Epoch [35/50] - Loss: 0.2775
Epoch [36/50] - Loss: 0.2799
Epoch [37/50] - Loss: 0.2733
Epoch [38/50] - Loss: 0.2608
Epoch [39/50] - Loss: 0.2548
Epoch [40/50] - Loss: 0.2436
Epoch [41/50] - Loss: 0.2396
Epoch [42/50] - Loss: 0.2358
Epoch [43/50] - Loss: 0.2292
Epoch [44/50] - Loss: 0.2205
Epoch [45/50] - Loss: 0.2140
Epoch [46/50] - Loss: 0.2109
Epoch [47/50] - Loss: 0.2033
Epoch [48/50] - Loss: 0.2003
Epoch [49/50] - Loss: 0.1949
Epoch [50/50] - Loss: 0.1883
sum preds 0
sum labels 573
 - Test Metrics: Accuracy=0.7674, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_naive_naive_1804093615.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for cora with SAR and naive, MLP,0.3: 0.0000 ± 0.0000
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3160
Epoch [2/50] - Loss: 0.9336
Epoch [3/50] - Loss: 0.6949
Epoch [4/50] - Loss: 0.5909
Epoch [5/50] - Loss: 0.5871
Epoch [6/50] - Loss: 0.5837
Epoch [7/50] - Loss: 0.6054
Epoch [8/50] - Loss: 0.5764
Epoch [9/50] - Loss: 0.5607
Epoch [10/50] - Loss: 0.5275
Epoch [11/50] - Loss: 0.4942
Epoch [12/50] - Loss: 0.4711
Epoch [13/50] - Loss: 0.4598
Epoch [14/50] - Loss: 0.4495
Epoch [15/50] - Loss: 0.4493
Epoch [16/50] - Loss: 0.4475
Epoch [17/50] - Loss: 0.4330
Epoch [18/50] - Loss: 0.4272
Epoch [19/50] - Loss: 0.4157
Epoch [20/50] - Loss: 0.4034
Epoch [21/50] - Loss: 0.4001
Epoch [22/50] - Loss: 0.3924
Epoch [23/50] - Loss: 0.3871
Epoch [24/50] - Loss: 0.3844
Epoch [25/50] - Loss: 0.3729
Epoch [26/50] - Loss: 0.3734
Epoch [27/50] - Loss: 0.3677
Epoch [28/50] - Loss: 0.3645
Epoch [29/50] - Loss: 0.3565
Epoch [30/50] - Loss: 0.3562
Epoch [31/50] - Loss: 0.3531
Epoch [32/50] - Loss: 0.3455
Epoch [33/50] - Loss: 0.3476
Epoch [34/50] - Loss: 0.3377
Epoch [35/50] - Loss: 0.3356
Epoch [36/50] - Loss: 0.3354
Epoch [37/50] - Loss: 0.3312
Epoch [38/50] - Loss: 0.3305
Epoch [39/50] - Loss: 0.3275
Epoch [40/50] - Loss: 0.3241
Epoch [41/50] - Loss: 0.3235
Epoch [42/50] - Loss: 0.3218
Epoch [43/50] - Loss: 0.3222
Epoch [44/50] - Loss: 0.3199
Epoch [45/50] - Loss: 0.3138
Epoch [46/50] - Loss: 0.3154
Epoch [47/50] - Loss: 0.3085
Epoch [48/50] - Loss: 0.3103
Epoch [49/50] - Loss: 0.3114
Epoch [50/50] - Loss: 0.3059
sum preds 0
sum labels 573
 - Test Metrics: Accuracy=0.7674, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2362
Epoch [2/50] - Loss: 0.8512
Epoch [3/50] - Loss: 0.6465
Epoch [4/50] - Loss: 0.5847
Epoch [5/50] - Loss: 0.5948
Epoch [6/50] - Loss: 0.5986
Epoch [7/50] - Loss: 0.5804
Epoch [8/50] - Loss: 0.5717
Epoch [9/50] - Loss: 0.5353
Epoch [10/50] - Loss: 0.4911
Epoch [11/50] - Loss: 0.4724
Epoch [12/50] - Loss: 0.4525
Epoch [13/50] - Loss: 0.4531
Epoch [14/50] - Loss: 0.4494
Epoch [15/50] - Loss: 0.4402
Epoch [16/50] - Loss: 0.4377
Epoch [17/50] - Loss: 0.4204
Epoch [18/50] - Loss: 0.4168
Epoch [19/50] - Loss: 0.4112
Epoch [20/50] - Loss: 0.4002
Epoch [21/50] - Loss: 0.3941
Epoch [22/50] - Loss: 0.3868
Epoch [23/50] - Loss: 0.3811
Epoch [24/50] - Loss: 0.3744
Epoch [25/50] - Loss: 0.3736
Epoch [26/50] - Loss: 0.3726
Epoch [27/50] - Loss: 0.3598
Epoch [28/50] - Loss: 0.3560
Epoch [29/50] - Loss: 0.3544
Epoch [30/50] - Loss: 0.3520
Epoch [31/50] - Loss: 0.3477
Epoch [32/50] - Loss: 0.3479
Epoch [33/50] - Loss: 0.3417
Epoch [34/50] - Loss: 0.3383
Epoch [35/50] - Loss: 0.3371
Epoch [36/50] - Loss: 0.3301
Epoch [37/50] - Loss: 0.3334
Epoch [38/50] - Loss: 0.3296
Epoch [39/50] - Loss: 0.3227
Epoch [40/50] - Loss: 0.3253
Epoch [41/50] - Loss: 0.3185
Epoch [42/50] - Loss: 0.3138
Epoch [43/50] - Loss: 0.3128
Epoch [44/50] - Loss: 0.3032
Epoch [45/50] - Loss: 0.3084
Epoch [46/50] - Loss: 0.3034
Epoch [47/50] - Loss: 0.3031
Epoch [48/50] - Loss: 0.2973
Epoch [49/50] - Loss: 0.2956
Epoch [50/50] - Loss: 0.2902
sum preds 17
sum labels 573
 - Test Metrics: Accuracy=0.7743, F1=0.0576, Recall=0.0297, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2103
Epoch [2/50] - Loss: 0.7949
Epoch [3/50] - Loss: 0.6085
Epoch [4/50] - Loss: 0.5757
Epoch [5/50] - Loss: 0.6020
Epoch [6/50] - Loss: 0.6008
Epoch [7/50] - Loss: 0.5826
Epoch [8/50] - Loss: 0.5431
Epoch [9/50] - Loss: 0.5057
Epoch [10/50] - Loss: 0.4720
Epoch [11/50] - Loss: 0.4533
Epoch [12/50] - Loss: 0.4511
Epoch [13/50] - Loss: 0.4447
Epoch [14/50] - Loss: 0.4428
Epoch [15/50] - Loss: 0.4307
Epoch [16/50] - Loss: 0.4195
Epoch [17/50] - Loss: 0.4123
Epoch [18/50] - Loss: 0.3975
Epoch [19/50] - Loss: 0.3941
Epoch [20/50] - Loss: 0.3939
Epoch [21/50] - Loss: 0.3889
Epoch [22/50] - Loss: 0.3852
Epoch [23/50] - Loss: 0.3790
Epoch [24/50] - Loss: 0.3662
Epoch [25/50] - Loss: 0.3661
Epoch [26/50] - Loss: 0.3586
Epoch [27/50] - Loss: 0.3577
Epoch [28/50] - Loss: 0.3579
Epoch [29/50] - Loss: 0.3477
Epoch [30/50] - Loss: 0.3520
Epoch [31/50] - Loss: 0.3475
Epoch [32/50] - Loss: 0.3481
Epoch [33/50] - Loss: 0.3422
Epoch [34/50] - Loss: 0.3374
Epoch [35/50] - Loss: 0.3370
Epoch [36/50] - Loss: 0.3304
Epoch [37/50] - Loss: 0.3306
Epoch [38/50] - Loss: 0.3272
Epoch [39/50] - Loss: 0.3305
Epoch [40/50] - Loss: 0.3277
Epoch [41/50] - Loss: 0.3225
Epoch [42/50] - Loss: 0.3140
Epoch [43/50] - Loss: 0.3169
Epoch [44/50] - Loss: 0.3202
Epoch [45/50] - Loss: 0.3105
Epoch [46/50] - Loss: 0.3157
Epoch [47/50] - Loss: 0.3101
Epoch [48/50] - Loss: 0.3046
Epoch [49/50] - Loss: 0.3046
Epoch [50/50] - Loss: 0.3002
sum preds 11
sum labels 573
 - Test Metrics: Accuracy=0.7718, F1=0.0377, Recall=0.0192, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_naive_naive_1804093655.csv.
Average F1 over valid seeds: 0.0318 ± 0.0239
___________________________________________________________________________________
Avg F1 for cora with SAR and naive, GATConv,0.3: 0.0318 ± 0.0239
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2551
Epoch [2/50] - Loss: 0.9105
Epoch [3/50] - Loss: 0.6995
Epoch [4/50] - Loss: 0.6053
Epoch [5/50] - Loss: 0.6038
Epoch [6/50] - Loss: 0.6163
Epoch [7/50] - Loss: 0.6218
Epoch [8/50] - Loss: 0.6139
Epoch [9/50] - Loss: 0.5898
Epoch [10/50] - Loss: 0.5584
Epoch [11/50] - Loss: 0.5334
Epoch [12/50] - Loss: 0.5115
Epoch [13/50] - Loss: 0.4962
Epoch [14/50] - Loss: 0.4862
Epoch [15/50] - Loss: 0.4790
Epoch [16/50] - Loss: 0.4789
Epoch [17/50] - Loss: 0.4749
Epoch [18/50] - Loss: 0.4613
Epoch [19/50] - Loss: 0.4536
Epoch [20/50] - Loss: 0.4438
Epoch [21/50] - Loss: 0.4392
Epoch [22/50] - Loss: 0.4340
Epoch [23/50] - Loss: 0.4158
Epoch [24/50] - Loss: 0.4243
Epoch [25/50] - Loss: 0.4107
Epoch [26/50] - Loss: 0.4120
Epoch [27/50] - Loss: 0.4078
Epoch [28/50] - Loss: 0.3993
Epoch [29/50] - Loss: 0.3943
Epoch [30/50] - Loss: 0.3879
Epoch [31/50] - Loss: 0.3903
Epoch [32/50] - Loss: 0.3842
Epoch [33/50] - Loss: 0.3795
Epoch [34/50] - Loss: 0.3823
Epoch [35/50] - Loss: 0.3786
Epoch [36/50] - Loss: 0.3775
Epoch [37/50] - Loss: 0.3714
Epoch [38/50] - Loss: 0.3687
Epoch [39/50] - Loss: 0.3672
Epoch [40/50] - Loss: 0.3616
Epoch [41/50] - Loss: 0.3595
Epoch [42/50] - Loss: 0.3591
Epoch [43/50] - Loss: 0.3536
Epoch [44/50] - Loss: 0.3561
Epoch [45/50] - Loss: 0.3490
Epoch [46/50] - Loss: 0.3521
Epoch [47/50] - Loss: 0.3439
Epoch [48/50] - Loss: 0.3423
Epoch [49/50] - Loss: 0.3426
Epoch [50/50] - Loss: 0.3412
sum preds 0
sum labels 573
 - Test Metrics: Accuracy=0.7674, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3194
Epoch [2/50] - Loss: 1.0366
Epoch [3/50] - Loss: 0.8148
Epoch [4/50] - Loss: 0.6771
Epoch [5/50] - Loss: 0.6171
Epoch [6/50] - Loss: 0.5905
Epoch [7/50] - Loss: 0.5972
Epoch [8/50] - Loss: 0.5903
Epoch [9/50] - Loss: 0.5940
Epoch [10/50] - Loss: 0.5773
Epoch [11/50] - Loss: 0.5709
Epoch [12/50] - Loss: 0.5449
Epoch [13/50] - Loss: 0.5151
Epoch [14/50] - Loss: 0.5018
Epoch [15/50] - Loss: 0.4907
Epoch [16/50] - Loss: 0.4769
Epoch [17/50] - Loss: 0.4645
Epoch [18/50] - Loss: 0.4506
Epoch [19/50] - Loss: 0.4457
Epoch [20/50] - Loss: 0.4408
Epoch [21/50] - Loss: 0.4325
Epoch [22/50] - Loss: 0.4276
Epoch [23/50] - Loss: 0.4169
Epoch [24/50] - Loss: 0.4102
Epoch [25/50] - Loss: 0.4063
Epoch [26/50] - Loss: 0.4002
Epoch [27/50] - Loss: 0.3920
Epoch [28/50] - Loss: 0.3877
Epoch [29/50] - Loss: 0.3801
Epoch [30/50] - Loss: 0.3750
Epoch [31/50] - Loss: 0.3763
Epoch [32/50] - Loss: 0.3699
Epoch [33/50] - Loss: 0.3677
Epoch [34/50] - Loss: 0.3618
Epoch [35/50] - Loss: 0.3601
Epoch [36/50] - Loss: 0.3560
Epoch [37/50] - Loss: 0.3573
Epoch [38/50] - Loss: 0.3491
Epoch [39/50] - Loss: 0.3464
Epoch [40/50] - Loss: 0.3416
Epoch [41/50] - Loss: 0.3359
Epoch [42/50] - Loss: 0.3379
Epoch [43/50] - Loss: 0.3378
Epoch [44/50] - Loss: 0.3356
Epoch [45/50] - Loss: 0.3306
Epoch [46/50] - Loss: 0.3302
Epoch [47/50] - Loss: 0.3315
Epoch [48/50] - Loss: 0.3254
Epoch [49/50] - Loss: 0.3216
Epoch [50/50] - Loss: 0.3231
sum preds 0
sum labels 573
 - Test Metrics: Accuracy=0.7674, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4551
Epoch [2/50] - Loss: 1.2072
Epoch [3/50] - Loss: 1.0510
Epoch [4/50] - Loss: 0.9174
Epoch [5/50] - Loss: 0.7975
Epoch [6/50] - Loss: 0.7136
Epoch [7/50] - Loss: 0.6543
Epoch [8/50] - Loss: 0.6188
Epoch [9/50] - Loss: 0.6056
Epoch [10/50] - Loss: 0.6030
Epoch [11/50] - Loss: 0.6003
Epoch [12/50] - Loss: 0.5943
Epoch [13/50] - Loss: 0.5878
Epoch [14/50] - Loss: 0.5830
Epoch [15/50] - Loss: 0.5754
Epoch [16/50] - Loss: 0.5626
Epoch [17/50] - Loss: 0.5469
Epoch [18/50] - Loss: 0.5365
Epoch [19/50] - Loss: 0.5180
Epoch [20/50] - Loss: 0.5151
Epoch [21/50] - Loss: 0.5024
Epoch [22/50] - Loss: 0.4996
Epoch [23/50] - Loss: 0.4933
Epoch [24/50] - Loss: 0.4837
Epoch [25/50] - Loss: 0.4822
Epoch [26/50] - Loss: 0.4758
Epoch [27/50] - Loss: 0.4720
Epoch [28/50] - Loss: 0.4636
Epoch [29/50] - Loss: 0.4584
Epoch [30/50] - Loss: 0.4536
Epoch [31/50] - Loss: 0.4477
Epoch [32/50] - Loss: 0.4393
Epoch [33/50] - Loss: 0.4393
Epoch [34/50] - Loss: 0.4292
Epoch [35/50] - Loss: 0.4290
Epoch [36/50] - Loss: 0.4243
Epoch [37/50] - Loss: 0.4237
Epoch [38/50] - Loss: 0.4202
Epoch [39/50] - Loss: 0.4140
Epoch [40/50] - Loss: 0.4146
Epoch [41/50] - Loss: 0.4067
Epoch [42/50] - Loss: 0.4056
Epoch [43/50] - Loss: 0.3983
Epoch [44/50] - Loss: 0.3997
Epoch [45/50] - Loss: 0.3920
Epoch [46/50] - Loss: 0.3907
Epoch [47/50] - Loss: 0.3925
Epoch [48/50] - Loss: 0.3903
Epoch [49/50] - Loss: 0.3880
Epoch [50/50] - Loss: 0.3891
sum preds 0
sum labels 573
 - Test Metrics: Accuracy=0.7674, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_naive_naive_1804093737.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for cora with SAR and naive, GCNConv,0.3: 0.0000 ± 0.0000
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3899
Epoch [2/50] - Loss: 1.2162
Epoch [3/50] - Loss: 1.0516
Epoch [4/50] - Loss: 0.8938
Epoch [5/50] - Loss: 0.7550
Epoch [6/50] - Loss: 0.6471
Epoch [7/50] - Loss: 0.5668
Epoch [8/50] - Loss: 0.5204
Epoch [9/50] - Loss: 0.4901
Epoch [10/50] - Loss: 0.4797
Epoch [11/50] - Loss: 0.4726
Epoch [12/50] - Loss: 0.4778
Epoch [13/50] - Loss: 0.4699
Epoch [14/50] - Loss: 0.4557
Epoch [15/50] - Loss: 0.4490
Epoch [16/50] - Loss: 0.4398
Epoch [17/50] - Loss: 0.4321
Epoch [18/50] - Loss: 0.4106
Epoch [19/50] - Loss: 0.3959
Epoch [20/50] - Loss: 0.3832
Epoch [21/50] - Loss: 0.3697
Epoch [22/50] - Loss: 0.3629
Epoch [23/50] - Loss: 0.3517
Epoch [24/50] - Loss: 0.3396
Epoch [25/50] - Loss: 0.3326
Epoch [26/50] - Loss: 0.3252
Epoch [27/50] - Loss: 0.3115
Epoch [28/50] - Loss: 0.3078
Epoch [29/50] - Loss: 0.2975
Epoch [30/50] - Loss: 0.2930
Epoch [31/50] - Loss: 0.2793
Epoch [32/50] - Loss: 0.2726
Epoch [33/50] - Loss: 0.2667
Epoch [34/50] - Loss: 0.2561
Epoch [35/50] - Loss: 0.2481
Epoch [36/50] - Loss: 0.2383
Epoch [37/50] - Loss: 0.2325
Epoch [38/50] - Loss: 0.2277
Epoch [39/50] - Loss: 0.2175
Epoch [40/50] - Loss: 0.2146
Epoch [41/50] - Loss: 0.2068
Epoch [42/50] - Loss: 0.2053
Epoch [43/50] - Loss: 0.1964
Epoch [44/50] - Loss: 0.1914
Epoch [45/50] - Loss: 0.1858
Epoch [46/50] - Loss: 0.1819
Epoch [47/50] - Loss: 0.1784
Epoch [48/50] - Loss: 0.1745
Epoch [49/50] - Loss: 0.1705
Epoch [50/50] - Loss: 0.1716
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3098
Epoch [2/50] - Loss: 1.0633
Epoch [3/50] - Loss: 0.8425
Epoch [4/50] - Loss: 0.6698
Epoch [5/50] - Loss: 0.5621
Epoch [6/50] - Loss: 0.4986
Epoch [7/50] - Loss: 0.4746
Epoch [8/50] - Loss: 0.4695
Epoch [9/50] - Loss: 0.4685
Epoch [10/50] - Loss: 0.4623
Epoch [11/50] - Loss: 0.4562
Epoch [12/50] - Loss: 0.4390
Epoch [13/50] - Loss: 0.4190
Epoch [14/50] - Loss: 0.3931
Epoch [15/50] - Loss: 0.3757
Epoch [16/50] - Loss: 0.3503
Epoch [17/50] - Loss: 0.3364
Epoch [18/50] - Loss: 0.3192
Epoch [19/50] - Loss: 0.3124
Epoch [20/50] - Loss: 0.3030
Epoch [21/50] - Loss: 0.2926
Epoch [22/50] - Loss: 0.2829
Epoch [23/50] - Loss: 0.2749
Epoch [24/50] - Loss: 0.2658
Epoch [25/50] - Loss: 0.2521
Epoch [26/50] - Loss: 0.2417
Epoch [27/50] - Loss: 0.2308
Epoch [28/50] - Loss: 0.2215
Epoch [29/50] - Loss: 0.2129
Epoch [30/50] - Loss: 0.2098
Epoch [31/50] - Loss: 0.2006
Epoch [32/50] - Loss: 0.1931
Epoch [33/50] - Loss: 0.1909
Epoch [34/50] - Loss: 0.1864
Epoch [35/50] - Loss: 0.1778
Epoch [36/50] - Loss: 0.1713
Epoch [37/50] - Loss: 0.1699
Epoch [38/50] - Loss: 0.1640
Epoch [39/50] - Loss: 0.1619
Epoch [40/50] - Loss: 0.1580
Epoch [41/50] - Loss: 0.1530
Epoch [42/50] - Loss: 0.1507
Epoch [43/50] - Loss: 0.1489
Epoch [44/50] - Loss: 0.1468
Epoch [45/50] - Loss: 0.1378
Epoch [46/50] - Loss: 0.1388
Epoch [47/50] - Loss: 0.1371
Epoch [48/50] - Loss: 0.1348
Epoch [49/50] - Loss: 0.1318
Epoch [50/50] - Loss: 0.1306
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.5321
Epoch [2/50] - Loss: 1.3407
Epoch [3/50] - Loss: 1.1513
Epoch [4/50] - Loss: 0.9613
Epoch [5/50] - Loss: 0.7901
Epoch [6/50] - Loss: 0.6565
Epoch [7/50] - Loss: 0.5673
Epoch [8/50] - Loss: 0.5137
Epoch [9/50] - Loss: 0.4930
Epoch [10/50] - Loss: 0.4900
Epoch [11/50] - Loss: 0.4955
Epoch [12/50] - Loss: 0.4901
Epoch [13/50] - Loss: 0.4781
Epoch [14/50] - Loss: 0.4671
Epoch [15/50] - Loss: 0.4541
Epoch [16/50] - Loss: 0.4333
Epoch [17/50] - Loss: 0.4226
Epoch [18/50] - Loss: 0.4013
Epoch [19/50] - Loss: 0.3867
Epoch [20/50] - Loss: 0.3720
Epoch [21/50] - Loss: 0.3560
Epoch [22/50] - Loss: 0.3448
Epoch [23/50] - Loss: 0.3334
Epoch [24/50] - Loss: 0.3239
Epoch [25/50] - Loss: 0.3174
Epoch [26/50] - Loss: 0.3085
Epoch [27/50] - Loss: 0.2940
Epoch [28/50] - Loss: 0.2869
Epoch [29/50] - Loss: 0.2767
Epoch [30/50] - Loss: 0.2667
Epoch [31/50] - Loss: 0.2611
Epoch [32/50] - Loss: 0.2494
Epoch [33/50] - Loss: 0.2416
Epoch [34/50] - Loss: 0.2326
Epoch [35/50] - Loss: 0.2197
Epoch [36/50] - Loss: 0.2221
Epoch [37/50] - Loss: 0.2127
Epoch [38/50] - Loss: 0.2037
Epoch [39/50] - Loss: 0.1973
Epoch [40/50] - Loss: 0.1873
Epoch [41/50] - Loss: 0.1852
Epoch [42/50] - Loss: 0.1816
Epoch [43/50] - Loss: 0.1752
Epoch [44/50] - Loss: 0.1680
Epoch [45/50] - Loss: 0.1646
Epoch [46/50] - Loss: 0.1628
Epoch [47/50] - Loss: 0.1580
Epoch [48/50] - Loss: 0.1544
Epoch [49/50] - Loss: 0.1509
Epoch [50/50] - Loss: 0.1464
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_naive_naive_1804093818.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for cora with SAR and naive, MLP,0.2: 0.0000 ± 0.0000
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3119
Epoch [2/50] - Loss: 0.8985
Epoch [3/50] - Loss: 0.6212
Epoch [4/50] - Loss: 0.4829
Epoch [5/50] - Loss: 0.4473
Epoch [6/50] - Loss: 0.4497
Epoch [7/50] - Loss: 0.4775
Epoch [8/50] - Loss: 0.4711
Epoch [9/50] - Loss: 0.4693
Epoch [10/50] - Loss: 0.4472
Epoch [11/50] - Loss: 0.4200
Epoch [12/50] - Loss: 0.4011
Epoch [13/50] - Loss: 0.3794
Epoch [14/50] - Loss: 0.3579
Epoch [15/50] - Loss: 0.3528
Epoch [16/50] - Loss: 0.3500
Epoch [17/50] - Loss: 0.3406
Epoch [18/50] - Loss: 0.3431
Epoch [19/50] - Loss: 0.3370
Epoch [20/50] - Loss: 0.3274
Epoch [21/50] - Loss: 0.3230
Epoch [22/50] - Loss: 0.3106
Epoch [23/50] - Loss: 0.3093
Epoch [24/50] - Loss: 0.3056
Epoch [25/50] - Loss: 0.2950
Epoch [26/50] - Loss: 0.2963
Epoch [27/50] - Loss: 0.2915
Epoch [28/50] - Loss: 0.2865
Epoch [29/50] - Loss: 0.2789
Epoch [30/50] - Loss: 0.2765
Epoch [31/50] - Loss: 0.2750
Epoch [32/50] - Loss: 0.2682
Epoch [33/50] - Loss: 0.2712
Epoch [34/50] - Loss: 0.2572
Epoch [35/50] - Loss: 0.2602
Epoch [36/50] - Loss: 0.2585
Epoch [37/50] - Loss: 0.2534
Epoch [38/50] - Loss: 0.2546
Epoch [39/50] - Loss: 0.2496
Epoch [40/50] - Loss: 0.2510
Epoch [41/50] - Loss: 0.2503
Epoch [42/50] - Loss: 0.2422
Epoch [43/50] - Loss: 0.2457
Epoch [44/50] - Loss: 0.2454
Epoch [45/50] - Loss: 0.2363
Epoch [46/50] - Loss: 0.2432
Epoch [47/50] - Loss: 0.2338
Epoch [48/50] - Loss: 0.2331
Epoch [49/50] - Loss: 0.2351
Epoch [50/50] - Loss: 0.2302
sum preds 1
sum labels 654
 - Test Metrics: Accuracy=0.7433, F1=0.0031, Recall=0.0015, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2238
Epoch [2/50] - Loss: 0.7962
Epoch [3/50] - Loss: 0.5535
Epoch [4/50] - Loss: 0.4553
Epoch [5/50] - Loss: 0.4479
Epoch [6/50] - Loss: 0.4624
Epoch [7/50] - Loss: 0.4590
Epoch [8/50] - Loss: 0.4712
Epoch [9/50] - Loss: 0.4583
Epoch [10/50] - Loss: 0.4230
Epoch [11/50] - Loss: 0.4078
Epoch [12/50] - Loss: 0.3784
Epoch [13/50] - Loss: 0.3695
Epoch [14/50] - Loss: 0.3558
Epoch [15/50] - Loss: 0.3455
Epoch [16/50] - Loss: 0.3502
Epoch [17/50] - Loss: 0.3402
Epoch [18/50] - Loss: 0.3408
Epoch [19/50] - Loss: 0.3378
Epoch [20/50] - Loss: 0.3287
Epoch [21/50] - Loss: 0.3198
Epoch [22/50] - Loss: 0.3110
Epoch [23/50] - Loss: 0.3069
Epoch [24/50] - Loss: 0.3008
Epoch [25/50] - Loss: 0.2982
Epoch [26/50] - Loss: 0.2960
Epoch [27/50] - Loss: 0.2839
Epoch [28/50] - Loss: 0.2817
Epoch [29/50] - Loss: 0.2789
Epoch [30/50] - Loss: 0.2796
Epoch [31/50] - Loss: 0.2726
Epoch [32/50] - Loss: 0.2737
Epoch [33/50] - Loss: 0.2674
Epoch [34/50] - Loss: 0.2664
Epoch [35/50] - Loss: 0.2611
Epoch [36/50] - Loss: 0.2606
Epoch [37/50] - Loss: 0.2597
Epoch [38/50] - Loss: 0.2592
Epoch [39/50] - Loss: 0.2525
Epoch [40/50] - Loss: 0.2536
Epoch [41/50] - Loss: 0.2474
Epoch [42/50] - Loss: 0.2445
Epoch [43/50] - Loss: 0.2460
Epoch [44/50] - Loss: 0.2404
Epoch [45/50] - Loss: 0.2442
Epoch [46/50] - Loss: 0.2422
Epoch [47/50] - Loss: 0.2371
Epoch [48/50] - Loss: 0.2352
Epoch [49/50] - Loss: 0.2331
Epoch [50/50] - Loss: 0.2296
sum preds 1
sum labels 654
 - Test Metrics: Accuracy=0.7433, F1=0.0031, Recall=0.0015, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.1982
Epoch [2/50] - Loss: 0.7356
Epoch [3/50] - Loss: 0.5003
Epoch [4/50] - Loss: 0.4412
Epoch [5/50] - Loss: 0.4561
Epoch [6/50] - Loss: 0.4810
Epoch [7/50] - Loss: 0.4820
Epoch [8/50] - Loss: 0.4634
Epoch [9/50] - Loss: 0.4447
Epoch [10/50] - Loss: 0.4143
Epoch [11/50] - Loss: 0.3846
Epoch [12/50] - Loss: 0.3700
Epoch [13/50] - Loss: 0.3504
Epoch [14/50] - Loss: 0.3515
Epoch [15/50] - Loss: 0.3442
Epoch [16/50] - Loss: 0.3405
Epoch [17/50] - Loss: 0.3400
Epoch [18/50] - Loss: 0.3334
Epoch [19/50] - Loss: 0.3241
Epoch [20/50] - Loss: 0.3189
Epoch [21/50] - Loss: 0.3129
Epoch [22/50] - Loss: 0.3077
Epoch [23/50] - Loss: 0.3001
Epoch [24/50] - Loss: 0.2928
Epoch [25/50] - Loss: 0.2957
Epoch [26/50] - Loss: 0.2863
Epoch [27/50] - Loss: 0.2835
Epoch [28/50] - Loss: 0.2815
Epoch [29/50] - Loss: 0.2754
Epoch [30/50] - Loss: 0.2764
Epoch [31/50] - Loss: 0.2730
Epoch [32/50] - Loss: 0.2735
Epoch [33/50] - Loss: 0.2655
Epoch [34/50] - Loss: 0.2601
Epoch [35/50] - Loss: 0.2646
Epoch [36/50] - Loss: 0.2553
Epoch [37/50] - Loss: 0.2555
Epoch [38/50] - Loss: 0.2568
Epoch [39/50] - Loss: 0.2546
Epoch [40/50] - Loss: 0.2538
Epoch [41/50] - Loss: 0.2489
Epoch [42/50] - Loss: 0.2430
Epoch [43/50] - Loss: 0.2473
Epoch [44/50] - Loss: 0.2464
Epoch [45/50] - Loss: 0.2380
Epoch [46/50] - Loss: 0.2387
Epoch [47/50] - Loss: 0.2392
Epoch [48/50] - Loss: 0.2346
Epoch [49/50] - Loss: 0.2331
Epoch [50/50] - Loss: 0.2303
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_naive_naive_1804093900.csv.
Average F1 over valid seeds: 0.0020 ± 0.0014
___________________________________________________________________________________
Avg F1 for cora with SAR and naive, GATConv,0.2: 0.0020 ± 0.0014
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2465
Epoch [2/50] - Loss: 0.8717
Epoch [3/50] - Loss: 0.6266
Epoch [4/50] - Loss: 0.5022
Epoch [5/50] - Loss: 0.4749
Epoch [6/50] - Loss: 0.4756
Epoch [7/50] - Loss: 0.4868
Epoch [8/50] - Loss: 0.4944
Epoch [9/50] - Loss: 0.4853
Epoch [10/50] - Loss: 0.4794
Epoch [11/50] - Loss: 0.4588
Epoch [12/50] - Loss: 0.4339
Epoch [13/50] - Loss: 0.4186
Epoch [14/50] - Loss: 0.4015
Epoch [15/50] - Loss: 0.3904
Epoch [16/50] - Loss: 0.3824
Epoch [17/50] - Loss: 0.3822
Epoch [18/50] - Loss: 0.3758
Epoch [19/50] - Loss: 0.3721
Epoch [20/50] - Loss: 0.3683
Epoch [21/50] - Loss: 0.3643
Epoch [22/50] - Loss: 0.3575
Epoch [23/50] - Loss: 0.3435
Epoch [24/50] - Loss: 0.3474
Epoch [25/50] - Loss: 0.3351
Epoch [26/50] - Loss: 0.3344
Epoch [27/50] - Loss: 0.3300
Epoch [28/50] - Loss: 0.3258
Epoch [29/50] - Loss: 0.3191
Epoch [30/50] - Loss: 0.3143
Epoch [31/50] - Loss: 0.3154
Epoch [32/50] - Loss: 0.3102
Epoch [33/50] - Loss: 0.3056
Epoch [34/50] - Loss: 0.3059
Epoch [35/50] - Loss: 0.3038
Epoch [36/50] - Loss: 0.3038
Epoch [37/50] - Loss: 0.2983
Epoch [38/50] - Loss: 0.2924
Epoch [39/50] - Loss: 0.2920
Epoch [40/50] - Loss: 0.2891
Epoch [41/50] - Loss: 0.2844
Epoch [42/50] - Loss: 0.2870
Epoch [43/50] - Loss: 0.2818
Epoch [44/50] - Loss: 0.2837
Epoch [45/50] - Loss: 0.2774
Epoch [46/50] - Loss: 0.2781
Epoch [47/50] - Loss: 0.2729
Epoch [48/50] - Loss: 0.2715
Epoch [49/50] - Loss: 0.2694
Epoch [50/50] - Loss: 0.2696
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3148
Epoch [2/50] - Loss: 1.0087
Epoch [3/50] - Loss: 0.7591
Epoch [4/50] - Loss: 0.5942
Epoch [5/50] - Loss: 0.5073
Epoch [6/50] - Loss: 0.4664
Epoch [7/50] - Loss: 0.4614
Epoch [8/50] - Loss: 0.4548
Epoch [9/50] - Loss: 0.4681
Epoch [10/50] - Loss: 0.4568
Epoch [11/50] - Loss: 0.4702
Epoch [12/50] - Loss: 0.4521
Epoch [13/50] - Loss: 0.4320
Epoch [14/50] - Loss: 0.4248
Epoch [15/50] - Loss: 0.4123
Epoch [16/50] - Loss: 0.3999
Epoch [17/50] - Loss: 0.3835
Epoch [18/50] - Loss: 0.3626
Epoch [19/50] - Loss: 0.3588
Epoch [20/50] - Loss: 0.3590
Epoch [21/50] - Loss: 0.3486
Epoch [22/50] - Loss: 0.3468
Epoch [23/50] - Loss: 0.3392
Epoch [24/50] - Loss: 0.3338
Epoch [25/50] - Loss: 0.3310
Epoch [26/50] - Loss: 0.3227
Epoch [27/50] - Loss: 0.3157
Epoch [28/50] - Loss: 0.3108
Epoch [29/50] - Loss: 0.3041
Epoch [30/50] - Loss: 0.2997
Epoch [31/50] - Loss: 0.2985
Epoch [32/50] - Loss: 0.2928
Epoch [33/50] - Loss: 0.2943
Epoch [34/50] - Loss: 0.2876
Epoch [35/50] - Loss: 0.2882
Epoch [36/50] - Loss: 0.2819
Epoch [37/50] - Loss: 0.2848
Epoch [38/50] - Loss: 0.2764
Epoch [39/50] - Loss: 0.2741
Epoch [40/50] - Loss: 0.2694
Epoch [41/50] - Loss: 0.2665
Epoch [42/50] - Loss: 0.2665
Epoch [43/50] - Loss: 0.2639
Epoch [44/50] - Loss: 0.2615
Epoch [45/50] - Loss: 0.2584
Epoch [46/50] - Loss: 0.2586
Epoch [47/50] - Loss: 0.2562
Epoch [48/50] - Loss: 0.2532
Epoch [49/50] - Loss: 0.2512
Epoch [50/50] - Loss: 0.2498
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4594
Epoch [2/50] - Loss: 1.1931
Epoch [3/50] - Loss: 1.0231
Epoch [4/50] - Loss: 0.8735
Epoch [5/50] - Loss: 0.7386
Epoch [6/50] - Loss: 0.6365
Epoch [7/50] - Loss: 0.5628
Epoch [8/50] - Loss: 0.5099
Epoch [9/50] - Loss: 0.4835
Epoch [10/50] - Loss: 0.4762
Epoch [11/50] - Loss: 0.4684
Epoch [12/50] - Loss: 0.4657
Epoch [13/50] - Loss: 0.4614
Epoch [14/50] - Loss: 0.4662
Epoch [15/50] - Loss: 0.4639
Epoch [16/50] - Loss: 0.4587
Epoch [17/50] - Loss: 0.4512
Epoch [18/50] - Loss: 0.4448
Epoch [19/50] - Loss: 0.4273
Epoch [20/50] - Loss: 0.4272
Epoch [21/50] - Loss: 0.4124
Epoch [22/50] - Loss: 0.4089
Epoch [23/50] - Loss: 0.4048
Epoch [24/50] - Loss: 0.3981
Epoch [25/50] - Loss: 0.3964
Epoch [26/50] - Loss: 0.3891
Epoch [27/50] - Loss: 0.3880
Epoch [28/50] - Loss: 0.3821
Epoch [29/50] - Loss: 0.3803
Epoch [30/50] - Loss: 0.3775
Epoch [31/50] - Loss: 0.3736
Epoch [32/50] - Loss: 0.3670
Epoch [33/50] - Loss: 0.3665
Epoch [34/50] - Loss: 0.3583
Epoch [35/50] - Loss: 0.3576
Epoch [36/50] - Loss: 0.3554
Epoch [37/50] - Loss: 0.3530
Epoch [38/50] - Loss: 0.3530
Epoch [39/50] - Loss: 0.3450
Epoch [40/50] - Loss: 0.3447
Epoch [41/50] - Loss: 0.3390
Epoch [42/50] - Loss: 0.3384
Epoch [43/50] - Loss: 0.3351
Epoch [44/50] - Loss: 0.3330
Epoch [45/50] - Loss: 0.3262
Epoch [46/50] - Loss: 0.3222
Epoch [47/50] - Loss: 0.3245
Epoch [48/50] - Loss: 0.3240
Epoch [49/50] - Loss: 0.3201
Epoch [50/50] - Loss: 0.3203
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_naive_naive_1804093943.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for cora with SAR and naive, GCNConv,0.2: 0.0000 ± 0.0000
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8089, F1=0.1621, Recall=0.0896, Precision=0.8462
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8131, F1=0.2096, Recall=0.1202, Precision=0.8194
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8249, F1=0.2992, Recall=0.1813, Precision=0.8558
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_NNIF_NNIF_1804094026.csv.
Average F1 over valid seeds: 0.2236 ± 0.0568
___________________________________________________________________________________
Avg F1 for cora with SAR and NNIF, MLP,0.4: 0.2236 ± 0.0568
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7787, F1=0.1080, Recall=0.0576, Precision=0.8684
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7868, F1=0.1886, Recall=0.1065, Precision=0.8243
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8006, F1=0.2726, Recall=0.1606, Precision=0.9020
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_NNIF_NNIF_1804094054.csv.
Average F1 over valid seeds: 0.1897 ± 0.0672
___________________________________________________________________________________
Avg F1 for cora with SAR and NNIF, MLP,0.3: 0.1897 ± 0.0672
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7504, F1=0.0757, Recall=0.0398, Precision=0.7879
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7622, F1=0.1515, Recall=0.0826, Precision=0.9153
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7579, F1=0.1175, Recall=0.0627, Precision=0.9318
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_NNIF_NNIF_1804094104.csv.
Average F1 over valid seeds: 0.1149 ± 0.0310
___________________________________________________________________________________
Avg F1 for cora with SAR and NNIF, MLP,0.2: 0.1149 ± 0.0310
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3890
Epoch [2/50] - Loss: 1.2479
Epoch [3/50] - Loss: 1.1145
Epoch [4/50] - Loss: 0.9958
Epoch [5/50] - Loss: 0.9035
Epoch [6/50] - Loss: 0.8272
Epoch [7/50] - Loss: 0.7785
Epoch [8/50] - Loss: 0.7534
Epoch [9/50] - Loss: 0.7361
Epoch [10/50] - Loss: 0.7268
Epoch [11/50] - Loss: 0.7008
Epoch [12/50] - Loss: 0.6890
Epoch [13/50] - Loss: 0.6614
Epoch [14/50] - Loss: 0.6397
Epoch [15/50] - Loss: 0.6189
Epoch [16/50] - Loss: 0.5929
Epoch [17/50] - Loss: 0.5675
Epoch [18/50] - Loss: 0.5500
Epoch [19/50] - Loss: 0.5400
Epoch [20/50] - Loss: 0.5294
Epoch [21/50] - Loss: 0.5124
Epoch [22/50] - Loss: 0.4922
Epoch [23/50] - Loss: 0.4799
Epoch [24/50] - Loss: 0.4635
Epoch [25/50] - Loss: 0.4502
Epoch [26/50] - Loss: 0.4378
Epoch [27/50] - Loss: 0.4212
Epoch [28/50] - Loss: 0.4033
Epoch [29/50] - Loss: 0.3907
Epoch [30/50] - Loss: 0.3803
Epoch [31/50] - Loss: 0.3502
Epoch [32/50] - Loss: 0.3386
Epoch [33/50] - Loss: 0.3270
Epoch [34/50] - Loss: 0.3103
Epoch [35/50] - Loss: 0.2878
Epoch [36/50] - Loss: 0.2751
Epoch [37/50] - Loss: 0.2470
Epoch [38/50] - Loss: 0.2372
Epoch [39/50] - Loss: 0.2199
Epoch [40/50] - Loss: 0.2072
Epoch [41/50] - Loss: 0.1940
Epoch [42/50] - Loss: 0.1839
Epoch [43/50] - Loss: 0.1683
Epoch [44/50] - Loss: 0.1557
Epoch [45/50] - Loss: 0.1467
Epoch [46/50] - Loss: 0.1301
Epoch [47/50] - Loss: 0.1231
Epoch [48/50] - Loss: 0.1190
Epoch [49/50] - Loss: 0.1079
Epoch [50/50] - Loss: 0.1045
sum preds 45
sum labels 491
 - Test Metrics: Accuracy=0.8051, F1=0.1343, Recall=0.0733, Precision=0.8000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3232
Epoch [2/50] - Loss: 1.1253
Epoch [3/50] - Loss: 0.9496
Epoch [4/50] - Loss: 0.8327
Epoch [5/50] - Loss: 0.7576
Epoch [6/50] - Loss: 0.7055
Epoch [7/50] - Loss: 0.6994
Epoch [8/50] - Loss: 0.6988
Epoch [9/50] - Loss: 0.6671
Epoch [10/50] - Loss: 0.6381
Epoch [11/50] - Loss: 0.6002
Epoch [12/50] - Loss: 0.5624
Epoch [13/50] - Loss: 0.5340
Epoch [14/50] - Loss: 0.5137
Epoch [15/50] - Loss: 0.4956
Epoch [16/50] - Loss: 0.4807
Epoch [17/50] - Loss: 0.4670
Epoch [18/50] - Loss: 0.4450
Epoch [19/50] - Loss: 0.4358
Epoch [20/50] - Loss: 0.4096
Epoch [21/50] - Loss: 0.4037
Epoch [22/50] - Loss: 0.3802
Epoch [23/50] - Loss: 0.3711
Epoch [24/50] - Loss: 0.3505
Epoch [25/50] - Loss: 0.3477
Epoch [26/50] - Loss: 0.3241
Epoch [27/50] - Loss: 0.3119
Epoch [28/50] - Loss: 0.2952
Epoch [29/50] - Loss: 0.2770
Epoch [30/50] - Loss: 0.2607
Epoch [31/50] - Loss: 0.2439
Epoch [32/50] - Loss: 0.2269
Epoch [33/50] - Loss: 0.2192
Epoch [34/50] - Loss: 0.2032
Epoch [35/50] - Loss: 0.1929
Epoch [36/50] - Loss: 0.1834
Epoch [37/50] - Loss: 0.1690
Epoch [38/50] - Loss: 0.1647
Epoch [39/50] - Loss: 0.1522
Epoch [40/50] - Loss: 0.1423
Epoch [41/50] - Loss: 0.1365
Epoch [42/50] - Loss: 0.1306
Epoch [43/50] - Loss: 0.1226
Epoch [44/50] - Loss: 0.1151
Epoch [45/50] - Loss: 0.1057
Epoch [46/50] - Loss: 0.1020
Epoch [47/50] - Loss: 0.0971
Epoch [48/50] - Loss: 0.0925
Epoch [49/50] - Loss: 0.0860
Epoch [50/50] - Loss: 0.0863
sum preds 64
sum labels 491
 - Test Metrics: Accuracy=0.8123, F1=0.1946, Recall=0.1100, Precision=0.8438
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.5108
Epoch [2/50] - Loss: 1.3522
Epoch [3/50] - Loss: 1.2003
Epoch [4/50] - Loss: 1.0497
Epoch [5/50] - Loss: 0.9230
Epoch [6/50] - Loss: 0.8422
Epoch [7/50] - Loss: 0.7832
Epoch [8/50] - Loss: 0.7743
Epoch [9/50] - Loss: 0.7530
Epoch [10/50] - Loss: 0.7444
Epoch [11/50] - Loss: 0.7163
Epoch [12/50] - Loss: 0.7092
Epoch [13/50] - Loss: 0.6693
Epoch [14/50] - Loss: 0.6289
Epoch [15/50] - Loss: 0.6189
Epoch [16/50] - Loss: 0.5880
Epoch [17/50] - Loss: 0.5573
Epoch [18/50] - Loss: 0.5532
Epoch [19/50] - Loss: 0.5424
Epoch [20/50] - Loss: 0.5150
Epoch [21/50] - Loss: 0.5000
Epoch [22/50] - Loss: 0.4817
Epoch [23/50] - Loss: 0.4616
Epoch [24/50] - Loss: 0.4514
Epoch [25/50] - Loss: 0.4343
Epoch [26/50] - Loss: 0.4156
Epoch [27/50] - Loss: 0.4130
Epoch [28/50] - Loss: 0.3867
Epoch [29/50] - Loss: 0.3808
Epoch [30/50] - Loss: 0.3537
Epoch [31/50] - Loss: 0.3476
Epoch [32/50] - Loss: 0.3335
Epoch [33/50] - Loss: 0.3174
Epoch [34/50] - Loss: 0.2996
Epoch [35/50] - Loss: 0.2939
Epoch [36/50] - Loss: 0.2696
Epoch [37/50] - Loss: 0.2611
Epoch [38/50] - Loss: 0.2456
Epoch [39/50] - Loss: 0.2266
Epoch [40/50] - Loss: 0.2154
Epoch [41/50] - Loss: 0.2047
Epoch [42/50] - Loss: 0.1933
Epoch [43/50] - Loss: 0.1775
Epoch [44/50] - Loss: 0.1652
Epoch [45/50] - Loss: 0.1568
Epoch [46/50] - Loss: 0.1461
Epoch [47/50] - Loss: 0.1368
Epoch [48/50] - Loss: 0.1326
Epoch [49/50] - Loss: 0.1226
Epoch [50/50] - Loss: 0.1161
sum preds 50
sum labels 491
 - Test Metrics: Accuracy=0.7988, F1=0.1146, Recall=0.0631, Precision=0.6200
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_two_nnif_two_nnif_1804094114.csv.
Average F1 over valid seeds: 0.1478 ± 0.0340
___________________________________________________________________________________
Avg F1 for cora with SAR and two_nnif, MLP,0.4: 0.1478 ± 0.0340
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3242
Epoch [2/50] - Loss: 0.9843
Epoch [3/50] - Loss: 0.7929
Epoch [4/50] - Loss: 0.7337
Epoch [5/50] - Loss: 0.7431
Epoch [6/50] - Loss: 0.7150
Epoch [7/50] - Loss: 0.7026
Epoch [8/50] - Loss: 0.6534
Epoch [9/50] - Loss: 0.6080
Epoch [10/50] - Loss: 0.5617
Epoch [11/50] - Loss: 0.5499
Epoch [12/50] - Loss: 0.5486
Epoch [13/50] - Loss: 0.5284
Epoch [14/50] - Loss: 0.5237
Epoch [15/50] - Loss: 0.5111
Epoch [16/50] - Loss: 0.5006
Epoch [17/50] - Loss: 0.4948
Epoch [18/50] - Loss: 0.4855
Epoch [19/50] - Loss: 0.4749
Epoch [20/50] - Loss: 0.4752
Epoch [21/50] - Loss: 0.4608
Epoch [22/50] - Loss: 0.4549
Epoch [23/50] - Loss: 0.4480
Epoch [24/50] - Loss: 0.4435
Epoch [25/50] - Loss: 0.4386
Epoch [26/50] - Loss: 0.4181
Epoch [27/50] - Loss: 0.4294
Epoch [28/50] - Loss: 0.4246
Epoch [29/50] - Loss: 0.4282
Epoch [30/50] - Loss: 0.4209
Epoch [31/50] - Loss: 0.4149
Epoch [32/50] - Loss: 0.4041
Epoch [33/50] - Loss: 0.4092
Epoch [34/50] - Loss: 0.4134
Epoch [35/50] - Loss: 0.4163
Epoch [36/50] - Loss: 0.3959
Epoch [37/50] - Loss: 0.4047
Epoch [38/50] - Loss: 0.3994
Epoch [39/50] - Loss: 0.4016
Epoch [40/50] - Loss: 0.3957
Epoch [41/50] - Loss: 0.3890
Epoch [42/50] - Loss: 0.3869
Epoch [43/50] - Loss: 0.3935
Epoch [44/50] - Loss: 0.3882
Epoch [45/50] - Loss: 0.3806
Epoch [46/50] - Loss: 0.3837
Epoch [47/50] - Loss: 0.3770
Epoch [48/50] - Loss: 0.3779
Epoch [49/50] - Loss: 0.3756
Epoch [50/50] - Loss: 0.3768
sum preds 74
sum labels 491
 - Test Metrics: Accuracy=0.8207, F1=0.2442, Recall=0.1405, Precision=0.9324
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2586
Epoch [2/50] - Loss: 0.9178
Epoch [3/50] - Loss: 0.7570
Epoch [4/50] - Loss: 0.7073
Epoch [5/50] - Loss: 0.7295
Epoch [6/50] - Loss: 0.6838
Epoch [7/50] - Loss: 0.6534
Epoch [8/50] - Loss: 0.5928
Epoch [9/50] - Loss: 0.5669
Epoch [10/50] - Loss: 0.5367
Epoch [11/50] - Loss: 0.5281
Epoch [12/50] - Loss: 0.5073
Epoch [13/50] - Loss: 0.5100
Epoch [14/50] - Loss: 0.4951
Epoch [15/50] - Loss: 0.4777
Epoch [16/50] - Loss: 0.4655
Epoch [17/50] - Loss: 0.4581
Epoch [18/50] - Loss: 0.4459
Epoch [19/50] - Loss: 0.4558
Epoch [20/50] - Loss: 0.4392
Epoch [21/50] - Loss: 0.4309
Epoch [22/50] - Loss: 0.4319
Epoch [23/50] - Loss: 0.4224
Epoch [24/50] - Loss: 0.4162
Epoch [25/50] - Loss: 0.4065
Epoch [26/50] - Loss: 0.4077
Epoch [27/50] - Loss: 0.4017
Epoch [28/50] - Loss: 0.3958
Epoch [29/50] - Loss: 0.3898
Epoch [30/50] - Loss: 0.3872
Epoch [31/50] - Loss: 0.3819
Epoch [32/50] - Loss: 0.3881
Epoch [33/50] - Loss: 0.3837
Epoch [34/50] - Loss: 0.3773
Epoch [35/50] - Loss: 0.3686
Epoch [36/50] - Loss: 0.3721
Epoch [37/50] - Loss: 0.3702
Epoch [38/50] - Loss: 0.3521
Epoch [39/50] - Loss: 0.3554
Epoch [40/50] - Loss: 0.3549
Epoch [41/50] - Loss: 0.3458
Epoch [42/50] - Loss: 0.3515
Epoch [43/50] - Loss: 0.3397
Epoch [44/50] - Loss: 0.3392
Epoch [45/50] - Loss: 0.3446
Epoch [46/50] - Loss: 0.3356
Epoch [47/50] - Loss: 0.3256
Epoch [48/50] - Loss: 0.3281
Epoch [49/50] - Loss: 0.3242
Epoch [50/50] - Loss: 0.3103
sum preds 161
sum labels 491
 - Test Metrics: Accuracy=0.8564, F1=0.4755, Recall=0.3157, Precision=0.9627
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2257
Epoch [2/50] - Loss: 0.8679
Epoch [3/50] - Loss: 0.7337
Epoch [4/50] - Loss: 0.7058
Epoch [5/50] - Loss: 0.7172
Epoch [6/50] - Loss: 0.6881
Epoch [7/50] - Loss: 0.6334
Epoch [8/50] - Loss: 0.5625
Epoch [9/50] - Loss: 0.5477
Epoch [10/50] - Loss: 0.5319
Epoch [11/50] - Loss: 0.5190
Epoch [12/50] - Loss: 0.5069
Epoch [13/50] - Loss: 0.4988
Epoch [14/50] - Loss: 0.4904
Epoch [15/50] - Loss: 0.4728
Epoch [16/50] - Loss: 0.4603
Epoch [17/50] - Loss: 0.4628
Epoch [18/50] - Loss: 0.4484
Epoch [19/50] - Loss: 0.4393
Epoch [20/50] - Loss: 0.4338
Epoch [21/50] - Loss: 0.4329
Epoch [22/50] - Loss: 0.4254
Epoch [23/50] - Loss: 0.4180
Epoch [24/50] - Loss: 0.4145
Epoch [25/50] - Loss: 0.4000
Epoch [26/50] - Loss: 0.3960
Epoch [27/50] - Loss: 0.3971
Epoch [28/50] - Loss: 0.3942
Epoch [29/50] - Loss: 0.3881
Epoch [30/50] - Loss: 0.3793
Epoch [31/50] - Loss: 0.3755
Epoch [32/50] - Loss: 0.3758
Epoch [33/50] - Loss: 0.3607
Epoch [34/50] - Loss: 0.3575
Epoch [35/50] - Loss: 0.3566
Epoch [36/50] - Loss: 0.3568
Epoch [37/50] - Loss: 0.3575
Epoch [38/50] - Loss: 0.3490
Epoch [39/50] - Loss: 0.3388
Epoch [40/50] - Loss: 0.3389
Epoch [41/50] - Loss: 0.3425
Epoch [42/50] - Loss: 0.3286
Epoch [43/50] - Loss: 0.3256
Epoch [44/50] - Loss: 0.3210
Epoch [45/50] - Loss: 0.3231
Epoch [46/50] - Loss: 0.3121
Epoch [47/50] - Loss: 0.3131
Epoch [48/50] - Loss: 0.3078
Epoch [49/50] - Loss: 0.2997
Epoch [50/50] - Loss: 0.2935
sum preds 139
sum labels 491
 - Test Metrics: Accuracy=0.8471, F1=0.4222, Recall=0.2709, Precision=0.9568
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_two_nnif_two_nnif_1804094156.csv.
Average F1 over valid seeds: 0.3806 ± 0.0989
___________________________________________________________________________________
Avg F1 for cora with SAR and two_nnif, GATConv,0.4: 0.3806 ± 0.0989
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2678
Epoch [2/50] - Loss: 0.9705
Epoch [3/50] - Loss: 0.8085
Epoch [4/50] - Loss: 0.7596
Epoch [5/50] - Loss: 0.7627
Epoch [6/50] - Loss: 0.7300
Epoch [7/50] - Loss: 0.7138
Epoch [8/50] - Loss: 0.6790
Epoch [9/50] - Loss: 0.6579
Epoch [10/50] - Loss: 0.6234
Epoch [11/50] - Loss: 0.6011
Epoch [12/50] - Loss: 0.5873
Epoch [13/50] - Loss: 0.5718
Epoch [14/50] - Loss: 0.5566
Epoch [15/50] - Loss: 0.5494
Epoch [16/50] - Loss: 0.5336
Epoch [17/50] - Loss: 0.5338
Epoch [18/50] - Loss: 0.5231
Epoch [19/50] - Loss: 0.4927
Epoch [20/50] - Loss: 0.5065
Epoch [21/50] - Loss: 0.4959
Epoch [22/50] - Loss: 0.4945
Epoch [23/50] - Loss: 0.4806
Epoch [24/50] - Loss: 0.4864
Epoch [25/50] - Loss: 0.4772
Epoch [26/50] - Loss: 0.4753
Epoch [27/50] - Loss: 0.4605
Epoch [28/50] - Loss: 0.4593
Epoch [29/50] - Loss: 0.4583
Epoch [30/50] - Loss: 0.4482
Epoch [31/50] - Loss: 0.4435
Epoch [32/50] - Loss: 0.4399
Epoch [33/50] - Loss: 0.4325
Epoch [34/50] - Loss: 0.4340
Epoch [35/50] - Loss: 0.4249
Epoch [36/50] - Loss: 0.4227
Epoch [37/50] - Loss: 0.4249
Epoch [38/50] - Loss: 0.4238
Epoch [39/50] - Loss: 0.4220
Epoch [40/50] - Loss: 0.4130
Epoch [41/50] - Loss: 0.4016
Epoch [42/50] - Loss: 0.3987
Epoch [43/50] - Loss: 0.4013
Epoch [44/50] - Loss: 0.3870
Epoch [45/50] - Loss: 0.3819
Epoch [46/50] - Loss: 0.3744
Epoch [47/50] - Loss: 0.3751
Epoch [48/50] - Loss: 0.3635
Epoch [49/50] - Loss: 0.3627
Epoch [50/50] - Loss: 0.3625
sum preds 113
sum labels 491
 - Test Metrics: Accuracy=0.8370, F1=0.3576, Recall=0.2200, Precision=0.9558
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3286
Epoch [2/50] - Loss: 1.0848
Epoch [3/50] - Loss: 0.8852
Epoch [4/50] - Loss: 0.7861
Epoch [5/50] - Loss: 0.7365
Epoch [6/50] - Loss: 0.7353
Epoch [7/50] - Loss: 0.7189
Epoch [8/50] - Loss: 0.6966
Epoch [9/50] - Loss: 0.6880
Epoch [10/50] - Loss: 0.6522
Epoch [11/50] - Loss: 0.6298
Epoch [12/50] - Loss: 0.6041
Epoch [13/50] - Loss: 0.5733
Epoch [14/50] - Loss: 0.5549
Epoch [15/50] - Loss: 0.5393
Epoch [16/50] - Loss: 0.5326
Epoch [17/50] - Loss: 0.5192
Epoch [18/50] - Loss: 0.5108
Epoch [19/50] - Loss: 0.4978
Epoch [20/50] - Loss: 0.4865
Epoch [21/50] - Loss: 0.4726
Epoch [22/50] - Loss: 0.4658
Epoch [23/50] - Loss: 0.4568
Epoch [24/50] - Loss: 0.4513
Epoch [25/50] - Loss: 0.4406
Epoch [26/50] - Loss: 0.4213
Epoch [27/50] - Loss: 0.4192
Epoch [28/50] - Loss: 0.4136
Epoch [29/50] - Loss: 0.4114
Epoch [30/50] - Loss: 0.4018
Epoch [31/50] - Loss: 0.4002
Epoch [32/50] - Loss: 0.3953
Epoch [33/50] - Loss: 0.3791
Epoch [34/50] - Loss: 0.3800
Epoch [35/50] - Loss: 0.3705
Epoch [36/50] - Loss: 0.3707
Epoch [37/50] - Loss: 0.3623
Epoch [38/50] - Loss: 0.3605
Epoch [39/50] - Loss: 0.3581
Epoch [40/50] - Loss: 0.3551
Epoch [41/50] - Loss: 0.3496
Epoch [42/50] - Loss: 0.3407
Epoch [43/50] - Loss: 0.3427
Epoch [44/50] - Loss: 0.3420
Epoch [45/50] - Loss: 0.3444
Epoch [46/50] - Loss: 0.3327
Epoch [47/50] - Loss: 0.3273
Epoch [48/50] - Loss: 0.3258
Epoch [49/50] - Loss: 0.3248
Epoch [50/50] - Loss: 0.3292
sum preds 146
sum labels 491
 - Test Metrics: Accuracy=0.8501, F1=0.4396, Recall=0.2851, Precision=0.9589
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4500
Epoch [2/50] - Loss: 1.2288
Epoch [3/50] - Loss: 1.0935
Epoch [4/50] - Loss: 0.9796
Epoch [5/50] - Loss: 0.8877
Epoch [6/50] - Loss: 0.8203
Epoch [7/50] - Loss: 0.7844
Epoch [8/50] - Loss: 0.7591
Epoch [9/50] - Loss: 0.7419
Epoch [10/50] - Loss: 0.7527
Epoch [11/50] - Loss: 0.7183
Epoch [12/50] - Loss: 0.7203
Epoch [13/50] - Loss: 0.7079
Epoch [14/50] - Loss: 0.6896
Epoch [15/50] - Loss: 0.6813
Epoch [16/50] - Loss: 0.6533
Epoch [17/50] - Loss: 0.6319
Epoch [18/50] - Loss: 0.6295
Epoch [19/50] - Loss: 0.6129
Epoch [20/50] - Loss: 0.5953
Epoch [21/50] - Loss: 0.5933
Epoch [22/50] - Loss: 0.5843
Epoch [23/50] - Loss: 0.5753
Epoch [24/50] - Loss: 0.5595
Epoch [25/50] - Loss: 0.5499
Epoch [26/50] - Loss: 0.5474
Epoch [27/50] - Loss: 0.5364
Epoch [28/50] - Loss: 0.5267
Epoch [29/50] - Loss: 0.5145
Epoch [30/50] - Loss: 0.5103
Epoch [31/50] - Loss: 0.5100
Epoch [32/50] - Loss: 0.5065
Epoch [33/50] - Loss: 0.5013
Epoch [34/50] - Loss: 0.4879
Epoch [35/50] - Loss: 0.4801
Epoch [36/50] - Loss: 0.4693
Epoch [37/50] - Loss: 0.4616
Epoch [38/50] - Loss: 0.4600
Epoch [39/50] - Loss: 0.4539
Epoch [40/50] - Loss: 0.4400
Epoch [41/50] - Loss: 0.4441
Epoch [42/50] - Loss: 0.4411
Epoch [43/50] - Loss: 0.4385
Epoch [44/50] - Loss: 0.4421
Epoch [45/50] - Loss: 0.4173
Epoch [46/50] - Loss: 0.4225
Epoch [47/50] - Loss: 0.4104
Epoch [48/50] - Loss: 0.4095
Epoch [49/50] - Loss: 0.4017
Epoch [50/50] - Loss: 0.3911
sum preds 115
sum labels 491
 - Test Metrics: Accuracy=0.8379, F1=0.3630, Recall=0.2240, Precision=0.9565
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_two_nnif_two_nnif_1804094239.csv.
Average F1 over valid seeds: 0.3867 ± 0.0374
___________________________________________________________________________________
Avg F1 for cora with SAR and two_nnif, GCNConv,0.4: 0.3867 ± 0.0374
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3900
Epoch [2/50] - Loss: 1.2373
Epoch [3/50] - Loss: 1.0955
Epoch [4/50] - Loss: 0.9622
Epoch [5/50] - Loss: 0.8407
Epoch [6/50] - Loss: 0.7554
Epoch [7/50] - Loss: 0.7086
Epoch [8/50] - Loss: 0.6608
Epoch [9/50] - Loss: 0.6618
Epoch [10/50] - Loss: 0.6655
Epoch [11/50] - Loss: 0.6436
Epoch [12/50] - Loss: 0.6333
Epoch [13/50] - Loss: 0.5956
Epoch [14/50] - Loss: 0.6042
Epoch [15/50] - Loss: 0.5749
Epoch [16/50] - Loss: 0.5523
Epoch [17/50] - Loss: 0.5266
Epoch [18/50] - Loss: 0.5206
Epoch [19/50] - Loss: 0.5061
Epoch [20/50] - Loss: 0.4861
Epoch [21/50] - Loss: 0.4679
Epoch [22/50] - Loss: 0.4640
Epoch [23/50] - Loss: 0.4412
Epoch [24/50] - Loss: 0.4303
Epoch [25/50] - Loss: 0.4189
Epoch [26/50] - Loss: 0.4073
Epoch [27/50] - Loss: 0.3787
Epoch [28/50] - Loss: 0.3731
Epoch [29/50] - Loss: 0.3734
Epoch [30/50] - Loss: 0.3550
Epoch [31/50] - Loss: 0.3468
Epoch [32/50] - Loss: 0.3317
Epoch [33/50] - Loss: 0.3270
Epoch [34/50] - Loss: 0.3157
Epoch [35/50] - Loss: 0.3052
Epoch [36/50] - Loss: 0.3014
Epoch [37/50] - Loss: 0.2902
Epoch [38/50] - Loss: 0.2880
Epoch [39/50] - Loss: 0.2682
Epoch [40/50] - Loss: 0.2590
Epoch [41/50] - Loss: 0.2513
Epoch [42/50] - Loss: 0.2414
Epoch [43/50] - Loss: 0.2284
Epoch [44/50] - Loss: 0.2212
Epoch [45/50] - Loss: 0.2037
Epoch [46/50] - Loss: 0.1913
Epoch [47/50] - Loss: 0.1764
Epoch [48/50] - Loss: 0.1629
Epoch [49/50] - Loss: 0.1585
Epoch [50/50] - Loss: 0.1473
sum preds 40
sum labels 573
 - Test Metrics: Accuracy=0.7803, F1=0.1175, Recall=0.0628, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3199
Epoch [2/50] - Loss: 1.1065
Epoch [3/50] - Loss: 0.9174
Epoch [4/50] - Loss: 0.7909
Epoch [5/50] - Loss: 0.6898
Epoch [6/50] - Loss: 0.6659
Epoch [7/50] - Loss: 0.6384
Epoch [8/50] - Loss: 0.6463
Epoch [9/50] - Loss: 0.6071
Epoch [10/50] - Loss: 0.5860
Epoch [11/50] - Loss: 0.5585
Epoch [12/50] - Loss: 0.5193
Epoch [13/50] - Loss: 0.4972
Epoch [14/50] - Loss: 0.4740
Epoch [15/50] - Loss: 0.4552
Epoch [16/50] - Loss: 0.4399
Epoch [17/50] - Loss: 0.4303
Epoch [18/50] - Loss: 0.4146
Epoch [19/50] - Loss: 0.3925
Epoch [20/50] - Loss: 0.3831
Epoch [21/50] - Loss: 0.3696
Epoch [22/50] - Loss: 0.3502
Epoch [23/50] - Loss: 0.3331
Epoch [24/50] - Loss: 0.3212
Epoch [25/50] - Loss: 0.3057
Epoch [26/50] - Loss: 0.2973
Epoch [27/50] - Loss: 0.2935
Epoch [28/50] - Loss: 0.2774
Epoch [29/50] - Loss: 0.2730
Epoch [30/50] - Loss: 0.2692
Epoch [31/50] - Loss: 0.2584
Epoch [32/50] - Loss: 0.2485
Epoch [33/50] - Loss: 0.2468
Epoch [34/50] - Loss: 0.2382
Epoch [35/50] - Loss: 0.2408
Epoch [36/50] - Loss: 0.2262
Epoch [37/50] - Loss: 0.2199
Epoch [38/50] - Loss: 0.2140
Epoch [39/50] - Loss: 0.2158
Epoch [40/50] - Loss: 0.2031
Epoch [41/50] - Loss: 0.1986
Epoch [42/50] - Loss: 0.1902
Epoch [43/50] - Loss: 0.1882
Epoch [44/50] - Loss: 0.1837
Epoch [45/50] - Loss: 0.1738
Epoch [46/50] - Loss: 0.1633
Epoch [47/50] - Loss: 0.1499
Epoch [48/50] - Loss: 0.1389
Epoch [49/50] - Loss: 0.1257
Epoch [50/50] - Loss: 0.1143
sum preds 61
sum labels 573
 - Test Metrics: Accuracy=0.7889, F1=0.1798, Recall=0.0995, Precision=0.9344
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.5207
Epoch [2/50] - Loss: 1.3497
Epoch [3/50] - Loss: 1.1866
Epoch [4/50] - Loss: 1.0232
Epoch [5/50] - Loss: 0.8871
Epoch [6/50] - Loss: 0.7806
Epoch [7/50] - Loss: 0.6986
Epoch [8/50] - Loss: 0.6744
Epoch [9/50] - Loss: 0.6564
Epoch [10/50] - Loss: 0.6636
Epoch [11/50] - Loss: 0.6535
Epoch [12/50] - Loss: 0.6339
Epoch [13/50] - Loss: 0.5855
Epoch [14/50] - Loss: 0.5825
Epoch [15/50] - Loss: 0.5541
Epoch [16/50] - Loss: 0.5323
Epoch [17/50] - Loss: 0.4996
Epoch [18/50] - Loss: 0.4771
Epoch [19/50] - Loss: 0.4714
Epoch [20/50] - Loss: 0.4530
Epoch [21/50] - Loss: 0.4468
Epoch [22/50] - Loss: 0.4212
Epoch [23/50] - Loss: 0.4035
Epoch [24/50] - Loss: 0.3980
Epoch [25/50] - Loss: 0.3829
Epoch [26/50] - Loss: 0.3678
Epoch [27/50] - Loss: 0.3427
Epoch [28/50] - Loss: 0.3413
Epoch [29/50] - Loss: 0.3254
Epoch [30/50] - Loss: 0.3115
Epoch [31/50] - Loss: 0.3036
Epoch [32/50] - Loss: 0.2932
Epoch [33/50] - Loss: 0.2835
Epoch [34/50] - Loss: 0.2810
Epoch [35/50] - Loss: 0.2652
Epoch [36/50] - Loss: 0.2607
Epoch [37/50] - Loss: 0.2580
Epoch [38/50] - Loss: 0.2457
Epoch [39/50] - Loss: 0.2399
Epoch [40/50] - Loss: 0.2351
Epoch [41/50] - Loss: 0.2204
Epoch [42/50] - Loss: 0.2196
Epoch [43/50] - Loss: 0.2102
Epoch [44/50] - Loss: 0.2065
Epoch [45/50] - Loss: 0.1950
Epoch [46/50] - Loss: 0.1892
Epoch [47/50] - Loss: 0.1889
Epoch [48/50] - Loss: 0.1773
Epoch [49/50] - Loss: 0.1722
Epoch [50/50] - Loss: 0.1721
sum preds 29
sum labels 573
 - Test Metrics: Accuracy=0.7759, F1=0.0831, Recall=0.0436, Precision=0.8621
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_two_nnif_two_nnif_1804094324.csv.
Average F1 over valid seeds: 0.1268 ± 0.0400
___________________________________________________________________________________
Avg F1 for cora with SAR and two_nnif, MLP,0.3: 0.1268 ± 0.0400
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3238
Epoch [2/50] - Loss: 0.9497
Epoch [3/50] - Loss: 0.7354
Epoch [4/50] - Loss: 0.6504
Epoch [5/50] - Loss: 0.6295
Epoch [6/50] - Loss: 0.6510
Epoch [7/50] - Loss: 0.6377
Epoch [8/50] - Loss: 0.5946
Epoch [9/50] - Loss: 0.5624
Epoch [10/50] - Loss: 0.5520
Epoch [11/50] - Loss: 0.5165
Epoch [12/50] - Loss: 0.4940
Epoch [13/50] - Loss: 0.4850
Epoch [14/50] - Loss: 0.4786
Epoch [15/50] - Loss: 0.4741
Epoch [16/50] - Loss: 0.4706
Epoch [17/50] - Loss: 0.4646
Epoch [18/50] - Loss: 0.4474
Epoch [19/50] - Loss: 0.4318
Epoch [20/50] - Loss: 0.4266
Epoch [21/50] - Loss: 0.4162
Epoch [22/50] - Loss: 0.4099
Epoch [23/50] - Loss: 0.4042
Epoch [24/50] - Loss: 0.4009
Epoch [25/50] - Loss: 0.3969
Epoch [26/50] - Loss: 0.3909
Epoch [27/50] - Loss: 0.3842
Epoch [28/50] - Loss: 0.3866
Epoch [29/50] - Loss: 0.3799
Epoch [30/50] - Loss: 0.3782
Epoch [31/50] - Loss: 0.3806
Epoch [32/50] - Loss: 0.3632
Epoch [33/50] - Loss: 0.3692
Epoch [34/50] - Loss: 0.3579
Epoch [35/50] - Loss: 0.3710
Epoch [36/50] - Loss: 0.3631
Epoch [37/50] - Loss: 0.3535
Epoch [38/50] - Loss: 0.3496
Epoch [39/50] - Loss: 0.3462
Epoch [40/50] - Loss: 0.3441
Epoch [41/50] - Loss: 0.3409
Epoch [42/50] - Loss: 0.3537
Epoch [43/50] - Loss: 0.3412
Epoch [44/50] - Loss: 0.3422
Epoch [45/50] - Loss: 0.3400
Epoch [46/50] - Loss: 0.3431
Epoch [47/50] - Loss: 0.3365
Epoch [48/50] - Loss: 0.3334
Epoch [49/50] - Loss: 0.3274
Epoch [50/50] - Loss: 0.3287
sum preds 2
sum labels 573
 - Test Metrics: Accuracy=0.7682, F1=0.0070, Recall=0.0035, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2368
Epoch [2/50] - Loss: 0.8832
Epoch [3/50] - Loss: 0.6943
Epoch [4/50] - Loss: 0.6424
Epoch [5/50] - Loss: 0.6268
Epoch [6/50] - Loss: 0.6202
Epoch [7/50] - Loss: 0.6080
Epoch [8/50] - Loss: 0.5926
Epoch [9/50] - Loss: 0.5233
Epoch [10/50] - Loss: 0.5057
Epoch [11/50] - Loss: 0.4775
Epoch [12/50] - Loss: 0.4724
Epoch [13/50] - Loss: 0.4753
Epoch [14/50] - Loss: 0.4512
Epoch [15/50] - Loss: 0.4542
Epoch [16/50] - Loss: 0.4360
Epoch [17/50] - Loss: 0.4431
Epoch [18/50] - Loss: 0.4324
Epoch [19/50] - Loss: 0.4162
Epoch [20/50] - Loss: 0.4084
Epoch [21/50] - Loss: 0.4009
Epoch [22/50] - Loss: 0.3876
Epoch [23/50] - Loss: 0.3978
Epoch [24/50] - Loss: 0.3894
Epoch [25/50] - Loss: 0.3743
Epoch [26/50] - Loss: 0.3802
Epoch [27/50] - Loss: 0.3646
Epoch [28/50] - Loss: 0.3655
Epoch [29/50] - Loss: 0.3633
Epoch [30/50] - Loss: 0.3665
Epoch [31/50] - Loss: 0.3545
Epoch [32/50] - Loss: 0.3591
Epoch [33/50] - Loss: 0.3431
Epoch [34/50] - Loss: 0.3542
Epoch [35/50] - Loss: 0.3417
Epoch [36/50] - Loss: 0.3479
Epoch [37/50] - Loss: 0.3430
Epoch [38/50] - Loss: 0.3399
Epoch [39/50] - Loss: 0.3417
Epoch [40/50] - Loss: 0.3352
Epoch [41/50] - Loss: 0.3362
Epoch [42/50] - Loss: 0.3365
Epoch [43/50] - Loss: 0.3288
Epoch [44/50] - Loss: 0.3325
Epoch [45/50] - Loss: 0.3299
Epoch [46/50] - Loss: 0.3184
Epoch [47/50] - Loss: 0.3155
Epoch [48/50] - Loss: 0.3175
Epoch [49/50] - Loss: 0.3190
Epoch [50/50] - Loss: 0.3111
sum preds 64
sum labels 573
 - Test Metrics: Accuracy=0.7917, F1=0.1947, Recall=0.1082, Precision=0.9688
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2165
Epoch [2/50] - Loss: 0.8171
Epoch [3/50] - Loss: 0.6373
Epoch [4/50] - Loss: 0.6096
Epoch [5/50] - Loss: 0.6286
Epoch [6/50] - Loss: 0.6331
Epoch [7/50] - Loss: 0.5869
Epoch [8/50] - Loss: 0.5356
Epoch [9/50] - Loss: 0.5162
Epoch [10/50] - Loss: 0.4824
Epoch [11/50] - Loss: 0.4574
Epoch [12/50] - Loss: 0.4550
Epoch [13/50] - Loss: 0.4601
Epoch [14/50] - Loss: 0.4473
Epoch [15/50] - Loss: 0.4342
Epoch [16/50] - Loss: 0.4352
Epoch [17/50] - Loss: 0.4183
Epoch [18/50] - Loss: 0.4074
Epoch [19/50] - Loss: 0.4035
Epoch [20/50] - Loss: 0.4048
Epoch [21/50] - Loss: 0.3936
Epoch [22/50] - Loss: 0.3963
Epoch [23/50] - Loss: 0.3827
Epoch [24/50] - Loss: 0.3826
Epoch [25/50] - Loss: 0.3820
Epoch [26/50] - Loss: 0.3704
Epoch [27/50] - Loss: 0.3599
Epoch [28/50] - Loss: 0.3589
Epoch [29/50] - Loss: 0.3622
Epoch [30/50] - Loss: 0.3559
Epoch [31/50] - Loss: 0.3626
Epoch [32/50] - Loss: 0.3492
Epoch [33/50] - Loss: 0.3466
Epoch [34/50] - Loss: 0.3513
Epoch [35/50] - Loss: 0.3392
Epoch [36/50] - Loss: 0.3482
Epoch [37/50] - Loss: 0.3369
Epoch [38/50] - Loss: 0.3291
Epoch [39/50] - Loss: 0.3306
Epoch [40/50] - Loss: 0.3319
Epoch [41/50] - Loss: 0.3261
Epoch [42/50] - Loss: 0.3251
Epoch [43/50] - Loss: 0.3153
Epoch [44/50] - Loss: 0.3170
Epoch [45/50] - Loss: 0.3037
Epoch [46/50] - Loss: 0.3122
Epoch [47/50] - Loss: 0.3109
Epoch [48/50] - Loss: 0.3032
Epoch [49/50] - Loss: 0.3002
Epoch [50/50] - Loss: 0.2947
sum preds 79
sum labels 573
 - Test Metrics: Accuracy=0.7962, F1=0.2301, Recall=0.1309, Precision=0.9494
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_two_nnif_two_nnif_1804094404.csv.
Average F1 over valid seeds: 0.1439 ± 0.0979
___________________________________________________________________________________
Avg F1 for cora with SAR and two_nnif, GATConv,0.3: 0.1439 ± 0.0979
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2620
Epoch [2/50] - Loss: 0.9405
Epoch [3/50] - Loss: 0.7413
Epoch [4/50] - Loss: 0.6556
Epoch [5/50] - Loss: 0.6557
Epoch [6/50] - Loss: 0.6702
Epoch [7/50] - Loss: 0.6560
Epoch [8/50] - Loss: 0.6360
Epoch [9/50] - Loss: 0.6185
Epoch [10/50] - Loss: 0.5906
Epoch [11/50] - Loss: 0.5715
Epoch [12/50] - Loss: 0.5461
Epoch [13/50] - Loss: 0.5195
Epoch [14/50] - Loss: 0.5142
Epoch [15/50] - Loss: 0.5096
Epoch [16/50] - Loss: 0.4917
Epoch [17/50] - Loss: 0.4856
Epoch [18/50] - Loss: 0.4850
Epoch [19/50] - Loss: 0.4672
Epoch [20/50] - Loss: 0.4701
Epoch [21/50] - Loss: 0.4548
Epoch [22/50] - Loss: 0.4513
Epoch [23/50] - Loss: 0.4421
Epoch [24/50] - Loss: 0.4341
Epoch [25/50] - Loss: 0.4335
Epoch [26/50] - Loss: 0.4290
Epoch [27/50] - Loss: 0.4284
Epoch [28/50] - Loss: 0.4200
Epoch [29/50] - Loss: 0.4237
Epoch [30/50] - Loss: 0.4087
Epoch [31/50] - Loss: 0.4136
Epoch [32/50] - Loss: 0.4091
Epoch [33/50] - Loss: 0.3967
Epoch [34/50] - Loss: 0.4024
Epoch [35/50] - Loss: 0.3924
Epoch [36/50] - Loss: 0.3894
Epoch [37/50] - Loss: 0.3932
Epoch [38/50] - Loss: 0.3832
Epoch [39/50] - Loss: 0.3841
Epoch [40/50] - Loss: 0.3770
Epoch [41/50] - Loss: 0.3715
Epoch [42/50] - Loss: 0.3666
Epoch [43/50] - Loss: 0.3737
Epoch [44/50] - Loss: 0.3674
Epoch [45/50] - Loss: 0.3696
Epoch [46/50] - Loss: 0.3624
Epoch [47/50] - Loss: 0.3642
Epoch [48/50] - Loss: 0.3551
Epoch [49/50] - Loss: 0.3622
Epoch [50/50] - Loss: 0.3660
sum preds 0
sum labels 573
 - Test Metrics: Accuracy=0.7674, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3242
Epoch [2/50] - Loss: 1.0592
Epoch [3/50] - Loss: 0.8457
Epoch [4/50] - Loss: 0.7209
Epoch [5/50] - Loss: 0.6458
Epoch [6/50] - Loss: 0.6274
Epoch [7/50] - Loss: 0.6434
Epoch [8/50] - Loss: 0.6460
Epoch [9/50] - Loss: 0.6410
Epoch [10/50] - Loss: 0.6093
Epoch [11/50] - Loss: 0.5690
Epoch [12/50] - Loss: 0.5762
Epoch [13/50] - Loss: 0.5378
Epoch [14/50] - Loss: 0.5129
Epoch [15/50] - Loss: 0.4872
Epoch [16/50] - Loss: 0.4980
Epoch [17/50] - Loss: 0.4805
Epoch [18/50] - Loss: 0.4707
Epoch [19/50] - Loss: 0.4611
Epoch [20/50] - Loss: 0.4539
Epoch [21/50] - Loss: 0.4320
Epoch [22/50] - Loss: 0.4284
Epoch [23/50] - Loss: 0.4233
Epoch [24/50] - Loss: 0.4164
Epoch [25/50] - Loss: 0.4075
Epoch [26/50] - Loss: 0.4006
Epoch [27/50] - Loss: 0.3961
Epoch [28/50] - Loss: 0.3971
Epoch [29/50] - Loss: 0.3838
Epoch [30/50] - Loss: 0.3879
Epoch [31/50] - Loss: 0.3786
Epoch [32/50] - Loss: 0.3796
Epoch [33/50] - Loss: 0.3645
Epoch [34/50] - Loss: 0.3572
Epoch [35/50] - Loss: 0.3783
Epoch [36/50] - Loss: 0.3745
Epoch [37/50] - Loss: 0.3616
Epoch [38/50] - Loss: 0.3496
Epoch [39/50] - Loss: 0.3603
Epoch [40/50] - Loss: 0.3566
Epoch [41/50] - Loss: 0.3592
Epoch [42/50] - Loss: 0.3496
Epoch [43/50] - Loss: 0.3542
Epoch [44/50] - Loss: 0.3542
Epoch [45/50] - Loss: 0.3453
Epoch [46/50] - Loss: 0.3359
Epoch [47/50] - Loss: 0.3323
Epoch [48/50] - Loss: 0.3412
Epoch [49/50] - Loss: 0.3342
Epoch [50/50] - Loss: 0.3361
sum preds 8
sum labels 573
 - Test Metrics: Accuracy=0.7706, F1=0.0275, Recall=0.0140, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4534
Epoch [2/50] - Loss: 1.2179
Epoch [3/50] - Loss: 1.0734
Epoch [4/50] - Loss: 0.9486
Epoch [5/50] - Loss: 0.8332
Epoch [6/50] - Loss: 0.7651
Epoch [7/50] - Loss: 0.7016
Epoch [8/50] - Loss: 0.6693
Epoch [9/50] - Loss: 0.6625
Epoch [10/50] - Loss: 0.6513
Epoch [11/50] - Loss: 0.6285
Epoch [12/50] - Loss: 0.6425
Epoch [13/50] - Loss: 0.6332
Epoch [14/50] - Loss: 0.6233
Epoch [15/50] - Loss: 0.5851
Epoch [16/50] - Loss: 0.5857
Epoch [17/50] - Loss: 0.5670
Epoch [18/50] - Loss: 0.5752
Epoch [19/50] - Loss: 0.5514
Epoch [20/50] - Loss: 0.5451
Epoch [21/50] - Loss: 0.5429
Epoch [22/50] - Loss: 0.5365
Epoch [23/50] - Loss: 0.5168
Epoch [24/50] - Loss: 0.5083
Epoch [25/50] - Loss: 0.5090
Epoch [26/50] - Loss: 0.4903
Epoch [27/50] - Loss: 0.4817
Epoch [28/50] - Loss: 0.4773
Epoch [29/50] - Loss: 0.4750
Epoch [30/50] - Loss: 0.4810
Epoch [31/50] - Loss: 0.4585
Epoch [32/50] - Loss: 0.4638
Epoch [33/50] - Loss: 0.4441
Epoch [34/50] - Loss: 0.4474
Epoch [35/50] - Loss: 0.4455
Epoch [36/50] - Loss: 0.4392
Epoch [37/50] - Loss: 0.4274
Epoch [38/50] - Loss: 0.4325
Epoch [39/50] - Loss: 0.4277
Epoch [40/50] - Loss: 0.4257
Epoch [41/50] - Loss: 0.4201
Epoch [42/50] - Loss: 0.4182
Epoch [43/50] - Loss: 0.4090
Epoch [44/50] - Loss: 0.4133
Epoch [45/50] - Loss: 0.4029
Epoch [46/50] - Loss: 0.3986
Epoch [47/50] - Loss: 0.3995
Epoch [48/50] - Loss: 0.4033
Epoch [49/50] - Loss: 0.4051
Epoch [50/50] - Loss: 0.3980
sum preds 36
sum labels 573
 - Test Metrics: Accuracy=0.7812, F1=0.1149, Recall=0.0611, Precision=0.9722
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_two_nnif_two_nnif_1804094449.csv.
Average F1 over valid seeds: 0.0475 ± 0.0490
___________________________________________________________________________________
Avg F1 for cora with SAR and two_nnif, GCNConv,0.3: 0.0475 ± 0.0490
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3912
Epoch [2/50] - Loss: 1.2286
Epoch [3/50] - Loss: 1.0758
Epoch [4/50] - Loss: 0.9260
Epoch [5/50] - Loss: 0.7959
Epoch [6/50] - Loss: 0.7014
Epoch [7/50] - Loss: 0.6253
Epoch [8/50] - Loss: 0.5794
Epoch [9/50] - Loss: 0.5676
Epoch [10/50] - Loss: 0.5241
Epoch [11/50] - Loss: 0.5395
Epoch [12/50] - Loss: 0.5396
Epoch [13/50] - Loss: 0.5006
Epoch [14/50] - Loss: 0.5265
Epoch [15/50] - Loss: 0.4721
Epoch [16/50] - Loss: 0.4865
Epoch [17/50] - Loss: 0.4627
Epoch [18/50] - Loss: 0.4303
Epoch [19/50] - Loss: 0.4326
Epoch [20/50] - Loss: 0.4083
Epoch [21/50] - Loss: 0.3830
Epoch [22/50] - Loss: 0.3738
Epoch [23/50] - Loss: 0.3640
Epoch [24/50] - Loss: 0.3529
Epoch [25/50] - Loss: 0.3420
Epoch [26/50] - Loss: 0.3300
Epoch [27/50] - Loss: 0.3251
Epoch [28/50] - Loss: 0.3134
Epoch [29/50] - Loss: 0.3004
Epoch [30/50] - Loss: 0.2973
Epoch [31/50] - Loss: 0.2737
Epoch [32/50] - Loss: 0.2721
Epoch [33/50] - Loss: 0.2541
Epoch [34/50] - Loss: 0.2577
Epoch [35/50] - Loss: 0.2503
Epoch [36/50] - Loss: 0.2432
Epoch [37/50] - Loss: 0.2380
Epoch [38/50] - Loss: 0.2315
Epoch [39/50] - Loss: 0.2166
Epoch [40/50] - Loss: 0.2223
Epoch [41/50] - Loss: 0.2127
Epoch [42/50] - Loss: 0.2082
Epoch [43/50] - Loss: 0.2027
Epoch [44/50] - Loss: 0.2030
Epoch [45/50] - Loss: 0.1902
Epoch [46/50] - Loss: 0.1860
Epoch [47/50] - Loss: 0.1752
Epoch [48/50] - Loss: 0.1803
Epoch [49/50] - Loss: 0.1724
Epoch [50/50] - Loss: 0.1606
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3142
Epoch [2/50] - Loss: 1.0852
Epoch [3/50] - Loss: 0.8866
Epoch [4/50] - Loss: 0.7122
Epoch [5/50] - Loss: 0.5994
Epoch [6/50] - Loss: 0.5505
Epoch [7/50] - Loss: 0.5255
Epoch [8/50] - Loss: 0.5241
Epoch [9/50] - Loss: 0.5082
Epoch [10/50] - Loss: 0.4935
Epoch [11/50] - Loss: 0.4681
Epoch [12/50] - Loss: 0.4473
Epoch [13/50] - Loss: 0.4294
Epoch [14/50] - Loss: 0.4082
Epoch [15/50] - Loss: 0.3968
Epoch [16/50] - Loss: 0.3525
Epoch [17/50] - Loss: 0.3394
Epoch [18/50] - Loss: 0.3446
Epoch [19/50] - Loss: 0.3145
Epoch [20/50] - Loss: 0.3164
Epoch [21/50] - Loss: 0.3040
Epoch [22/50] - Loss: 0.2830
Epoch [23/50] - Loss: 0.2816
Epoch [24/50] - Loss: 0.2661
Epoch [25/50] - Loss: 0.2606
Epoch [26/50] - Loss: 0.2388
Epoch [27/50] - Loss: 0.2388
Epoch [28/50] - Loss: 0.2327
Epoch [29/50] - Loss: 0.2194
Epoch [30/50] - Loss: 0.2064
Epoch [31/50] - Loss: 0.2098
Epoch [32/50] - Loss: 0.2034
Epoch [33/50] - Loss: 0.2002
Epoch [34/50] - Loss: 0.1826
Epoch [35/50] - Loss: 0.1825
Epoch [36/50] - Loss: 0.1820
Epoch [37/50] - Loss: 0.1683
Epoch [38/50] - Loss: 0.1737
Epoch [39/50] - Loss: 0.1636
Epoch [40/50] - Loss: 0.1702
Epoch [41/50] - Loss: 0.1524
Epoch [42/50] - Loss: 0.1537
Epoch [43/50] - Loss: 0.1509
Epoch [44/50] - Loss: 0.1475
Epoch [45/50] - Loss: 0.1505
Epoch [46/50] - Loss: 0.1494
Epoch [47/50] - Loss: 0.1432
Epoch [48/50] - Loss: 0.1477
Epoch [49/50] - Loss: 0.1342
Epoch [50/50] - Loss: 0.1368
sum preds 1
sum labels 654
 - Test Metrics: Accuracy=0.7433, F1=0.0031, Recall=0.0015, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.5297
Epoch [2/50] - Loss: 1.3479
Epoch [3/50] - Loss: 1.1707
Epoch [4/50] - Loss: 0.9917
Epoch [5/50] - Loss: 0.8306
Epoch [6/50] - Loss: 0.7107
Epoch [7/50] - Loss: 0.6253
Epoch [8/50] - Loss: 0.5652
Epoch [9/50] - Loss: 0.5547
Epoch [10/50] - Loss: 0.5349
Epoch [11/50] - Loss: 0.5574
Epoch [12/50] - Loss: 0.5330
Epoch [13/50] - Loss: 0.5186
Epoch [14/50] - Loss: 0.5048
Epoch [15/50] - Loss: 0.4712
Epoch [16/50] - Loss: 0.4676
Epoch [17/50] - Loss: 0.4395
Epoch [18/50] - Loss: 0.4218
Epoch [19/50] - Loss: 0.4049
Epoch [20/50] - Loss: 0.3843
Epoch [21/50] - Loss: 0.3638
Epoch [22/50] - Loss: 0.3627
Epoch [23/50] - Loss: 0.3404
Epoch [24/50] - Loss: 0.3365
Epoch [25/50] - Loss: 0.3245
Epoch [26/50] - Loss: 0.3092
Epoch [27/50] - Loss: 0.3013
Epoch [28/50] - Loss: 0.2934
Epoch [29/50] - Loss: 0.2847
Epoch [30/50] - Loss: 0.2712
Epoch [31/50] - Loss: 0.2578
Epoch [32/50] - Loss: 0.2461
Epoch [33/50] - Loss: 0.2285
Epoch [34/50] - Loss: 0.2315
Epoch [35/50] - Loss: 0.2183
Epoch [36/50] - Loss: 0.2102
Epoch [37/50] - Loss: 0.2084
Epoch [38/50] - Loss: 0.2010
Epoch [39/50] - Loss: 0.1944
Epoch [40/50] - Loss: 0.1907
Epoch [41/50] - Loss: 0.1834
Epoch [42/50] - Loss: 0.1747
Epoch [43/50] - Loss: 0.1797
Epoch [44/50] - Loss: 0.1694
Epoch [45/50] - Loss: 0.1667
Epoch [46/50] - Loss: 0.1663
Epoch [47/50] - Loss: 0.1629
Epoch [48/50] - Loss: 0.1575
Epoch [49/50] - Loss: 0.1571
Epoch [50/50] - Loss: 0.1507
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_two_nnif_two_nnif_1804094534.csv.
Average F1 over valid seeds: 0.0010 ± 0.0014
___________________________________________________________________________________
Avg F1 for cora with SAR and two_nnif, MLP,0.2: 0.0010 ± 0.0014
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3190
Epoch [2/50] - Loss: 0.9239
Epoch [3/50] - Loss: 0.6652
Epoch [4/50] - Loss: 0.5398
Epoch [5/50] - Loss: 0.5137
Epoch [6/50] - Loss: 0.5078
Epoch [7/50] - Loss: 0.5472
Epoch [8/50] - Loss: 0.4800
Epoch [9/50] - Loss: 0.5098
Epoch [10/50] - Loss: 0.4638
Epoch [11/50] - Loss: 0.4681
Epoch [12/50] - Loss: 0.4204
Epoch [13/50] - Loss: 0.4165
Epoch [14/50] - Loss: 0.4014
Epoch [15/50] - Loss: 0.3810
Epoch [16/50] - Loss: 0.3954
Epoch [17/50] - Loss: 0.3851
Epoch [18/50] - Loss: 0.3876
Epoch [19/50] - Loss: 0.3700
Epoch [20/50] - Loss: 0.3586
Epoch [21/50] - Loss: 0.3483
Epoch [22/50] - Loss: 0.3368
Epoch [23/50] - Loss: 0.3465
Epoch [24/50] - Loss: 0.3319
Epoch [25/50] - Loss: 0.3289
Epoch [26/50] - Loss: 0.3342
Epoch [27/50] - Loss: 0.3214
Epoch [28/50] - Loss: 0.3246
Epoch [29/50] - Loss: 0.3221
Epoch [30/50] - Loss: 0.3101
Epoch [31/50] - Loss: 0.3132
Epoch [32/50] - Loss: 0.3118
Epoch [33/50] - Loss: 0.3122
Epoch [34/50] - Loss: 0.3004
Epoch [35/50] - Loss: 0.3070
Epoch [36/50] - Loss: 0.2917
Epoch [37/50] - Loss: 0.2969
Epoch [38/50] - Loss: 0.2884
Epoch [39/50] - Loss: 0.2904
Epoch [40/50] - Loss: 0.2921
Epoch [41/50] - Loss: 0.2791
Epoch [42/50] - Loss: 0.2959
Epoch [43/50] - Loss: 0.2748
Epoch [44/50] - Loss: 0.2753
Epoch [45/50] - Loss: 0.2819
Epoch [46/50] - Loss: 0.2827
Epoch [47/50] - Loss: 0.2682
Epoch [48/50] - Loss: 0.2677
Epoch [49/50] - Loss: 0.2677
Epoch [50/50] - Loss: 0.2633
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2347
Epoch [2/50] - Loss: 0.8230
Epoch [3/50] - Loss: 0.5791
Epoch [4/50] - Loss: 0.4964
Epoch [5/50] - Loss: 0.4899
Epoch [6/50] - Loss: 0.5021
Epoch [7/50] - Loss: 0.5168
Epoch [8/50] - Loss: 0.5144
Epoch [9/50] - Loss: 0.4771
Epoch [10/50] - Loss: 0.4623
Epoch [11/50] - Loss: 0.4152
Epoch [12/50] - Loss: 0.4031
Epoch [13/50] - Loss: 0.3751
Epoch [14/50] - Loss: 0.3733
Epoch [15/50] - Loss: 0.3802
Epoch [16/50] - Loss: 0.3674
Epoch [17/50] - Loss: 0.3770
Epoch [18/50] - Loss: 0.3607
Epoch [19/50] - Loss: 0.3518
Epoch [20/50] - Loss: 0.3390
Epoch [21/50] - Loss: 0.3389
Epoch [22/50] - Loss: 0.3297
Epoch [23/50] - Loss: 0.3276
Epoch [24/50] - Loss: 0.3252
Epoch [25/50] - Loss: 0.3148
Epoch [26/50] - Loss: 0.3049
Epoch [27/50] - Loss: 0.3058
Epoch [28/50] - Loss: 0.2982
Epoch [29/50] - Loss: 0.2988
Epoch [30/50] - Loss: 0.3073
Epoch [31/50] - Loss: 0.2840
Epoch [32/50] - Loss: 0.2820
Epoch [33/50] - Loss: 0.2749
Epoch [34/50] - Loss: 0.2840
Epoch [35/50] - Loss: 0.2779
Epoch [36/50] - Loss: 0.2752
Epoch [37/50] - Loss: 0.2780
Epoch [38/50] - Loss: 0.2700
Epoch [39/50] - Loss: 0.2620
Epoch [40/50] - Loss: 0.2716
Epoch [41/50] - Loss: 0.2647
Epoch [42/50] - Loss: 0.2609
Epoch [43/50] - Loss: 0.2765
Epoch [44/50] - Loss: 0.2528
Epoch [45/50] - Loss: 0.2527
Epoch [46/50] - Loss: 0.2600
Epoch [47/50] - Loss: 0.2499
Epoch [48/50] - Loss: 0.2356
Epoch [49/50] - Loss: 0.2543
Epoch [50/50] - Loss: 0.2555
sum preds 4
sum labels 654
 - Test Metrics: Accuracy=0.7437, F1=0.0091, Recall=0.0046, Precision=0.7500
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2001
Epoch [2/50] - Loss: 0.7551
Epoch [3/50] - Loss: 0.5540
Epoch [4/50] - Loss: 0.4795
Epoch [5/50] - Loss: 0.5106
Epoch [6/50] - Loss: 0.5192
Epoch [7/50] - Loss: 0.4943
Epoch [8/50] - Loss: 0.5005
Epoch [9/50] - Loss: 0.4680
Epoch [10/50] - Loss: 0.4278
Epoch [11/50] - Loss: 0.4017
Epoch [12/50] - Loss: 0.3806
Epoch [13/50] - Loss: 0.3696
Epoch [14/50] - Loss: 0.3731
Epoch [15/50] - Loss: 0.3700
Epoch [16/50] - Loss: 0.3549
Epoch [17/50] - Loss: 0.3527
Epoch [18/50] - Loss: 0.3493
Epoch [19/50] - Loss: 0.3489
Epoch [20/50] - Loss: 0.3240
Epoch [21/50] - Loss: 0.3210
Epoch [22/50] - Loss: 0.3165
Epoch [23/50] - Loss: 0.3328
Epoch [24/50] - Loss: 0.3171
Epoch [25/50] - Loss: 0.2969
Epoch [26/50] - Loss: 0.3192
Epoch [27/50] - Loss: 0.2917
Epoch [28/50] - Loss: 0.2927
Epoch [29/50] - Loss: 0.2938
Epoch [30/50] - Loss: 0.3093
Epoch [31/50] - Loss: 0.2936
Epoch [32/50] - Loss: 0.2855
Epoch [33/50] - Loss: 0.2923
Epoch [34/50] - Loss: 0.2802
Epoch [35/50] - Loss: 0.2796
Epoch [36/50] - Loss: 0.2835
Epoch [37/50] - Loss: 0.2804
Epoch [38/50] - Loss: 0.2813
Epoch [39/50] - Loss: 0.2711
Epoch [40/50] - Loss: 0.2693
Epoch [41/50] - Loss: 0.2706
Epoch [42/50] - Loss: 0.2632
Epoch [43/50] - Loss: 0.2628
Epoch [44/50] - Loss: 0.2587
Epoch [45/50] - Loss: 0.2565
Epoch [46/50] - Loss: 0.2597
Epoch [47/50] - Loss: 0.2589
Epoch [48/50] - Loss: 0.2632
Epoch [49/50] - Loss: 0.2537
Epoch [50/50] - Loss: 0.2399
sum preds 11
sum labels 654
 - Test Metrics: Accuracy=0.7472, F1=0.0331, Recall=0.0168, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_two_nnif_two_nnif_1804094612.csv.
Average F1 over valid seeds: 0.0141 ± 0.0140
___________________________________________________________________________________
Avg F1 for cora with SAR and two_nnif, GATConv,0.2: 0.0141 ± 0.0140
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.2551
Epoch [2/50] - Loss: 0.8968
Epoch [3/50] - Loss: 0.6790
Epoch [4/50] - Loss: 0.5592
Epoch [5/50] - Loss: 0.5466
Epoch [6/50] - Loss: 0.5296
Epoch [7/50] - Loss: 0.5513
Epoch [8/50] - Loss: 0.5617
Epoch [9/50] - Loss: 0.5477
Epoch [10/50] - Loss: 0.5145
Epoch [11/50] - Loss: 0.4868
Epoch [12/50] - Loss: 0.4814
Epoch [13/50] - Loss: 0.4368
Epoch [14/50] - Loss: 0.4376
Epoch [15/50] - Loss: 0.4347
Epoch [16/50] - Loss: 0.4259
Epoch [17/50] - Loss: 0.4315
Epoch [18/50] - Loss: 0.4150
Epoch [19/50] - Loss: 0.4126
Epoch [20/50] - Loss: 0.4163
Epoch [21/50] - Loss: 0.4000
Epoch [22/50] - Loss: 0.3774
Epoch [23/50] - Loss: 0.3797
Epoch [24/50] - Loss: 0.3804
Epoch [25/50] - Loss: 0.3665
Epoch [26/50] - Loss: 0.3766
Epoch [27/50] - Loss: 0.3565
Epoch [28/50] - Loss: 0.3539
Epoch [29/50] - Loss: 0.3526
Epoch [30/50] - Loss: 0.3551
Epoch [31/50] - Loss: 0.3362
Epoch [32/50] - Loss: 0.3422
Epoch [33/50] - Loss: 0.3394
Epoch [34/50] - Loss: 0.3392
Epoch [35/50] - Loss: 0.3392
Epoch [36/50] - Loss: 0.3275
Epoch [37/50] - Loss: 0.3333
Epoch [38/50] - Loss: 0.3256
Epoch [39/50] - Loss: 0.3172
Epoch [40/50] - Loss: 0.3092
Epoch [41/50] - Loss: 0.3115
Epoch [42/50] - Loss: 0.3046
Epoch [43/50] - Loss: 0.3233
Epoch [44/50] - Loss: 0.3010
Epoch [45/50] - Loss: 0.3037
Epoch [46/50] - Loss: 0.3093
Epoch [47/50] - Loss: 0.2999
Epoch [48/50] - Loss: 0.3014
Epoch [49/50] - Loss: 0.2983
Epoch [50/50] - Loss: 0.2953
sum preds 0
sum labels 654
 - Test Metrics: Accuracy=0.7429, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.3166
Epoch [2/50] - Loss: 1.0345
Epoch [3/50] - Loss: 0.8026
Epoch [4/50] - Loss: 0.6599
Epoch [5/50] - Loss: 0.5643
Epoch [6/50] - Loss: 0.5420
Epoch [7/50] - Loss: 0.5302
Epoch [8/50] - Loss: 0.5073
Epoch [9/50] - Loss: 0.5086
Epoch [10/50] - Loss: 0.5054
Epoch [11/50] - Loss: 0.5058
Epoch [12/50] - Loss: 0.4899
Epoch [13/50] - Loss: 0.4523
Epoch [14/50] - Loss: 0.4495
Epoch [15/50] - Loss: 0.4210
Epoch [16/50] - Loss: 0.3975
Epoch [17/50] - Loss: 0.3966
Epoch [18/50] - Loss: 0.3860
Epoch [19/50] - Loss: 0.3825
Epoch [20/50] - Loss: 0.3819
Epoch [21/50] - Loss: 0.3508
Epoch [22/50] - Loss: 0.3639
Epoch [23/50] - Loss: 0.3433
Epoch [24/50] - Loss: 0.3479
Epoch [25/50] - Loss: 0.3394
Epoch [26/50] - Loss: 0.3311
Epoch [27/50] - Loss: 0.3165
Epoch [28/50] - Loss: 0.3343
Epoch [29/50] - Loss: 0.3203
Epoch [30/50] - Loss: 0.3248
Epoch [31/50] - Loss: 0.3020
Epoch [32/50] - Loss: 0.3007
Epoch [33/50] - Loss: 0.2891
Epoch [34/50] - Loss: 0.3020
Epoch [35/50] - Loss: 0.3010
Epoch [36/50] - Loss: 0.2962
Epoch [37/50] - Loss: 0.2880
Epoch [38/50] - Loss: 0.2932
Epoch [39/50] - Loss: 0.2969
Epoch [40/50] - Loss: 0.2938
Epoch [41/50] - Loss: 0.2795
Epoch [42/50] - Loss: 0.2787
Epoch [43/50] - Loss: 0.2706
Epoch [44/50] - Loss: 0.2775
Epoch [45/50] - Loss: 0.2787
Epoch [46/50] - Loss: 0.2649
Epoch [47/50] - Loss: 0.2748
Epoch [48/50] - Loss: 0.2767
Epoch [49/50] - Loss: 0.2759
Epoch [50/50] - Loss: 0.2722
sum preds 1
sum labels 654
 - Test Metrics: Accuracy=0.7433, F1=0.0031, Recall=0.0015, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4587
Epoch [2/50] - Loss: 1.2053
Epoch [3/50] - Loss: 1.0458
Epoch [4/50] - Loss: 0.9046
Epoch [5/50] - Loss: 0.7824
Epoch [6/50] - Loss: 0.6803
Epoch [7/50] - Loss: 0.6122
Epoch [8/50] - Loss: 0.5713
Epoch [9/50] - Loss: 0.5290
Epoch [10/50] - Loss: 0.5260
Epoch [11/50] - Loss: 0.5301
Epoch [12/50] - Loss: 0.5420
Epoch [13/50] - Loss: 0.5310
Epoch [14/50] - Loss: 0.5227
Epoch [15/50] - Loss: 0.5046
Epoch [16/50] - Loss: 0.4986
Epoch [17/50] - Loss: 0.4809
Epoch [18/50] - Loss: 0.4617
Epoch [19/50] - Loss: 0.4847
Epoch [20/50] - Loss: 0.4525
Epoch [21/50] - Loss: 0.4306
Epoch [22/50] - Loss: 0.4410
Epoch [23/50] - Loss: 0.4317
Epoch [24/50] - Loss: 0.4345
Epoch [25/50] - Loss: 0.4229
Epoch [26/50] - Loss: 0.4174
Epoch [27/50] - Loss: 0.4282
Epoch [28/50] - Loss: 0.4162
Epoch [29/50] - Loss: 0.3968
Epoch [30/50] - Loss: 0.4000
Epoch [31/50] - Loss: 0.3959
Epoch [32/50] - Loss: 0.3935
Epoch [33/50] - Loss: 0.3911
Epoch [34/50] - Loss: 0.3737
Epoch [35/50] - Loss: 0.3655
Epoch [36/50] - Loss: 0.3765
Epoch [37/50] - Loss: 0.3810
Epoch [38/50] - Loss: 0.3664
Epoch [39/50] - Loss: 0.3705
Epoch [40/50] - Loss: 0.3642
Epoch [41/50] - Loss: 0.3511
Epoch [42/50] - Loss: 0.3393
Epoch [43/50] - Loss: 0.3411
Epoch [44/50] - Loss: 0.3388
Epoch [45/50] - Loss: 0.3366
Epoch [46/50] - Loss: 0.3391
Epoch [47/50] - Loss: 0.3435
Epoch [48/50] - Loss: 0.3362
Epoch [49/50] - Loss: 0.3467
Epoch [50/50] - Loss: 0.3220
sum preds 7
sum labels 654
 - Test Metrics: Accuracy=0.7457, F1=0.0212, Recall=0.0107, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_two_nnif_two_nnif_1804094658.csv.
Average F1 over valid seeds: 0.0081 ± 0.0093
___________________________________________________________________________________
Avg F1 for cora with SAR and two_nnif, GCNConv,0.2: 0.0081 ± 0.0093
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6947
Epoch [2/50] - Loss: 0.6764
Epoch [3/50] - Loss: 0.6554
Epoch [4/50] - Loss: 0.6298
Epoch [5/50] - Loss: 0.6020
Epoch [6/50] - Loss: 0.5728
Epoch [7/50] - Loss: 0.5426
Epoch [8/50] - Loss: 0.5116
Epoch [9/50] - Loss: 0.4803
Epoch [10/50] - Loss: 0.4494
Epoch [11/50] - Loss: 0.4192
Epoch [12/50] - Loss: 0.3901
Epoch [13/50] - Loss: 0.3622
Epoch [14/50] - Loss: 0.3357
Epoch [15/50] - Loss: 0.3106
Epoch [16/50] - Loss: 0.2871
Epoch [17/50] - Loss: 0.2651
Epoch [18/50] - Loss: 0.2445
Epoch [19/50] - Loss: 0.2254
Epoch [20/50] - Loss: 0.2075
Epoch [21/50] - Loss: 0.1910
Epoch [22/50] - Loss: 0.1756
Epoch [23/50] - Loss: 0.1613
Epoch [24/50] - Loss: 0.1480
Epoch [25/50] - Loss: 0.1357
Epoch [26/50] - Loss: 0.1244
Epoch [27/50] - Loss: 0.1140
Epoch [28/50] - Loss: 0.1044
Epoch [29/50] - Loss: 0.0956
Epoch [30/50] - Loss: 0.0876
Epoch [31/50] - Loss: 0.0802
Epoch [32/50] - Loss: 0.0736
Epoch [33/50] - Loss: 0.0676
Epoch [34/50] - Loss: 0.0621
Epoch [35/50] - Loss: 0.0572
Epoch [36/50] - Loss: 0.0527
Epoch [37/50] - Loss: 0.0487
Epoch [38/50] - Loss: 0.0450
Epoch [39/50] - Loss: 0.0417
Epoch [40/50] - Loss: 0.0387
Epoch [41/50] - Loss: 0.0360
Epoch [42/50] - Loss: 0.0335
Epoch [43/50] - Loss: 0.0312
Epoch [44/50] - Loss: 0.0292
Epoch [45/50] - Loss: 0.0273
Epoch [46/50] - Loss: 0.0256
Epoch [47/50] - Loss: 0.0240
Epoch [48/50] - Loss: 0.0226
Epoch [49/50] - Loss: 0.0212
Epoch [50/50] - Loss: 0.0200
sum preds 694
sum labels 491
 - Test Metrics: Accuracy=0.7551, F1=0.5080, Recall=0.6130, Precision=0.4337
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7048
Epoch [2/50] - Loss: 0.6825
Epoch [3/50] - Loss: 0.6601
Epoch [4/50] - Loss: 0.6335
Epoch [5/50] - Loss: 0.6040
Epoch [6/50] - Loss: 0.5729
Epoch [7/50] - Loss: 0.5410
Epoch [8/50] - Loss: 0.5091
Epoch [9/50] - Loss: 0.4773
Epoch [10/50] - Loss: 0.4461
Epoch [11/50] - Loss: 0.4157
Epoch [12/50] - Loss: 0.3865
Epoch [13/50] - Loss: 0.3588
Epoch [14/50] - Loss: 0.3326
Epoch [15/50] - Loss: 0.3082
Epoch [16/50] - Loss: 0.2854
Epoch [17/50] - Loss: 0.2641
Epoch [18/50] - Loss: 0.2444
Epoch [19/50] - Loss: 0.2260
Epoch [20/50] - Loss: 0.2088
Epoch [21/50] - Loss: 0.1929
Epoch [22/50] - Loss: 0.1780
Epoch [23/50] - Loss: 0.1642
Epoch [24/50] - Loss: 0.1514
Epoch [25/50] - Loss: 0.1396
Epoch [26/50] - Loss: 0.1287
Epoch [27/50] - Loss: 0.1186
Epoch [28/50] - Loss: 0.1094
Epoch [29/50] - Loss: 0.1011
Epoch [30/50] - Loss: 0.0935
Epoch [31/50] - Loss: 0.0866
Epoch [32/50] - Loss: 0.0803
Epoch [33/50] - Loss: 0.0745
Epoch [34/50] - Loss: 0.0693
Epoch [35/50] - Loss: 0.0646
Epoch [36/50] - Loss: 0.0603
Epoch [37/50] - Loss: 0.0563
Epoch [38/50] - Loss: 0.0528
Epoch [39/50] - Loss: 0.0495
Epoch [40/50] - Loss: 0.0465
Epoch [41/50] - Loss: 0.0438
Epoch [42/50] - Loss: 0.0412
Epoch [43/50] - Loss: 0.0389
Epoch [44/50] - Loss: 0.0367
Epoch [45/50] - Loss: 0.0347
Epoch [46/50] - Loss: 0.0329
Epoch [47/50] - Loss: 0.0312
Epoch [48/50] - Loss: 0.0296
Epoch [49/50] - Loss: 0.0281
Epoch [50/50] - Loss: 0.0267
sum preds 583
sum labels 491
 - Test Metrics: Accuracy=0.7749, F1=0.5009, Recall=0.5479, Precision=0.4614
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6979
Epoch [2/50] - Loss: 0.6785
Epoch [3/50] - Loss: 0.6573
Epoch [4/50] - Loss: 0.6325
Epoch [5/50] - Loss: 0.6053
Epoch [6/50] - Loss: 0.5765
Epoch [7/50] - Loss: 0.5467
Epoch [8/50] - Loss: 0.5161
Epoch [9/50] - Loss: 0.4849
Epoch [10/50] - Loss: 0.4538
Epoch [11/50] - Loss: 0.4232
Epoch [12/50] - Loss: 0.3935
Epoch [13/50] - Loss: 0.3651
Epoch [14/50] - Loss: 0.3381
Epoch [15/50] - Loss: 0.3126
Epoch [16/50] - Loss: 0.2887
Epoch [17/50] - Loss: 0.2665
Epoch [18/50] - Loss: 0.2457
Epoch [19/50] - Loss: 0.2264
Epoch [20/50] - Loss: 0.2085
Epoch [21/50] - Loss: 0.1918
Epoch [22/50] - Loss: 0.1763
Epoch [23/50] - Loss: 0.1619
Epoch [24/50] - Loss: 0.1486
Epoch [25/50] - Loss: 0.1363
Epoch [26/50] - Loss: 0.1249
Epoch [27/50] - Loss: 0.1143
Epoch [28/50] - Loss: 0.1046
Epoch [29/50] - Loss: 0.0957
Epoch [30/50] - Loss: 0.0876
Epoch [31/50] - Loss: 0.0802
Epoch [32/50] - Loss: 0.0735
Epoch [33/50] - Loss: 0.0674
Epoch [34/50] - Loss: 0.0619
Epoch [35/50] - Loss: 0.0569
Epoch [36/50] - Loss: 0.0524
Epoch [37/50] - Loss: 0.0483
Epoch [38/50] - Loss: 0.0447
Epoch [39/50] - Loss: 0.0414
Epoch [40/50] - Loss: 0.0385
Epoch [41/50] - Loss: 0.0358
Epoch [42/50] - Loss: 0.0334
Epoch [43/50] - Loss: 0.0312
Epoch [44/50] - Loss: 0.0292
Epoch [45/50] - Loss: 0.0274
Epoch [46/50] - Loss: 0.0258
Epoch [47/50] - Loss: 0.0243
Epoch [48/50] - Loss: 0.0229
Epoch [49/50] - Loss: 0.0217
Epoch [50/50] - Loss: 0.0205
sum preds 630
sum labels 491
 - Test Metrics: Accuracy=0.7887, F1=0.5513, Recall=0.6293, Precision=0.4905
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_spy_spy_1804094740.csv.
Average F1 over valid seeds: 0.5201 ± 0.0223
___________________________________________________________________________________
Avg F1 for cora with SAR and spy, MLP,0.4: 0.5201 ± 0.0223
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6925
Epoch [2/50] - Loss: 0.6556
Epoch [3/50] - Loss: 0.6212
Epoch [4/50] - Loss: 0.5840
Epoch [5/50] - Loss: 0.5449
Epoch [6/50] - Loss: 0.5064
Epoch [7/50] - Loss: 0.4717
Epoch [8/50] - Loss: 0.4419
Epoch [9/50] - Loss: 0.4155
Epoch [10/50] - Loss: 0.3914
Epoch [11/50] - Loss: 0.3694
Epoch [12/50] - Loss: 0.3498
Epoch [13/50] - Loss: 0.3326
Epoch [14/50] - Loss: 0.3171
Epoch [15/50] - Loss: 0.3027
Epoch [16/50] - Loss: 0.2891
Epoch [17/50] - Loss: 0.2759
Epoch [18/50] - Loss: 0.2632
Epoch [19/50] - Loss: 0.2506
Epoch [20/50] - Loss: 0.2384
Epoch [21/50] - Loss: 0.2268
Epoch [22/50] - Loss: 0.2159
Epoch [23/50] - Loss: 0.2054
Epoch [24/50] - Loss: 0.1950
Epoch [25/50] - Loss: 0.1847
Epoch [26/50] - Loss: 0.1755
Epoch [27/50] - Loss: 0.1677
Epoch [28/50] - Loss: 0.1607
Epoch [29/50] - Loss: 0.1541
Epoch [30/50] - Loss: 0.1478
Epoch [31/50] - Loss: 0.1415
Epoch [32/50] - Loss: 0.1354
Epoch [33/50] - Loss: 0.1300
Epoch [34/50] - Loss: 0.1255
Epoch [35/50] - Loss: 0.1216
Epoch [36/50] - Loss: 0.1179
Epoch [37/50] - Loss: 0.1139
Epoch [38/50] - Loss: 0.1102
Epoch [39/50] - Loss: 0.1071
Epoch [40/50] - Loss: 0.1042
Epoch [41/50] - Loss: 0.1015
Epoch [42/50] - Loss: 0.0988
Epoch [43/50] - Loss: 0.0961
Epoch [44/50] - Loss: 0.0937
Epoch [45/50] - Loss: 0.0913
Epoch [46/50] - Loss: 0.0891
Epoch [47/50] - Loss: 0.0870
Epoch [48/50] - Loss: 0.0853
Epoch [49/50] - Loss: 0.0838
Epoch [50/50] - Loss: 0.0821
sum preds 453
sum labels 491
 - Test Metrics: Accuracy=0.8883, F1=0.7182, Recall=0.6904, Precision=0.7483
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6883
Epoch [2/50] - Loss: 0.6538
Epoch [3/50] - Loss: 0.6189
Epoch [4/50] - Loss: 0.5799
Epoch [5/50] - Loss: 0.5403
Epoch [6/50] - Loss: 0.5032
Epoch [7/50] - Loss: 0.4689
Epoch [8/50] - Loss: 0.4370
Epoch [9/50] - Loss: 0.4076
Epoch [10/50] - Loss: 0.3813
Epoch [11/50] - Loss: 0.3579
Epoch [12/50] - Loss: 0.3370
Epoch [13/50] - Loss: 0.3177
Epoch [14/50] - Loss: 0.2994
Epoch [15/50] - Loss: 0.2821
Epoch [16/50] - Loss: 0.2662
Epoch [17/50] - Loss: 0.2515
Epoch [18/50] - Loss: 0.2380
Epoch [19/50] - Loss: 0.2254
Epoch [20/50] - Loss: 0.2133
Epoch [21/50] - Loss: 0.2018
Epoch [22/50] - Loss: 0.1907
Epoch [23/50] - Loss: 0.1803
Epoch [24/50] - Loss: 0.1709
Epoch [25/50] - Loss: 0.1631
Epoch [26/50] - Loss: 0.1563
Epoch [27/50] - Loss: 0.1502
Epoch [28/50] - Loss: 0.1441
Epoch [29/50] - Loss: 0.1382
Epoch [30/50] - Loss: 0.1325
Epoch [31/50] - Loss: 0.1274
Epoch [32/50] - Loss: 0.1229
Epoch [33/50] - Loss: 0.1187
Epoch [34/50] - Loss: 0.1146
Epoch [35/50] - Loss: 0.1105
Epoch [36/50] - Loss: 0.1068
Epoch [37/50] - Loss: 0.1040
Epoch [38/50] - Loss: 0.1019
Epoch [39/50] - Loss: 0.0998
Epoch [40/50] - Loss: 0.0978
Epoch [41/50] - Loss: 0.0958
Epoch [42/50] - Loss: 0.0940
Epoch [43/50] - Loss: 0.0925
Epoch [44/50] - Loss: 0.0911
Epoch [45/50] - Loss: 0.0896
Epoch [46/50] - Loss: 0.0882
Epoch [47/50] - Loss: 0.0872
Epoch [48/50] - Loss: 0.0861
Epoch [49/50] - Loss: 0.0849
Epoch [50/50] - Loss: 0.0838
sum preds 442
sum labels 491
 - Test Metrics: Accuracy=0.8778, F1=0.6881, Recall=0.6538, Precision=0.7262
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6794
Epoch [2/50] - Loss: 0.6230
Epoch [3/50] - Loss: 0.5668
Epoch [4/50] - Loss: 0.5135
Epoch [5/50] - Loss: 0.4649
Epoch [6/50] - Loss: 0.4219
Epoch [7/50] - Loss: 0.3850
Epoch [8/50] - Loss: 0.3545
Epoch [9/50] - Loss: 0.3298
Epoch [10/50] - Loss: 0.3099
Epoch [11/50] - Loss: 0.2937
Epoch [12/50] - Loss: 0.2802
Epoch [13/50] - Loss: 0.2683
Epoch [14/50] - Loss: 0.2573
Epoch [15/50] - Loss: 0.2470
Epoch [16/50] - Loss: 0.2374
Epoch [17/50] - Loss: 0.2282
Epoch [18/50] - Loss: 0.2192
Epoch [19/50] - Loss: 0.2102
Epoch [20/50] - Loss: 0.2015
Epoch [21/50] - Loss: 0.1932
Epoch [22/50] - Loss: 0.1858
Epoch [23/50] - Loss: 0.1790
Epoch [24/50] - Loss: 0.1725
Epoch [25/50] - Loss: 0.1665
Epoch [26/50] - Loss: 0.1609
Epoch [27/50] - Loss: 0.1558
Epoch [28/50] - Loss: 0.1509
Epoch [29/50] - Loss: 0.1461
Epoch [30/50] - Loss: 0.1414
Epoch [31/50] - Loss: 0.1368
Epoch [32/50] - Loss: 0.1323
Epoch [33/50] - Loss: 0.1279
Epoch [34/50] - Loss: 0.1235
Epoch [35/50] - Loss: 0.1194
Epoch [36/50] - Loss: 0.1158
Epoch [37/50] - Loss: 0.1124
Epoch [38/50] - Loss: 0.1088
Epoch [39/50] - Loss: 0.1053
Epoch [40/50] - Loss: 0.1021
Epoch [41/50] - Loss: 0.0993
Epoch [42/50] - Loss: 0.0967
Epoch [43/50] - Loss: 0.0944
Epoch [44/50] - Loss: 0.0922
Epoch [45/50] - Loss: 0.0903
Epoch [46/50] - Loss: 0.0878
Epoch [47/50] - Loss: 0.0855
Epoch [48/50] - Loss: 0.0834
Epoch [49/50] - Loss: 0.0812
Epoch [50/50] - Loss: 0.0790
sum preds 475
sum labels 491
 - Test Metrics: Accuracy=0.8782, F1=0.6998, Recall=0.6884, Precision=0.7116
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_spy_spy_1804094758.csv.
Average F1 over valid seeds: 0.7020 ± 0.0124
___________________________________________________________________________________
Avg F1 for cora with SAR and spy, GATConv,0.4: 0.7020 ± 0.0124
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6884
Epoch [2/50] - Loss: 0.6551
Epoch [3/50] - Loss: 0.6223
Epoch [4/50] - Loss: 0.5869
Epoch [5/50] - Loss: 0.5494
Epoch [6/50] - Loss: 0.5129
Epoch [7/50] - Loss: 0.4798
Epoch [8/50] - Loss: 0.4508
Epoch [9/50] - Loss: 0.4252
Epoch [10/50] - Loss: 0.4024
Epoch [11/50] - Loss: 0.3823
Epoch [12/50] - Loss: 0.3651
Epoch [13/50] - Loss: 0.3501
Epoch [14/50] - Loss: 0.3366
Epoch [15/50] - Loss: 0.3242
Epoch [16/50] - Loss: 0.3129
Epoch [17/50] - Loss: 0.3025
Epoch [18/50] - Loss: 0.2930
Epoch [19/50] - Loss: 0.2839
Epoch [20/50] - Loss: 0.2752
Epoch [21/50] - Loss: 0.2670
Epoch [22/50] - Loss: 0.2593
Epoch [23/50] - Loss: 0.2521
Epoch [24/50] - Loss: 0.2454
Epoch [25/50] - Loss: 0.2390
Epoch [26/50] - Loss: 0.2330
Epoch [27/50] - Loss: 0.2275
Epoch [28/50] - Loss: 0.2223
Epoch [29/50] - Loss: 0.2174
Epoch [30/50] - Loss: 0.2127
Epoch [31/50] - Loss: 0.2082
Epoch [32/50] - Loss: 0.2038
Epoch [33/50] - Loss: 0.1996
Epoch [34/50] - Loss: 0.1954
Epoch [35/50] - Loss: 0.1913
Epoch [36/50] - Loss: 0.1874
Epoch [37/50] - Loss: 0.1837
Epoch [38/50] - Loss: 0.1801
Epoch [39/50] - Loss: 0.1766
Epoch [40/50] - Loss: 0.1732
Epoch [41/50] - Loss: 0.1699
Epoch [42/50] - Loss: 0.1667
Epoch [43/50] - Loss: 0.1636
Epoch [44/50] - Loss: 0.1605
Epoch [45/50] - Loss: 0.1576
Epoch [46/50] - Loss: 0.1547
Epoch [47/50] - Loss: 0.1519
Epoch [48/50] - Loss: 0.1493
Epoch [49/50] - Loss: 0.1467
Epoch [50/50] - Loss: 0.1441
sum preds 467
sum labels 491
 - Test Metrics: Accuracy=0.8900, F1=0.7265, Recall=0.7088, Precision=0.7452
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7073
Epoch [2/50] - Loss: 0.6762
Epoch [3/50] - Loss: 0.6501
Epoch [4/50] - Loss: 0.6237
Epoch [5/50] - Loss: 0.5941
Epoch [6/50] - Loss: 0.5618
Epoch [7/50] - Loss: 0.5287
Epoch [8/50] - Loss: 0.4976
Epoch [9/50] - Loss: 0.4695
Epoch [10/50] - Loss: 0.4441
Epoch [11/50] - Loss: 0.4203
Epoch [12/50] - Loss: 0.3984
Epoch [13/50] - Loss: 0.3786
Epoch [14/50] - Loss: 0.3613
Epoch [15/50] - Loss: 0.3463
Epoch [16/50] - Loss: 0.3332
Epoch [17/50] - Loss: 0.3214
Epoch [18/50] - Loss: 0.3106
Epoch [19/50] - Loss: 0.3005
Epoch [20/50] - Loss: 0.2912
Epoch [21/50] - Loss: 0.2824
Epoch [22/50] - Loss: 0.2742
Epoch [23/50] - Loss: 0.2662
Epoch [24/50] - Loss: 0.2585
Epoch [25/50] - Loss: 0.2510
Epoch [26/50] - Loss: 0.2438
Epoch [27/50] - Loss: 0.2369
Epoch [28/50] - Loss: 0.2303
Epoch [29/50] - Loss: 0.2240
Epoch [30/50] - Loss: 0.2179
Epoch [31/50] - Loss: 0.2121
Epoch [32/50] - Loss: 0.2065
Epoch [33/50] - Loss: 0.2012
Epoch [34/50] - Loss: 0.1961
Epoch [35/50] - Loss: 0.1911
Epoch [36/50] - Loss: 0.1863
Epoch [37/50] - Loss: 0.1815
Epoch [38/50] - Loss: 0.1769
Epoch [39/50] - Loss: 0.1725
Epoch [40/50] - Loss: 0.1682
Epoch [41/50] - Loss: 0.1641
Epoch [42/50] - Loss: 0.1601
Epoch [43/50] - Loss: 0.1563
Epoch [44/50] - Loss: 0.1527
Epoch [45/50] - Loss: 0.1492
Epoch [46/50] - Loss: 0.1458
Epoch [47/50] - Loss: 0.1425
Epoch [48/50] - Loss: 0.1394
Epoch [49/50] - Loss: 0.1364
Epoch [50/50] - Loss: 0.1334
sum preds 398
sum labels 491
 - Test Metrics: Accuracy=0.8929, F1=0.7132, Recall=0.6456, Precision=0.7965
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6885
Epoch [2/50] - Loss: 0.6437
Epoch [3/50] - Loss: 0.5958
Epoch [4/50] - Loss: 0.5473
Epoch [5/50] - Loss: 0.5029
Epoch [6/50] - Loss: 0.4642
Epoch [7/50] - Loss: 0.4307
Epoch [8/50] - Loss: 0.4017
Epoch [9/50] - Loss: 0.3770
Epoch [10/50] - Loss: 0.3560
Epoch [11/50] - Loss: 0.3380
Epoch [12/50] - Loss: 0.3223
Epoch [13/50] - Loss: 0.3084
Epoch [14/50] - Loss: 0.2958
Epoch [15/50] - Loss: 0.2843
Epoch [16/50] - Loss: 0.2737
Epoch [17/50] - Loss: 0.2635
Epoch [18/50] - Loss: 0.2539
Epoch [19/50] - Loss: 0.2446
Epoch [20/50] - Loss: 0.2358
Epoch [21/50] - Loss: 0.2274
Epoch [22/50] - Loss: 0.2194
Epoch [23/50] - Loss: 0.2118
Epoch [24/50] - Loss: 0.2048
Epoch [25/50] - Loss: 0.1983
Epoch [26/50] - Loss: 0.1923
Epoch [27/50] - Loss: 0.1869
Epoch [28/50] - Loss: 0.1818
Epoch [29/50] - Loss: 0.1771
Epoch [30/50] - Loss: 0.1727
Epoch [31/50] - Loss: 0.1685
Epoch [32/50] - Loss: 0.1646
Epoch [33/50] - Loss: 0.1607
Epoch [34/50] - Loss: 0.1569
Epoch [35/50] - Loss: 0.1533
Epoch [36/50] - Loss: 0.1497
Epoch [37/50] - Loss: 0.1463
Epoch [38/50] - Loss: 0.1430
Epoch [39/50] - Loss: 0.1398
Epoch [40/50] - Loss: 0.1368
Epoch [41/50] - Loss: 0.1340
Epoch [42/50] - Loss: 0.1312
Epoch [43/50] - Loss: 0.1285
Epoch [44/50] - Loss: 0.1259
Epoch [45/50] - Loss: 0.1234
Epoch [46/50] - Loss: 0.1209
Epoch [47/50] - Loss: 0.1184
Epoch [48/50] - Loss: 0.1160
Epoch [49/50] - Loss: 0.1137
Epoch [50/50] - Loss: 0.1114
sum preds 460
sum labels 491
 - Test Metrics: Accuracy=0.8996, F1=0.7487, Recall=0.7251, Precision=0.7739
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_spy_spy_1804094818.csv.
Average F1 over valid seeds: 0.7295 ± 0.0147
___________________________________________________________________________________
Avg F1 for cora with SAR and spy, GCNConv,0.4: 0.7295 ± 0.0147
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6994
Epoch [2/50] - Loss: 0.6798
Epoch [3/50] - Loss: 0.6611
Epoch [4/50] - Loss: 0.6384
Epoch [5/50] - Loss: 0.6129
Epoch [6/50] - Loss: 0.5860
Epoch [7/50] - Loss: 0.5582
Epoch [8/50] - Loss: 0.5296
Epoch [9/50] - Loss: 0.5004
Epoch [10/50] - Loss: 0.4708
Epoch [11/50] - Loss: 0.4414
Epoch [12/50] - Loss: 0.4127
Epoch [13/50] - Loss: 0.3850
Epoch [14/50] - Loss: 0.3584
Epoch [15/50] - Loss: 0.3330
Epoch [16/50] - Loss: 0.3089
Epoch [17/50] - Loss: 0.2861
Epoch [18/50] - Loss: 0.2647
Epoch [19/50] - Loss: 0.2445
Epoch [20/50] - Loss: 0.2257
Epoch [21/50] - Loss: 0.2080
Epoch [22/50] - Loss: 0.1915
Epoch [23/50] - Loss: 0.1762
Epoch [24/50] - Loss: 0.1620
Epoch [25/50] - Loss: 0.1490
Epoch [26/50] - Loss: 0.1369
Epoch [27/50] - Loss: 0.1259
Epoch [28/50] - Loss: 0.1159
Epoch [29/50] - Loss: 0.1067
Epoch [30/50] - Loss: 0.0984
Epoch [31/50] - Loss: 0.0908
Epoch [32/50] - Loss: 0.0839
Epoch [33/50] - Loss: 0.0776
Epoch [34/50] - Loss: 0.0720
Epoch [35/50] - Loss: 0.0669
Epoch [36/50] - Loss: 0.0623
Epoch [37/50] - Loss: 0.0580
Epoch [38/50] - Loss: 0.0542
Epoch [39/50] - Loss: 0.0507
Epoch [40/50] - Loss: 0.0476
Epoch [41/50] - Loss: 0.0447
Epoch [42/50] - Loss: 0.0420
Epoch [43/50] - Loss: 0.0396
Epoch [44/50] - Loss: 0.0374
Epoch [45/50] - Loss: 0.0354
Epoch [46/50] - Loss: 0.0335
Epoch [47/50] - Loss: 0.0319
Epoch [48/50] - Loss: 0.0303
Epoch [49/50] - Loss: 0.0289
Epoch [50/50] - Loss: 0.0276
sum preds 507
sum labels 573
 - Test Metrics: Accuracy=0.7824, F1=0.5037, Recall=0.4747, Precision=0.5365
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7210
Epoch [2/50] - Loss: 0.6933
Epoch [3/50] - Loss: 0.6677
Epoch [4/50] - Loss: 0.6398
Epoch [5/50] - Loss: 0.6102
Epoch [6/50] - Loss: 0.5797
Epoch [7/50] - Loss: 0.5488
Epoch [8/50] - Loss: 0.5178
Epoch [9/50] - Loss: 0.4871
Epoch [10/50] - Loss: 0.4568
Epoch [11/50] - Loss: 0.4274
Epoch [12/50] - Loss: 0.3988
Epoch [13/50] - Loss: 0.3714
Epoch [14/50] - Loss: 0.3452
Epoch [15/50] - Loss: 0.3202
Epoch [16/50] - Loss: 0.2965
Epoch [17/50] - Loss: 0.2742
Epoch [18/50] - Loss: 0.2531
Epoch [19/50] - Loss: 0.2334
Epoch [20/50] - Loss: 0.2150
Epoch [21/50] - Loss: 0.1978
Epoch [22/50] - Loss: 0.1817
Epoch [23/50] - Loss: 0.1668
Epoch [24/50] - Loss: 0.1530
Epoch [25/50] - Loss: 0.1401
Epoch [26/50] - Loss: 0.1283
Epoch [27/50] - Loss: 0.1175
Epoch [28/50] - Loss: 0.1076
Epoch [29/50] - Loss: 0.0986
Epoch [30/50] - Loss: 0.0905
Epoch [31/50] - Loss: 0.0831
Epoch [32/50] - Loss: 0.0765
Epoch [33/50] - Loss: 0.0704
Epoch [34/50] - Loss: 0.0650
Epoch [35/50] - Loss: 0.0601
Epoch [36/50] - Loss: 0.0557
Epoch [37/50] - Loss: 0.0517
Epoch [38/50] - Loss: 0.0480
Epoch [39/50] - Loss: 0.0447
Epoch [40/50] - Loss: 0.0417
Epoch [41/50] - Loss: 0.0390
Epoch [42/50] - Loss: 0.0366
Epoch [43/50] - Loss: 0.0343
Epoch [44/50] - Loss: 0.0323
Epoch [45/50] - Loss: 0.0304
Epoch [46/50] - Loss: 0.0287
Epoch [47/50] - Loss: 0.0272
Epoch [48/50] - Loss: 0.0258
Epoch [49/50] - Loss: 0.0245
Epoch [50/50] - Loss: 0.0233
sum preds 493
sum labels 573
 - Test Metrics: Accuracy=0.7840, F1=0.5009, Recall=0.4660, Precision=0.5416
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7074
Epoch [2/50] - Loss: 0.6853
Epoch [3/50] - Loss: 0.6649
Epoch [4/50] - Loss: 0.6419
Epoch [5/50] - Loss: 0.6166
Epoch [6/50] - Loss: 0.5894
Epoch [7/50] - Loss: 0.5611
Epoch [8/50] - Loss: 0.5323
Epoch [9/50] - Loss: 0.5033
Epoch [10/50] - Loss: 0.4743
Epoch [11/50] - Loss: 0.4453
Epoch [12/50] - Loss: 0.4165
Epoch [13/50] - Loss: 0.3884
Epoch [14/50] - Loss: 0.3611
Epoch [15/50] - Loss: 0.3351
Epoch [16/50] - Loss: 0.3102
Epoch [17/50] - Loss: 0.2868
Epoch [18/50] - Loss: 0.2647
Epoch [19/50] - Loss: 0.2440
Epoch [20/50] - Loss: 0.2248
Epoch [21/50] - Loss: 0.2068
Epoch [22/50] - Loss: 0.1901
Epoch [23/50] - Loss: 0.1747
Epoch [24/50] - Loss: 0.1604
Epoch [25/50] - Loss: 0.1472
Epoch [26/50] - Loss: 0.1351
Epoch [27/50] - Loss: 0.1241
Epoch [28/50] - Loss: 0.1140
Epoch [29/50] - Loss: 0.1048
Epoch [30/50] - Loss: 0.0964
Epoch [31/50] - Loss: 0.0889
Epoch [32/50] - Loss: 0.0821
Epoch [33/50] - Loss: 0.0759
Epoch [34/50] - Loss: 0.0704
Epoch [35/50] - Loss: 0.0654
Epoch [36/50] - Loss: 0.0609
Epoch [37/50] - Loss: 0.0569
Epoch [38/50] - Loss: 0.0532
Epoch [39/50] - Loss: 0.0499
Epoch [40/50] - Loss: 0.0469
Epoch [41/50] - Loss: 0.0442
Epoch [42/50] - Loss: 0.0417
Epoch [43/50] - Loss: 0.0394
Epoch [44/50] - Loss: 0.0374
Epoch [45/50] - Loss: 0.0355
Epoch [46/50] - Loss: 0.0337
Epoch [47/50] - Loss: 0.0322
Epoch [48/50] - Loss: 0.0307
Epoch [49/50] - Loss: 0.0293
Epoch [50/50] - Loss: 0.0281
sum preds 536
sum labels 573
 - Test Metrics: Accuracy=0.7820, F1=0.5158, Recall=0.4991, Precision=0.5336
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_spy_spy_1804094838.csv.
Average F1 over valid seeds: 0.5068 ± 0.0064
___________________________________________________________________________________
Avg F1 for cora with SAR and spy, MLP,0.3: 0.5068 ± 0.0064
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6966
Epoch [2/50] - Loss: 0.6546
Epoch [3/50] - Loss: 0.6238
Epoch [4/50] - Loss: 0.5963
Epoch [5/50] - Loss: 0.5687
Epoch [6/50] - Loss: 0.5383
Epoch [7/50] - Loss: 0.5064
Epoch [8/50] - Loss: 0.4762
Epoch [9/50] - Loss: 0.4495
Epoch [10/50] - Loss: 0.4267
Epoch [11/50] - Loss: 0.4057
Epoch [12/50] - Loss: 0.3852
Epoch [13/50] - Loss: 0.3646
Epoch [14/50] - Loss: 0.3448
Epoch [15/50] - Loss: 0.3269
Epoch [16/50] - Loss: 0.3108
Epoch [17/50] - Loss: 0.2950
Epoch [18/50] - Loss: 0.2788
Epoch [19/50] - Loss: 0.2623
Epoch [20/50] - Loss: 0.2466
Epoch [21/50] - Loss: 0.2324
Epoch [22/50] - Loss: 0.2193
Epoch [23/50] - Loss: 0.2062
Epoch [24/50] - Loss: 0.1935
Epoch [25/50] - Loss: 0.1820
Epoch [26/50] - Loss: 0.1720
Epoch [27/50] - Loss: 0.1625
Epoch [28/50] - Loss: 0.1529
Epoch [29/50] - Loss: 0.1438
Epoch [30/50] - Loss: 0.1356
Epoch [31/50] - Loss: 0.1277
Epoch [32/50] - Loss: 0.1196
Epoch [33/50] - Loss: 0.1121
Epoch [34/50] - Loss: 0.1054
Epoch [35/50] - Loss: 0.0998
Epoch [36/50] - Loss: 0.0948
Epoch [37/50] - Loss: 0.0903
Epoch [38/50] - Loss: 0.0861
Epoch [39/50] - Loss: 0.0817
Epoch [40/50] - Loss: 0.0778
Epoch [41/50] - Loss: 0.0745
Epoch [42/50] - Loss: 0.0718
Epoch [43/50] - Loss: 0.0693
Epoch [44/50] - Loss: 0.0670
Epoch [45/50] - Loss: 0.0648
Epoch [46/50] - Loss: 0.0629
Epoch [47/50] - Loss: 0.0612
Epoch [48/50] - Loss: 0.0596
Epoch [49/50] - Loss: 0.0580
Epoch [50/50] - Loss: 0.0566
sum preds 379
sum labels 573
 - Test Metrics: Accuracy=0.8498, F1=0.6113, Recall=0.5079, Precision=0.7678
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6960
Epoch [2/50] - Loss: 0.6569
Epoch [3/50] - Loss: 0.6274
Epoch [4/50] - Loss: 0.5955
Epoch [5/50] - Loss: 0.5599
Epoch [6/50] - Loss: 0.5219
Epoch [7/50] - Loss: 0.4847
Epoch [8/50] - Loss: 0.4512
Epoch [9/50] - Loss: 0.4226
Epoch [10/50] - Loss: 0.3973
Epoch [11/50] - Loss: 0.3733
Epoch [12/50] - Loss: 0.3503
Epoch [13/50] - Loss: 0.3293
Epoch [14/50] - Loss: 0.3106
Epoch [15/50] - Loss: 0.2934
Epoch [16/50] - Loss: 0.2769
Epoch [17/50] - Loss: 0.2607
Epoch [18/50] - Loss: 0.2449
Epoch [19/50] - Loss: 0.2298
Epoch [20/50] - Loss: 0.2157
Epoch [21/50] - Loss: 0.2025
Epoch [22/50] - Loss: 0.1900
Epoch [23/50] - Loss: 0.1784
Epoch [24/50] - Loss: 0.1675
Epoch [25/50] - Loss: 0.1575
Epoch [26/50] - Loss: 0.1485
Epoch [27/50] - Loss: 0.1403
Epoch [28/50] - Loss: 0.1327
Epoch [29/50] - Loss: 0.1257
Epoch [30/50] - Loss: 0.1193
Epoch [31/50] - Loss: 0.1133
Epoch [32/50] - Loss: 0.1079
Epoch [33/50] - Loss: 0.1032
Epoch [34/50] - Loss: 0.0990
Epoch [35/50] - Loss: 0.0954
Epoch [36/50] - Loss: 0.0919
Epoch [37/50] - Loss: 0.0886
Epoch [38/50] - Loss: 0.0852
Epoch [39/50] - Loss: 0.0821
Epoch [40/50] - Loss: 0.0792
Epoch [41/50] - Loss: 0.0768
Epoch [42/50] - Loss: 0.0746
Epoch [43/50] - Loss: 0.0725
Epoch [44/50] - Loss: 0.0706
Epoch [45/50] - Loss: 0.0690
Epoch [46/50] - Loss: 0.0677
Epoch [47/50] - Loss: 0.0666
Epoch [48/50] - Loss: 0.0657
Epoch [49/50] - Loss: 0.0648
Epoch [50/50] - Loss: 0.0639
sum preds 382
sum labels 573
 - Test Metrics: Accuracy=0.8518, F1=0.6178, Recall=0.5148, Precision=0.7723
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6738
Epoch [2/50] - Loss: 0.6159
Epoch [3/50] - Loss: 0.5678
Epoch [4/50] - Loss: 0.5227
Epoch [5/50] - Loss: 0.4788
Epoch [6/50] - Loss: 0.4391
Epoch [7/50] - Loss: 0.4056
Epoch [8/50] - Loss: 0.3778
Epoch [9/50] - Loss: 0.3545
Epoch [10/50] - Loss: 0.3347
Epoch [11/50] - Loss: 0.3179
Epoch [12/50] - Loss: 0.3037
Epoch [13/50] - Loss: 0.2914
Epoch [14/50] - Loss: 0.2802
Epoch [15/50] - Loss: 0.2695
Epoch [16/50] - Loss: 0.2589
Epoch [17/50] - Loss: 0.2483
Epoch [18/50] - Loss: 0.2380
Epoch [19/50] - Loss: 0.2282
Epoch [20/50] - Loss: 0.2192
Epoch [21/50] - Loss: 0.2112
Epoch [22/50] - Loss: 0.2041
Epoch [23/50] - Loss: 0.1976
Epoch [24/50] - Loss: 0.1912
Epoch [25/50] - Loss: 0.1849
Epoch [26/50] - Loss: 0.1786
Epoch [27/50] - Loss: 0.1726
Epoch [28/50] - Loss: 0.1670
Epoch [29/50] - Loss: 0.1617
Epoch [30/50] - Loss: 0.1565
Epoch [31/50] - Loss: 0.1516
Epoch [32/50] - Loss: 0.1468
Epoch [33/50] - Loss: 0.1421
Epoch [34/50] - Loss: 0.1376
Epoch [35/50] - Loss: 0.1334
Epoch [36/50] - Loss: 0.1293
Epoch [37/50] - Loss: 0.1252
Epoch [38/50] - Loss: 0.1213
Epoch [39/50] - Loss: 0.1176
Epoch [40/50] - Loss: 0.1141
Epoch [41/50] - Loss: 0.1106
Epoch [42/50] - Loss: 0.1073
Epoch [43/50] - Loss: 0.1041
Epoch [44/50] - Loss: 0.1010
Epoch [45/50] - Loss: 0.0980
Epoch [46/50] - Loss: 0.0949
Epoch [47/50] - Loss: 0.0920
Epoch [48/50] - Loss: 0.0894
Epoch [49/50] - Loss: 0.0870
Epoch [50/50] - Loss: 0.0845
sum preds 423
sum labels 573
 - Test Metrics: Accuracy=0.8579, F1=0.6486, Recall=0.5637, Precision=0.7636
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_spy_spy_1804094857.csv.
Average F1 over valid seeds: 0.6259 ± 0.0163
___________________________________________________________________________________
Avg F1 for cora with SAR and spy, GATConv,0.3: 0.6259 ± 0.0163
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6871
Epoch [2/50] - Loss: 0.6490
Epoch [3/50] - Loss: 0.6204
Epoch [4/50] - Loss: 0.5952
Epoch [5/50] - Loss: 0.5691
Epoch [6/50] - Loss: 0.5403
Epoch [7/50] - Loss: 0.5101
Epoch [8/50] - Loss: 0.4815
Epoch [9/50] - Loss: 0.4571
Epoch [10/50] - Loss: 0.4367
Epoch [11/50] - Loss: 0.4180
Epoch [12/50] - Loss: 0.3992
Epoch [13/50] - Loss: 0.3809
Epoch [14/50] - Loss: 0.3648
Epoch [15/50] - Loss: 0.3513
Epoch [16/50] - Loss: 0.3394
Epoch [17/50] - Loss: 0.3276
Epoch [18/50] - Loss: 0.3154
Epoch [19/50] - Loss: 0.3037
Epoch [20/50] - Loss: 0.2932
Epoch [21/50] - Loss: 0.2837
Epoch [22/50] - Loss: 0.2745
Epoch [23/50] - Loss: 0.2653
Epoch [24/50] - Loss: 0.2563
Epoch [25/50] - Loss: 0.2482
Epoch [26/50] - Loss: 0.2409
Epoch [27/50] - Loss: 0.2339
Epoch [28/50] - Loss: 0.2269
Epoch [29/50] - Loss: 0.2202
Epoch [30/50] - Loss: 0.2140
Epoch [31/50] - Loss: 0.2082
Epoch [32/50] - Loss: 0.2026
Epoch [33/50] - Loss: 0.1969
Epoch [34/50] - Loss: 0.1914
Epoch [35/50] - Loss: 0.1864
Epoch [36/50] - Loss: 0.1815
Epoch [37/50] - Loss: 0.1767
Epoch [38/50] - Loss: 0.1720
Epoch [39/50] - Loss: 0.1675
Epoch [40/50] - Loss: 0.1633
Epoch [41/50] - Loss: 0.1592
Epoch [42/50] - Loss: 0.1551
Epoch [43/50] - Loss: 0.1511
Epoch [44/50] - Loss: 0.1474
Epoch [45/50] - Loss: 0.1438
Epoch [46/50] - Loss: 0.1403
Epoch [47/50] - Loss: 0.1369
Epoch [48/50] - Loss: 0.1336
Epoch [49/50] - Loss: 0.1305
Epoch [50/50] - Loss: 0.1274
sum preds 399
sum labels 573
 - Test Metrics: Accuracy=0.8620, F1=0.6502, Recall=0.5515, Precision=0.7920
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7139
Epoch [2/50] - Loss: 0.6737
Epoch [3/50] - Loss: 0.6442
Epoch [4/50] - Loss: 0.6198
Epoch [5/50] - Loss: 0.5972
Epoch [6/50] - Loss: 0.5741
Epoch [7/50] - Loss: 0.5493
Epoch [8/50] - Loss: 0.5225
Epoch [9/50] - Loss: 0.4952
Epoch [10/50] - Loss: 0.4697
Epoch [11/50] - Loss: 0.4471
Epoch [12/50] - Loss: 0.4271
Epoch [13/50] - Loss: 0.4089
Epoch [14/50] - Loss: 0.3917
Epoch [15/50] - Loss: 0.3753
Epoch [16/50] - Loss: 0.3599
Epoch [17/50] - Loss: 0.3461
Epoch [18/50] - Loss: 0.3338
Epoch [19/50] - Loss: 0.3230
Epoch [20/50] - Loss: 0.3127
Epoch [21/50] - Loss: 0.3027
Epoch [22/50] - Loss: 0.2930
Epoch [23/50] - Loss: 0.2836
Epoch [24/50] - Loss: 0.2749
Epoch [25/50] - Loss: 0.2668
Epoch [26/50] - Loss: 0.2592
Epoch [27/50] - Loss: 0.2517
Epoch [28/50] - Loss: 0.2444
Epoch [29/50] - Loss: 0.2374
Epoch [30/50] - Loss: 0.2309
Epoch [31/50] - Loss: 0.2248
Epoch [32/50] - Loss: 0.2189
Epoch [33/50] - Loss: 0.2131
Epoch [34/50] - Loss: 0.2075
Epoch [35/50] - Loss: 0.2022
Epoch [36/50] - Loss: 0.1972
Epoch [37/50] - Loss: 0.1924
Epoch [38/50] - Loss: 0.1877
Epoch [39/50] - Loss: 0.1832
Epoch [40/50] - Loss: 0.1790
Epoch [41/50] - Loss: 0.1749
Epoch [42/50] - Loss: 0.1711
Epoch [43/50] - Loss: 0.1673
Epoch [44/50] - Loss: 0.1637
Epoch [45/50] - Loss: 0.1603
Epoch [46/50] - Loss: 0.1572
Epoch [47/50] - Loss: 0.1541
Epoch [48/50] - Loss: 0.1511
Epoch [49/50] - Loss: 0.1483
Epoch [50/50] - Loss: 0.1455
sum preds 377
sum labels 573
 - Test Metrics: Accuracy=0.8701, F1=0.6632, Recall=0.5497, Precision=0.8355
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6815
Epoch [2/50] - Loss: 0.6333
Epoch [3/50] - Loss: 0.5840
Epoch [4/50] - Loss: 0.5371
Epoch [5/50] - Loss: 0.4944
Epoch [6/50] - Loss: 0.4568
Epoch [7/50] - Loss: 0.4245
Epoch [8/50] - Loss: 0.3969
Epoch [9/50] - Loss: 0.3728
Epoch [10/50] - Loss: 0.3515
Epoch [11/50] - Loss: 0.3328
Epoch [12/50] - Loss: 0.3161
Epoch [13/50] - Loss: 0.3011
Epoch [14/50] - Loss: 0.2874
Epoch [15/50] - Loss: 0.2746
Epoch [16/50] - Loss: 0.2628
Epoch [17/50] - Loss: 0.2517
Epoch [18/50] - Loss: 0.2414
Epoch [19/50] - Loss: 0.2318
Epoch [20/50] - Loss: 0.2227
Epoch [21/50] - Loss: 0.2143
Epoch [22/50] - Loss: 0.2064
Epoch [23/50] - Loss: 0.1991
Epoch [24/50] - Loss: 0.1921
Epoch [25/50] - Loss: 0.1856
Epoch [26/50] - Loss: 0.1794
Epoch [27/50] - Loss: 0.1734
Epoch [28/50] - Loss: 0.1677
Epoch [29/50] - Loss: 0.1623
Epoch [30/50] - Loss: 0.1571
Epoch [31/50] - Loss: 0.1520
Epoch [32/50] - Loss: 0.1473
Epoch [33/50] - Loss: 0.1427
Epoch [34/50] - Loss: 0.1383
Epoch [35/50] - Loss: 0.1342
Epoch [36/50] - Loss: 0.1302
Epoch [37/50] - Loss: 0.1265
Epoch [38/50] - Loss: 0.1229
Epoch [39/50] - Loss: 0.1195
Epoch [40/50] - Loss: 0.1161
Epoch [41/50] - Loss: 0.1130
Epoch [42/50] - Loss: 0.1099
Epoch [43/50] - Loss: 0.1069
Epoch [44/50] - Loss: 0.1041
Epoch [45/50] - Loss: 0.1014
Epoch [46/50] - Loss: 0.0988
Epoch [47/50] - Loss: 0.0963
Epoch [48/50] - Loss: 0.0939
Epoch [49/50] - Loss: 0.0916
Epoch [50/50] - Loss: 0.0894
sum preds 424
sum labels 573
 - Test Metrics: Accuracy=0.8721, F1=0.6841, Recall=0.5951, Precision=0.8042
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_spy_spy_1804094917.csv.
Average F1 over valid seeds: 0.6658 ± 0.0139
___________________________________________________________________________________
Avg F1 for cora with SAR and spy, GCNConv,0.3: 0.6658 ± 0.0139
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7063
Epoch [2/50] - Loss: 0.6811
Epoch [3/50] - Loss: 0.6605
Epoch [4/50] - Loss: 0.6378
Epoch [5/50] - Loss: 0.6133
Epoch [6/50] - Loss: 0.5875
Epoch [7/50] - Loss: 0.5606
Epoch [8/50] - Loss: 0.5332
Epoch [9/50] - Loss: 0.5053
Epoch [10/50] - Loss: 0.4775
Epoch [11/50] - Loss: 0.4499
Epoch [12/50] - Loss: 0.4227
Epoch [13/50] - Loss: 0.3958
Epoch [14/50] - Loss: 0.3693
Epoch [15/50] - Loss: 0.3435
Epoch [16/50] - Loss: 0.3185
Epoch [17/50] - Loss: 0.2944
Epoch [18/50] - Loss: 0.2713
Epoch [19/50] - Loss: 0.2494
Epoch [20/50] - Loss: 0.2288
Epoch [21/50] - Loss: 0.2095
Epoch [22/50] - Loss: 0.1915
Epoch [23/50] - Loss: 0.1748
Epoch [24/50] - Loss: 0.1593
Epoch [25/50] - Loss: 0.1451
Epoch [26/50] - Loss: 0.1321
Epoch [27/50] - Loss: 0.1202
Epoch [28/50] - Loss: 0.1094
Epoch [29/50] - Loss: 0.0996
Epoch [30/50] - Loss: 0.0908
Epoch [31/50] - Loss: 0.0829
Epoch [32/50] - Loss: 0.0757
Epoch [33/50] - Loss: 0.0693
Epoch [34/50] - Loss: 0.0635
Epoch [35/50] - Loss: 0.0583
Epoch [36/50] - Loss: 0.0537
Epoch [37/50] - Loss: 0.0495
Epoch [38/50] - Loss: 0.0458
Epoch [39/50] - Loss: 0.0424
Epoch [40/50] - Loss: 0.0394
Epoch [41/50] - Loss: 0.0366
Epoch [42/50] - Loss: 0.0342
Epoch [43/50] - Loss: 0.0319
Epoch [44/50] - Loss: 0.0299
Epoch [45/50] - Loss: 0.0280
Epoch [46/50] - Loss: 0.0263
Epoch [47/50] - Loss: 0.0248
Epoch [48/50] - Loss: 0.0234
Epoch [49/50] - Loss: 0.0221
Epoch [50/50] - Loss: 0.0209
sum preds 356
sum labels 654
 - Test Metrics: Accuracy=0.7807, F1=0.4475, Recall=0.3456, Precision=0.6348
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7378
Epoch [2/50] - Loss: 0.7001
Epoch [3/50] - Loss: 0.6661
Epoch [4/50] - Loss: 0.6327
Epoch [5/50] - Loss: 0.6008
Epoch [6/50] - Loss: 0.5709
Epoch [7/50] - Loss: 0.5434
Epoch [8/50] - Loss: 0.5179
Epoch [9/50] - Loss: 0.4937
Epoch [10/50] - Loss: 0.4699
Epoch [11/50] - Loss: 0.4456
Epoch [12/50] - Loss: 0.4207
Epoch [13/50] - Loss: 0.3951
Epoch [14/50] - Loss: 0.3690
Epoch [15/50] - Loss: 0.3431
Epoch [16/50] - Loss: 0.3187
Epoch [17/50] - Loss: 0.2962
Epoch [18/50] - Loss: 0.2759
Epoch [19/50] - Loss: 0.2572
Epoch [20/50] - Loss: 0.2392
Epoch [21/50] - Loss: 0.2214
Epoch [22/50] - Loss: 0.2035
Epoch [23/50] - Loss: 0.1858
Epoch [24/50] - Loss: 0.1688
Epoch [25/50] - Loss: 0.1531
Epoch [26/50] - Loss: 0.1388
Epoch [27/50] - Loss: 0.1261
Epoch [28/50] - Loss: 0.1148
Epoch [29/50] - Loss: 0.1045
Epoch [30/50] - Loss: 0.0951
Epoch [31/50] - Loss: 0.0864
Epoch [32/50] - Loss: 0.0785
Epoch [33/50] - Loss: 0.0713
Epoch [34/50] - Loss: 0.0648
Epoch [35/50] - Loss: 0.0590
Epoch [36/50] - Loss: 0.0539
Epoch [37/50] - Loss: 0.0494
Epoch [38/50] - Loss: 0.0454
Epoch [39/50] - Loss: 0.0417
Epoch [40/50] - Loss: 0.0385
Epoch [41/50] - Loss: 0.0355
Epoch [42/50] - Loss: 0.0328
Epoch [43/50] - Loss: 0.0303
Epoch [44/50] - Loss: 0.0281
Epoch [45/50] - Loss: 0.0260
Epoch [46/50] - Loss: 0.0242
Epoch [47/50] - Loss: 0.0225
Epoch [48/50] - Loss: 0.0211
Epoch [49/50] - Loss: 0.0197
Epoch [50/50] - Loss: 0.0185
sum preds 342
sum labels 654
 - Test Metrics: Accuracy=0.7783, F1=0.4337, Recall=0.3303, Precision=0.6316
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7194
Epoch [2/50] - Loss: 0.6890
Epoch [3/50] - Loss: 0.6631
Epoch [4/50] - Loss: 0.6361
Epoch [5/50] - Loss: 0.6083
Epoch [6/50] - Loss: 0.5802
Epoch [7/50] - Loss: 0.5519
Epoch [8/50] - Loss: 0.5237
Epoch [9/50] - Loss: 0.4956
Epoch [10/50] - Loss: 0.4676
Epoch [11/50] - Loss: 0.4396
Epoch [12/50] - Loss: 0.4122
Epoch [13/50] - Loss: 0.3853
Epoch [14/50] - Loss: 0.3592
Epoch [15/50] - Loss: 0.3341
Epoch [16/50] - Loss: 0.3101
Epoch [17/50] - Loss: 0.2874
Epoch [18/50] - Loss: 0.2660
Epoch [19/50] - Loss: 0.2459
Epoch [20/50] - Loss: 0.2269
Epoch [21/50] - Loss: 0.2090
Epoch [22/50] - Loss: 0.1922
Epoch [23/50] - Loss: 0.1766
Epoch [24/50] - Loss: 0.1621
Epoch [25/50] - Loss: 0.1488
Epoch [26/50] - Loss: 0.1365
Epoch [27/50] - Loss: 0.1252
Epoch [28/50] - Loss: 0.1149
Epoch [29/50] - Loss: 0.1054
Epoch [30/50] - Loss: 0.0967
Epoch [31/50] - Loss: 0.0889
Epoch [32/50] - Loss: 0.0817
Epoch [33/50] - Loss: 0.0752
Epoch [34/50] - Loss: 0.0693
Epoch [35/50] - Loss: 0.0640
Epoch [36/50] - Loss: 0.0592
Epoch [37/50] - Loss: 0.0548
Epoch [38/50] - Loss: 0.0508
Epoch [39/50] - Loss: 0.0471
Epoch [40/50] - Loss: 0.0438
Epoch [41/50] - Loss: 0.0407
Epoch [42/50] - Loss: 0.0379
Epoch [43/50] - Loss: 0.0352
Epoch [44/50] - Loss: 0.0329
Epoch [45/50] - Loss: 0.0307
Epoch [46/50] - Loss: 0.0286
Epoch [47/50] - Loss: 0.0268
Epoch [48/50] - Loss: 0.0250
Epoch [49/50] - Loss: 0.0235
Epoch [50/50] - Loss: 0.0220
sum preds 367
sum labels 654
 - Test Metrics: Accuracy=0.7716, F1=0.4310, Recall=0.3364, Precision=0.5995
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_spy_spy_1804094935.csv.
Average F1 over valid seeds: 0.4374 ± 0.0072
___________________________________________________________________________________
Avg F1 for cora with SAR and spy, MLP,0.2: 0.4374 ± 0.0072
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7029
Epoch [2/50] - Loss: 0.6432
Epoch [3/50] - Loss: 0.6002
Epoch [4/50] - Loss: 0.5679
Epoch [5/50] - Loss: 0.5444
Epoch [6/50] - Loss: 0.5251
Epoch [7/50] - Loss: 0.5056
Epoch [8/50] - Loss: 0.4838
Epoch [9/50] - Loss: 0.4593
Epoch [10/50] - Loss: 0.4339
Epoch [11/50] - Loss: 0.4093
Epoch [12/50] - Loss: 0.3880
Epoch [13/50] - Loss: 0.3706
Epoch [14/50] - Loss: 0.3560
Epoch [15/50] - Loss: 0.3424
Epoch [16/50] - Loss: 0.3283
Epoch [17/50] - Loss: 0.3131
Epoch [18/50] - Loss: 0.2968
Epoch [19/50] - Loss: 0.2809
Epoch [20/50] - Loss: 0.2664
Epoch [21/50] - Loss: 0.2542
Epoch [22/50] - Loss: 0.2437
Epoch [23/50] - Loss: 0.2337
Epoch [24/50] - Loss: 0.2236
Epoch [25/50] - Loss: 0.2135
Epoch [26/50] - Loss: 0.2034
Epoch [27/50] - Loss: 0.1937
Epoch [28/50] - Loss: 0.1848
Epoch [29/50] - Loss: 0.1760
Epoch [30/50] - Loss: 0.1669
Epoch [31/50] - Loss: 0.1580
Epoch [32/50] - Loss: 0.1498
Epoch [33/50] - Loss: 0.1429
Epoch [34/50] - Loss: 0.1366
Epoch [35/50] - Loss: 0.1304
Epoch [36/50] - Loss: 0.1243
Epoch [37/50] - Loss: 0.1185
Epoch [38/50] - Loss: 0.1136
Epoch [39/50] - Loss: 0.1091
Epoch [40/50] - Loss: 0.1048
Epoch [41/50] - Loss: 0.1001
Epoch [42/50] - Loss: 0.0950
Epoch [43/50] - Loss: 0.0898
Epoch [44/50] - Loss: 0.0851
Epoch [45/50] - Loss: 0.0811
Epoch [46/50] - Loss: 0.0777
Epoch [47/50] - Loss: 0.0747
Epoch [48/50] - Loss: 0.0719
Epoch [49/50] - Loss: 0.0691
Epoch [50/50] - Loss: 0.0664
sum preds 314
sum labels 654
 - Test Metrics: Accuracy=0.8255, F1=0.5413, Recall=0.4006, Precision=0.8344
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7039
Epoch [2/50] - Loss: 0.6519
Epoch [3/50] - Loss: 0.6195
Epoch [4/50] - Loss: 0.5913
Epoch [5/50] - Loss: 0.5649
Epoch [6/50] - Loss: 0.5395
Epoch [7/50] - Loss: 0.5145
Epoch [8/50] - Loss: 0.4892
Epoch [9/50] - Loss: 0.4628
Epoch [10/50] - Loss: 0.4355
Epoch [11/50] - Loss: 0.4082
Epoch [12/50] - Loss: 0.3829
Epoch [13/50] - Loss: 0.3616
Epoch [14/50] - Loss: 0.3448
Epoch [15/50] - Loss: 0.3302
Epoch [16/50] - Loss: 0.3154
Epoch [17/50] - Loss: 0.2987
Epoch [18/50] - Loss: 0.2806
Epoch [19/50] - Loss: 0.2626
Epoch [20/50] - Loss: 0.2460
Epoch [21/50] - Loss: 0.2311
Epoch [22/50] - Loss: 0.2175
Epoch [23/50] - Loss: 0.2044
Epoch [24/50] - Loss: 0.1915
Epoch [25/50] - Loss: 0.1790
Epoch [26/50] - Loss: 0.1671
Epoch [27/50] - Loss: 0.1565
Epoch [28/50] - Loss: 0.1470
Epoch [29/50] - Loss: 0.1386
Epoch [30/50] - Loss: 0.1309
Epoch [31/50] - Loss: 0.1239
Epoch [32/50] - Loss: 0.1175
Epoch [33/50] - Loss: 0.1119
Epoch [34/50] - Loss: 0.1071
Epoch [35/50] - Loss: 0.1028
Epoch [36/50] - Loss: 0.0990
Epoch [37/50] - Loss: 0.0956
Epoch [38/50] - Loss: 0.0925
Epoch [39/50] - Loss: 0.0899
Epoch [40/50] - Loss: 0.0877
Epoch [41/50] - Loss: 0.0859
Epoch [42/50] - Loss: 0.0845
Epoch [43/50] - Loss: 0.0831
Epoch [44/50] - Loss: 0.0818
Epoch [45/50] - Loss: 0.0805
Epoch [46/50] - Loss: 0.0794
Epoch [47/50] - Loss: 0.0783
Epoch [48/50] - Loss: 0.0772
Epoch [49/50] - Loss: 0.0760
Epoch [50/50] - Loss: 0.0747
sum preds 382
sum labels 654
 - Test Metrics: Accuracy=0.8506, F1=0.6332, Recall=0.5015, Precision=0.8586
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6660
Epoch [2/50] - Loss: 0.5905
Epoch [3/50] - Loss: 0.5428
Epoch [4/50] - Loss: 0.5104
Epoch [5/50] - Loss: 0.4808
Epoch [6/50] - Loss: 0.4489
Epoch [7/50] - Loss: 0.4175
Epoch [8/50] - Loss: 0.3901
Epoch [9/50] - Loss: 0.3682
Epoch [10/50] - Loss: 0.3507
Epoch [11/50] - Loss: 0.3360
Epoch [12/50] - Loss: 0.3223
Epoch [13/50] - Loss: 0.3089
Epoch [14/50] - Loss: 0.2957
Epoch [15/50] - Loss: 0.2834
Epoch [16/50] - Loss: 0.2721
Epoch [17/50] - Loss: 0.2618
Epoch [18/50] - Loss: 0.2520
Epoch [19/50] - Loss: 0.2423
Epoch [20/50] - Loss: 0.2326
Epoch [21/50] - Loss: 0.2232
Epoch [22/50] - Loss: 0.2146
Epoch [23/50] - Loss: 0.2071
Epoch [24/50] - Loss: 0.2004
Epoch [25/50] - Loss: 0.1940
Epoch [26/50] - Loss: 0.1876
Epoch [27/50] - Loss: 0.1810
Epoch [28/50] - Loss: 0.1743
Epoch [29/50] - Loss: 0.1678
Epoch [30/50] - Loss: 0.1614
Epoch [31/50] - Loss: 0.1552
Epoch [32/50] - Loss: 0.1496
Epoch [33/50] - Loss: 0.1443
Epoch [34/50] - Loss: 0.1392
Epoch [35/50] - Loss: 0.1343
Epoch [36/50] - Loss: 0.1297
Epoch [37/50] - Loss: 0.1255
Epoch [38/50] - Loss: 0.1215
Epoch [39/50] - Loss: 0.1173
Epoch [40/50] - Loss: 0.1129
Epoch [41/50] - Loss: 0.1087
Epoch [42/50] - Loss: 0.1051
Epoch [43/50] - Loss: 0.1020
Epoch [44/50] - Loss: 0.0989
Epoch [45/50] - Loss: 0.0955
Epoch [46/50] - Loss: 0.0923
Epoch [47/50] - Loss: 0.0895
Epoch [48/50] - Loss: 0.0870
Epoch [49/50] - Loss: 0.0847
Epoch [50/50] - Loss: 0.0818
sum preds 342
sum labels 654
 - Test Metrics: Accuracy=0.8365, F1=0.5823, Recall=0.4434, Precision=0.8480
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_spy_spy_1804094952.csv.
Average F1 over valid seeds: 0.5856 ± 0.0376
___________________________________________________________________________________
Avg F1 for cora with SAR and spy, GATConv,0.2: 0.5856 ± 0.0376
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6866
Epoch [2/50] - Loss: 0.6317
Epoch [3/50] - Loss: 0.5922
Epoch [4/50] - Loss: 0.5647
Epoch [5/50] - Loss: 0.5452
Epoch [6/50] - Loss: 0.5286
Epoch [7/50] - Loss: 0.5113
Epoch [8/50] - Loss: 0.4918
Epoch [9/50] - Loss: 0.4704
Epoch [10/50] - Loss: 0.4490
Epoch [11/50] - Loss: 0.4286
Epoch [12/50] - Loss: 0.4103
Epoch [13/50] - Loss: 0.3941
Epoch [14/50] - Loss: 0.3801
Epoch [15/50] - Loss: 0.3677
Epoch [16/50] - Loss: 0.3552
Epoch [17/50] - Loss: 0.3422
Epoch [18/50] - Loss: 0.3283
Epoch [19/50] - Loss: 0.3144
Epoch [20/50] - Loss: 0.3015
Epoch [21/50] - Loss: 0.2901
Epoch [22/50] - Loss: 0.2803
Epoch [23/50] - Loss: 0.2712
Epoch [24/50] - Loss: 0.2619
Epoch [25/50] - Loss: 0.2523
Epoch [26/50] - Loss: 0.2431
Epoch [27/50] - Loss: 0.2347
Epoch [28/50] - Loss: 0.2272
Epoch [29/50] - Loss: 0.2200
Epoch [30/50] - Loss: 0.2128
Epoch [31/50] - Loss: 0.2057
Epoch [32/50] - Loss: 0.1990
Epoch [33/50] - Loss: 0.1931
Epoch [34/50] - Loss: 0.1877
Epoch [35/50] - Loss: 0.1823
Epoch [36/50] - Loss: 0.1769
Epoch [37/50] - Loss: 0.1717
Epoch [38/50] - Loss: 0.1669
Epoch [39/50] - Loss: 0.1623
Epoch [40/50] - Loss: 0.1577
Epoch [41/50] - Loss: 0.1530
Epoch [42/50] - Loss: 0.1484
Epoch [43/50] - Loss: 0.1442
Epoch [44/50] - Loss: 0.1401
Epoch [45/50] - Loss: 0.1361
Epoch [46/50] - Loss: 0.1322
Epoch [47/50] - Loss: 0.1285
Epoch [48/50] - Loss: 0.1251
Epoch [49/50] - Loss: 0.1217
Epoch [50/50] - Loss: 0.1184
sum preds 353
sum labels 654
 - Test Metrics: Accuracy=0.8361, F1=0.5859, Recall=0.4511, Precision=0.8357
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.7244
Epoch [2/50] - Loss: 0.6689
Epoch [3/50] - Loss: 0.6286
Epoch [4/50] - Loss: 0.5976
Epoch [5/50] - Loss: 0.5730
Epoch [6/50] - Loss: 0.5538
Epoch [7/50] - Loss: 0.5386
Epoch [8/50] - Loss: 0.5253
Epoch [9/50] - Loss: 0.5119
Epoch [10/50] - Loss: 0.4969
Epoch [11/50] - Loss: 0.4793
Epoch [12/50] - Loss: 0.4594
Epoch [13/50] - Loss: 0.4381
Epoch [14/50] - Loss: 0.4179
Epoch [15/50] - Loss: 0.4008
Epoch [16/50] - Loss: 0.3869
Epoch [17/50] - Loss: 0.3752
Epoch [18/50] - Loss: 0.3640
Epoch [19/50] - Loss: 0.3523
Epoch [20/50] - Loss: 0.3398
Epoch [21/50] - Loss: 0.3268
Epoch [22/50] - Loss: 0.3141
Epoch [23/50] - Loss: 0.3023
Epoch [24/50] - Loss: 0.2918
Epoch [25/50] - Loss: 0.2826
Epoch [26/50] - Loss: 0.2740
Epoch [27/50] - Loss: 0.2658
Epoch [28/50] - Loss: 0.2574
Epoch [29/50] - Loss: 0.2489
Epoch [30/50] - Loss: 0.2406
Epoch [31/50] - Loss: 0.2326
Epoch [32/50] - Loss: 0.2252
Epoch [33/50] - Loss: 0.2182
Epoch [34/50] - Loss: 0.2114
Epoch [35/50] - Loss: 0.2046
Epoch [36/50] - Loss: 0.1980
Epoch [37/50] - Loss: 0.1917
Epoch [38/50] - Loss: 0.1860
Epoch [39/50] - Loss: 0.1808
Epoch [40/50] - Loss: 0.1758
Epoch [41/50] - Loss: 0.1710
Epoch [42/50] - Loss: 0.1663
Epoch [43/50] - Loss: 0.1619
Epoch [44/50] - Loss: 0.1578
Epoch [45/50] - Loss: 0.1539
Epoch [46/50] - Loss: 0.1501
Epoch [47/50] - Loss: 0.1463
Epoch [48/50] - Loss: 0.1425
Epoch [49/50] - Loss: 0.1390
Epoch [50/50] - Loss: 0.1356
sum preds 305
sum labels 654
 - Test Metrics: Accuracy=0.8337, F1=0.5589, Recall=0.4098, Precision=0.8787
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.6722
Epoch [2/50] - Loss: 0.6125
Epoch [3/50] - Loss: 0.5657
Epoch [4/50] - Loss: 0.5306
Epoch [5/50] - Loss: 0.4997
Epoch [6/50] - Loss: 0.4673
Epoch [7/50] - Loss: 0.4341
Epoch [8/50] - Loss: 0.4044
Epoch [9/50] - Loss: 0.3811
Epoch [10/50] - Loss: 0.3638
Epoch [11/50] - Loss: 0.3484
Epoch [12/50] - Loss: 0.3322
Epoch [13/50] - Loss: 0.3154
Epoch [14/50] - Loss: 0.2996
Epoch [15/50] - Loss: 0.2863
Epoch [16/50] - Loss: 0.2752
Epoch [17/50] - Loss: 0.2650
Epoch [18/50] - Loss: 0.2546
Epoch [19/50] - Loss: 0.2438
Epoch [20/50] - Loss: 0.2335
Epoch [21/50] - Loss: 0.2244
Epoch [22/50] - Loss: 0.2165
Epoch [23/50] - Loss: 0.2092
Epoch [24/50] - Loss: 0.2020
Epoch [25/50] - Loss: 0.1946
Epoch [26/50] - Loss: 0.1875
Epoch [27/50] - Loss: 0.1811
Epoch [28/50] - Loss: 0.1753
Epoch [29/50] - Loss: 0.1698
Epoch [30/50] - Loss: 0.1641
Epoch [31/50] - Loss: 0.1585
Epoch [32/50] - Loss: 0.1532
Epoch [33/50] - Loss: 0.1485
Epoch [34/50] - Loss: 0.1441
Epoch [35/50] - Loss: 0.1398
Epoch [36/50] - Loss: 0.1355
Epoch [37/50] - Loss: 0.1313
Epoch [38/50] - Loss: 0.1275
Epoch [39/50] - Loss: 0.1240
Epoch [40/50] - Loss: 0.1205
Epoch [41/50] - Loss: 0.1171
Epoch [42/50] - Loss: 0.1138
Epoch [43/50] - Loss: 0.1108
Epoch [44/50] - Loss: 0.1080
Epoch [45/50] - Loss: 0.1053
Epoch [46/50] - Loss: 0.1026
Epoch [47/50] - Loss: 0.1000
Epoch [48/50] - Loss: 0.0976
Epoch [49/50] - Loss: 0.0953
Epoch [50/50] - Loss: 0.0931
sum preds 352
sum labels 654
 - Test Metrics: Accuracy=0.8388, F1=0.5924, Recall=0.4557, Precision=0.8466
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_spy_spy_1804095013.csv.
Average F1 over valid seeds: 0.5791 ± 0.0145
___________________________________________________________________________________
Avg F1 for cora with SAR and spy, GCNConv,0.2: 0.5791 ± 0.0145
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5231
Epoch [2/50] - Loss: 0.5108
Epoch [3/50] - Loss: 0.4970
Epoch [4/50] - Loss: 0.4809
Epoch [5/50] - Loss: 0.4628
Epoch [6/50] - Loss: 0.4433
Epoch [7/50] - Loss: 0.4226
Epoch [8/50] - Loss: 0.4008
Epoch [9/50] - Loss: 0.3784
Epoch [10/50] - Loss: 0.3553
Epoch [11/50] - Loss: 0.3322
Epoch [12/50] - Loss: 0.3090
Epoch [13/50] - Loss: 0.2862
Epoch [14/50] - Loss: 0.2639
Epoch [15/50] - Loss: 0.2423
Epoch [16/50] - Loss: 0.2214
Epoch [17/50] - Loss: 0.2013
Epoch [18/50] - Loss: 0.1820
Epoch [19/50] - Loss: 0.1633
Epoch [20/50] - Loss: 0.1454
Epoch [21/50] - Loss: 0.1282
Epoch [22/50] - Loss: 0.1118
Epoch [23/50] - Loss: 0.1044
Epoch [24/50] - Loss: 0.0965
Epoch [25/50] - Loss: 0.0876
Epoch [26/50] - Loss: 0.0784
Epoch [27/50] - Loss: 0.0692
Epoch [28/50] - Loss: 0.0605
Epoch [29/50] - Loss: 0.0591
Epoch [30/50] - Loss: 0.0586
Epoch [31/50] - Loss: 0.0533
Epoch [32/50] - Loss: 0.0439
Epoch [33/50] - Loss: 0.0439
Epoch [34/50] - Loss: 0.0435
Epoch [35/50] - Loss: 0.0425
Epoch [36/50] - Loss: 0.0410
Epoch [37/50] - Loss: 0.0391
Epoch [38/50] - Loss: 0.0370
Epoch [39/50] - Loss: 0.0347
Epoch [40/50] - Loss: 0.0323
Epoch [41/50] - Loss: 0.0300
Epoch [42/50] - Loss: 0.0278
Epoch [43/50] - Loss: 0.0258
Epoch [44/50] - Loss: 0.0239
Epoch [45/50] - Loss: 0.0237
Epoch [46/50] - Loss: 0.0216
Epoch [47/50] - Loss: 0.0210
Epoch [48/50] - Loss: 0.0203
Epoch [49/50] - Loss: 0.0196
Epoch [50/50] - Loss: 0.0193
sum preds 566
sum labels 491
 - Test Metrics: Accuracy=0.8551, F1=0.6736, Recall=0.7251, Precision=0.6290
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4977
Epoch [2/50] - Loss: 0.4836
Epoch [3/50] - Loss: 0.4689
Epoch [4/50] - Loss: 0.4518
Epoch [5/50] - Loss: 0.4330
Epoch [6/50] - Loss: 0.4128
Epoch [7/50] - Loss: 0.3919
Epoch [8/50] - Loss: 0.3706
Epoch [9/50] - Loss: 0.3490
Epoch [10/50] - Loss: 0.3270
Epoch [11/50] - Loss: 0.3048
Epoch [12/50] - Loss: 0.2827
Epoch [13/50] - Loss: 0.2608
Epoch [14/50] - Loss: 0.2391
Epoch [15/50] - Loss: 0.2180
Epoch [16/50] - Loss: 0.1973
Epoch [17/50] - Loss: 0.1771
Epoch [18/50] - Loss: 0.1575
Epoch [19/50] - Loss: 0.1386
Epoch [20/50] - Loss: 0.1205
Epoch [21/50] - Loss: 0.1032
Epoch [22/50] - Loss: 0.0953
Epoch [23/50] - Loss: 0.0869
Epoch [24/50] - Loss: 0.0776
Epoch [25/50] - Loss: 0.0681
Epoch [26/50] - Loss: 0.0588
Epoch [27/50] - Loss: 0.0502
Epoch [28/50] - Loss: 0.0553
Epoch [29/50] - Loss: 0.0547
Epoch [30/50] - Loss: 0.0478
Epoch [31/50] - Loss: 0.0360
Epoch [32/50] - Loss: 0.0362
Epoch [33/50] - Loss: 0.0362
Epoch [34/50] - Loss: 0.0357
Epoch [35/50] - Loss: 0.0346
Epoch [36/50] - Loss: 0.0332
Epoch [37/50] - Loss: 0.0314
Epoch [38/50] - Loss: 0.0294
Epoch [39/50] - Loss: 0.0272
Epoch [40/50] - Loss: 0.0251
Epoch [41/50] - Loss: 0.0229
Epoch [42/50] - Loss: 0.0209
Epoch [43/50] - Loss: 0.0190
Epoch [44/50] - Loss: 0.0172
Epoch [45/50] - Loss: 0.0157
Epoch [46/50] - Loss: 0.0142
Epoch [47/50] - Loss: 0.0129
Epoch [48/50] - Loss: 0.0198
Epoch [49/50] - Loss: 0.0157
Epoch [50/50] - Loss: 0.0117
sum preds 538
sum labels 491
 - Test Metrics: Accuracy=0.8509, F1=0.6550, Recall=0.6864, Precision=0.6264
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5210
Epoch [2/50] - Loss: 0.5103
Epoch [3/50] - Loss: 0.5002
Epoch [4/50] - Loss: 0.4882
Epoch [5/50] - Loss: 0.4743
Epoch [6/50] - Loss: 0.4590
Epoch [7/50] - Loss: 0.4424
Epoch [8/50] - Loss: 0.4248
Epoch [9/50] - Loss: 0.4063
Epoch [10/50] - Loss: 0.3865
Epoch [11/50] - Loss: 0.3657
Epoch [12/50] - Loss: 0.3441
Epoch [13/50] - Loss: 0.3219
Epoch [14/50] - Loss: 0.2994
Epoch [15/50] - Loss: 0.2767
Epoch [16/50] - Loss: 0.2541
Epoch [17/50] - Loss: 0.2316
Epoch [18/50] - Loss: 0.2096
Epoch [19/50] - Loss: 0.1881
Epoch [20/50] - Loss: 0.1673
Epoch [21/50] - Loss: 0.1473
Epoch [22/50] - Loss: 0.1282
Epoch [23/50] - Loss: 0.1101
Epoch [24/50] - Loss: 0.0929
Epoch [25/50] - Loss: 0.0779
Epoch [26/50] - Loss: 0.0724
Epoch [27/50] - Loss: 0.0656
Epoch [28/50] - Loss: 0.0583
Epoch [29/50] - Loss: 0.0510
Epoch [30/50] - Loss: 0.0442
Epoch [31/50] - Loss: 0.0411
Epoch [32/50] - Loss: 0.0388
Epoch [33/50] - Loss: 0.0334
Epoch [34/50] - Loss: 0.0317
Epoch [35/50] - Loss: 0.0298
Epoch [36/50] - Loss: 0.0278
Epoch [37/50] - Loss: 0.0258
Epoch [38/50] - Loss: 0.0238
Epoch [39/50] - Loss: 0.0227
Epoch [40/50] - Loss: 0.0214
Epoch [41/50] - Loss: 0.0208
Epoch [42/50] - Loss: 0.0200
Epoch [43/50] - Loss: 0.0192
Epoch [44/50] - Loss: 0.0184
Epoch [45/50] - Loss: 0.0175
Epoch [46/50] - Loss: 0.0166
Epoch [47/50] - Loss: 0.0158
Epoch [48/50] - Loss: 0.0149
Epoch [49/50] - Loss: 0.0141
Epoch [50/50] - Loss: 0.0177
sum preds 567
sum labels 491
 - Test Metrics: Accuracy=0.8589, F1=0.6824, Recall=0.7352, Precision=0.6367
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_nnpu_nnpu_1804095033.csv.
Average F1 over valid seeds: 0.6703 ± 0.0114
___________________________________________________________________________________
Avg F1 for cora with SAR and nnpu, MLP,0.4: 0.6703 ± 0.0114
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4947
Epoch [2/50] - Loss: 0.4572
Epoch [3/50] - Loss: 0.4220
Epoch [4/50] - Loss: 0.3891
Epoch [5/50] - Loss: 0.3591
Epoch [6/50] - Loss: 0.3323
Epoch [7/50] - Loss: 0.3087
Epoch [8/50] - Loss: 0.2879
Epoch [9/50] - Loss: 0.2692
Epoch [10/50] - Loss: 0.2516
Epoch [11/50] - Loss: 0.2345
Epoch [12/50] - Loss: 0.2171
Epoch [13/50] - Loss: 0.1991
Epoch [14/50] - Loss: 0.1803
Epoch [15/50] - Loss: 0.1634
Epoch [16/50] - Loss: 0.1468
Epoch [17/50] - Loss: 0.1284
Epoch [18/50] - Loss: 0.1123
Epoch [19/50] - Loss: 0.1026
Epoch [20/50] - Loss: 0.0939
Epoch [21/50] - Loss: 0.0849
Epoch [22/50] - Loss: 0.0743
Epoch [23/50] - Loss: 0.0631
Epoch [24/50] - Loss: 0.0586
Epoch [25/50] - Loss: 0.0534
Epoch [26/50] - Loss: 0.0480
Epoch [27/50] - Loss: 0.0442
Epoch [28/50] - Loss: 0.0396
Epoch [29/50] - Loss: 0.0385
Epoch [30/50] - Loss: 0.0369
Epoch [31/50] - Loss: 0.0348
Epoch [32/50] - Loss: 0.0324
Epoch [33/50] - Loss: 0.0297
Epoch [34/50] - Loss: 0.0270
Epoch [35/50] - Loss: 0.0254
Epoch [36/50] - Loss: 0.0232
Epoch [37/50] - Loss: 0.0219
Epoch [38/50] - Loss: 0.0207
Epoch [39/50] - Loss: 0.0204
Epoch [40/50] - Loss: 0.0200
Epoch [41/50] - Loss: 0.0194
Epoch [42/50] - Loss: 0.0185
Epoch [43/50] - Loss: 0.0175
Epoch [44/50] - Loss: 0.0163
Epoch [45/50] - Loss: 0.0150
Epoch [46/50] - Loss: 0.0136
Epoch [47/50] - Loss: 0.0162
Epoch [48/50] - Loss: 0.0122
Epoch [49/50] - Loss: 0.0119
Epoch [50/50] - Loss: 0.0116
sum preds 607
sum labels 491
 - Test Metrics: Accuracy=0.9152, F1=0.8160, Recall=0.9124, Precision=0.7381
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5054
Epoch [2/50] - Loss: 0.4827
Epoch [3/50] - Loss: 0.4618
Epoch [4/50] - Loss: 0.4394
Epoch [5/50] - Loss: 0.4162
Epoch [6/50] - Loss: 0.3928
Epoch [7/50] - Loss: 0.3698
Epoch [8/50] - Loss: 0.3476
Epoch [9/50] - Loss: 0.3260
Epoch [10/50] - Loss: 0.3052
Epoch [11/50] - Loss: 0.2852
Epoch [12/50] - Loss: 0.2657
Epoch [13/50] - Loss: 0.2465
Epoch [14/50] - Loss: 0.2274
Epoch [15/50] - Loss: 0.2080
Epoch [16/50] - Loss: 0.1886
Epoch [17/50] - Loss: 0.1695
Epoch [18/50] - Loss: 0.1513
Epoch [19/50] - Loss: 0.1342
Epoch [20/50] - Loss: 0.1188
Epoch [21/50] - Loss: 0.1050
Epoch [22/50] - Loss: 0.0927
Epoch [23/50] - Loss: 0.0815
Epoch [24/50] - Loss: 0.0729
Epoch [25/50] - Loss: 0.0654
Epoch [26/50] - Loss: 0.0581
Epoch [27/50] - Loss: 0.0527
Epoch [28/50] - Loss: 0.0484
Epoch [29/50] - Loss: 0.0443
Epoch [30/50] - Loss: 0.0401
Epoch [31/50] - Loss: 0.0375
Epoch [32/50] - Loss: 0.0347
Epoch [33/50] - Loss: 0.0333
Epoch [34/50] - Loss: 0.0306
Epoch [35/50] - Loss: 0.0291
Epoch [36/50] - Loss: 0.0273
Epoch [37/50] - Loss: 0.0266
Epoch [38/50] - Loss: 0.0248
Epoch [39/50] - Loss: 0.0239
Epoch [40/50] - Loss: 0.0228
Epoch [41/50] - Loss: 0.0214
Epoch [42/50] - Loss: 0.0199
Epoch [43/50] - Loss: 0.0223
Epoch [44/50] - Loss: 0.0181
Epoch [45/50] - Loss: 0.0184
Epoch [46/50] - Loss: 0.0187
Epoch [47/50] - Loss: 0.0186
Epoch [48/50] - Loss: 0.0182
Epoch [49/50] - Loss: 0.0177
Epoch [50/50] - Loss: 0.0169
sum preds 586
sum labels 491
 - Test Metrics: Accuracy=0.9240, F1=0.8319, Recall=0.9124, Precision=0.7645
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4984
Epoch [2/50] - Loss: 0.4662
Epoch [3/50] - Loss: 0.4331
Epoch [4/50] - Loss: 0.3992
Epoch [5/50] - Loss: 0.3669
Epoch [6/50] - Loss: 0.3372
Epoch [7/50] - Loss: 0.3105
Epoch [8/50] - Loss: 0.2866
Epoch [9/50] - Loss: 0.2649
Epoch [10/50] - Loss: 0.2446
Epoch [11/50] - Loss: 0.2250
Epoch [12/50] - Loss: 0.2059
Epoch [13/50] - Loss: 0.1870
Epoch [14/50] - Loss: 0.1683
Epoch [15/50] - Loss: 0.1502
Epoch [16/50] - Loss: 0.1370
Epoch [17/50] - Loss: 0.1231
Epoch [18/50] - Loss: 0.1083
Epoch [19/50] - Loss: 0.0951
Epoch [20/50] - Loss: 0.0871
Epoch [21/50] - Loss: 0.0787
Epoch [22/50] - Loss: 0.0690
Epoch [23/50] - Loss: 0.0601
Epoch [24/50] - Loss: 0.0547
Epoch [25/50] - Loss: 0.0489
Epoch [26/50] - Loss: 0.0431
Epoch [27/50] - Loss: 0.0422
Epoch [28/50] - Loss: 0.0368
Epoch [29/50] - Loss: 0.0328
Epoch [30/50] - Loss: 0.0308
Epoch [31/50] - Loss: 0.0283
Epoch [32/50] - Loss: 0.0256
Epoch [33/50] - Loss: 0.0229
Epoch [34/50] - Loss: 0.0203
Epoch [35/50] - Loss: 0.0181
Epoch [36/50] - Loss: 0.0161
Epoch [37/50] - Loss: 0.0193
Epoch [38/50] - Loss: 0.0140
Epoch [39/50] - Loss: 0.0136
Epoch [40/50] - Loss: 0.0131
Epoch [41/50] - Loss: 0.0125
Epoch [42/50] - Loss: 0.0118
Epoch [43/50] - Loss: 0.0112
Epoch [44/50] - Loss: 0.0105
Epoch [45/50] - Loss: 0.0097
Epoch [46/50] - Loss: 0.0090
Epoch [47/50] - Loss: 0.0083
Epoch [48/50] - Loss: 0.0112
Epoch [49/50] - Loss: 0.0077
Epoch [50/50] - Loss: 0.0077
sum preds 558
sum labels 491
 - Test Metrics: Accuracy=0.9122, F1=0.8008, Recall=0.8554, Precision=0.7527
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_nnpu_nnpu_1804095035.csv.
Average F1 over valid seeds: 0.8162 ± 0.0127
___________________________________________________________________________________
Avg F1 for cora with SAR and nnpu, GATConv,0.4: 0.8162 ± 0.0127
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4948
Epoch [2/50] - Loss: 0.4620
Epoch [3/50] - Loss: 0.4308
Epoch [4/50] - Loss: 0.4006
Epoch [5/50] - Loss: 0.3728
Epoch [6/50] - Loss: 0.3478
Epoch [7/50] - Loss: 0.3259
Epoch [8/50] - Loss: 0.3066
Epoch [9/50] - Loss: 0.2892
Epoch [10/50] - Loss: 0.2729
Epoch [11/50] - Loss: 0.2572
Epoch [12/50] - Loss: 0.2420
Epoch [13/50] - Loss: 0.2266
Epoch [14/50] - Loss: 0.2107
Epoch [15/50] - Loss: 0.1943
Epoch [16/50] - Loss: 0.1777
Epoch [17/50] - Loss: 0.1614
Epoch [18/50] - Loss: 0.1461
Epoch [19/50] - Loss: 0.1321
Epoch [20/50] - Loss: 0.1194
Epoch [21/50] - Loss: 0.1080
Epoch [22/50] - Loss: 0.0977
Epoch [23/50] - Loss: 0.0880
Epoch [24/50] - Loss: 0.0788
Epoch [25/50] - Loss: 0.0717
Epoch [26/50] - Loss: 0.0671
Epoch [27/50] - Loss: 0.0622
Epoch [28/50] - Loss: 0.0562
Epoch [29/50] - Loss: 0.0528
Epoch [30/50] - Loss: 0.0498
Epoch [31/50] - Loss: 0.0462
Epoch [32/50] - Loss: 0.0421
Epoch [33/50] - Loss: 0.0409
Epoch [34/50] - Loss: 0.0387
Epoch [35/50] - Loss: 0.0350
Epoch [36/50] - Loss: 0.0339
Epoch [37/50] - Loss: 0.0323
Epoch [38/50] - Loss: 0.0304
Epoch [39/50] - Loss: 0.0283
Epoch [40/50] - Loss: 0.0308
Epoch [41/50] - Loss: 0.0282
Epoch [42/50] - Loss: 0.0260
Epoch [43/50] - Loss: 0.0261
Epoch [44/50] - Loss: 0.0258
Epoch [45/50] - Loss: 0.0252
Epoch [46/50] - Loss: 0.0243
Epoch [47/50] - Loss: 0.0232
Epoch [48/50] - Loss: 0.0218
Epoch [49/50] - Loss: 0.0204
Epoch [50/50] - Loss: 0.0189
sum preds 598
sum labels 491
 - Test Metrics: Accuracy=0.9248, F1=0.8356, Recall=0.9267, Precision=0.7609
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4934
Epoch [2/50] - Loss: 0.4565
Epoch [3/50] - Loss: 0.4206
Epoch [4/50] - Loss: 0.3867
Epoch [5/50] - Loss: 0.3570
Epoch [6/50] - Loss: 0.3323
Epoch [7/50] - Loss: 0.3124
Epoch [8/50] - Loss: 0.2965
Epoch [9/50] - Loss: 0.2834
Epoch [10/50] - Loss: 0.2723
Epoch [11/50] - Loss: 0.2622
Epoch [12/50] - Loss: 0.2522
Epoch [13/50] - Loss: 0.2415
Epoch [14/50] - Loss: 0.2294
Epoch [15/50] - Loss: 0.2156
Epoch [16/50] - Loss: 0.2003
Epoch [17/50] - Loss: 0.1844
Epoch [18/50] - Loss: 0.1697
Epoch [19/50] - Loss: 0.1537
Epoch [20/50] - Loss: 0.1397
Epoch [21/50] - Loss: 0.1292
Epoch [22/50] - Loss: 0.1205
Epoch [23/50] - Loss: 0.1130
Epoch [24/50] - Loss: 0.1059
Epoch [25/50] - Loss: 0.0985
Epoch [26/50] - Loss: 0.0902
Epoch [27/50] - Loss: 0.0808
Epoch [28/50] - Loss: 0.0706
Epoch [29/50] - Loss: 0.0642
Epoch [30/50] - Loss: 0.0616
Epoch [31/50] - Loss: 0.0580
Epoch [32/50] - Loss: 0.0538
Epoch [33/50] - Loss: 0.0490
Epoch [34/50] - Loss: 0.0441
Epoch [35/50] - Loss: 0.0397
Epoch [36/50] - Loss: 0.0383
Epoch [37/50] - Loss: 0.0351
Epoch [38/50] - Loss: 0.0335
Epoch [39/50] - Loss: 0.0315
Epoch [40/50] - Loss: 0.0298
Epoch [41/50] - Loss: 0.0287
Epoch [42/50] - Loss: 0.0276
Epoch [43/50] - Loss: 0.0263
Epoch [44/50] - Loss: 0.0248
Epoch [45/50] - Loss: 0.0254
Epoch [46/50] - Loss: 0.0228
Epoch [47/50] - Loss: 0.0222
Epoch [48/50] - Loss: 0.0214
Epoch [49/50] - Loss: 0.0204
Epoch [50/50] - Loss: 0.0215
sum preds 578
sum labels 491
 - Test Metrics: Accuracy=0.9332, F1=0.8513, Recall=0.9267, Precision=0.7872
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4936
Epoch [2/50] - Loss: 0.4653
Epoch [3/50] - Loss: 0.4331
Epoch [4/50] - Loss: 0.4005
Epoch [5/50] - Loss: 0.3698
Epoch [6/50] - Loss: 0.3421
Epoch [7/50] - Loss: 0.3177
Epoch [8/50] - Loss: 0.2964
Epoch [9/50] - Loss: 0.2779
Epoch [10/50] - Loss: 0.2614
Epoch [11/50] - Loss: 0.2466
Epoch [12/50] - Loss: 0.2326
Epoch [13/50] - Loss: 0.2188
Epoch [14/50] - Loss: 0.2049
Epoch [15/50] - Loss: 0.1907
Epoch [16/50] - Loss: 0.1761
Epoch [17/50] - Loss: 0.1614
Epoch [18/50] - Loss: 0.1496
Epoch [19/50] - Loss: 0.1367
Epoch [20/50] - Loss: 0.1227
Epoch [21/50] - Loss: 0.1137
Epoch [22/50] - Loss: 0.1074
Epoch [23/50] - Loss: 0.1021
Epoch [24/50] - Loss: 0.0964
Epoch [25/50] - Loss: 0.0897
Epoch [26/50] - Loss: 0.0819
Epoch [27/50] - Loss: 0.0731
Epoch [28/50] - Loss: 0.0688
Epoch [29/50] - Loss: 0.0668
Epoch [30/50] - Loss: 0.0637
Epoch [31/50] - Loss: 0.0598
Epoch [32/50] - Loss: 0.0554
Epoch [33/50] - Loss: 0.0507
Epoch [34/50] - Loss: 0.0460
Epoch [35/50] - Loss: 0.0447
Epoch [36/50] - Loss: 0.0416
Epoch [37/50] - Loss: 0.0398
Epoch [38/50] - Loss: 0.0375
Epoch [39/50] - Loss: 0.0376
Epoch [40/50] - Loss: 0.0342
Epoch [41/50] - Loss: 0.0342
Epoch [42/50] - Loss: 0.0339
Epoch [43/50] - Loss: 0.0332
Epoch [44/50] - Loss: 0.0321
Epoch [45/50] - Loss: 0.0306
Epoch [46/50] - Loss: 0.0290
Epoch [47/50] - Loss: 0.0272
Epoch [48/50] - Loss: 0.0254
Epoch [49/50] - Loss: 0.0264
Epoch [50/50] - Loss: 0.0248
sum preds 561
sum labels 491
 - Test Metrics: Accuracy=0.9227, F1=0.8251, Recall=0.8839, Precision=0.7736
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_nnpu_nnpu_1804095037.csv.
Average F1 over valid seeds: 0.8373 ± 0.0108
___________________________________________________________________________________
Avg F1 for cora with SAR and nnpu, GCNConv,0.4: 0.8373 ± 0.0108
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5233
Epoch [2/50] - Loss: 0.5109
Epoch [3/50] - Loss: 0.4970
Epoch [4/50] - Loss: 0.4807
Epoch [5/50] - Loss: 0.4625
Epoch [6/50] - Loss: 0.4428
Epoch [7/50] - Loss: 0.4220
Epoch [8/50] - Loss: 0.4001
Epoch [9/50] - Loss: 0.3773
Epoch [10/50] - Loss: 0.3539
Epoch [11/50] - Loss: 0.3302
Epoch [12/50] - Loss: 0.3065
Epoch [13/50] - Loss: 0.2830
Epoch [14/50] - Loss: 0.2600
Epoch [15/50] - Loss: 0.2375
Epoch [16/50] - Loss: 0.2157
Epoch [17/50] - Loss: 0.1946
Epoch [18/50] - Loss: 0.1743
Epoch [19/50] - Loss: 0.1547
Epoch [20/50] - Loss: 0.1358
Epoch [21/50] - Loss: 0.1178
Epoch [22/50] - Loss: 0.1057
Epoch [23/50] - Loss: 0.0978
Epoch [24/50] - Loss: 0.0889
Epoch [25/50] - Loss: 0.0794
Epoch [26/50] - Loss: 0.0699
Epoch [27/50] - Loss: 0.0609
Epoch [28/50] - Loss: 0.0536
Epoch [29/50] - Loss: 0.0518
Epoch [30/50] - Loss: 0.0457
Epoch [31/50] - Loss: 0.0422
Epoch [32/50] - Loss: 0.0401
Epoch [33/50] - Loss: 0.0377
Epoch [34/50] - Loss: 0.0350
Epoch [35/50] - Loss: 0.0322
Epoch [36/50] - Loss: 0.0294
Epoch [37/50] - Loss: 0.0267
Epoch [38/50] - Loss: 0.0242
Epoch [39/50] - Loss: 0.0259
Epoch [40/50] - Loss: 0.0213
Epoch [41/50] - Loss: 0.0210
Epoch [42/50] - Loss: 0.0209
Epoch [43/50] - Loss: 0.0206
Epoch [44/50] - Loss: 0.0201
Epoch [45/50] - Loss: 0.0195
Epoch [46/50] - Loss: 0.0188
Epoch [47/50] - Loss: 0.0180
Epoch [48/50] - Loss: 0.0171
Epoch [49/50] - Loss: 0.0162
Epoch [50/50] - Loss: 0.0153
sum preds 514
sum labels 573
 - Test Metrics: Accuracy=0.8469, F1=0.6532, Recall=0.6195, Precision=0.6907
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4976
Epoch [2/50] - Loss: 0.4833
Epoch [3/50] - Loss: 0.4680
Epoch [4/50] - Loss: 0.4504
Epoch [5/50] - Loss: 0.4310
Epoch [6/50] - Loss: 0.4104
Epoch [7/50] - Loss: 0.3891
Epoch [8/50] - Loss: 0.3672
Epoch [9/50] - Loss: 0.3449
Epoch [10/50] - Loss: 0.3222
Epoch [11/50] - Loss: 0.2993
Epoch [12/50] - Loss: 0.2763
Epoch [13/50] - Loss: 0.2535
Epoch [14/50] - Loss: 0.2310
Epoch [15/50] - Loss: 0.2087
Epoch [16/50] - Loss: 0.1870
Epoch [17/50] - Loss: 0.1657
Epoch [18/50] - Loss: 0.1450
Epoch [19/50] - Loss: 0.1250
Epoch [20/50] - Loss: 0.1057
Epoch [21/50] - Loss: 0.0942
Epoch [22/50] - Loss: 0.0854
Epoch [23/50] - Loss: 0.0758
Epoch [24/50] - Loss: 0.0660
Epoch [25/50] - Loss: 0.0567
Epoch [26/50] - Loss: 0.0481
Epoch [27/50] - Loss: 0.0458
Epoch [28/50] - Loss: 0.0441
Epoch [29/50] - Loss: 0.0364
Epoch [30/50] - Loss: 0.0330
Epoch [31/50] - Loss: 0.0317
Epoch [32/50] - Loss: 0.0301
Epoch [33/50] - Loss: 0.0283
Epoch [34/50] - Loss: 0.0264
Epoch [35/50] - Loss: 0.0244
Epoch [36/50] - Loss: 0.0223
Epoch [37/50] - Loss: 0.0204
Epoch [38/50] - Loss: 0.0185
Epoch [39/50] - Loss: 0.0168
Epoch [40/50] - Loss: 0.0153
Epoch [41/50] - Loss: 0.0139
Epoch [42/50] - Loss: 0.0127
Epoch [43/50] - Loss: 0.0184
Epoch [44/50] - Loss: 0.0124
Epoch [45/50] - Loss: 0.0116
Epoch [46/50] - Loss: 0.0118
Epoch [47/50] - Loss: 0.0119
Epoch [48/50] - Loss: 0.0120
Epoch [49/50] - Loss: 0.0120
Epoch [50/50] - Loss: 0.0119
sum preds 462
sum labels 573
 - Test Metrics: Accuracy=0.8559, F1=0.6570, Recall=0.5934, Precision=0.7359
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5211
Epoch [2/50] - Loss: 0.5098
Epoch [3/50] - Loss: 0.4991
Epoch [4/50] - Loss: 0.4866
Epoch [5/50] - Loss: 0.4724
Epoch [6/50] - Loss: 0.4567
Epoch [7/50] - Loss: 0.4395
Epoch [8/50] - Loss: 0.4212
Epoch [9/50] - Loss: 0.4018
Epoch [10/50] - Loss: 0.3812
Epoch [11/50] - Loss: 0.3596
Epoch [12/50] - Loss: 0.3371
Epoch [13/50] - Loss: 0.3138
Epoch [14/50] - Loss: 0.2902
Epoch [15/50] - Loss: 0.2662
Epoch [16/50] - Loss: 0.2423
Epoch [17/50] - Loss: 0.2186
Epoch [18/50] - Loss: 0.1953
Epoch [19/50] - Loss: 0.1727
Epoch [20/50] - Loss: 0.1508
Epoch [21/50] - Loss: 0.1298
Epoch [22/50] - Loss: 0.1098
Epoch [23/50] - Loss: 0.0908
Epoch [24/50] - Loss: 0.0745
Epoch [25/50] - Loss: 0.0690
Epoch [26/50] - Loss: 0.0625
Epoch [27/50] - Loss: 0.0556
Epoch [28/50] - Loss: 0.0487
Epoch [29/50] - Loss: 0.0423
Epoch [30/50] - Loss: 0.0366
Epoch [31/50] - Loss: 0.0331
Epoch [32/50] - Loss: 0.0306
Epoch [33/50] - Loss: 0.0279
Epoch [34/50] - Loss: 0.0266
Epoch [35/50] - Loss: 0.0252
Epoch [36/50] - Loss: 0.0237
Epoch [37/50] - Loss: 0.0222
Epoch [38/50] - Loss: 0.0206
Epoch [39/50] - Loss: 0.0191
Epoch [40/50] - Loss: 0.0177
Epoch [41/50] - Loss: 0.0163
Epoch [42/50] - Loss: 0.0151
Epoch [43/50] - Loss: 0.0147
Epoch [44/50] - Loss: 0.0136
Epoch [45/50] - Loss: 0.0133
Epoch [46/50] - Loss: 0.0129
Epoch [47/50] - Loss: 0.0125
Epoch [48/50] - Loss: 0.0120
Epoch [49/50] - Loss: 0.0115
Epoch [50/50] - Loss: 0.0111
sum preds 546
sum labels 573
 - Test Metrics: Accuracy=0.8518, F1=0.6738, Recall=0.6579, Precision=0.6905
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_nnpu_nnpu_1804095038.csv.
Average F1 over valid seeds: 0.6613 ± 0.0090
___________________________________________________________________________________
Avg F1 for cora with SAR and nnpu, MLP,0.3: 0.6613 ± 0.0090
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4949
Epoch [2/50] - Loss: 0.4582
Epoch [3/50] - Loss: 0.4237
Epoch [4/50] - Loss: 0.3913
Epoch [5/50] - Loss: 0.3618
Epoch [6/50] - Loss: 0.3354
Epoch [7/50] - Loss: 0.3122
Epoch [8/50] - Loss: 0.2918
Epoch [9/50] - Loss: 0.2735
Epoch [10/50] - Loss: 0.2564
Epoch [11/50] - Loss: 0.2397
Epoch [12/50] - Loss: 0.2227
Epoch [13/50] - Loss: 0.2047
Epoch [14/50] - Loss: 0.1859
Epoch [15/50] - Loss: 0.1665
Epoch [16/50] - Loss: 0.1510
Epoch [17/50] - Loss: 0.1337
Epoch [18/50] - Loss: 0.1152
Epoch [19/50] - Loss: 0.1061
Epoch [20/50] - Loss: 0.0999
Epoch [21/50] - Loss: 0.0936
Epoch [22/50] - Loss: 0.0852
Epoch [23/50] - Loss: 0.0743
Epoch [24/50] - Loss: 0.0621
Epoch [25/50] - Loss: 0.0591
Epoch [26/50] - Loss: 0.0573
Epoch [27/50] - Loss: 0.0542
Epoch [28/50] - Loss: 0.0502
Epoch [29/50] - Loss: 0.0456
Epoch [30/50] - Loss: 0.0408
Epoch [31/50] - Loss: 0.0361
Epoch [32/50] - Loss: 0.0317
Epoch [33/50] - Loss: 0.0345
Epoch [34/50] - Loss: 0.0341
Epoch [35/50] - Loss: 0.0277
Epoch [36/50] - Loss: 0.0255
Epoch [37/50] - Loss: 0.0258
Epoch [38/50] - Loss: 0.0255
Epoch [39/50] - Loss: 0.0249
Epoch [40/50] - Loss: 0.0238
Epoch [41/50] - Loss: 0.0226
Epoch [42/50] - Loss: 0.0211
Epoch [43/50] - Loss: 0.0196
Epoch [44/50] - Loss: 0.0180
Epoch [45/50] - Loss: 0.0164
Epoch [46/50] - Loss: 0.0150
Epoch [47/50] - Loss: 0.0136
Epoch [48/50] - Loss: 0.0162
Epoch [49/50] - Loss: 0.0139
Epoch [50/50] - Loss: 0.0124
sum preds 622
sum labels 573
 - Test Metrics: Accuracy=0.9200, F1=0.8351, Recall=0.8709, Precision=0.8023
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5052
Epoch [2/50] - Loss: 0.4825
Epoch [3/50] - Loss: 0.4617
Epoch [4/50] - Loss: 0.4397
Epoch [5/50] - Loss: 0.4169
Epoch [6/50] - Loss: 0.3939
Epoch [7/50] - Loss: 0.3713
Epoch [8/50] - Loss: 0.3495
Epoch [9/50] - Loss: 0.3286
Epoch [10/50] - Loss: 0.3086
Epoch [11/50] - Loss: 0.2895
Epoch [12/50] - Loss: 0.2711
Epoch [13/50] - Loss: 0.2531
Epoch [14/50] - Loss: 0.2351
Epoch [15/50] - Loss: 0.2173
Epoch [16/50] - Loss: 0.1995
Epoch [17/50] - Loss: 0.1819
Epoch [18/50] - Loss: 0.1648
Epoch [19/50] - Loss: 0.1484
Epoch [20/50] - Loss: 0.1331
Epoch [21/50] - Loss: 0.1189
Epoch [22/50] - Loss: 0.1059
Epoch [23/50] - Loss: 0.0938
Epoch [24/50] - Loss: 0.0824
Epoch [25/50] - Loss: 0.0716
Epoch [26/50] - Loss: 0.0645
Epoch [27/50] - Loss: 0.0582
Epoch [28/50] - Loss: 0.0513
Epoch [29/50] - Loss: 0.0463
Epoch [30/50] - Loss: 0.0429
Epoch [31/50] - Loss: 0.0376
Epoch [32/50] - Loss: 0.0348
Epoch [33/50] - Loss: 0.0319
Epoch [34/50] - Loss: 0.0301
Epoch [35/50] - Loss: 0.0281
Epoch [36/50] - Loss: 0.0259
Epoch [37/50] - Loss: 0.0236
Epoch [38/50] - Loss: 0.0253
Epoch [39/50] - Loss: 0.0216
Epoch [40/50] - Loss: 0.0210
Epoch [41/50] - Loss: 0.0210
Epoch [42/50] - Loss: 0.0206
Epoch [43/50] - Loss: 0.0200
Epoch [44/50] - Loss: 0.0191
Epoch [45/50] - Loss: 0.0179
Epoch [46/50] - Loss: 0.0165
Epoch [47/50] - Loss: 0.0151
Epoch [48/50] - Loss: 0.0136
Epoch [49/50] - Loss: 0.0123
Epoch [50/50] - Loss: 0.0111
sum preds 663
sum labels 573
 - Test Metrics: Accuracy=0.9131, F1=0.8269, Recall=0.8918, Precision=0.7707
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4982
Epoch [2/50] - Loss: 0.4663
Epoch [3/50] - Loss: 0.4335
Epoch [4/50] - Loss: 0.3998
Epoch [5/50] - Loss: 0.3676
Epoch [6/50] - Loss: 0.3380
Epoch [7/50] - Loss: 0.3113
Epoch [8/50] - Loss: 0.2872
Epoch [9/50] - Loss: 0.2650
Epoch [10/50] - Loss: 0.2444
Epoch [11/50] - Loss: 0.2249
Epoch [12/50] - Loss: 0.2059
Epoch [13/50] - Loss: 0.1871
Epoch [14/50] - Loss: 0.1686
Epoch [15/50] - Loss: 0.1512
Epoch [16/50] - Loss: 0.1382
Epoch [17/50] - Loss: 0.1240
Epoch [18/50] - Loss: 0.1094
Epoch [19/50] - Loss: 0.0995
Epoch [20/50] - Loss: 0.0900
Epoch [21/50] - Loss: 0.0800
Epoch [22/50] - Loss: 0.0722
Epoch [23/50] - Loss: 0.0655
Epoch [24/50] - Loss: 0.0585
Epoch [25/50] - Loss: 0.0549
Epoch [26/50] - Loss: 0.0491
Epoch [27/50] - Loss: 0.0447
Epoch [28/50] - Loss: 0.0416
Epoch [29/50] - Loss: 0.0382
Epoch [30/50] - Loss: 0.0346
Epoch [31/50] - Loss: 0.0311
Epoch [32/50] - Loss: 0.0278
Epoch [33/50] - Loss: 0.0287
Epoch [34/50] - Loss: 0.0235
Epoch [35/50] - Loss: 0.0221
Epoch [36/50] - Loss: 0.0205
Epoch [37/50] - Loss: 0.0189
Epoch [38/50] - Loss: 0.0173
Epoch [39/50] - Loss: 0.0176
Epoch [40/50] - Loss: 0.0155
Epoch [41/50] - Loss: 0.0151
Epoch [42/50] - Loss: 0.0146
Epoch [43/50] - Loss: 0.0141
Epoch [44/50] - Loss: 0.0135
Epoch [45/50] - Loss: 0.0129
Epoch [46/50] - Loss: 0.0122
Epoch [47/50] - Loss: 0.0115
Epoch [48/50] - Loss: 0.0109
Epoch [49/50] - Loss: 0.0102
Epoch [50/50] - Loss: 0.0095
sum preds 585
sum labels 573
 - Test Metrics: Accuracy=0.9058, F1=0.7997, Recall=0.8080, Precision=0.7915
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_nnpu_nnpu_1804095039.csv.
Average F1 over valid seeds: 0.8206 ± 0.0152
___________________________________________________________________________________
Avg F1 for cora with SAR and nnpu, GATConv,0.3: 0.8206 ± 0.0152
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4951
Epoch [2/50] - Loss: 0.4632
Epoch [3/50] - Loss: 0.4327
Epoch [4/50] - Loss: 0.4032
Epoch [5/50] - Loss: 0.3757
Epoch [6/50] - Loss: 0.3510
Epoch [7/50] - Loss: 0.3294
Epoch [8/50] - Loss: 0.3105
Epoch [9/50] - Loss: 0.2938
Epoch [10/50] - Loss: 0.2784
Epoch [11/50] - Loss: 0.2634
Epoch [12/50] - Loss: 0.2485
Epoch [13/50] - Loss: 0.2333
Epoch [14/50] - Loss: 0.2178
Epoch [15/50] - Loss: 0.2017
Epoch [16/50] - Loss: 0.1852
Epoch [17/50] - Loss: 0.1689
Epoch [18/50] - Loss: 0.1533
Epoch [19/50] - Loss: 0.1389
Epoch [20/50] - Loss: 0.1262
Epoch [21/50] - Loss: 0.1149
Epoch [22/50] - Loss: 0.1047
Epoch [23/50] - Loss: 0.0951
Epoch [24/50] - Loss: 0.0860
Epoch [25/50] - Loss: 0.0771
Epoch [26/50] - Loss: 0.0726
Epoch [27/50] - Loss: 0.0677
Epoch [28/50] - Loss: 0.0617
Epoch [29/50] - Loss: 0.0553
Epoch [30/50] - Loss: 0.0547
Epoch [31/50] - Loss: 0.0531
Epoch [32/50] - Loss: 0.0489
Epoch [33/50] - Loss: 0.0424
Epoch [34/50] - Loss: 0.0428
Epoch [35/50] - Loss: 0.0426
Epoch [36/50] - Loss: 0.0415
Epoch [37/50] - Loss: 0.0397
Epoch [38/50] - Loss: 0.0374
Epoch [39/50] - Loss: 0.0348
Epoch [40/50] - Loss: 0.0320
Epoch [41/50] - Loss: 0.0291
Epoch [42/50] - Loss: 0.0284
Epoch [43/50] - Loss: 0.0281
Epoch [44/50] - Loss: 0.0249
Epoch [45/50] - Loss: 0.0245
Epoch [46/50] - Loss: 0.0237
Epoch [47/50] - Loss: 0.0227
Epoch [48/50] - Loss: 0.0215
Epoch [49/50] - Loss: 0.0206
Epoch [50/50] - Loss: 0.0201
sum preds 605
sum labels 573
 - Test Metrics: Accuracy=0.9310, F1=0.8557, Recall=0.8796, Precision=0.8331
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4938
Epoch [2/50] - Loss: 0.4570
Epoch [3/50] - Loss: 0.4211
Epoch [4/50] - Loss: 0.3871
Epoch [5/50] - Loss: 0.3571
Epoch [6/50] - Loss: 0.3320
Epoch [7/50] - Loss: 0.3115
Epoch [8/50] - Loss: 0.2950
Epoch [9/50] - Loss: 0.2814
Epoch [10/50] - Loss: 0.2698
Epoch [11/50] - Loss: 0.2591
Epoch [12/50] - Loss: 0.2484
Epoch [13/50] - Loss: 0.2372
Epoch [14/50] - Loss: 0.2249
Epoch [15/50] - Loss: 0.2114
Epoch [16/50] - Loss: 0.1965
Epoch [17/50] - Loss: 0.1825
Epoch [18/50] - Loss: 0.1677
Epoch [19/50] - Loss: 0.1513
Epoch [20/50] - Loss: 0.1358
Epoch [21/50] - Loss: 0.1256
Epoch [22/50] - Loss: 0.1176
Epoch [23/50] - Loss: 0.1109
Epoch [24/50] - Loss: 0.1044
Epoch [25/50] - Loss: 0.0974
Epoch [26/50] - Loss: 0.0890
Epoch [27/50] - Loss: 0.0794
Epoch [28/50] - Loss: 0.0692
Epoch [29/50] - Loss: 0.0653
Epoch [30/50] - Loss: 0.0631
Epoch [31/50] - Loss: 0.0598
Epoch [32/50] - Loss: 0.0557
Epoch [33/50] - Loss: 0.0511
Epoch [34/50] - Loss: 0.0462
Epoch [35/50] - Loss: 0.0413
Epoch [36/50] - Loss: 0.0404
Epoch [37/50] - Loss: 0.0401
Epoch [38/50] - Loss: 0.0359
Epoch [39/50] - Loss: 0.0327
Epoch [40/50] - Loss: 0.0323
Epoch [41/50] - Loss: 0.0314
Epoch [42/50] - Loss: 0.0301
Epoch [43/50] - Loss: 0.0284
Epoch [44/50] - Loss: 0.0264
Epoch [45/50] - Loss: 0.0244
Epoch [46/50] - Loss: 0.0230
Epoch [47/50] - Loss: 0.0215
Epoch [48/50] - Loss: 0.0209
Epoch [49/50] - Loss: 0.0207
Epoch [50/50] - Loss: 0.0205
sum preds 598
sum labels 573
 - Test Metrics: Accuracy=0.9322, F1=0.8574, Recall=0.8761, Precision=0.8395
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4939
Epoch [2/50] - Loss: 0.4658
Epoch [3/50] - Loss: 0.4339
Epoch [4/50] - Loss: 0.4016
Epoch [5/50] - Loss: 0.3711
Epoch [6/50] - Loss: 0.3437
Epoch [7/50] - Loss: 0.3196
Epoch [8/50] - Loss: 0.2987
Epoch [9/50] - Loss: 0.2805
Epoch [10/50] - Loss: 0.2645
Epoch [11/50] - Loss: 0.2500
Epoch [12/50] - Loss: 0.2365
Epoch [13/50] - Loss: 0.2232
Epoch [14/50] - Loss: 0.2099
Epoch [15/50] - Loss: 0.1962
Epoch [16/50] - Loss: 0.1822
Epoch [17/50] - Loss: 0.1681
Epoch [18/50] - Loss: 0.1544
Epoch [19/50] - Loss: 0.1416
Epoch [20/50] - Loss: 0.1297
Epoch [21/50] - Loss: 0.1202
Epoch [22/50] - Loss: 0.1123
Epoch [23/50] - Loss: 0.1052
Epoch [24/50] - Loss: 0.0984
Epoch [25/50] - Loss: 0.0913
Epoch [26/50] - Loss: 0.0838
Epoch [27/50] - Loss: 0.0769
Epoch [28/50] - Loss: 0.0731
Epoch [29/50] - Loss: 0.0684
Epoch [30/50] - Loss: 0.0631
Epoch [31/50] - Loss: 0.0625
Epoch [32/50] - Loss: 0.0601
Epoch [33/50] - Loss: 0.0556
Epoch [34/50] - Loss: 0.0514
Epoch [35/50] - Loss: 0.0500
Epoch [36/50] - Loss: 0.0480
Epoch [37/50] - Loss: 0.0454
Epoch [38/50] - Loss: 0.0424
Epoch [39/50] - Loss: 0.0415
Epoch [40/50] - Loss: 0.0396
Epoch [41/50] - Loss: 0.0374
Epoch [42/50] - Loss: 0.0365
Epoch [43/50] - Loss: 0.0352
Epoch [44/50] - Loss: 0.0336
Epoch [45/50] - Loss: 0.0317
Epoch [46/50] - Loss: 0.0315
Epoch [47/50] - Loss: 0.0292
Epoch [48/50] - Loss: 0.0293
Epoch [49/50] - Loss: 0.0292
Epoch [50/50] - Loss: 0.0287
sum preds 580
sum labels 573
 - Test Metrics: Accuracy=0.9184, F1=0.8257, Recall=0.8307, Precision=0.8207
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_nnpu_nnpu_1804095042.csv.
Average F1 over valid seeds: 0.8462 ± 0.0146
___________________________________________________________________________________
Avg F1 for cora with SAR and nnpu, GCNConv,0.3: 0.8462 ± 0.0146
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5232
Epoch [2/50] - Loss: 0.5098
Epoch [3/50] - Loss: 0.4945
Epoch [4/50] - Loss: 0.4768
Epoch [5/50] - Loss: 0.4573
Epoch [6/50] - Loss: 0.4361
Epoch [7/50] - Loss: 0.4137
Epoch [8/50] - Loss: 0.3901
Epoch [9/50] - Loss: 0.3656
Epoch [10/50] - Loss: 0.3402
Epoch [11/50] - Loss: 0.3144
Epoch [12/50] - Loss: 0.2884
Epoch [13/50] - Loss: 0.2625
Epoch [14/50] - Loss: 0.2369
Epoch [15/50] - Loss: 0.2119
Epoch [16/50] - Loss: 0.1875
Epoch [17/50] - Loss: 0.1639
Epoch [18/50] - Loss: 0.1412
Epoch [19/50] - Loss: 0.1193
Epoch [20/50] - Loss: 0.0991
Epoch [21/50] - Loss: 0.0916
Epoch [22/50] - Loss: 0.0830
Epoch [23/50] - Loss: 0.0739
Epoch [24/50] - Loss: 0.0648
Epoch [25/50] - Loss: 0.0560
Epoch [26/50] - Loss: 0.0479
Epoch [27/50] - Loss: 0.0405
Epoch [28/50] - Loss: 0.0413
Epoch [29/50] - Loss: 0.0397
Epoch [30/50] - Loss: 0.0309
Epoch [31/50] - Loss: 0.0278
Epoch [32/50] - Loss: 0.0268
Epoch [33/50] - Loss: 0.0256
Epoch [34/50] - Loss: 0.0242
Epoch [35/50] - Loss: 0.0226
Epoch [36/50] - Loss: 0.0209
Epoch [37/50] - Loss: 0.0193
Epoch [38/50] - Loss: 0.0177
Epoch [39/50] - Loss: 0.0161
Epoch [40/50] - Loss: 0.0147
Epoch [41/50] - Loss: 0.0134
Epoch [42/50] - Loss: 0.0122
Epoch [43/50] - Loss: 0.0111
Epoch [44/50] - Loss: 0.0102
Epoch [45/50] - Loss: 0.0094
Epoch [46/50] - Loss: 0.0086
Epoch [47/50] - Loss: 0.0080
Epoch [48/50] - Loss: 0.0090
Epoch [49/50] - Loss: 0.0073
Epoch [50/50] - Loss: 0.0072
sum preds 589
sum labels 654
 - Test Metrics: Accuracy=0.8164, F1=0.6243, Recall=0.5933, Precision=0.6587
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4976
Epoch [2/50] - Loss: 0.4825
Epoch [3/50] - Loss: 0.4665
Epoch [4/50] - Loss: 0.4481
Epoch [5/50] - Loss: 0.4281
Epoch [6/50] - Loss: 0.4068
Epoch [7/50] - Loss: 0.3846
Epoch [8/50] - Loss: 0.3616
Epoch [9/50] - Loss: 0.3380
Epoch [10/50] - Loss: 0.3139
Epoch [11/50] - Loss: 0.2894
Epoch [12/50] - Loss: 0.2647
Epoch [13/50] - Loss: 0.2399
Epoch [14/50] - Loss: 0.2154
Epoch [15/50] - Loss: 0.1912
Epoch [16/50] - Loss: 0.1675
Epoch [17/50] - Loss: 0.1444
Epoch [18/50] - Loss: 0.1221
Epoch [19/50] - Loss: 0.1008
Epoch [20/50] - Loss: 0.0896
Epoch [21/50] - Loss: 0.0816
Epoch [22/50] - Loss: 0.0728
Epoch [23/50] - Loss: 0.0640
Epoch [24/50] - Loss: 0.0554
Epoch [25/50] - Loss: 0.0475
Epoch [26/50] - Loss: 0.0405
Epoch [27/50] - Loss: 0.0343
Epoch [28/50] - Loss: 0.0383
Epoch [29/50] - Loss: 0.0361
Epoch [30/50] - Loss: 0.0255
Epoch [31/50] - Loss: 0.0250
Epoch [32/50] - Loss: 0.0246
Epoch [33/50] - Loss: 0.0239
Epoch [34/50] - Loss: 0.0231
Epoch [35/50] - Loss: 0.0221
Epoch [36/50] - Loss: 0.0210
Epoch [37/50] - Loss: 0.0198
Epoch [38/50] - Loss: 0.0186
Epoch [39/50] - Loss: 0.0174
Epoch [40/50] - Loss: 0.0162
Epoch [41/50] - Loss: 0.0151
Epoch [42/50] - Loss: 0.0140
Epoch [43/50] - Loss: 0.0129
Epoch [44/50] - Loss: 0.0119
Epoch [45/50] - Loss: 0.0110
Epoch [46/50] - Loss: 0.0101
Epoch [47/50] - Loss: 0.0093
Epoch [48/50] - Loss: 0.0086
Epoch [49/50] - Loss: 0.0079
Epoch [50/50] - Loss: 0.0072
sum preds 567
sum labels 654
 - Test Metrics: Accuracy=0.8392, F1=0.6650, Recall=0.6208, Precision=0.7160
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5213
Epoch [2/50] - Loss: 0.5092
Epoch [3/50] - Loss: 0.4975
Epoch [4/50] - Loss: 0.4840
Epoch [5/50] - Loss: 0.4688
Epoch [6/50] - Loss: 0.4521
Epoch [7/50] - Loss: 0.4341
Epoch [8/50] - Loss: 0.4149
Epoch [9/50] - Loss: 0.3945
Epoch [10/50] - Loss: 0.3729
Epoch [11/50] - Loss: 0.3503
Epoch [12/50] - Loss: 0.3268
Epoch [13/50] - Loss: 0.3025
Epoch [14/50] - Loss: 0.2778
Epoch [15/50] - Loss: 0.2529
Epoch [16/50] - Loss: 0.2281
Epoch [17/50] - Loss: 0.2037
Epoch [18/50] - Loss: 0.1797
Epoch [19/50] - Loss: 0.1564
Epoch [20/50] - Loss: 0.1339
Epoch [21/50] - Loss: 0.1123
Epoch [22/50] - Loss: 0.0917
Epoch [23/50] - Loss: 0.0731
Epoch [24/50] - Loss: 0.0683
Epoch [25/50] - Loss: 0.0626
Epoch [26/50] - Loss: 0.0564
Epoch [27/50] - Loss: 0.0501
Epoch [28/50] - Loss: 0.0440
Epoch [29/50] - Loss: 0.0383
Epoch [30/50] - Loss: 0.0332
Epoch [31/50] - Loss: 0.0287
Epoch [32/50] - Loss: 0.0267
Epoch [33/50] - Loss: 0.0237
Epoch [34/50] - Loss: 0.0223
Epoch [35/50] - Loss: 0.0214
Epoch [36/50] - Loss: 0.0205
Epoch [37/50] - Loss: 0.0194
Epoch [38/50] - Loss: 0.0183
Epoch [39/50] - Loss: 0.0172
Epoch [40/50] - Loss: 0.0160
Epoch [41/50] - Loss: 0.0149
Epoch [42/50] - Loss: 0.0139
Epoch [43/50] - Loss: 0.0129
Epoch [44/50] - Loss: 0.0120
Epoch [45/50] - Loss: 0.0111
Epoch [46/50] - Loss: 0.0103
Epoch [47/50] - Loss: 0.0096
Epoch [48/50] - Loss: 0.0089
Epoch [49/50] - Loss: 0.0083
Epoch [50/50] - Loss: 0.0078
sum preds 621
sum labels 654
 - Test Metrics: Accuracy=0.8314, F1=0.6635, Recall=0.6468, Precision=0.6812
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_nnpu_nnpu_1804095044.csv.
Average F1 over valid seeds: 0.6510 ± 0.0189
___________________________________________________________________________________
Avg F1 for cora with SAR and nnpu, MLP,0.2: 0.6510 ± 0.0189
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4949
Epoch [2/50] - Loss: 0.4585
Epoch [3/50] - Loss: 0.4241
Epoch [4/50] - Loss: 0.3915
Epoch [5/50] - Loss: 0.3615
Epoch [6/50] - Loss: 0.3342
Epoch [7/50] - Loss: 0.3098
Epoch [8/50] - Loss: 0.2879
Epoch [9/50] - Loss: 0.2677
Epoch [10/50] - Loss: 0.2486
Epoch [11/50] - Loss: 0.2300
Epoch [12/50] - Loss: 0.2113
Epoch [13/50] - Loss: 0.1922
Epoch [14/50] - Loss: 0.1726
Epoch [15/50] - Loss: 0.1546
Epoch [16/50] - Loss: 0.1381
Epoch [17/50] - Loss: 0.1197
Epoch [18/50] - Loss: 0.1079
Epoch [19/50] - Loss: 0.0996
Epoch [20/50] - Loss: 0.0914
Epoch [21/50] - Loss: 0.0817
Epoch [22/50] - Loss: 0.0701
Epoch [23/50] - Loss: 0.0591
Epoch [24/50] - Loss: 0.0549
Epoch [25/50] - Loss: 0.0499
Epoch [26/50] - Loss: 0.0444
Epoch [27/50] - Loss: 0.0389
Epoch [28/50] - Loss: 0.0363
Epoch [29/50] - Loss: 0.0328
Epoch [30/50] - Loss: 0.0294
Epoch [31/50] - Loss: 0.0278
Epoch [32/50] - Loss: 0.0259
Epoch [33/50] - Loss: 0.0238
Epoch [34/50] - Loss: 0.0217
Epoch [35/50] - Loss: 0.0195
Epoch [36/50] - Loss: 0.0176
Epoch [37/50] - Loss: 0.0167
Epoch [38/50] - Loss: 0.0159
Epoch [39/50] - Loss: 0.0150
Epoch [40/50] - Loss: 0.0140
Epoch [41/50] - Loss: 0.0129
Epoch [42/50] - Loss: 0.0119
Epoch [43/50] - Loss: 0.0140
Epoch [44/50] - Loss: 0.0108
Epoch [45/50] - Loss: 0.0105
Epoch [46/50] - Loss: 0.0102
Epoch [47/50] - Loss: 0.0097
Epoch [48/50] - Loss: 0.0092
Epoch [49/50] - Loss: 0.0086
Epoch [50/50] - Loss: 0.0079
sum preds 676
sum labels 654
 - Test Metrics: Accuracy=0.9119, F1=0.8316, Recall=0.8456, Precision=0.8180
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5051
Epoch [2/50] - Loss: 0.4823
Epoch [3/50] - Loss: 0.4617
Epoch [4/50] - Loss: 0.4400
Epoch [5/50] - Loss: 0.4176
Epoch [6/50] - Loss: 0.3951
Epoch [7/50] - Loss: 0.3730
Epoch [8/50] - Loss: 0.3518
Epoch [9/50] - Loss: 0.3318
Epoch [10/50] - Loss: 0.3127
Epoch [11/50] - Loss: 0.2945
Epoch [12/50] - Loss: 0.2769
Epoch [13/50] - Loss: 0.2599
Epoch [14/50] - Loss: 0.2430
Epoch [15/50] - Loss: 0.2261
Epoch [16/50] - Loss: 0.2088
Epoch [17/50] - Loss: 0.1910
Epoch [18/50] - Loss: 0.1731
Epoch [19/50] - Loss: 0.1554
Epoch [20/50] - Loss: 0.1387
Epoch [21/50] - Loss: 0.1233
Epoch [22/50] - Loss: 0.1096
Epoch [23/50] - Loss: 0.0972
Epoch [24/50] - Loss: 0.0857
Epoch [25/50] - Loss: 0.0773
Epoch [26/50] - Loss: 0.0702
Epoch [27/50] - Loss: 0.0622
Epoch [28/50] - Loss: 0.0607
Epoch [29/50] - Loss: 0.0568
Epoch [30/50] - Loss: 0.0496
Epoch [31/50] - Loss: 0.0450
Epoch [32/50] - Loss: 0.0428
Epoch [33/50] - Loss: 0.0399
Epoch [34/50] - Loss: 0.0365
Epoch [35/50] - Loss: 0.0330
Epoch [36/50] - Loss: 0.0295
Epoch [37/50] - Loss: 0.0301
Epoch [38/50] - Loss: 0.0269
Epoch [39/50] - Loss: 0.0243
Epoch [40/50] - Loss: 0.0237
Epoch [41/50] - Loss: 0.0227
Epoch [42/50] - Loss: 0.0215
Epoch [43/50] - Loss: 0.0201
Epoch [44/50] - Loss: 0.0187
Epoch [45/50] - Loss: 0.0174
Epoch [46/50] - Loss: 0.0161
Epoch [47/50] - Loss: 0.0150
Epoch [48/50] - Loss: 0.0141
Epoch [49/50] - Loss: 0.0151
Epoch [50/50] - Loss: 0.0132
sum preds 665
sum labels 654
 - Test Metrics: Accuracy=0.8943, F1=0.7961, Recall=0.8028, Precision=0.7895
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4984
Epoch [2/50] - Loss: 0.4665
Epoch [3/50] - Loss: 0.4340
Epoch [4/50] - Loss: 0.4004
Epoch [5/50] - Loss: 0.3681
Epoch [6/50] - Loss: 0.3386
Epoch [7/50] - Loss: 0.3120
Epoch [8/50] - Loss: 0.2884
Epoch [9/50] - Loss: 0.2672
Epoch [10/50] - Loss: 0.2477
Epoch [11/50] - Loss: 0.2294
Epoch [12/50] - Loss: 0.2113
Epoch [13/50] - Loss: 0.1929
Epoch [14/50] - Loss: 0.1744
Epoch [15/50] - Loss: 0.1591
Epoch [16/50] - Loss: 0.1464
Epoch [17/50] - Loss: 0.1327
Epoch [18/50] - Loss: 0.1181
Epoch [19/50] - Loss: 0.1076
Epoch [20/50] - Loss: 0.1006
Epoch [21/50] - Loss: 0.0925
Epoch [22/50] - Loss: 0.0824
Epoch [23/50] - Loss: 0.0705
Epoch [24/50] - Loss: 0.0649
Epoch [25/50] - Loss: 0.0587
Epoch [26/50] - Loss: 0.0522
Epoch [27/50] - Loss: 0.0515
Epoch [28/50] - Loss: 0.0450
Epoch [29/50] - Loss: 0.0392
Epoch [30/50] - Loss: 0.0365
Epoch [31/50] - Loss: 0.0335
Epoch [32/50] - Loss: 0.0305
Epoch [33/50] - Loss: 0.0276
Epoch [34/50] - Loss: 0.0249
Epoch [35/50] - Loss: 0.0223
Epoch [36/50] - Loss: 0.0200
Epoch [37/50] - Loss: 0.0185
Epoch [38/50] - Loss: 0.0171
Epoch [39/50] - Loss: 0.0157
Epoch [40/50] - Loss: 0.0144
Epoch [41/50] - Loss: 0.0132
Epoch [42/50] - Loss: 0.0121
Epoch [43/50] - Loss: 0.0111
Epoch [44/50] - Loss: 0.0101
Epoch [45/50] - Loss: 0.0134
Epoch [46/50] - Loss: 0.0091
Epoch [47/50] - Loss: 0.0090
Epoch [48/50] - Loss: 0.0088
Epoch [49/50] - Loss: 0.0086
Epoch [50/50] - Loss: 0.0084
sum preds 600
sum labels 654
 - Test Metrics: Accuracy=0.9041, F1=0.8054, Recall=0.7722, Precision=0.8417
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_nnpu_nnpu_1804095045.csv.
Average F1 over valid seeds: 0.8110 ± 0.0150
___________________________________________________________________________________
Avg F1 for cora with SAR and nnpu, GATConv,0.2: 0.8110 ± 0.0150
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4950
Epoch [2/50] - Loss: 0.4635
Epoch [3/50] - Loss: 0.4335
Epoch [4/50] - Loss: 0.4039
Epoch [5/50] - Loss: 0.3763
Epoch [6/50] - Loss: 0.3511
Epoch [7/50] - Loss: 0.3286
Epoch [8/50] - Loss: 0.3082
Epoch [9/50] - Loss: 0.2898
Epoch [10/50] - Loss: 0.2727
Epoch [11/50] - Loss: 0.2563
Epoch [12/50] - Loss: 0.2400
Epoch [13/50] - Loss: 0.2232
Epoch [14/50] - Loss: 0.2061
Epoch [15/50] - Loss: 0.1888
Epoch [16/50] - Loss: 0.1718
Epoch [17/50] - Loss: 0.1554
Epoch [18/50] - Loss: 0.1400
Epoch [19/50] - Loss: 0.1259
Epoch [20/50] - Loss: 0.1130
Epoch [21/50] - Loss: 0.1013
Epoch [22/50] - Loss: 0.0904
Epoch [23/50] - Loss: 0.0802
Epoch [24/50] - Loss: 0.0743
Epoch [25/50] - Loss: 0.0675
Epoch [26/50] - Loss: 0.0599
Epoch [27/50] - Loss: 0.0557
Epoch [28/50] - Loss: 0.0524
Epoch [29/50] - Loss: 0.0470
Epoch [30/50] - Loss: 0.0426
Epoch [31/50] - Loss: 0.0403
Epoch [32/50] - Loss: 0.0375
Epoch [33/50] - Loss: 0.0343
Epoch [34/50] - Loss: 0.0310
Epoch [35/50] - Loss: 0.0335
Epoch [36/50] - Loss: 0.0313
Epoch [37/50] - Loss: 0.0264
Epoch [38/50] - Loss: 0.0260
Epoch [39/50] - Loss: 0.0252
Epoch [40/50] - Loss: 0.0242
Epoch [41/50] - Loss: 0.0230
Epoch [42/50] - Loss: 0.0217
Epoch [43/50] - Loss: 0.0203
Epoch [44/50] - Loss: 0.0217
Epoch [45/50] - Loss: 0.0187
Epoch [46/50] - Loss: 0.0183
Epoch [47/50] - Loss: 0.0177
Epoch [48/50] - Loss: 0.0171
Epoch [49/50] - Loss: 0.0177
Epoch [50/50] - Loss: 0.0166
sum preds 638
sum labels 654
 - Test Metrics: Accuracy=0.9182, F1=0.8390, Recall=0.8287, Precision=0.8495
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4945
Epoch [2/50] - Loss: 0.4578
Epoch [3/50] - Loss: 0.4215
Epoch [4/50] - Loss: 0.3870
Epoch [5/50] - Loss: 0.3564
Epoch [6/50] - Loss: 0.3307
Epoch [7/50] - Loss: 0.3099
Epoch [8/50] - Loss: 0.2931
Epoch [9/50] - Loss: 0.2792
Epoch [10/50] - Loss: 0.2674
Epoch [11/50] - Loss: 0.2566
Epoch [12/50] - Loss: 0.2460
Epoch [13/50] - Loss: 0.2350
Epoch [14/50] - Loss: 0.2232
Epoch [15/50] - Loss: 0.2103
Epoch [16/50] - Loss: 0.1981
Epoch [17/50] - Loss: 0.1856
Epoch [18/50] - Loss: 0.1707
Epoch [19/50] - Loss: 0.1539
Epoch [20/50] - Loss: 0.1365
Epoch [21/50] - Loss: 0.1258
Epoch [22/50] - Loss: 0.1176
Epoch [23/50] - Loss: 0.1110
Epoch [24/50] - Loss: 0.1051
Epoch [25/50] - Loss: 0.0982
Epoch [26/50] - Loss: 0.0898
Epoch [27/50] - Loss: 0.0798
Epoch [28/50] - Loss: 0.0688
Epoch [29/50] - Loss: 0.0615
Epoch [30/50] - Loss: 0.0593
Epoch [31/50] - Loss: 0.0559
Epoch [32/50] - Loss: 0.0516
Epoch [33/50] - Loss: 0.0468
Epoch [34/50] - Loss: 0.0418
Epoch [35/50] - Loss: 0.0368
Epoch [36/50] - Loss: 0.0364
Epoch [37/50] - Loss: 0.0358
Epoch [38/50] - Loss: 0.0311
Epoch [39/50] - Loss: 0.0284
Epoch [40/50] - Loss: 0.0280
Epoch [41/50] - Loss: 0.0272
Epoch [42/50] - Loss: 0.0260
Epoch [43/50] - Loss: 0.0245
Epoch [44/50] - Loss: 0.0229
Epoch [45/50] - Loss: 0.0211
Epoch [46/50] - Loss: 0.0194
Epoch [47/50] - Loss: 0.0177
Epoch [48/50] - Loss: 0.0201
Epoch [49/50] - Loss: 0.0183
Epoch [50/50] - Loss: 0.0159
sum preds 641
sum labels 654
 - Test Metrics: Accuracy=0.9210, F1=0.8448, Recall=0.8364, Precision=0.8534
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4938
Epoch [2/50] - Loss: 0.4657
Epoch [3/50] - Loss: 0.4338
Epoch [4/50] - Loss: 0.4013
Epoch [5/50] - Loss: 0.3706
Epoch [6/50] - Loss: 0.3430
Epoch [7/50] - Loss: 0.3188
Epoch [8/50] - Loss: 0.2981
Epoch [9/50] - Loss: 0.2804
Epoch [10/50] - Loss: 0.2648
Epoch [11/50] - Loss: 0.2507
Epoch [12/50] - Loss: 0.2373
Epoch [13/50] - Loss: 0.2239
Epoch [14/50] - Loss: 0.2103
Epoch [15/50] - Loss: 0.1963
Epoch [16/50] - Loss: 0.1819
Epoch [17/50] - Loss: 0.1675
Epoch [18/50] - Loss: 0.1567
Epoch [19/50] - Loss: 0.1442
Epoch [20/50] - Loss: 0.1307
Epoch [21/50] - Loss: 0.1217
Epoch [22/50] - Loss: 0.1159
Epoch [23/50] - Loss: 0.1106
Epoch [24/50] - Loss: 0.1051
Epoch [25/50] - Loss: 0.0988
Epoch [26/50] - Loss: 0.0914
Epoch [27/50] - Loss: 0.0831
Epoch [28/50] - Loss: 0.0760
Epoch [29/50] - Loss: 0.0733
Epoch [30/50] - Loss: 0.0696
Epoch [31/50] - Loss: 0.0651
Epoch [32/50] - Loss: 0.0600
Epoch [33/50] - Loss: 0.0570
Epoch [34/50] - Loss: 0.0550
Epoch [35/50] - Loss: 0.0507
Epoch [36/50] - Loss: 0.0486
Epoch [37/50] - Loss: 0.0472
Epoch [38/50] - Loss: 0.0452
Epoch [39/50] - Loss: 0.0427
Epoch [40/50] - Loss: 0.0399
Epoch [41/50] - Loss: 0.0372
Epoch [42/50] - Loss: 0.0355
Epoch [43/50] - Loss: 0.0347
Epoch [44/50] - Loss: 0.0332
Epoch [45/50] - Loss: 0.0324
Epoch [46/50] - Loss: 0.0312
Epoch [47/50] - Loss: 0.0297
Epoch [48/50] - Loss: 0.0280
Epoch [49/50] - Loss: 0.0303
Epoch [50/50] - Loss: 0.0276
sum preds 613
sum labels 654
 - Test Metrics: Accuracy=0.9076, F1=0.8145, Recall=0.7890, Precision=0.8418
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_nnpu_nnpu_1804095047.csv.
Average F1 over valid seeds: 0.8328 ± 0.0131
___________________________________________________________________________________
Avg F1 for cora with SAR and nnpu, GCNConv,0.2: 0.8328 ± 0.0131
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5003
Epoch [2/50] - Loss: 0.4919
Epoch [3/50] - Loss: 0.4815
Epoch [4/50] - Loss: 0.4685
Epoch [5/50] - Loss: 0.4541
Epoch [6/50] - Loss: 0.4382
Epoch [7/50] - Loss: 0.4211
Epoch [8/50] - Loss: 0.4029
Epoch [9/50] - Loss: 0.3838
Epoch [10/50] - Loss: 0.3638
Epoch [11/50] - Loss: 0.3433
Epoch [12/50] - Loss: 0.3223
Epoch [13/50] - Loss: 0.3011
Epoch [14/50] - Loss: 0.2798
Epoch [15/50] - Loss: 0.2588
Epoch [16/50] - Loss: 0.2383
Epoch [17/50] - Loss: 0.2183
Epoch [18/50] - Loss: 0.1991
Epoch [19/50] - Loss: 0.1808
Epoch [20/50] - Loss: 0.1633
Epoch [21/50] - Loss: 0.1468
Epoch [22/50] - Loss: 0.1313
Epoch [23/50] - Loss: 0.1167
Epoch [24/50] - Loss: 0.1031
Epoch [25/50] - Loss: 0.0903
Epoch [26/50] - Loss: 0.0784
Epoch [27/50] - Loss: 0.0672
Epoch [28/50] - Loss: 0.0567
Epoch [29/50] - Loss: 0.0468
Epoch [30/50] - Loss: 0.0375
Epoch [31/50] - Loss: 0.0288
Epoch [32/50] - Loss: 0.0205
Epoch [33/50] - Loss: 0.0127
Epoch [34/50] - Loss: 0.0053
Epoch [35/50] - Loss: -0.0017
Epoch [36/50] - Loss: -0.0083
Epoch [37/50] - Loss: -0.0146
Epoch [38/50] - Loss: -0.0207
Epoch [39/50] - Loss: -0.0265
Epoch [40/50] - Loss: -0.0320
Epoch [41/50] - Loss: -0.0374
Epoch [42/50] - Loss: -0.0425
Epoch [43/50] - Loss: -0.0474
Epoch [44/50] - Loss: -0.0522
Epoch [45/50] - Loss: -0.0567
Epoch [46/50] - Loss: -0.0610
Epoch [47/50] - Loss: -0.0651
Epoch [48/50] - Loss: -0.0690
Epoch [49/50] - Loss: -0.0727
Epoch [50/50] - Loss: -0.0762
sum preds 249
sum labels 491
 - Test Metrics: Accuracy=0.8438, F1=0.4973, Recall=0.3747, Precision=0.7390
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4896
Epoch [3/50] - Loss: 0.4774
Epoch [4/50] - Loss: 0.4623
Epoch [5/50] - Loss: 0.4454
Epoch [6/50] - Loss: 0.4273
Epoch [7/50] - Loss: 0.4081
Epoch [8/50] - Loss: 0.3879
Epoch [9/50] - Loss: 0.3668
Epoch [10/50] - Loss: 0.3451
Epoch [11/50] - Loss: 0.3230
Epoch [12/50] - Loss: 0.3008
Epoch [13/50] - Loss: 0.2786
Epoch [14/50] - Loss: 0.2567
Epoch [15/50] - Loss: 0.2353
Epoch [16/50] - Loss: 0.2145
Epoch [17/50] - Loss: 0.1945
Epoch [18/50] - Loss: 0.1753
Epoch [19/50] - Loss: 0.1570
Epoch [20/50] - Loss: 0.1397
Epoch [21/50] - Loss: 0.1234
Epoch [22/50] - Loss: 0.1081
Epoch [23/50] - Loss: 0.0937
Epoch [24/50] - Loss: 0.0802
Epoch [25/50] - Loss: 0.0675
Epoch [26/50] - Loss: 0.0557
Epoch [27/50] - Loss: 0.0446
Epoch [28/50] - Loss: 0.0342
Epoch [29/50] - Loss: 0.0244
Epoch [30/50] - Loss: 0.0152
Epoch [31/50] - Loss: 0.0066
Epoch [32/50] - Loss: -0.0015
Epoch [33/50] - Loss: -0.0092
Epoch [34/50] - Loss: -0.0164
Epoch [35/50] - Loss: -0.0232
Epoch [36/50] - Loss: -0.0296
Epoch [37/50] - Loss: -0.0357
Epoch [38/50] - Loss: -0.0415
Epoch [39/50] - Loss: -0.0470
Epoch [40/50] - Loss: -0.0522
Epoch [41/50] - Loss: -0.0572
Epoch [42/50] - Loss: -0.0619
Epoch [43/50] - Loss: -0.0663
Epoch [44/50] - Loss: -0.0706
Epoch [45/50] - Loss: -0.0747
Epoch [46/50] - Loss: -0.0785
Epoch [47/50] - Loss: -0.0821
Epoch [48/50] - Loss: -0.0856
Epoch [49/50] - Loss: -0.0889
Epoch [50/50] - Loss: -0.0920
sum preds 248
sum labels 491
 - Test Metrics: Accuracy=0.8627, F1=0.5575, Recall=0.4196, Precision=0.8306
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5002
Epoch [2/50] - Loss: 0.4915
Epoch [3/50] - Loss: 0.4809
Epoch [4/50] - Loss: 0.4679
Epoch [5/50] - Loss: 0.4532
Epoch [6/50] - Loss: 0.4373
Epoch [7/50] - Loss: 0.4206
Epoch [8/50] - Loss: 0.4032
Epoch [9/50] - Loss: 0.3852
Epoch [10/50] - Loss: 0.3668
Epoch [11/50] - Loss: 0.3480
Epoch [12/50] - Loss: 0.3289
Epoch [13/50] - Loss: 0.3097
Epoch [14/50] - Loss: 0.2905
Epoch [15/50] - Loss: 0.2713
Epoch [16/50] - Loss: 0.2523
Epoch [17/50] - Loss: 0.2335
Epoch [18/50] - Loss: 0.2149
Epoch [19/50] - Loss: 0.1966
Epoch [20/50] - Loss: 0.1789
Epoch [21/50] - Loss: 0.1616
Epoch [22/50] - Loss: 0.1449
Epoch [23/50] - Loss: 0.1288
Epoch [24/50] - Loss: 0.1134
Epoch [25/50] - Loss: 0.0989
Epoch [26/50] - Loss: 0.0850
Epoch [27/50] - Loss: 0.0720
Epoch [28/50] - Loss: 0.0597
Epoch [29/50] - Loss: 0.0481
Epoch [30/50] - Loss: 0.0372
Epoch [31/50] - Loss: 0.0270
Epoch [32/50] - Loss: 0.0174
Epoch [33/50] - Loss: 0.0084
Epoch [34/50] - Loss: -0.0000
Epoch [35/50] - Loss: -0.0079
Epoch [36/50] - Loss: -0.0154
Epoch [37/50] - Loss: -0.0224
Epoch [38/50] - Loss: -0.0289
Epoch [39/50] - Loss: -0.0351
Epoch [40/50] - Loss: -0.0409
Epoch [41/50] - Loss: -0.0463
Epoch [42/50] - Loss: -0.0515
Epoch [43/50] - Loss: -0.0564
Epoch [44/50] - Loss: -0.0609
Epoch [45/50] - Loss: -0.0653
Epoch [46/50] - Loss: -0.0693
Epoch [47/50] - Loss: -0.0732
Epoch [48/50] - Loss: -0.0769
Epoch [49/50] - Loss: -0.0804
Epoch [50/50] - Loss: -0.0838
sum preds 250
sum labels 491
 - Test Metrics: Accuracy=0.8559, F1=0.5371, Recall=0.4053, Precision=0.7960
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_imbnnpu_imbnnpu_1804095049.csv.
Average F1 over valid seeds: 0.5306 ± 0.0250
___________________________________________________________________________________
Avg F1 for cora with SAR and imbnnpu, MLP,0.4: 0.5306 ± 0.0250
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4972
Epoch [2/50] - Loss: 0.4735
Epoch [3/50] - Loss: 0.4477
Epoch [4/50] - Loss: 0.4190
Epoch [5/50] - Loss: 0.3886
Epoch [6/50] - Loss: 0.3574
Epoch [7/50] - Loss: 0.3268
Epoch [8/50] - Loss: 0.2971
Epoch [9/50] - Loss: 0.2691
Epoch [10/50] - Loss: 0.2427
Epoch [11/50] - Loss: 0.2182
Epoch [12/50] - Loss: 0.1955
Epoch [13/50] - Loss: 0.1745
Epoch [14/50] - Loss: 0.1553
Epoch [15/50] - Loss: 0.1378
Epoch [16/50] - Loss: 0.1218
Epoch [17/50] - Loss: 0.1074
Epoch [18/50] - Loss: 0.0942
Epoch [19/50] - Loss: 0.0823
Epoch [20/50] - Loss: 0.0715
Epoch [21/50] - Loss: 0.0616
Epoch [22/50] - Loss: 0.0527
Epoch [23/50] - Loss: 0.0445
Epoch [24/50] - Loss: 0.0370
Epoch [25/50] - Loss: 0.0303
Epoch [26/50] - Loss: 0.0240
Epoch [27/50] - Loss: 0.0183
Epoch [28/50] - Loss: 0.0130
Epoch [29/50] - Loss: 0.0081
Epoch [30/50] - Loss: 0.0035
Epoch [31/50] - Loss: -0.0009
Epoch [32/50] - Loss: -0.0049
Epoch [33/50] - Loss: -0.0086
Epoch [34/50] - Loss: -0.0119
Epoch [35/50] - Loss: -0.0149
Epoch [36/50] - Loss: -0.0177
Epoch [37/50] - Loss: -0.0203
Epoch [38/50] - Loss: -0.0227
Epoch [39/50] - Loss: -0.0250
Epoch [40/50] - Loss: -0.0272
Epoch [41/50] - Loss: -0.0293
Epoch [42/50] - Loss: -0.0313
Epoch [43/50] - Loss: -0.0334
Epoch [44/50] - Loss: -0.0356
Epoch [45/50] - Loss: -0.0377
Epoch [46/50] - Loss: -0.0398
Epoch [47/50] - Loss: -0.0418
Epoch [48/50] - Loss: -0.0438
Epoch [49/50] - Loss: -0.0457
Epoch [50/50] - Loss: -0.0475
sum preds 441
sum labels 491
 - Test Metrics: Accuracy=0.9252, F1=0.8090, Recall=0.7678, Precision=0.8549
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5031
Epoch [2/50] - Loss: 0.4893
Epoch [3/50] - Loss: 0.4750
Epoch [4/50] - Loss: 0.4572
Epoch [5/50] - Loss: 0.4358
Epoch [6/50] - Loss: 0.4117
Epoch [7/50] - Loss: 0.3867
Epoch [8/50] - Loss: 0.3614
Epoch [9/50] - Loss: 0.3359
Epoch [10/50] - Loss: 0.3102
Epoch [11/50] - Loss: 0.2846
Epoch [12/50] - Loss: 0.2595
Epoch [13/50] - Loss: 0.2352
Epoch [14/50] - Loss: 0.2121
Epoch [15/50] - Loss: 0.1906
Epoch [16/50] - Loss: 0.1706
Epoch [17/50] - Loss: 0.1524
Epoch [18/50] - Loss: 0.1358
Epoch [19/50] - Loss: 0.1209
Epoch [20/50] - Loss: 0.1076
Epoch [21/50] - Loss: 0.0957
Epoch [22/50] - Loss: 0.0851
Epoch [23/50] - Loss: 0.0756
Epoch [24/50] - Loss: 0.0671
Epoch [25/50] - Loss: 0.0595
Epoch [26/50] - Loss: 0.0526
Epoch [27/50] - Loss: 0.0465
Epoch [28/50] - Loss: 0.0408
Epoch [29/50] - Loss: 0.0355
Epoch [30/50] - Loss: 0.0305
Epoch [31/50] - Loss: 0.0259
Epoch [32/50] - Loss: 0.0214
Epoch [33/50] - Loss: 0.0172
Epoch [34/50] - Loss: 0.0131
Epoch [35/50] - Loss: 0.0091
Epoch [36/50] - Loss: 0.0054
Epoch [37/50] - Loss: 0.0018
Epoch [38/50] - Loss: -0.0019
Epoch [39/50] - Loss: -0.0056
Epoch [40/50] - Loss: -0.0093
Epoch [41/50] - Loss: -0.0129
Epoch [42/50] - Loss: -0.0162
Epoch [43/50] - Loss: -0.0193
Epoch [44/50] - Loss: -0.0222
Epoch [45/50] - Loss: -0.0250
Epoch [46/50] - Loss: -0.0279
Epoch [47/50] - Loss: -0.0309
Epoch [48/50] - Loss: -0.0336
Epoch [49/50] - Loss: -0.0359
Epoch [50/50] - Loss: -0.0380
sum preds 465
sum labels 491
 - Test Metrics: Accuracy=0.9278, F1=0.8201, Recall=0.7984, Precision=0.8430
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4995
Epoch [2/50] - Loss: 0.4797
Epoch [3/50] - Loss: 0.4573
Epoch [4/50] - Loss: 0.4306
Epoch [5/50] - Loss: 0.4015
Epoch [6/50] - Loss: 0.3718
Epoch [7/50] - Loss: 0.3421
Epoch [8/50] - Loss: 0.3125
Epoch [9/50] - Loss: 0.2834
Epoch [10/50] - Loss: 0.2550
Epoch [11/50] - Loss: 0.2277
Epoch [12/50] - Loss: 0.2020
Epoch [13/50] - Loss: 0.1779
Epoch [14/50] - Loss: 0.1552
Epoch [15/50] - Loss: 0.1345
Epoch [16/50] - Loss: 0.1153
Epoch [17/50] - Loss: 0.0978
Epoch [18/50] - Loss: 0.0816
Epoch [19/50] - Loss: 0.0670
Epoch [20/50] - Loss: 0.0537
Epoch [21/50] - Loss: 0.0416
Epoch [22/50] - Loss: 0.0309
Epoch [23/50] - Loss: 0.0216
Epoch [24/50] - Loss: 0.0135
Epoch [25/50] - Loss: 0.0063
Epoch [26/50] - Loss: -0.0001
Epoch [27/50] - Loss: -0.0060
Epoch [28/50] - Loss: -0.0115
Epoch [29/50] - Loss: -0.0166
Epoch [30/50] - Loss: -0.0213
Epoch [31/50] - Loss: -0.0255
Epoch [32/50] - Loss: -0.0291
Epoch [33/50] - Loss: -0.0323
Epoch [34/50] - Loss: -0.0354
Epoch [35/50] - Loss: -0.0383
Epoch [36/50] - Loss: -0.0411
Epoch [37/50] - Loss: -0.0437
Epoch [38/50] - Loss: -0.0462
Epoch [39/50] - Loss: -0.0484
Epoch [40/50] - Loss: -0.0504
Epoch [41/50] - Loss: -0.0523
Epoch [42/50] - Loss: -0.0541
Epoch [43/50] - Loss: -0.0558
Epoch [44/50] - Loss: -0.0574
Epoch [45/50] - Loss: -0.0589
Epoch [46/50] - Loss: -0.0603
Epoch [47/50] - Loss: -0.0616
Epoch [48/50] - Loss: -0.0629
Epoch [49/50] - Loss: -0.0642
Epoch [50/50] - Loss: -0.0654
sum preds 393
sum labels 491
 - Test Metrics: Accuracy=0.9244, F1=0.7964, Recall=0.7169, Precision=0.8957
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_imbnnpu_imbnnpu_1804095050.csv.
Average F1 over valid seeds: 0.8085 ± 0.0097
___________________________________________________________________________________
Avg F1 for cora with SAR and imbnnpu, GATConv,0.4: 0.8085 ± 0.0097
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4800
Epoch [3/50] - Loss: 0.4585
Epoch [4/50] - Loss: 0.4341
Epoch [5/50] - Loss: 0.4077
Epoch [6/50] - Loss: 0.3809
Epoch [7/50] - Loss: 0.3544
Epoch [8/50] - Loss: 0.3282
Epoch [9/50] - Loss: 0.3023
Epoch [10/50] - Loss: 0.2769
Epoch [11/50] - Loss: 0.2524
Epoch [12/50] - Loss: 0.2291
Epoch [13/50] - Loss: 0.2074
Epoch [14/50] - Loss: 0.1873
Epoch [15/50] - Loss: 0.1689
Epoch [16/50] - Loss: 0.1521
Epoch [17/50] - Loss: 0.1368
Epoch [18/50] - Loss: 0.1229
Epoch [19/50] - Loss: 0.1103
Epoch [20/50] - Loss: 0.0989
Epoch [21/50] - Loss: 0.0886
Epoch [22/50] - Loss: 0.0792
Epoch [23/50] - Loss: 0.0708
Epoch [24/50] - Loss: 0.0632
Epoch [25/50] - Loss: 0.0562
Epoch [26/50] - Loss: 0.0499
Epoch [27/50] - Loss: 0.0441
Epoch [28/50] - Loss: 0.0389
Epoch [29/50] - Loss: 0.0340
Epoch [30/50] - Loss: 0.0296
Epoch [31/50] - Loss: 0.0255
Epoch [32/50] - Loss: 0.0216
Epoch [33/50] - Loss: 0.0181
Epoch [34/50] - Loss: 0.0147
Epoch [35/50] - Loss: 0.0116
Epoch [36/50] - Loss: 0.0087
Epoch [37/50] - Loss: 0.0059
Epoch [38/50] - Loss: 0.0033
Epoch [39/50] - Loss: 0.0009
Epoch [40/50] - Loss: -0.0015
Epoch [41/50] - Loss: -0.0037
Epoch [42/50] - Loss: -0.0058
Epoch [43/50] - Loss: -0.0077
Epoch [44/50] - Loss: -0.0096
Epoch [45/50] - Loss: -0.0114
Epoch [46/50] - Loss: -0.0131
Epoch [47/50] - Loss: -0.0148
Epoch [48/50] - Loss: -0.0163
Epoch [49/50] - Loss: -0.0178
Epoch [50/50] - Loss: -0.0192
sum preds 473
sum labels 491
 - Test Metrics: Accuracy=0.9412, F1=0.8548, Recall=0.8391, Precision=0.8710
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5002
Epoch [2/50] - Loss: 0.4803
Epoch [3/50] - Loss: 0.4594
Epoch [4/50] - Loss: 0.4359
Epoch [5/50] - Loss: 0.4114
Epoch [6/50] - Loss: 0.3863
Epoch [7/50] - Loss: 0.3607
Epoch [8/50] - Loss: 0.3349
Epoch [9/50] - Loss: 0.3092
Epoch [10/50] - Loss: 0.2847
Epoch [11/50] - Loss: 0.2614
Epoch [12/50] - Loss: 0.2395
Epoch [13/50] - Loss: 0.2187
Epoch [14/50] - Loss: 0.1991
Epoch [15/50] - Loss: 0.1809
Epoch [16/50] - Loss: 0.1638
Epoch [17/50] - Loss: 0.1482
Epoch [18/50] - Loss: 0.1338
Epoch [19/50] - Loss: 0.1208
Epoch [20/50] - Loss: 0.1089
Epoch [21/50] - Loss: 0.0982
Epoch [22/50] - Loss: 0.0884
Epoch [23/50] - Loss: 0.0795
Epoch [24/50] - Loss: 0.0714
Epoch [25/50] - Loss: 0.0641
Epoch [26/50] - Loss: 0.0574
Epoch [27/50] - Loss: 0.0513
Epoch [28/50] - Loss: 0.0457
Epoch [29/50] - Loss: 0.0405
Epoch [30/50] - Loss: 0.0358
Epoch [31/50] - Loss: 0.0313
Epoch [32/50] - Loss: 0.0273
Epoch [33/50] - Loss: 0.0235
Epoch [34/50] - Loss: 0.0199
Epoch [35/50] - Loss: 0.0166
Epoch [36/50] - Loss: 0.0135
Epoch [37/50] - Loss: 0.0106
Epoch [38/50] - Loss: 0.0078
Epoch [39/50] - Loss: 0.0052
Epoch [40/50] - Loss: 0.0028
Epoch [41/50] - Loss: 0.0005
Epoch [42/50] - Loss: -0.0017
Epoch [43/50] - Loss: -0.0037
Epoch [44/50] - Loss: -0.0057
Epoch [45/50] - Loss: -0.0075
Epoch [46/50] - Loss: -0.0093
Epoch [47/50] - Loss: -0.0109
Epoch [48/50] - Loss: -0.0125
Epoch [49/50] - Loss: -0.0140
Epoch [50/50] - Loss: -0.0155
sum preds 492
sum labels 491
 - Test Metrics: Accuracy=0.9399, F1=0.8545, Recall=0.8554, Precision=0.8537
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4977
Epoch [2/50] - Loss: 0.4811
Epoch [3/50] - Loss: 0.4605
Epoch [4/50] - Loss: 0.4367
Epoch [5/50] - Loss: 0.4119
Epoch [6/50] - Loss: 0.3874
Epoch [7/50] - Loss: 0.3635
Epoch [8/50] - Loss: 0.3402
Epoch [9/50] - Loss: 0.3173
Epoch [10/50] - Loss: 0.2950
Epoch [11/50] - Loss: 0.2734
Epoch [12/50] - Loss: 0.2528
Epoch [13/50] - Loss: 0.2331
Epoch [14/50] - Loss: 0.2146
Epoch [15/50] - Loss: 0.1972
Epoch [16/50] - Loss: 0.1808
Epoch [17/50] - Loss: 0.1655
Epoch [18/50] - Loss: 0.1512
Epoch [19/50] - Loss: 0.1379
Epoch [20/50] - Loss: 0.1256
Epoch [21/50] - Loss: 0.1142
Epoch [22/50] - Loss: 0.1037
Epoch [23/50] - Loss: 0.0941
Epoch [24/50] - Loss: 0.0852
Epoch [25/50] - Loss: 0.0769
Epoch [26/50] - Loss: 0.0694
Epoch [27/50] - Loss: 0.0624
Epoch [28/50] - Loss: 0.0559
Epoch [29/50] - Loss: 0.0499
Epoch [30/50] - Loss: 0.0443
Epoch [31/50] - Loss: 0.0391
Epoch [32/50] - Loss: 0.0343
Epoch [33/50] - Loss: 0.0298
Epoch [34/50] - Loss: 0.0256
Epoch [35/50] - Loss: 0.0216
Epoch [36/50] - Loss: 0.0179
Epoch [37/50] - Loss: 0.0144
Epoch [38/50] - Loss: 0.0111
Epoch [39/50] - Loss: 0.0079
Epoch [40/50] - Loss: 0.0050
Epoch [41/50] - Loss: 0.0021
Epoch [42/50] - Loss: -0.0005
Epoch [43/50] - Loss: -0.0031
Epoch [44/50] - Loss: -0.0055
Epoch [45/50] - Loss: -0.0078
Epoch [46/50] - Loss: -0.0099
Epoch [47/50] - Loss: -0.0119
Epoch [48/50] - Loss: -0.0138
Epoch [49/50] - Loss: -0.0156
Epoch [50/50] - Loss: -0.0174
sum preds 472
sum labels 491
 - Test Metrics: Accuracy=0.9282, F1=0.8224, Recall=0.8065, Precision=0.8390
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_imbnnpu_imbnnpu_1804095052.csv.
Average F1 over valid seeds: 0.8439 ± 0.0152
___________________________________________________________________________________
Avg F1 for cora with SAR and imbnnpu, GCNConv,0.4: 0.8439 ± 0.0152
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4920
Epoch [3/50] - Loss: 0.4817
Epoch [4/50] - Loss: 0.4689
Epoch [5/50] - Loss: 0.4545
Epoch [6/50] - Loss: 0.4386
Epoch [7/50] - Loss: 0.4213
Epoch [8/50] - Loss: 0.4028
Epoch [9/50] - Loss: 0.3833
Epoch [10/50] - Loss: 0.3630
Epoch [11/50] - Loss: 0.3418
Epoch [12/50] - Loss: 0.3202
Epoch [13/50] - Loss: 0.2982
Epoch [14/50] - Loss: 0.2761
Epoch [15/50] - Loss: 0.2542
Epoch [16/50] - Loss: 0.2326
Epoch [17/50] - Loss: 0.2115
Epoch [18/50] - Loss: 0.1912
Epoch [19/50] - Loss: 0.1716
Epoch [20/50] - Loss: 0.1530
Epoch [21/50] - Loss: 0.1353
Epoch [22/50] - Loss: 0.1185
Epoch [23/50] - Loss: 0.1027
Epoch [24/50] - Loss: 0.0879
Epoch [25/50] - Loss: 0.0739
Epoch [26/50] - Loss: 0.0608
Epoch [27/50] - Loss: 0.0485
Epoch [28/50] - Loss: 0.0369
Epoch [29/50] - Loss: 0.0260
Epoch [30/50] - Loss: 0.0157
Epoch [31/50] - Loss: 0.0060
Epoch [32/50] - Loss: -0.0031
Epoch [33/50] - Loss: -0.0117
Epoch [34/50] - Loss: -0.0199
Epoch [35/50] - Loss: -0.0276
Epoch [36/50] - Loss: -0.0349
Epoch [37/50] - Loss: -0.0418
Epoch [38/50] - Loss: -0.0483
Epoch [39/50] - Loss: -0.0544
Epoch [40/50] - Loss: -0.0602
Epoch [41/50] - Loss: -0.0657
Epoch [42/50] - Loss: -0.0708
Epoch [43/50] - Loss: -0.0757
Epoch [44/50] - Loss: -0.0802
Epoch [45/50] - Loss: -0.0846
Epoch [46/50] - Loss: -0.0886
Epoch [47/50] - Loss: -0.0925
Epoch [48/50] - Loss: -0.0961
Epoch [49/50] - Loss: -0.0996
Epoch [50/50] - Loss: -0.1029
sum preds 198
sum labels 573
 - Test Metrics: Accuracy=0.8120, F1=0.3995, Recall=0.2688, Precision=0.7778
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4892
Epoch [3/50] - Loss: 0.4767
Epoch [4/50] - Loss: 0.4613
Epoch [5/50] - Loss: 0.4442
Epoch [6/50] - Loss: 0.4258
Epoch [7/50] - Loss: 0.4060
Epoch [8/50] - Loss: 0.3851
Epoch [9/50] - Loss: 0.3633
Epoch [10/50] - Loss: 0.3409
Epoch [11/50] - Loss: 0.3181
Epoch [12/50] - Loss: 0.2951
Epoch [13/50] - Loss: 0.2720
Epoch [14/50] - Loss: 0.2493
Epoch [15/50] - Loss: 0.2269
Epoch [16/50] - Loss: 0.2052
Epoch [17/50] - Loss: 0.1842
Epoch [18/50] - Loss: 0.1641
Epoch [19/50] - Loss: 0.1449
Epoch [20/50] - Loss: 0.1268
Epoch [21/50] - Loss: 0.1097
Epoch [22/50] - Loss: 0.0935
Epoch [23/50] - Loss: 0.0784
Epoch [24/50] - Loss: 0.0642
Epoch [25/50] - Loss: 0.0510
Epoch [26/50] - Loss: 0.0386
Epoch [27/50] - Loss: 0.0270
Epoch [28/50] - Loss: 0.0162
Epoch [29/50] - Loss: 0.0061
Epoch [30/50] - Loss: -0.0034
Epoch [31/50] - Loss: -0.0123
Epoch [32/50] - Loss: -0.0205
Epoch [33/50] - Loss: -0.0283
Epoch [34/50] - Loss: -0.0355
Epoch [35/50] - Loss: -0.0423
Epoch [36/50] - Loss: -0.0486
Epoch [37/50] - Loss: -0.0546
Epoch [38/50] - Loss: -0.0601
Epoch [39/50] - Loss: -0.0654
Epoch [40/50] - Loss: -0.0703
Epoch [41/50] - Loss: -0.0750
Epoch [42/50] - Loss: -0.0794
Epoch [43/50] - Loss: -0.0836
Epoch [44/50] - Loss: -0.0876
Epoch [45/50] - Loss: -0.0913
Epoch [46/50] - Loss: -0.0949
Epoch [47/50] - Loss: -0.0983
Epoch [48/50] - Loss: -0.1016
Epoch [49/50] - Loss: -0.1047
Epoch [50/50] - Loss: -0.1076
sum preds 213
sum labels 573
 - Test Metrics: Accuracy=0.8270, F1=0.4580, Recall=0.3141, Precision=0.8451
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5003
Epoch [2/50] - Loss: 0.4911
Epoch [3/50] - Loss: 0.4802
Epoch [4/50] - Loss: 0.4670
Epoch [5/50] - Loss: 0.4521
Epoch [6/50] - Loss: 0.4357
Epoch [7/50] - Loss: 0.4182
Epoch [8/50] - Loss: 0.3998
Epoch [9/50] - Loss: 0.3808
Epoch [10/50] - Loss: 0.3613
Epoch [11/50] - Loss: 0.3414
Epoch [12/50] - Loss: 0.3213
Epoch [13/50] - Loss: 0.3010
Epoch [14/50] - Loss: 0.2806
Epoch [15/50] - Loss: 0.2603
Epoch [16/50] - Loss: 0.2401
Epoch [17/50] - Loss: 0.2201
Epoch [18/50] - Loss: 0.2006
Epoch [19/50] - Loss: 0.1815
Epoch [20/50] - Loss: 0.1629
Epoch [21/50] - Loss: 0.1449
Epoch [22/50] - Loss: 0.1276
Epoch [23/50] - Loss: 0.1111
Epoch [24/50] - Loss: 0.0953
Epoch [25/50] - Loss: 0.0803
Epoch [26/50] - Loss: 0.0662
Epoch [27/50] - Loss: 0.0529
Epoch [28/50] - Loss: 0.0405
Epoch [29/50] - Loss: 0.0288
Epoch [30/50] - Loss: 0.0179
Epoch [31/50] - Loss: 0.0076
Epoch [32/50] - Loss: -0.0019
Epoch [33/50] - Loss: -0.0109
Epoch [34/50] - Loss: -0.0193
Epoch [35/50] - Loss: -0.0271
Epoch [36/50] - Loss: -0.0345
Epoch [37/50] - Loss: -0.0414
Epoch [38/50] - Loss: -0.0479
Epoch [39/50] - Loss: -0.0540
Epoch [40/50] - Loss: -0.0598
Epoch [41/50] - Loss: -0.0652
Epoch [42/50] - Loss: -0.0703
Epoch [43/50] - Loss: -0.0751
Epoch [44/50] - Loss: -0.0796
Epoch [45/50] - Loss: -0.0839
Epoch [46/50] - Loss: -0.0879
Epoch [47/50] - Loss: -0.0918
Epoch [48/50] - Loss: -0.0954
Epoch [49/50] - Loss: -0.0988
Epoch [50/50] - Loss: -0.1020
sum preds 210
sum labels 573
 - Test Metrics: Accuracy=0.8258, F1=0.4521, Recall=0.3089, Precision=0.8429
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_imbnnpu_imbnnpu_1804095054.csv.
Average F1 over valid seeds: 0.4365 ± 0.0263
___________________________________________________________________________________
Avg F1 for cora with SAR and imbnnpu, MLP,0.3: 0.4365 ± 0.0263
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4974
Epoch [2/50] - Loss: 0.4743
Epoch [3/50] - Loss: 0.4490
Epoch [4/50] - Loss: 0.4210
Epoch [5/50] - Loss: 0.3910
Epoch [6/50] - Loss: 0.3603
Epoch [7/50] - Loss: 0.3301
Epoch [8/50] - Loss: 0.3010
Epoch [9/50] - Loss: 0.2734
Epoch [10/50] - Loss: 0.2475
Epoch [11/50] - Loss: 0.2233
Epoch [12/50] - Loss: 0.2008
Epoch [13/50] - Loss: 0.1801
Epoch [14/50] - Loss: 0.1611
Epoch [15/50] - Loss: 0.1436
Epoch [16/50] - Loss: 0.1277
Epoch [17/50] - Loss: 0.1132
Epoch [18/50] - Loss: 0.1000
Epoch [19/50] - Loss: 0.0879
Epoch [20/50] - Loss: 0.0768
Epoch [21/50] - Loss: 0.0667
Epoch [22/50] - Loss: 0.0573
Epoch [23/50] - Loss: 0.0486
Epoch [24/50] - Loss: 0.0406
Epoch [25/50] - Loss: 0.0334
Epoch [26/50] - Loss: 0.0267
Epoch [27/50] - Loss: 0.0206
Epoch [28/50] - Loss: 0.0149
Epoch [29/50] - Loss: 0.0096
Epoch [30/50] - Loss: 0.0047
Epoch [31/50] - Loss: 0.0001
Epoch [32/50] - Loss: -0.0045
Epoch [33/50] - Loss: -0.0086
Epoch [34/50] - Loss: -0.0122
Epoch [35/50] - Loss: -0.0155
Epoch [36/50] - Loss: -0.0186
Epoch [37/50] - Loss: -0.0215
Epoch [38/50] - Loss: -0.0241
Epoch [39/50] - Loss: -0.0265
Epoch [40/50] - Loss: -0.0288
Epoch [41/50] - Loss: -0.0308
Epoch [42/50] - Loss: -0.0328
Epoch [43/50] - Loss: -0.0349
Epoch [44/50] - Loss: -0.0368
Epoch [45/50] - Loss: -0.0387
Epoch [46/50] - Loss: -0.0405
Epoch [47/50] - Loss: -0.0423
Epoch [48/50] - Loss: -0.0440
Epoch [49/50] - Loss: -0.0457
Epoch [50/50] - Loss: -0.0475
sum preds 438
sum labels 573
 - Test Metrics: Accuracy=0.9078, F1=0.7755, Recall=0.6841, Precision=0.8950
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5029
Epoch [2/50] - Loss: 0.4891
Epoch [3/50] - Loss: 0.4749
Epoch [4/50] - Loss: 0.4573
Epoch [5/50] - Loss: 0.4363
Epoch [6/50] - Loss: 0.4130
Epoch [7/50] - Loss: 0.3886
Epoch [8/50] - Loss: 0.3638
Epoch [9/50] - Loss: 0.3389
Epoch [10/50] - Loss: 0.3139
Epoch [11/50] - Loss: 0.2889
Epoch [12/50] - Loss: 0.2643
Epoch [13/50] - Loss: 0.2404
Epoch [14/50] - Loss: 0.2175
Epoch [15/50] - Loss: 0.1959
Epoch [16/50] - Loss: 0.1758
Epoch [17/50] - Loss: 0.1574
Epoch [18/50] - Loss: 0.1406
Epoch [19/50] - Loss: 0.1255
Epoch [20/50] - Loss: 0.1118
Epoch [21/50] - Loss: 0.0994
Epoch [22/50] - Loss: 0.0883
Epoch [23/50] - Loss: 0.0781
Epoch [24/50] - Loss: 0.0688
Epoch [25/50] - Loss: 0.0603
Epoch [26/50] - Loss: 0.0524
Epoch [27/50] - Loss: 0.0453
Epoch [28/50] - Loss: 0.0386
Epoch [29/50] - Loss: 0.0323
Epoch [30/50] - Loss: 0.0264
Epoch [31/50] - Loss: 0.0205
Epoch [32/50] - Loss: 0.0148
Epoch [33/50] - Loss: 0.0095
Epoch [34/50] - Loss: 0.0047
Epoch [35/50] - Loss: 0.0002
Epoch [36/50] - Loss: -0.0039
Epoch [37/50] - Loss: -0.0078
Epoch [38/50] - Loss: -0.0117
Epoch [39/50] - Loss: -0.0156
Epoch [40/50] - Loss: -0.0200
Epoch [41/50] - Loss: -0.0239
Epoch [42/50] - Loss: -0.0270
Epoch [43/50] - Loss: -0.0300
Epoch [44/50] - Loss: -0.0328
Epoch [45/50] - Loss: -0.0357
Epoch [46/50] - Loss: -0.0386
Epoch [47/50] - Loss: -0.0416
Epoch [48/50] - Loss: -0.0443
Epoch [49/50] - Loss: -0.0468
Epoch [50/50] - Loss: -0.0491
sum preds 459
sum labels 573
 - Test Metrics: Accuracy=0.9074, F1=0.7791, Recall=0.7016, Precision=0.8758
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4993
Epoch [2/50] - Loss: 0.4793
Epoch [3/50] - Loss: 0.4570
Epoch [4/50] - Loss: 0.4306
Epoch [5/50] - Loss: 0.4019
Epoch [6/50] - Loss: 0.3723
Epoch [7/50] - Loss: 0.3425
Epoch [8/50] - Loss: 0.3129
Epoch [9/50] - Loss: 0.2838
Epoch [10/50] - Loss: 0.2559
Epoch [11/50] - Loss: 0.2293
Epoch [12/50] - Loss: 0.2042
Epoch [13/50] - Loss: 0.1809
Epoch [14/50] - Loss: 0.1590
Epoch [15/50] - Loss: 0.1387
Epoch [16/50] - Loss: 0.1196
Epoch [17/50] - Loss: 0.1018
Epoch [18/50] - Loss: 0.0853
Epoch [19/50] - Loss: 0.0702
Epoch [20/50] - Loss: 0.0564
Epoch [21/50] - Loss: 0.0440
Epoch [22/50] - Loss: 0.0329
Epoch [23/50] - Loss: 0.0233
Epoch [24/50] - Loss: 0.0148
Epoch [25/50] - Loss: 0.0073
Epoch [26/50] - Loss: 0.0006
Epoch [27/50] - Loss: -0.0053
Epoch [28/50] - Loss: -0.0108
Epoch [29/50] - Loss: -0.0162
Epoch [30/50] - Loss: -0.0214
Epoch [31/50] - Loss: -0.0265
Epoch [32/50] - Loss: -0.0315
Epoch [33/50] - Loss: -0.0362
Epoch [34/50] - Loss: -0.0404
Epoch [35/50] - Loss: -0.0441
Epoch [36/50] - Loss: -0.0474
Epoch [37/50] - Loss: -0.0505
Epoch [38/50] - Loss: -0.0534
Epoch [39/50] - Loss: -0.0560
Epoch [40/50] - Loss: -0.0584
Epoch [41/50] - Loss: -0.0606
Epoch [42/50] - Loss: -0.0626
Epoch [43/50] - Loss: -0.0644
Epoch [44/50] - Loss: -0.0661
Epoch [45/50] - Loss: -0.0679
Epoch [46/50] - Loss: -0.0697
Epoch [47/50] - Loss: -0.0716
Epoch [48/50] - Loss: -0.0736
Epoch [49/50] - Loss: -0.0756
Epoch [50/50] - Loss: -0.0774
sum preds 375
sum labels 573
 - Test Metrics: Accuracy=0.8896, F1=0.7131, Recall=0.5899, Precision=0.9013
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_imbnnpu_imbnnpu_1804095055.csv.
Average F1 over valid seeds: 0.7559 ± 0.0303
___________________________________________________________________________________
Avg F1 for cora with SAR and imbnnpu, GATConv,0.3: 0.7559 ± 0.0303
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5002
Epoch [2/50] - Loss: 0.4809
Epoch [3/50] - Loss: 0.4601
Epoch [4/50] - Loss: 0.4366
Epoch [5/50] - Loss: 0.4110
Epoch [6/50] - Loss: 0.3848
Epoch [7/50] - Loss: 0.3586
Epoch [8/50] - Loss: 0.3327
Epoch [9/50] - Loss: 0.3071
Epoch [10/50] - Loss: 0.2821
Epoch [11/50] - Loss: 0.2582
Epoch [12/50] - Loss: 0.2355
Epoch [13/50] - Loss: 0.2139
Epoch [14/50] - Loss: 0.1939
Epoch [15/50] - Loss: 0.1754
Epoch [16/50] - Loss: 0.1586
Epoch [17/50] - Loss: 0.1433
Epoch [18/50] - Loss: 0.1294
Epoch [19/50] - Loss: 0.1167
Epoch [20/50] - Loss: 0.1053
Epoch [21/50] - Loss: 0.0950
Epoch [22/50] - Loss: 0.0856
Epoch [23/50] - Loss: 0.0771
Epoch [24/50] - Loss: 0.0694
Epoch [25/50] - Loss: 0.0624
Epoch [26/50] - Loss: 0.0559
Epoch [27/50] - Loss: 0.0500
Epoch [28/50] - Loss: 0.0446
Epoch [29/50] - Loss: 0.0395
Epoch [30/50] - Loss: 0.0349
Epoch [31/50] - Loss: 0.0305
Epoch [32/50] - Loss: 0.0264
Epoch [33/50] - Loss: 0.0226
Epoch [34/50] - Loss: 0.0191
Epoch [35/50] - Loss: 0.0157
Epoch [36/50] - Loss: 0.0126
Epoch [37/50] - Loss: 0.0096
Epoch [38/50] - Loss: 0.0068
Epoch [39/50] - Loss: 0.0042
Epoch [40/50] - Loss: 0.0016
Epoch [41/50] - Loss: -0.0007
Epoch [42/50] - Loss: -0.0030
Epoch [43/50] - Loss: -0.0051
Epoch [44/50] - Loss: -0.0072
Epoch [45/50] - Loss: -0.0091
Epoch [46/50] - Loss: -0.0110
Epoch [47/50] - Loss: -0.0127
Epoch [48/50] - Loss: -0.0144
Epoch [49/50] - Loss: -0.0161
Epoch [50/50] - Loss: -0.0176
sum preds 490
sum labels 573
 - Test Metrics: Accuracy=0.9298, F1=0.8373, Recall=0.7766, Precision=0.9082
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4806
Epoch [3/50] - Loss: 0.4595
Epoch [4/50] - Loss: 0.4360
Epoch [5/50] - Loss: 0.4115
Epoch [6/50] - Loss: 0.3867
Epoch [7/50] - Loss: 0.3614
Epoch [8/50] - Loss: 0.3355
Epoch [9/50] - Loss: 0.3098
Epoch [10/50] - Loss: 0.2851
Epoch [11/50] - Loss: 0.2617
Epoch [12/50] - Loss: 0.2397
Epoch [13/50] - Loss: 0.2190
Epoch [14/50] - Loss: 0.1994
Epoch [15/50] - Loss: 0.1810
Epoch [16/50] - Loss: 0.1639
Epoch [17/50] - Loss: 0.1482
Epoch [18/50] - Loss: 0.1339
Epoch [19/50] - Loss: 0.1208
Epoch [20/50] - Loss: 0.1089
Epoch [21/50] - Loss: 0.0981
Epoch [22/50] - Loss: 0.0882
Epoch [23/50] - Loss: 0.0792
Epoch [24/50] - Loss: 0.0711
Epoch [25/50] - Loss: 0.0636
Epoch [26/50] - Loss: 0.0568
Epoch [27/50] - Loss: 0.0506
Epoch [28/50] - Loss: 0.0448
Epoch [29/50] - Loss: 0.0396
Epoch [30/50] - Loss: 0.0347
Epoch [31/50] - Loss: 0.0302
Epoch [32/50] - Loss: 0.0260
Epoch [33/50] - Loss: 0.0221
Epoch [34/50] - Loss: 0.0184
Epoch [35/50] - Loss: 0.0150
Epoch [36/50] - Loss: 0.0117
Epoch [37/50] - Loss: 0.0087
Epoch [38/50] - Loss: 0.0058
Epoch [39/50] - Loss: 0.0030
Epoch [40/50] - Loss: 0.0004
Epoch [41/50] - Loss: -0.0021
Epoch [42/50] - Loss: -0.0046
Epoch [43/50] - Loss: -0.0069
Epoch [44/50] - Loss: -0.0091
Epoch [45/50] - Loss: -0.0113
Epoch [46/50] - Loss: -0.0134
Epoch [47/50] - Loss: -0.0155
Epoch [48/50] - Loss: -0.0175
Epoch [49/50] - Loss: -0.0194
Epoch [50/50] - Loss: -0.0213
sum preds 501
sum labels 573
 - Test Metrics: Accuracy=0.9188, F1=0.8138, Recall=0.7627, Precision=0.8723
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4980
Epoch [2/50] - Loss: 0.4816
Epoch [3/50] - Loss: 0.4613
Epoch [4/50] - Loss: 0.4380
Epoch [5/50] - Loss: 0.4138
Epoch [6/50] - Loss: 0.3896
Epoch [7/50] - Loss: 0.3660
Epoch [8/50] - Loss: 0.3430
Epoch [9/50] - Loss: 0.3205
Epoch [10/50] - Loss: 0.2986
Epoch [11/50] - Loss: 0.2776
Epoch [12/50] - Loss: 0.2574
Epoch [13/50] - Loss: 0.2383
Epoch [14/50] - Loss: 0.2202
Epoch [15/50] - Loss: 0.2033
Epoch [16/50] - Loss: 0.1874
Epoch [17/50] - Loss: 0.1725
Epoch [18/50] - Loss: 0.1587
Epoch [19/50] - Loss: 0.1458
Epoch [20/50] - Loss: 0.1338
Epoch [21/50] - Loss: 0.1228
Epoch [22/50] - Loss: 0.1125
Epoch [23/50] - Loss: 0.1031
Epoch [24/50] - Loss: 0.0943
Epoch [25/50] - Loss: 0.0862
Epoch [26/50] - Loss: 0.0787
Epoch [27/50] - Loss: 0.0717
Epoch [28/50] - Loss: 0.0653
Epoch [29/50] - Loss: 0.0592
Epoch [30/50] - Loss: 0.0536
Epoch [31/50] - Loss: 0.0483
Epoch [32/50] - Loss: 0.0433
Epoch [33/50] - Loss: 0.0386
Epoch [34/50] - Loss: 0.0342
Epoch [35/50] - Loss: 0.0300
Epoch [36/50] - Loss: 0.0261
Epoch [37/50] - Loss: 0.0223
Epoch [38/50] - Loss: 0.0188
Epoch [39/50] - Loss: 0.0154
Epoch [40/50] - Loss: 0.0122
Epoch [41/50] - Loss: 0.0092
Epoch [42/50] - Loss: 0.0063
Epoch [43/50] - Loss: 0.0036
Epoch [44/50] - Loss: 0.0010
Epoch [45/50] - Loss: -0.0015
Epoch [46/50] - Loss: -0.0038
Epoch [47/50] - Loss: -0.0061
Epoch [48/50] - Loss: -0.0083
Epoch [49/50] - Loss: -0.0103
Epoch [50/50] - Loss: -0.0123
sum preds 483
sum labels 573
 - Test Metrics: Accuracy=0.9131, F1=0.7973, Recall=0.7347, Precision=0.8716
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_imbnnpu_imbnnpu_1804095058.csv.
Average F1 over valid seeds: 0.8161 ± 0.0164
___________________________________________________________________________________
Avg F1 for cora with SAR and imbnnpu, GCNConv,0.3: 0.8161 ± 0.0164
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4901
Epoch [3/50] - Loss: 0.4780
Epoch [4/50] - Loss: 0.4636
Epoch [5/50] - Loss: 0.4474
Epoch [6/50] - Loss: 0.4296
Epoch [7/50] - Loss: 0.4104
Epoch [8/50] - Loss: 0.3900
Epoch [9/50] - Loss: 0.3685
Epoch [10/50] - Loss: 0.3461
Epoch [11/50] - Loss: 0.3230
Epoch [12/50] - Loss: 0.2994
Epoch [13/50] - Loss: 0.2755
Epoch [14/50] - Loss: 0.2516
Epoch [15/50] - Loss: 0.2278
Epoch [16/50] - Loss: 0.2044
Epoch [17/50] - Loss: 0.1817
Epoch [18/50] - Loss: 0.1597
Epoch [19/50] - Loss: 0.1386
Epoch [20/50] - Loss: 0.1185
Epoch [21/50] - Loss: 0.0995
Epoch [22/50] - Loss: 0.0816
Epoch [23/50] - Loss: 0.0648
Epoch [24/50] - Loss: 0.0491
Epoch [25/50] - Loss: 0.0344
Epoch [26/50] - Loss: 0.0206
Epoch [27/50] - Loss: 0.0078
Epoch [28/50] - Loss: -0.0042
Epoch [29/50] - Loss: -0.0153
Epoch [30/50] - Loss: -0.0257
Epoch [31/50] - Loss: -0.0354
Epoch [32/50] - Loss: -0.0444
Epoch [33/50] - Loss: -0.0527
Epoch [34/50] - Loss: -0.0605
Epoch [35/50] - Loss: -0.0677
Epoch [36/50] - Loss: -0.0745
Epoch [37/50] - Loss: -0.0807
Epoch [38/50] - Loss: -0.0866
Epoch [39/50] - Loss: -0.0920
Epoch [40/50] - Loss: -0.0970
Epoch [41/50] - Loss: -0.1017
Epoch [42/50] - Loss: -0.1062
Epoch [43/50] - Loss: -0.1103
Epoch [44/50] - Loss: -0.1142
Epoch [45/50] - Loss: -0.1179
Epoch [46/50] - Loss: -0.1214
Epoch [47/50] - Loss: -0.1247
Epoch [48/50] - Loss: -0.1277
Epoch [49/50] - Loss: -0.1306
Epoch [50/50] - Loss: -0.1334
sum preds 151
sum labels 654
 - Test Metrics: Accuracy=0.7811, F1=0.3081, Recall=0.1896, Precision=0.8212
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4881
Epoch [3/50] - Loss: 0.4749
Epoch [4/50] - Loss: 0.4590
Epoch [5/50] - Loss: 0.4411
Epoch [6/50] - Loss: 0.4216
Epoch [7/50] - Loss: 0.4007
Epoch [8/50] - Loss: 0.3785
Epoch [9/50] - Loss: 0.3555
Epoch [10/50] - Loss: 0.3318
Epoch [11/50] - Loss: 0.3078
Epoch [12/50] - Loss: 0.2834
Epoch [13/50] - Loss: 0.2591
Epoch [14/50] - Loss: 0.2351
Epoch [15/50] - Loss: 0.2117
Epoch [16/50] - Loss: 0.1888
Epoch [17/50] - Loss: 0.1669
Epoch [18/50] - Loss: 0.1458
Epoch [19/50] - Loss: 0.1258
Epoch [20/50] - Loss: 0.1068
Epoch [21/50] - Loss: 0.0889
Epoch [22/50] - Loss: 0.0721
Epoch [23/50] - Loss: 0.0564
Epoch [24/50] - Loss: 0.0417
Epoch [25/50] - Loss: 0.0279
Epoch [26/50] - Loss: 0.0151
Epoch [27/50] - Loss: 0.0032
Epoch [28/50] - Loss: -0.0079
Epoch [29/50] - Loss: -0.0183
Epoch [30/50] - Loss: -0.0280
Epoch [31/50] - Loss: -0.0371
Epoch [32/50] - Loss: -0.0455
Epoch [33/50] - Loss: -0.0535
Epoch [34/50] - Loss: -0.0609
Epoch [35/50] - Loss: -0.0678
Epoch [36/50] - Loss: -0.0743
Epoch [37/50] - Loss: -0.0804
Epoch [38/50] - Loss: -0.0861
Epoch [39/50] - Loss: -0.0914
Epoch [40/50] - Loss: -0.0963
Epoch [41/50] - Loss: -0.1009
Epoch [42/50] - Loss: -0.1052
Epoch [43/50] - Loss: -0.1092
Epoch [44/50] - Loss: -0.1129
Epoch [45/50] - Loss: -0.1164
Epoch [46/50] - Loss: -0.1197
Epoch [47/50] - Loss: -0.1228
Epoch [48/50] - Loss: -0.1257
Epoch [49/50] - Loss: -0.1285
Epoch [50/50] - Loss: -0.1312
sum preds 159
sum labels 654
 - Test Metrics: Accuracy=0.7905, F1=0.3444, Recall=0.2141, Precision=0.8805
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4905
Epoch [3/50] - Loss: 0.4792
Epoch [4/50] - Loss: 0.4657
Epoch [5/50] - Loss: 0.4505
Epoch [6/50] - Loss: 0.4337
Epoch [7/50] - Loss: 0.4155
Epoch [8/50] - Loss: 0.3963
Epoch [9/50] - Loss: 0.3764
Epoch [10/50] - Loss: 0.3559
Epoch [11/50] - Loss: 0.3352
Epoch [12/50] - Loss: 0.3142
Epoch [13/50] - Loss: 0.2932
Epoch [14/50] - Loss: 0.2721
Epoch [15/50] - Loss: 0.2512
Epoch [16/50] - Loss: 0.2304
Epoch [17/50] - Loss: 0.2098
Epoch [18/50] - Loss: 0.1895
Epoch [19/50] - Loss: 0.1697
Epoch [20/50] - Loss: 0.1503
Epoch [21/50] - Loss: 0.1316
Epoch [22/50] - Loss: 0.1137
Epoch [23/50] - Loss: 0.0965
Epoch [24/50] - Loss: 0.0801
Epoch [25/50] - Loss: 0.0646
Epoch [26/50] - Loss: 0.0500
Epoch [27/50] - Loss: 0.0362
Epoch [28/50] - Loss: 0.0233
Epoch [29/50] - Loss: 0.0112
Epoch [30/50] - Loss: -0.0001
Epoch [31/50] - Loss: -0.0107
Epoch [32/50] - Loss: -0.0205
Epoch [33/50] - Loss: -0.0296
Epoch [34/50] - Loss: -0.0381
Epoch [35/50] - Loss: -0.0460
Epoch [36/50] - Loss: -0.0533
Epoch [37/50] - Loss: -0.0601
Epoch [38/50] - Loss: -0.0665
Epoch [39/50] - Loss: -0.0724
Epoch [40/50] - Loss: -0.0780
Epoch [41/50] - Loss: -0.0832
Epoch [42/50] - Loss: -0.0880
Epoch [43/50] - Loss: -0.0925
Epoch [44/50] - Loss: -0.0968
Epoch [45/50] - Loss: -0.1008
Epoch [46/50] - Loss: -0.1046
Epoch [47/50] - Loss: -0.1081
Epoch [48/50] - Loss: -0.1115
Epoch [49/50] - Loss: -0.1147
Epoch [50/50] - Loss: -0.1178
sum preds 179
sum labels 654
 - Test Metrics: Accuracy=0.7905, F1=0.3601, Recall=0.2294, Precision=0.8380
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_imbnnpu_imbnnpu_1804095100.csv.
Average F1 over valid seeds: 0.3375 ± 0.0218
___________________________________________________________________________________
Avg F1 for cora with SAR and imbnnpu, MLP,0.2: 0.3375 ± 0.0218
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4973
Epoch [2/50] - Loss: 0.4737
Epoch [3/50] - Loss: 0.4477
Epoch [4/50] - Loss: 0.4183
Epoch [5/50] - Loss: 0.3868
Epoch [6/50] - Loss: 0.3547
Epoch [7/50] - Loss: 0.3233
Epoch [8/50] - Loss: 0.2931
Epoch [9/50] - Loss: 0.2645
Epoch [10/50] - Loss: 0.2377
Epoch [11/50] - Loss: 0.2128
Epoch [12/50] - Loss: 0.1896
Epoch [13/50] - Loss: 0.1684
Epoch [14/50] - Loss: 0.1489
Epoch [15/50] - Loss: 0.1311
Epoch [16/50] - Loss: 0.1151
Epoch [17/50] - Loss: 0.1005
Epoch [18/50] - Loss: 0.0871
Epoch [19/50] - Loss: 0.0749
Epoch [20/50] - Loss: 0.0639
Epoch [21/50] - Loss: 0.0539
Epoch [22/50] - Loss: 0.0447
Epoch [23/50] - Loss: 0.0364
Epoch [24/50] - Loss: 0.0287
Epoch [25/50] - Loss: 0.0215
Epoch [26/50] - Loss: 0.0148
Epoch [27/50] - Loss: 0.0086
Epoch [28/50] - Loss: 0.0030
Epoch [29/50] - Loss: -0.0023
Epoch [30/50] - Loss: -0.0073
Epoch [31/50] - Loss: -0.0120
Epoch [32/50] - Loss: -0.0164
Epoch [33/50] - Loss: -0.0207
Epoch [34/50] - Loss: -0.0247
Epoch [35/50] - Loss: -0.0284
Epoch [36/50] - Loss: -0.0320
Epoch [37/50] - Loss: -0.0353
Epoch [38/50] - Loss: -0.0386
Epoch [39/50] - Loss: -0.0415
Epoch [40/50] - Loss: -0.0442
Epoch [41/50] - Loss: -0.0468
Epoch [42/50] - Loss: -0.0495
Epoch [43/50] - Loss: -0.0521
Epoch [44/50] - Loss: -0.0546
Epoch [45/50] - Loss: -0.0570
Epoch [46/50] - Loss: -0.0593
Epoch [47/50] - Loss: -0.0614
Epoch [48/50] - Loss: -0.0634
Epoch [49/50] - Loss: -0.0653
Epoch [50/50] - Loss: -0.0672
sum preds 390
sum labels 654
 - Test Metrics: Accuracy=0.8703, F1=0.6839, Recall=0.5459, Precision=0.9154
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5028
Epoch [2/50] - Loss: 0.4892
Epoch [3/50] - Loss: 0.4751
Epoch [4/50] - Loss: 0.4578
Epoch [5/50] - Loss: 0.4376
Epoch [6/50] - Loss: 0.4155
Epoch [7/50] - Loss: 0.3922
Epoch [8/50] - Loss: 0.3683
Epoch [9/50] - Loss: 0.3439
Epoch [10/50] - Loss: 0.3192
Epoch [11/50] - Loss: 0.2946
Epoch [12/50] - Loss: 0.2703
Epoch [13/50] - Loss: 0.2467
Epoch [14/50] - Loss: 0.2239
Epoch [15/50] - Loss: 0.2022
Epoch [16/50] - Loss: 0.1819
Epoch [17/50] - Loss: 0.1631
Epoch [18/50] - Loss: 0.1457
Epoch [19/50] - Loss: 0.1297
Epoch [20/50] - Loss: 0.1151
Epoch [21/50] - Loss: 0.1017
Epoch [22/50] - Loss: 0.0895
Epoch [23/50] - Loss: 0.0782
Epoch [24/50] - Loss: 0.0679
Epoch [25/50] - Loss: 0.0584
Epoch [26/50] - Loss: 0.0498
Epoch [27/50] - Loss: 0.0418
Epoch [28/50] - Loss: 0.0343
Epoch [29/50] - Loss: 0.0273
Epoch [30/50] - Loss: 0.0207
Epoch [31/50] - Loss: 0.0146
Epoch [32/50] - Loss: 0.0089
Epoch [33/50] - Loss: 0.0035
Epoch [34/50] - Loss: -0.0018
Epoch [35/50] - Loss: -0.0068
Epoch [36/50] - Loss: -0.0116
Epoch [37/50] - Loss: -0.0162
Epoch [38/50] - Loss: -0.0208
Epoch [39/50] - Loss: -0.0252
Epoch [40/50] - Loss: -0.0294
Epoch [41/50] - Loss: -0.0334
Epoch [42/50] - Loss: -0.0373
Epoch [43/50] - Loss: -0.0413
Epoch [44/50] - Loss: -0.0456
Epoch [45/50] - Loss: -0.0505
Epoch [46/50] - Loss: -0.0552
Epoch [47/50] - Loss: -0.0593
Epoch [48/50] - Loss: -0.0628
Epoch [49/50] - Loss: -0.0659
Epoch [50/50] - Loss: -0.0685
sum preds 378
sum labels 654
 - Test Metrics: Accuracy=0.8585, F1=0.6512, Recall=0.5138, Precision=0.8889
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4995
Epoch [2/50] - Loss: 0.4798
Epoch [3/50] - Loss: 0.4586
Epoch [4/50] - Loss: 0.4336
Epoch [5/50] - Loss: 0.4064
Epoch [6/50] - Loss: 0.3781
Epoch [7/50] - Loss: 0.3494
Epoch [8/50] - Loss: 0.3204
Epoch [9/50] - Loss: 0.2917
Epoch [10/50] - Loss: 0.2635
Epoch [11/50] - Loss: 0.2365
Epoch [12/50] - Loss: 0.2106
Epoch [13/50] - Loss: 0.1859
Epoch [14/50] - Loss: 0.1623
Epoch [15/50] - Loss: 0.1399
Epoch [16/50] - Loss: 0.1192
Epoch [17/50] - Loss: 0.1002
Epoch [18/50] - Loss: 0.0826
Epoch [19/50] - Loss: 0.0664
Epoch [20/50] - Loss: 0.0516
Epoch [21/50] - Loss: 0.0380
Epoch [22/50] - Loss: 0.0255
Epoch [23/50] - Loss: 0.0141
Epoch [24/50] - Loss: 0.0037
Epoch [25/50] - Loss: -0.0056
Epoch [26/50] - Loss: -0.0139
Epoch [27/50] - Loss: -0.0212
Epoch [28/50] - Loss: -0.0278
Epoch [29/50] - Loss: -0.0341
Epoch [30/50] - Loss: -0.0401
Epoch [31/50] - Loss: -0.0461
Epoch [32/50] - Loss: -0.0515
Epoch [33/50] - Loss: -0.0564
Epoch [34/50] - Loss: -0.0609
Epoch [35/50] - Loss: -0.0652
Epoch [36/50] - Loss: -0.0693
Epoch [37/50] - Loss: -0.0733
Epoch [38/50] - Loss: -0.0770
Epoch [39/50] - Loss: -0.0802
Epoch [40/50] - Loss: -0.0831
Epoch [41/50] - Loss: -0.0860
Epoch [42/50] - Loss: -0.0889
Epoch [43/50] - Loss: -0.0916
Epoch [44/50] - Loss: -0.0942
Epoch [45/50] - Loss: -0.0968
Epoch [46/50] - Loss: -0.0993
Epoch [47/50] - Loss: -0.1018
Epoch [48/50] - Loss: -0.1039
Epoch [49/50] - Loss: -0.1058
Epoch [50/50] - Loss: -0.1076
sum preds 324
sum labels 654
 - Test Metrics: Accuracy=0.8506, F1=0.6115, Recall=0.4572, Precision=0.9228
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_imbnnpu_imbnnpu_1804095101.csv.
Average F1 over valid seeds: 0.6488 ± 0.0296
___________________________________________________________________________________
Avg F1 for cora with SAR and imbnnpu, GATConv,0.2: 0.6488 ± 0.0296
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4805
Epoch [3/50] - Loss: 0.4593
Epoch [4/50] - Loss: 0.4348
Epoch [5/50] - Loss: 0.4085
Epoch [6/50] - Loss: 0.3815
Epoch [7/50] - Loss: 0.3542
Epoch [8/50] - Loss: 0.3270
Epoch [9/50] - Loss: 0.3002
Epoch [10/50] - Loss: 0.2744
Epoch [11/50] - Loss: 0.2498
Epoch [12/50] - Loss: 0.2265
Epoch [13/50] - Loss: 0.2046
Epoch [14/50] - Loss: 0.1840
Epoch [15/50] - Loss: 0.1651
Epoch [16/50] - Loss: 0.1477
Epoch [17/50] - Loss: 0.1320
Epoch [18/50] - Loss: 0.1177
Epoch [19/50] - Loss: 0.1049
Epoch [20/50] - Loss: 0.0932
Epoch [21/50] - Loss: 0.0827
Epoch [22/50] - Loss: 0.0732
Epoch [23/50] - Loss: 0.0646
Epoch [24/50] - Loss: 0.0567
Epoch [25/50] - Loss: 0.0496
Epoch [26/50] - Loss: 0.0431
Epoch [27/50] - Loss: 0.0372
Epoch [28/50] - Loss: 0.0317
Epoch [29/50] - Loss: 0.0267
Epoch [30/50] - Loss: 0.0220
Epoch [31/50] - Loss: 0.0177
Epoch [32/50] - Loss: 0.0137
Epoch [33/50] - Loss: 0.0099
Epoch [34/50] - Loss: 0.0064
Epoch [35/50] - Loss: 0.0030
Epoch [36/50] - Loss: -0.0002
Epoch [37/50] - Loss: -0.0032
Epoch [38/50] - Loss: -0.0061
Epoch [39/50] - Loss: -0.0089
Epoch [40/50] - Loss: -0.0116
Epoch [41/50] - Loss: -0.0142
Epoch [42/50] - Loss: -0.0168
Epoch [43/50] - Loss: -0.0192
Epoch [44/50] - Loss: -0.0216
Epoch [45/50] - Loss: -0.0240
Epoch [46/50] - Loss: -0.0262
Epoch [47/50] - Loss: -0.0284
Epoch [48/50] - Loss: -0.0306
Epoch [49/50] - Loss: -0.0326
Epoch [50/50] - Loss: -0.0346
sum preds 476
sum labels 654
 - Test Metrics: Accuracy=0.8994, F1=0.7735, Recall=0.6682, Precision=0.9181
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5014
Epoch [2/50] - Loss: 0.4810
Epoch [3/50] - Loss: 0.4597
Epoch [4/50] - Loss: 0.4359
Epoch [5/50] - Loss: 0.4113
Epoch [6/50] - Loss: 0.3866
Epoch [7/50] - Loss: 0.3619
Epoch [8/50] - Loss: 0.3366
Epoch [9/50] - Loss: 0.3110
Epoch [10/50] - Loss: 0.2861
Epoch [11/50] - Loss: 0.2625
Epoch [12/50] - Loss: 0.2401
Epoch [13/50] - Loss: 0.2189
Epoch [14/50] - Loss: 0.1988
Epoch [15/50] - Loss: 0.1798
Epoch [16/50] - Loss: 0.1622
Epoch [17/50] - Loss: 0.1458
Epoch [18/50] - Loss: 0.1308
Epoch [19/50] - Loss: 0.1171
Epoch [20/50] - Loss: 0.1045
Epoch [21/50] - Loss: 0.0931
Epoch [22/50] - Loss: 0.0826
Epoch [23/50] - Loss: 0.0731
Epoch [24/50] - Loss: 0.0643
Epoch [25/50] - Loss: 0.0563
Epoch [26/50] - Loss: 0.0490
Epoch [27/50] - Loss: 0.0423
Epoch [28/50] - Loss: 0.0360
Epoch [29/50] - Loss: 0.0303
Epoch [30/50] - Loss: 0.0249
Epoch [31/50] - Loss: 0.0199
Epoch [32/50] - Loss: 0.0153
Epoch [33/50] - Loss: 0.0110
Epoch [34/50] - Loss: 0.0069
Epoch [35/50] - Loss: 0.0031
Epoch [36/50] - Loss: -0.0005
Epoch [37/50] - Loss: -0.0039
Epoch [38/50] - Loss: -0.0070
Epoch [39/50] - Loss: -0.0100
Epoch [40/50] - Loss: -0.0129
Epoch [41/50] - Loss: -0.0155
Epoch [42/50] - Loss: -0.0180
Epoch [43/50] - Loss: -0.0204
Epoch [44/50] - Loss: -0.0227
Epoch [45/50] - Loss: -0.0248
Epoch [46/50] - Loss: -0.0269
Epoch [47/50] - Loss: -0.0289
Epoch [48/50] - Loss: -0.0307
Epoch [49/50] - Loss: -0.0326
Epoch [50/50] - Loss: -0.0343
sum preds 503
sum labels 654
 - Test Metrics: Accuracy=0.9013, F1=0.7831, Recall=0.6927, Precision=0.9006
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4978
Epoch [2/50] - Loss: 0.4814
Epoch [3/50] - Loss: 0.4613
Epoch [4/50] - Loss: 0.4385
Epoch [5/50] - Loss: 0.4147
Epoch [6/50] - Loss: 0.3908
Epoch [7/50] - Loss: 0.3672
Epoch [8/50] - Loss: 0.3442
Epoch [9/50] - Loss: 0.3217
Epoch [10/50] - Loss: 0.2999
Epoch [11/50] - Loss: 0.2789
Epoch [12/50] - Loss: 0.2589
Epoch [13/50] - Loss: 0.2398
Epoch [14/50] - Loss: 0.2217
Epoch [15/50] - Loss: 0.2046
Epoch [16/50] - Loss: 0.1884
Epoch [17/50] - Loss: 0.1732
Epoch [18/50] - Loss: 0.1590
Epoch [19/50] - Loss: 0.1458
Epoch [20/50] - Loss: 0.1334
Epoch [21/50] - Loss: 0.1220
Epoch [22/50] - Loss: 0.1114
Epoch [23/50] - Loss: 0.1016
Epoch [24/50] - Loss: 0.0925
Epoch [25/50] - Loss: 0.0841
Epoch [26/50] - Loss: 0.0764
Epoch [27/50] - Loss: 0.0691
Epoch [28/50] - Loss: 0.0624
Epoch [29/50] - Loss: 0.0561
Epoch [30/50] - Loss: 0.0502
Epoch [31/50] - Loss: 0.0447
Epoch [32/50] - Loss: 0.0394
Epoch [33/50] - Loss: 0.0344
Epoch [34/50] - Loss: 0.0298
Epoch [35/50] - Loss: 0.0253
Epoch [36/50] - Loss: 0.0211
Epoch [37/50] - Loss: 0.0171
Epoch [38/50] - Loss: 0.0133
Epoch [39/50] - Loss: 0.0097
Epoch [40/50] - Loss: 0.0063
Epoch [41/50] - Loss: 0.0030
Epoch [42/50] - Loss: -0.0001
Epoch [43/50] - Loss: -0.0030
Epoch [44/50] - Loss: -0.0058
Epoch [45/50] - Loss: -0.0086
Epoch [46/50] - Loss: -0.0111
Epoch [47/50] - Loss: -0.0136
Epoch [48/50] - Loss: -0.0160
Epoch [49/50] - Loss: -0.0182
Epoch [50/50] - Loss: -0.0204
sum preds 475
sum labels 654
 - Test Metrics: Accuracy=0.8864, F1=0.7440, Recall=0.6422, Precision=0.8842
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_imbnnpu_imbnnpu_1804095103.csv.
Average F1 over valid seeds: 0.7668 ± 0.0166
___________________________________________________________________________________
Avg F1 for cora with SAR and imbnnpu, GCNConv,0.2: 0.7668 ± 0.0166
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.0400
Epoch 10 / 50, Loss: 6.1907
Epoch 20 / 50, Loss: 5.8524
Epoch 30 / 50, Loss: 5.8063
Epoch 40 / 50, Loss: 5.9706
sum preds 212.0
sum labels 491
 - Test Metrics: Accuracy=0.8736, F1=0.5718, Recall=0.4094, Precision=0.9481
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.2103
Epoch 10 / 50, Loss: 6.1307
Epoch 20 / 50, Loss: 6.0885
Epoch 30 / 50, Loss: 5.6915
Epoch 40 / 50, Loss: 5.9233
sum preds 233.0
sum labels 491
 - Test Metrics: Accuracy=0.8765, F1=0.5939, Recall=0.4379, Precision=0.9227
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.11206225986408355, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 5.8578
Epoch 10 / 50, Loss: 5.8774
Epoch 20 / 50, Loss: 5.7723
Epoch 30 / 50, Loss: 5.9941
Epoch 40 / 50, Loss: 5.5723
sum preds 201.0
sum labels 491
 - Test Metrics: Accuracy=0.8656, F1=0.5376, Recall=0.3788, Precision=0.9254
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_ours_1804095105.csv.
Average F1 over valid seeds: 0.5678 ± 0.0232
___________________________________________________________________________________
Avg F1 for cora with SAR and ours, GCNConv,0.4: 0.5678 ± 0.0232
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.9903
Epoch 10 / 50, Loss: 7.2424
Epoch 20 / 50, Loss: 6.6302
Epoch 30 / 50, Loss: 6.6374
Epoch 40 / 50, Loss: 6.8704
sum preds 203.0
sum labels 573
 - Test Metrics: Accuracy=0.8417, F1=0.4974, Recall=0.3368, Precision=0.9507
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.1368
Epoch 10 / 50, Loss: 6.9542
Epoch 20 / 50, Loss: 6.9914
Epoch 30 / 50, Loss: 6.5657
Epoch 40 / 50, Loss: 6.8364
sum preds 253.0
sum labels 573
 - Test Metrics: Accuracy=0.8563, F1=0.5714, Recall=0.4119, Precision=0.9328
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.1474310303856642, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 6.9178
Epoch 10 / 50, Loss: 6.8802
Epoch 20 / 50, Loss: 6.8253
Epoch 30 / 50, Loss: 7.0351
Epoch 40 / 50, Loss: 6.3831
sum preds 198.0
sum labels 573
 - Test Metrics: Accuracy=0.8437, F1=0.5006, Recall=0.3368, Precision=0.9747
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_ours_1804095145.csv.
Average F1 over valid seeds: 0.5232 ± 0.0342
___________________________________________________________________________________
Avg F1 for cora with SAR and ours, GCNConv,0.3: 0.5232 ± 0.0342
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.4564
Epoch 10 / 50, Loss: 7.7919
Epoch 20 / 50, Loss: 7.3521
Epoch 30 / 50, Loss: 7.2086
Epoch 40 / 50, Loss: 7.6028
sum preds 156.0
sum labels 654
 - Test Metrics: Accuracy=0.8027, F1=0.3802, Recall=0.2355, Precision=0.9872
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.9932
Epoch 10 / 50, Loss: 8.1107
Epoch 20 / 50, Loss: 7.9970
Epoch 30 / 50, Loss: 7.2109
Epoch 40 / 50, Loss: 7.6391
sum preds 175.0
sum labels 654
 - Test Metrics: Accuracy=0.8023, F1=0.3932, Recall=0.2492, Precision=0.9314
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=17, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.18009008335674812, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 7.7871
Epoch 10 / 50, Loss: 7.8212
Epoch 20 / 50, Loss: 7.7632
Epoch 30 / 50, Loss: 8.0615
Epoch 40 / 50, Loss: 7.3083
sum preds 86.0
sum labels 654
 - Test Metrics: Accuracy=0.7744, F1=0.2243, Recall=0.1269, Precision=0.9651
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to cora_experimentations\cora_SAR_ours_1804095223.csv.
Average F1 over valid seeds: 0.3326 ± 0.0767
___________________________________________________________________________________
Avg F1 for cora with SAR and ours, GCNConv,0.2: 0.3326 ± 0.0767
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 7.0383
Epoch [2/50] - Loss: 5.5288
Epoch [3/50] - Loss: 4.5223
Epoch [4/50] - Loss: 4.3252
Epoch [5/50] - Loss: 4.1727
Epoch [6/50] - Loss: 4.0370
Epoch [7/50] - Loss: 3.9338
Epoch [8/50] - Loss: 3.8409
Epoch [9/50] - Loss: 3.7720
Epoch [10/50] - Loss: 3.7141
Epoch [11/50] - Loss: 3.6709
Epoch [12/50] - Loss: 3.6299
Epoch [13/50] - Loss: 3.5992
Epoch [14/50] - Loss: 3.5803
Epoch [15/50] - Loss: 3.5644
Epoch [16/50] - Loss: 3.5405
Epoch [17/50] - Loss: 3.5313
Epoch [18/50] - Loss: 3.5186
Epoch [19/50] - Loss: 3.5070
Epoch [20/50] - Loss: 3.4897
Epoch [21/50] - Loss: 3.4862
Epoch [22/50] - Loss: 3.4688
Epoch [23/50] - Loss: 3.4634
Epoch [24/50] - Loss: 3.4595
Epoch [25/50] - Loss: 3.4490
Epoch [26/50] - Loss: 3.4363
Epoch [27/50] - Loss: 3.4254
Epoch [28/50] - Loss: 3.4264
Epoch [29/50] - Loss: 3.4146
Epoch [30/50] - Loss: 3.3967
Epoch [31/50] - Loss: 3.3894
Epoch [32/50] - Loss: 3.3779
Epoch [33/50] - Loss: 3.3822
Epoch [34/50] - Loss: 3.3685
Epoch [35/50] - Loss: 3.3486
Epoch [36/50] - Loss: 3.3473
Epoch [37/50] - Loss: 3.3344
Epoch [38/50] - Loss: 3.3260
Epoch [39/50] - Loss: 3.3116
Epoch [40/50] - Loss: 3.3074
Epoch [41/50] - Loss: 3.2939
Epoch [42/50] - Loss: 3.2873
Epoch [43/50] - Loss: 3.2658
Epoch [44/50] - Loss: 3.2690
Epoch [45/50] - Loss: 3.2574
Epoch [46/50] - Loss: 3.2473
Epoch [47/50] - Loss: 3.2294
Epoch [48/50] - Loss: 3.2271
Epoch [49/50] - Loss: 3.2151
Epoch [50/50] - Loss: 3.2071
sum preds 450
sum labels 4725
 - Test Metrics: Accuracy=0.7400, F1=0.1677, Recall=0.0919, Precision=0.9644
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.2058
Epoch [2/50] - Loss: 5.1404
Epoch [3/50] - Loss: 4.4731
Epoch [4/50] - Loss: 4.2455
Epoch [5/50] - Loss: 4.0682
Epoch [6/50] - Loss: 3.9323
Epoch [7/50] - Loss: 3.8177
Epoch [8/50] - Loss: 3.7468
Epoch [9/50] - Loss: 3.6887
Epoch [10/50] - Loss: 3.6410
Epoch [11/50] - Loss: 3.6047
Epoch [12/50] - Loss: 3.5790
Epoch [13/50] - Loss: 3.5591
Epoch [14/50] - Loss: 3.5382
Epoch [15/50] - Loss: 3.5310
Epoch [16/50] - Loss: 3.5098
Epoch [17/50] - Loss: 3.4955
Epoch [18/50] - Loss: 3.5044
Epoch [19/50] - Loss: 3.4833
Epoch [20/50] - Loss: 3.4791
Epoch [21/50] - Loss: 3.4702
Epoch [22/50] - Loss: 3.4706
Epoch [23/50] - Loss: 3.4614
Epoch [24/50] - Loss: 3.4598
Epoch [25/50] - Loss: 3.4491
Epoch [26/50] - Loss: 3.4457
Epoch [27/50] - Loss: 3.4427
Epoch [28/50] - Loss: 3.4366
Epoch [29/50] - Loss: 3.4271
Epoch [30/50] - Loss: 3.4269
Epoch [31/50] - Loss: 3.4076
Epoch [32/50] - Loss: 3.4072
Epoch [33/50] - Loss: 3.4012
Epoch [34/50] - Loss: 3.3978
Epoch [35/50] - Loss: 3.3924
Epoch [36/50] - Loss: 3.3896
Epoch [37/50] - Loss: 3.3754
Epoch [38/50] - Loss: 3.3665
Epoch [39/50] - Loss: 3.3635
Epoch [40/50] - Loss: 3.3610
Epoch [41/50] - Loss: 3.3416
Epoch [42/50] - Loss: 3.3346
Epoch [43/50] - Loss: 3.3323
Epoch [44/50] - Loss: 3.3262
Epoch [45/50] - Loss: 3.3166
Epoch [46/50] - Loss: 3.2997
Epoch [47/50] - Loss: 3.2905
Epoch [48/50] - Loss: 3.2834
Epoch [49/50] - Loss: 3.2779
Epoch [50/50] - Loss: 3.2698
sum preds 447
sum labels 4725
 - Test Metrics: Accuracy=0.7394, F1=0.1651, Recall=0.0904, Precision=0.9553
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.5634
Epoch [2/50] - Loss: 5.3001
Epoch [3/50] - Loss: 4.5182
Epoch [4/50] - Loss: 4.2953
Epoch [5/50] - Loss: 4.1472
Epoch [6/50] - Loss: 3.9987
Epoch [7/50] - Loss: 3.9057
Epoch [8/50] - Loss: 3.8101
Epoch [9/50] - Loss: 3.7483
Epoch [10/50] - Loss: 3.6944
Epoch [11/50] - Loss: 3.6571
Epoch [12/50] - Loss: 3.6183
Epoch [13/50] - Loss: 3.5800
Epoch [14/50] - Loss: 3.5574
Epoch [15/50] - Loss: 3.5288
Epoch [16/50] - Loss: 3.5084
Epoch [17/50] - Loss: 3.4780
Epoch [18/50] - Loss: 3.4466
Epoch [19/50] - Loss: 3.4367
Epoch [20/50] - Loss: 3.4089
Epoch [21/50] - Loss: 3.3996
Epoch [22/50] - Loss: 3.3744
Epoch [23/50] - Loss: 3.3591
Epoch [24/50] - Loss: 3.3424
Epoch [25/50] - Loss: 3.3214
Epoch [26/50] - Loss: 3.3074
Epoch [27/50] - Loss: 3.2945
Epoch [28/50] - Loss: 3.2774
Epoch [29/50] - Loss: 3.2695
Epoch [30/50] - Loss: 3.2521
Epoch [31/50] - Loss: 3.2437
Epoch [32/50] - Loss: 3.2288
Epoch [33/50] - Loss: 3.2210
Epoch [34/50] - Loss: 3.2094
Epoch [35/50] - Loss: 3.2000
Epoch [36/50] - Loss: 3.1782
Epoch [37/50] - Loss: 3.1749
Epoch [38/50] - Loss: 3.1668
Epoch [39/50] - Loss: 3.1464
Epoch [40/50] - Loss: 3.1409
Epoch [41/50] - Loss: 3.1314
Epoch [42/50] - Loss: 3.1187
Epoch [43/50] - Loss: 3.1123
Epoch [44/50] - Loss: 3.1056
Epoch [45/50] - Loss: 3.0962
Epoch [46/50] - Loss: 3.0754
Epoch [47/50] - Loss: 3.0719
Epoch [48/50] - Loss: 3.0615
Epoch [49/50] - Loss: 3.0541
Epoch [50/50] - Loss: 3.0443
sum preds 558
sum labels 4725
 - Test Metrics: Accuracy=0.7440, F1=0.1972, Recall=0.1103, Precision=0.9337
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_naive_naive_1804095302.csv.
Average F1 over valid seeds: 0.1767 ± 0.0146
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and naive, MLP,0.4: 0.1767 ± 0.0146
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.8596
Epoch [2/50] - Loss: 4.5364
Epoch [3/50] - Loss: 4.3614
Epoch [4/50] - Loss: 4.1948
Epoch [5/50] - Loss: 4.0736
Epoch [6/50] - Loss: 3.9802
Epoch [7/50] - Loss: 3.8990
Epoch [8/50] - Loss: 3.8269
Epoch [9/50] - Loss: 3.7588
Epoch [10/50] - Loss: 3.7089
Epoch [11/50] - Loss: 3.6625
Epoch [12/50] - Loss: 3.6326
Epoch [13/50] - Loss: 3.6094
Epoch [14/50] - Loss: 3.5768
Epoch [15/50] - Loss: 3.5577
Epoch [16/50] - Loss: 3.5307
Epoch [17/50] - Loss: 3.5083
Epoch [18/50] - Loss: 3.5007
Epoch [19/50] - Loss: 3.4789
Epoch [20/50] - Loss: 3.4765
Epoch [21/50] - Loss: 3.4553
Epoch [22/50] - Loss: 3.4442
Epoch [23/50] - Loss: 3.4240
Epoch [24/50] - Loss: 3.4028
Epoch [25/50] - Loss: 3.3960
Epoch [26/50] - Loss: 3.3767
Epoch [27/50] - Loss: 3.3687
Epoch [28/50] - Loss: 3.3598
Epoch [29/50] - Loss: 3.3395
Epoch [30/50] - Loss: 3.3226
Epoch [31/50] - Loss: 3.3180
Epoch [32/50] - Loss: 3.3100
Epoch [33/50] - Loss: 3.2949
Epoch [34/50] - Loss: 3.2740
Epoch [35/50] - Loss: 3.2771
Epoch [36/50] - Loss: 3.2587
Epoch [37/50] - Loss: 3.2480
Epoch [38/50] - Loss: 3.2410
Epoch [39/50] - Loss: 3.2281
Epoch [40/50] - Loss: 3.2107
Epoch [41/50] - Loss: 3.2174
Epoch [42/50] - Loss: 3.2031
Epoch [43/50] - Loss: 3.1937
Epoch [44/50] - Loss: 3.1855
Epoch [45/50] - Loss: 3.1755
Epoch [46/50] - Loss: 3.1692
Epoch [47/50] - Loss: 3.1494
Epoch [48/50] - Loss: 3.1441
Epoch [49/50] - Loss: 3.1370
Epoch [50/50] - Loss: 3.1350
sum preds 489
sum labels 4725
 - Test Metrics: Accuracy=0.7411, F1=0.1772, Recall=0.0978, Precision=0.9448
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.0075
Epoch [2/50] - Loss: 4.6593
Epoch [3/50] - Loss: 4.3642
Epoch [4/50] - Loss: 4.2516
Epoch [5/50] - Loss: 4.1033
Epoch [6/50] - Loss: 4.0094
Epoch [7/50] - Loss: 3.9125
Epoch [8/50] - Loss: 3.8333
Epoch [9/50] - Loss: 3.7714
Epoch [10/50] - Loss: 3.7146
Epoch [11/50] - Loss: 3.6695
Epoch [12/50] - Loss: 3.6250
Epoch [13/50] - Loss: 3.5979
Epoch [14/50] - Loss: 3.5745
Epoch [15/50] - Loss: 3.5411
Epoch [16/50] - Loss: 3.5212
Epoch [17/50] - Loss: 3.4955
Epoch [18/50] - Loss: 3.4819
Epoch [19/50] - Loss: 3.4625
Epoch [20/50] - Loss: 3.4382
Epoch [21/50] - Loss: 3.4315
Epoch [22/50] - Loss: 3.4056
Epoch [23/50] - Loss: 3.3973
Epoch [24/50] - Loss: 3.3866
Epoch [25/50] - Loss: 3.3649
Epoch [26/50] - Loss: 3.3476
Epoch [27/50] - Loss: 3.3376
Epoch [28/50] - Loss: 3.3245
Epoch [29/50] - Loss: 3.3157
Epoch [30/50] - Loss: 3.3037
Epoch [31/50] - Loss: 3.2849
Epoch [32/50] - Loss: 3.2780
Epoch [33/50] - Loss: 3.2621
Epoch [34/50] - Loss: 3.2530
Epoch [35/50] - Loss: 3.2361
Epoch [36/50] - Loss: 3.2295
Epoch [37/50] - Loss: 3.2177
Epoch [38/50] - Loss: 3.2063
Epoch [39/50] - Loss: 3.2026
Epoch [40/50] - Loss: 3.1833
Epoch [41/50] - Loss: 3.1864
Epoch [42/50] - Loss: 3.1770
Epoch [43/50] - Loss: 3.1617
Epoch [44/50] - Loss: 3.1607
Epoch [45/50] - Loss: 3.1491
Epoch [46/50] - Loss: 3.1497
Epoch [47/50] - Loss: 3.1395
Epoch [48/50] - Loss: 3.1288
Epoch [49/50] - Loss: 3.1268
Epoch [50/50] - Loss: 3.1122
sum preds 330
sum labels 4725
 - Test Metrics: Accuracy=0.7322, F1=0.1223, Recall=0.0654, Precision=0.9364
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.2077
Epoch [2/50] - Loss: 4.9145
Epoch [3/50] - Loss: 4.4234
Epoch [4/50] - Loss: 4.3162
Epoch [5/50] - Loss: 4.1966
Epoch [6/50] - Loss: 4.0840
Epoch [7/50] - Loss: 4.0021
Epoch [8/50] - Loss: 3.9115
Epoch [9/50] - Loss: 3.8405
Epoch [10/50] - Loss: 3.7706
Epoch [11/50] - Loss: 3.7174
Epoch [12/50] - Loss: 3.6591
Epoch [13/50] - Loss: 3.6145
Epoch [14/50] - Loss: 3.5784
Epoch [15/50] - Loss: 3.5358
Epoch [16/50] - Loss: 3.4941
Epoch [17/50] - Loss: 3.4731
Epoch [18/50] - Loss: 3.4319
Epoch [19/50] - Loss: 3.4056
Epoch [20/50] - Loss: 3.3877
Epoch [21/50] - Loss: 3.3662
Epoch [22/50] - Loss: 3.3543
Epoch [23/50] - Loss: 3.3448
Epoch [24/50] - Loss: 3.3271
Epoch [25/50] - Loss: 3.3097
Epoch [26/50] - Loss: 3.2968
Epoch [27/50] - Loss: 3.2914
Epoch [28/50] - Loss: 3.2712
Epoch [29/50] - Loss: 3.2624
Epoch [30/50] - Loss: 3.2528
Epoch [31/50] - Loss: 3.2441
Epoch [32/50] - Loss: 3.2255
Epoch [33/50] - Loss: 3.2220
Epoch [34/50] - Loss: 3.2209
Epoch [35/50] - Loss: 3.2111
Epoch [36/50] - Loss: 3.1984
Epoch [37/50] - Loss: 3.1863
Epoch [38/50] - Loss: 3.1806
Epoch [39/50] - Loss: 3.1784
Epoch [40/50] - Loss: 3.1629
Epoch [41/50] - Loss: 3.1533
Epoch [42/50] - Loss: 3.1494
Epoch [43/50] - Loss: 3.1390
Epoch [44/50] - Loss: 3.1247
Epoch [45/50] - Loss: 3.1141
Epoch [46/50] - Loss: 3.1112
Epoch [47/50] - Loss: 3.0907
Epoch [48/50] - Loss: 3.0827
Epoch [49/50] - Loss: 3.0795
Epoch [50/50] - Loss: 3.0525
sum preds 443
sum labels 4725
 - Test Metrics: Accuracy=0.7382, F1=0.1606, Recall=0.0878, Precision=0.9368
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_naive_naive_1804101927.csv.
Average F1 over valid seeds: 0.1534 ± 0.0230
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and naive, GATConv,0.4: 0.1534 ± 0.0230
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.3523
Epoch [2/50] - Loss: 5.1863
Epoch [3/50] - Loss: 4.5706
Epoch [4/50] - Loss: 4.4181
Epoch [5/50] - Loss: 4.3495
Epoch [6/50] - Loss: 4.2588
Epoch [7/50] - Loss: 4.1749
Epoch [8/50] - Loss: 4.1240
Epoch [9/50] - Loss: 4.0499
Epoch [10/50] - Loss: 3.9912
Epoch [11/50] - Loss: 3.9377
Epoch [12/50] - Loss: 3.8965
Epoch [13/50] - Loss: 3.8474
Epoch [14/50] - Loss: 3.8161
Epoch [15/50] - Loss: 3.7733
Epoch [16/50] - Loss: 3.7282
Epoch [17/50] - Loss: 3.6951
Epoch [18/50] - Loss: 3.6585
Epoch [19/50] - Loss: 3.6277
Epoch [20/50] - Loss: 3.6064
Epoch [21/50] - Loss: 3.5759
Epoch [22/50] - Loss: 3.5620
Epoch [23/50] - Loss: 3.5412
Epoch [24/50] - Loss: 3.5294
Epoch [25/50] - Loss: 3.5155
Epoch [26/50] - Loss: 3.5136
Epoch [27/50] - Loss: 3.4970
Epoch [28/50] - Loss: 3.4891
Epoch [29/50] - Loss: 3.4872
Epoch [30/50] - Loss: 3.4766
Epoch [31/50] - Loss: 3.4584
Epoch [32/50] - Loss: 3.4593
Epoch [33/50] - Loss: 3.4517
Epoch [34/50] - Loss: 3.4470
Epoch [35/50] - Loss: 3.4488
Epoch [36/50] - Loss: 3.4444
Epoch [37/50] - Loss: 3.4249
Epoch [38/50] - Loss: 3.4296
Epoch [39/50] - Loss: 3.4350
Epoch [40/50] - Loss: 3.4295
Epoch [41/50] - Loss: 3.4233
Epoch [42/50] - Loss: 3.4135
Epoch [43/50] - Loss: 3.4047
Epoch [44/50] - Loss: 3.4172
Epoch [45/50] - Loss: 3.4093
Epoch [46/50] - Loss: 3.4018
Epoch [47/50] - Loss: 3.4032
Epoch [48/50] - Loss: 3.3952
Epoch [49/50] - Loss: 3.3922
Epoch [50/50] - Loss: 3.3938
sum preds 0
sum labels 4725
 - Test Metrics: Accuracy=0.7148, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.3430
Epoch [2/50] - Loss: 5.1884
Epoch [3/50] - Loss: 4.5751
Epoch [4/50] - Loss: 4.4083
Epoch [5/50] - Loss: 4.3308
Epoch [6/50] - Loss: 4.2445
Epoch [7/50] - Loss: 4.1749
Epoch [8/50] - Loss: 4.1030
Epoch [9/50] - Loss: 4.0427
Epoch [10/50] - Loss: 3.9876
Epoch [11/50] - Loss: 3.9367
Epoch [12/50] - Loss: 3.8929
Epoch [13/50] - Loss: 3.8379
Epoch [14/50] - Loss: 3.8065
Epoch [15/50] - Loss: 3.7746
Epoch [16/50] - Loss: 3.7394
Epoch [17/50] - Loss: 3.7220
Epoch [18/50] - Loss: 3.6900
Epoch [19/50] - Loss: 3.6689
Epoch [20/50] - Loss: 3.6572
Epoch [21/50] - Loss: 3.6349
Epoch [22/50] - Loss: 3.6148
Epoch [23/50] - Loss: 3.6091
Epoch [24/50] - Loss: 3.5996
Epoch [25/50] - Loss: 3.5854
Epoch [26/50] - Loss: 3.5743
Epoch [27/50] - Loss: 3.5608
Epoch [28/50] - Loss: 3.5506
Epoch [29/50] - Loss: 3.5441
Epoch [30/50] - Loss: 3.5336
Epoch [31/50] - Loss: 3.5275
Epoch [32/50] - Loss: 3.5202
Epoch [33/50] - Loss: 3.5128
Epoch [34/50] - Loss: 3.5041
Epoch [35/50] - Loss: 3.4980
Epoch [36/50] - Loss: 3.4953
Epoch [37/50] - Loss: 3.4936
Epoch [38/50] - Loss: 3.4775
Epoch [39/50] - Loss: 3.4733
Epoch [40/50] - Loss: 3.4755
Epoch [41/50] - Loss: 3.4658
Epoch [42/50] - Loss: 3.4625
Epoch [43/50] - Loss: 3.4567
Epoch [44/50] - Loss: 3.4545
Epoch [45/50] - Loss: 3.4493
Epoch [46/50] - Loss: 3.4476
Epoch [47/50] - Loss: 3.4476
Epoch [48/50] - Loss: 3.4337
Epoch [49/50] - Loss: 3.4278
Epoch [50/50] - Loss: 3.4348
sum preds 0
sum labels 4725
 - Test Metrics: Accuracy=0.7148, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.4050
Epoch [2/50] - Loss: 5.2489
Epoch [3/50] - Loss: 4.5839
Epoch [4/50] - Loss: 4.4253
Epoch [5/50] - Loss: 4.3422
Epoch [6/50] - Loss: 4.2250
Epoch [7/50] - Loss: 4.1466
Epoch [8/50] - Loss: 4.0733
Epoch [9/50] - Loss: 3.9962
Epoch [10/50] - Loss: 3.9431
Epoch [11/50] - Loss: 3.8781
Epoch [12/50] - Loss: 3.8390
Epoch [13/50] - Loss: 3.8006
Epoch [14/50] - Loss: 3.7591
Epoch [15/50] - Loss: 3.7171
Epoch [16/50] - Loss: 3.6936
Epoch [17/50] - Loss: 3.6608
Epoch [18/50] - Loss: 3.6367
Epoch [19/50] - Loss: 3.6255
Epoch [20/50] - Loss: 3.6144
Epoch [21/50] - Loss: 3.5908
Epoch [22/50] - Loss: 3.5653
Epoch [23/50] - Loss: 3.5602
Epoch [24/50] - Loss: 3.5500
Epoch [25/50] - Loss: 3.5324
Epoch [26/50] - Loss: 3.5332
Epoch [27/50] - Loss: 3.5173
Epoch [28/50] - Loss: 3.5087
Epoch [29/50] - Loss: 3.4997
Epoch [30/50] - Loss: 3.4860
Epoch [31/50] - Loss: 3.4800
Epoch [32/50] - Loss: 3.4683
Epoch [33/50] - Loss: 3.4685
Epoch [34/50] - Loss: 3.4593
Epoch [35/50] - Loss: 3.4623
Epoch [36/50] - Loss: 3.4590
Epoch [37/50] - Loss: 3.4484
Epoch [38/50] - Loss: 3.4328
Epoch [39/50] - Loss: 3.4291
Epoch [40/50] - Loss: 3.4302
Epoch [41/50] - Loss: 3.4192
Epoch [42/50] - Loss: 3.4258
Epoch [43/50] - Loss: 3.4115
Epoch [44/50] - Loss: 3.4071
Epoch [45/50] - Loss: 3.4055
Epoch [46/50] - Loss: 3.3988
Epoch [47/50] - Loss: 3.3960
Epoch [48/50] - Loss: 3.3883
Epoch [49/50] - Loss: 3.3895
Epoch [50/50] - Loss: 3.3800
sum preds 0
sum labels 4725
 - Test Metrics: Accuracy=0.7148, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_naive_naive_1804104612.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and naive, GCNConv,0.4: 0.0000 ± 0.0000
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 7.0483
Epoch [2/50] - Loss: 5.3084
Epoch [3/50] - Loss: 3.9819
Epoch [4/50] - Loss: 3.6670
Epoch [5/50] - Loss: 3.5883
Epoch [6/50] - Loss: 3.4619
Epoch [7/50] - Loss: 3.3880
Epoch [8/50] - Loss: 3.3139
Epoch [9/50] - Loss: 3.2595
Epoch [10/50] - Loss: 3.2136
Epoch [11/50] - Loss: 3.1778
Epoch [12/50] - Loss: 3.1425
Epoch [13/50] - Loss: 3.1177
Epoch [14/50] - Loss: 3.0959
Epoch [15/50] - Loss: 3.0860
Epoch [16/50] - Loss: 3.0635
Epoch [17/50] - Loss: 3.0529
Epoch [18/50] - Loss: 3.0434
Epoch [19/50] - Loss: 3.0327
Epoch [20/50] - Loss: 3.0187
Epoch [21/50] - Loss: 3.0129
Epoch [22/50] - Loss: 3.0021
Epoch [23/50] - Loss: 3.0037
Epoch [24/50] - Loss: 3.0007
Epoch [25/50] - Loss: 2.9938
Epoch [26/50] - Loss: 2.9861
Epoch [27/50] - Loss: 2.9787
Epoch [28/50] - Loss: 2.9808
Epoch [29/50] - Loss: 2.9789
Epoch [30/50] - Loss: 2.9685
Epoch [31/50] - Loss: 2.9664
Epoch [32/50] - Loss: 2.9638
Epoch [33/50] - Loss: 2.9745
Epoch [34/50] - Loss: 2.9690
Epoch [35/50] - Loss: 2.9565
Epoch [36/50] - Loss: 2.9660
Epoch [37/50] - Loss: 2.9572
Epoch [38/50] - Loss: 2.9563
Epoch [39/50] - Loss: 2.9517
Epoch [40/50] - Loss: 2.9540
Epoch [41/50] - Loss: 2.9485
Epoch [42/50] - Loss: 2.9504
Epoch [43/50] - Loss: 2.9373
Epoch [44/50] - Loss: 2.9489
Epoch [45/50] - Loss: 2.9456
Epoch [46/50] - Loss: 2.9427
Epoch [47/50] - Loss: 2.9370
Epoch [48/50] - Loss: 2.9402
Epoch [49/50] - Loss: 2.9370
Epoch [50/50] - Loss: 2.9378
sum preds 150
sum labels 5513
 - Test Metrics: Accuracy=0.6898, F1=0.0494, Recall=0.0254, Precision=0.9333
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.1051
Epoch [2/50] - Loss: 4.8257
Epoch [3/50] - Loss: 3.9240
Epoch [4/50] - Loss: 3.6513
Epoch [5/50] - Loss: 3.5629
Epoch [6/50] - Loss: 3.4528
Epoch [7/50] - Loss: 3.3492
Epoch [8/50] - Loss: 3.2689
Epoch [9/50] - Loss: 3.2025
Epoch [10/50] - Loss: 3.1535
Epoch [11/50] - Loss: 3.1145
Epoch [12/50] - Loss: 3.0872
Epoch [13/50] - Loss: 3.0654
Epoch [14/50] - Loss: 3.0462
Epoch [15/50] - Loss: 3.0386
Epoch [16/50] - Loss: 3.0163
Epoch [17/50] - Loss: 3.0061
Epoch [18/50] - Loss: 3.0107
Epoch [19/50] - Loss: 2.9927
Epoch [20/50] - Loss: 2.9896
Epoch [21/50] - Loss: 2.9801
Epoch [22/50] - Loss: 2.9811
Epoch [23/50] - Loss: 2.9724
Epoch [24/50] - Loss: 2.9725
Epoch [25/50] - Loss: 2.9621
Epoch [26/50] - Loss: 2.9594
Epoch [27/50] - Loss: 2.9595
Epoch [28/50] - Loss: 2.9559
Epoch [29/50] - Loss: 2.9510
Epoch [30/50] - Loss: 2.9508
Epoch [31/50] - Loss: 2.9408
Epoch [32/50] - Loss: 2.9426
Epoch [33/50] - Loss: 2.9426
Epoch [34/50] - Loss: 2.9404
Epoch [35/50] - Loss: 2.9395
Epoch [36/50] - Loss: 2.9399
Epoch [37/50] - Loss: 2.9297
Epoch [38/50] - Loss: 2.9265
Epoch [39/50] - Loss: 2.9232
Epoch [40/50] - Loss: 2.9309
Epoch [41/50] - Loss: 2.9163
Epoch [42/50] - Loss: 2.9179
Epoch [43/50] - Loss: 2.9217
Epoch [44/50] - Loss: 2.9180
Epoch [45/50] - Loss: 2.9123
Epoch [46/50] - Loss: 2.9050
Epoch [47/50] - Loss: 2.9019
Epoch [48/50] - Loss: 2.9020
Epoch [49/50] - Loss: 2.9030
Epoch [50/50] - Loss: 2.8975
sum preds 209
sum labels 5513
 - Test Metrics: Accuracy=0.6936, F1=0.0706, Recall=0.0366, Precision=0.9665
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.5129
Epoch [2/50] - Loss: 5.0279
Epoch [3/50] - Loss: 3.9905
Epoch [4/50] - Loss: 3.6820
Epoch [5/50] - Loss: 3.6285
Epoch [6/50] - Loss: 3.5266
Epoch [7/50] - Loss: 3.4657
Epoch [8/50] - Loss: 3.4019
Epoch [9/50] - Loss: 3.3605
Epoch [10/50] - Loss: 3.3152
Epoch [11/50] - Loss: 3.2841
Epoch [12/50] - Loss: 3.2457
Epoch [13/50] - Loss: 3.2082
Epoch [14/50] - Loss: 3.1867
Epoch [15/50] - Loss: 3.1572
Epoch [16/50] - Loss: 3.1323
Epoch [17/50] - Loss: 3.0984
Epoch [18/50] - Loss: 3.0554
Epoch [19/50] - Loss: 3.0348
Epoch [20/50] - Loss: 2.9975
Epoch [21/50] - Loss: 2.9812
Epoch [22/50] - Loss: 2.9504
Epoch [23/50] - Loss: 2.9303
Epoch [24/50] - Loss: 2.9128
Epoch [25/50] - Loss: 2.8913
Epoch [26/50] - Loss: 2.8779
Epoch [27/50] - Loss: 2.8681
Epoch [28/50] - Loss: 2.8542
Epoch [29/50] - Loss: 2.8477
Epoch [30/50] - Loss: 2.8326
Epoch [31/50] - Loss: 2.8208
Epoch [32/50] - Loss: 2.8113
Epoch [33/50] - Loss: 2.8096
Epoch [34/50] - Loss: 2.7998
Epoch [35/50] - Loss: 2.7924
Epoch [36/50] - Loss: 2.7733
Epoch [37/50] - Loss: 2.7733
Epoch [38/50] - Loss: 2.7692
Epoch [39/50] - Loss: 2.7554
Epoch [40/50] - Loss: 2.7497
Epoch [41/50] - Loss: 2.7422
Epoch [42/50] - Loss: 2.7351
Epoch [43/50] - Loss: 2.7287
Epoch [44/50] - Loss: 2.7293
Epoch [45/50] - Loss: 2.7174
Epoch [46/50] - Loss: 2.6993
Epoch [47/50] - Loss: 2.7020
Epoch [48/50] - Loss: 2.6950
Epoch [49/50] - Loss: 2.6888
Epoch [50/50] - Loss: 2.6807
sum preds 0
sum labels 5513
 - Test Metrics: Accuracy=0.6823, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_naive_naive_1804111258.csv.
Average F1 over valid seeds: 0.0400 ± 0.0296
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and naive, MLP,0.3: 0.0400 ± 0.0296
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.6883
Epoch [2/50] - Loss: 3.9809
Epoch [3/50] - Loss: 3.7019
Epoch [4/50] - Loss: 3.6162
Epoch [5/50] - Loss: 3.4926
Epoch [6/50] - Loss: 3.4337
Epoch [7/50] - Loss: 3.3745
Epoch [8/50] - Loss: 3.3210
Epoch [9/50] - Loss: 3.2730
Epoch [10/50] - Loss: 3.2396
Epoch [11/50] - Loss: 3.2029
Epoch [12/50] - Loss: 3.1810
Epoch [13/50] - Loss: 3.1600
Epoch [14/50] - Loss: 3.1283
Epoch [15/50] - Loss: 3.1147
Epoch [16/50] - Loss: 3.0873
Epoch [17/50] - Loss: 3.0707
Epoch [18/50] - Loss: 3.0659
Epoch [19/50] - Loss: 3.0473
Epoch [20/50] - Loss: 3.0482
Epoch [21/50] - Loss: 3.0263
Epoch [22/50] - Loss: 3.0173
Epoch [23/50] - Loss: 2.9958
Epoch [24/50] - Loss: 2.9814
Epoch [25/50] - Loss: 2.9783
Epoch [26/50] - Loss: 2.9595
Epoch [27/50] - Loss: 2.9573
Epoch [28/50] - Loss: 2.9473
Epoch [29/50] - Loss: 2.9328
Epoch [30/50] - Loss: 2.9182
Epoch [31/50] - Loss: 2.9115
Epoch [32/50] - Loss: 2.9081
Epoch [33/50] - Loss: 2.8944
Epoch [34/50] - Loss: 2.8788
Epoch [35/50] - Loss: 2.8801
Epoch [36/50] - Loss: 2.8638
Epoch [37/50] - Loss: 2.8552
Epoch [38/50] - Loss: 2.8463
Epoch [39/50] - Loss: 2.8329
Epoch [40/50] - Loss: 2.8185
Epoch [41/50] - Loss: 2.8194
Epoch [42/50] - Loss: 2.8078
Epoch [43/50] - Loss: 2.7985
Epoch [44/50] - Loss: 2.7849
Epoch [45/50] - Loss: 2.7786
Epoch [46/50] - Loss: 2.7726
Epoch [47/50] - Loss: 2.7563
Epoch [48/50] - Loss: 2.7503
Epoch [49/50] - Loss: 2.7360
Epoch [50/50] - Loss: 2.7366
sum preds 39
sum labels 5513
 - Test Metrics: Accuracy=0.6845, F1=0.0137, Recall=0.0069, Precision=0.9744
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.8723
Epoch [2/50] - Loss: 4.1859
Epoch [3/50] - Loss: 3.6981
Epoch [4/50] - Loss: 3.6473
Epoch [5/50] - Loss: 3.5362
Epoch [6/50] - Loss: 3.4634
Epoch [7/50] - Loss: 3.3914
Epoch [8/50] - Loss: 3.3339
Epoch [9/50] - Loss: 3.2863
Epoch [10/50] - Loss: 3.2407
Epoch [11/50] - Loss: 3.2054
Epoch [12/50] - Loss: 3.1663
Epoch [13/50] - Loss: 3.1428
Epoch [14/50] - Loss: 3.1189
Epoch [15/50] - Loss: 3.0931
Epoch [16/50] - Loss: 3.0771
Epoch [17/50] - Loss: 3.0526
Epoch [18/50] - Loss: 3.0406
Epoch [19/50] - Loss: 3.0268
Epoch [20/50] - Loss: 3.0067
Epoch [21/50] - Loss: 2.9982
Epoch [22/50] - Loss: 2.9744
Epoch [23/50] - Loss: 2.9664
Epoch [24/50] - Loss: 2.9571
Epoch [25/50] - Loss: 2.9361
Epoch [26/50] - Loss: 2.9224
Epoch [27/50] - Loss: 2.9170
Epoch [28/50] - Loss: 2.9041
Epoch [29/50] - Loss: 2.8957
Epoch [30/50] - Loss: 2.8878
Epoch [31/50] - Loss: 2.8681
Epoch [32/50] - Loss: 2.8618
Epoch [33/50] - Loss: 2.8513
Epoch [34/50] - Loss: 2.8386
Epoch [35/50] - Loss: 2.8212
Epoch [36/50] - Loss: 2.8158
Epoch [37/50] - Loss: 2.8046
Epoch [38/50] - Loss: 2.7934
Epoch [39/50] - Loss: 2.7898
Epoch [40/50] - Loss: 2.7704
Epoch [41/50] - Loss: 2.7685
Epoch [42/50] - Loss: 2.7595
Epoch [43/50] - Loss: 2.7466
Epoch [44/50] - Loss: 2.7441
Epoch [45/50] - Loss: 2.7314
Epoch [46/50] - Loss: 2.7349
Epoch [47/50] - Loss: 2.7254
Epoch [48/50] - Loss: 2.7144
Epoch [49/50] - Loss: 2.7141
Epoch [50/50] - Loss: 2.7018
sum preds 87
sum labels 5513
 - Test Metrics: Accuracy=0.6868, F1=0.0293, Recall=0.0149, Precision=0.9425
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.1013
Epoch [2/50] - Loss: 4.5287
Epoch [3/50] - Loss: 3.8003
Epoch [4/50] - Loss: 3.6706
Epoch [5/50] - Loss: 3.6104
Epoch [6/50] - Loss: 3.5120
Epoch [7/50] - Loss: 3.4529
Epoch [8/50] - Loss: 3.3916
Epoch [9/50] - Loss: 3.3427
Epoch [10/50] - Loss: 3.2923
Epoch [11/50] - Loss: 3.2577
Epoch [12/50] - Loss: 3.2235
Epoch [13/50] - Loss: 3.1952
Epoch [14/50] - Loss: 3.1739
Epoch [15/50] - Loss: 3.1365
Epoch [16/50] - Loss: 3.1020
Epoch [17/50] - Loss: 3.0825
Epoch [18/50] - Loss: 3.0434
Epoch [19/50] - Loss: 3.0175
Epoch [20/50] - Loss: 2.9967
Epoch [21/50] - Loss: 2.9713
Epoch [22/50] - Loss: 2.9557
Epoch [23/50] - Loss: 2.9465
Epoch [24/50] - Loss: 2.9277
Epoch [25/50] - Loss: 2.9101
Epoch [26/50] - Loss: 2.8964
Epoch [27/50] - Loss: 2.8881
Epoch [28/50] - Loss: 2.8667
Epoch [29/50] - Loss: 2.8610
Epoch [30/50] - Loss: 2.8507
Epoch [31/50] - Loss: 2.8419
Epoch [32/50] - Loss: 2.8198
Epoch [33/50] - Loss: 2.8169
Epoch [34/50] - Loss: 2.8164
Epoch [35/50] - Loss: 2.8030
Epoch [36/50] - Loss: 2.7910
Epoch [37/50] - Loss: 2.7801
Epoch [38/50] - Loss: 2.7723
Epoch [39/50] - Loss: 2.7679
Epoch [40/50] - Loss: 2.7546
Epoch [41/50] - Loss: 2.7443
Epoch [42/50] - Loss: 2.7451
Epoch [43/50] - Loss: 2.7319
Epoch [44/50] - Loss: 2.7194
Epoch [45/50] - Loss: 2.7080
Epoch [46/50] - Loss: 2.7035
Epoch [47/50] - Loss: 2.6832
Epoch [48/50] - Loss: 2.6777
Epoch [49/50] - Loss: 2.6702
Epoch [50/50] - Loss: 2.6497
sum preds 183
sum labels 5513
 - Test Metrics: Accuracy=0.6921, F1=0.0618, Recall=0.0319, Precision=0.9617
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_naive_naive_1804114038.csv.
Average F1 over valid seeds: 0.0349 ± 0.0200
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and naive, GATConv,0.3: 0.0349 ± 0.0200
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.2736
Epoch [2/50] - Loss: 4.8835
Epoch [3/50] - Loss: 4.0292
Epoch [4/50] - Loss: 3.7610
Epoch [5/50] - Loss: 3.7147
Epoch [6/50] - Loss: 3.6592
Epoch [7/50] - Loss: 3.5854
Epoch [8/50] - Loss: 3.5518
Epoch [9/50] - Loss: 3.5046
Epoch [10/50] - Loss: 3.4613
Epoch [11/50] - Loss: 3.4259
Epoch [12/50] - Loss: 3.4027
Epoch [13/50] - Loss: 3.3666
Epoch [14/50] - Loss: 3.3415
Epoch [15/50] - Loss: 3.3155
Epoch [16/50] - Loss: 3.2922
Epoch [17/50] - Loss: 3.2742
Epoch [18/50] - Loss: 3.2489
Epoch [19/50] - Loss: 3.2236
Epoch [20/50] - Loss: 3.2001
Epoch [21/50] - Loss: 3.1680
Epoch [22/50] - Loss: 3.1420
Epoch [23/50] - Loss: 3.1219
Epoch [24/50] - Loss: 3.1020
Epoch [25/50] - Loss: 3.0857
Epoch [26/50] - Loss: 3.0797
Epoch [27/50] - Loss: 3.0620
Epoch [28/50] - Loss: 3.0482
Epoch [29/50] - Loss: 3.0479
Epoch [30/50] - Loss: 3.0309
Epoch [31/50] - Loss: 3.0166
Epoch [32/50] - Loss: 3.0155
Epoch [33/50] - Loss: 3.0057
Epoch [34/50] - Loss: 2.9999
Epoch [35/50] - Loss: 3.0017
Epoch [36/50] - Loss: 2.9973
Epoch [37/50] - Loss: 2.9750
Epoch [38/50] - Loss: 2.9835
Epoch [39/50] - Loss: 2.9818
Epoch [40/50] - Loss: 2.9764
Epoch [41/50] - Loss: 2.9729
Epoch [42/50] - Loss: 2.9648
Epoch [43/50] - Loss: 2.9527
Epoch [44/50] - Loss: 2.9663
Epoch [45/50] - Loss: 2.9546
Epoch [46/50] - Loss: 2.9503
Epoch [47/50] - Loss: 2.9565
Epoch [48/50] - Loss: 2.9431
Epoch [49/50] - Loss: 2.9458
Epoch [50/50] - Loss: 2.9421
sum preds 0
sum labels 5513
 - Test Metrics: Accuracy=0.6823, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.2632
Epoch [2/50] - Loss: 4.8943
Epoch [3/50] - Loss: 4.0458
Epoch [4/50] - Loss: 3.7563
Epoch [5/50] - Loss: 3.7037
Epoch [6/50] - Loss: 3.6517
Epoch [7/50] - Loss: 3.5919
Epoch [8/50] - Loss: 3.5421
Epoch [9/50] - Loss: 3.5046
Epoch [10/50] - Loss: 3.4691
Epoch [11/50] - Loss: 3.4331
Epoch [12/50] - Loss: 3.4042
Epoch [13/50] - Loss: 3.3627
Epoch [14/50] - Loss: 3.3431
Epoch [15/50] - Loss: 3.3207
Epoch [16/50] - Loss: 3.2903
Epoch [17/50] - Loss: 3.2763
Epoch [18/50] - Loss: 3.2508
Epoch [19/50] - Loss: 3.2297
Epoch [20/50] - Loss: 3.2199
Epoch [21/50] - Loss: 3.2020
Epoch [22/50] - Loss: 3.1861
Epoch [23/50] - Loss: 3.1786
Epoch [24/50] - Loss: 3.1708
Epoch [25/50] - Loss: 3.1600
Epoch [26/50] - Loss: 3.1499
Epoch [27/50] - Loss: 3.1399
Epoch [28/50] - Loss: 3.1248
Epoch [29/50] - Loss: 3.1211
Epoch [30/50] - Loss: 3.1095
Epoch [31/50] - Loss: 3.1022
Epoch [32/50] - Loss: 3.0994
Epoch [33/50] - Loss: 3.0919
Epoch [34/50] - Loss: 3.0803
Epoch [35/50] - Loss: 3.0754
Epoch [36/50] - Loss: 3.0736
Epoch [37/50] - Loss: 3.0702
Epoch [38/50] - Loss: 3.0575
Epoch [39/50] - Loss: 3.0522
Epoch [40/50] - Loss: 3.0514
Epoch [41/50] - Loss: 3.0424
Epoch [42/50] - Loss: 3.0407
Epoch [43/50] - Loss: 3.0342
Epoch [44/50] - Loss: 3.0332
Epoch [45/50] - Loss: 3.0279
Epoch [46/50] - Loss: 3.0227
Epoch [47/50] - Loss: 3.0229
Epoch [48/50] - Loss: 3.0107
Epoch [49/50] - Loss: 3.0022
Epoch [50/50] - Loss: 3.0068
sum preds 0
sum labels 5513
 - Test Metrics: Accuracy=0.6823, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.3352
Epoch [2/50] - Loss: 4.9641
Epoch [3/50] - Loss: 4.0555
Epoch [4/50] - Loss: 3.7769
Epoch [5/50] - Loss: 3.7275
Epoch [6/50] - Loss: 3.6444
Epoch [7/50] - Loss: 3.5797
Epoch [8/50] - Loss: 3.5255
Epoch [9/50] - Loss: 3.4739
Epoch [10/50] - Loss: 3.4417
Epoch [11/50] - Loss: 3.3913
Epoch [12/50] - Loss: 3.3635
Epoch [13/50] - Loss: 3.3394
Epoch [14/50] - Loss: 3.3064
Epoch [15/50] - Loss: 3.2732
Epoch [16/50] - Loss: 3.2516
Epoch [17/50] - Loss: 3.2250
Epoch [18/50] - Loss: 3.2055
Epoch [19/50] - Loss: 3.1973
Epoch [20/50] - Loss: 3.1873
Epoch [21/50] - Loss: 3.1673
Epoch [22/50] - Loss: 3.1450
Epoch [23/50] - Loss: 3.1393
Epoch [24/50] - Loss: 3.1322
Epoch [25/50] - Loss: 3.1165
Epoch [26/50] - Loss: 3.1207
Epoch [27/50] - Loss: 3.1025
Epoch [28/50] - Loss: 3.0955
Epoch [29/50] - Loss: 3.0890
Epoch [30/50] - Loss: 3.0772
Epoch [31/50] - Loss: 3.0677
Epoch [32/50] - Loss: 3.0631
Epoch [33/50] - Loss: 3.0591
Epoch [34/50] - Loss: 3.0484
Epoch [35/50] - Loss: 3.0535
Epoch [36/50] - Loss: 3.0506
Epoch [37/50] - Loss: 3.0416
Epoch [38/50] - Loss: 3.0259
Epoch [39/50] - Loss: 3.0189
Epoch [40/50] - Loss: 3.0213
Epoch [41/50] - Loss: 3.0102
Epoch [42/50] - Loss: 3.0174
Epoch [43/50] - Loss: 3.0018
Epoch [44/50] - Loss: 3.0014
Epoch [45/50] - Loss: 2.9917
Epoch [46/50] - Loss: 2.9888
Epoch [47/50] - Loss: 2.9865
Epoch [48/50] - Loss: 2.9779
Epoch [49/50] - Loss: 2.9789
Epoch [50/50] - Loss: 2.9705
sum preds 0
sum labels 5513
 - Test Metrics: Accuracy=0.6823, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_naive_naive_1804120833.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and naive, GCNConv,0.3: 0.0000 ± 0.0000
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 7.0581
Epoch [2/50] - Loss: 5.0831
Epoch [3/50] - Loss: 3.3978
Epoch [4/50] - Loss: 2.8404
Epoch [5/50] - Loss: 2.8191
Epoch [6/50] - Loss: 2.7656
Epoch [7/50] - Loss: 2.7042
Epoch [8/50] - Loss: 2.6602
Epoch [9/50] - Loss: 2.6249
Epoch [10/50] - Loss: 2.6006
Epoch [11/50] - Loss: 2.5759
Epoch [12/50] - Loss: 2.5501
Epoch [13/50] - Loss: 2.5305
Epoch [14/50] - Loss: 2.5118
Epoch [15/50] - Loss: 2.5067
Epoch [16/50] - Loss: 2.4858
Epoch [17/50] - Loss: 2.4735
Epoch [18/50] - Loss: 2.4652
Epoch [19/50] - Loss: 2.4558
Epoch [20/50] - Loss: 2.4406
Epoch [21/50] - Loss: 2.4318
Epoch [22/50] - Loss: 2.4164
Epoch [23/50] - Loss: 2.4156
Epoch [24/50] - Loss: 2.4042
Epoch [25/50] - Loss: 2.3972
Epoch [26/50] - Loss: 2.3897
Epoch [27/50] - Loss: 2.3799
Epoch [28/50] - Loss: 2.3740
Epoch [29/50] - Loss: 2.3681
Epoch [30/50] - Loss: 2.3550
Epoch [31/50] - Loss: 2.3473
Epoch [32/50] - Loss: 2.3418
Epoch [33/50] - Loss: 2.3467
Epoch [34/50] - Loss: 2.3365
Epoch [35/50] - Loss: 2.3285
Epoch [36/50] - Loss: 2.3283
Epoch [37/50] - Loss: 2.3154
Epoch [38/50] - Loss: 2.3128
Epoch [39/50] - Loss: 2.3029
Epoch [40/50] - Loss: 2.3024
Epoch [41/50] - Loss: 2.2918
Epoch [42/50] - Loss: 2.2913
Epoch [43/50] - Loss: 2.2778
Epoch [44/50] - Loss: 2.2839
Epoch [45/50] - Loss: 2.2788
Epoch [46/50] - Loss: 2.2713
Epoch [47/50] - Loss: 2.2626
Epoch [48/50] - Loss: 2.2625
Epoch [49/50] - Loss: 2.2567
Epoch [50/50] - Loss: 2.2522
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.0070
Epoch [2/50] - Loss: 4.5166
Epoch [3/50] - Loss: 3.3246
Epoch [4/50] - Loss: 2.8547
Epoch [5/50] - Loss: 2.7730
Epoch [6/50] - Loss: 2.7073
Epoch [7/50] - Loss: 2.6171
Epoch [8/50] - Loss: 2.5650
Epoch [9/50] - Loss: 2.5175
Epoch [10/50] - Loss: 2.4799
Epoch [11/50] - Loss: 2.4473
Epoch [12/50] - Loss: 2.4239
Epoch [13/50] - Loss: 2.4023
Epoch [14/50] - Loss: 2.3835
Epoch [15/50] - Loss: 2.3759
Epoch [16/50] - Loss: 2.3558
Epoch [17/50] - Loss: 2.3468
Epoch [18/50] - Loss: 2.3464
Epoch [19/50] - Loss: 2.3311
Epoch [20/50] - Loss: 2.3331
Epoch [21/50] - Loss: 2.3242
Epoch [22/50] - Loss: 2.3181
Epoch [23/50] - Loss: 2.3152
Epoch [24/50] - Loss: 2.3175
Epoch [25/50] - Loss: 2.3065
Epoch [26/50] - Loss: 2.3033
Epoch [27/50] - Loss: 2.3028
Epoch [28/50] - Loss: 2.3035
Epoch [29/50] - Loss: 2.3020
Epoch [30/50] - Loss: 2.2991
Epoch [31/50] - Loss: 2.2927
Epoch [32/50] - Loss: 2.2952
Epoch [33/50] - Loss: 2.2944
Epoch [34/50] - Loss: 2.2963
Epoch [35/50] - Loss: 2.2937
Epoch [36/50] - Loss: 2.2938
Epoch [37/50] - Loss: 2.2853
Epoch [38/50] - Loss: 2.2817
Epoch [39/50] - Loss: 2.2816
Epoch [40/50] - Loss: 2.2881
Epoch [41/50] - Loss: 2.2743
Epoch [42/50] - Loss: 2.2792
Epoch [43/50] - Loss: 2.2831
Epoch [44/50] - Loss: 2.2784
Epoch [45/50] - Loss: 2.2746
Epoch [46/50] - Loss: 2.2694
Epoch [47/50] - Loss: 2.2678
Epoch [48/50] - Loss: 2.2690
Epoch [49/50] - Loss: 2.2694
Epoch [50/50] - Loss: 2.2663
sum preds 57
sum labels 6300
 - Test Metrics: Accuracy=0.6557, F1=0.0173, Recall=0.0087, Precision=0.9649
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.4621
Epoch [2/50] - Loss: 4.7530
Epoch [3/50] - Loss: 3.4172
Epoch [4/50] - Loss: 2.8775
Epoch [5/50] - Loss: 2.8053
Epoch [6/50] - Loss: 2.7563
Epoch [7/50] - Loss: 2.7138
Epoch [8/50] - Loss: 2.6634
Epoch [9/50] - Loss: 2.6373
Epoch [10/50] - Loss: 2.6069
Epoch [11/50] - Loss: 2.5847
Epoch [12/50] - Loss: 2.5578
Epoch [13/50] - Loss: 2.5380
Epoch [14/50] - Loss: 2.5236
Epoch [15/50] - Loss: 2.4999
Epoch [16/50] - Loss: 2.4818
Epoch [17/50] - Loss: 2.4520
Epoch [18/50] - Loss: 2.4259
Epoch [19/50] - Loss: 2.4033
Epoch [20/50] - Loss: 2.3743
Epoch [21/50] - Loss: 2.3591
Epoch [22/50] - Loss: 2.3300
Epoch [23/50] - Loss: 2.3173
Epoch [24/50] - Loss: 2.3031
Epoch [25/50] - Loss: 2.2865
Epoch [26/50] - Loss: 2.2725
Epoch [27/50] - Loss: 2.2629
Epoch [28/50] - Loss: 2.2470
Epoch [29/50] - Loss: 2.2438
Epoch [30/50] - Loss: 2.2261
Epoch [31/50] - Loss: 2.2194
Epoch [32/50] - Loss: 2.2103
Epoch [33/50] - Loss: 2.2083
Epoch [34/50] - Loss: 2.1972
Epoch [35/50] - Loss: 2.1931
Epoch [36/50] - Loss: 2.1733
Epoch [37/50] - Loss: 2.1749
Epoch [38/50] - Loss: 2.1726
Epoch [39/50] - Loss: 2.1646
Epoch [40/50] - Loss: 2.1527
Epoch [41/50] - Loss: 2.1482
Epoch [42/50] - Loss: 2.1466
Epoch [43/50] - Loss: 2.1418
Epoch [44/50] - Loss: 2.1398
Epoch [45/50] - Loss: 2.1322
Epoch [46/50] - Loss: 2.1198
Epoch [47/50] - Loss: 2.1245
Epoch [48/50] - Loss: 2.1168
Epoch [49/50] - Loss: 2.1141
Epoch [50/50] - Loss: 2.1078
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_naive_naive_1804123618.csv.
Average F1 over valid seeds: 0.0058 ± 0.0082
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and naive, MLP,0.2: 0.0058 ± 0.0082
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.5166
Epoch [2/50] - Loss: 3.3780
Epoch [3/50] - Loss: 2.8448
Epoch [4/50] - Loss: 2.8397
Epoch [5/50] - Loss: 2.7562
Epoch [6/50] - Loss: 2.6928
Epoch [7/50] - Loss: 2.6541
Epoch [8/50] - Loss: 2.6245
Epoch [9/50] - Loss: 2.5885
Epoch [10/50] - Loss: 2.5657
Epoch [11/50] - Loss: 2.5443
Epoch [12/50] - Loss: 2.5314
Epoch [13/50] - Loss: 2.5184
Epoch [14/50] - Loss: 2.4930
Epoch [15/50] - Loss: 2.4816
Epoch [16/50] - Loss: 2.4591
Epoch [17/50] - Loss: 2.4465
Epoch [18/50] - Loss: 2.4384
Epoch [19/50] - Loss: 2.4262
Epoch [20/50] - Loss: 2.4249
Epoch [21/50] - Loss: 2.4094
Epoch [22/50] - Loss: 2.4085
Epoch [23/50] - Loss: 2.3867
Epoch [24/50] - Loss: 2.3801
Epoch [25/50] - Loss: 2.3729
Epoch [26/50] - Loss: 2.3600
Epoch [27/50] - Loss: 2.3590
Epoch [28/50] - Loss: 2.3517
Epoch [29/50] - Loss: 2.3389
Epoch [30/50] - Loss: 2.3339
Epoch [31/50] - Loss: 2.3230
Epoch [32/50] - Loss: 2.3237
Epoch [33/50] - Loss: 2.3165
Epoch [34/50] - Loss: 2.2996
Epoch [35/50] - Loss: 2.2998
Epoch [36/50] - Loss: 2.2856
Epoch [37/50] - Loss: 2.2777
Epoch [38/50] - Loss: 2.2703
Epoch [39/50] - Loss: 2.2563
Epoch [40/50] - Loss: 2.2465
Epoch [41/50] - Loss: 2.2462
Epoch [42/50] - Loss: 2.2314
Epoch [43/50] - Loss: 2.2227
Epoch [44/50] - Loss: 2.2082
Epoch [45/50] - Loss: 2.1956
Epoch [46/50] - Loss: 2.1900
Epoch [47/50] - Loss: 2.1761
Epoch [48/50] - Loss: 2.1685
Epoch [49/50] - Loss: 2.1542
Epoch [50/50] - Loss: 2.1486
sum preds 26
sum labels 6300
 - Test Metrics: Accuracy=0.6541, F1=0.0079, Recall=0.0040, Precision=0.9615
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.7386
Epoch [2/50] - Loss: 3.7015
Epoch [3/50] - Loss: 2.9012
Epoch [4/50] - Loss: 2.8205
Epoch [5/50] - Loss: 2.7839
Epoch [6/50] - Loss: 2.7230
Epoch [7/50] - Loss: 2.6798
Epoch [8/50] - Loss: 2.6438
Epoch [9/50] - Loss: 2.6144
Epoch [10/50] - Loss: 2.5850
Epoch [11/50] - Loss: 2.5565
Epoch [12/50] - Loss: 2.5278
Epoch [13/50] - Loss: 2.5093
Epoch [14/50] - Loss: 2.4942
Epoch [15/50] - Loss: 2.4657
Epoch [16/50] - Loss: 2.4552
Epoch [17/50] - Loss: 2.4380
Epoch [18/50] - Loss: 2.4241
Epoch [19/50] - Loss: 2.4123
Epoch [20/50] - Loss: 2.4010
Epoch [21/50] - Loss: 2.3943
Epoch [22/50] - Loss: 2.3747
Epoch [23/50] - Loss: 2.3655
Epoch [24/50] - Loss: 2.3661
Epoch [25/50] - Loss: 2.3453
Epoch [26/50] - Loss: 2.3377
Epoch [27/50] - Loss: 2.3345
Epoch [28/50] - Loss: 2.3263
Epoch [29/50] - Loss: 2.3214
Epoch [30/50] - Loss: 2.3131
Epoch [31/50] - Loss: 2.2956
Epoch [32/50] - Loss: 2.2900
Epoch [33/50] - Loss: 2.2793
Epoch [34/50] - Loss: 2.2703
Epoch [35/50] - Loss: 2.2564
Epoch [36/50] - Loss: 2.2481
Epoch [37/50] - Loss: 2.2343
Epoch [38/50] - Loss: 2.2238
Epoch [39/50] - Loss: 2.2174
Epoch [40/50] - Loss: 2.2071
Epoch [41/50] - Loss: 2.2024
Epoch [42/50] - Loss: 2.1898
Epoch [43/50] - Loss: 2.1749
Epoch [44/50] - Loss: 2.1698
Epoch [45/50] - Loss: 2.1603
Epoch [46/50] - Loss: 2.1633
Epoch [47/50] - Loss: 2.1513
Epoch [48/50] - Loss: 2.1366
Epoch [49/50] - Loss: 2.1310
Epoch [50/50] - Loss: 2.1214
sum preds 8
sum labels 6300
 - Test Metrics: Accuracy=0.6532, F1=0.0025, Recall=0.0013, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.9966
Epoch [2/50] - Loss: 4.1386
Epoch [3/50] - Loss: 3.1066
Epoch [4/50] - Loss: 2.8359
Epoch [5/50] - Loss: 2.8053
Epoch [6/50] - Loss: 2.7582
Epoch [7/50] - Loss: 2.7096
Epoch [8/50] - Loss: 2.6681
Epoch [9/50] - Loss: 2.6411
Epoch [10/50] - Loss: 2.6111
Epoch [11/50] - Loss: 2.5824
Epoch [12/50] - Loss: 2.5607
Epoch [13/50] - Loss: 2.5432
Epoch [14/50] - Loss: 2.5303
Epoch [15/50] - Loss: 2.4998
Epoch [16/50] - Loss: 2.4745
Epoch [17/50] - Loss: 2.4625
Epoch [18/50] - Loss: 2.4287
Epoch [19/50] - Loss: 2.4124
Epoch [20/50] - Loss: 2.3958
Epoch [21/50] - Loss: 2.3743
Epoch [22/50] - Loss: 2.3621
Epoch [23/50] - Loss: 2.3522
Epoch [24/50] - Loss: 2.3351
Epoch [25/50] - Loss: 2.3162
Epoch [26/50] - Loss: 2.2947
Epoch [27/50] - Loss: 2.2824
Epoch [28/50] - Loss: 2.2595
Epoch [29/50] - Loss: 2.2490
Epoch [30/50] - Loss: 2.2381
Epoch [31/50] - Loss: 2.2236
Epoch [32/50] - Loss: 2.2030
Epoch [33/50] - Loss: 2.2011
Epoch [34/50] - Loss: 2.1997
Epoch [35/50] - Loss: 2.1865
Epoch [36/50] - Loss: 2.1754
Epoch [37/50] - Loss: 2.1617
Epoch [38/50] - Loss: 2.1616
Epoch [39/50] - Loss: 2.1562
Epoch [40/50] - Loss: 2.1452
Epoch [41/50] - Loss: 2.1346
Epoch [42/50] - Loss: 2.1361
Epoch [43/50] - Loss: 2.1265
Epoch [44/50] - Loss: 2.1175
Epoch [45/50] - Loss: 2.1079
Epoch [46/50] - Loss: 2.1049
Epoch [47/50] - Loss: 2.0838
Epoch [48/50] - Loss: 2.0831
Epoch [49/50] - Loss: 2.0811
Epoch [50/50] - Loss: 2.0629
sum preds 20
sum labels 6300
 - Test Metrics: Accuracy=0.6538, F1=0.0063, Recall=0.0032, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_naive_naive_1804130447.csv.
Average F1 over valid seeds: 0.0056 ± 0.0023
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and naive, GATConv,0.2: 0.0056 ± 0.0023
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.1964
Epoch [2/50] - Loss: 4.5842
Epoch [3/50] - Loss: 3.4671
Epoch [4/50] - Loss: 2.9916
Epoch [5/50] - Loss: 2.8931
Epoch [6/50] - Loss: 2.8748
Epoch [7/50] - Loss: 2.8306
Epoch [8/50] - Loss: 2.8063
Epoch [9/50] - Loss: 2.7754
Epoch [10/50] - Loss: 2.7447
Epoch [11/50] - Loss: 2.7243
Epoch [12/50] - Loss: 2.7072
Epoch [13/50] - Loss: 2.6897
Epoch [14/50] - Loss: 2.6689
Epoch [15/50] - Loss: 2.6507
Epoch [16/50] - Loss: 2.6360
Epoch [17/50] - Loss: 2.6255
Epoch [18/50] - Loss: 2.6086
Epoch [19/50] - Loss: 2.5991
Epoch [20/50] - Loss: 2.5882
Epoch [21/50] - Loss: 2.5742
Epoch [22/50] - Loss: 2.5606
Epoch [23/50] - Loss: 2.5504
Epoch [24/50] - Loss: 2.5285
Epoch [25/50] - Loss: 2.5141
Epoch [26/50] - Loss: 2.5058
Epoch [27/50] - Loss: 2.4860
Epoch [28/50] - Loss: 2.4671
Epoch [29/50] - Loss: 2.4606
Epoch [30/50] - Loss: 2.4416
Epoch [31/50] - Loss: 2.4287
Epoch [32/50] - Loss: 2.4218
Epoch [33/50] - Loss: 2.4129
Epoch [34/50] - Loss: 2.4008
Epoch [35/50] - Loss: 2.3965
Epoch [36/50] - Loss: 2.3937
Epoch [37/50] - Loss: 2.3719
Epoch [38/50] - Loss: 2.3797
Epoch [39/50] - Loss: 2.3768
Epoch [40/50] - Loss: 2.3666
Epoch [41/50] - Loss: 2.3673
Epoch [42/50] - Loss: 2.3598
Epoch [43/50] - Loss: 2.3471
Epoch [44/50] - Loss: 2.3577
Epoch [45/50] - Loss: 2.3440
Epoch [46/50] - Loss: 2.3441
Epoch [47/50] - Loss: 2.3445
Epoch [48/50] - Loss: 2.3325
Epoch [49/50] - Loss: 2.3392
Epoch [50/50] - Loss: 2.3291
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.1855
Epoch [2/50] - Loss: 4.6006
Epoch [3/50] - Loss: 3.4877
Epoch [4/50] - Loss: 2.9918
Epoch [5/50] - Loss: 2.8789
Epoch [6/50] - Loss: 2.8634
Epoch [7/50] - Loss: 2.8309
Epoch [8/50] - Loss: 2.7900
Epoch [9/50] - Loss: 2.7721
Epoch [10/50] - Loss: 2.7509
Epoch [11/50] - Loss: 2.7257
Epoch [12/50] - Loss: 2.7125
Epoch [13/50] - Loss: 2.6794
Epoch [14/50] - Loss: 2.6716
Epoch [15/50] - Loss: 2.6610
Epoch [16/50] - Loss: 2.6370
Epoch [17/50] - Loss: 2.6299
Epoch [18/50] - Loss: 2.6107
Epoch [19/50] - Loss: 2.6011
Epoch [20/50] - Loss: 2.5930
Epoch [21/50] - Loss: 2.5784
Epoch [22/50] - Loss: 2.5645
Epoch [23/50] - Loss: 2.5595
Epoch [24/50] - Loss: 2.5558
Epoch [25/50] - Loss: 2.5462
Epoch [26/50] - Loss: 2.5370
Epoch [27/50] - Loss: 2.5323
Epoch [28/50] - Loss: 2.5183
Epoch [29/50] - Loss: 2.5161
Epoch [30/50] - Loss: 2.5050
Epoch [31/50] - Loss: 2.4994
Epoch [32/50] - Loss: 2.4971
Epoch [33/50] - Loss: 2.4910
Epoch [34/50] - Loss: 2.4819
Epoch [35/50] - Loss: 2.4779
Epoch [36/50] - Loss: 2.4786
Epoch [37/50] - Loss: 2.4724
Epoch [38/50] - Loss: 2.4643
Epoch [39/50] - Loss: 2.4604
Epoch [40/50] - Loss: 2.4555
Epoch [41/50] - Loss: 2.4524
Epoch [42/50] - Loss: 2.4486
Epoch [43/50] - Loss: 2.4431
Epoch [44/50] - Loss: 2.4407
Epoch [45/50] - Loss: 2.4348
Epoch [46/50] - Loss: 2.4322
Epoch [47/50] - Loss: 2.4338
Epoch [48/50] - Loss: 2.4273
Epoch [49/50] - Loss: 2.4205
Epoch [50/50] - Loss: 2.4192
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.2641
Epoch [2/50] - Loss: 4.6739
Epoch [3/50] - Loss: 3.4897
Epoch [4/50] - Loss: 2.9878
Epoch [5/50] - Loss: 2.8908
Epoch [6/50] - Loss: 2.8579
Epoch [7/50] - Loss: 2.8188
Epoch [8/50] - Loss: 2.7785
Epoch [9/50] - Loss: 2.7464
Epoch [10/50] - Loss: 2.7285
Epoch [11/50] - Loss: 2.6925
Epoch [12/50] - Loss: 2.6754
Epoch [13/50] - Loss: 2.6576
Epoch [14/50] - Loss: 2.6363
Epoch [15/50] - Loss: 2.6170
Epoch [16/50] - Loss: 2.6014
Epoch [17/50] - Loss: 2.5843
Epoch [18/50] - Loss: 2.5659
Epoch [19/50] - Loss: 2.5631
Epoch [20/50] - Loss: 2.5541
Epoch [21/50] - Loss: 2.5409
Epoch [22/50] - Loss: 2.5248
Epoch [23/50] - Loss: 2.5221
Epoch [24/50] - Loss: 2.5179
Epoch [25/50] - Loss: 2.5061
Epoch [26/50] - Loss: 2.5078
Epoch [27/50] - Loss: 2.4916
Epoch [28/50] - Loss: 2.4888
Epoch [29/50] - Loss: 2.4853
Epoch [30/50] - Loss: 2.4739
Epoch [31/50] - Loss: 2.4707
Epoch [32/50] - Loss: 2.4729
Epoch [33/50] - Loss: 2.4673
Epoch [34/50] - Loss: 2.4537
Epoch [35/50] - Loss: 2.4585
Epoch [36/50] - Loss: 2.4549
Epoch [37/50] - Loss: 2.4503
Epoch [38/50] - Loss: 2.4407
Epoch [39/50] - Loss: 2.4295
Epoch [40/50] - Loss: 2.4299
Epoch [41/50] - Loss: 2.4249
Epoch [42/50] - Loss: 2.4305
Epoch [43/50] - Loss: 2.4165
Epoch [44/50] - Loss: 2.4154
Epoch [45/50] - Loss: 2.4081
Epoch [46/50] - Loss: 2.4056
Epoch [47/50] - Loss: 2.4050
Epoch [48/50] - Loss: 2.3915
Epoch [49/50] - Loss: 2.3953
Epoch [50/50] - Loss: 2.3898
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_naive_naive_1804133246.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and naive, GCNConv,0.2: 0.0000 ± 0.0000
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8504, F1=0.6775, Recall=0.5509, Precision=0.8797
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8522, F1=0.6824, Recall=0.5566, Precision=0.8817
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8498, F1=0.6741, Recall=0.5446, Precision=0.8845
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_NNIF_NNIF_1804140038.csv.
Average F1 over valid seeds: 0.6780 ± 0.0034
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and NNIF, MLP,0.4: 0.6780 ± 0.0034
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8249, F1=0.6501, Recall=0.5119, Precision=0.8905
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8347, F1=0.6753, Recall=0.5411, Precision=0.8982
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8284, F1=0.6563, Recall=0.5157, Precision=0.9023
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_NNIF_NNIF_1804140140.csv.
Average F1 over valid seeds: 0.6606 ± 0.0108
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and NNIF, MLP,0.3: 0.6606 ± 0.0108
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7883, F1=0.5841, Recall=0.4279, Precision=0.9195
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7939, F1=0.5973, Recall=0.4402, Precision=0.9290
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7931, F1=0.5995, Recall=0.4460, Precision=0.9141
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_NNIF_NNIF_1804140222.csv.
Average F1 over valid seeds: 0.5936 ± 0.0068
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and NNIF, MLP,0.2: 0.5936 ± 0.0068
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.7248
Epoch [2/50] - Loss: 4.8372
Epoch [3/50] - Loss: 3.9927
Epoch [4/50] - Loss: 3.5735
Epoch [5/50] - Loss: 3.3753
Epoch [6/50] - Loss: 3.1128
Epoch [7/50] - Loss: 2.8908
Epoch [8/50] - Loss: 2.6689
Epoch [9/50] - Loss: 2.4786
Epoch [10/50] - Loss: 2.3196
Epoch [11/50] - Loss: 2.2095
Epoch [12/50] - Loss: 2.1265
Epoch [13/50] - Loss: 2.0682
Epoch [14/50] - Loss: 2.0172
Epoch [15/50] - Loss: 1.9728
Epoch [16/50] - Loss: 1.9515
Epoch [17/50] - Loss: 1.9278
Epoch [18/50] - Loss: 1.9071
Epoch [19/50] - Loss: 1.8831
Epoch [20/50] - Loss: 1.8665
Epoch [21/50] - Loss: 1.8596
Epoch [22/50] - Loss: 1.8445
Epoch [23/50] - Loss: 1.8355
Epoch [24/50] - Loss: 1.8284
Epoch [25/50] - Loss: 1.8229
Epoch [26/50] - Loss: 1.8143
Epoch [27/50] - Loss: 1.8145
Epoch [28/50] - Loss: 1.8004
Epoch [29/50] - Loss: 1.8061
Epoch [30/50] - Loss: 1.8003
Epoch [31/50] - Loss: 1.7944
Epoch [32/50] - Loss: 1.7897
Epoch [33/50] - Loss: 1.7845
Epoch [34/50] - Loss: 1.7792
Epoch [35/50] - Loss: 1.7807
Epoch [36/50] - Loss: 1.7765
Epoch [37/50] - Loss: 1.7753
Epoch [38/50] - Loss: 1.7736
Epoch [39/50] - Loss: 1.7723
Epoch [40/50] - Loss: 1.7680
Epoch [41/50] - Loss: 1.7651
Epoch [42/50] - Loss: 1.7665
Epoch [43/50] - Loss: 1.7611
Epoch [44/50] - Loss: 1.7542
Epoch [45/50] - Loss: 1.7539
Epoch [46/50] - Loss: 1.7516
Epoch [47/50] - Loss: 1.7504
Epoch [48/50] - Loss: 1.7513
Epoch [49/50] - Loss: 1.7492
Epoch [50/50] - Loss: 1.7484
sum preds 3417
sum labels 4725
 - Test Metrics: Accuracy=0.8553, F1=0.7055, Recall=0.6078, Precision=0.8405
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.4404
Epoch [2/50] - Loss: 4.7418
Epoch [3/50] - Loss: 3.9745
Epoch [4/50] - Loss: 3.4862
Epoch [5/50] - Loss: 3.2240
Epoch [6/50] - Loss: 2.9322
Epoch [7/50] - Loss: 2.6936
Epoch [8/50] - Loss: 2.4910
Epoch [9/50] - Loss: 2.3294
Epoch [10/50] - Loss: 2.2105
Epoch [11/50] - Loss: 2.1165
Epoch [12/50] - Loss: 2.0509
Epoch [13/50] - Loss: 1.9957
Epoch [14/50] - Loss: 1.9503
Epoch [15/50] - Loss: 1.9115
Epoch [16/50] - Loss: 1.8914
Epoch [17/50] - Loss: 1.8667
Epoch [18/50] - Loss: 1.8410
Epoch [19/50] - Loss: 1.8256
Epoch [20/50] - Loss: 1.8076
Epoch [21/50] - Loss: 1.7949
Epoch [22/50] - Loss: 1.7860
Epoch [23/50] - Loss: 1.7775
Epoch [24/50] - Loss: 1.7654
Epoch [25/50] - Loss: 1.7640
Epoch [26/50] - Loss: 1.7547
Epoch [27/50] - Loss: 1.7411
Epoch [28/50] - Loss: 1.7332
Epoch [29/50] - Loss: 1.7282
Epoch [30/50] - Loss: 1.7190
Epoch [31/50] - Loss: 1.7168
Epoch [32/50] - Loss: 1.7119
Epoch [33/50] - Loss: 1.7076
Epoch [34/50] - Loss: 1.6976
Epoch [35/50] - Loss: 1.6868
Epoch [36/50] - Loss: 1.6856
Epoch [37/50] - Loss: 1.6780
Epoch [38/50] - Loss: 1.6689
Epoch [39/50] - Loss: 1.6569
Epoch [40/50] - Loss: 1.6514
Epoch [41/50] - Loss: 1.6357
Epoch [42/50] - Loss: 1.6334
Epoch [43/50] - Loss: 1.6220
Epoch [44/50] - Loss: 1.6183
Epoch [45/50] - Loss: 1.6081
Epoch [46/50] - Loss: 1.6044
Epoch [47/50] - Loss: 1.5938
Epoch [48/50] - Loss: 1.5919
Epoch [49/50] - Loss: 1.5838
Epoch [50/50] - Loss: 1.5689
sum preds 3403
sum labels 4725
 - Test Metrics: Accuracy=0.8569, F1=0.7084, Recall=0.6093, Precision=0.8460
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.5507
Epoch [2/50] - Loss: 4.8057
Epoch [3/50] - Loss: 4.0460
Epoch [4/50] - Loss: 3.5845
Epoch [5/50] - Loss: 3.3742
Epoch [6/50] - Loss: 3.1141
Epoch [7/50] - Loss: 2.8681
Epoch [8/50] - Loss: 2.6588
Epoch [9/50] - Loss: 2.4603
Epoch [10/50] - Loss: 2.3080
Epoch [11/50] - Loss: 2.1922
Epoch [12/50] - Loss: 2.0951
Epoch [13/50] - Loss: 2.0306
Epoch [14/50] - Loss: 1.9734
Epoch [15/50] - Loss: 1.9414
Epoch [16/50] - Loss: 1.9013
Epoch [17/50] - Loss: 1.8769
Epoch [18/50] - Loss: 1.8432
Epoch [19/50] - Loss: 1.8264
Epoch [20/50] - Loss: 1.8145
Epoch [21/50] - Loss: 1.7959
Epoch [22/50] - Loss: 1.7725
Epoch [23/50] - Loss: 1.7615
Epoch [24/50] - Loss: 1.7582
Epoch [25/50] - Loss: 1.7435
Epoch [26/50] - Loss: 1.7400
Epoch [27/50] - Loss: 1.7335
Epoch [28/50] - Loss: 1.7291
Epoch [29/50] - Loss: 1.7234
Epoch [30/50] - Loss: 1.7136
Epoch [31/50] - Loss: 1.7060
Epoch [32/50] - Loss: 1.7087
Epoch [33/50] - Loss: 1.6995
Epoch [34/50] - Loss: 1.7048
Epoch [35/50] - Loss: 1.7012
Epoch [36/50] - Loss: 1.6893
Epoch [37/50] - Loss: 1.6873
Epoch [38/50] - Loss: 1.6880
Epoch [39/50] - Loss: 1.6874
Epoch [40/50] - Loss: 1.6756
Epoch [41/50] - Loss: 1.6825
Epoch [42/50] - Loss: 1.6757
Epoch [43/50] - Loss: 1.6766
Epoch [44/50] - Loss: 1.6745
Epoch [45/50] - Loss: 1.6707
Epoch [46/50] - Loss: 1.6693
Epoch [47/50] - Loss: 1.6651
Epoch [48/50] - Loss: 1.6700
Epoch [49/50] - Loss: 1.6637
Epoch [50/50] - Loss: 1.6622
sum preds 3480
sum labels 4725
 - Test Metrics: Accuracy=0.8598, F1=0.7169, Recall=0.6224, Precision=0.8451
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_two_nnif_two_nnif_1804140304.csv.
Average F1 over valid seeds: 0.7103 ± 0.0048
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and two_nnif, MLP,0.4: 0.7103 ± 0.0048
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.9209
Epoch [2/50] - Loss: 3.9301
Epoch [3/50] - Loss: 3.6246
Epoch [4/50] - Loss: 3.4715
Epoch [5/50] - Loss: 3.2616
Epoch [6/50] - Loss: 3.1033
Epoch [7/50] - Loss: 2.9056
Epoch [8/50] - Loss: 2.7055
Epoch [9/50] - Loss: 2.5504
Epoch [10/50] - Loss: 2.4421
Epoch [11/50] - Loss: 2.3668
Epoch [12/50] - Loss: 2.3214
Epoch [13/50] - Loss: 2.2983
Epoch [14/50] - Loss: 2.2660
Epoch [15/50] - Loss: 2.2352
Epoch [16/50] - Loss: 2.2112
Epoch [17/50] - Loss: 2.1995
Epoch [18/50] - Loss: 2.1702
Epoch [19/50] - Loss: 2.1608
Epoch [20/50] - Loss: 2.1501
Epoch [21/50] - Loss: 2.1404
Epoch [22/50] - Loss: 2.1234
Epoch [23/50] - Loss: 2.1218
Epoch [24/50] - Loss: 2.1058
Epoch [25/50] - Loss: 2.0964
Epoch [26/50] - Loss: 2.0864
Epoch [27/50] - Loss: 2.0692
Epoch [28/50] - Loss: 2.0741
Epoch [29/50] - Loss: 2.0576
Epoch [30/50] - Loss: 2.0538
Epoch [31/50] - Loss: 2.0409
Epoch [32/50] - Loss: 2.0294
Epoch [33/50] - Loss: 2.0209
Epoch [34/50] - Loss: 2.0155
Epoch [35/50] - Loss: 2.0094
Epoch [36/50] - Loss: 1.9943
Epoch [37/50] - Loss: 1.9959
Epoch [38/50] - Loss: 1.9968
Epoch [39/50] - Loss: 1.9918
Epoch [40/50] - Loss: 1.9857
Epoch [41/50] - Loss: 1.9744
Epoch [42/50] - Loss: 1.9606
Epoch [43/50] - Loss: 1.9613
Epoch [44/50] - Loss: 1.9508
Epoch [45/50] - Loss: 1.9538
Epoch [46/50] - Loss: 1.9410
Epoch [47/50] - Loss: 1.9395
Epoch [48/50] - Loss: 1.9263
Epoch [49/50] - Loss: 1.9361
Epoch [50/50] - Loss: 1.9238
sum preds 3418
sum labels 4725
 - Test Metrics: Accuracy=0.8677, F1=0.7309, Recall=0.6298, Precision=0.8707
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.9709
Epoch [2/50] - Loss: 4.0210
Epoch [3/50] - Loss: 3.6537
Epoch [4/50] - Loss: 3.5137
Epoch [5/50] - Loss: 3.3243
Epoch [6/50] - Loss: 3.0993
Epoch [7/50] - Loss: 2.9185
Epoch [8/50] - Loss: 2.7226
Epoch [9/50] - Loss: 2.5626
Epoch [10/50] - Loss: 2.4404
Epoch [11/50] - Loss: 2.3596
Epoch [12/50] - Loss: 2.2989
Epoch [13/50] - Loss: 2.2533
Epoch [14/50] - Loss: 2.2202
Epoch [15/50] - Loss: 2.1960
Epoch [16/50] - Loss: 2.1687
Epoch [17/50] - Loss: 2.1495
Epoch [18/50] - Loss: 2.1193
Epoch [19/50] - Loss: 2.0984
Epoch [20/50] - Loss: 2.0839
Epoch [21/50] - Loss: 2.0707
Epoch [22/50] - Loss: 2.0411
Epoch [23/50] - Loss: 2.0296
Epoch [24/50] - Loss: 2.0136
Epoch [25/50] - Loss: 1.9972
Epoch [26/50] - Loss: 1.9937
Epoch [27/50] - Loss: 1.9767
Epoch [28/50] - Loss: 1.9561
Epoch [29/50] - Loss: 1.9486
Epoch [30/50] - Loss: 1.9371
Epoch [31/50] - Loss: 1.9338
Epoch [32/50] - Loss: 1.9095
Epoch [33/50] - Loss: 1.8989
Epoch [34/50] - Loss: 1.8881
Epoch [35/50] - Loss: 1.8783
Epoch [36/50] - Loss: 1.8670
Epoch [37/50] - Loss: 1.8592
Epoch [38/50] - Loss: 1.8474
Epoch [39/50] - Loss: 1.8345
Epoch [40/50] - Loss: 1.8282
Epoch [41/50] - Loss: 1.8265
Epoch [42/50] - Loss: 1.8112
Epoch [43/50] - Loss: 1.8091
Epoch [44/50] - Loss: 1.7944
Epoch [45/50] - Loss: 1.7803
Epoch [46/50] - Loss: 1.7805
Epoch [47/50] - Loss: 1.7773
Epoch [48/50] - Loss: 1.7575
Epoch [49/50] - Loss: 1.7570
Epoch [50/50] - Loss: 1.7515
sum preds 3360
sum labels 4725
 - Test Metrics: Accuracy=0.8685, F1=0.7305, Recall=0.6250, Precision=0.8789
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1596
Epoch [2/50] - Loss: 4.2995
Epoch [3/50] - Loss: 3.7433
Epoch [4/50] - Loss: 3.4855
Epoch [5/50] - Loss: 3.2495
Epoch [6/50] - Loss: 3.0018
Epoch [7/50] - Loss: 2.7973
Epoch [8/50] - Loss: 2.6314
Epoch [9/50] - Loss: 2.4973
Epoch [10/50] - Loss: 2.3848
Epoch [11/50] - Loss: 2.3069
Epoch [12/50] - Loss: 2.2760
Epoch [13/50] - Loss: 2.2235
Epoch [14/50] - Loss: 2.1990
Epoch [15/50] - Loss: 2.1789
Epoch [16/50] - Loss: 2.1566
Epoch [17/50] - Loss: 2.1338
Epoch [18/50] - Loss: 2.1099
Epoch [19/50] - Loss: 2.0837
Epoch [20/50] - Loss: 2.0723
Epoch [21/50] - Loss: 2.0568
Epoch [22/50] - Loss: 2.0328
Epoch [23/50] - Loss: 2.0169
Epoch [24/50] - Loss: 2.0013
Epoch [25/50] - Loss: 1.9826
Epoch [26/50] - Loss: 1.9652
Epoch [27/50] - Loss: 1.9565
Epoch [28/50] - Loss: 1.9469
Epoch [29/50] - Loss: 1.9264
Epoch [30/50] - Loss: 1.9088
Epoch [31/50] - Loss: 1.8981
Epoch [32/50] - Loss: 1.8963
Epoch [33/50] - Loss: 1.8868
Epoch [34/50] - Loss: 1.8683
Epoch [35/50] - Loss: 1.8578
Epoch [36/50] - Loss: 1.8450
Epoch [37/50] - Loss: 1.8418
Epoch [38/50] - Loss: 1.8339
Epoch [39/50] - Loss: 1.8256
Epoch [40/50] - Loss: 1.8149
Epoch [41/50] - Loss: 1.8128
Epoch [42/50] - Loss: 1.8041
Epoch [43/50] - Loss: 1.7828
Epoch [44/50] - Loss: 1.7875
Epoch [45/50] - Loss: 1.7883
Epoch [46/50] - Loss: 1.7757
Epoch [47/50] - Loss: 1.7656
Epoch [48/50] - Loss: 1.7602
Epoch [49/50] - Loss: 1.7558
Epoch [50/50] - Loss: 1.7584
sum preds 3102
sum labels 4725
 - Test Metrics: Accuracy=0.8536, F1=0.6902, Recall=0.5716, Precision=0.8707
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_two_nnif_two_nnif_1804142300.csv.
Average F1 over valid seeds: 0.7172 ± 0.0191
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and two_nnif, GATConv,0.4: 0.7172 ± 0.0191
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.2233
Epoch [2/50] - Loss: 4.4915
Epoch [3/50] - Loss: 3.9760
Epoch [4/50] - Loss: 3.7306
Epoch [5/50] - Loss: 3.6064
Epoch [6/50] - Loss: 3.4441
Epoch [7/50] - Loss: 3.2614
Epoch [8/50] - Loss: 3.0922
Epoch [9/50] - Loss: 2.9111
Epoch [10/50] - Loss: 2.7612
Epoch [11/50] - Loss: 2.6264
Epoch [12/50] - Loss: 2.5142
Epoch [13/50] - Loss: 2.4400
Epoch [14/50] - Loss: 2.3752
Epoch [15/50] - Loss: 2.3258
Epoch [16/50] - Loss: 2.2935
Epoch [17/50] - Loss: 2.2690
Epoch [18/50] - Loss: 2.2444
Epoch [19/50] - Loss: 2.2246
Epoch [20/50] - Loss: 2.2129
Epoch [21/50] - Loss: 2.1911
Epoch [22/50] - Loss: 2.1813
Epoch [23/50] - Loss: 2.1631
Epoch [24/50] - Loss: 2.1667
Epoch [25/50] - Loss: 2.1465
Epoch [26/50] - Loss: 2.1552
Epoch [27/50] - Loss: 2.1431
Epoch [28/50] - Loss: 2.1388
Epoch [29/50] - Loss: 2.1290
Epoch [30/50] - Loss: 2.1249
Epoch [31/50] - Loss: 2.1123
Epoch [32/50] - Loss: 2.1060
Epoch [33/50] - Loss: 2.0991
Epoch [34/50] - Loss: 2.0852
Epoch [35/50] - Loss: 2.0912
Epoch [36/50] - Loss: 2.0847
Epoch [37/50] - Loss: 2.0791
Epoch [38/50] - Loss: 2.0719
Epoch [39/50] - Loss: 2.0644
Epoch [40/50] - Loss: 2.0599
Epoch [41/50] - Loss: 2.0589
Epoch [42/50] - Loss: 2.0565
Epoch [43/50] - Loss: 2.0498
Epoch [44/50] - Loss: 2.0422
Epoch [45/50] - Loss: 2.0389
Epoch [46/50] - Loss: 2.0212
Epoch [47/50] - Loss: 2.0278
Epoch [48/50] - Loss: 2.0226
Epoch [49/50] - Loss: 2.0109
Epoch [50/50] - Loss: 2.0160
sum preds 3444
sum labels 4725
 - Test Metrics: Accuracy=0.8704, F1=0.7372, Recall=0.6372, Precision=0.8743
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1363
Epoch [2/50] - Loss: 4.2855
Epoch [3/50] - Loss: 3.7807
Epoch [4/50] - Loss: 3.5790
Epoch [5/50] - Loss: 3.3974
Epoch [6/50] - Loss: 3.1944
Epoch [7/50] - Loss: 3.0138
Epoch [8/50] - Loss: 2.8423
Epoch [9/50] - Loss: 2.6986
Epoch [10/50] - Loss: 2.5844
Epoch [11/50] - Loss: 2.4826
Epoch [12/50] - Loss: 2.4059
Epoch [13/50] - Loss: 2.3448
Epoch [14/50] - Loss: 2.3030
Epoch [15/50] - Loss: 2.2697
Epoch [16/50] - Loss: 2.2456
Epoch [17/50] - Loss: 2.2271
Epoch [18/50] - Loss: 2.2041
Epoch [19/50] - Loss: 2.1919
Epoch [20/50] - Loss: 2.1740
Epoch [21/50] - Loss: 2.1593
Epoch [22/50] - Loss: 2.1500
Epoch [23/50] - Loss: 2.1396
Epoch [24/50] - Loss: 2.1341
Epoch [25/50] - Loss: 2.1277
Epoch [26/50] - Loss: 2.1169
Epoch [27/50] - Loss: 2.1126
Epoch [28/50] - Loss: 2.0995
Epoch [29/50] - Loss: 2.0949
Epoch [30/50] - Loss: 2.0934
Epoch [31/50] - Loss: 2.0885
Epoch [32/50] - Loss: 2.0774
Epoch [33/50] - Loss: 2.0808
Epoch [34/50] - Loss: 2.0775
Epoch [35/50] - Loss: 2.0723
Epoch [36/50] - Loss: 2.0607
Epoch [37/50] - Loss: 2.0581
Epoch [38/50] - Loss: 2.0622
Epoch [39/50] - Loss: 2.0542
Epoch [40/50] - Loss: 2.0591
Epoch [41/50] - Loss: 2.0518
Epoch [42/50] - Loss: 2.0467
Epoch [43/50] - Loss: 2.0386
Epoch [44/50] - Loss: 2.0402
Epoch [45/50] - Loss: 2.0420
Epoch [46/50] - Loss: 2.0379
Epoch [47/50] - Loss: 2.0318
Epoch [48/50] - Loss: 2.0290
Epoch [49/50] - Loss: 2.0353
Epoch [50/50] - Loss: 2.0302
sum preds 3385
sum labels 4725
 - Test Metrics: Accuracy=0.8713, F1=0.7371, Recall=0.6326, Precision=0.8830
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1032
Epoch [2/50] - Loss: 4.2389
Epoch [3/50] - Loss: 3.7171
Epoch [4/50] - Loss: 3.4387
Epoch [5/50] - Loss: 3.1970
Epoch [6/50] - Loss: 2.9783
Epoch [7/50] - Loss: 2.7937
Epoch [8/50] - Loss: 2.6371
Epoch [9/50] - Loss: 2.5175
Epoch [10/50] - Loss: 2.4264
Epoch [11/50] - Loss: 2.3544
Epoch [12/50] - Loss: 2.3018
Epoch [13/50] - Loss: 2.2561
Epoch [14/50] - Loss: 2.2279
Epoch [15/50] - Loss: 2.2067
Epoch [16/50] - Loss: 2.1893
Epoch [17/50] - Loss: 2.1633
Epoch [18/50] - Loss: 2.1562
Epoch [19/50] - Loss: 2.1441
Epoch [20/50] - Loss: 2.1263
Epoch [21/50] - Loss: 2.1164
Epoch [22/50] - Loss: 2.1032
Epoch [23/50] - Loss: 2.0956
Epoch [24/50] - Loss: 2.0930
Epoch [25/50] - Loss: 2.0902
Epoch [26/50] - Loss: 2.0704
Epoch [27/50] - Loss: 2.0700
Epoch [28/50] - Loss: 2.0599
Epoch [29/50] - Loss: 2.0580
Epoch [30/50] - Loss: 2.0534
Epoch [31/50] - Loss: 2.0507
Epoch [32/50] - Loss: 2.0511
Epoch [33/50] - Loss: 2.0380
Epoch [34/50] - Loss: 2.0379
Epoch [35/50] - Loss: 2.0333
Epoch [36/50] - Loss: 2.0287
Epoch [37/50] - Loss: 2.0331
Epoch [38/50] - Loss: 2.0279
Epoch [39/50] - Loss: 2.0303
Epoch [40/50] - Loss: 2.0193
Epoch [41/50] - Loss: 2.0138
Epoch [42/50] - Loss: 2.0188
Epoch [43/50] - Loss: 2.0164
Epoch [44/50] - Loss: 2.0128
Epoch [45/50] - Loss: 2.0111
Epoch [46/50] - Loss: 1.9970
Epoch [47/50] - Loss: 1.9991
Epoch [48/50] - Loss: 2.0026
Epoch [49/50] - Loss: 1.9982
Epoch [50/50] - Loss: 1.9910
sum preds 3346
sum labels 4725
 - Test Metrics: Accuracy=0.8694, F1=0.7320, Recall=0.6252, Precision=0.8828
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_two_nnif_two_nnif_1804144323.csv.
Average F1 over valid seeds: 0.7354 ± 0.0024
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and two_nnif, GCNConv,0.4: 0.7354 ± 0.0024
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.7514
Epoch [2/50] - Loss: 4.7447
Epoch [3/50] - Loss: 3.7331
Epoch [4/50] - Loss: 3.1724
Epoch [5/50] - Loss: 2.9931
Epoch [6/50] - Loss: 2.8242
Epoch [7/50] - Loss: 2.6456
Epoch [8/50] - Loss: 2.4871
Epoch [9/50] - Loss: 2.3427
Epoch [10/50] - Loss: 2.1956
Epoch [11/50] - Loss: 2.0754
Epoch [12/50] - Loss: 1.9888
Epoch [13/50] - Loss: 1.9139
Epoch [14/50] - Loss: 1.8608
Epoch [15/50] - Loss: 1.8112
Epoch [16/50] - Loss: 1.7704
Epoch [17/50] - Loss: 1.7351
Epoch [18/50] - Loss: 1.7127
Epoch [19/50] - Loss: 1.6923
Epoch [20/50] - Loss: 1.6695
Epoch [21/50] - Loss: 1.6505
Epoch [22/50] - Loss: 1.6376
Epoch [23/50] - Loss: 1.6285
Epoch [24/50] - Loss: 1.6153
Epoch [25/50] - Loss: 1.5994
Epoch [26/50] - Loss: 1.5999
Epoch [27/50] - Loss: 1.5876
Epoch [28/50] - Loss: 1.5805
Epoch [29/50] - Loss: 1.5776
Epoch [30/50] - Loss: 1.5725
Epoch [31/50] - Loss: 1.5627
Epoch [32/50] - Loss: 1.5605
Epoch [33/50] - Loss: 1.5602
Epoch [34/50] - Loss: 1.5440
Epoch [35/50] - Loss: 1.5522
Epoch [36/50] - Loss: 1.5357
Epoch [37/50] - Loss: 1.5379
Epoch [38/50] - Loss: 1.5410
Epoch [39/50] - Loss: 1.5373
Epoch [40/50] - Loss: 1.5304
Epoch [41/50] - Loss: 1.5249
Epoch [42/50] - Loss: 1.5248
Epoch [43/50] - Loss: 1.5224
Epoch [44/50] - Loss: 1.5260
Epoch [45/50] - Loss: 1.5168
Epoch [46/50] - Loss: 1.5206
Epoch [47/50] - Loss: 1.5070
Epoch [48/50] - Loss: 1.5092
Epoch [49/50] - Loss: 1.5018
Epoch [50/50] - Loss: 1.4961
sum preds 3596
sum labels 5513
 - Test Metrics: Accuracy=0.8278, F1=0.6719, Recall=0.5551, Precision=0.8509
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.4254
Epoch [2/50] - Loss: 4.6157
Epoch [3/50] - Loss: 3.6933
Epoch [4/50] - Loss: 3.1021
Epoch [5/50] - Loss: 2.8354
Epoch [6/50] - Loss: 2.6162
Epoch [7/50] - Loss: 2.4014
Epoch [8/50] - Loss: 2.2256
Epoch [9/50] - Loss: 2.0851
Epoch [10/50] - Loss: 1.9734
Epoch [11/50] - Loss: 1.8912
Epoch [12/50] - Loss: 1.8165
Epoch [13/50] - Loss: 1.7624
Epoch [14/50] - Loss: 1.7140
Epoch [15/50] - Loss: 1.6732
Epoch [16/50] - Loss: 1.6454
Epoch [17/50] - Loss: 1.6036
Epoch [18/50] - Loss: 1.5895
Epoch [19/50] - Loss: 1.5564
Epoch [20/50] - Loss: 1.5335
Epoch [21/50] - Loss: 1.5124
Epoch [22/50] - Loss: 1.4969
Epoch [23/50] - Loss: 1.4886
Epoch [24/50] - Loss: 1.4702
Epoch [25/50] - Loss: 1.4561
Epoch [26/50] - Loss: 1.4500
Epoch [27/50] - Loss: 1.4367
Epoch [28/50] - Loss: 1.4172
Epoch [29/50] - Loss: 1.4057
Epoch [30/50] - Loss: 1.3994
Epoch [31/50] - Loss: 1.3888
Epoch [32/50] - Loss: 1.3789
Epoch [33/50] - Loss: 1.3750
Epoch [34/50] - Loss: 1.3668
Epoch [35/50] - Loss: 1.3545
Epoch [36/50] - Loss: 1.3440
Epoch [37/50] - Loss: 1.3368
Epoch [38/50] - Loss: 1.3349
Epoch [39/50] - Loss: 1.3204
Epoch [40/50] - Loss: 1.3150
Epoch [41/50] - Loss: 1.3022
Epoch [42/50] - Loss: 1.2959
Epoch [43/50] - Loss: 1.2953
Epoch [44/50] - Loss: 1.2821
Epoch [45/50] - Loss: 1.2700
Epoch [46/50] - Loss: 1.2685
Epoch [47/50] - Loss: 1.2626
Epoch [48/50] - Loss: 1.2587
Epoch [49/50] - Loss: 1.2503
Epoch [50/50] - Loss: 1.2442
sum preds 3754
sum labels 5513
 - Test Metrics: Accuracy=0.8383, F1=0.6971, Recall=0.5859, Precision=0.8604
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.5523
Epoch [2/50] - Loss: 4.6933
Epoch [3/50] - Loss: 3.7910
Epoch [4/50] - Loss: 3.2092
Epoch [5/50] - Loss: 3.0088
Epoch [6/50] - Loss: 2.8401
Epoch [7/50] - Loss: 2.6352
Epoch [8/50] - Loss: 2.4669
Epoch [9/50] - Loss: 2.3057
Epoch [10/50] - Loss: 2.1594
Epoch [11/50] - Loss: 2.0576
Epoch [12/50] - Loss: 1.9390
Epoch [13/50] - Loss: 1.8559
Epoch [14/50] - Loss: 1.7964
Epoch [15/50] - Loss: 1.7454
Epoch [16/50] - Loss: 1.7106
Epoch [17/50] - Loss: 1.6662
Epoch [18/50] - Loss: 1.6463
Epoch [19/50] - Loss: 1.6187
Epoch [20/50] - Loss: 1.5918
Epoch [21/50] - Loss: 1.5836
Epoch [22/50] - Loss: 1.5553
Epoch [23/50] - Loss: 1.5429
Epoch [24/50] - Loss: 1.5344
Epoch [25/50] - Loss: 1.5127
Epoch [26/50] - Loss: 1.5077
Epoch [27/50] - Loss: 1.5019
Epoch [28/50] - Loss: 1.4911
Epoch [29/50] - Loss: 1.4752
Epoch [30/50] - Loss: 1.4731
Epoch [31/50] - Loss: 1.4676
Epoch [32/50] - Loss: 1.4618
Epoch [33/50] - Loss: 1.4613
Epoch [34/50] - Loss: 1.4598
Epoch [35/50] - Loss: 1.4581
Epoch [36/50] - Loss: 1.4426
Epoch [37/50] - Loss: 1.4387
Epoch [38/50] - Loss: 1.4348
Epoch [39/50] - Loss: 1.4327
Epoch [40/50] - Loss: 1.4252
Epoch [41/50] - Loss: 1.4254
Epoch [42/50] - Loss: 1.4234
Epoch [43/50] - Loss: 1.4084
Epoch [44/50] - Loss: 1.4072
Epoch [45/50] - Loss: 1.4016
Epoch [46/50] - Loss: 1.3946
Epoch [47/50] - Loss: 1.3860
Epoch [48/50] - Loss: 1.3919
Epoch [49/50] - Loss: 1.3756
Epoch [50/50] - Loss: 1.3756
sum preds 3659
sum labels 5513
 - Test Metrics: Accuracy=0.8370, F1=0.6917, Recall=0.5754, Precision=0.8669
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_two_nnif_two_nnif_1804150345.csv.
Average F1 over valid seeds: 0.6869 ± 0.0108
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and two_nnif, MLP,0.3: 0.6869 ± 0.0108
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.8291
Epoch [2/50] - Loss: 3.6064
Epoch [3/50] - Loss: 3.1715
Epoch [4/50] - Loss: 3.0679
Epoch [5/50] - Loss: 2.9146
Epoch [6/50] - Loss: 2.7600
Epoch [7/50] - Loss: 2.6323
Epoch [8/50] - Loss: 2.4921
Epoch [9/50] - Loss: 2.3721
Epoch [10/50] - Loss: 2.2482
Epoch [11/50] - Loss: 2.1707
Epoch [12/50] - Loss: 2.1118
Epoch [13/50] - Loss: 2.0664
Epoch [14/50] - Loss: 2.0461
Epoch [15/50] - Loss: 2.0147
Epoch [16/50] - Loss: 1.9915
Epoch [17/50] - Loss: 1.9672
Epoch [18/50] - Loss: 1.9460
Epoch [19/50] - Loss: 1.9376
Epoch [20/50] - Loss: 1.9251
Epoch [21/50] - Loss: 1.9052
Epoch [22/50] - Loss: 1.9042
Epoch [23/50] - Loss: 1.8885
Epoch [24/50] - Loss: 1.8662
Epoch [25/50] - Loss: 1.8541
Epoch [26/50] - Loss: 1.8527
Epoch [27/50] - Loss: 1.8354
Epoch [28/50] - Loss: 1.8212
Epoch [29/50] - Loss: 1.8050
Epoch [30/50] - Loss: 1.8146
Epoch [31/50] - Loss: 1.7988
Epoch [32/50] - Loss: 1.7977
Epoch [33/50] - Loss: 1.7844
Epoch [34/50] - Loss: 1.7663
Epoch [35/50] - Loss: 1.7685
Epoch [36/50] - Loss: 1.7579
Epoch [37/50] - Loss: 1.7343
Epoch [38/50] - Loss: 1.7406
Epoch [39/50] - Loss: 1.7380
Epoch [40/50] - Loss: 1.7165
Epoch [41/50] - Loss: 1.7184
Epoch [42/50] - Loss: 1.7018
Epoch [43/50] - Loss: 1.6910
Epoch [44/50] - Loss: 1.6990
Epoch [45/50] - Loss: 1.6903
Epoch [46/50] - Loss: 1.6886
Epoch [47/50] - Loss: 1.6677
Epoch [48/50] - Loss: 1.6687
Epoch [49/50] - Loss: 1.6632
Epoch [50/50] - Loss: 1.6513
sum preds 3487
sum labels 5513
 - Test Metrics: Accuracy=0.8366, F1=0.6849, Recall=0.5590, Precision=0.8839
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.8870
Epoch [2/50] - Loss: 3.7455
Epoch [3/50] - Loss: 3.2188
Epoch [4/50] - Loss: 3.0835
Epoch [5/50] - Loss: 2.9532
Epoch [6/50] - Loss: 2.7896
Epoch [7/50] - Loss: 2.6075
Epoch [8/50] - Loss: 2.4686
Epoch [9/50] - Loss: 2.3327
Epoch [10/50] - Loss: 2.2397
Epoch [11/50] - Loss: 2.1501
Epoch [12/50] - Loss: 2.0675
Epoch [13/50] - Loss: 2.0254
Epoch [14/50] - Loss: 1.9794
Epoch [15/50] - Loss: 1.9631
Epoch [16/50] - Loss: 1.9329
Epoch [17/50] - Loss: 1.9137
Epoch [18/50] - Loss: 1.8902
Epoch [19/50] - Loss: 1.8525
Epoch [20/50] - Loss: 1.8461
Epoch [21/50] - Loss: 1.8252
Epoch [22/50] - Loss: 1.8051
Epoch [23/50] - Loss: 1.7888
Epoch [24/50] - Loss: 1.7617
Epoch [25/50] - Loss: 1.7602
Epoch [26/50] - Loss: 1.7360
Epoch [27/50] - Loss: 1.7191
Epoch [28/50] - Loss: 1.7077
Epoch [29/50] - Loss: 1.6903
Epoch [30/50] - Loss: 1.6755
Epoch [31/50] - Loss: 1.6650
Epoch [32/50] - Loss: 1.6645
Epoch [33/50] - Loss: 1.6511
Epoch [34/50] - Loss: 1.6435
Epoch [35/50] - Loss: 1.6296
Epoch [36/50] - Loss: 1.6216
Epoch [37/50] - Loss: 1.5980
Epoch [38/50] - Loss: 1.6043
Epoch [39/50] - Loss: 1.5997
Epoch [40/50] - Loss: 1.5919
Epoch [41/50] - Loss: 1.5842
Epoch [42/50] - Loss: 1.5731
Epoch [43/50] - Loss: 1.5715
Epoch [44/50] - Loss: 1.5582
Epoch [45/50] - Loss: 1.5549
Epoch [46/50] - Loss: 1.5482
Epoch [47/50] - Loss: 1.5408
Epoch [48/50] - Loss: 1.5384
Epoch [49/50] - Loss: 1.5307
Epoch [50/50] - Loss: 1.5183
sum preds 3400
sum labels 5513
 - Test Metrics: Accuracy=0.8387, F1=0.6860, Recall=0.5545, Precision=0.8991
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1036
Epoch [2/50] - Loss: 4.1036
Epoch [3/50] - Loss: 3.4129
Epoch [4/50] - Loss: 3.1085
Epoch [5/50] - Loss: 2.9703
Epoch [6/50] - Loss: 2.7730
Epoch [7/50] - Loss: 2.5920
Epoch [8/50] - Loss: 2.4586
Epoch [9/50] - Loss: 2.3305
Epoch [10/50] - Loss: 2.2498
Epoch [11/50] - Loss: 2.1477
Epoch [12/50] - Loss: 2.0967
Epoch [13/50] - Loss: 2.0367
Epoch [14/50] - Loss: 2.0147
Epoch [15/50] - Loss: 1.9674
Epoch [16/50] - Loss: 1.9504
Epoch [17/50] - Loss: 1.9432
Epoch [18/50] - Loss: 1.9156
Epoch [19/50] - Loss: 1.9007
Epoch [20/50] - Loss: 1.8774
Epoch [21/50] - Loss: 1.8586
Epoch [22/50] - Loss: 1.8410
Epoch [23/50] - Loss: 1.8306
Epoch [24/50] - Loss: 1.8002
Epoch [25/50] - Loss: 1.7947
Epoch [26/50] - Loss: 1.7672
Epoch [27/50] - Loss: 1.7567
Epoch [28/50] - Loss: 1.7408
Epoch [29/50] - Loss: 1.7277
Epoch [30/50] - Loss: 1.7160
Epoch [31/50] - Loss: 1.7114
Epoch [32/50] - Loss: 1.6960
Epoch [33/50] - Loss: 1.6877
Epoch [34/50] - Loss: 1.6734
Epoch [35/50] - Loss: 1.6587
Epoch [36/50] - Loss: 1.6504
Epoch [37/50] - Loss: 1.6423
Epoch [38/50] - Loss: 1.6309
Epoch [39/50] - Loss: 1.6235
Epoch [40/50] - Loss: 1.6196
Epoch [41/50] - Loss: 1.6098
Epoch [42/50] - Loss: 1.6097
Epoch [43/50] - Loss: 1.6019
Epoch [44/50] - Loss: 1.5852
Epoch [45/50] - Loss: 1.5843
Epoch [46/50] - Loss: 1.5715
Epoch [47/50] - Loss: 1.5719
Epoch [48/50] - Loss: 1.5599
Epoch [49/50] - Loss: 1.5535
Epoch [50/50] - Loss: 1.5529
sum preds 3247
sum labels 5513
 - Test Metrics: Accuracy=0.8290, F1=0.6612, Recall=0.5253, Precision=0.8919
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_two_nnif_two_nnif_1804152322.csv.
Average F1 over valid seeds: 0.6773 ± 0.0114
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and two_nnif, GATConv,0.3: 0.6773 ± 0.0114
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1765
Epoch [2/50] - Loss: 4.3167
Epoch [3/50] - Loss: 3.6766
Epoch [4/50] - Loss: 3.3308
Epoch [5/50] - Loss: 3.1893
Epoch [6/50] - Loss: 3.0740
Epoch [7/50] - Loss: 2.9879
Epoch [8/50] - Loss: 2.8613
Epoch [9/50] - Loss: 2.7597
Epoch [10/50] - Loss: 2.6560
Epoch [11/50] - Loss: 2.5535
Epoch [12/50] - Loss: 2.4436
Epoch [13/50] - Loss: 2.3579
Epoch [14/50] - Loss: 2.2686
Epoch [15/50] - Loss: 2.1977
Epoch [16/50] - Loss: 2.1391
Epoch [17/50] - Loss: 2.1002
Epoch [18/50] - Loss: 2.0776
Epoch [19/50] - Loss: 2.0477
Epoch [20/50] - Loss: 2.0233
Epoch [21/50] - Loss: 1.9999
Epoch [22/50] - Loss: 1.9789
Epoch [23/50] - Loss: 1.9562
Epoch [24/50] - Loss: 1.9348
Epoch [25/50] - Loss: 1.9178
Epoch [26/50] - Loss: 1.9147
Epoch [27/50] - Loss: 1.8974
Epoch [28/50] - Loss: 1.8850
Epoch [29/50] - Loss: 1.8916
Epoch [30/50] - Loss: 1.8778
Epoch [31/50] - Loss: 1.8620
Epoch [32/50] - Loss: 1.8583
Epoch [33/50] - Loss: 1.8652
Epoch [34/50] - Loss: 1.8514
Epoch [35/50] - Loss: 1.8529
Epoch [36/50] - Loss: 1.8438
Epoch [37/50] - Loss: 1.8500
Epoch [38/50] - Loss: 1.8395
Epoch [39/50] - Loss: 1.8387
Epoch [40/50] - Loss: 1.8263
Epoch [41/50] - Loss: 1.8330
Epoch [42/50] - Loss: 1.8307
Epoch [43/50] - Loss: 1.8275
Epoch [44/50] - Loss: 1.8175
Epoch [45/50] - Loss: 1.8196
Epoch [46/50] - Loss: 1.8182
Epoch [47/50] - Loss: 1.8018
Epoch [48/50] - Loss: 1.8071
Epoch [49/50] - Loss: 1.8116
Epoch [50/50] - Loss: 1.8052
sum preds 3565
sum labels 5513
 - Test Metrics: Accuracy=0.8444, F1=0.7026, Recall=0.5785, Precision=0.8945
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.0743
Epoch [2/50] - Loss: 4.0724
Epoch [3/50] - Loss: 3.4256
Epoch [4/50] - Loss: 3.1655
Epoch [5/50] - Loss: 3.0629
Epoch [6/50] - Loss: 2.8955
Epoch [7/50] - Loss: 2.7580
Epoch [8/50] - Loss: 2.6306
Epoch [9/50] - Loss: 2.5175
Epoch [10/50] - Loss: 2.3992
Epoch [11/50] - Loss: 2.3060
Epoch [12/50] - Loss: 2.2441
Epoch [13/50] - Loss: 2.1757
Epoch [14/50] - Loss: 2.1074
Epoch [15/50] - Loss: 2.0580
Epoch [16/50] - Loss: 2.0255
Epoch [17/50] - Loss: 2.0082
Epoch [18/50] - Loss: 1.9775
Epoch [19/50] - Loss: 1.9711
Epoch [20/50] - Loss: 1.9416
Epoch [21/50] - Loss: 1.9387
Epoch [22/50] - Loss: 1.9238
Epoch [23/50] - Loss: 1.9172
Epoch [24/50] - Loss: 1.9077
Epoch [25/50] - Loss: 1.8996
Epoch [26/50] - Loss: 1.8941
Epoch [27/50] - Loss: 1.8741
Epoch [28/50] - Loss: 1.8747
Epoch [29/50] - Loss: 1.8713
Epoch [30/50] - Loss: 1.8573
Epoch [31/50] - Loss: 1.8524
Epoch [32/50] - Loss: 1.8354
Epoch [33/50] - Loss: 1.8459
Epoch [34/50] - Loss: 1.8385
Epoch [35/50] - Loss: 1.8402
Epoch [36/50] - Loss: 1.8292
Epoch [37/50] - Loss: 1.8275
Epoch [38/50] - Loss: 1.8347
Epoch [39/50] - Loss: 1.8166
Epoch [40/50] - Loss: 1.8070
Epoch [41/50] - Loss: 1.8065
Epoch [42/50] - Loss: 1.8052
Epoch [43/50] - Loss: 1.7952
Epoch [44/50] - Loss: 1.7977
Epoch [45/50] - Loss: 1.7886
Epoch [46/50] - Loss: 1.7980
Epoch [47/50] - Loss: 1.7941
Epoch [48/50] - Loss: 1.7826
Epoch [49/50] - Loss: 1.7824
Epoch [50/50] - Loss: 1.7833
sum preds 3664
sum labels 5513
 - Test Metrics: Accuracy=0.8516, F1=0.7194, Recall=0.5988, Precision=0.9009
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.0413
Epoch [2/50] - Loss: 4.0401
Epoch [3/50] - Loss: 3.4025
Epoch [4/50] - Loss: 3.1018
Epoch [5/50] - Loss: 2.9184
Epoch [6/50] - Loss: 2.7393
Epoch [7/50] - Loss: 2.5696
Epoch [8/50] - Loss: 2.4471
Epoch [9/50] - Loss: 2.3279
Epoch [10/50] - Loss: 2.2382
Epoch [11/50] - Loss: 2.1708
Epoch [12/50] - Loss: 2.1151
Epoch [13/50] - Loss: 2.0562
Epoch [14/50] - Loss: 2.0151
Epoch [15/50] - Loss: 1.9951
Epoch [16/50] - Loss: 1.9744
Epoch [17/50] - Loss: 1.9602
Epoch [18/50] - Loss: 1.9361
Epoch [19/50] - Loss: 1.9298
Epoch [20/50] - Loss: 1.9221
Epoch [21/50] - Loss: 1.9083
Epoch [22/50] - Loss: 1.9049
Epoch [23/50] - Loss: 1.8944
Epoch [24/50] - Loss: 1.8841
Epoch [25/50] - Loss: 1.8633
Epoch [26/50] - Loss: 1.8634
Epoch [27/50] - Loss: 1.8568
Epoch [28/50] - Loss: 1.8591
Epoch [29/50] - Loss: 1.8475
Epoch [30/50] - Loss: 1.8395
Epoch [31/50] - Loss: 1.8335
Epoch [32/50] - Loss: 1.8279
Epoch [33/50] - Loss: 1.8367
Epoch [34/50] - Loss: 1.8180
Epoch [35/50] - Loss: 1.8211
Epoch [36/50] - Loss: 1.8161
Epoch [37/50] - Loss: 1.8113
Epoch [38/50] - Loss: 1.7992
Epoch [39/50] - Loss: 1.8050
Epoch [40/50] - Loss: 1.7947
Epoch [41/50] - Loss: 1.8057
Epoch [42/50] - Loss: 1.7975
Epoch [43/50] - Loss: 1.7960
Epoch [44/50] - Loss: 1.7898
Epoch [45/50] - Loss: 1.7914
Epoch [46/50] - Loss: 1.7908
Epoch [47/50] - Loss: 1.7909
Epoch [48/50] - Loss: 1.7829
Epoch [49/50] - Loss: 1.7897
Epoch [50/50] - Loss: 1.7818
sum preds 3484
sum labels 5513
 - Test Metrics: Accuracy=0.8432, F1=0.6976, Recall=0.5692, Precision=0.9007
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_two_nnif_two_nnif_1804154302.csv.
Average F1 over valid seeds: 0.7065 ± 0.0093
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and two_nnif, GCNConv,0.3: 0.7065 ± 0.0093
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1118
Epoch [2/50] - Loss: 4.2694
Epoch [3/50] - Loss: 3.3221
Epoch [4/50] - Loss: 2.5874
Epoch [5/50] - Loss: 2.2484
Epoch [6/50] - Loss: 2.1295
Epoch [7/50] - Loss: 2.0582
Epoch [8/50] - Loss: 1.9494
Epoch [9/50] - Loss: 1.8604
Epoch [10/50] - Loss: 1.7770
Epoch [11/50] - Loss: 1.7042
Epoch [12/50] - Loss: 1.6299
Epoch [13/50] - Loss: 1.5656
Epoch [14/50] - Loss: 1.5115
Epoch [15/50] - Loss: 1.4615
Epoch [16/50] - Loss: 1.4172
Epoch [17/50] - Loss: 1.3759
Epoch [18/50] - Loss: 1.3464
Epoch [19/50] - Loss: 1.3264
Epoch [20/50] - Loss: 1.3111
Epoch [21/50] - Loss: 1.2857
Epoch [22/50] - Loss: 1.2681
Epoch [23/50] - Loss: 1.2524
Epoch [24/50] - Loss: 1.2412
Epoch [25/50] - Loss: 1.2393
Epoch [26/50] - Loss: 1.2291
Epoch [27/50] - Loss: 1.2183
Epoch [28/50] - Loss: 1.2158
Epoch [29/50] - Loss: 1.2027
Epoch [30/50] - Loss: 1.1955
Epoch [31/50] - Loss: 1.1964
Epoch [32/50] - Loss: 1.1819
Epoch [33/50] - Loss: 1.1829
Epoch [34/50] - Loss: 1.1751
Epoch [35/50] - Loss: 1.1779
Epoch [36/50] - Loss: 1.1724
Epoch [37/50] - Loss: 1.1679
Epoch [38/50] - Loss: 1.1605
Epoch [39/50] - Loss: 1.1595
Epoch [40/50] - Loss: 1.1613
Epoch [41/50] - Loss: 1.1525
Epoch [42/50] - Loss: 1.1536
Epoch [43/50] - Loss: 1.1564
Epoch [44/50] - Loss: 1.1502
Epoch [45/50] - Loss: 1.1488
Epoch [46/50] - Loss: 1.1499
Epoch [47/50] - Loss: 1.1375
Epoch [48/50] - Loss: 1.1401
Epoch [49/50] - Loss: 1.1443
Epoch [50/50] - Loss: 1.1401
sum preds 3336
sum labels 6300
 - Test Metrics: Accuracy=0.7937, F1=0.6117, Recall=0.4678, Precision=0.8834
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.8793
Epoch [2/50] - Loss: 4.0623
Epoch [3/50] - Loss: 3.1463
Epoch [4/50] - Loss: 2.4861
Epoch [5/50] - Loss: 2.2222
Epoch [6/50] - Loss: 2.1608
Epoch [7/50] - Loss: 2.0918
Epoch [8/50] - Loss: 1.9995
Epoch [9/50] - Loss: 1.9152
Epoch [10/50] - Loss: 1.8642
Epoch [11/50] - Loss: 1.7989
Epoch [12/50] - Loss: 1.7346
Epoch [13/50] - Loss: 1.6793
Epoch [14/50] - Loss: 1.6203
Epoch [15/50] - Loss: 1.5629
Epoch [16/50] - Loss: 1.5108
Epoch [17/50] - Loss: 1.4687
Epoch [18/50] - Loss: 1.4318
Epoch [19/50] - Loss: 1.3969
Epoch [20/50] - Loss: 1.3671
Epoch [21/50] - Loss: 1.3318
Epoch [22/50] - Loss: 1.3215
Epoch [23/50] - Loss: 1.2968
Epoch [24/50] - Loss: 1.2745
Epoch [25/50] - Loss: 1.2588
Epoch [26/50] - Loss: 1.2476
Epoch [27/50] - Loss: 1.2347
Epoch [28/50] - Loss: 1.2294
Epoch [29/50] - Loss: 1.2184
Epoch [30/50] - Loss: 1.2116
Epoch [31/50] - Loss: 1.1934
Epoch [32/50] - Loss: 1.1872
Epoch [33/50] - Loss: 1.1809
Epoch [34/50] - Loss: 1.1725
Epoch [35/50] - Loss: 1.1727
Epoch [36/50] - Loss: 1.1698
Epoch [37/50] - Loss: 1.1643
Epoch [38/50] - Loss: 1.1588
Epoch [39/50] - Loss: 1.1556
Epoch [40/50] - Loss: 1.1481
Epoch [41/50] - Loss: 1.1545
Epoch [42/50] - Loss: 1.1509
Epoch [43/50] - Loss: 1.1460
Epoch [44/50] - Loss: 1.1399
Epoch [45/50] - Loss: 1.1352
Epoch [46/50] - Loss: 1.1336
Epoch [47/50] - Loss: 1.1279
Epoch [48/50] - Loss: 1.1298
Epoch [49/50] - Loss: 1.1267
Epoch [50/50] - Loss: 1.1255
sum preds 3407
sum labels 6300
 - Test Metrics: Accuracy=0.8010, F1=0.6280, Recall=0.4838, Precision=0.8946
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.8689
Epoch [2/50] - Loss: 3.9733
Epoch [3/50] - Loss: 3.0943
Epoch [4/50] - Loss: 2.4629
Epoch [5/50] - Loss: 2.1917
Epoch [6/50] - Loss: 2.0789
Epoch [7/50] - Loss: 1.9870
Epoch [8/50] - Loss: 1.8747
Epoch [9/50] - Loss: 1.7805
Epoch [10/50] - Loss: 1.6962
Epoch [11/50] - Loss: 1.6160
Epoch [12/50] - Loss: 1.5389
Epoch [13/50] - Loss: 1.4752
Epoch [14/50] - Loss: 1.4223
Epoch [15/50] - Loss: 1.3745
Epoch [16/50] - Loss: 1.3313
Epoch [17/50] - Loss: 1.2899
Epoch [18/50] - Loss: 1.2695
Epoch [19/50] - Loss: 1.2391
Epoch [20/50] - Loss: 1.2232
Epoch [21/50] - Loss: 1.2026
Epoch [22/50] - Loss: 1.1849
Epoch [23/50] - Loss: 1.1740
Epoch [24/50] - Loss: 1.1587
Epoch [25/50] - Loss: 1.1476
Epoch [26/50] - Loss: 1.1414
Epoch [27/50] - Loss: 1.1302
Epoch [28/50] - Loss: 1.1208
Epoch [29/50] - Loss: 1.1209
Epoch [30/50] - Loss: 1.1138
Epoch [31/50] - Loss: 1.1101
Epoch [32/50] - Loss: 1.1096
Epoch [33/50] - Loss: 1.0973
Epoch [34/50] - Loss: 1.0899
Epoch [35/50] - Loss: 1.0955
Epoch [36/50] - Loss: 1.0897
Epoch [37/50] - Loss: 1.0780
Epoch [38/50] - Loss: 1.0866
Epoch [39/50] - Loss: 1.0822
Epoch [40/50] - Loss: 1.0758
Epoch [41/50] - Loss: 1.0732
Epoch [42/50] - Loss: 1.0750
Epoch [43/50] - Loss: 1.0647
Epoch [44/50] - Loss: 1.0651
Epoch [45/50] - Loss: 1.0673
Epoch [46/50] - Loss: 1.0638
Epoch [47/50] - Loss: 1.0634
Epoch [48/50] - Loss: 1.0627
Epoch [49/50] - Loss: 1.0611
Epoch [50/50] - Loss: 1.0651
sum preds 3484
sum labels 6300
 - Test Metrics: Accuracy=0.8001, F1=0.6294, Recall=0.4887, Precision=0.8838
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_two_nnif_two_nnif_1804160242.csv.
Average F1 over valid seeds: 0.6230 ± 0.0080
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and two_nnif, MLP,0.2: 0.6230 ± 0.0080
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.2248
Epoch [2/50] - Loss: 3.0352
Epoch [3/50] - Loss: 2.4060
Epoch [4/50] - Loss: 2.2578
Epoch [5/50] - Loss: 2.2103
Epoch [6/50] - Loss: 2.1285
Epoch [7/50] - Loss: 2.0332
Epoch [8/50] - Loss: 1.9623
Epoch [9/50] - Loss: 1.9024
Epoch [10/50] - Loss: 1.8291
Epoch [11/50] - Loss: 1.7588
Epoch [12/50] - Loss: 1.7126
Epoch [13/50] - Loss: 1.6582
Epoch [14/50] - Loss: 1.6189
Epoch [15/50] - Loss: 1.5856
Epoch [16/50] - Loss: 1.5554
Epoch [17/50] - Loss: 1.5424
Epoch [18/50] - Loss: 1.5146
Epoch [19/50] - Loss: 1.5040
Epoch [20/50] - Loss: 1.4856
Epoch [21/50] - Loss: 1.4718
Epoch [22/50] - Loss: 1.4651
Epoch [23/50] - Loss: 1.4513
Epoch [24/50] - Loss: 1.4388
Epoch [25/50] - Loss: 1.4260
Epoch [26/50] - Loss: 1.4158
Epoch [27/50] - Loss: 1.4030
Epoch [28/50] - Loss: 1.3857
Epoch [29/50] - Loss: 1.3830
Epoch [30/50] - Loss: 1.3775
Epoch [31/50] - Loss: 1.3595
Epoch [32/50] - Loss: 1.3542
Epoch [33/50] - Loss: 1.3464
Epoch [34/50] - Loss: 1.3397
Epoch [35/50] - Loss: 1.3200
Epoch [36/50] - Loss: 1.3213
Epoch [37/50] - Loss: 1.3091
Epoch [38/50] - Loss: 1.3037
Epoch [39/50] - Loss: 1.2894
Epoch [40/50] - Loss: 1.2863
Epoch [41/50] - Loss: 1.2830
Epoch [42/50] - Loss: 1.2813
Epoch [43/50] - Loss: 1.2707
Epoch [44/50] - Loss: 1.2601
Epoch [45/50] - Loss: 1.2562
Epoch [46/50] - Loss: 1.2492
Epoch [47/50] - Loss: 1.2475
Epoch [48/50] - Loss: 1.2428
Epoch [49/50] - Loss: 1.2413
Epoch [50/50] - Loss: 1.2246
sum preds 3095
sum labels 6300
 - Test Metrics: Accuracy=0.7924, F1=0.5990, Recall=0.4467, Precision=0.9092
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.4074
Epoch [2/50] - Loss: 3.3998
Epoch [3/50] - Loss: 2.6987
Epoch [4/50] - Loss: 2.3564
Epoch [5/50] - Loss: 2.2153
Epoch [6/50] - Loss: 2.1365
Epoch [7/50] - Loss: 2.0657
Epoch [8/50] - Loss: 1.9852
Epoch [9/50] - Loss: 1.9084
Epoch [10/50] - Loss: 1.8441
Epoch [11/50] - Loss: 1.7834
Epoch [12/50] - Loss: 1.7475
Epoch [13/50] - Loss: 1.7075
Epoch [14/50] - Loss: 1.6722
Epoch [15/50] - Loss: 1.6386
Epoch [16/50] - Loss: 1.6075
Epoch [17/50] - Loss: 1.5840
Epoch [18/50] - Loss: 1.5601
Epoch [19/50] - Loss: 1.5403
Epoch [20/50] - Loss: 1.5264
Epoch [21/50] - Loss: 1.4984
Epoch [22/50] - Loss: 1.4913
Epoch [23/50] - Loss: 1.4747
Epoch [24/50] - Loss: 1.4617
Epoch [25/50] - Loss: 1.4483
Epoch [26/50] - Loss: 1.4366
Epoch [27/50] - Loss: 1.4258
Epoch [28/50] - Loss: 1.4142
Epoch [29/50] - Loss: 1.4034
Epoch [30/50] - Loss: 1.3923
Epoch [31/50] - Loss: 1.3837
Epoch [32/50] - Loss: 1.3711
Epoch [33/50] - Loss: 1.3671
Epoch [34/50] - Loss: 1.3510
Epoch [35/50] - Loss: 1.3377
Epoch [36/50] - Loss: 1.3406
Epoch [37/50] - Loss: 1.3289
Epoch [38/50] - Loss: 1.3164
Epoch [39/50] - Loss: 1.3181
Epoch [40/50] - Loss: 1.3071
Epoch [41/50] - Loss: 1.3045
Epoch [42/50] - Loss: 1.2890
Epoch [43/50] - Loss: 1.2932
Epoch [44/50] - Loss: 1.2843
Epoch [45/50] - Loss: 1.2800
Epoch [46/50] - Loss: 1.2685
Epoch [47/50] - Loss: 1.2638
Epoch [48/50] - Loss: 1.2662
Epoch [49/50] - Loss: 1.2541
Epoch [50/50] - Loss: 1.2474
sum preds 3148
sum labels 6300
 - Test Metrics: Accuracy=0.7991, F1=0.6143, Recall=0.4606, Precision=0.9219
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.2817
Epoch [2/50] - Loss: 3.1393
Epoch [3/50] - Loss: 2.4642
Epoch [4/50] - Loss: 2.2304
Epoch [5/50] - Loss: 2.1657
Epoch [6/50] - Loss: 2.0940
Epoch [7/50] - Loss: 1.9879
Epoch [8/50] - Loss: 1.8927
Epoch [9/50] - Loss: 1.8186
Epoch [10/50] - Loss: 1.7546
Epoch [11/50] - Loss: 1.6806
Epoch [12/50] - Loss: 1.6258
Epoch [13/50] - Loss: 1.5733
Epoch [14/50] - Loss: 1.5312
Epoch [15/50] - Loss: 1.4977
Epoch [16/50] - Loss: 1.4782
Epoch [17/50] - Loss: 1.4538
Epoch [18/50] - Loss: 1.4474
Epoch [19/50] - Loss: 1.4306
Epoch [20/50] - Loss: 1.4155
Epoch [21/50] - Loss: 1.4032
Epoch [22/50] - Loss: 1.3870
Epoch [23/50] - Loss: 1.3784
Epoch [24/50] - Loss: 1.3718
Epoch [25/50] - Loss: 1.3636
Epoch [26/50] - Loss: 1.3538
Epoch [27/50] - Loss: 1.3437
Epoch [28/50] - Loss: 1.3325
Epoch [29/50] - Loss: 1.3222
Epoch [30/50] - Loss: 1.3179
Epoch [31/50] - Loss: 1.3074
Epoch [32/50] - Loss: 1.2981
Epoch [33/50] - Loss: 1.2887
Epoch [34/50] - Loss: 1.2859
Epoch [35/50] - Loss: 1.2788
Epoch [36/50] - Loss: 1.2776
Epoch [37/50] - Loss: 1.2574
Epoch [38/50] - Loss: 1.2548
Epoch [39/50] - Loss: 1.2481
Epoch [40/50] - Loss: 1.2336
Epoch [41/50] - Loss: 1.2369
Epoch [42/50] - Loss: 1.2279
Epoch [43/50] - Loss: 1.2145
Epoch [44/50] - Loss: 1.2138
Epoch [45/50] - Loss: 1.2008
Epoch [46/50] - Loss: 1.1957
Epoch [47/50] - Loss: 1.1897
Epoch [48/50] - Loss: 1.1804
Epoch [49/50] - Loss: 1.1792
Epoch [50/50] - Loss: 1.1700
sum preds 3215
sum labels 6300
 - Test Metrics: Accuracy=0.7982, F1=0.6152, Recall=0.4646, Precision=0.9104
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_two_nnif_two_nnif_1804162014.csv.
Average F1 over valid seeds: 0.6095 ± 0.0074
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and two_nnif, GATConv,0.2: 0.6095 ± 0.0074
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.5441
Epoch [2/50] - Loss: 3.7744
Epoch [3/50] - Loss: 3.1134
Epoch [4/50] - Loss: 2.6592
Epoch [5/50] - Loss: 2.4162
Epoch [6/50] - Loss: 2.3121
Epoch [7/50] - Loss: 2.2623
Epoch [8/50] - Loss: 2.2142
Epoch [9/50] - Loss: 2.1719
Epoch [10/50] - Loss: 2.1199
Epoch [11/50] - Loss: 2.0762
Epoch [12/50] - Loss: 2.0311
Epoch [13/50] - Loss: 2.0018
Epoch [14/50] - Loss: 1.9698
Epoch [15/50] - Loss: 1.9308
Epoch [16/50] - Loss: 1.9039
Epoch [17/50] - Loss: 1.8667
Epoch [18/50] - Loss: 1.8274
Epoch [19/50] - Loss: 1.7918
Epoch [20/50] - Loss: 1.7532
Epoch [21/50] - Loss: 1.7187
Epoch [22/50] - Loss: 1.6873
Epoch [23/50] - Loss: 1.6498
Epoch [24/50] - Loss: 1.6255
Epoch [25/50] - Loss: 1.5970
Epoch [26/50] - Loss: 1.5844
Epoch [27/50] - Loss: 1.5541
Epoch [28/50] - Loss: 1.5394
Epoch [29/50] - Loss: 1.5304
Epoch [30/50] - Loss: 1.5133
Epoch [31/50] - Loss: 1.4981
Epoch [32/50] - Loss: 1.4917
Epoch [33/50] - Loss: 1.4811
Epoch [34/50] - Loss: 1.4753
Epoch [35/50] - Loss: 1.4700
Epoch [36/50] - Loss: 1.4561
Epoch [37/50] - Loss: 1.4500
Epoch [38/50] - Loss: 1.4357
Epoch [39/50] - Loss: 1.4436
Epoch [40/50] - Loss: 1.4323
Epoch [41/50] - Loss: 1.4330
Epoch [42/50] - Loss: 1.4265
Epoch [43/50] - Loss: 1.4178
Epoch [44/50] - Loss: 1.4126
Epoch [45/50] - Loss: 1.4133
Epoch [46/50] - Loss: 1.4087
Epoch [47/50] - Loss: 1.4077
Epoch [48/50] - Loss: 1.3994
Epoch [49/50] - Loss: 1.4007
Epoch [50/50] - Loss: 1.3993
sum preds 3292
sum labels 6300
 - Test Metrics: Accuracy=0.8066, F1=0.6343, Recall=0.4829, Precision=0.9241
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.6527
Epoch [2/50] - Loss: 4.1053
Epoch [3/50] - Loss: 3.5398
Epoch [4/50] - Loss: 3.0303
Epoch [5/50] - Loss: 2.6521
Epoch [6/50] - Loss: 2.4290
Epoch [7/50] - Loss: 2.3213
Epoch [8/50] - Loss: 2.2527
Epoch [9/50] - Loss: 2.2052
Epoch [10/50] - Loss: 2.1393
Epoch [11/50] - Loss: 2.0595
Epoch [12/50] - Loss: 1.9988
Epoch [13/50] - Loss: 1.9332
Epoch [14/50] - Loss: 1.8740
Epoch [15/50] - Loss: 1.8293
Epoch [16/50] - Loss: 1.7838
Epoch [17/50] - Loss: 1.7451
Epoch [18/50] - Loss: 1.7049
Epoch [19/50] - Loss: 1.6721
Epoch [20/50] - Loss: 1.6498
Epoch [21/50] - Loss: 1.6253
Epoch [22/50] - Loss: 1.6166
Epoch [23/50] - Loss: 1.5991
Epoch [24/50] - Loss: 1.5738
Epoch [25/50] - Loss: 1.5520
Epoch [26/50] - Loss: 1.5573
Epoch [27/50] - Loss: 1.5397
Epoch [28/50] - Loss: 1.5243
Epoch [29/50] - Loss: 1.5132
Epoch [30/50] - Loss: 1.5168
Epoch [31/50] - Loss: 1.5104
Epoch [32/50] - Loss: 1.4975
Epoch [33/50] - Loss: 1.4965
Epoch [34/50] - Loss: 1.4881
Epoch [35/50] - Loss: 1.4827
Epoch [36/50] - Loss: 1.4808
Epoch [37/50] - Loss: 1.4717
Epoch [38/50] - Loss: 1.4743
Epoch [39/50] - Loss: 1.4624
Epoch [40/50] - Loss: 1.4543
Epoch [41/50] - Loss: 1.4538
Epoch [42/50] - Loss: 1.4529
Epoch [43/50] - Loss: 1.4399
Epoch [44/50] - Loss: 1.4394
Epoch [45/50] - Loss: 1.4347
Epoch [46/50] - Loss: 1.4368
Epoch [47/50] - Loss: 1.4293
Epoch [48/50] - Loss: 1.4264
Epoch [49/50] - Loss: 1.4224
Epoch [50/50] - Loss: 1.4221
sum preds 3138
sum labels 6300
 - Test Metrics: Accuracy=0.8009, F1=0.6173, Recall=0.4624, Precision=0.9283
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.5540
Epoch [2/50] - Loss: 3.8163
Epoch [3/50] - Loss: 3.1247
Epoch [4/50] - Loss: 2.6207
Epoch [5/50] - Loss: 2.3633
Epoch [6/50] - Loss: 2.2673
Epoch [7/50] - Loss: 2.2029
Epoch [8/50] - Loss: 2.1371
Epoch [9/50] - Loss: 2.0646
Epoch [10/50] - Loss: 1.9799
Epoch [11/50] - Loss: 1.9082
Epoch [12/50] - Loss: 1.8454
Epoch [13/50] - Loss: 1.7734
Epoch [14/50] - Loss: 1.7207
Epoch [15/50] - Loss: 1.6593
Epoch [16/50] - Loss: 1.6254
Epoch [17/50] - Loss: 1.5820
Epoch [18/50] - Loss: 1.5513
Epoch [19/50] - Loss: 1.5261
Epoch [20/50] - Loss: 1.5087
Epoch [21/50] - Loss: 1.4900
Epoch [22/50] - Loss: 1.4736
Epoch [23/50] - Loss: 1.4568
Epoch [24/50] - Loss: 1.4479
Epoch [25/50] - Loss: 1.4354
Epoch [26/50] - Loss: 1.4328
Epoch [27/50] - Loss: 1.4223
Epoch [28/50] - Loss: 1.4120
Epoch [29/50] - Loss: 1.4072
Epoch [30/50] - Loss: 1.4017
Epoch [31/50] - Loss: 1.3993
Epoch [32/50] - Loss: 1.3929
Epoch [33/50] - Loss: 1.3840
Epoch [34/50] - Loss: 1.3841
Epoch [35/50] - Loss: 1.3782
Epoch [36/50] - Loss: 1.3706
Epoch [37/50] - Loss: 1.3672
Epoch [38/50] - Loss: 1.3696
Epoch [39/50] - Loss: 1.3637
Epoch [40/50] - Loss: 1.3607
Epoch [41/50] - Loss: 1.3489
Epoch [42/50] - Loss: 1.3553
Epoch [43/50] - Loss: 1.3492
Epoch [44/50] - Loss: 1.3450
Epoch [45/50] - Loss: 1.3433
Epoch [46/50] - Loss: 1.3447
Epoch [47/50] - Loss: 1.3339
Epoch [48/50] - Loss: 1.3288
Epoch [49/50] - Loss: 1.3345
Epoch [50/50] - Loss: 1.3350
sum preds 3276
sum labels 6300
 - Test Metrics: Accuracy=0.8050, F1=0.6305, Recall=0.4792, Precision=0.9216
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_two_nnif_two_nnif_1804163752.csv.
Average F1 over valid seeds: 0.6274 ± 0.0073
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and two_nnif, GCNConv,0.2: 0.6274 ± 0.0073
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.2995
Epoch [2/50] - Loss: 3.9380
Epoch [3/50] - Loss: 3.5546
Epoch [4/50] - Loss: 3.2405
Epoch [5/50] - Loss: 3.0195
Epoch [6/50] - Loss: 2.7723
Epoch [7/50] - Loss: 2.4781
Epoch [8/50] - Loss: 2.2386
Epoch [9/50] - Loss: 2.0027
Epoch [10/50] - Loss: 1.7970
Epoch [11/50] - Loss: 1.6359
Epoch [12/50] - Loss: 1.5008
Epoch [13/50] - Loss: 1.3990
Epoch [14/50] - Loss: 1.3157
Epoch [15/50] - Loss: 1.2516
Epoch [16/50] - Loss: 1.2003
Epoch [17/50] - Loss: 1.1454
Epoch [18/50] - Loss: 1.1227
Epoch [19/50] - Loss: 1.0923
Epoch [20/50] - Loss: 1.0663
Epoch [21/50] - Loss: 1.0450
Epoch [22/50] - Loss: 1.0221
Epoch [23/50] - Loss: 1.0094
Epoch [24/50] - Loss: 0.9965
Epoch [25/50] - Loss: 0.9817
Epoch [26/50] - Loss: 0.9705
Epoch [27/50] - Loss: 0.9562
Epoch [28/50] - Loss: 0.9477
Epoch [29/50] - Loss: 0.9320
Epoch [30/50] - Loss: 0.9278
Epoch [31/50] - Loss: 0.9186
Epoch [32/50] - Loss: 0.9022
Epoch [33/50] - Loss: 0.9005
Epoch [34/50] - Loss: 0.8987
Epoch [35/50] - Loss: 0.8866
Epoch [36/50] - Loss: 0.8856
Epoch [37/50] - Loss: 0.8781
Epoch [38/50] - Loss: 0.8742
Epoch [39/50] - Loss: 0.8593
Epoch [40/50] - Loss: 0.8611
Epoch [41/50] - Loss: 0.8636
Epoch [42/50] - Loss: 0.8532
Epoch [43/50] - Loss: 0.8585
Epoch [44/50] - Loss: 0.8520
Epoch [45/50] - Loss: 0.8463
Epoch [46/50] - Loss: 0.8457
Epoch [47/50] - Loss: 0.8406
Epoch [48/50] - Loss: 0.8418
Epoch [49/50] - Loss: 0.8304
Epoch [50/50] - Loss: 0.8305
sum preds 6150
sum labels 4725
 - Test Metrics: Accuracy=0.8236, F1=0.7312, Recall=0.8415, Precision=0.6465
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.7096
Epoch [2/50] - Loss: 4.2969
Epoch [3/50] - Loss: 3.7910
Epoch [4/50] - Loss: 3.3252
Epoch [5/50] - Loss: 3.0154
Epoch [6/50] - Loss: 2.7738
Epoch [7/50] - Loss: 2.5136
Epoch [8/50] - Loss: 2.2638
Epoch [9/50] - Loss: 2.0543
Epoch [10/50] - Loss: 1.8580
Epoch [11/50] - Loss: 1.7003
Epoch [12/50] - Loss: 1.5667
Epoch [13/50] - Loss: 1.4635
Epoch [14/50] - Loss: 1.3707
Epoch [15/50] - Loss: 1.3047
Epoch [16/50] - Loss: 1.2534
Epoch [17/50] - Loss: 1.1983
Epoch [18/50] - Loss: 1.1524
Epoch [19/50] - Loss: 1.1265
Epoch [20/50] - Loss: 1.0898
Epoch [21/50] - Loss: 1.0560
Epoch [22/50] - Loss: 1.0308
Epoch [23/50] - Loss: 1.0091
Epoch [24/50] - Loss: 0.9840
Epoch [25/50] - Loss: 0.9699
Epoch [26/50] - Loss: 0.9583
Epoch [27/50] - Loss: 0.9374
Epoch [28/50] - Loss: 0.9241
Epoch [29/50] - Loss: 0.9160
Epoch [30/50] - Loss: 0.8999
Epoch [31/50] - Loss: 0.8937
Epoch [32/50] - Loss: 0.8870
Epoch [33/50] - Loss: 0.8789
Epoch [34/50] - Loss: 0.8668
Epoch [35/50] - Loss: 0.8568
Epoch [36/50] - Loss: 0.8557
Epoch [37/50] - Loss: 0.8532
Epoch [38/50] - Loss: 0.8423
Epoch [39/50] - Loss: 0.8360
Epoch [40/50] - Loss: 0.8318
Epoch [41/50] - Loss: 0.8292
Epoch [42/50] - Loss: 0.8287
Epoch [43/50] - Loss: 0.8226
Epoch [44/50] - Loss: 0.8157
Epoch [45/50] - Loss: 0.8111
Epoch [46/50] - Loss: 0.8062
Epoch [47/50] - Loss: 0.8036
Epoch [48/50] - Loss: 0.8013
Epoch [49/50] - Loss: 0.7986
Epoch [50/50] - Loss: 0.7959
sum preds 6094
sum labels 4725
 - Test Metrics: Accuracy=0.8248, F1=0.7317, Recall=0.8377, Precision=0.6495
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.1778
Epoch [2/50] - Loss: 3.7716
Epoch [3/50] - Loss: 3.3630
Epoch [4/50] - Loss: 3.0897
Epoch [5/50] - Loss: 2.9051
Epoch [6/50] - Loss: 2.6813
Epoch [7/50] - Loss: 2.4568
Epoch [8/50] - Loss: 2.2554
Epoch [9/50] - Loss: 2.0523
Epoch [10/50] - Loss: 1.8646
Epoch [11/50] - Loss: 1.7140
Epoch [12/50] - Loss: 1.5778
Epoch [13/50] - Loss: 1.4627
Epoch [14/50] - Loss: 1.3722
Epoch [15/50] - Loss: 1.3019
Epoch [16/50] - Loss: 1.2419
Epoch [17/50] - Loss: 1.1954
Epoch [18/50] - Loss: 1.1550
Epoch [19/50] - Loss: 1.1269
Epoch [20/50] - Loss: 1.0942
Epoch [21/50] - Loss: 1.0710
Epoch [22/50] - Loss: 1.0499
Epoch [23/50] - Loss: 1.0290
Epoch [24/50] - Loss: 1.0138
Epoch [25/50] - Loss: 0.9948
Epoch [26/50] - Loss: 0.9849
Epoch [27/50] - Loss: 0.9727
Epoch [28/50] - Loss: 0.9656
Epoch [29/50] - Loss: 0.9461
Epoch [30/50] - Loss: 0.9405
Epoch [31/50] - Loss: 0.9303
Epoch [32/50] - Loss: 0.9207
Epoch [33/50] - Loss: 0.9192
Epoch [34/50] - Loss: 0.9105
Epoch [35/50] - Loss: 0.9034
Epoch [36/50] - Loss: 0.8928
Epoch [37/50] - Loss: 0.8971
Epoch [38/50] - Loss: 0.8893
Epoch [39/50] - Loss: 0.8786
Epoch [40/50] - Loss: 0.8748
Epoch [41/50] - Loss: 0.8745
Epoch [42/50] - Loss: 0.8659
Epoch [43/50] - Loss: 0.8645
Epoch [44/50] - Loss: 0.8546
Epoch [45/50] - Loss: 0.8536
Epoch [46/50] - Loss: 0.8551
Epoch [47/50] - Loss: 0.8513
Epoch [48/50] - Loss: 0.8499
Epoch [49/50] - Loss: 0.8468
Epoch [50/50] - Loss: 0.8384
sum preds 5524
sum labels 4725
 - Test Metrics: Accuracy=0.8472, F1=0.7530, Recall=0.8167, Precision=0.6986
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_spy_spy_1804165530.csv.
Average F1 over valid seeds: 0.7386 ± 0.0102
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and spy, MLP,0.4: 0.7386 ± 0.0102
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9054
Epoch [2/50] - Loss: 3.4512
Epoch [3/50] - Loss: 3.2104
Epoch [4/50] - Loss: 2.9951
Epoch [5/50] - Loss: 2.7549
Epoch [6/50] - Loss: 2.5321
Epoch [7/50] - Loss: 2.2936
Epoch [8/50] - Loss: 2.0856
Epoch [9/50] - Loss: 1.9148
Epoch [10/50] - Loss: 1.7857
Epoch [11/50] - Loss: 1.6893
Epoch [12/50] - Loss: 1.6210
Epoch [13/50] - Loss: 1.5639
Epoch [14/50] - Loss: 1.5359
Epoch [15/50] - Loss: 1.5050
Epoch [16/50] - Loss: 1.4876
Epoch [17/50] - Loss: 1.4575
Epoch [18/50] - Loss: 1.4231
Epoch [19/50] - Loss: 1.4049
Epoch [20/50] - Loss: 1.3804
Epoch [21/50] - Loss: 1.3797
Epoch [22/50] - Loss: 1.3589
Epoch [23/50] - Loss: 1.3526
Epoch [24/50] - Loss: 1.3276
Epoch [25/50] - Loss: 1.3309
Epoch [26/50] - Loss: 1.3215
Epoch [27/50] - Loss: 1.3096
Epoch [28/50] - Loss: 1.3007
Epoch [29/50] - Loss: 1.2912
Epoch [30/50] - Loss: 1.2826
Epoch [31/50] - Loss: 1.2790
Epoch [32/50] - Loss: 1.2716
Epoch [33/50] - Loss: 1.2703
Epoch [34/50] - Loss: 1.2632
Epoch [35/50] - Loss: 1.2425
Epoch [36/50] - Loss: 1.2394
Epoch [37/50] - Loss: 1.2352
Epoch [38/50] - Loss: 1.2411
Epoch [39/50] - Loss: 1.2376
Epoch [40/50] - Loss: 1.2259
Epoch [41/50] - Loss: 1.2220
Epoch [42/50] - Loss: 1.2167
Epoch [43/50] - Loss: 1.2238
Epoch [44/50] - Loss: 1.2076
Epoch [45/50] - Loss: 1.2036
Epoch [46/50] - Loss: 1.1918
Epoch [47/50] - Loss: 1.1770
Epoch [48/50] - Loss: 1.1943
Epoch [49/50] - Loss: 1.1867
Epoch [50/50] - Loss: 1.1775
sum preds 5289
sum labels 4725
 - Test Metrics: Accuracy=0.8723, F1=0.7887, Recall=0.8358, Precision=0.7466
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9634
Epoch [2/50] - Loss: 3.5646
Epoch [3/50] - Loss: 3.2748
Epoch [4/50] - Loss: 3.0805
Epoch [5/50] - Loss: 2.8929
Epoch [6/50] - Loss: 2.6734
Epoch [7/50] - Loss: 2.4850
Epoch [8/50] - Loss: 2.3077
Epoch [9/50] - Loss: 2.1381
Epoch [10/50] - Loss: 1.9797
Epoch [11/50] - Loss: 1.8657
Epoch [12/50] - Loss: 1.7648
Epoch [13/50] - Loss: 1.6846
Epoch [14/50] - Loss: 1.6357
Epoch [15/50] - Loss: 1.5763
Epoch [16/50] - Loss: 1.5385
Epoch [17/50] - Loss: 1.5044
Epoch [18/50] - Loss: 1.4743
Epoch [19/50] - Loss: 1.4416
Epoch [20/50] - Loss: 1.4142
Epoch [21/50] - Loss: 1.3966
Epoch [22/50] - Loss: 1.3832
Epoch [23/50] - Loss: 1.3522
Epoch [24/50] - Loss: 1.3310
Epoch [25/50] - Loss: 1.3140
Epoch [26/50] - Loss: 1.3114
Epoch [27/50] - Loss: 1.2917
Epoch [28/50] - Loss: 1.2780
Epoch [29/50] - Loss: 1.2572
Epoch [30/50] - Loss: 1.2464
Epoch [31/50] - Loss: 1.2411
Epoch [32/50] - Loss: 1.2270
Epoch [33/50] - Loss: 1.2201
Epoch [34/50] - Loss: 1.2010
Epoch [35/50] - Loss: 1.1938
Epoch [36/50] - Loss: 1.1899
Epoch [37/50] - Loss: 1.1877
Epoch [38/50] - Loss: 1.1787
Epoch [39/50] - Loss: 1.1727
Epoch [40/50] - Loss: 1.1613
Epoch [41/50] - Loss: 1.1506
Epoch [42/50] - Loss: 1.1513
Epoch [43/50] - Loss: 1.1459
Epoch [44/50] - Loss: 1.1429
Epoch [45/50] - Loss: 1.1281
Epoch [46/50] - Loss: 1.1329
Epoch [47/50] - Loss: 1.1212
Epoch [48/50] - Loss: 1.1219
Epoch [49/50] - Loss: 1.1150
Epoch [50/50] - Loss: 1.1175
sum preds 5074
sum labels 4725
 - Test Metrics: Accuracy=0.8749, F1=0.7884, Recall=0.8176, Precision=0.7613
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9431
Epoch [2/50] - Loss: 3.4709
Epoch [3/50] - Loss: 3.1041
Epoch [4/50] - Loss: 2.8311
Epoch [5/50] - Loss: 2.5672
Epoch [6/50] - Loss: 2.3194
Epoch [7/50] - Loss: 2.1342
Epoch [8/50] - Loss: 1.9713
Epoch [9/50] - Loss: 1.8400
Epoch [10/50] - Loss: 1.7330
Epoch [11/50] - Loss: 1.6525
Epoch [12/50] - Loss: 1.5939
Epoch [13/50] - Loss: 1.5540
Epoch [14/50] - Loss: 1.5230
Epoch [15/50] - Loss: 1.4981
Epoch [16/50] - Loss: 1.4612
Epoch [17/50] - Loss: 1.4345
Epoch [18/50] - Loss: 1.4155
Epoch [19/50] - Loss: 1.3963
Epoch [20/50] - Loss: 1.3787
Epoch [21/50] - Loss: 1.3646
Epoch [22/50] - Loss: 1.3481
Epoch [23/50] - Loss: 1.3435
Epoch [24/50] - Loss: 1.3286
Epoch [25/50] - Loss: 1.3088
Epoch [26/50] - Loss: 1.3101
Epoch [27/50] - Loss: 1.2925
Epoch [28/50] - Loss: 1.2711
Epoch [29/50] - Loss: 1.2669
Epoch [30/50] - Loss: 1.2583
Epoch [31/50] - Loss: 1.2431
Epoch [32/50] - Loss: 1.2298
Epoch [33/50] - Loss: 1.2193
Epoch [34/50] - Loss: 1.2176
Epoch [35/50] - Loss: 1.2006
Epoch [36/50] - Loss: 1.2000
Epoch [37/50] - Loss: 1.1861
Epoch [38/50] - Loss: 1.1806
Epoch [39/50] - Loss: 1.1715
Epoch [40/50] - Loss: 1.1571
Epoch [41/50] - Loss: 1.1451
Epoch [42/50] - Loss: 1.1444
Epoch [43/50] - Loss: 1.1355
Epoch [44/50] - Loss: 1.1269
Epoch [45/50] - Loss: 1.1235
Epoch [46/50] - Loss: 1.1101
Epoch [47/50] - Loss: 1.1034
Epoch [48/50] - Loss: 1.1032
Epoch [49/50] - Loss: 1.0944
Epoch [50/50] - Loss: 1.0913
sum preds 4676
sum labels 4725
 - Test Metrics: Accuracy=0.8838, F1=0.7952, Recall=0.7911, Precision=0.7994
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_spy_spy_1804170736.csv.
Average F1 over valid seeds: 0.7908 ± 0.0031
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and spy, GATConv,0.4: 0.7908 ± 0.0031
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.0284
Epoch [2/50] - Loss: 3.7142
Epoch [3/50] - Loss: 3.4263
Epoch [4/50] - Loss: 3.1739
Epoch [5/50] - Loss: 2.9648
Epoch [6/50] - Loss: 2.7331
Epoch [7/50] - Loss: 2.5350
Epoch [8/50] - Loss: 2.3504
Epoch [9/50] - Loss: 2.1791
Epoch [10/50] - Loss: 2.0396
Epoch [11/50] - Loss: 1.9175
Epoch [12/50] - Loss: 1.8202
Epoch [13/50] - Loss: 1.7354
Epoch [14/50] - Loss: 1.6606
Epoch [15/50] - Loss: 1.6102
Epoch [16/50] - Loss: 1.5790
Epoch [17/50] - Loss: 1.5430
Epoch [18/50] - Loss: 1.5067
Epoch [19/50] - Loss: 1.4851
Epoch [20/50] - Loss: 1.4646
Epoch [21/50] - Loss: 1.4347
Epoch [22/50] - Loss: 1.4208
Epoch [23/50] - Loss: 1.4076
Epoch [24/50] - Loss: 1.3964
Epoch [25/50] - Loss: 1.3906
Epoch [26/50] - Loss: 1.3644
Epoch [27/50] - Loss: 1.3629
Epoch [28/50] - Loss: 1.3465
Epoch [29/50] - Loss: 1.3532
Epoch [30/50] - Loss: 1.3272
Epoch [31/50] - Loss: 1.3142
Epoch [32/50] - Loss: 1.3013
Epoch [33/50] - Loss: 1.3070
Epoch [34/50] - Loss: 1.3108
Epoch [35/50] - Loss: 1.2852
Epoch [36/50] - Loss: 1.2884
Epoch [37/50] - Loss: 1.2885
Epoch [38/50] - Loss: 1.2821
Epoch [39/50] - Loss: 1.2683
Epoch [40/50] - Loss: 1.2627
Epoch [41/50] - Loss: 1.2534
Epoch [42/50] - Loss: 1.2574
Epoch [43/50] - Loss: 1.2577
Epoch [44/50] - Loss: 1.2511
Epoch [45/50] - Loss: 1.2521
Epoch [46/50] - Loss: 1.2413
Epoch [47/50] - Loss: 1.2231
Epoch [48/50] - Loss: 1.2320
Epoch [49/50] - Loss: 1.2408
Epoch [50/50] - Loss: 1.2188
sum preds 5303
sum labels 4725
 - Test Metrics: Accuracy=0.8722, F1=0.7888, Recall=0.8370, Precision=0.7458
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8931
Epoch [2/50] - Loss: 3.4184
Epoch [3/50] - Loss: 3.1946
Epoch [4/50] - Loss: 3.0250
Epoch [5/50] - Loss: 2.8230
Epoch [6/50] - Loss: 2.6620
Epoch [7/50] - Loss: 2.4774
Epoch [8/50] - Loss: 2.2902
Epoch [9/50] - Loss: 2.1198
Epoch [10/50] - Loss: 1.9702
Epoch [11/50] - Loss: 1.8517
Epoch [12/50] - Loss: 1.7463
Epoch [13/50] - Loss: 1.6692
Epoch [14/50] - Loss: 1.6028
Epoch [15/50] - Loss: 1.5622
Epoch [16/50] - Loss: 1.5286
Epoch [17/50] - Loss: 1.4907
Epoch [18/50] - Loss: 1.4685
Epoch [19/50] - Loss: 1.4573
Epoch [20/50] - Loss: 1.4313
Epoch [21/50] - Loss: 1.4246
Epoch [22/50] - Loss: 1.3994
Epoch [23/50] - Loss: 1.3874
Epoch [24/50] - Loss: 1.3734
Epoch [25/50] - Loss: 1.3767
Epoch [26/50] - Loss: 1.3598
Epoch [27/50] - Loss: 1.3440
Epoch [28/50] - Loss: 1.3409
Epoch [29/50] - Loss: 1.3380
Epoch [30/50] - Loss: 1.3298
Epoch [31/50] - Loss: 1.3342
Epoch [32/50] - Loss: 1.3141
Epoch [33/50] - Loss: 1.3120
Epoch [34/50] - Loss: 1.3041
Epoch [35/50] - Loss: 1.3011
Epoch [36/50] - Loss: 1.2974
Epoch [37/50] - Loss: 1.2928
Epoch [38/50] - Loss: 1.2828
Epoch [39/50] - Loss: 1.2858
Epoch [40/50] - Loss: 1.2818
Epoch [41/50] - Loss: 1.2796
Epoch [42/50] - Loss: 1.2772
Epoch [43/50] - Loss: 1.2641
Epoch [44/50] - Loss: 1.2629
Epoch [45/50] - Loss: 1.2606
Epoch [46/50] - Loss: 1.2553
Epoch [47/50] - Loss: 1.2532
Epoch [48/50] - Loss: 1.2532
Epoch [49/50] - Loss: 1.2566
Epoch [50/50] - Loss: 1.2491
sum preds 5152
sum labels 4725
 - Test Metrics: Accuracy=0.8776, F1=0.7948, Recall=0.8307, Precision=0.7618
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9406
Epoch [2/50] - Loss: 3.4919
Epoch [3/50] - Loss: 3.1898
Epoch [4/50] - Loss: 2.9978
Epoch [5/50] - Loss: 2.7683
Epoch [6/50] - Loss: 2.5513
Epoch [7/50] - Loss: 2.3468
Epoch [8/50] - Loss: 2.1685
Epoch [9/50] - Loss: 2.0100
Epoch [10/50] - Loss: 1.8801
Epoch [11/50] - Loss: 1.7688
Epoch [12/50] - Loss: 1.6758
Epoch [13/50] - Loss: 1.6089
Epoch [14/50] - Loss: 1.5522
Epoch [15/50] - Loss: 1.5162
Epoch [16/50] - Loss: 1.4774
Epoch [17/50] - Loss: 1.4526
Epoch [18/50] - Loss: 1.4337
Epoch [19/50] - Loss: 1.4104
Epoch [20/50] - Loss: 1.3840
Epoch [21/50] - Loss: 1.3709
Epoch [22/50] - Loss: 1.3622
Epoch [23/50] - Loss: 1.3496
Epoch [24/50] - Loss: 1.3444
Epoch [25/50] - Loss: 1.3230
Epoch [26/50] - Loss: 1.3213
Epoch [27/50] - Loss: 1.3073
Epoch [28/50] - Loss: 1.3078
Epoch [29/50] - Loss: 1.2949
Epoch [30/50] - Loss: 1.2855
Epoch [31/50] - Loss: 1.2768
Epoch [32/50] - Loss: 1.2798
Epoch [33/50] - Loss: 1.2668
Epoch [34/50] - Loss: 1.2621
Epoch [35/50] - Loss: 1.2630
Epoch [36/50] - Loss: 1.2604
Epoch [37/50] - Loss: 1.2561
Epoch [38/50] - Loss: 1.2547
Epoch [39/50] - Loss: 1.2482
Epoch [40/50] - Loss: 1.2435
Epoch [41/50] - Loss: 1.2403
Epoch [42/50] - Loss: 1.2361
Epoch [43/50] - Loss: 1.2362
Epoch [44/50] - Loss: 1.2389
Epoch [45/50] - Loss: 1.2247
Epoch [46/50] - Loss: 1.2241
Epoch [47/50] - Loss: 1.2185
Epoch [48/50] - Loss: 1.2170
Epoch [49/50] - Loss: 1.2218
Epoch [50/50] - Loss: 1.2097
sum preds 4764
sum labels 4725
 - Test Metrics: Accuracy=0.8859, F1=0.8007, Recall=0.8040, Precision=0.7974
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_spy_spy_1804171926.csv.
Average F1 over valid seeds: 0.7948 ± 0.0049
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and spy, GCNConv,0.4: 0.7948 ± 0.0049
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.3607
Epoch [2/50] - Loss: 3.8847
Epoch [3/50] - Loss: 3.3541
Epoch [4/50] - Loss: 2.9186
Epoch [5/50] - Loss: 2.6656
Epoch [6/50] - Loss: 2.5416
Epoch [7/50] - Loss: 2.3940
Epoch [8/50] - Loss: 2.2232
Epoch [9/50] - Loss: 2.0704
Epoch [10/50] - Loss: 1.9382
Epoch [11/50] - Loss: 1.8023
Epoch [12/50] - Loss: 1.6716
Epoch [13/50] - Loss: 1.5501
Epoch [14/50] - Loss: 1.4495
Epoch [15/50] - Loss: 1.3574
Epoch [16/50] - Loss: 1.2881
Epoch [17/50] - Loss: 1.2315
Epoch [18/50] - Loss: 1.1811
Epoch [19/50] - Loss: 1.1416
Epoch [20/50] - Loss: 1.1040
Epoch [21/50] - Loss: 1.0735
Epoch [22/50] - Loss: 1.0528
Epoch [23/50] - Loss: 1.0243
Epoch [24/50] - Loss: 1.0103
Epoch [25/50] - Loss: 0.9887
Epoch [26/50] - Loss: 0.9764
Epoch [27/50] - Loss: 0.9601
Epoch [28/50] - Loss: 0.9461
Epoch [29/50] - Loss: 0.9316
Epoch [30/50] - Loss: 0.9195
Epoch [31/50] - Loss: 0.9126
Epoch [32/50] - Loss: 0.9043
Epoch [33/50] - Loss: 0.8983
Epoch [34/50] - Loss: 0.8854
Epoch [35/50] - Loss: 0.8775
Epoch [36/50] - Loss: 0.8701
Epoch [37/50] - Loss: 0.8691
Epoch [38/50] - Loss: 0.8583
Epoch [39/50] - Loss: 0.8554
Epoch [40/50] - Loss: 0.8477
Epoch [41/50] - Loss: 0.8426
Epoch [42/50] - Loss: 0.8400
Epoch [43/50] - Loss: 0.8358
Epoch [44/50] - Loss: 0.8311
Epoch [45/50] - Loss: 0.8321
Epoch [46/50] - Loss: 0.8224
Epoch [47/50] - Loss: 0.8154
Epoch [48/50] - Loss: 0.8216
Epoch [49/50] - Loss: 0.8142
Epoch [50/50] - Loss: 0.8095
sum preds 5760
sum labels 5513
 - Test Metrics: Accuracy=0.8413, F1=0.7556, Recall=0.7725, Precision=0.7394
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.8538
Epoch [2/50] - Loss: 4.3551
Epoch [3/50] - Loss: 3.7289
Epoch [4/50] - Loss: 3.1416
Epoch [5/50] - Loss: 2.7374
Epoch [6/50] - Loss: 2.5378
Epoch [7/50] - Loss: 2.3550
Epoch [8/50] - Loss: 2.1484
Epoch [9/50] - Loss: 1.9706
Epoch [10/50] - Loss: 1.8149
Epoch [11/50] - Loss: 1.6765
Epoch [12/50] - Loss: 1.5624
Epoch [13/50] - Loss: 1.4601
Epoch [14/50] - Loss: 1.3756
Epoch [15/50] - Loss: 1.3084
Epoch [16/50] - Loss: 1.2452
Epoch [17/50] - Loss: 1.1929
Epoch [18/50] - Loss: 1.1466
Epoch [19/50] - Loss: 1.1232
Epoch [20/50] - Loss: 1.0912
Epoch [21/50] - Loss: 1.0571
Epoch [22/50] - Loss: 1.0369
Epoch [23/50] - Loss: 1.0140
Epoch [24/50] - Loss: 0.9885
Epoch [25/50] - Loss: 0.9757
Epoch [26/50] - Loss: 0.9595
Epoch [27/50] - Loss: 0.9477
Epoch [28/50] - Loss: 0.9267
Epoch [29/50] - Loss: 0.9136
Epoch [30/50] - Loss: 0.9046
Epoch [31/50] - Loss: 0.8996
Epoch [32/50] - Loss: 0.8828
Epoch [33/50] - Loss: 0.8719
Epoch [34/50] - Loss: 0.8704
Epoch [35/50] - Loss: 0.8555
Epoch [36/50] - Loss: 0.8470
Epoch [37/50] - Loss: 0.8445
Epoch [38/50] - Loss: 0.8376
Epoch [39/50] - Loss: 0.8256
Epoch [40/50] - Loss: 0.8239
Epoch [41/50] - Loss: 0.8136
Epoch [42/50] - Loss: 0.8099
Epoch [43/50] - Loss: 0.8039
Epoch [44/50] - Loss: 0.7950
Epoch [45/50] - Loss: 0.7967
Epoch [46/50] - Loss: 0.7940
Epoch [47/50] - Loss: 0.7870
Epoch [48/50] - Loss: 0.7844
Epoch [49/50] - Loss: 0.7798
Epoch [50/50] - Loss: 0.7759
sum preds 5827
sum labels 5513
 - Test Metrics: Accuracy=0.8486, F1=0.7683, Recall=0.7901, Precision=0.7476
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.1850
Epoch [2/50] - Loss: 3.6873
Epoch [3/50] - Loss: 3.1671
Epoch [4/50] - Loss: 2.8167
Epoch [5/50] - Loss: 2.6449
Epoch [6/50] - Loss: 2.5040
Epoch [7/50] - Loss: 2.3312
Epoch [8/50] - Loss: 2.1597
Epoch [9/50] - Loss: 2.0098
Epoch [10/50] - Loss: 1.8518
Epoch [11/50] - Loss: 1.7069
Epoch [12/50] - Loss: 1.5694
Epoch [13/50] - Loss: 1.4594
Epoch [14/50] - Loss: 1.3601
Epoch [15/50] - Loss: 1.2873
Epoch [16/50] - Loss: 1.2221
Epoch [17/50] - Loss: 1.1725
Epoch [18/50] - Loss: 1.1279
Epoch [19/50] - Loss: 1.0870
Epoch [20/50] - Loss: 1.0570
Epoch [21/50] - Loss: 1.0287
Epoch [22/50] - Loss: 1.0038
Epoch [23/50] - Loss: 0.9848
Epoch [24/50] - Loss: 0.9684
Epoch [25/50] - Loss: 0.9428
Epoch [26/50] - Loss: 0.9351
Epoch [27/50] - Loss: 0.9175
Epoch [28/50] - Loss: 0.9058
Epoch [29/50] - Loss: 0.8963
Epoch [30/50] - Loss: 0.8848
Epoch [31/50] - Loss: 0.8715
Epoch [32/50] - Loss: 0.8621
Epoch [33/50] - Loss: 0.8547
Epoch [34/50] - Loss: 0.8475
Epoch [35/50] - Loss: 0.8420
Epoch [36/50] - Loss: 0.8387
Epoch [37/50] - Loss: 0.8293
Epoch [38/50] - Loss: 0.8234
Epoch [39/50] - Loss: 0.8122
Epoch [40/50] - Loss: 0.8141
Epoch [41/50] - Loss: 0.8023
Epoch [42/50] - Loss: 0.7972
Epoch [43/50] - Loss: 0.8005
Epoch [44/50] - Loss: 0.7934
Epoch [45/50] - Loss: 0.7855
Epoch [46/50] - Loss: 0.7797
Epoch [47/50] - Loss: 0.7761
Epoch [48/50] - Loss: 0.7794
Epoch [49/50] - Loss: 0.7773
Epoch [50/50] - Loss: 0.7691
sum preds 5742
sum labels 5513
 - Test Metrics: Accuracy=0.8451, F1=0.7611, Recall=0.7769, Precision=0.7459
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_spy_spy_1804173114.csv.
Average F1 over valid seeds: 0.7616 ± 0.0052
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and spy, MLP,0.3: 0.7616 ± 0.0052
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8102
Epoch [2/50] - Loss: 3.1449
Epoch [3/50] - Loss: 2.7956
Epoch [4/50] - Loss: 2.6760
Epoch [5/50] - Loss: 2.5544
Epoch [6/50] - Loss: 2.4109
Epoch [7/50] - Loss: 2.2911
Epoch [8/50] - Loss: 2.1960
Epoch [9/50] - Loss: 2.0769
Epoch [10/50] - Loss: 1.9342
Epoch [11/50] - Loss: 1.8110
Epoch [12/50] - Loss: 1.7013
Epoch [13/50] - Loss: 1.6145
Epoch [14/50] - Loss: 1.5452
Epoch [15/50] - Loss: 1.5086
Epoch [16/50] - Loss: 1.4634
Epoch [17/50] - Loss: 1.4313
Epoch [18/50] - Loss: 1.3989
Epoch [19/50] - Loss: 1.3810
Epoch [20/50] - Loss: 1.3620
Epoch [21/50] - Loss: 1.3401
Epoch [22/50] - Loss: 1.3266
Epoch [23/50] - Loss: 1.3095
Epoch [24/50] - Loss: 1.2957
Epoch [25/50] - Loss: 1.2822
Epoch [26/50] - Loss: 1.2635
Epoch [27/50] - Loss: 1.2578
Epoch [28/50] - Loss: 1.2456
Epoch [29/50] - Loss: 1.2216
Epoch [30/50] - Loss: 1.2197
Epoch [31/50] - Loss: 1.2206
Epoch [32/50] - Loss: 1.2042
Epoch [33/50] - Loss: 1.1958
Epoch [34/50] - Loss: 1.1836
Epoch [35/50] - Loss: 1.1757
Epoch [36/50] - Loss: 1.1747
Epoch [37/50] - Loss: 1.1675
Epoch [38/50] - Loss: 1.1565
Epoch [39/50] - Loss: 1.1533
Epoch [40/50] - Loss: 1.1399
Epoch [41/50] - Loss: 1.1336
Epoch [42/50] - Loss: 1.1332
Epoch [43/50] - Loss: 1.1169
Epoch [44/50] - Loss: 1.1181
Epoch [45/50] - Loss: 1.1128
Epoch [46/50] - Loss: 1.1051
Epoch [47/50] - Loss: 1.1089
Epoch [48/50] - Loss: 1.0967
Epoch [49/50] - Loss: 1.0931
Epoch [50/50] - Loss: 1.0950
sum preds 5014
sum labels 5513
 - Test Metrics: Accuracy=0.8739, F1=0.7921, Recall=0.7562, Precision=0.8315
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9118
Epoch [2/50] - Loss: 3.3877
Epoch [3/50] - Loss: 2.9983
Epoch [4/50] - Loss: 2.7638
Epoch [5/50] - Loss: 2.6537
Epoch [6/50] - Loss: 2.5408
Epoch [7/50] - Loss: 2.3834
Epoch [8/50] - Loss: 2.2495
Epoch [9/50] - Loss: 2.1204
Epoch [10/50] - Loss: 2.0028
Epoch [11/50] - Loss: 1.8818
Epoch [12/50] - Loss: 1.7839
Epoch [13/50] - Loss: 1.6949
Epoch [14/50] - Loss: 1.6203
Epoch [15/50] - Loss: 1.5582
Epoch [16/50] - Loss: 1.5134
Epoch [17/50] - Loss: 1.4670
Epoch [18/50] - Loss: 1.4422
Epoch [19/50] - Loss: 1.4198
Epoch [20/50] - Loss: 1.3805
Epoch [21/50] - Loss: 1.3596
Epoch [22/50] - Loss: 1.3423
Epoch [23/50] - Loss: 1.3034
Epoch [24/50] - Loss: 1.2888
Epoch [25/50] - Loss: 1.2736
Epoch [26/50] - Loss: 1.2558
Epoch [27/50] - Loss: 1.2384
Epoch [28/50] - Loss: 1.2263
Epoch [29/50] - Loss: 1.2006
Epoch [30/50] - Loss: 1.1863
Epoch [31/50] - Loss: 1.1736
Epoch [32/50] - Loss: 1.1706
Epoch [33/50] - Loss: 1.1570
Epoch [34/50] - Loss: 1.1372
Epoch [35/50] - Loss: 1.1286
Epoch [36/50] - Loss: 1.1280
Epoch [37/50] - Loss: 1.1189
Epoch [38/50] - Loss: 1.0964
Epoch [39/50] - Loss: 1.0776
Epoch [40/50] - Loss: 1.0884
Epoch [41/50] - Loss: 1.0726
Epoch [42/50] - Loss: 1.0556
Epoch [43/50] - Loss: 1.0606
Epoch [44/50] - Loss: 1.0516
Epoch [45/50] - Loss: 1.0345
Epoch [46/50] - Loss: 1.0387
Epoch [47/50] - Loss: 1.0298
Epoch [48/50] - Loss: 1.0195
Epoch [49/50] - Loss: 1.0265
Epoch [50/50] - Loss: 1.0120
sum preds 5068
sum labels 5513
 - Test Metrics: Accuracy=0.8809, F1=0.8046, Recall=0.7722, Precision=0.8400
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8996
Epoch [2/50] - Loss: 3.3339
Epoch [3/50] - Loss: 2.9130
Epoch [4/50] - Loss: 2.6443
Epoch [5/50] - Loss: 2.4547
Epoch [6/50] - Loss: 2.2644
Epoch [7/50] - Loss: 2.0724
Epoch [8/50] - Loss: 1.9369
Epoch [9/50] - Loss: 1.8162
Epoch [10/50] - Loss: 1.7151
Epoch [11/50] - Loss: 1.6312
Epoch [12/50] - Loss: 1.5675
Epoch [13/50] - Loss: 1.5230
Epoch [14/50] - Loss: 1.4734
Epoch [15/50] - Loss: 1.4490
Epoch [16/50] - Loss: 1.4207
Epoch [17/50] - Loss: 1.3969
Epoch [18/50] - Loss: 1.3760
Epoch [19/50] - Loss: 1.3520
Epoch [20/50] - Loss: 1.3317
Epoch [21/50] - Loss: 1.3222
Epoch [22/50] - Loss: 1.3165
Epoch [23/50] - Loss: 1.2935
Epoch [24/50] - Loss: 1.2739
Epoch [25/50] - Loss: 1.2682
Epoch [26/50] - Loss: 1.2573
Epoch [27/50] - Loss: 1.2450
Epoch [28/50] - Loss: 1.2347
Epoch [29/50] - Loss: 1.2152
Epoch [30/50] - Loss: 1.2136
Epoch [31/50] - Loss: 1.2072
Epoch [32/50] - Loss: 1.1978
Epoch [33/50] - Loss: 1.1847
Epoch [34/50] - Loss: 1.1631
Epoch [35/50] - Loss: 1.1687
Epoch [36/50] - Loss: 1.1555
Epoch [37/50] - Loss: 1.1502
Epoch [38/50] - Loss: 1.1392
Epoch [39/50] - Loss: 1.1346
Epoch [40/50] - Loss: 1.1182
Epoch [41/50] - Loss: 1.1138
Epoch [42/50] - Loss: 1.1023
Epoch [43/50] - Loss: 1.0948
Epoch [44/50] - Loss: 1.0890
Epoch [45/50] - Loss: 1.0799
Epoch [46/50] - Loss: 1.0659
Epoch [47/50] - Loss: 1.0690
Epoch [48/50] - Loss: 1.0595
Epoch [49/50] - Loss: 1.0452
Epoch [50/50] - Loss: 1.0351
sum preds 5052
sum labels 5513
 - Test Metrics: Accuracy=0.8801, F1=0.8030, Recall=0.7695, Precision=0.8397
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_spy_spy_1804174317.csv.
Average F1 over valid seeds: 0.7999 ± 0.0056
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and spy, GATConv,0.3: 0.7999 ± 0.0056
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9856
Epoch [2/50] - Loss: 3.5498
Epoch [3/50] - Loss: 3.1860
Epoch [4/50] - Loss: 2.9376
Epoch [5/50] - Loss: 2.7841
Epoch [6/50] - Loss: 2.6662
Epoch [7/50] - Loss: 2.5152
Epoch [8/50] - Loss: 2.3832
Epoch [9/50] - Loss: 2.2605
Epoch [10/50] - Loss: 2.1355
Epoch [11/50] - Loss: 2.0108
Epoch [12/50] - Loss: 1.9104
Epoch [13/50] - Loss: 1.8090
Epoch [14/50] - Loss: 1.7394
Epoch [15/50] - Loss: 1.6660
Epoch [16/50] - Loss: 1.6129
Epoch [17/50] - Loss: 1.5577
Epoch [18/50] - Loss: 1.5221
Epoch [19/50] - Loss: 1.4826
Epoch [20/50] - Loss: 1.4510
Epoch [21/50] - Loss: 1.4299
Epoch [22/50] - Loss: 1.4038
Epoch [23/50] - Loss: 1.3853
Epoch [24/50] - Loss: 1.3673
Epoch [25/50] - Loss: 1.3548
Epoch [26/50] - Loss: 1.3367
Epoch [27/50] - Loss: 1.3263
Epoch [28/50] - Loss: 1.3218
Epoch [29/50] - Loss: 1.3045
Epoch [30/50] - Loss: 1.2949
Epoch [31/50] - Loss: 1.2875
Epoch [32/50] - Loss: 1.2669
Epoch [33/50] - Loss: 1.2645
Epoch [34/50] - Loss: 1.2530
Epoch [35/50] - Loss: 1.2497
Epoch [36/50] - Loss: 1.2487
Epoch [37/50] - Loss: 1.2385
Epoch [38/50] - Loss: 1.2307
Epoch [39/50] - Loss: 1.2251
Epoch [40/50] - Loss: 1.2207
Epoch [41/50] - Loss: 1.2110
Epoch [42/50] - Loss: 1.2096
Epoch [43/50] - Loss: 1.2085
Epoch [44/50] - Loss: 1.2022
Epoch [45/50] - Loss: 1.2005
Epoch [46/50] - Loss: 1.1972
Epoch [47/50] - Loss: 1.1862
Epoch [48/50] - Loss: 1.1869
Epoch [49/50] - Loss: 1.1904
Epoch [50/50] - Loss: 1.1831
sum preds 5051
sum labels 5513
 - Test Metrics: Accuracy=0.8770, F1=0.7980, Recall=0.7646, Precision=0.8345
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8130
Epoch [2/50] - Loss: 3.1728
Epoch [3/50] - Loss: 2.8599
Epoch [4/50] - Loss: 2.7354
Epoch [5/50] - Loss: 2.6196
Epoch [6/50] - Loss: 2.4752
Epoch [7/50] - Loss: 2.3536
Epoch [8/50] - Loss: 2.2603
Epoch [9/50] - Loss: 2.1603
Epoch [10/50] - Loss: 2.0500
Epoch [11/50] - Loss: 1.9429
Epoch [12/50] - Loss: 1.8404
Epoch [13/50] - Loss: 1.7464
Epoch [14/50] - Loss: 1.6615
Epoch [15/50] - Loss: 1.6043
Epoch [16/50] - Loss: 1.5385
Epoch [17/50] - Loss: 1.4900
Epoch [18/50] - Loss: 1.4537
Epoch [19/50] - Loss: 1.4242
Epoch [20/50] - Loss: 1.4059
Epoch [21/50] - Loss: 1.3757
Epoch [22/50] - Loss: 1.3567
Epoch [23/50] - Loss: 1.3346
Epoch [24/50] - Loss: 1.3336
Epoch [25/50] - Loss: 1.3146
Epoch [26/50] - Loss: 1.3135
Epoch [27/50] - Loss: 1.2818
Epoch [28/50] - Loss: 1.2854
Epoch [29/50] - Loss: 1.2727
Epoch [30/50] - Loss: 1.2707
Epoch [31/50] - Loss: 1.2659
Epoch [32/50] - Loss: 1.2513
Epoch [33/50] - Loss: 1.2404
Epoch [34/50] - Loss: 1.2355
Epoch [35/50] - Loss: 1.2247
Epoch [36/50] - Loss: 1.2282
Epoch [37/50] - Loss: 1.2267
Epoch [38/50] - Loss: 1.2145
Epoch [39/50] - Loss: 1.2132
Epoch [40/50] - Loss: 1.2061
Epoch [41/50] - Loss: 1.1958
Epoch [42/50] - Loss: 1.1998
Epoch [43/50] - Loss: 1.1932
Epoch [44/50] - Loss: 1.1899
Epoch [45/50] - Loss: 1.1863
Epoch [46/50] - Loss: 1.1782
Epoch [47/50] - Loss: 1.1797
Epoch [48/50] - Loss: 1.1826
Epoch [49/50] - Loss: 1.1707
Epoch [50/50] - Loss: 1.1667
sum preds 5105
sum labels 5513
 - Test Metrics: Accuracy=0.8842, F1=0.8107, Recall=0.7807, Precision=0.8431
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8935
Epoch [2/50] - Loss: 3.3394
Epoch [3/50] - Loss: 2.9577
Epoch [4/50] - Loss: 2.7535
Epoch [5/50] - Loss: 2.6290
Epoch [6/50] - Loss: 2.4686
Epoch [7/50] - Loss: 2.2914
Epoch [8/50] - Loss: 2.1531
Epoch [9/50] - Loss: 2.0202
Epoch [10/50] - Loss: 1.8994
Epoch [11/50] - Loss: 1.8001
Epoch [12/50] - Loss: 1.7000
Epoch [13/50] - Loss: 1.6234
Epoch [14/50] - Loss: 1.5582
Epoch [15/50] - Loss: 1.5172
Epoch [16/50] - Loss: 1.4670
Epoch [17/50] - Loss: 1.4303
Epoch [18/50] - Loss: 1.4067
Epoch [19/50] - Loss: 1.3815
Epoch [20/50] - Loss: 1.3568
Epoch [21/50] - Loss: 1.3490
Epoch [22/50] - Loss: 1.3307
Epoch [23/50] - Loss: 1.3213
Epoch [24/50] - Loss: 1.3050
Epoch [25/50] - Loss: 1.2992
Epoch [26/50] - Loss: 1.2861
Epoch [27/50] - Loss: 1.2689
Epoch [28/50] - Loss: 1.2623
Epoch [29/50] - Loss: 1.2536
Epoch [30/50] - Loss: 1.2555
Epoch [31/50] - Loss: 1.2372
Epoch [32/50] - Loss: 1.2380
Epoch [33/50] - Loss: 1.2279
Epoch [34/50] - Loss: 1.2298
Epoch [35/50] - Loss: 1.2311
Epoch [36/50] - Loss: 1.2131
Epoch [37/50] - Loss: 1.2138
Epoch [38/50] - Loss: 1.1969
Epoch [39/50] - Loss: 1.2026
Epoch [40/50] - Loss: 1.2017
Epoch [41/50] - Loss: 1.1881
Epoch [42/50] - Loss: 1.1948
Epoch [43/50] - Loss: 1.1872
Epoch [44/50] - Loss: 1.1771
Epoch [45/50] - Loss: 1.1731
Epoch [46/50] - Loss: 1.1816
Epoch [47/50] - Loss: 1.1834
Epoch [48/50] - Loss: 1.1690
Epoch [49/50] - Loss: 1.1701
Epoch [50/50] - Loss: 1.1665
sum preds 5023
sum labels 5513
 - Test Metrics: Accuracy=0.8820, F1=0.8056, Recall=0.7698, Precision=0.8449
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_spy_spy_1804175518.csv.
Average F1 over valid seeds: 0.8048 ± 0.0052
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and spy, GCNConv,0.3: 0.8048 ± 0.0052
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.6887
Epoch [2/50] - Loss: 3.3351
Epoch [3/50] - Loss: 2.9134
Epoch [4/50] - Loss: 2.4962
Epoch [5/50] - Loss: 2.1763
Epoch [6/50] - Loss: 1.9810
Epoch [7/50] - Loss: 1.8834
Epoch [8/50] - Loss: 1.7972
Epoch [9/50] - Loss: 1.7086
Epoch [10/50] - Loss: 1.6162
Epoch [11/50] - Loss: 1.5244
Epoch [12/50] - Loss: 1.4446
Epoch [13/50] - Loss: 1.3773
Epoch [14/50] - Loss: 1.2998
Epoch [15/50] - Loss: 1.2218
Epoch [16/50] - Loss: 1.1750
Epoch [17/50] - Loss: 1.1190
Epoch [18/50] - Loss: 1.0604
Epoch [19/50] - Loss: 1.0102
Epoch [20/50] - Loss: 0.9676
Epoch [21/50] - Loss: 0.9294
Epoch [22/50] - Loss: 0.8962
Epoch [23/50] - Loss: 0.8634
Epoch [24/50] - Loss: 0.8402
Epoch [25/50] - Loss: 0.8094
Epoch [26/50] - Loss: 0.7913
Epoch [27/50] - Loss: 0.7677
Epoch [28/50] - Loss: 0.7468
Epoch [29/50] - Loss: 0.7345
Epoch [30/50] - Loss: 0.7146
Epoch [31/50] - Loss: 0.6973
Epoch [32/50] - Loss: 0.6887
Epoch [33/50] - Loss: 0.6741
Epoch [34/50] - Loss: 0.6615
Epoch [35/50] - Loss: 0.6543
Epoch [36/50] - Loss: 0.6426
Epoch [37/50] - Loss: 0.6362
Epoch [38/50] - Loss: 0.6213
Epoch [39/50] - Loss: 0.6102
Epoch [40/50] - Loss: 0.6038
Epoch [41/50] - Loss: 0.6060
Epoch [42/50] - Loss: 0.5916
Epoch [43/50] - Loss: 0.5831
Epoch [44/50] - Loss: 0.5754
Epoch [45/50] - Loss: 0.5689
Epoch [46/50] - Loss: 0.5636
Epoch [47/50] - Loss: 0.5539
Epoch [48/50] - Loss: 0.5414
Epoch [49/50] - Loss: 0.5494
Epoch [50/50] - Loss: 0.5361
sum preds 6208
sum labels 6300
 - Test Metrics: Accuracy=0.8367, F1=0.7632, Recall=0.7576, Precision=0.7688
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.4882
Epoch [2/50] - Loss: 3.2288
Epoch [3/50] - Loss: 2.9336
Epoch [4/50] - Loss: 2.6278
Epoch [5/50] - Loss: 2.3430
Epoch [6/50] - Loss: 2.1201
Epoch [7/50] - Loss: 1.9950
Epoch [8/50] - Loss: 1.9074
Epoch [9/50] - Loss: 1.8289
Epoch [10/50] - Loss: 1.7421
Epoch [11/50] - Loss: 1.6304
Epoch [12/50] - Loss: 1.5327
Epoch [13/50] - Loss: 1.4327
Epoch [14/50] - Loss: 1.3317
Epoch [15/50] - Loss: 1.2475
Epoch [16/50] - Loss: 1.1701
Epoch [17/50] - Loss: 1.1002
Epoch [18/50] - Loss: 1.0339
Epoch [19/50] - Loss: 0.9865
Epoch [20/50] - Loss: 0.9460
Epoch [21/50] - Loss: 0.9052
Epoch [22/50] - Loss: 0.8725
Epoch [23/50] - Loss: 0.8432
Epoch [24/50] - Loss: 0.8123
Epoch [25/50] - Loss: 0.7956
Epoch [26/50] - Loss: 0.7705
Epoch [27/50] - Loss: 0.7523
Epoch [28/50] - Loss: 0.7380
Epoch [29/50] - Loss: 0.7226
Epoch [30/50] - Loss: 0.7117
Epoch [31/50] - Loss: 0.6879
Epoch [32/50] - Loss: 0.6831
Epoch [33/50] - Loss: 0.6715
Epoch [34/50] - Loss: 0.6600
Epoch [35/50] - Loss: 0.6468
Epoch [36/50] - Loss: 0.6441
Epoch [37/50] - Loss: 0.6267
Epoch [38/50] - Loss: 0.6252
Epoch [39/50] - Loss: 0.6158
Epoch [40/50] - Loss: 0.6110
Epoch [41/50] - Loss: 0.6057
Epoch [42/50] - Loss: 0.5900
Epoch [43/50] - Loss: 0.5878
Epoch [44/50] - Loss: 0.5815
Epoch [45/50] - Loss: 0.5778
Epoch [46/50] - Loss: 0.5688
Epoch [47/50] - Loss: 0.5635
Epoch [48/50] - Loss: 0.5611
Epoch [49/50] - Loss: 0.5539
Epoch [50/50] - Loss: 0.5502
sum preds 6450
sum labels 6300
 - Test Metrics: Accuracy=0.8263, F1=0.7528, Recall=0.7617, Precision=0.7440
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.6089
Epoch [2/50] - Loss: 3.2083
Epoch [3/50] - Loss: 2.7715
Epoch [4/50] - Loss: 2.3639
Epoch [5/50] - Loss: 2.0635
Epoch [6/50] - Loss: 1.8812
Epoch [7/50] - Loss: 1.7663
Epoch [8/50] - Loss: 1.6692
Epoch [9/50] - Loss: 1.5610
Epoch [10/50] - Loss: 1.4428
Epoch [11/50] - Loss: 1.3570
Epoch [12/50] - Loss: 1.2661
Epoch [13/50] - Loss: 1.1918
Epoch [14/50] - Loss: 1.1274
Epoch [15/50] - Loss: 1.0674
Epoch [16/50] - Loss: 1.0139
Epoch [17/50] - Loss: 0.9701
Epoch [18/50] - Loss: 0.9278
Epoch [19/50] - Loss: 0.8965
Epoch [20/50] - Loss: 0.8700
Epoch [21/50] - Loss: 0.8434
Epoch [22/50] - Loss: 0.8167
Epoch [23/50] - Loss: 0.7958
Epoch [24/50] - Loss: 0.7769
Epoch [25/50] - Loss: 0.7555
Epoch [26/50] - Loss: 0.7423
Epoch [27/50] - Loss: 0.7272
Epoch [28/50] - Loss: 0.7153
Epoch [29/50] - Loss: 0.7041
Epoch [30/50] - Loss: 0.6913
Epoch [31/50] - Loss: 0.6763
Epoch [32/50] - Loss: 0.6642
Epoch [33/50] - Loss: 0.6619
Epoch [34/50] - Loss: 0.6504
Epoch [35/50] - Loss: 0.6374
Epoch [36/50] - Loss: 0.6323
Epoch [37/50] - Loss: 0.6244
Epoch [38/50] - Loss: 0.6195
Epoch [39/50] - Loss: 0.6141
Epoch [40/50] - Loss: 0.6070
Epoch [41/50] - Loss: 0.5967
Epoch [42/50] - Loss: 0.5890
Epoch [43/50] - Loss: 0.5850
Epoch [44/50] - Loss: 0.5775
Epoch [45/50] - Loss: 0.5754
Epoch [46/50] - Loss: 0.5646
Epoch [47/50] - Loss: 0.5649
Epoch [48/50] - Loss: 0.5586
Epoch [49/50] - Loss: 0.5537
Epoch [50/50] - Loss: 0.5505
sum preds 5836
sum labels 6300
 - Test Metrics: Accuracy=0.8335, F1=0.7512, Recall=0.7235, Precision=0.7810
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_spy_spy_1804180718.csv.
Average F1 over valid seeds: 0.7557 ± 0.0053
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and spy, MLP,0.2: 0.7557 ± 0.0053
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.1945
Epoch [2/50] - Loss: 2.6161
Epoch [3/50] - Loss: 2.2155
Epoch [4/50] - Loss: 2.0235
Epoch [5/50] - Loss: 1.9597
Epoch [6/50] - Loss: 1.9166
Epoch [7/50] - Loss: 1.8196
Epoch [8/50] - Loss: 1.7317
Epoch [9/50] - Loss: 1.6722
Epoch [10/50] - Loss: 1.6074
Epoch [11/50] - Loss: 1.5530
Epoch [12/50] - Loss: 1.4959
Epoch [13/50] - Loss: 1.4223
Epoch [14/50] - Loss: 1.3477
Epoch [15/50] - Loss: 1.2844
Epoch [16/50] - Loss: 1.2299
Epoch [17/50] - Loss: 1.1577
Epoch [18/50] - Loss: 1.1286
Epoch [19/50] - Loss: 1.0892
Epoch [20/50] - Loss: 1.0672
Epoch [21/50] - Loss: 1.0483
Epoch [22/50] - Loss: 1.0197
Epoch [23/50] - Loss: 1.0099
Epoch [24/50] - Loss: 0.9970
Epoch [25/50] - Loss: 0.9791
Epoch [26/50] - Loss: 0.9777
Epoch [27/50] - Loss: 0.9568
Epoch [28/50] - Loss: 0.9462
Epoch [29/50] - Loss: 0.9299
Epoch [30/50] - Loss: 0.9207
Epoch [31/50] - Loss: 0.9059
Epoch [32/50] - Loss: 0.9007
Epoch [33/50] - Loss: 0.8981
Epoch [34/50] - Loss: 0.8907
Epoch [35/50] - Loss: 0.8664
Epoch [36/50] - Loss: 0.8649
Epoch [37/50] - Loss: 0.8680
Epoch [38/50] - Loss: 0.8572
Epoch [39/50] - Loss: 0.8466
Epoch [40/50] - Loss: 0.8312
Epoch [41/50] - Loss: 0.8336
Epoch [42/50] - Loss: 0.8176
Epoch [43/50] - Loss: 0.8128
Epoch [44/50] - Loss: 0.8178
Epoch [45/50] - Loss: 0.8081
Epoch [46/50] - Loss: 0.7974
Epoch [47/50] - Loss: 0.7966
Epoch [48/50] - Loss: 0.7909
Epoch [49/50] - Loss: 0.7829
Epoch [50/50] - Loss: 0.7791
sum preds 5452
sum labels 6300
 - Test Metrics: Accuracy=0.8675, F1=0.7954, Recall=0.7419, Precision=0.8573
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.2785
Epoch [2/50] - Loss: 2.8068
Epoch [3/50] - Loss: 2.4115
Epoch [4/50] - Loss: 2.1362
Epoch [5/50] - Loss: 1.9565
Epoch [6/50] - Loss: 1.8332
Epoch [7/50] - Loss: 1.7200
Epoch [8/50] - Loss: 1.6080
Epoch [9/50] - Loss: 1.4996
Epoch [10/50] - Loss: 1.4163
Epoch [11/50] - Loss: 1.3544
Epoch [12/50] - Loss: 1.2943
Epoch [13/50] - Loss: 1.2492
Epoch [14/50] - Loss: 1.2096
Epoch [15/50] - Loss: 1.1700
Epoch [16/50] - Loss: 1.1467
Epoch [17/50] - Loss: 1.1219
Epoch [18/50] - Loss: 1.1007
Epoch [19/50] - Loss: 1.0777
Epoch [20/50] - Loss: 1.0611
Epoch [21/50] - Loss: 1.0452
Epoch [22/50] - Loss: 1.0350
Epoch [23/50] - Loss: 1.0252
Epoch [24/50] - Loss: 1.0122
Epoch [25/50] - Loss: 1.0038
Epoch [26/50] - Loss: 0.9952
Epoch [27/50] - Loss: 0.9766
Epoch [28/50] - Loss: 0.9729
Epoch [29/50] - Loss: 0.9637
Epoch [30/50] - Loss: 0.9550
Epoch [31/50] - Loss: 0.9570
Epoch [32/50] - Loss: 0.9449
Epoch [33/50] - Loss: 0.9325
Epoch [34/50] - Loss: 0.9252
Epoch [35/50] - Loss: 0.9162
Epoch [36/50] - Loss: 0.9117
Epoch [37/50] - Loss: 0.8931
Epoch [38/50] - Loss: 0.8940
Epoch [39/50] - Loss: 0.8810
Epoch [40/50] - Loss: 0.8795
Epoch [41/50] - Loss: 0.8645
Epoch [42/50] - Loss: 0.8562
Epoch [43/50] - Loss: 0.8451
Epoch [44/50] - Loss: 0.8359
Epoch [45/50] - Loss: 0.8333
Epoch [46/50] - Loss: 0.8298
Epoch [47/50] - Loss: 0.8201
Epoch [48/50] - Loss: 0.8186
Epoch [49/50] - Loss: 0.8089
Epoch [50/50] - Loss: 0.7984
sum preds 5328
sum labels 6300
 - Test Metrics: Accuracy=0.8642, F1=0.7881, Recall=0.7273, Precision=0.8600
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.2815
Epoch [2/50] - Loss: 2.8296
Epoch [3/50] - Loss: 2.4118
Epoch [4/50] - Loss: 2.1014
Epoch [5/50] - Loss: 1.9313
Epoch [6/50] - Loss: 1.8478
Epoch [7/50] - Loss: 1.7579
Epoch [8/50] - Loss: 1.6827
Epoch [9/50] - Loss: 1.5784
Epoch [10/50] - Loss: 1.4970
Epoch [11/50] - Loss: 1.4205
Epoch [12/50] - Loss: 1.3497
Epoch [13/50] - Loss: 1.3004
Epoch [14/50] - Loss: 1.2527
Epoch [15/50] - Loss: 1.2082
Epoch [16/50] - Loss: 1.1782
Epoch [17/50] - Loss: 1.1467
Epoch [18/50] - Loss: 1.1140
Epoch [19/50] - Loss: 1.0892
Epoch [20/50] - Loss: 1.0704
Epoch [21/50] - Loss: 1.0589
Epoch [22/50] - Loss: 1.0512
Epoch [23/50] - Loss: 1.0339
Epoch [24/50] - Loss: 1.0218
Epoch [25/50] - Loss: 1.0153
Epoch [26/50] - Loss: 0.9982
Epoch [27/50] - Loss: 0.9891
Epoch [28/50] - Loss: 0.9786
Epoch [29/50] - Loss: 0.9795
Epoch [30/50] - Loss: 0.9666
Epoch [31/50] - Loss: 0.9624
Epoch [32/50] - Loss: 0.9496
Epoch [33/50] - Loss: 0.9418
Epoch [34/50] - Loss: 0.9307
Epoch [35/50] - Loss: 0.9172
Epoch [36/50] - Loss: 0.9157
Epoch [37/50] - Loss: 0.9068
Epoch [38/50] - Loss: 0.8958
Epoch [39/50] - Loss: 0.8949
Epoch [40/50] - Loss: 0.8737
Epoch [41/50] - Loss: 0.8670
Epoch [42/50] - Loss: 0.8657
Epoch [43/50] - Loss: 0.8554
Epoch [44/50] - Loss: 0.8496
Epoch [45/50] - Loss: 0.8433
Epoch [46/50] - Loss: 0.8298
Epoch [47/50] - Loss: 0.8276
Epoch [48/50] - Loss: 0.8239
Epoch [49/50] - Loss: 0.8114
Epoch [50/50] - Loss: 0.8019
sum preds 5130
sum labels 6300
 - Test Metrics: Accuracy=0.8646, F1=0.7851, Recall=0.7122, Precision=0.8747
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_spy_spy_1804181646.csv.
Average F1 over valid seeds: 0.7896 ± 0.0043
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and spy, GATConv,0.2: 0.7896 ± 0.0043
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.3375
Epoch [2/50] - Loss: 2.9822
Epoch [3/50] - Loss: 2.6563
Epoch [4/50] - Loss: 2.3914
Epoch [5/50] - Loss: 2.2023
Epoch [6/50] - Loss: 2.0918
Epoch [7/50] - Loss: 2.0223
Epoch [8/50] - Loss: 1.9643
Epoch [9/50] - Loss: 1.8886
Epoch [10/50] - Loss: 1.8001
Epoch [11/50] - Loss: 1.7217
Epoch [12/50] - Loss: 1.6553
Epoch [13/50] - Loss: 1.5781
Epoch [14/50] - Loss: 1.4965
Epoch [15/50] - Loss: 1.4438
Epoch [16/50] - Loss: 1.3801
Epoch [17/50] - Loss: 1.3191
Epoch [18/50] - Loss: 1.2796
Epoch [19/50] - Loss: 1.2408
Epoch [20/50] - Loss: 1.2033
Epoch [21/50] - Loss: 1.1765
Epoch [22/50] - Loss: 1.1405
Epoch [23/50] - Loss: 1.1173
Epoch [24/50] - Loss: 1.0912
Epoch [25/50] - Loss: 1.0725
Epoch [26/50] - Loss: 1.0539
Epoch [27/50] - Loss: 1.0385
Epoch [28/50] - Loss: 1.0213
Epoch [29/50] - Loss: 1.0140
Epoch [30/50] - Loss: 0.9970
Epoch [31/50] - Loss: 0.9905
Epoch [32/50] - Loss: 0.9849
Epoch [33/50] - Loss: 0.9689
Epoch [34/50] - Loss: 0.9525
Epoch [35/50] - Loss: 0.9473
Epoch [36/50] - Loss: 0.9364
Epoch [37/50] - Loss: 0.9308
Epoch [38/50] - Loss: 0.9220
Epoch [39/50] - Loss: 0.9205
Epoch [40/50] - Loss: 0.9129
Epoch [41/50] - Loss: 0.9068
Epoch [42/50] - Loss: 0.9071
Epoch [43/50] - Loss: 0.8922
Epoch [44/50] - Loss: 0.8895
Epoch [45/50] - Loss: 0.8917
Epoch [46/50] - Loss: 0.8880
Epoch [47/50] - Loss: 0.8777
Epoch [48/50] - Loss: 0.8748
Epoch [49/50] - Loss: 0.8690
Epoch [50/50] - Loss: 0.8653
sum preds 5504
sum labels 6300
 - Test Metrics: Accuracy=0.8699, F1=0.8001, Recall=0.7495, Precision=0.8579
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.3334
Epoch [2/50] - Loss: 2.9906
Epoch [3/50] - Loss: 2.6760
Epoch [4/50] - Loss: 2.4265
Epoch [5/50] - Loss: 2.2174
Epoch [6/50] - Loss: 2.0954
Epoch [7/50] - Loss: 1.9989
Epoch [8/50] - Loss: 1.9238
Epoch [9/50] - Loss: 1.8401
Epoch [10/50] - Loss: 1.7404
Epoch [11/50] - Loss: 1.6547
Epoch [12/50] - Loss: 1.5686
Epoch [13/50] - Loss: 1.4851
Epoch [14/50] - Loss: 1.4228
Epoch [15/50] - Loss: 1.3629
Epoch [16/50] - Loss: 1.3033
Epoch [17/50] - Loss: 1.2671
Epoch [18/50] - Loss: 1.2251
Epoch [19/50] - Loss: 1.1975
Epoch [20/50] - Loss: 1.1663
Epoch [21/50] - Loss: 1.1430
Epoch [22/50] - Loss: 1.1181
Epoch [23/50] - Loss: 1.1008
Epoch [24/50] - Loss: 1.0855
Epoch [25/50] - Loss: 1.0735
Epoch [26/50] - Loss: 1.0573
Epoch [27/50] - Loss: 1.0446
Epoch [28/50] - Loss: 1.0384
Epoch [29/50] - Loss: 1.0259
Epoch [30/50] - Loss: 1.0230
Epoch [31/50] - Loss: 1.0082
Epoch [32/50] - Loss: 1.0056
Epoch [33/50] - Loss: 0.9930
Epoch [34/50] - Loss: 0.9957
Epoch [35/50] - Loss: 0.9846
Epoch [36/50] - Loss: 0.9842
Epoch [37/50] - Loss: 0.9732
Epoch [38/50] - Loss: 0.9664
Epoch [39/50] - Loss: 0.9557
Epoch [40/50] - Loss: 0.9608
Epoch [41/50] - Loss: 0.9533
Epoch [42/50] - Loss: 0.9458
Epoch [43/50] - Loss: 0.9493
Epoch [44/50] - Loss: 0.9381
Epoch [45/50] - Loss: 0.9293
Epoch [46/50] - Loss: 0.9269
Epoch [47/50] - Loss: 0.9290
Epoch [48/50] - Loss: 0.9222
Epoch [49/50] - Loss: 0.9201
Epoch [50/50] - Loss: 0.9178
sum preds 5409
sum labels 6300
 - Test Metrics: Accuracy=0.8669, F1=0.7937, Recall=0.7376, Precision=0.8591
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.3759
Epoch [2/50] - Loss: 3.1078
Epoch [3/50] - Loss: 2.8403
Epoch [4/50] - Loss: 2.5872
Epoch [5/50] - Loss: 2.3652
Epoch [6/50] - Loss: 2.1868
Epoch [7/50] - Loss: 2.0610
Epoch [8/50] - Loss: 1.9772
Epoch [9/50] - Loss: 1.9123
Epoch [10/50] - Loss: 1.8399
Epoch [11/50] - Loss: 1.7695
Epoch [12/50] - Loss: 1.6775
Epoch [13/50] - Loss: 1.5996
Epoch [14/50] - Loss: 1.5202
Epoch [15/50] - Loss: 1.4458
Epoch [16/50] - Loss: 1.3919
Epoch [17/50] - Loss: 1.3289
Epoch [18/50] - Loss: 1.2854
Epoch [19/50] - Loss: 1.2381
Epoch [20/50] - Loss: 1.1930
Epoch [21/50] - Loss: 1.1591
Epoch [22/50] - Loss: 1.1285
Epoch [23/50] - Loss: 1.1080
Epoch [24/50] - Loss: 1.0764
Epoch [25/50] - Loss: 1.0637
Epoch [26/50] - Loss: 1.0394
Epoch [27/50] - Loss: 1.0297
Epoch [28/50] - Loss: 1.0109
Epoch [29/50] - Loss: 0.9995
Epoch [30/50] - Loss: 0.9896
Epoch [31/50] - Loss: 0.9771
Epoch [32/50] - Loss: 0.9670
Epoch [33/50] - Loss: 0.9640
Epoch [34/50] - Loss: 0.9521
Epoch [35/50] - Loss: 0.9464
Epoch [36/50] - Loss: 0.9340
Epoch [37/50] - Loss: 0.9327
Epoch [38/50] - Loss: 0.9269
Epoch [39/50] - Loss: 0.9167
Epoch [40/50] - Loss: 0.9187
Epoch [41/50] - Loss: 0.9050
Epoch [42/50] - Loss: 0.9050
Epoch [43/50] - Loss: 0.8961
Epoch [44/50] - Loss: 0.8926
Epoch [45/50] - Loss: 0.8854
Epoch [46/50] - Loss: 0.8828
Epoch [47/50] - Loss: 0.8722
Epoch [48/50] - Loss: 0.8761
Epoch [49/50] - Loss: 0.8691
Epoch [50/50] - Loss: 0.8685
sum preds 5152
sum labels 6300
 - Test Metrics: Accuracy=0.8675, F1=0.7901, Recall=0.7181, Precision=0.8781
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_spy_spy_1804182609.csv.
Average F1 over valid seeds: 0.7946 ± 0.0041
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and spy, GCNConv,0.2: 0.7946 ± 0.0041
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5087
Epoch [2/50] - Loss: 0.5076
Epoch [3/50] - Loss: 0.5064
Epoch [4/50] - Loss: 0.5051
Epoch [5/50] - Loss: 0.5037
Epoch [6/50] - Loss: 0.5022
Epoch [7/50] - Loss: 0.5005
Epoch [8/50] - Loss: 0.4986
Epoch [9/50] - Loss: 0.4966
Epoch [10/50] - Loss: 0.4945
Epoch [11/50] - Loss: 0.4923
Epoch [12/50] - Loss: 0.4900
Epoch [13/50] - Loss: 0.4874
Epoch [14/50] - Loss: 0.4848
Epoch [15/50] - Loss: 0.4819
Epoch [16/50] - Loss: 0.4790
Epoch [17/50] - Loss: 0.4759
Epoch [18/50] - Loss: 0.4726
Epoch [19/50] - Loss: 0.4692
Epoch [20/50] - Loss: 0.4656
Epoch [21/50] - Loss: 0.4618
Epoch [22/50] - Loss: 0.4579
Epoch [23/50] - Loss: 0.4538
Epoch [24/50] - Loss: 0.4496
Epoch [25/50] - Loss: 0.4452
Epoch [26/50] - Loss: 0.4407
Epoch [27/50] - Loss: 0.4360
Epoch [28/50] - Loss: 0.4312
Epoch [29/50] - Loss: 0.4262
Epoch [30/50] - Loss: 0.4211
Epoch [31/50] - Loss: 0.4159
Epoch [32/50] - Loss: 0.4106
Epoch [33/50] - Loss: 0.4052
Epoch [34/50] - Loss: 0.3997
Epoch [35/50] - Loss: 0.3941
Epoch [36/50] - Loss: 0.3884
Epoch [37/50] - Loss: 0.3826
Epoch [38/50] - Loss: 0.3769
Epoch [39/50] - Loss: 0.3710
Epoch [40/50] - Loss: 0.3652
Epoch [41/50] - Loss: 0.3593
Epoch [42/50] - Loss: 0.3533
Epoch [43/50] - Loss: 0.3474
Epoch [44/50] - Loss: 0.3415
Epoch [45/50] - Loss: 0.3356
Epoch [46/50] - Loss: 0.3297
Epoch [47/50] - Loss: 0.3238
Epoch [48/50] - Loss: 0.3180
Epoch [49/50] - Loss: 0.3122
Epoch [50/50] - Loss: 0.3064
sum preds 3115
sum labels 4725
 - Test Metrics: Accuracy=0.8229, F1=0.6258, Recall=0.5192, Precision=0.7875
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4937
Epoch [2/50] - Loss: 0.4924
Epoch [3/50] - Loss: 0.4912
Epoch [4/50] - Loss: 0.4901
Epoch [5/50] - Loss: 0.4890
Epoch [6/50] - Loss: 0.4876
Epoch [7/50] - Loss: 0.4860
Epoch [8/50] - Loss: 0.4843
Epoch [9/50] - Loss: 0.4823
Epoch [10/50] - Loss: 0.4802
Epoch [11/50] - Loss: 0.4780
Epoch [12/50] - Loss: 0.4756
Epoch [13/50] - Loss: 0.4731
Epoch [14/50] - Loss: 0.4704
Epoch [15/50] - Loss: 0.4676
Epoch [16/50] - Loss: 0.4646
Epoch [17/50] - Loss: 0.4614
Epoch [18/50] - Loss: 0.4581
Epoch [19/50] - Loss: 0.4547
Epoch [20/50] - Loss: 0.4510
Epoch [21/50] - Loss: 0.4473
Epoch [22/50] - Loss: 0.4434
Epoch [23/50] - Loss: 0.4393
Epoch [24/50] - Loss: 0.4351
Epoch [25/50] - Loss: 0.4308
Epoch [26/50] - Loss: 0.4264
Epoch [27/50] - Loss: 0.4218
Epoch [28/50] - Loss: 0.4172
Epoch [29/50] - Loss: 0.4124
Epoch [30/50] - Loss: 0.4076
Epoch [31/50] - Loss: 0.4027
Epoch [32/50] - Loss: 0.3977
Epoch [33/50] - Loss: 0.3927
Epoch [34/50] - Loss: 0.3876
Epoch [35/50] - Loss: 0.3825
Epoch [36/50] - Loss: 0.3774
Epoch [37/50] - Loss: 0.3722
Epoch [38/50] - Loss: 0.3670
Epoch [39/50] - Loss: 0.3618
Epoch [40/50] - Loss: 0.3566
Epoch [41/50] - Loss: 0.3513
Epoch [42/50] - Loss: 0.3461
Epoch [43/50] - Loss: 0.3408
Epoch [44/50] - Loss: 0.3356
Epoch [45/50] - Loss: 0.3303
Epoch [46/50] - Loss: 0.3250
Epoch [47/50] - Loss: 0.3197
Epoch [48/50] - Loss: 0.3144
Epoch [49/50] - Loss: 0.3090
Epoch [50/50] - Loss: 0.3037
sum preds 2383
sum labels 4725
 - Test Metrics: Accuracy=0.8035, F1=0.5419, Recall=0.4076, Precision=0.8082
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5114
Epoch [2/50] - Loss: 0.5095
Epoch [3/50] - Loss: 0.5076
Epoch [4/50] - Loss: 0.5056
Epoch [5/50] - Loss: 0.5034
Epoch [6/50] - Loss: 0.5010
Epoch [7/50] - Loss: 0.4983
Epoch [8/50] - Loss: 0.4955
Epoch [9/50] - Loss: 0.4926
Epoch [10/50] - Loss: 0.4894
Epoch [11/50] - Loss: 0.4861
Epoch [12/50] - Loss: 0.4827
Epoch [13/50] - Loss: 0.4790
Epoch [14/50] - Loss: 0.4752
Epoch [15/50] - Loss: 0.4713
Epoch [16/50] - Loss: 0.4672
Epoch [17/50] - Loss: 0.4628
Epoch [18/50] - Loss: 0.4583
Epoch [19/50] - Loss: 0.4537
Epoch [20/50] - Loss: 0.4489
Epoch [21/50] - Loss: 0.4440
Epoch [22/50] - Loss: 0.4389
Epoch [23/50] - Loss: 0.4337
Epoch [24/50] - Loss: 0.4284
Epoch [25/50] - Loss: 0.4230
Epoch [26/50] - Loss: 0.4175
Epoch [27/50] - Loss: 0.4119
Epoch [28/50] - Loss: 0.4063
Epoch [29/50] - Loss: 0.4006
Epoch [30/50] - Loss: 0.3949
Epoch [31/50] - Loss: 0.3893
Epoch [32/50] - Loss: 0.3836
Epoch [33/50] - Loss: 0.3780
Epoch [34/50] - Loss: 0.3723
Epoch [35/50] - Loss: 0.3668
Epoch [36/50] - Loss: 0.3612
Epoch [37/50] - Loss: 0.3558
Epoch [38/50] - Loss: 0.3503
Epoch [39/50] - Loss: 0.3450
Epoch [40/50] - Loss: 0.3396
Epoch [41/50] - Loss: 0.3343
Epoch [42/50] - Loss: 0.3291
Epoch [43/50] - Loss: 0.3239
Epoch [44/50] - Loss: 0.3187
Epoch [45/50] - Loss: 0.3135
Epoch [46/50] - Loss: 0.3083
Epoch [47/50] - Loss: 0.3032
Epoch [48/50] - Loss: 0.2981
Epoch [49/50] - Loss: 0.2931
Epoch [50/50] - Loss: 0.2881
sum preds 2550
sum labels 4725
 - Test Metrics: Accuracy=0.8051, F1=0.5562, Recall=0.4281, Precision=0.7933
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_nnpu_nnpu_1804183530.csv.
Average F1 over valid seeds: 0.5746 ± 0.0366
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and nnpu, MLP,0.4: 0.5746 ± 0.0366
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4982
Epoch [3/50] - Loss: 0.4962
Epoch [4/50] - Loss: 0.4937
Epoch [5/50] - Loss: 0.4910
Epoch [6/50] - Loss: 0.4881
Epoch [7/50] - Loss: 0.4851
Epoch [8/50] - Loss: 0.4819
Epoch [9/50] - Loss: 0.4785
Epoch [10/50] - Loss: 0.4749
Epoch [11/50] - Loss: 0.4712
Epoch [12/50] - Loss: 0.4674
Epoch [13/50] - Loss: 0.4635
Epoch [14/50] - Loss: 0.4595
Epoch [15/50] - Loss: 0.4553
Epoch [16/50] - Loss: 0.4511
Epoch [17/50] - Loss: 0.4466
Epoch [18/50] - Loss: 0.4421
Epoch [19/50] - Loss: 0.4374
Epoch [20/50] - Loss: 0.4327
Epoch [21/50] - Loss: 0.4278
Epoch [22/50] - Loss: 0.4229
Epoch [23/50] - Loss: 0.4179
Epoch [24/50] - Loss: 0.4128
Epoch [25/50] - Loss: 0.4076
Epoch [26/50] - Loss: 0.4024
Epoch [27/50] - Loss: 0.3970
Epoch [28/50] - Loss: 0.3917
Epoch [29/50] - Loss: 0.3863
Epoch [30/50] - Loss: 0.3808
Epoch [31/50] - Loss: 0.3753
Epoch [32/50] - Loss: 0.3698
Epoch [33/50] - Loss: 0.3642
Epoch [34/50] - Loss: 0.3587
Epoch [35/50] - Loss: 0.3531
Epoch [36/50] - Loss: 0.3475
Epoch [37/50] - Loss: 0.3419
Epoch [38/50] - Loss: 0.3362
Epoch [39/50] - Loss: 0.3306
Epoch [40/50] - Loss: 0.3249
Epoch [41/50] - Loss: 0.3192
Epoch [42/50] - Loss: 0.3135
Epoch [43/50] - Loss: 0.3079
Epoch [44/50] - Loss: 0.3022
Epoch [45/50] - Loss: 0.2966
Epoch [46/50] - Loss: 0.2909
Epoch [47/50] - Loss: 0.2853
Epoch [48/50] - Loss: 0.2798
Epoch [49/50] - Loss: 0.2742
Epoch [50/50] - Loss: 0.2688
sum preds 3380
sum labels 4725
 - Test Metrics: Accuracy=0.8330, F1=0.6586, Recall=0.5649, Precision=0.7896
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4962
Epoch [3/50] - Loss: 0.4915
Epoch [4/50] - Loss: 0.4865
Epoch [5/50] - Loss: 0.4813
Epoch [6/50] - Loss: 0.4760
Epoch [7/50] - Loss: 0.4706
Epoch [8/50] - Loss: 0.4651
Epoch [9/50] - Loss: 0.4595
Epoch [10/50] - Loss: 0.4538
Epoch [11/50] - Loss: 0.4480
Epoch [12/50] - Loss: 0.4423
Epoch [13/50] - Loss: 0.4366
Epoch [14/50] - Loss: 0.4311
Epoch [15/50] - Loss: 0.4257
Epoch [16/50] - Loss: 0.4203
Epoch [17/50] - Loss: 0.4151
Epoch [18/50] - Loss: 0.4100
Epoch [19/50] - Loss: 0.4050
Epoch [20/50] - Loss: 0.4002
Epoch [21/50] - Loss: 0.3955
Epoch [22/50] - Loss: 0.3909
Epoch [23/50] - Loss: 0.3866
Epoch [24/50] - Loss: 0.3823
Epoch [25/50] - Loss: 0.3782
Epoch [26/50] - Loss: 0.3742
Epoch [27/50] - Loss: 0.3702
Epoch [28/50] - Loss: 0.3662
Epoch [29/50] - Loss: 0.3622
Epoch [30/50] - Loss: 0.3583
Epoch [31/50] - Loss: 0.3543
Epoch [32/50] - Loss: 0.3503
Epoch [33/50] - Loss: 0.3461
Epoch [34/50] - Loss: 0.3420
Epoch [35/50] - Loss: 0.3377
Epoch [36/50] - Loss: 0.3334
Epoch [37/50] - Loss: 0.3290
Epoch [38/50] - Loss: 0.3246
Epoch [39/50] - Loss: 0.3202
Epoch [40/50] - Loss: 0.3158
Epoch [41/50] - Loss: 0.3114
Epoch [42/50] - Loss: 0.3072
Epoch [43/50] - Loss: 0.3030
Epoch [44/50] - Loss: 0.2988
Epoch [45/50] - Loss: 0.2947
Epoch [46/50] - Loss: 0.2906
Epoch [47/50] - Loss: 0.2865
Epoch [48/50] - Loss: 0.2824
Epoch [49/50] - Loss: 0.2783
Epoch [50/50] - Loss: 0.2741
sum preds 2824
sum labels 4725
 - Test Metrics: Accuracy=0.8224, F1=0.6101, Recall=0.4874, Precision=0.8155
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4953
Epoch [3/50] - Loss: 0.4907
Epoch [4/50] - Loss: 0.4860
Epoch [5/50] - Loss: 0.4811
Epoch [6/50] - Loss: 0.4760
Epoch [7/50] - Loss: 0.4708
Epoch [8/50] - Loss: 0.4654
Epoch [9/50] - Loss: 0.4599
Epoch [10/50] - Loss: 0.4542
Epoch [11/50] - Loss: 0.4485
Epoch [12/50] - Loss: 0.4426
Epoch [13/50] - Loss: 0.4368
Epoch [14/50] - Loss: 0.4309
Epoch [15/50] - Loss: 0.4251
Epoch [16/50] - Loss: 0.4194
Epoch [17/50] - Loss: 0.4136
Epoch [18/50] - Loss: 0.4079
Epoch [19/50] - Loss: 0.4021
Epoch [20/50] - Loss: 0.3964
Epoch [21/50] - Loss: 0.3906
Epoch [22/50] - Loss: 0.3849
Epoch [23/50] - Loss: 0.3792
Epoch [24/50] - Loss: 0.3735
Epoch [25/50] - Loss: 0.3678
Epoch [26/50] - Loss: 0.3621
Epoch [27/50] - Loss: 0.3564
Epoch [28/50] - Loss: 0.3507
Epoch [29/50] - Loss: 0.3450
Epoch [30/50] - Loss: 0.3392
Epoch [31/50] - Loss: 0.3334
Epoch [32/50] - Loss: 0.3275
Epoch [33/50] - Loss: 0.3216
Epoch [34/50] - Loss: 0.3157
Epoch [35/50] - Loss: 0.3098
Epoch [36/50] - Loss: 0.3040
Epoch [37/50] - Loss: 0.2981
Epoch [38/50] - Loss: 0.2923
Epoch [39/50] - Loss: 0.2865
Epoch [40/50] - Loss: 0.2808
Epoch [41/50] - Loss: 0.2753
Epoch [42/50] - Loss: 0.2698
Epoch [43/50] - Loss: 0.2644
Epoch [44/50] - Loss: 0.2591
Epoch [45/50] - Loss: 0.2538
Epoch [46/50] - Loss: 0.2487
Epoch [47/50] - Loss: 0.2435
Epoch [48/50] - Loss: 0.2385
Epoch [49/50] - Loss: 0.2335
Epoch [50/50] - Loss: 0.2286
sum preds 3550
sum labels 4725
 - Test Metrics: Accuracy=0.8248, F1=0.6492, Recall=0.5685, Precision=0.7566
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_nnpu_nnpu_1804183532.csv.
Average F1 over valid seeds: 0.6393 ± 0.0210
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and nnpu, GATConv,0.4: 0.6393 ± 0.0210
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5002
Epoch [2/50] - Loss: 0.4984
Epoch [3/50] - Loss: 0.4966
Epoch [4/50] - Loss: 0.4945
Epoch [5/50] - Loss: 0.4921
Epoch [6/50] - Loss: 0.4896
Epoch [7/50] - Loss: 0.4870
Epoch [8/50] - Loss: 0.4843
Epoch [9/50] - Loss: 0.4815
Epoch [10/50] - Loss: 0.4786
Epoch [11/50] - Loss: 0.4755
Epoch [12/50] - Loss: 0.4725
Epoch [13/50] - Loss: 0.4693
Epoch [14/50] - Loss: 0.4661
Epoch [15/50] - Loss: 0.4628
Epoch [16/50] - Loss: 0.4594
Epoch [17/50] - Loss: 0.4559
Epoch [18/50] - Loss: 0.4523
Epoch [19/50] - Loss: 0.4486
Epoch [20/50] - Loss: 0.4449
Epoch [21/50] - Loss: 0.4411
Epoch [22/50] - Loss: 0.4372
Epoch [23/50] - Loss: 0.4333
Epoch [24/50] - Loss: 0.4292
Epoch [25/50] - Loss: 0.4251
Epoch [26/50] - Loss: 0.4210
Epoch [27/50] - Loss: 0.4167
Epoch [28/50] - Loss: 0.4123
Epoch [29/50] - Loss: 0.4078
Epoch [30/50] - Loss: 0.4032
Epoch [31/50] - Loss: 0.3986
Epoch [32/50] - Loss: 0.3938
Epoch [33/50] - Loss: 0.3891
Epoch [34/50] - Loss: 0.3845
Epoch [35/50] - Loss: 0.3797
Epoch [36/50] - Loss: 0.3750
Epoch [37/50] - Loss: 0.3702
Epoch [38/50] - Loss: 0.3653
Epoch [39/50] - Loss: 0.3604
Epoch [40/50] - Loss: 0.3554
Epoch [41/50] - Loss: 0.3505
Epoch [42/50] - Loss: 0.3456
Epoch [43/50] - Loss: 0.3407
Epoch [44/50] - Loss: 0.3357
Epoch [45/50] - Loss: 0.3308
Epoch [46/50] - Loss: 0.3259
Epoch [47/50] - Loss: 0.3211
Epoch [48/50] - Loss: 0.3162
Epoch [49/50] - Loss: 0.3114
Epoch [50/50] - Loss: 0.3066
sum preds 3448
sum labels 4725
 - Test Metrics: Accuracy=0.8424, F1=0.6805, Recall=0.5886, Precision=0.8066
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5006
Epoch [2/50] - Loss: 0.4973
Epoch [3/50] - Loss: 0.4943
Epoch [4/50] - Loss: 0.4912
Epoch [5/50] - Loss: 0.4880
Epoch [6/50] - Loss: 0.4846
Epoch [7/50] - Loss: 0.4810
Epoch [8/50] - Loss: 0.4774
Epoch [9/50] - Loss: 0.4736
Epoch [10/50] - Loss: 0.4697
Epoch [11/50] - Loss: 0.4658
Epoch [12/50] - Loss: 0.4619
Epoch [13/50] - Loss: 0.4579
Epoch [14/50] - Loss: 0.4539
Epoch [15/50] - Loss: 0.4497
Epoch [16/50] - Loss: 0.4454
Epoch [17/50] - Loss: 0.4411
Epoch [18/50] - Loss: 0.4366
Epoch [19/50] - Loss: 0.4321
Epoch [20/50] - Loss: 0.4277
Epoch [21/50] - Loss: 0.4233
Epoch [22/50] - Loss: 0.4189
Epoch [23/50] - Loss: 0.4144
Epoch [24/50] - Loss: 0.4099
Epoch [25/50] - Loss: 0.4053
Epoch [26/50] - Loss: 0.4007
Epoch [27/50] - Loss: 0.3960
Epoch [28/50] - Loss: 0.3914
Epoch [29/50] - Loss: 0.3867
Epoch [30/50] - Loss: 0.3820
Epoch [31/50] - Loss: 0.3773
Epoch [32/50] - Loss: 0.3727
Epoch [33/50] - Loss: 0.3681
Epoch [34/50] - Loss: 0.3635
Epoch [35/50] - Loss: 0.3589
Epoch [36/50] - Loss: 0.3543
Epoch [37/50] - Loss: 0.3496
Epoch [38/50] - Loss: 0.3450
Epoch [39/50] - Loss: 0.3403
Epoch [40/50] - Loss: 0.3357
Epoch [41/50] - Loss: 0.3310
Epoch [42/50] - Loss: 0.3264
Epoch [43/50] - Loss: 0.3218
Epoch [44/50] - Loss: 0.3173
Epoch [45/50] - Loss: 0.3128
Epoch [46/50] - Loss: 0.3083
Epoch [47/50] - Loss: 0.3039
Epoch [48/50] - Loss: 0.2995
Epoch [49/50] - Loss: 0.2952
Epoch [50/50] - Loss: 0.2909
sum preds 3064
sum labels 4725
 - Test Metrics: Accuracy=0.8288, F1=0.6358, Recall=0.5240, Precision=0.8081
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4970
Epoch [3/50] - Loss: 0.4940
Epoch [4/50] - Loss: 0.4907
Epoch [5/50] - Loss: 0.4871
Epoch [6/50] - Loss: 0.4832
Epoch [7/50] - Loss: 0.4792
Epoch [8/50] - Loss: 0.4751
Epoch [9/50] - Loss: 0.4710
Epoch [10/50] - Loss: 0.4668
Epoch [11/50] - Loss: 0.4625
Epoch [12/50] - Loss: 0.4582
Epoch [13/50] - Loss: 0.4538
Epoch [14/50] - Loss: 0.4493
Epoch [15/50] - Loss: 0.4447
Epoch [16/50] - Loss: 0.4401
Epoch [17/50] - Loss: 0.4355
Epoch [18/50] - Loss: 0.4310
Epoch [19/50] - Loss: 0.4264
Epoch [20/50] - Loss: 0.4219
Epoch [21/50] - Loss: 0.4174
Epoch [22/50] - Loss: 0.4129
Epoch [23/50] - Loss: 0.4085
Epoch [24/50] - Loss: 0.4040
Epoch [25/50] - Loss: 0.3995
Epoch [26/50] - Loss: 0.3951
Epoch [27/50] - Loss: 0.3907
Epoch [28/50] - Loss: 0.3863
Epoch [29/50] - Loss: 0.3819
Epoch [30/50] - Loss: 0.3776
Epoch [31/50] - Loss: 0.3732
Epoch [32/50] - Loss: 0.3689
Epoch [33/50] - Loss: 0.3645
Epoch [34/50] - Loss: 0.3601
Epoch [35/50] - Loss: 0.3557
Epoch [36/50] - Loss: 0.3513
Epoch [37/50] - Loss: 0.3469
Epoch [38/50] - Loss: 0.3425
Epoch [39/50] - Loss: 0.3380
Epoch [40/50] - Loss: 0.3336
Epoch [41/50] - Loss: 0.3291
Epoch [42/50] - Loss: 0.3247
Epoch [43/50] - Loss: 0.3203
Epoch [44/50] - Loss: 0.3160
Epoch [45/50] - Loss: 0.3117
Epoch [46/50] - Loss: 0.3075
Epoch [47/50] - Loss: 0.3032
Epoch [48/50] - Loss: 0.2990
Epoch [49/50] - Loss: 0.2949
Epoch [50/50] - Loss: 0.2908
sum preds 2834
sum labels 4725
 - Test Metrics: Accuracy=0.8201, F1=0.6056, Recall=0.4844, Precision=0.8077
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_nnpu_nnpu_1804183535.csv.
Average F1 over valid seeds: 0.6406 ± 0.0308
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and nnpu, GCNConv,0.4: 0.6406 ± 0.0308
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5087
Epoch [2/50] - Loss: 0.5076
Epoch [3/50] - Loss: 0.5064
Epoch [4/50] - Loss: 0.5051
Epoch [5/50] - Loss: 0.5038
Epoch [6/50] - Loss: 0.5023
Epoch [7/50] - Loss: 0.5006
Epoch [8/50] - Loss: 0.4988
Epoch [9/50] - Loss: 0.4969
Epoch [10/50] - Loss: 0.4949
Epoch [11/50] - Loss: 0.4927
Epoch [12/50] - Loss: 0.4904
Epoch [13/50] - Loss: 0.4879
Epoch [14/50] - Loss: 0.4853
Epoch [15/50] - Loss: 0.4825
Epoch [16/50] - Loss: 0.4797
Epoch [17/50] - Loss: 0.4766
Epoch [18/50] - Loss: 0.4734
Epoch [19/50] - Loss: 0.4701
Epoch [20/50] - Loss: 0.4666
Epoch [21/50] - Loss: 0.4629
Epoch [22/50] - Loss: 0.4591
Epoch [23/50] - Loss: 0.4552
Epoch [24/50] - Loss: 0.4511
Epoch [25/50] - Loss: 0.4468
Epoch [26/50] - Loss: 0.4424
Epoch [27/50] - Loss: 0.4379
Epoch [28/50] - Loss: 0.4332
Epoch [29/50] - Loss: 0.4284
Epoch [30/50] - Loss: 0.4234
Epoch [31/50] - Loss: 0.4184
Epoch [32/50] - Loss: 0.4133
Epoch [33/50] - Loss: 0.4080
Epoch [34/50] - Loss: 0.4027
Epoch [35/50] - Loss: 0.3973
Epoch [36/50] - Loss: 0.3918
Epoch [37/50] - Loss: 0.3862
Epoch [38/50] - Loss: 0.3806
Epoch [39/50] - Loss: 0.3750
Epoch [40/50] - Loss: 0.3694
Epoch [41/50] - Loss: 0.3637
Epoch [42/50] - Loss: 0.3580
Epoch [43/50] - Loss: 0.3523
Epoch [44/50] - Loss: 0.3467
Epoch [45/50] - Loss: 0.3410
Epoch [46/50] - Loss: 0.3354
Epoch [47/50] - Loss: 0.3298
Epoch [48/50] - Loss: 0.3242
Epoch [49/50] - Loss: 0.3187
Epoch [50/50] - Loss: 0.3132
sum preds 3284
sum labels 5513
 - Test Metrics: Accuracy=0.7998, F1=0.6050, Recall=0.4827, Precision=0.8103
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4937
Epoch [2/50] - Loss: 0.4924
Epoch [3/50] - Loss: 0.4913
Epoch [4/50] - Loss: 0.4902
Epoch [5/50] - Loss: 0.4891
Epoch [6/50] - Loss: 0.4878
Epoch [7/50] - Loss: 0.4863
Epoch [8/50] - Loss: 0.4846
Epoch [9/50] - Loss: 0.4827
Epoch [10/50] - Loss: 0.4807
Epoch [11/50] - Loss: 0.4785
Epoch [12/50] - Loss: 0.4762
Epoch [13/50] - Loss: 0.4738
Epoch [14/50] - Loss: 0.4712
Epoch [15/50] - Loss: 0.4685
Epoch [16/50] - Loss: 0.4656
Epoch [17/50] - Loss: 0.4626
Epoch [18/50] - Loss: 0.4594
Epoch [19/50] - Loss: 0.4560
Epoch [20/50] - Loss: 0.4525
Epoch [21/50] - Loss: 0.4489
Epoch [22/50] - Loss: 0.4452
Epoch [23/50] - Loss: 0.4413
Epoch [24/50] - Loss: 0.4373
Epoch [25/50] - Loss: 0.4331
Epoch [26/50] - Loss: 0.4289
Epoch [27/50] - Loss: 0.4245
Epoch [28/50] - Loss: 0.4201
Epoch [29/50] - Loss: 0.4155
Epoch [30/50] - Loss: 0.4109
Epoch [31/50] - Loss: 0.4062
Epoch [32/50] - Loss: 0.4015
Epoch [33/50] - Loss: 0.3967
Epoch [34/50] - Loss: 0.3919
Epoch [35/50] - Loss: 0.3871
Epoch [36/50] - Loss: 0.3822
Epoch [37/50] - Loss: 0.3773
Epoch [38/50] - Loss: 0.3724
Epoch [39/50] - Loss: 0.3675
Epoch [40/50] - Loss: 0.3626
Epoch [41/50] - Loss: 0.3577
Epoch [42/50] - Loss: 0.3528
Epoch [43/50] - Loss: 0.3478
Epoch [44/50] - Loss: 0.3429
Epoch [45/50] - Loss: 0.3379
Epoch [46/50] - Loss: 0.3330
Epoch [47/50] - Loss: 0.3280
Epoch [48/50] - Loss: 0.3230
Epoch [49/50] - Loss: 0.3180
Epoch [50/50] - Loss: 0.3130
sum preds 2480
sum labels 5513
 - Test Metrics: Accuracy=0.7802, F1=0.5227, Recall=0.3789, Precision=0.8423
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5114
Epoch [2/50] - Loss: 0.5096
Epoch [3/50] - Loss: 0.5077
Epoch [4/50] - Loss: 0.5057
Epoch [5/50] - Loss: 0.5036
Epoch [6/50] - Loss: 0.5013
Epoch [7/50] - Loss: 0.4988
Epoch [8/50] - Loss: 0.4961
Epoch [9/50] - Loss: 0.4932
Epoch [10/50] - Loss: 0.4902
Epoch [11/50] - Loss: 0.4870
Epoch [12/50] - Loss: 0.4837
Epoch [13/50] - Loss: 0.4802
Epoch [14/50] - Loss: 0.4765
Epoch [15/50] - Loss: 0.4727
Epoch [16/50] - Loss: 0.4687
Epoch [17/50] - Loss: 0.4645
Epoch [18/50] - Loss: 0.4602
Epoch [19/50] - Loss: 0.4557
Epoch [20/50] - Loss: 0.4511
Epoch [21/50] - Loss: 0.4463
Epoch [22/50] - Loss: 0.4415
Epoch [23/50] - Loss: 0.4364
Epoch [24/50] - Loss: 0.4313
Epoch [25/50] - Loss: 0.4261
Epoch [26/50] - Loss: 0.4208
Epoch [27/50] - Loss: 0.4155
Epoch [28/50] - Loss: 0.4101
Epoch [29/50] - Loss: 0.4046
Epoch [30/50] - Loss: 0.3992
Epoch [31/50] - Loss: 0.3937
Epoch [32/50] - Loss: 0.3883
Epoch [33/50] - Loss: 0.3829
Epoch [34/50] - Loss: 0.3775
Epoch [35/50] - Loss: 0.3721
Epoch [36/50] - Loss: 0.3669
Epoch [37/50] - Loss: 0.3616
Epoch [38/50] - Loss: 0.3564
Epoch [39/50] - Loss: 0.3513
Epoch [40/50] - Loss: 0.3463
Epoch [41/50] - Loss: 0.3413
Epoch [42/50] - Loss: 0.3363
Epoch [43/50] - Loss: 0.3314
Epoch [44/50] - Loss: 0.3265
Epoch [45/50] - Loss: 0.3216
Epoch [46/50] - Loss: 0.3167
Epoch [47/50] - Loss: 0.3119
Epoch [48/50] - Loss: 0.3072
Epoch [49/50] - Loss: 0.3024
Epoch [50/50] - Loss: 0.2978
sum preds 2729
sum labels 5513
 - Test Metrics: Accuracy=0.7837, F1=0.5445, Recall=0.4070, Precision=0.8223
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_nnpu_nnpu_1804183537.csv.
Average F1 over valid seeds: 0.5574 ± 0.0348
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and nnpu, MLP,0.3: 0.5574 ± 0.0348
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4982
Epoch [3/50] - Loss: 0.4962
Epoch [4/50] - Loss: 0.4938
Epoch [5/50] - Loss: 0.4911
Epoch [6/50] - Loss: 0.4883
Epoch [7/50] - Loss: 0.4854
Epoch [8/50] - Loss: 0.4823
Epoch [9/50] - Loss: 0.4790
Epoch [10/50] - Loss: 0.4756
Epoch [11/50] - Loss: 0.4720
Epoch [12/50] - Loss: 0.4683
Epoch [13/50] - Loss: 0.4645
Epoch [14/50] - Loss: 0.4605
Epoch [15/50] - Loss: 0.4565
Epoch [16/50] - Loss: 0.4524
Epoch [17/50] - Loss: 0.4481
Epoch [18/50] - Loss: 0.4438
Epoch [19/50] - Loss: 0.4392
Epoch [20/50] - Loss: 0.4346
Epoch [21/50] - Loss: 0.4299
Epoch [22/50] - Loss: 0.4252
Epoch [23/50] - Loss: 0.4203
Epoch [24/50] - Loss: 0.4154
Epoch [25/50] - Loss: 0.4104
Epoch [26/50] - Loss: 0.4054
Epoch [27/50] - Loss: 0.4002
Epoch [28/50] - Loss: 0.3951
Epoch [29/50] - Loss: 0.3899
Epoch [30/50] - Loss: 0.3846
Epoch [31/50] - Loss: 0.3794
Epoch [32/50] - Loss: 0.3741
Epoch [33/50] - Loss: 0.3688
Epoch [34/50] - Loss: 0.3635
Epoch [35/50] - Loss: 0.3582
Epoch [36/50] - Loss: 0.3529
Epoch [37/50] - Loss: 0.3475
Epoch [38/50] - Loss: 0.3422
Epoch [39/50] - Loss: 0.3369
Epoch [40/50] - Loss: 0.3315
Epoch [41/50] - Loss: 0.3262
Epoch [42/50] - Loss: 0.3209
Epoch [43/50] - Loss: 0.3155
Epoch [44/50] - Loss: 0.3102
Epoch [45/50] - Loss: 0.3050
Epoch [46/50] - Loss: 0.2997
Epoch [47/50] - Loss: 0.2945
Epoch [48/50] - Loss: 0.2893
Epoch [49/50] - Loss: 0.2842
Epoch [50/50] - Loss: 0.2792
sum preds 3572
sum labels 5513
 - Test Metrics: Accuracy=0.8120, F1=0.6408, Recall=0.5280, Precision=0.8149
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4963
Epoch [3/50] - Loss: 0.4918
Epoch [4/50] - Loss: 0.4869
Epoch [5/50] - Loss: 0.4819
Epoch [6/50] - Loss: 0.4768
Epoch [7/50] - Loss: 0.4716
Epoch [8/50] - Loss: 0.4663
Epoch [9/50] - Loss: 0.4609
Epoch [10/50] - Loss: 0.4555
Epoch [11/50] - Loss: 0.4500
Epoch [12/50] - Loss: 0.4445
Epoch [13/50] - Loss: 0.4390
Epoch [14/50] - Loss: 0.4336
Epoch [15/50] - Loss: 0.4282
Epoch [16/50] - Loss: 0.4231
Epoch [17/50] - Loss: 0.4180
Epoch [18/50] - Loss: 0.4131
Epoch [19/50] - Loss: 0.4084
Epoch [20/50] - Loss: 0.4037
Epoch [21/50] - Loss: 0.3992
Epoch [22/50] - Loss: 0.3949
Epoch [23/50] - Loss: 0.3907
Epoch [24/50] - Loss: 0.3866
Epoch [25/50] - Loss: 0.3827
Epoch [26/50] - Loss: 0.3789
Epoch [27/50] - Loss: 0.3752
Epoch [28/50] - Loss: 0.3715
Epoch [29/50] - Loss: 0.3679
Epoch [30/50] - Loss: 0.3643
Epoch [31/50] - Loss: 0.3607
Epoch [32/50] - Loss: 0.3570
Epoch [33/50] - Loss: 0.3533
Epoch [34/50] - Loss: 0.3495
Epoch [35/50] - Loss: 0.3456
Epoch [36/50] - Loss: 0.3416
Epoch [37/50] - Loss: 0.3376
Epoch [38/50] - Loss: 0.3335
Epoch [39/50] - Loss: 0.3293
Epoch [40/50] - Loss: 0.3252
Epoch [41/50] - Loss: 0.3210
Epoch [42/50] - Loss: 0.3169
Epoch [43/50] - Loss: 0.3128
Epoch [44/50] - Loss: 0.3089
Epoch [45/50] - Loss: 0.3049
Epoch [46/50] - Loss: 0.3010
Epoch [47/50] - Loss: 0.2972
Epoch [48/50] - Loss: 0.2934
Epoch [49/50] - Loss: 0.2895
Epoch [50/50] - Loss: 0.2857
sum preds 3118
sum labels 5513
 - Test Metrics: Accuracy=0.8045, F1=0.6069, Recall=0.4751, Precision=0.8400
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4954
Epoch [3/50] - Loss: 0.4910
Epoch [4/50] - Loss: 0.4864
Epoch [5/50] - Loss: 0.4817
Epoch [6/50] - Loss: 0.4768
Epoch [7/50] - Loss: 0.4718
Epoch [8/50] - Loss: 0.4667
Epoch [9/50] - Loss: 0.4614
Epoch [10/50] - Loss: 0.4560
Epoch [11/50] - Loss: 0.4505
Epoch [12/50] - Loss: 0.4449
Epoch [13/50] - Loss: 0.4393
Epoch [14/50] - Loss: 0.4336
Epoch [15/50] - Loss: 0.4280
Epoch [16/50] - Loss: 0.4224
Epoch [17/50] - Loss: 0.4169
Epoch [18/50] - Loss: 0.4115
Epoch [19/50] - Loss: 0.4060
Epoch [20/50] - Loss: 0.4006
Epoch [21/50] - Loss: 0.3951
Epoch [22/50] - Loss: 0.3897
Epoch [23/50] - Loss: 0.3843
Epoch [24/50] - Loss: 0.3789
Epoch [25/50] - Loss: 0.3736
Epoch [26/50] - Loss: 0.3682
Epoch [27/50] - Loss: 0.3629
Epoch [28/50] - Loss: 0.3575
Epoch [29/50] - Loss: 0.3522
Epoch [30/50] - Loss: 0.3467
Epoch [31/50] - Loss: 0.3413
Epoch [32/50] - Loss: 0.3358
Epoch [33/50] - Loss: 0.3303
Epoch [34/50] - Loss: 0.3247
Epoch [35/50] - Loss: 0.3191
Epoch [36/50] - Loss: 0.3135
Epoch [37/50] - Loss: 0.3080
Epoch [38/50] - Loss: 0.3025
Epoch [39/50] - Loss: 0.2970
Epoch [40/50] - Loss: 0.2916
Epoch [41/50] - Loss: 0.2863
Epoch [42/50] - Loss: 0.2810
Epoch [43/50] - Loss: 0.2759
Epoch [44/50] - Loss: 0.2708
Epoch [45/50] - Loss: 0.2659
Epoch [46/50] - Loss: 0.2610
Epoch [47/50] - Loss: 0.2562
Epoch [48/50] - Loss: 0.2515
Epoch [49/50] - Loss: 0.2468
Epoch [50/50] - Loss: 0.2422
sum preds 3930
sum labels 5513
 - Test Metrics: Accuracy=0.8136, F1=0.6574, Recall=0.5630, Precision=0.7898
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_nnpu_nnpu_1804183539.csv.
Average F1 over valid seeds: 0.6350 ± 0.0210
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and nnpu, GATConv,0.3: 0.6350 ± 0.0210
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5002
Epoch [2/50] - Loss: 0.4984
Epoch [3/50] - Loss: 0.4967
Epoch [4/50] - Loss: 0.4946
Epoch [5/50] - Loss: 0.4924
Epoch [6/50] - Loss: 0.4899
Epoch [7/50] - Loss: 0.4874
Epoch [8/50] - Loss: 0.4848
Epoch [9/50] - Loss: 0.4821
Epoch [10/50] - Loss: 0.4793
Epoch [11/50] - Loss: 0.4764
Epoch [12/50] - Loss: 0.4734
Epoch [13/50] - Loss: 0.4703
Epoch [14/50] - Loss: 0.4672
Epoch [15/50] - Loss: 0.4640
Epoch [16/50] - Loss: 0.4607
Epoch [17/50] - Loss: 0.4574
Epoch [18/50] - Loss: 0.4539
Epoch [19/50] - Loss: 0.4504
Epoch [20/50] - Loss: 0.4468
Epoch [21/50] - Loss: 0.4431
Epoch [22/50] - Loss: 0.4394
Epoch [23/50] - Loss: 0.4355
Epoch [24/50] - Loss: 0.4316
Epoch [25/50] - Loss: 0.4276
Epoch [26/50] - Loss: 0.4234
Epoch [27/50] - Loss: 0.4191
Epoch [28/50] - Loss: 0.4148
Epoch [29/50] - Loss: 0.4104
Epoch [30/50] - Loss: 0.4061
Epoch [31/50] - Loss: 0.4018
Epoch [32/50] - Loss: 0.3974
Epoch [33/50] - Loss: 0.3929
Epoch [34/50] - Loss: 0.3884
Epoch [35/50] - Loss: 0.3838
Epoch [36/50] - Loss: 0.3792
Epoch [37/50] - Loss: 0.3746
Epoch [38/50] - Loss: 0.3699
Epoch [39/50] - Loss: 0.3653
Epoch [40/50] - Loss: 0.3607
Epoch [41/50] - Loss: 0.3560
Epoch [42/50] - Loss: 0.3513
Epoch [43/50] - Loss: 0.3467
Epoch [44/50] - Loss: 0.3420
Epoch [45/50] - Loss: 0.3374
Epoch [46/50] - Loss: 0.3327
Epoch [47/50] - Loss: 0.3281
Epoch [48/50] - Loss: 0.3235
Epoch [49/50] - Loss: 0.3190
Epoch [50/50] - Loss: 0.3144
sum preds 3730
sum labels 5513
 - Test Metrics: Accuracy=0.8228, F1=0.6673, Recall=0.5594, Precision=0.8268
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5006
Epoch [2/50] - Loss: 0.4973
Epoch [3/50] - Loss: 0.4944
Epoch [4/50] - Loss: 0.4915
Epoch [5/50] - Loss: 0.4884
Epoch [6/50] - Loss: 0.4851
Epoch [7/50] - Loss: 0.4817
Epoch [8/50] - Loss: 0.4782
Epoch [9/50] - Loss: 0.4746
Epoch [10/50] - Loss: 0.4709
Epoch [11/50] - Loss: 0.4671
Epoch [12/50] - Loss: 0.4633
Epoch [13/50] - Loss: 0.4595
Epoch [14/50] - Loss: 0.4557
Epoch [15/50] - Loss: 0.4517
Epoch [16/50] - Loss: 0.4478
Epoch [17/50] - Loss: 0.4437
Epoch [18/50] - Loss: 0.4396
Epoch [19/50] - Loss: 0.4354
Epoch [20/50] - Loss: 0.4311
Epoch [21/50] - Loss: 0.4269
Epoch [22/50] - Loss: 0.4225
Epoch [23/50] - Loss: 0.4183
Epoch [24/50] - Loss: 0.4140
Epoch [25/50] - Loss: 0.4098
Epoch [26/50] - Loss: 0.4056
Epoch [27/50] - Loss: 0.4014
Epoch [28/50] - Loss: 0.3971
Epoch [29/50] - Loss: 0.3927
Epoch [30/50] - Loss: 0.3884
Epoch [31/50] - Loss: 0.3840
Epoch [32/50] - Loss: 0.3795
Epoch [33/50] - Loss: 0.3752
Epoch [34/50] - Loss: 0.3708
Epoch [35/50] - Loss: 0.3664
Epoch [36/50] - Loss: 0.3621
Epoch [37/50] - Loss: 0.3578
Epoch [38/50] - Loss: 0.3535
Epoch [39/50] - Loss: 0.3492
Epoch [40/50] - Loss: 0.3449
Epoch [41/50] - Loss: 0.3405
Epoch [42/50] - Loss: 0.3362
Epoch [43/50] - Loss: 0.3318
Epoch [44/50] - Loss: 0.3275
Epoch [45/50] - Loss: 0.3232
Epoch [46/50] - Loss: 0.3189
Epoch [47/50] - Loss: 0.3147
Epoch [48/50] - Loss: 0.3105
Epoch [49/50] - Loss: 0.3064
Epoch [50/50] - Loss: 0.3023
sum preds 3324
sum labels 5513
 - Test Metrics: Accuracy=0.8109, F1=0.6287, Recall=0.5039, Precision=0.8357
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4970
Epoch [3/50] - Loss: 0.4941
Epoch [4/50] - Loss: 0.4909
Epoch [5/50] - Loss: 0.4874
Epoch [6/50] - Loss: 0.4836
Epoch [7/50] - Loss: 0.4797
Epoch [8/50] - Loss: 0.4758
Epoch [9/50] - Loss: 0.4718
Epoch [10/50] - Loss: 0.4677
Epoch [11/50] - Loss: 0.4636
Epoch [12/50] - Loss: 0.4594
Epoch [13/50] - Loss: 0.4551
Epoch [14/50] - Loss: 0.4508
Epoch [15/50] - Loss: 0.4464
Epoch [16/50] - Loss: 0.4420
Epoch [17/50] - Loss: 0.4376
Epoch [18/50] - Loss: 0.4331
Epoch [19/50] - Loss: 0.4287
Epoch [20/50] - Loss: 0.4243
Epoch [21/50] - Loss: 0.4200
Epoch [22/50] - Loss: 0.4157
Epoch [23/50] - Loss: 0.4114
Epoch [24/50] - Loss: 0.4072
Epoch [25/50] - Loss: 0.4029
Epoch [26/50] - Loss: 0.3987
Epoch [27/50] - Loss: 0.3944
Epoch [28/50] - Loss: 0.3903
Epoch [29/50] - Loss: 0.3861
Epoch [30/50] - Loss: 0.3819
Epoch [31/50] - Loss: 0.3778
Epoch [32/50] - Loss: 0.3737
Epoch [33/50] - Loss: 0.3695
Epoch [34/50] - Loss: 0.3654
Epoch [35/50] - Loss: 0.3612
Epoch [36/50] - Loss: 0.3570
Epoch [37/50] - Loss: 0.3528
Epoch [38/50] - Loss: 0.3486
Epoch [39/50] - Loss: 0.3444
Epoch [40/50] - Loss: 0.3401
Epoch [41/50] - Loss: 0.3359
Epoch [42/50] - Loss: 0.3317
Epoch [43/50] - Loss: 0.3275
Epoch [44/50] - Loss: 0.3233
Epoch [45/50] - Loss: 0.3192
Epoch [46/50] - Loss: 0.3151
Epoch [47/50] - Loss: 0.3111
Epoch [48/50] - Loss: 0.3071
Epoch [49/50] - Loss: 0.3032
Epoch [50/50] - Loss: 0.2993
sum preds 3072
sum labels 5513
 - Test Metrics: Accuracy=0.8023, F1=0.6003, Recall=0.4674, Precision=0.8389
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_nnpu_nnpu_1804183541.csv.
Average F1 over valid seeds: 0.6321 ± 0.0274
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and nnpu, GCNConv,0.3: 0.6321 ± 0.0274
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5087
Epoch [2/50] - Loss: 0.5076
Epoch [3/50] - Loss: 0.5064
Epoch [4/50] - Loss: 0.5052
Epoch [5/50] - Loss: 0.5039
Epoch [6/50] - Loss: 0.5024
Epoch [7/50] - Loss: 0.5008
Epoch [8/50] - Loss: 0.4991
Epoch [9/50] - Loss: 0.4972
Epoch [10/50] - Loss: 0.4953
Epoch [11/50] - Loss: 0.4932
Epoch [12/50] - Loss: 0.4909
Epoch [13/50] - Loss: 0.4886
Epoch [14/50] - Loss: 0.4860
Epoch [15/50] - Loss: 0.4834
Epoch [16/50] - Loss: 0.4806
Epoch [17/50] - Loss: 0.4776
Epoch [18/50] - Loss: 0.4745
Epoch [19/50] - Loss: 0.4713
Epoch [20/50] - Loss: 0.4679
Epoch [21/50] - Loss: 0.4644
Epoch [22/50] - Loss: 0.4606
Epoch [23/50] - Loss: 0.4568
Epoch [24/50] - Loss: 0.4528
Epoch [25/50] - Loss: 0.4487
Epoch [26/50] - Loss: 0.4444
Epoch [27/50] - Loss: 0.4400
Epoch [28/50] - Loss: 0.4354
Epoch [29/50] - Loss: 0.4307
Epoch [30/50] - Loss: 0.4259
Epoch [31/50] - Loss: 0.4210
Epoch [32/50] - Loss: 0.4160
Epoch [33/50] - Loss: 0.4109
Epoch [34/50] - Loss: 0.4057
Epoch [35/50] - Loss: 0.4004
Epoch [36/50] - Loss: 0.3951
Epoch [37/50] - Loss: 0.3897
Epoch [38/50] - Loss: 0.3843
Epoch [39/50] - Loss: 0.3788
Epoch [40/50] - Loss: 0.3733
Epoch [41/50] - Loss: 0.3678
Epoch [42/50] - Loss: 0.3622
Epoch [43/50] - Loss: 0.3567
Epoch [44/50] - Loss: 0.3512
Epoch [45/50] - Loss: 0.3456
Epoch [46/50] - Loss: 0.3401
Epoch [47/50] - Loss: 0.3346
Epoch [48/50] - Loss: 0.3292
Epoch [49/50] - Loss: 0.3238
Epoch [50/50] - Loss: 0.3184
sum preds 3621
sum labels 6300
 - Test Metrics: Accuracy=0.7876, F1=0.6116, Recall=0.4816, Precision=0.8379
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4937
Epoch [2/50] - Loss: 0.4925
Epoch [3/50] - Loss: 0.4913
Epoch [4/50] - Loss: 0.4903
Epoch [5/50] - Loss: 0.4893
Epoch [6/50] - Loss: 0.4881
Epoch [7/50] - Loss: 0.4867
Epoch [8/50] - Loss: 0.4851
Epoch [9/50] - Loss: 0.4833
Epoch [10/50] - Loss: 0.4814
Epoch [11/50] - Loss: 0.4794
Epoch [12/50] - Loss: 0.4773
Epoch [13/50] - Loss: 0.4750
Epoch [14/50] - Loss: 0.4726
Epoch [15/50] - Loss: 0.4700
Epoch [16/50] - Loss: 0.4673
Epoch [17/50] - Loss: 0.4644
Epoch [18/50] - Loss: 0.4614
Epoch [19/50] - Loss: 0.4582
Epoch [20/50] - Loss: 0.4549
Epoch [21/50] - Loss: 0.4515
Epoch [22/50] - Loss: 0.4479
Epoch [23/50] - Loss: 0.4442
Epoch [24/50] - Loss: 0.4404
Epoch [25/50] - Loss: 0.4365
Epoch [26/50] - Loss: 0.4324
Epoch [27/50] - Loss: 0.4283
Epoch [28/50] - Loss: 0.4241
Epoch [29/50] - Loss: 0.4198
Epoch [30/50] - Loss: 0.4154
Epoch [31/50] - Loss: 0.4110
Epoch [32/50] - Loss: 0.4065
Epoch [33/50] - Loss: 0.4020
Epoch [34/50] - Loss: 0.3974
Epoch [35/50] - Loss: 0.3928
Epoch [36/50] - Loss: 0.3883
Epoch [37/50] - Loss: 0.3836
Epoch [38/50] - Loss: 0.3790
Epoch [39/50] - Loss: 0.3744
Epoch [40/50] - Loss: 0.3698
Epoch [41/50] - Loss: 0.3652
Epoch [42/50] - Loss: 0.3606
Epoch [43/50] - Loss: 0.3559
Epoch [44/50] - Loss: 0.3513
Epoch [45/50] - Loss: 0.3466
Epoch [46/50] - Loss: 0.3419
Epoch [47/50] - Loss: 0.3372
Epoch [48/50] - Loss: 0.3324
Epoch [49/50] - Loss: 0.3276
Epoch [50/50] - Loss: 0.3229
sum preds 2492
sum labels 6300
 - Test Metrics: Accuracy=0.7555, F1=0.4955, Recall=0.3457, Precision=0.8740
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5114
Epoch [2/50] - Loss: 0.5096
Epoch [3/50] - Loss: 0.5078
Epoch [4/50] - Loss: 0.5059
Epoch [5/50] - Loss: 0.5038
Epoch [6/50] - Loss: 0.5016
Epoch [7/50] - Loss: 0.4991
Epoch [8/50] - Loss: 0.4965
Epoch [9/50] - Loss: 0.4936
Epoch [10/50] - Loss: 0.4907
Epoch [11/50] - Loss: 0.4875
Epoch [12/50] - Loss: 0.4842
Epoch [13/50] - Loss: 0.4808
Epoch [14/50] - Loss: 0.4772
Epoch [15/50] - Loss: 0.4734
Epoch [16/50] - Loss: 0.4695
Epoch [17/50] - Loss: 0.4654
Epoch [18/50] - Loss: 0.4611
Epoch [19/50] - Loss: 0.4567
Epoch [20/50] - Loss: 0.4522
Epoch [21/50] - Loss: 0.4475
Epoch [22/50] - Loss: 0.4426
Epoch [23/50] - Loss: 0.4377
Epoch [24/50] - Loss: 0.4326
Epoch [25/50] - Loss: 0.4275
Epoch [26/50] - Loss: 0.4222
Epoch [27/50] - Loss: 0.4169
Epoch [28/50] - Loss: 0.4116
Epoch [29/50] - Loss: 0.4062
Epoch [30/50] - Loss: 0.4007
Epoch [31/50] - Loss: 0.3953
Epoch [32/50] - Loss: 0.3899
Epoch [33/50] - Loss: 0.3845
Epoch [34/50] - Loss: 0.3792
Epoch [35/50] - Loss: 0.3739
Epoch [36/50] - Loss: 0.3686
Epoch [37/50] - Loss: 0.3634
Epoch [38/50] - Loss: 0.3583
Epoch [39/50] - Loss: 0.3532
Epoch [40/50] - Loss: 0.3482
Epoch [41/50] - Loss: 0.3432
Epoch [42/50] - Loss: 0.3382
Epoch [43/50] - Loss: 0.3334
Epoch [44/50] - Loss: 0.3285
Epoch [45/50] - Loss: 0.3237
Epoch [46/50] - Loss: 0.3189
Epoch [47/50] - Loss: 0.3142
Epoch [48/50] - Loss: 0.3095
Epoch [49/50] - Loss: 0.3048
Epoch [50/50] - Loss: 0.3002
sum preds 2941
sum labels 6300
 - Test Metrics: Accuracy=0.7633, F1=0.5352, Recall=0.3925, Precision=0.8409
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_nnpu_nnpu_1804183544.csv.
Average F1 over valid seeds: 0.5474 ± 0.0482
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and nnpu, MLP,0.2: 0.5474 ± 0.0482
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4982
Epoch [3/50] - Loss: 0.4962
Epoch [4/50] - Loss: 0.4939
Epoch [5/50] - Loss: 0.4914
Epoch [6/50] - Loss: 0.4887
Epoch [7/50] - Loss: 0.4858
Epoch [8/50] - Loss: 0.4828
Epoch [9/50] - Loss: 0.4797
Epoch [10/50] - Loss: 0.4764
Epoch [11/50] - Loss: 0.4730
Epoch [12/50] - Loss: 0.4696
Epoch [13/50] - Loss: 0.4660
Epoch [14/50] - Loss: 0.4623
Epoch [15/50] - Loss: 0.4585
Epoch [16/50] - Loss: 0.4545
Epoch [17/50] - Loss: 0.4503
Epoch [18/50] - Loss: 0.4460
Epoch [19/50] - Loss: 0.4416
Epoch [20/50] - Loss: 0.4373
Epoch [21/50] - Loss: 0.4329
Epoch [22/50] - Loss: 0.4283
Epoch [23/50] - Loss: 0.4237
Epoch [24/50] - Loss: 0.4190
Epoch [25/50] - Loss: 0.4142
Epoch [26/50] - Loss: 0.4093
Epoch [27/50] - Loss: 0.4044
Epoch [28/50] - Loss: 0.3995
Epoch [29/50] - Loss: 0.3945
Epoch [30/50] - Loss: 0.3896
Epoch [31/50] - Loss: 0.3846
Epoch [32/50] - Loss: 0.3796
Epoch [33/50] - Loss: 0.3746
Epoch [34/50] - Loss: 0.3695
Epoch [35/50] - Loss: 0.3644
Epoch [36/50] - Loss: 0.3594
Epoch [37/50] - Loss: 0.3543
Epoch [38/50] - Loss: 0.3493
Epoch [39/50] - Loss: 0.3442
Epoch [40/50] - Loss: 0.3392
Epoch [41/50] - Loss: 0.3341
Epoch [42/50] - Loss: 0.3290
Epoch [43/50] - Loss: 0.3240
Epoch [44/50] - Loss: 0.3189
Epoch [45/50] - Loss: 0.3138
Epoch [46/50] - Loss: 0.3088
Epoch [47/50] - Loss: 0.3039
Epoch [48/50] - Loss: 0.2989
Epoch [49/50] - Loss: 0.2940
Epoch [50/50] - Loss: 0.2891
sum preds 3973
sum labels 6300
 - Test Metrics: Accuracy=0.8004, F1=0.6475, Recall=0.5279, Precision=0.8372
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4964
Epoch [3/50] - Loss: 0.4920
Epoch [4/50] - Loss: 0.4873
Epoch [5/50] - Loss: 0.4824
Epoch [6/50] - Loss: 0.4775
Epoch [7/50] - Loss: 0.4724
Epoch [8/50] - Loss: 0.4673
Epoch [9/50] - Loss: 0.4620
Epoch [10/50] - Loss: 0.4568
Epoch [11/50] - Loss: 0.4514
Epoch [12/50] - Loss: 0.4461
Epoch [13/50] - Loss: 0.4408
Epoch [14/50] - Loss: 0.4356
Epoch [15/50] - Loss: 0.4304
Epoch [16/50] - Loss: 0.4254
Epoch [17/50] - Loss: 0.4205
Epoch [18/50] - Loss: 0.4158
Epoch [19/50] - Loss: 0.4112
Epoch [20/50] - Loss: 0.4067
Epoch [21/50] - Loss: 0.4024
Epoch [22/50] - Loss: 0.3983
Epoch [23/50] - Loss: 0.3943
Epoch [24/50] - Loss: 0.3904
Epoch [25/50] - Loss: 0.3867
Epoch [26/50] - Loss: 0.3832
Epoch [27/50] - Loss: 0.3797
Epoch [28/50] - Loss: 0.3763
Epoch [29/50] - Loss: 0.3730
Epoch [30/50] - Loss: 0.3697
Epoch [31/50] - Loss: 0.3664
Epoch [32/50] - Loss: 0.3631
Epoch [33/50] - Loss: 0.3598
Epoch [34/50] - Loss: 0.3563
Epoch [35/50] - Loss: 0.3528
Epoch [36/50] - Loss: 0.3493
Epoch [37/50] - Loss: 0.3456
Epoch [38/50] - Loss: 0.3419
Epoch [39/50] - Loss: 0.3381
Epoch [40/50] - Loss: 0.3343
Epoch [41/50] - Loss: 0.3305
Epoch [42/50] - Loss: 0.3266
Epoch [43/50] - Loss: 0.3229
Epoch [44/50] - Loss: 0.3192
Epoch [45/50] - Loss: 0.3155
Epoch [46/50] - Loss: 0.3120
Epoch [47/50] - Loss: 0.3085
Epoch [48/50] - Loss: 0.3050
Epoch [49/50] - Loss: 0.3016
Epoch [50/50] - Loss: 0.2981
sum preds 3356
sum labels 6300
 - Test Metrics: Accuracy=0.7846, F1=0.5953, Recall=0.4562, Precision=0.8564
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4955
Epoch [3/50] - Loss: 0.4911
Epoch [4/50] - Loss: 0.4866
Epoch [5/50] - Loss: 0.4820
Epoch [6/50] - Loss: 0.4772
Epoch [7/50] - Loss: 0.4723
Epoch [8/50] - Loss: 0.4673
Epoch [9/50] - Loss: 0.4621
Epoch [10/50] - Loss: 0.4568
Epoch [11/50] - Loss: 0.4513
Epoch [12/50] - Loss: 0.4459
Epoch [13/50] - Loss: 0.4403
Epoch [14/50] - Loss: 0.4348
Epoch [15/50] - Loss: 0.4293
Epoch [16/50] - Loss: 0.4238
Epoch [17/50] - Loss: 0.4184
Epoch [18/50] - Loss: 0.4131
Epoch [19/50] - Loss: 0.4077
Epoch [20/50] - Loss: 0.4024
Epoch [21/50] - Loss: 0.3970
Epoch [22/50] - Loss: 0.3917
Epoch [23/50] - Loss: 0.3864
Epoch [24/50] - Loss: 0.3812
Epoch [25/50] - Loss: 0.3760
Epoch [26/50] - Loss: 0.3708
Epoch [27/50] - Loss: 0.3655
Epoch [28/50] - Loss: 0.3603
Epoch [29/50] - Loss: 0.3551
Epoch [30/50] - Loss: 0.3498
Epoch [31/50] - Loss: 0.3445
Epoch [32/50] - Loss: 0.3392
Epoch [33/50] - Loss: 0.3338
Epoch [34/50] - Loss: 0.3284
Epoch [35/50] - Loss: 0.3230
Epoch [36/50] - Loss: 0.3177
Epoch [37/50] - Loss: 0.3123
Epoch [38/50] - Loss: 0.3070
Epoch [39/50] - Loss: 0.3017
Epoch [40/50] - Loss: 0.2965
Epoch [41/50] - Loss: 0.2914
Epoch [42/50] - Loss: 0.2863
Epoch [43/50] - Loss: 0.2814
Epoch [44/50] - Loss: 0.2765
Epoch [45/50] - Loss: 0.2718
Epoch [46/50] - Loss: 0.2672
Epoch [47/50] - Loss: 0.2626
Epoch [48/50] - Loss: 0.2581
Epoch [49/50] - Loss: 0.2537
Epoch [50/50] - Loss: 0.2494
sum preds 4384
sum labels 6300
 - Test Metrics: Accuracy=0.7973, F1=0.6557, Recall=0.5560, Precision=0.7990
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_nnpu_nnpu_1804183545.csv.
Average F1 over valid seeds: 0.6328 ± 0.0268
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and nnpu, GATConv,0.2: 0.6328 ± 0.0268
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5002
Epoch [2/50] - Loss: 0.4985
Epoch [3/50] - Loss: 0.4968
Epoch [4/50] - Loss: 0.4948
Epoch [5/50] - Loss: 0.4927
Epoch [6/50] - Loss: 0.4904
Epoch [7/50] - Loss: 0.4879
Epoch [8/50] - Loss: 0.4854
Epoch [9/50] - Loss: 0.4829
Epoch [10/50] - Loss: 0.4802
Epoch [11/50] - Loss: 0.4774
Epoch [12/50] - Loss: 0.4746
Epoch [13/50] - Loss: 0.4716
Epoch [14/50] - Loss: 0.4686
Epoch [15/50] - Loss: 0.4656
Epoch [16/50] - Loss: 0.4625
Epoch [17/50] - Loss: 0.4593
Epoch [18/50] - Loss: 0.4560
Epoch [19/50] - Loss: 0.4526
Epoch [20/50] - Loss: 0.4491
Epoch [21/50] - Loss: 0.4456
Epoch [22/50] - Loss: 0.4421
Epoch [23/50] - Loss: 0.4385
Epoch [24/50] - Loss: 0.4348
Epoch [25/50] - Loss: 0.4311
Epoch [26/50] - Loss: 0.4272
Epoch [27/50] - Loss: 0.4234
Epoch [28/50] - Loss: 0.4195
Epoch [29/50] - Loss: 0.4155
Epoch [30/50] - Loss: 0.4115
Epoch [31/50] - Loss: 0.4075
Epoch [32/50] - Loss: 0.4035
Epoch [33/50] - Loss: 0.3994
Epoch [34/50] - Loss: 0.3952
Epoch [35/50] - Loss: 0.3910
Epoch [36/50] - Loss: 0.3868
Epoch [37/50] - Loss: 0.3824
Epoch [38/50] - Loss: 0.3780
Epoch [39/50] - Loss: 0.3735
Epoch [40/50] - Loss: 0.3691
Epoch [41/50] - Loss: 0.3646
Epoch [42/50] - Loss: 0.3602
Epoch [43/50] - Loss: 0.3559
Epoch [44/50] - Loss: 0.3515
Epoch [45/50] - Loss: 0.3471
Epoch [46/50] - Loss: 0.3426
Epoch [47/50] - Loss: 0.3382
Epoch [48/50] - Loss: 0.3338
Epoch [49/50] - Loss: 0.3294
Epoch [50/50] - Loss: 0.3250
sum preds 4052
sum labels 6300
 - Test Metrics: Accuracy=0.8083, F1=0.6640, Recall=0.5456, Precision=0.8482
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4973
Epoch [3/50] - Loss: 0.4945
Epoch [4/50] - Loss: 0.4917
Epoch [5/50] - Loss: 0.4887
Epoch [6/50] - Loss: 0.4855
Epoch [7/50] - Loss: 0.4822
Epoch [8/50] - Loss: 0.4789
Epoch [9/50] - Loss: 0.4754
Epoch [10/50] - Loss: 0.4719
Epoch [11/50] - Loss: 0.4682
Epoch [12/50] - Loss: 0.4646
Epoch [13/50] - Loss: 0.4609
Epoch [14/50] - Loss: 0.4571
Epoch [15/50] - Loss: 0.4534
Epoch [16/50] - Loss: 0.4495
Epoch [17/50] - Loss: 0.4457
Epoch [18/50] - Loss: 0.4418
Epoch [19/50] - Loss: 0.4378
Epoch [20/50] - Loss: 0.4339
Epoch [21/50] - Loss: 0.4299
Epoch [22/50] - Loss: 0.4259
Epoch [23/50] - Loss: 0.4218
Epoch [24/50] - Loss: 0.4177
Epoch [25/50] - Loss: 0.4136
Epoch [26/50] - Loss: 0.4095
Epoch [27/50] - Loss: 0.4053
Epoch [28/50] - Loss: 0.4012
Epoch [29/50] - Loss: 0.3972
Epoch [30/50] - Loss: 0.3931
Epoch [31/50] - Loss: 0.3890
Epoch [32/50] - Loss: 0.3849
Epoch [33/50] - Loss: 0.3808
Epoch [34/50] - Loss: 0.3768
Epoch [35/50] - Loss: 0.3728
Epoch [36/50] - Loss: 0.3688
Epoch [37/50] - Loss: 0.3648
Epoch [38/50] - Loss: 0.3607
Epoch [39/50] - Loss: 0.3567
Epoch [40/50] - Loss: 0.3527
Epoch [41/50] - Loss: 0.3487
Epoch [42/50] - Loss: 0.3447
Epoch [43/50] - Loss: 0.3407
Epoch [44/50] - Loss: 0.3367
Epoch [45/50] - Loss: 0.3327
Epoch [46/50] - Loss: 0.3288
Epoch [47/50] - Loss: 0.3250
Epoch [48/50] - Loss: 0.3211
Epoch [49/50] - Loss: 0.3174
Epoch [50/50] - Loss: 0.3136
sum preds 3488
sum labels 6300
 - Test Metrics: Accuracy=0.7903, F1=0.6114, Recall=0.4749, Precision=0.8578
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4970
Epoch [3/50] - Loss: 0.4942
Epoch [4/50] - Loss: 0.4910
Epoch [5/50] - Loss: 0.4875
Epoch [6/50] - Loss: 0.4837
Epoch [7/50] - Loss: 0.4799
Epoch [8/50] - Loss: 0.4760
Epoch [9/50] - Loss: 0.4721
Epoch [10/50] - Loss: 0.4681
Epoch [11/50] - Loss: 0.4640
Epoch [12/50] - Loss: 0.4598
Epoch [13/50] - Loss: 0.4557
Epoch [14/50] - Loss: 0.4515
Epoch [15/50] - Loss: 0.4473
Epoch [16/50] - Loss: 0.4431
Epoch [17/50] - Loss: 0.4389
Epoch [18/50] - Loss: 0.4346
Epoch [19/50] - Loss: 0.4304
Epoch [20/50] - Loss: 0.4261
Epoch [21/50] - Loss: 0.4218
Epoch [22/50] - Loss: 0.4175
Epoch [23/50] - Loss: 0.4132
Epoch [24/50] - Loss: 0.4090
Epoch [25/50] - Loss: 0.4049
Epoch [26/50] - Loss: 0.4008
Epoch [27/50] - Loss: 0.3967
Epoch [28/50] - Loss: 0.3927
Epoch [29/50] - Loss: 0.3886
Epoch [30/50] - Loss: 0.3846
Epoch [31/50] - Loss: 0.3805
Epoch [32/50] - Loss: 0.3765
Epoch [33/50] - Loss: 0.3724
Epoch [34/50] - Loss: 0.3683
Epoch [35/50] - Loss: 0.3643
Epoch [36/50] - Loss: 0.3602
Epoch [37/50] - Loss: 0.3561
Epoch [38/50] - Loss: 0.3520
Epoch [39/50] - Loss: 0.3479
Epoch [40/50] - Loss: 0.3437
Epoch [41/50] - Loss: 0.3396
Epoch [42/50] - Loss: 0.3355
Epoch [43/50] - Loss: 0.3315
Epoch [44/50] - Loss: 0.3274
Epoch [45/50] - Loss: 0.3234
Epoch [46/50] - Loss: 0.3195
Epoch [47/50] - Loss: 0.3156
Epoch [48/50] - Loss: 0.3117
Epoch [49/50] - Loss: 0.3079
Epoch [50/50] - Loss: 0.3041
sum preds 3380
sum labels 6300
 - Test Metrics: Accuracy=0.7866, F1=0.6000, Recall=0.4610, Precision=0.8592
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_nnpu_nnpu_1804183548.csv.
Average F1 over valid seeds: 0.6251 ± 0.0279
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and nnpu, GCNConv,0.2: 0.6251 ± 0.0279
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4995
Epoch [3/50] - Loss: 0.4987
Epoch [4/50] - Loss: 0.4977
Epoch [5/50] - Loss: 0.4966
Epoch [6/50] - Loss: 0.4953
Epoch [7/50] - Loss: 0.4939
Epoch [8/50] - Loss: 0.4924
Epoch [9/50] - Loss: 0.4908
Epoch [10/50] - Loss: 0.4890
Epoch [11/50] - Loss: 0.4872
Epoch [12/50] - Loss: 0.4852
Epoch [13/50] - Loss: 0.4831
Epoch [14/50] - Loss: 0.4808
Epoch [15/50] - Loss: 0.4783
Epoch [16/50] - Loss: 0.4758
Epoch [17/50] - Loss: 0.4731
Epoch [18/50] - Loss: 0.4702
Epoch [19/50] - Loss: 0.4672
Epoch [20/50] - Loss: 0.4641
Epoch [21/50] - Loss: 0.4608
Epoch [22/50] - Loss: 0.4573
Epoch [23/50] - Loss: 0.4537
Epoch [24/50] - Loss: 0.4499
Epoch [25/50] - Loss: 0.4459
Epoch [26/50] - Loss: 0.4418
Epoch [27/50] - Loss: 0.4376
Epoch [28/50] - Loss: 0.4332
Epoch [29/50] - Loss: 0.4286
Epoch [30/50] - Loss: 0.4239
Epoch [31/50] - Loss: 0.4191
Epoch [32/50] - Loss: 0.4141
Epoch [33/50] - Loss: 0.4090
Epoch [34/50] - Loss: 0.4038
Epoch [35/50] - Loss: 0.3984
Epoch [36/50] - Loss: 0.3930
Epoch [37/50] - Loss: 0.3875
Epoch [38/50] - Loss: 0.3819
Epoch [39/50] - Loss: 0.3762
Epoch [40/50] - Loss: 0.3705
Epoch [41/50] - Loss: 0.3647
Epoch [42/50] - Loss: 0.3589
Epoch [43/50] - Loss: 0.3531
Epoch [44/50] - Loss: 0.3473
Epoch [45/50] - Loss: 0.3415
Epoch [46/50] - Loss: 0.3357
Epoch [47/50] - Loss: 0.3300
Epoch [48/50] - Loss: 0.3242
Epoch [49/50] - Loss: 0.3186
Epoch [50/50] - Loss: 0.3130
sum preds 5714
sum labels 4725
 - Test Metrics: Accuracy=0.8063, F1=0.6926, Recall=0.7651, Precision=0.6327
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4995
Epoch [3/50] - Loss: 0.4988
Epoch [4/50] - Loss: 0.4979
Epoch [5/50] - Loss: 0.4969
Epoch [6/50] - Loss: 0.4958
Epoch [7/50] - Loss: 0.4945
Epoch [8/50] - Loss: 0.4931
Epoch [9/50] - Loss: 0.4915
Epoch [10/50] - Loss: 0.4898
Epoch [11/50] - Loss: 0.4879
Epoch [12/50] - Loss: 0.4859
Epoch [13/50] - Loss: 0.4838
Epoch [14/50] - Loss: 0.4815
Epoch [15/50] - Loss: 0.4790
Epoch [16/50] - Loss: 0.4764
Epoch [17/50] - Loss: 0.4737
Epoch [18/50] - Loss: 0.4708
Epoch [19/50] - Loss: 0.4678
Epoch [20/50] - Loss: 0.4646
Epoch [21/50] - Loss: 0.4612
Epoch [22/50] - Loss: 0.4577
Epoch [23/50] - Loss: 0.4540
Epoch [24/50] - Loss: 0.4502
Epoch [25/50] - Loss: 0.4462
Epoch [26/50] - Loss: 0.4421
Epoch [27/50] - Loss: 0.4378
Epoch [28/50] - Loss: 0.4333
Epoch [29/50] - Loss: 0.4287
Epoch [30/50] - Loss: 0.4240
Epoch [31/50] - Loss: 0.4191
Epoch [32/50] - Loss: 0.4141
Epoch [33/50] - Loss: 0.4090
Epoch [34/50] - Loss: 0.4037
Epoch [35/50] - Loss: 0.3984
Epoch [36/50] - Loss: 0.3929
Epoch [37/50] - Loss: 0.3874
Epoch [38/50] - Loss: 0.3818
Epoch [39/50] - Loss: 0.3762
Epoch [40/50] - Loss: 0.3704
Epoch [41/50] - Loss: 0.3647
Epoch [42/50] - Loss: 0.3589
Epoch [43/50] - Loss: 0.3531
Epoch [44/50] - Loss: 0.3474
Epoch [45/50] - Loss: 0.3416
Epoch [46/50] - Loss: 0.3359
Epoch [47/50] - Loss: 0.3302
Epoch [48/50] - Loss: 0.3245
Epoch [49/50] - Loss: 0.3189
Epoch [50/50] - Loss: 0.3134
sum preds 5392
sum labels 4725
 - Test Metrics: Accuracy=0.8088, F1=0.6870, Recall=0.7354, Precision=0.6445
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4990
Epoch [3/50] - Loss: 0.4978
Epoch [4/50] - Loss: 0.4963
Epoch [5/50] - Loss: 0.4948
Epoch [6/50] - Loss: 0.4930
Epoch [7/50] - Loss: 0.4912
Epoch [8/50] - Loss: 0.4892
Epoch [9/50] - Loss: 0.4870
Epoch [10/50] - Loss: 0.4848
Epoch [11/50] - Loss: 0.4824
Epoch [12/50] - Loss: 0.4798
Epoch [13/50] - Loss: 0.4772
Epoch [14/50] - Loss: 0.4743
Epoch [15/50] - Loss: 0.4713
Epoch [16/50] - Loss: 0.4682
Epoch [17/50] - Loss: 0.4649
Epoch [18/50] - Loss: 0.4615
Epoch [19/50] - Loss: 0.4579
Epoch [20/50] - Loss: 0.4542
Epoch [21/50] - Loss: 0.4503
Epoch [22/50] - Loss: 0.4462
Epoch [23/50] - Loss: 0.4421
Epoch [24/50] - Loss: 0.4377
Epoch [25/50] - Loss: 0.4333
Epoch [26/50] - Loss: 0.4287
Epoch [27/50] - Loss: 0.4239
Epoch [28/50] - Loss: 0.4190
Epoch [29/50] - Loss: 0.4141
Epoch [30/50] - Loss: 0.4090
Epoch [31/50] - Loss: 0.4037
Epoch [32/50] - Loss: 0.3984
Epoch [33/50] - Loss: 0.3930
Epoch [34/50] - Loss: 0.3875
Epoch [35/50] - Loss: 0.3820
Epoch [36/50] - Loss: 0.3763
Epoch [37/50] - Loss: 0.3707
Epoch [38/50] - Loss: 0.3649
Epoch [39/50] - Loss: 0.3592
Epoch [40/50] - Loss: 0.3534
Epoch [41/50] - Loss: 0.3477
Epoch [42/50] - Loss: 0.3419
Epoch [43/50] - Loss: 0.3361
Epoch [44/50] - Loss: 0.3304
Epoch [45/50] - Loss: 0.3247
Epoch [46/50] - Loss: 0.3191
Epoch [47/50] - Loss: 0.3135
Epoch [48/50] - Loss: 0.3080
Epoch [49/50] - Loss: 0.3025
Epoch [50/50] - Loss: 0.2971
sum preds 5083
sum labels 4725
 - Test Metrics: Accuracy=0.8143, F1=0.6864, Recall=0.7124, Precision=0.6622
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_imbnnpu_imbnnpu_1804183550.csv.
Average F1 over valid seeds: 0.6886 ± 0.0028
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and imbnnpu, MLP,0.4: 0.6886 ± 0.0028
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4981
Epoch [3/50] - Loss: 0.4963
Epoch [4/50] - Loss: 0.4942
Epoch [5/50] - Loss: 0.4918
Epoch [6/50] - Loss: 0.4892
Epoch [7/50] - Loss: 0.4865
Epoch [8/50] - Loss: 0.4838
Epoch [9/50] - Loss: 0.4810
Epoch [10/50] - Loss: 0.4780
Epoch [11/50] - Loss: 0.4749
Epoch [12/50] - Loss: 0.4716
Epoch [13/50] - Loss: 0.4683
Epoch [14/50] - Loss: 0.4648
Epoch [15/50] - Loss: 0.4612
Epoch [16/50] - Loss: 0.4574
Epoch [17/50] - Loss: 0.4536
Epoch [18/50] - Loss: 0.4496
Epoch [19/50] - Loss: 0.4455
Epoch [20/50] - Loss: 0.4412
Epoch [21/50] - Loss: 0.4368
Epoch [22/50] - Loss: 0.4323
Epoch [23/50] - Loss: 0.4276
Epoch [24/50] - Loss: 0.4228
Epoch [25/50] - Loss: 0.4178
Epoch [26/50] - Loss: 0.4127
Epoch [27/50] - Loss: 0.4075
Epoch [28/50] - Loss: 0.4022
Epoch [29/50] - Loss: 0.3968
Epoch [30/50] - Loss: 0.3912
Epoch [31/50] - Loss: 0.3856
Epoch [32/50] - Loss: 0.3798
Epoch [33/50] - Loss: 0.3740
Epoch [34/50] - Loss: 0.3680
Epoch [35/50] - Loss: 0.3620
Epoch [36/50] - Loss: 0.3559
Epoch [37/50] - Loss: 0.3497
Epoch [38/50] - Loss: 0.3435
Epoch [39/50] - Loss: 0.3373
Epoch [40/50] - Loss: 0.3310
Epoch [41/50] - Loss: 0.3248
Epoch [42/50] - Loss: 0.3184
Epoch [43/50] - Loss: 0.3121
Epoch [44/50] - Loss: 0.3059
Epoch [45/50] - Loss: 0.2996
Epoch [46/50] - Loss: 0.2933
Epoch [47/50] - Loss: 0.2871
Epoch [48/50] - Loss: 0.2810
Epoch [49/50] - Loss: 0.2749
Epoch [50/50] - Loss: 0.2689
sum preds 5246
sum labels 4725
 - Test Metrics: Accuracy=0.8323, F1=0.7213, Recall=0.7611, Precision=0.6855
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5008
Epoch [2/50] - Loss: 0.4987
Epoch [3/50] - Loss: 0.4967
Epoch [4/50] - Loss: 0.4943
Epoch [5/50] - Loss: 0.4917
Epoch [6/50] - Loss: 0.4888
Epoch [7/50] - Loss: 0.4856
Epoch [8/50] - Loss: 0.4821
Epoch [9/50] - Loss: 0.4784
Epoch [10/50] - Loss: 0.4746
Epoch [11/50] - Loss: 0.4708
Epoch [12/50] - Loss: 0.4668
Epoch [13/50] - Loss: 0.4628
Epoch [14/50] - Loss: 0.4586
Epoch [15/50] - Loss: 0.4544
Epoch [16/50] - Loss: 0.4500
Epoch [17/50] - Loss: 0.4456
Epoch [18/50] - Loss: 0.4410
Epoch [19/50] - Loss: 0.4363
Epoch [20/50] - Loss: 0.4316
Epoch [21/50] - Loss: 0.4268
Epoch [22/50] - Loss: 0.4219
Epoch [23/50] - Loss: 0.4169
Epoch [24/50] - Loss: 0.4119
Epoch [25/50] - Loss: 0.4068
Epoch [26/50] - Loss: 0.4017
Epoch [27/50] - Loss: 0.3966
Epoch [28/50] - Loss: 0.3914
Epoch [29/50] - Loss: 0.3862
Epoch [30/50] - Loss: 0.3810
Epoch [31/50] - Loss: 0.3757
Epoch [32/50] - Loss: 0.3704
Epoch [33/50] - Loss: 0.3651
Epoch [34/50] - Loss: 0.3597
Epoch [35/50] - Loss: 0.3544
Epoch [36/50] - Loss: 0.3491
Epoch [37/50] - Loss: 0.3437
Epoch [38/50] - Loss: 0.3384
Epoch [39/50] - Loss: 0.3331
Epoch [40/50] - Loss: 0.3278
Epoch [41/50] - Loss: 0.3225
Epoch [42/50] - Loss: 0.3172
Epoch [43/50] - Loss: 0.3120
Epoch [44/50] - Loss: 0.3068
Epoch [45/50] - Loss: 0.3017
Epoch [46/50] - Loss: 0.2966
Epoch [47/50] - Loss: 0.2916
Epoch [48/50] - Loss: 0.2866
Epoch [49/50] - Loss: 0.2817
Epoch [50/50] - Loss: 0.2769
sum preds 4186
sum labels 4725
 - Test Metrics: Accuracy=0.8550, F1=0.7303, Recall=0.6887, Precision=0.7774
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4972
Epoch [3/50] - Loss: 0.4943
Epoch [4/50] - Loss: 0.4909
Epoch [5/50] - Loss: 0.4870
Epoch [6/50] - Loss: 0.4829
Epoch [7/50] - Loss: 0.4787
Epoch [8/50] - Loss: 0.4744
Epoch [9/50] - Loss: 0.4701
Epoch [10/50] - Loss: 0.4656
Epoch [11/50] - Loss: 0.4611
Epoch [12/50] - Loss: 0.4564
Epoch [13/50] - Loss: 0.4517
Epoch [14/50] - Loss: 0.4468
Epoch [15/50] - Loss: 0.4417
Epoch [16/50] - Loss: 0.4366
Epoch [17/50] - Loss: 0.4314
Epoch [18/50] - Loss: 0.4260
Epoch [19/50] - Loss: 0.4206
Epoch [20/50] - Loss: 0.4150
Epoch [21/50] - Loss: 0.4094
Epoch [22/50] - Loss: 0.4037
Epoch [23/50] - Loss: 0.3978
Epoch [24/50] - Loss: 0.3919
Epoch [25/50] - Loss: 0.3860
Epoch [26/50] - Loss: 0.3799
Epoch [27/50] - Loss: 0.3738
Epoch [28/50] - Loss: 0.3677
Epoch [29/50] - Loss: 0.3615
Epoch [30/50] - Loss: 0.3553
Epoch [31/50] - Loss: 0.3490
Epoch [32/50] - Loss: 0.3428
Epoch [33/50] - Loss: 0.3365
Epoch [34/50] - Loss: 0.3303
Epoch [35/50] - Loss: 0.3241
Epoch [36/50] - Loss: 0.3179
Epoch [37/50] - Loss: 0.3117
Epoch [38/50] - Loss: 0.3055
Epoch [39/50] - Loss: 0.2994
Epoch [40/50] - Loss: 0.2934
Epoch [41/50] - Loss: 0.2874
Epoch [42/50] - Loss: 0.2814
Epoch [43/50] - Loss: 0.2756
Epoch [44/50] - Loss: 0.2697
Epoch [45/50] - Loss: 0.2640
Epoch [46/50] - Loss: 0.2583
Epoch [47/50] - Loss: 0.2528
Epoch [48/50] - Loss: 0.2473
Epoch [49/50] - Loss: 0.2418
Epoch [50/50] - Loss: 0.2365
sum preds 4834
sum labels 4725
 - Test Metrics: Accuracy=0.8383, F1=0.7197, Recall=0.7280, Precision=0.7116
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_imbnnpu_imbnnpu_1804183552.csv.
Average F1 over valid seeds: 0.7238 ± 0.0047
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and imbnnpu, GATConv,0.4: 0.7238 ± 0.0047
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4985
Epoch [3/50] - Loss: 0.4968
Epoch [4/50] - Loss: 0.4949
Epoch [5/50] - Loss: 0.4928
Epoch [6/50] - Loss: 0.4907
Epoch [7/50] - Loss: 0.4884
Epoch [8/50] - Loss: 0.4860
Epoch [9/50] - Loss: 0.4833
Epoch [10/50] - Loss: 0.4804
Epoch [11/50] - Loss: 0.4774
Epoch [12/50] - Loss: 0.4744
Epoch [13/50] - Loss: 0.4714
Epoch [14/50] - Loss: 0.4683
Epoch [15/50] - Loss: 0.4651
Epoch [16/50] - Loss: 0.4618
Epoch [17/50] - Loss: 0.4584
Epoch [18/50] - Loss: 0.4549
Epoch [19/50] - Loss: 0.4513
Epoch [20/50] - Loss: 0.4477
Epoch [21/50] - Loss: 0.4439
Epoch [22/50] - Loss: 0.4400
Epoch [23/50] - Loss: 0.4361
Epoch [24/50] - Loss: 0.4321
Epoch [25/50] - Loss: 0.4280
Epoch [26/50] - Loss: 0.4239
Epoch [27/50] - Loss: 0.4197
Epoch [28/50] - Loss: 0.4154
Epoch [29/50] - Loss: 0.4110
Epoch [30/50] - Loss: 0.4066
Epoch [31/50] - Loss: 0.4022
Epoch [32/50] - Loss: 0.3977
Epoch [33/50] - Loss: 0.3931
Epoch [34/50] - Loss: 0.3885
Epoch [35/50] - Loss: 0.3839
Epoch [36/50] - Loss: 0.3792
Epoch [37/50] - Loss: 0.3745
Epoch [38/50] - Loss: 0.3698
Epoch [39/50] - Loss: 0.3650
Epoch [40/50] - Loss: 0.3603
Epoch [41/50] - Loss: 0.3555
Epoch [42/50] - Loss: 0.3508
Epoch [43/50] - Loss: 0.3460
Epoch [44/50] - Loss: 0.3413
Epoch [45/50] - Loss: 0.3365
Epoch [46/50] - Loss: 0.3318
Epoch [47/50] - Loss: 0.3271
Epoch [48/50] - Loss: 0.3224
Epoch [49/50] - Loss: 0.3178
Epoch [50/50] - Loss: 0.3132
sum preds 5186
sum labels 4725
 - Test Metrics: Accuracy=0.8425, F1=0.7368, Recall=0.7727, Precision=0.7040
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4984
Epoch [3/50] - Loss: 0.4965
Epoch [4/50] - Loss: 0.4942
Epoch [5/50] - Loss: 0.4917
Epoch [6/50] - Loss: 0.4889
Epoch [7/50] - Loss: 0.4859
Epoch [8/50] - Loss: 0.4829
Epoch [9/50] - Loss: 0.4797
Epoch [10/50] - Loss: 0.4765
Epoch [11/50] - Loss: 0.4731
Epoch [12/50] - Loss: 0.4696
Epoch [13/50] - Loss: 0.4660
Epoch [14/50] - Loss: 0.4623
Epoch [15/50] - Loss: 0.4586
Epoch [16/50] - Loss: 0.4548
Epoch [17/50] - Loss: 0.4510
Epoch [18/50] - Loss: 0.4471
Epoch [19/50] - Loss: 0.4430
Epoch [20/50] - Loss: 0.4389
Epoch [21/50] - Loss: 0.4347
Epoch [22/50] - Loss: 0.4305
Epoch [23/50] - Loss: 0.4262
Epoch [24/50] - Loss: 0.4218
Epoch [25/50] - Loss: 0.4174
Epoch [26/50] - Loss: 0.4129
Epoch [27/50] - Loss: 0.4084
Epoch [28/50] - Loss: 0.4039
Epoch [29/50] - Loss: 0.3993
Epoch [30/50] - Loss: 0.3946
Epoch [31/50] - Loss: 0.3900
Epoch [32/50] - Loss: 0.3853
Epoch [33/50] - Loss: 0.3806
Epoch [34/50] - Loss: 0.3759
Epoch [35/50] - Loss: 0.3712
Epoch [36/50] - Loss: 0.3665
Epoch [37/50] - Loss: 0.3618
Epoch [38/50] - Loss: 0.3571
Epoch [39/50] - Loss: 0.3524
Epoch [40/50] - Loss: 0.3477
Epoch [41/50] - Loss: 0.3430
Epoch [42/50] - Loss: 0.3384
Epoch [43/50] - Loss: 0.3338
Epoch [44/50] - Loss: 0.3292
Epoch [45/50] - Loss: 0.3247
Epoch [46/50] - Loss: 0.3202
Epoch [47/50] - Loss: 0.3157
Epoch [48/50] - Loss: 0.3113
Epoch [49/50] - Loss: 0.3069
Epoch [50/50] - Loss: 0.3026
sum preds 4839
sum labels 4725
 - Test Metrics: Accuracy=0.8460, F1=0.7332, Recall=0.7420, Precision=0.7245
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4985
Epoch [3/50] - Loss: 0.4965
Epoch [4/50] - Loss: 0.4942
Epoch [5/50] - Loss: 0.4917
Epoch [6/50] - Loss: 0.4889
Epoch [7/50] - Loss: 0.4861
Epoch [8/50] - Loss: 0.4833
Epoch [9/50] - Loss: 0.4804
Epoch [10/50] - Loss: 0.4774
Epoch [11/50] - Loss: 0.4743
Epoch [12/50] - Loss: 0.4711
Epoch [13/50] - Loss: 0.4676
Epoch [14/50] - Loss: 0.4641
Epoch [15/50] - Loss: 0.4604
Epoch [16/50] - Loss: 0.4566
Epoch [17/50] - Loss: 0.4529
Epoch [18/50] - Loss: 0.4491
Epoch [19/50] - Loss: 0.4452
Epoch [20/50] - Loss: 0.4412
Epoch [21/50] - Loss: 0.4371
Epoch [22/50] - Loss: 0.4330
Epoch [23/50] - Loss: 0.4287
Epoch [24/50] - Loss: 0.4244
Epoch [25/50] - Loss: 0.4200
Epoch [26/50] - Loss: 0.4156
Epoch [27/50] - Loss: 0.4110
Epoch [28/50] - Loss: 0.4065
Epoch [29/50] - Loss: 0.4018
Epoch [30/50] - Loss: 0.3972
Epoch [31/50] - Loss: 0.3925
Epoch [32/50] - Loss: 0.3877
Epoch [33/50] - Loss: 0.3830
Epoch [34/50] - Loss: 0.3782
Epoch [35/50] - Loss: 0.3734
Epoch [36/50] - Loss: 0.3685
Epoch [37/50] - Loss: 0.3637
Epoch [38/50] - Loss: 0.3589
Epoch [39/50] - Loss: 0.3540
Epoch [40/50] - Loss: 0.3492
Epoch [41/50] - Loss: 0.3444
Epoch [42/50] - Loss: 0.3396
Epoch [43/50] - Loss: 0.3348
Epoch [44/50] - Loss: 0.3300
Epoch [45/50] - Loss: 0.3251
Epoch [46/50] - Loss: 0.3203
Epoch [47/50] - Loss: 0.3154
Epoch [48/50] - Loss: 0.3106
Epoch [49/50] - Loss: 0.3059
Epoch [50/50] - Loss: 0.3012
sum preds 4853
sum labels 4725
 - Test Metrics: Accuracy=0.8399, F1=0.7231, Recall=0.7329, Precision=0.7136
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_imbnnpu_imbnnpu_1804183555.csv.
Average F1 over valid seeds: 0.7310 ± 0.0058
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and imbnnpu, GCNConv,0.4: 0.7310 ± 0.0058
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4995
Epoch [3/50] - Loss: 0.4988
Epoch [4/50] - Loss: 0.4978
Epoch [5/50] - Loss: 0.4967
Epoch [6/50] - Loss: 0.4954
Epoch [7/50] - Loss: 0.4941
Epoch [8/50] - Loss: 0.4926
Epoch [9/50] - Loss: 0.4911
Epoch [10/50] - Loss: 0.4894
Epoch [11/50] - Loss: 0.4876
Epoch [12/50] - Loss: 0.4857
Epoch [13/50] - Loss: 0.4836
Epoch [14/50] - Loss: 0.4814
Epoch [15/50] - Loss: 0.4790
Epoch [16/50] - Loss: 0.4765
Epoch [17/50] - Loss: 0.4739
Epoch [18/50] - Loss: 0.4712
Epoch [19/50] - Loss: 0.4682
Epoch [20/50] - Loss: 0.4652
Epoch [21/50] - Loss: 0.4620
Epoch [22/50] - Loss: 0.4586
Epoch [23/50] - Loss: 0.4551
Epoch [24/50] - Loss: 0.4514
Epoch [25/50] - Loss: 0.4476
Epoch [26/50] - Loss: 0.4436
Epoch [27/50] - Loss: 0.4395
Epoch [28/50] - Loss: 0.4353
Epoch [29/50] - Loss: 0.4308
Epoch [30/50] - Loss: 0.4263
Epoch [31/50] - Loss: 0.4216
Epoch [32/50] - Loss: 0.4168
Epoch [33/50] - Loss: 0.4119
Epoch [34/50] - Loss: 0.4069
Epoch [35/50] - Loss: 0.4017
Epoch [36/50] - Loss: 0.3965
Epoch [37/50] - Loss: 0.3912
Epoch [38/50] - Loss: 0.3858
Epoch [39/50] - Loss: 0.3803
Epoch [40/50] - Loss: 0.3748
Epoch [41/50] - Loss: 0.3693
Epoch [42/50] - Loss: 0.3637
Epoch [43/50] - Loss: 0.3581
Epoch [44/50] - Loss: 0.3525
Epoch [45/50] - Loss: 0.3470
Epoch [46/50] - Loss: 0.3414
Epoch [47/50] - Loss: 0.3359
Epoch [48/50] - Loss: 0.3305
Epoch [49/50] - Loss: 0.3250
Epoch [50/50] - Loss: 0.3197
sum preds 6155
sum labels 5513
 - Test Metrics: Accuracy=0.8037, F1=0.7081, Recall=0.7493, Precision=0.6712
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4995
Epoch [3/50] - Loss: 0.4988
Epoch [4/50] - Loss: 0.4980
Epoch [5/50] - Loss: 0.4970
Epoch [6/50] - Loss: 0.4960
Epoch [7/50] - Loss: 0.4948
Epoch [8/50] - Loss: 0.4934
Epoch [9/50] - Loss: 0.4919
Epoch [10/50] - Loss: 0.4903
Epoch [11/50] - Loss: 0.4885
Epoch [12/50] - Loss: 0.4866
Epoch [13/50] - Loss: 0.4845
Epoch [14/50] - Loss: 0.4823
Epoch [15/50] - Loss: 0.4800
Epoch [16/50] - Loss: 0.4775
Epoch [17/50] - Loss: 0.4749
Epoch [18/50] - Loss: 0.4721
Epoch [19/50] - Loss: 0.4692
Epoch [20/50] - Loss: 0.4661
Epoch [21/50] - Loss: 0.4629
Epoch [22/50] - Loss: 0.4595
Epoch [23/50] - Loss: 0.4560
Epoch [24/50] - Loss: 0.4523
Epoch [25/50] - Loss: 0.4485
Epoch [26/50] - Loss: 0.4445
Epoch [27/50] - Loss: 0.4404
Epoch [28/50] - Loss: 0.4362
Epoch [29/50] - Loss: 0.4317
Epoch [30/50] - Loss: 0.4272
Epoch [31/50] - Loss: 0.4225
Epoch [32/50] - Loss: 0.4177
Epoch [33/50] - Loss: 0.4128
Epoch [34/50] - Loss: 0.4078
Epoch [35/50] - Loss: 0.4026
Epoch [36/50] - Loss: 0.3974
Epoch [37/50] - Loss: 0.3921
Epoch [38/50] - Loss: 0.3867
Epoch [39/50] - Loss: 0.3812
Epoch [40/50] - Loss: 0.3757
Epoch [41/50] - Loss: 0.3702
Epoch [42/50] - Loss: 0.3646
Epoch [43/50] - Loss: 0.3590
Epoch [44/50] - Loss: 0.3535
Epoch [45/50] - Loss: 0.3479
Epoch [46/50] - Loss: 0.3423
Epoch [47/50] - Loss: 0.3368
Epoch [48/50] - Loss: 0.3314
Epoch [49/50] - Loss: 0.3260
Epoch [50/50] - Loss: 0.3206
sum preds 5901
sum labels 5513
 - Test Metrics: Accuracy=0.8078, F1=0.7077, Recall=0.7326, Precision=0.6845
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4991
Epoch [3/50] - Loss: 0.4979
Epoch [4/50] - Loss: 0.4965
Epoch [5/50] - Loss: 0.4950
Epoch [6/50] - Loss: 0.4933
Epoch [7/50] - Loss: 0.4914
Epoch [8/50] - Loss: 0.4895
Epoch [9/50] - Loss: 0.4874
Epoch [10/50] - Loss: 0.4853
Epoch [11/50] - Loss: 0.4830
Epoch [12/50] - Loss: 0.4805
Epoch [13/50] - Loss: 0.4779
Epoch [14/50] - Loss: 0.4752
Epoch [15/50] - Loss: 0.4723
Epoch [16/50] - Loss: 0.4693
Epoch [17/50] - Loss: 0.4662
Epoch [18/50] - Loss: 0.4629
Epoch [19/50] - Loss: 0.4595
Epoch [20/50] - Loss: 0.4559
Epoch [21/50] - Loss: 0.4522
Epoch [22/50] - Loss: 0.4483
Epoch [23/50] - Loss: 0.4443
Epoch [24/50] - Loss: 0.4401
Epoch [25/50] - Loss: 0.4359
Epoch [26/50] - Loss: 0.4315
Epoch [27/50] - Loss: 0.4269
Epoch [28/50] - Loss: 0.4223
Epoch [29/50] - Loss: 0.4175
Epoch [30/50] - Loss: 0.4126
Epoch [31/50] - Loss: 0.4076
Epoch [32/50] - Loss: 0.4025
Epoch [33/50] - Loss: 0.3973
Epoch [34/50] - Loss: 0.3921
Epoch [35/50] - Loss: 0.3868
Epoch [36/50] - Loss: 0.3814
Epoch [37/50] - Loss: 0.3759
Epoch [38/50] - Loss: 0.3705
Epoch [39/50] - Loss: 0.3650
Epoch [40/50] - Loss: 0.3594
Epoch [41/50] - Loss: 0.3539
Epoch [42/50] - Loss: 0.3484
Epoch [43/50] - Loss: 0.3429
Epoch [44/50] - Loss: 0.3374
Epoch [45/50] - Loss: 0.3319
Epoch [46/50] - Loss: 0.3265
Epoch [47/50] - Loss: 0.3212
Epoch [48/50] - Loss: 0.3159
Epoch [49/50] - Loss: 0.3107
Epoch [50/50] - Loss: 0.3056
sum preds 5586
sum labels 5513
 - Test Metrics: Accuracy=0.8104, F1=0.7035, Recall=0.7081, Precision=0.6989
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_imbnnpu_imbnnpu_1804183557.csv.
Average F1 over valid seeds: 0.7064 ± 0.0021
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and imbnnpu, MLP,0.3: 0.7064 ± 0.0021
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4982
Epoch [3/50] - Loss: 0.4964
Epoch [4/50] - Loss: 0.4944
Epoch [5/50] - Loss: 0.4921
Epoch [6/50] - Loss: 0.4896
Epoch [7/50] - Loss: 0.4870
Epoch [8/50] - Loss: 0.4844
Epoch [9/50] - Loss: 0.4816
Epoch [10/50] - Loss: 0.4787
Epoch [11/50] - Loss: 0.4757
Epoch [12/50] - Loss: 0.4726
Epoch [13/50] - Loss: 0.4695
Epoch [14/50] - Loss: 0.4661
Epoch [15/50] - Loss: 0.4626
Epoch [16/50] - Loss: 0.4590
Epoch [17/50] - Loss: 0.4553
Epoch [18/50] - Loss: 0.4513
Epoch [19/50] - Loss: 0.4473
Epoch [20/50] - Loss: 0.4432
Epoch [21/50] - Loss: 0.4390
Epoch [22/50] - Loss: 0.4346
Epoch [23/50] - Loss: 0.4301
Epoch [24/50] - Loss: 0.4255
Epoch [25/50] - Loss: 0.4207
Epoch [26/50] - Loss: 0.4158
Epoch [27/50] - Loss: 0.4108
Epoch [28/50] - Loss: 0.4057
Epoch [29/50] - Loss: 0.4005
Epoch [30/50] - Loss: 0.3951
Epoch [31/50] - Loss: 0.3896
Epoch [32/50] - Loss: 0.3841
Epoch [33/50] - Loss: 0.3785
Epoch [34/50] - Loss: 0.3728
Epoch [35/50] - Loss: 0.3670
Epoch [36/50] - Loss: 0.3611
Epoch [37/50] - Loss: 0.3552
Epoch [38/50] - Loss: 0.3493
Epoch [39/50] - Loss: 0.3433
Epoch [40/50] - Loss: 0.3373
Epoch [41/50] - Loss: 0.3313
Epoch [42/50] - Loss: 0.3252
Epoch [43/50] - Loss: 0.3192
Epoch [44/50] - Loss: 0.3132
Epoch [45/50] - Loss: 0.3072
Epoch [46/50] - Loss: 0.3013
Epoch [47/50] - Loss: 0.2954
Epoch [48/50] - Loss: 0.2895
Epoch [49/50] - Loss: 0.2838
Epoch [50/50] - Loss: 0.2780
sum preds 5687
sum labels 5513
 - Test Metrics: Accuracy=0.8292, F1=0.7354, Recall=0.7470, Precision=0.7241
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5009
Epoch [2/50] - Loss: 0.4989
Epoch [3/50] - Loss: 0.4969
Epoch [4/50] - Loss: 0.4947
Epoch [5/50] - Loss: 0.4922
Epoch [6/50] - Loss: 0.4895
Epoch [7/50] - Loss: 0.4865
Epoch [8/50] - Loss: 0.4832
Epoch [9/50] - Loss: 0.4797
Epoch [10/50] - Loss: 0.4761
Epoch [11/50] - Loss: 0.4723
Epoch [12/50] - Loss: 0.4685
Epoch [13/50] - Loss: 0.4647
Epoch [14/50] - Loss: 0.4608
Epoch [15/50] - Loss: 0.4568
Epoch [16/50] - Loss: 0.4526
Epoch [17/50] - Loss: 0.4484
Epoch [18/50] - Loss: 0.4440
Epoch [19/50] - Loss: 0.4396
Epoch [20/50] - Loss: 0.4351
Epoch [21/50] - Loss: 0.4305
Epoch [22/50] - Loss: 0.4258
Epoch [23/50] - Loss: 0.4211
Epoch [24/50] - Loss: 0.4163
Epoch [25/50] - Loss: 0.4114
Epoch [26/50] - Loss: 0.4066
Epoch [27/50] - Loss: 0.4017
Epoch [28/50] - Loss: 0.3967
Epoch [29/50] - Loss: 0.3918
Epoch [30/50] - Loss: 0.3868
Epoch [31/50] - Loss: 0.3817
Epoch [32/50] - Loss: 0.3767
Epoch [33/50] - Loss: 0.3716
Epoch [34/50] - Loss: 0.3666
Epoch [35/50] - Loss: 0.3615
Epoch [36/50] - Loss: 0.3564
Epoch [37/50] - Loss: 0.3513
Epoch [38/50] - Loss: 0.3462
Epoch [39/50] - Loss: 0.3412
Epoch [40/50] - Loss: 0.3361
Epoch [41/50] - Loss: 0.3311
Epoch [42/50] - Loss: 0.3261
Epoch [43/50] - Loss: 0.3211
Epoch [44/50] - Loss: 0.3161
Epoch [45/50] - Loss: 0.3112
Epoch [46/50] - Loss: 0.3064
Epoch [47/50] - Loss: 0.3016
Epoch [48/50] - Loss: 0.2968
Epoch [49/50] - Loss: 0.2922
Epoch [50/50] - Loss: 0.2876
sum preds 4704
sum labels 5513
 - Test Metrics: Accuracy=0.8463, F1=0.7390, Recall=0.6847, Precision=0.8025
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4973
Epoch [3/50] - Loss: 0.4946
Epoch [4/50] - Loss: 0.4914
Epoch [5/50] - Loss: 0.4877
Epoch [6/50] - Loss: 0.4837
Epoch [7/50] - Loss: 0.4797
Epoch [8/50] - Loss: 0.4756
Epoch [9/50] - Loss: 0.4715
Epoch [10/50] - Loss: 0.4673
Epoch [11/50] - Loss: 0.4629
Epoch [12/50] - Loss: 0.4585
Epoch [13/50] - Loss: 0.4539
Epoch [14/50] - Loss: 0.4493
Epoch [15/50] - Loss: 0.4445
Epoch [16/50] - Loss: 0.4396
Epoch [17/50] - Loss: 0.4346
Epoch [18/50] - Loss: 0.4295
Epoch [19/50] - Loss: 0.4243
Epoch [20/50] - Loss: 0.4191
Epoch [21/50] - Loss: 0.4137
Epoch [22/50] - Loss: 0.4082
Epoch [23/50] - Loss: 0.4027
Epoch [24/50] - Loss: 0.3970
Epoch [25/50] - Loss: 0.3913
Epoch [26/50] - Loss: 0.3856
Epoch [27/50] - Loss: 0.3797
Epoch [28/50] - Loss: 0.3739
Epoch [29/50] - Loss: 0.3680
Epoch [30/50] - Loss: 0.3621
Epoch [31/50] - Loss: 0.3561
Epoch [32/50] - Loss: 0.3501
Epoch [33/50] - Loss: 0.3442
Epoch [34/50] - Loss: 0.3382
Epoch [35/50] - Loss: 0.3323
Epoch [36/50] - Loss: 0.3264
Epoch [37/50] - Loss: 0.3205
Epoch [38/50] - Loss: 0.3146
Epoch [39/50] - Loss: 0.3088
Epoch [40/50] - Loss: 0.3030
Epoch [41/50] - Loss: 0.2973
Epoch [42/50] - Loss: 0.2916
Epoch [43/50] - Loss: 0.2860
Epoch [44/50] - Loss: 0.2805
Epoch [45/50] - Loss: 0.2751
Epoch [46/50] - Loss: 0.2697
Epoch [47/50] - Loss: 0.2644
Epoch [48/50] - Loss: 0.2592
Epoch [49/50] - Loss: 0.2541
Epoch [50/50] - Loss: 0.2491
sum preds 5318
sum labels 5513
 - Test Metrics: Accuracy=0.8337, F1=0.7335, Recall=0.7205, Precision=0.7469
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_imbnnpu_imbnnpu_1804183559.csv.
Average F1 over valid seeds: 0.7359 ± 0.0023
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and imbnnpu, GATConv,0.3: 0.7359 ± 0.0023
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4986
Epoch [3/50] - Loss: 0.4970
Epoch [4/50] - Loss: 0.4952
Epoch [5/50] - Loss: 0.4932
Epoch [6/50] - Loss: 0.4912
Epoch [7/50] - Loss: 0.4890
Epoch [8/50] - Loss: 0.4867
Epoch [9/50] - Loss: 0.4841
Epoch [10/50] - Loss: 0.4813
Epoch [11/50] - Loss: 0.4785
Epoch [12/50] - Loss: 0.4757
Epoch [13/50] - Loss: 0.4728
Epoch [14/50] - Loss: 0.4698
Epoch [15/50] - Loss: 0.4668
Epoch [16/50] - Loss: 0.4636
Epoch [17/50] - Loss: 0.4604
Epoch [18/50] - Loss: 0.4570
Epoch [19/50] - Loss: 0.4535
Epoch [20/50] - Loss: 0.4500
Epoch [21/50] - Loss: 0.4464
Epoch [22/50] - Loss: 0.4427
Epoch [23/50] - Loss: 0.4389
Epoch [24/50] - Loss: 0.4350
Epoch [25/50] - Loss: 0.4311
Epoch [26/50] - Loss: 0.4271
Epoch [27/50] - Loss: 0.4230
Epoch [28/50] - Loss: 0.4189
Epoch [29/50] - Loss: 0.4147
Epoch [30/50] - Loss: 0.4104
Epoch [31/50] - Loss: 0.4061
Epoch [32/50] - Loss: 0.4018
Epoch [33/50] - Loss: 0.3973
Epoch [34/50] - Loss: 0.3929
Epoch [35/50] - Loss: 0.3884
Epoch [36/50] - Loss: 0.3839
Epoch [37/50] - Loss: 0.3794
Epoch [38/50] - Loss: 0.3748
Epoch [39/50] - Loss: 0.3702
Epoch [40/50] - Loss: 0.3656
Epoch [41/50] - Loss: 0.3610
Epoch [42/50] - Loss: 0.3565
Epoch [43/50] - Loss: 0.3519
Epoch [44/50] - Loss: 0.3473
Epoch [45/50] - Loss: 0.3427
Epoch [46/50] - Loss: 0.3382
Epoch [47/50] - Loss: 0.3336
Epoch [48/50] - Loss: 0.3291
Epoch [49/50] - Loss: 0.3247
Epoch [50/50] - Loss: 0.3202
sum preds 5653
sum labels 5513
 - Test Metrics: Accuracy=0.8407, F1=0.7525, Recall=0.7620, Precision=0.7431
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4985
Epoch [3/50] - Loss: 0.4966
Epoch [4/50] - Loss: 0.4945
Epoch [5/50] - Loss: 0.4921
Epoch [6/50] - Loss: 0.4894
Epoch [7/50] - Loss: 0.4866
Epoch [8/50] - Loss: 0.4837
Epoch [9/50] - Loss: 0.4807
Epoch [10/50] - Loss: 0.4776
Epoch [11/50] - Loss: 0.4744
Epoch [12/50] - Loss: 0.4711
Epoch [13/50] - Loss: 0.4676
Epoch [14/50] - Loss: 0.4642
Epoch [15/50] - Loss: 0.4606
Epoch [16/50] - Loss: 0.4570
Epoch [17/50] - Loss: 0.4534
Epoch [18/50] - Loss: 0.4496
Epoch [19/50] - Loss: 0.4458
Epoch [20/50] - Loss: 0.4419
Epoch [21/50] - Loss: 0.4379
Epoch [22/50] - Loss: 0.4339
Epoch [23/50] - Loss: 0.4298
Epoch [24/50] - Loss: 0.4256
Epoch [25/50] - Loss: 0.4214
Epoch [26/50] - Loss: 0.4172
Epoch [27/50] - Loss: 0.4129
Epoch [28/50] - Loss: 0.4085
Epoch [29/50] - Loss: 0.4041
Epoch [30/50] - Loss: 0.3997
Epoch [31/50] - Loss: 0.3953
Epoch [32/50] - Loss: 0.3908
Epoch [33/50] - Loss: 0.3863
Epoch [34/50] - Loss: 0.3818
Epoch [35/50] - Loss: 0.3774
Epoch [36/50] - Loss: 0.3729
Epoch [37/50] - Loss: 0.3683
Epoch [38/50] - Loss: 0.3639
Epoch [39/50] - Loss: 0.3593
Epoch [40/50] - Loss: 0.3549
Epoch [41/50] - Loss: 0.3504
Epoch [42/50] - Loss: 0.3460
Epoch [43/50] - Loss: 0.3415
Epoch [44/50] - Loss: 0.3371
Epoch [45/50] - Loss: 0.3328
Epoch [46/50] - Loss: 0.3284
Epoch [47/50] - Loss: 0.3241
Epoch [48/50] - Loss: 0.3198
Epoch [49/50] - Loss: 0.3156
Epoch [50/50] - Loss: 0.3114
sum preds 5365
sum labels 5513
 - Test Metrics: Accuracy=0.8443, F1=0.7516, Recall=0.7415, Precision=0.7620
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4985
Epoch [3/50] - Loss: 0.4967
Epoch [4/50] - Loss: 0.4945
Epoch [5/50] - Loss: 0.4920
Epoch [6/50] - Loss: 0.4894
Epoch [7/50] - Loss: 0.4867
Epoch [8/50] - Loss: 0.4839
Epoch [9/50] - Loss: 0.4811
Epoch [10/50] - Loss: 0.4783
Epoch [11/50] - Loss: 0.4753
Epoch [12/50] - Loss: 0.4722
Epoch [13/50] - Loss: 0.4688
Epoch [14/50] - Loss: 0.4654
Epoch [15/50] - Loss: 0.4618
Epoch [16/50] - Loss: 0.4583
Epoch [17/50] - Loss: 0.4547
Epoch [18/50] - Loss: 0.4510
Epoch [19/50] - Loss: 0.4472
Epoch [20/50] - Loss: 0.4434
Epoch [21/50] - Loss: 0.4395
Epoch [22/50] - Loss: 0.4355
Epoch [23/50] - Loss: 0.4314
Epoch [24/50] - Loss: 0.4272
Epoch [25/50] - Loss: 0.4230
Epoch [26/50] - Loss: 0.4187
Epoch [27/50] - Loss: 0.4144
Epoch [28/50] - Loss: 0.4100
Epoch [29/50] - Loss: 0.4055
Epoch [30/50] - Loss: 0.4010
Epoch [31/50] - Loss: 0.3965
Epoch [32/50] - Loss: 0.3920
Epoch [33/50] - Loss: 0.3874
Epoch [34/50] - Loss: 0.3828
Epoch [35/50] - Loss: 0.3782
Epoch [36/50] - Loss: 0.3735
Epoch [37/50] - Loss: 0.3688
Epoch [38/50] - Loss: 0.3641
Epoch [39/50] - Loss: 0.3594
Epoch [40/50] - Loss: 0.3547
Epoch [41/50] - Loss: 0.3498
Epoch [42/50] - Loss: 0.3450
Epoch [43/50] - Loss: 0.3403
Epoch [44/50] - Loss: 0.3356
Epoch [45/50] - Loss: 0.3309
Epoch [46/50] - Loss: 0.3263
Epoch [47/50] - Loss: 0.3217
Epoch [48/50] - Loss: 0.3171
Epoch [49/50] - Loss: 0.3126
Epoch [50/50] - Loss: 0.3081
sum preds 5310
sum labels 5513
 - Test Metrics: Accuracy=0.8391, F1=0.7419, Recall=0.7283, Precision=0.7561
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_imbnnpu_imbnnpu_1804183602.csv.
Average F1 over valid seeds: 0.7487 ± 0.0048
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and imbnnpu, GCNConv,0.3: 0.7487 ± 0.0048
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4995
Epoch [3/50] - Loss: 0.4987
Epoch [4/50] - Loss: 0.4978
Epoch [5/50] - Loss: 0.4967
Epoch [6/50] - Loss: 0.4956
Epoch [7/50] - Loss: 0.4943
Epoch [8/50] - Loss: 0.4929
Epoch [9/50] - Loss: 0.4913
Epoch [10/50] - Loss: 0.4897
Epoch [11/50] - Loss: 0.4880
Epoch [12/50] - Loss: 0.4861
Epoch [13/50] - Loss: 0.4841
Epoch [14/50] - Loss: 0.4819
Epoch [15/50] - Loss: 0.4796
Epoch [16/50] - Loss: 0.4772
Epoch [17/50] - Loss: 0.4746
Epoch [18/50] - Loss: 0.4719
Epoch [19/50] - Loss: 0.4691
Epoch [20/50] - Loss: 0.4661
Epoch [21/50] - Loss: 0.4630
Epoch [22/50] - Loss: 0.4597
Epoch [23/50] - Loss: 0.4563
Epoch [24/50] - Loss: 0.4527
Epoch [25/50] - Loss: 0.4489
Epoch [26/50] - Loss: 0.4451
Epoch [27/50] - Loss: 0.4410
Epoch [28/50] - Loss: 0.4369
Epoch [29/50] - Loss: 0.4326
Epoch [30/50] - Loss: 0.4281
Epoch [31/50] - Loss: 0.4235
Epoch [32/50] - Loss: 0.4188
Epoch [33/50] - Loss: 0.4140
Epoch [34/50] - Loss: 0.4090
Epoch [35/50] - Loss: 0.4040
Epoch [36/50] - Loss: 0.3989
Epoch [37/50] - Loss: 0.3936
Epoch [38/50] - Loss: 0.3883
Epoch [39/50] - Loss: 0.3830
Epoch [40/50] - Loss: 0.3776
Epoch [41/50] - Loss: 0.3721
Epoch [42/50] - Loss: 0.3666
Epoch [43/50] - Loss: 0.3611
Epoch [44/50] - Loss: 0.3556
Epoch [45/50] - Loss: 0.3501
Epoch [46/50] - Loss: 0.3446
Epoch [47/50] - Loss: 0.3392
Epoch [48/50] - Loss: 0.3338
Epoch [49/50] - Loss: 0.3284
Epoch [50/50] - Loss: 0.3232
sum preds 6667
sum labels 6300
 - Test Metrics: Accuracy=0.8022, F1=0.7232, Recall=0.7443, Precision=0.7033
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4995
Epoch [3/50] - Loss: 0.4989
Epoch [4/50] - Loss: 0.4981
Epoch [5/50] - Loss: 0.4972
Epoch [6/50] - Loss: 0.4963
Epoch [7/50] - Loss: 0.4952
Epoch [8/50] - Loss: 0.4939
Epoch [9/50] - Loss: 0.4925
Epoch [10/50] - Loss: 0.4910
Epoch [11/50] - Loss: 0.4894
Epoch [12/50] - Loss: 0.4877
Epoch [13/50] - Loss: 0.4858
Epoch [14/50] - Loss: 0.4838
Epoch [15/50] - Loss: 0.4816
Epoch [16/50] - Loss: 0.4793
Epoch [17/50] - Loss: 0.4768
Epoch [18/50] - Loss: 0.4742
Epoch [19/50] - Loss: 0.4715
Epoch [20/50] - Loss: 0.4686
Epoch [21/50] - Loss: 0.4656
Epoch [22/50] - Loss: 0.4624
Epoch [23/50] - Loss: 0.4591
Epoch [24/50] - Loss: 0.4556
Epoch [25/50] - Loss: 0.4520
Epoch [26/50] - Loss: 0.4482
Epoch [27/50] - Loss: 0.4443
Epoch [28/50] - Loss: 0.4403
Epoch [29/50] - Loss: 0.4361
Epoch [30/50] - Loss: 0.4317
Epoch [31/50] - Loss: 0.4273
Epoch [32/50] - Loss: 0.4227
Epoch [33/50] - Loss: 0.4180
Epoch [34/50] - Loss: 0.4132
Epoch [35/50] - Loss: 0.4083
Epoch [36/50] - Loss: 0.4032
Epoch [37/50] - Loss: 0.3981
Epoch [38/50] - Loss: 0.3929
Epoch [39/50] - Loss: 0.3877
Epoch [40/50] - Loss: 0.3824
Epoch [41/50] - Loss: 0.3771
Epoch [42/50] - Loss: 0.3717
Epoch [43/50] - Loss: 0.3663
Epoch [44/50] - Loss: 0.3609
Epoch [45/50] - Loss: 0.3555
Epoch [46/50] - Loss: 0.3501
Epoch [47/50] - Loss: 0.3447
Epoch [48/50] - Loss: 0.3394
Epoch [49/50] - Loss: 0.3341
Epoch [50/50] - Loss: 0.3289
sum preds 6438
sum labels 6300
 - Test Metrics: Accuracy=0.8080, F1=0.7265, Recall=0.7344, Precision=0.7187
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4990
Epoch [3/50] - Loss: 0.4979
Epoch [4/50] - Loss: 0.4965
Epoch [5/50] - Loss: 0.4950
Epoch [6/50] - Loss: 0.4933
Epoch [7/50] - Loss: 0.4915
Epoch [8/50] - Loss: 0.4896
Epoch [9/50] - Loss: 0.4876
Epoch [10/50] - Loss: 0.4854
Epoch [11/50] - Loss: 0.4831
Epoch [12/50] - Loss: 0.4807
Epoch [13/50] - Loss: 0.4781
Epoch [14/50] - Loss: 0.4754
Epoch [15/50] - Loss: 0.4726
Epoch [16/50] - Loss: 0.4696
Epoch [17/50] - Loss: 0.4665
Epoch [18/50] - Loss: 0.4633
Epoch [19/50] - Loss: 0.4599
Epoch [20/50] - Loss: 0.4563
Epoch [21/50] - Loss: 0.4527
Epoch [22/50] - Loss: 0.4488
Epoch [23/50] - Loss: 0.4449
Epoch [24/50] - Loss: 0.4408
Epoch [25/50] - Loss: 0.4366
Epoch [26/50] - Loss: 0.4322
Epoch [27/50] - Loss: 0.4277
Epoch [28/50] - Loss: 0.4231
Epoch [29/50] - Loss: 0.4184
Epoch [30/50] - Loss: 0.4136
Epoch [31/50] - Loss: 0.4087
Epoch [32/50] - Loss: 0.4036
Epoch [33/50] - Loss: 0.3985
Epoch [34/50] - Loss: 0.3934
Epoch [35/50] - Loss: 0.3881
Epoch [36/50] - Loss: 0.3828
Epoch [37/50] - Loss: 0.3775
Epoch [38/50] - Loss: 0.3721
Epoch [39/50] - Loss: 0.3666
Epoch [40/50] - Loss: 0.3612
Epoch [41/50] - Loss: 0.3558
Epoch [42/50] - Loss: 0.3504
Epoch [43/50] - Loss: 0.3450
Epoch [44/50] - Loss: 0.3396
Epoch [45/50] - Loss: 0.3343
Epoch [46/50] - Loss: 0.3290
Epoch [47/50] - Loss: 0.3238
Epoch [48/50] - Loss: 0.3186
Epoch [49/50] - Loss: 0.3135
Epoch [50/50] - Loss: 0.3085
sum preds 5985
sum labels 6300
 - Test Metrics: Accuracy=0.8003, F1=0.7051, Recall=0.6875, Precision=0.7236
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_imbnnpu_imbnnpu_1804183605.csv.
Average F1 over valid seeds: 0.7183 ± 0.0094
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and imbnnpu, MLP,0.2: 0.7183 ± 0.0094
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4982
Epoch [3/50] - Loss: 0.4965
Epoch [4/50] - Loss: 0.4946
Epoch [5/50] - Loss: 0.4923
Epoch [6/50] - Loss: 0.4899
Epoch [7/50] - Loss: 0.4874
Epoch [8/50] - Loss: 0.4848
Epoch [9/50] - Loss: 0.4821
Epoch [10/50] - Loss: 0.4794
Epoch [11/50] - Loss: 0.4765
Epoch [12/50] - Loss: 0.4736
Epoch [13/50] - Loss: 0.4705
Epoch [14/50] - Loss: 0.4673
Epoch [15/50] - Loss: 0.4640
Epoch [16/50] - Loss: 0.4605
Epoch [17/50] - Loss: 0.4569
Epoch [18/50] - Loss: 0.4532
Epoch [19/50] - Loss: 0.4494
Epoch [20/50] - Loss: 0.4455
Epoch [21/50] - Loss: 0.4414
Epoch [22/50] - Loss: 0.4373
Epoch [23/50] - Loss: 0.4330
Epoch [24/50] - Loss: 0.4286
Epoch [25/50] - Loss: 0.4240
Epoch [26/50] - Loss: 0.4193
Epoch [27/50] - Loss: 0.4145
Epoch [28/50] - Loss: 0.4096
Epoch [29/50] - Loss: 0.4045
Epoch [30/50] - Loss: 0.3993
Epoch [31/50] - Loss: 0.3941
Epoch [32/50] - Loss: 0.3888
Epoch [33/50] - Loss: 0.3834
Epoch [34/50] - Loss: 0.3779
Epoch [35/50] - Loss: 0.3723
Epoch [36/50] - Loss: 0.3667
Epoch [37/50] - Loss: 0.3611
Epoch [38/50] - Loss: 0.3553
Epoch [39/50] - Loss: 0.3496
Epoch [40/50] - Loss: 0.3438
Epoch [41/50] - Loss: 0.3380
Epoch [42/50] - Loss: 0.3321
Epoch [43/50] - Loss: 0.3263
Epoch [44/50] - Loss: 0.3205
Epoch [45/50] - Loss: 0.3147
Epoch [46/50] - Loss: 0.3089
Epoch [47/50] - Loss: 0.3031
Epoch [48/50] - Loss: 0.2974
Epoch [49/50] - Loss: 0.2917
Epoch [50/50] - Loss: 0.2861
sum preds 6362
sum labels 6300
 - Test Metrics: Accuracy=0.8260, F1=0.7508, Recall=0.7544, Precision=0.7471
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5008
Epoch [2/50] - Loss: 0.4989
Epoch [3/50] - Loss: 0.4970
Epoch [4/50] - Loss: 0.4949
Epoch [5/50] - Loss: 0.4926
Epoch [6/50] - Loss: 0.4900
Epoch [7/50] - Loss: 0.4872
Epoch [8/50] - Loss: 0.4840
Epoch [9/50] - Loss: 0.4807
Epoch [10/50] - Loss: 0.4772
Epoch [11/50] - Loss: 0.4737
Epoch [12/50] - Loss: 0.4701
Epoch [13/50] - Loss: 0.4665
Epoch [14/50] - Loss: 0.4627
Epoch [15/50] - Loss: 0.4589
Epoch [16/50] - Loss: 0.4550
Epoch [17/50] - Loss: 0.4509
Epoch [18/50] - Loss: 0.4468
Epoch [19/50] - Loss: 0.4426
Epoch [20/50] - Loss: 0.4383
Epoch [21/50] - Loss: 0.4339
Epoch [22/50] - Loss: 0.4295
Epoch [23/50] - Loss: 0.4250
Epoch [24/50] - Loss: 0.4205
Epoch [25/50] - Loss: 0.4159
Epoch [26/50] - Loss: 0.4113
Epoch [27/50] - Loss: 0.4066
Epoch [28/50] - Loss: 0.4019
Epoch [29/50] - Loss: 0.3972
Epoch [30/50] - Loss: 0.3925
Epoch [31/50] - Loss: 0.3877
Epoch [32/50] - Loss: 0.3829
Epoch [33/50] - Loss: 0.3782
Epoch [34/50] - Loss: 0.3733
Epoch [35/50] - Loss: 0.3685
Epoch [36/50] - Loss: 0.3637
Epoch [37/50] - Loss: 0.3589
Epoch [38/50] - Loss: 0.3541
Epoch [39/50] - Loss: 0.3493
Epoch [40/50] - Loss: 0.3446
Epoch [41/50] - Loss: 0.3398
Epoch [42/50] - Loss: 0.3351
Epoch [43/50] - Loss: 0.3304
Epoch [44/50] - Loss: 0.3257
Epoch [45/50] - Loss: 0.3210
Epoch [46/50] - Loss: 0.3164
Epoch [47/50] - Loss: 0.3119
Epoch [48/50] - Loss: 0.3074
Epoch [49/50] - Loss: 0.3029
Epoch [50/50] - Loss: 0.2986
sum preds 5283
sum labels 6300
 - Test Metrics: Accuracy=0.8381, F1=0.7464, Recall=0.6862, Precision=0.8183
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4973
Epoch [3/50] - Loss: 0.4945
Epoch [4/50] - Loss: 0.4914
Epoch [5/50] - Loss: 0.4878
Epoch [6/50] - Loss: 0.4840
Epoch [7/50] - Loss: 0.4800
Epoch [8/50] - Loss: 0.4760
Epoch [9/50] - Loss: 0.4719
Epoch [10/50] - Loss: 0.4678
Epoch [11/50] - Loss: 0.4635
Epoch [12/50] - Loss: 0.4592
Epoch [13/50] - Loss: 0.4547
Epoch [14/50] - Loss: 0.4501
Epoch [15/50] - Loss: 0.4454
Epoch [16/50] - Loss: 0.4406
Epoch [17/50] - Loss: 0.4358
Epoch [18/50] - Loss: 0.4308
Epoch [19/50] - Loss: 0.4257
Epoch [20/50] - Loss: 0.4205
Epoch [21/50] - Loss: 0.4152
Epoch [22/50] - Loss: 0.4098
Epoch [23/50] - Loss: 0.4044
Epoch [24/50] - Loss: 0.3989
Epoch [25/50] - Loss: 0.3933
Epoch [26/50] - Loss: 0.3877
Epoch [27/50] - Loss: 0.3820
Epoch [28/50] - Loss: 0.3763
Epoch [29/50] - Loss: 0.3706
Epoch [30/50] - Loss: 0.3648
Epoch [31/50] - Loss: 0.3590
Epoch [32/50] - Loss: 0.3532
Epoch [33/50] - Loss: 0.3474
Epoch [34/50] - Loss: 0.3417
Epoch [35/50] - Loss: 0.3359
Epoch [36/50] - Loss: 0.3302
Epoch [37/50] - Loss: 0.3245
Epoch [38/50] - Loss: 0.3189
Epoch [39/50] - Loss: 0.3133
Epoch [40/50] - Loss: 0.3077
Epoch [41/50] - Loss: 0.3023
Epoch [42/50] - Loss: 0.2968
Epoch [43/50] - Loss: 0.2915
Epoch [44/50] - Loss: 0.2862
Epoch [45/50] - Loss: 0.2810
Epoch [46/50] - Loss: 0.2759
Epoch [47/50] - Loss: 0.2709
Epoch [48/50] - Loss: 0.2659
Epoch [49/50] - Loss: 0.2611
Epoch [50/50] - Loss: 0.2563
sum preds 5861
sum labels 6300
 - Test Metrics: Accuracy=0.8197, F1=0.7310, Recall=0.7056, Precision=0.7584
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_imbnnpu_imbnnpu_1804183606.csv.
Average F1 over valid seeds: 0.7427 ± 0.0085
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and imbnnpu, GATConv,0.2: 0.7427 ± 0.0085
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4987
Epoch [3/50] - Loss: 0.4972
Epoch [4/50] - Loss: 0.4955
Epoch [5/50] - Loss: 0.4936
Epoch [6/50] - Loss: 0.4916
Epoch [7/50] - Loss: 0.4894
Epoch [8/50] - Loss: 0.4872
Epoch [9/50] - Loss: 0.4847
Epoch [10/50] - Loss: 0.4822
Epoch [11/50] - Loss: 0.4795
Epoch [12/50] - Loss: 0.4767
Epoch [13/50] - Loss: 0.4739
Epoch [14/50] - Loss: 0.4710
Epoch [15/50] - Loss: 0.4681
Epoch [16/50] - Loss: 0.4650
Epoch [17/50] - Loss: 0.4619
Epoch [18/50] - Loss: 0.4587
Epoch [19/50] - Loss: 0.4553
Epoch [20/50] - Loss: 0.4519
Epoch [21/50] - Loss: 0.4484
Epoch [22/50] - Loss: 0.4448
Epoch [23/50] - Loss: 0.4412
Epoch [24/50] - Loss: 0.4375
Epoch [25/50] - Loss: 0.4337
Epoch [26/50] - Loss: 0.4298
Epoch [27/50] - Loss: 0.4259
Epoch [28/50] - Loss: 0.4219
Epoch [29/50] - Loss: 0.4178
Epoch [30/50] - Loss: 0.4137
Epoch [31/50] - Loss: 0.4096
Epoch [32/50] - Loss: 0.4053
Epoch [33/50] - Loss: 0.4011
Epoch [34/50] - Loss: 0.3968
Epoch [35/50] - Loss: 0.3925
Epoch [36/50] - Loss: 0.3881
Epoch [37/50] - Loss: 0.3837
Epoch [38/50] - Loss: 0.3793
Epoch [39/50] - Loss: 0.3749
Epoch [40/50] - Loss: 0.3704
Epoch [41/50] - Loss: 0.3660
Epoch [42/50] - Loss: 0.3615
Epoch [43/50] - Loss: 0.3571
Epoch [44/50] - Loss: 0.3527
Epoch [45/50] - Loss: 0.3482
Epoch [46/50] - Loss: 0.3439
Epoch [47/50] - Loss: 0.3395
Epoch [48/50] - Loss: 0.3351
Epoch [49/50] - Loss: 0.3308
Epoch [50/50] - Loss: 0.3265
sum preds 6332
sum labels 6300
 - Test Metrics: Accuracy=0.8357, F1=0.7641, Recall=0.7660, Precision=0.7622
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4986
Epoch [3/50] - Loss: 0.4967
Epoch [4/50] - Loss: 0.4947
Epoch [5/50] - Loss: 0.4924
Epoch [6/50] - Loss: 0.4899
Epoch [7/50] - Loss: 0.4873
Epoch [8/50] - Loss: 0.4845
Epoch [9/50] - Loss: 0.4817
Epoch [10/50] - Loss: 0.4787
Epoch [11/50] - Loss: 0.4757
Epoch [12/50] - Loss: 0.4725
Epoch [13/50] - Loss: 0.4693
Epoch [14/50] - Loss: 0.4660
Epoch [15/50] - Loss: 0.4626
Epoch [16/50] - Loss: 0.4592
Epoch [17/50] - Loss: 0.4557
Epoch [18/50] - Loss: 0.4522
Epoch [19/50] - Loss: 0.4486
Epoch [20/50] - Loss: 0.4449
Epoch [21/50] - Loss: 0.4411
Epoch [22/50] - Loss: 0.4373
Epoch [23/50] - Loss: 0.4334
Epoch [24/50] - Loss: 0.4294
Epoch [25/50] - Loss: 0.4254
Epoch [26/50] - Loss: 0.4214
Epoch [27/50] - Loss: 0.4173
Epoch [28/50] - Loss: 0.4132
Epoch [29/50] - Loss: 0.4091
Epoch [30/50] - Loss: 0.4049
Epoch [31/50] - Loss: 0.4007
Epoch [32/50] - Loss: 0.3965
Epoch [33/50] - Loss: 0.3922
Epoch [34/50] - Loss: 0.3880
Epoch [35/50] - Loss: 0.3837
Epoch [36/50] - Loss: 0.3794
Epoch [37/50] - Loss: 0.3751
Epoch [38/50] - Loss: 0.3709
Epoch [39/50] - Loss: 0.3666
Epoch [40/50] - Loss: 0.3623
Epoch [41/50] - Loss: 0.3581
Epoch [42/50] - Loss: 0.3538
Epoch [43/50] - Loss: 0.3496
Epoch [44/50] - Loss: 0.3454
Epoch [45/50] - Loss: 0.3412
Epoch [46/50] - Loss: 0.3370
Epoch [47/50] - Loss: 0.3329
Epoch [48/50] - Loss: 0.3288
Epoch [49/50] - Loss: 0.3247
Epoch [50/50] - Loss: 0.3207
sum preds 6059
sum labels 6300
 - Test Metrics: Accuracy=0.8409, F1=0.7664, Recall=0.7517, Precision=0.7816
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5003
Epoch [2/50] - Loss: 0.4985
Epoch [3/50] - Loss: 0.4966
Epoch [4/50] - Loss: 0.4945
Epoch [5/50] - Loss: 0.4921
Epoch [6/50] - Loss: 0.4895
Epoch [7/50] - Loss: 0.4868
Epoch [8/50] - Loss: 0.4841
Epoch [9/50] - Loss: 0.4813
Epoch [10/50] - Loss: 0.4785
Epoch [11/50] - Loss: 0.4755
Epoch [12/50] - Loss: 0.4724
Epoch [13/50] - Loss: 0.4691
Epoch [14/50] - Loss: 0.4657
Epoch [15/50] - Loss: 0.4623
Epoch [16/50] - Loss: 0.4587
Epoch [17/50] - Loss: 0.4552
Epoch [18/50] - Loss: 0.4516
Epoch [19/50] - Loss: 0.4479
Epoch [20/50] - Loss: 0.4441
Epoch [21/50] - Loss: 0.4402
Epoch [22/50] - Loss: 0.4363
Epoch [23/50] - Loss: 0.4323
Epoch [24/50] - Loss: 0.4282
Epoch [25/50] - Loss: 0.4240
Epoch [26/50] - Loss: 0.4198
Epoch [27/50] - Loss: 0.4156
Epoch [28/50] - Loss: 0.4113
Epoch [29/50] - Loss: 0.4069
Epoch [30/50] - Loss: 0.4025
Epoch [31/50] - Loss: 0.3981
Epoch [32/50] - Loss: 0.3937
Epoch [33/50] - Loss: 0.3892
Epoch [34/50] - Loss: 0.3847
Epoch [35/50] - Loss: 0.3802
Epoch [36/50] - Loss: 0.3757
Epoch [37/50] - Loss: 0.3712
Epoch [38/50] - Loss: 0.3667
Epoch [39/50] - Loss: 0.3622
Epoch [40/50] - Loss: 0.3577
Epoch [41/50] - Loss: 0.3533
Epoch [42/50] - Loss: 0.3488
Epoch [43/50] - Loss: 0.3443
Epoch [44/50] - Loss: 0.3399
Epoch [45/50] - Loss: 0.3355
Epoch [46/50] - Loss: 0.3310
Epoch [47/50] - Loss: 0.3266
Epoch [48/50] - Loss: 0.3222
Epoch [49/50] - Loss: 0.3179
Epoch [50/50] - Loss: 0.3136
sum preds 5828
sum labels 6300
 - Test Metrics: Accuracy=0.8260, F1=0.7398, Recall=0.7121, Precision=0.7697
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_imbnnpu_imbnnpu_1804183609.csv.
Average F1 over valid seeds: 0.7568 ± 0.0120
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and imbnnpu, GCNConv,0.2: 0.7568 ± 0.0120
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 23.5452
Epoch 10 / 50, Loss: 19.8476
Epoch 20 / 50, Loss: 14.9580
Epoch 30 / 50, Loss: 10.3809
Epoch 40 / 50, Loss: 7.2098
sum preds 3022.0
sum labels 4725
 - Test Metrics: Accuracy=0.8453, F1=0.6692, Recall=0.5486, Precision=0.8577
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 24.0530
Epoch 10 / 50, Loss: 20.1123
Epoch 20 / 50, Loss: 15.1935
Epoch 30 / 50, Loss: 10.5108
Epoch 40 / 50, Loss: 7.3535
sum preds 3030.0
sum labels 4725
 - Test Metrics: Accuracy=0.8484, F1=0.6762, Recall=0.5549, Precision=0.8653
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 22.9421
Epoch 10 / 50, Loss: 19.2905
Epoch 20 / 50, Loss: 14.6479
Epoch 30 / 50, Loss: 10.2231
Epoch 40 / 50, Loss: 7.1205
sum preds 2971.0
sum labels 4725
 - Test Metrics: Accuracy=0.8454, F1=0.6671, Recall=0.5433, Precision=0.8640
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_ours_1804183612.csv.
Average F1 over valid seeds: 0.6708 ± 0.0039
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and ours, GCNConv,0.4: 0.6708 ± 0.0039
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 26.5426
Epoch 10 / 50, Loss: 22.2739
Epoch 20 / 50, Loss: 16.4546
Epoch 30 / 50, Loss: 11.3445
Epoch 40 / 50, Loss: 7.8921
sum preds 3337.0
sum labels 5513
 - Test Metrics: Accuracy=0.8153, F1=0.6377, Recall=0.5119, Precision=0.8457
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 27.1138
Epoch 10 / 50, Loss: 22.6592
Epoch 20 / 50, Loss: 16.7486
Epoch 30 / 50, Loss: 11.4517
Epoch 40 / 50, Loss: 8.0397
sum preds 3347.0
sum labels 5513
 - Test Metrics: Accuracy=0.8271, F1=0.6614, Recall=0.5315, Precision=0.8754
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 25.9880
Epoch 10 / 50, Loss: 21.6921
Epoch 20 / 50, Loss: 16.0999
Epoch 30 / 50, Loss: 11.1607
Epoch 40 / 50, Loss: 7.7955
sum preds 3224.0
sum labels 5513
 - Test Metrics: Accuracy=0.8222, F1=0.6469, Recall=0.5126, Precision=0.8766
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_ours_1804184305.csv.
Average F1 over valid seeds: 0.6487 ± 0.0097
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and ours, GCNConv,0.3: 0.6487 ± 0.0097
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 30.4416
Epoch 10 / 50, Loss: 25.0936
Epoch 20 / 50, Loss: 18.1909
Epoch 30 / 50, Loss: 12.4204
Epoch 40 / 50, Loss: 8.7534
sum preds 3488.0
sum labels 6300
 - Test Metrics: Accuracy=0.7890, F1=0.6089, Recall=0.4730, Precision=0.8544
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 31.3672
Epoch 10 / 50, Loss: 25.7258
Epoch 20 / 50, Loss: 18.5650
Epoch 30 / 50, Loss: 12.7298
Epoch 40 / 50, Loss: 9.0053
sum preds 3331.0
sum labels 6300
 - Test Metrics: Accuracy=0.7898, F1=0.6041, Recall=0.4617, Precision=0.8733
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 29.8913
Epoch 10 / 50, Loss: 24.6619
Epoch 20 / 50, Loss: 17.8589
Epoch 30 / 50, Loss: 12.2781
Epoch 40 / 50, Loss: 8.6372
sum preds 3063.0
sum labels 6300
 - Test Metrics: Accuracy=0.7822, F1=0.5780, Recall=0.4295, Precision=0.8834
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SCAR_ours_1804184940.csv.
Average F1 over valid seeds: 0.5970 ± 0.0136
___________________________________________________________________________________
Avg F1 for pubmed with SCAR and ours, GCNConv,0.2: 0.5970 ± 0.0136
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.6408
Epoch [2/50] - Loss: 4.7388
Epoch [3/50] - Loss: 4.3275
Epoch [4/50] - Loss: 4.1608
Epoch [5/50] - Loss: 3.9919
Epoch [6/50] - Loss: 3.8683
Epoch [7/50] - Loss: 3.7601
Epoch [8/50] - Loss: 3.6772
Epoch [9/50] - Loss: 3.6178
Epoch [10/50] - Loss: 3.5632
Epoch [11/50] - Loss: 3.5281
Epoch [12/50] - Loss: 3.4844
Epoch [13/50] - Loss: 3.4560
Epoch [14/50] - Loss: 3.4160
Epoch [15/50] - Loss: 3.3909
Epoch [16/50] - Loss: 3.3523
Epoch [17/50] - Loss: 3.3229
Epoch [18/50] - Loss: 3.2972
Epoch [19/50] - Loss: 3.2730
Epoch [20/50] - Loss: 3.2427
Epoch [21/50] - Loss: 3.2176
Epoch [22/50] - Loss: 3.1877
Epoch [23/50] - Loss: 3.1600
Epoch [24/50] - Loss: 3.1321
Epoch [25/50] - Loss: 3.1012
Epoch [26/50] - Loss: 3.0731
Epoch [27/50] - Loss: 3.0556
Epoch [28/50] - Loss: 3.0294
Epoch [29/50] - Loss: 2.9981
Epoch [30/50] - Loss: 2.9828
Epoch [31/50] - Loss: 2.9611
Epoch [32/50] - Loss: 2.9375
Epoch [33/50] - Loss: 2.9204
Epoch [34/50] - Loss: 2.9056
Epoch [35/50] - Loss: 2.8841
Epoch [36/50] - Loss: 2.8667
Epoch [37/50] - Loss: 2.8426
Epoch [38/50] - Loss: 2.8326
Epoch [39/50] - Loss: 2.8065
Epoch [40/50] - Loss: 2.7922
Epoch [41/50] - Loss: 2.7776
Epoch [42/50] - Loss: 2.7608
Epoch [43/50] - Loss: 2.7482
Epoch [44/50] - Loss: 2.7325
Epoch [45/50] - Loss: 2.7156
Epoch [46/50] - Loss: 2.7010
Epoch [47/50] - Loss: 2.6853
Epoch [48/50] - Loss: 2.6734
Epoch [49/50] - Loss: 2.6525
Epoch [50/50] - Loss: 2.6429
sum preds 548
sum labels 4725
 - Test Metrics: Accuracy=0.7427, F1=0.1915, Recall=0.1069, Precision=0.9215
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.6302
Epoch [2/50] - Loss: 4.8978
Epoch [3/50] - Loss: 4.4053
Epoch [4/50] - Loss: 4.2835
Epoch [5/50] - Loss: 4.1623
Epoch [6/50] - Loss: 4.0453
Epoch [7/50] - Loss: 3.9557
Epoch [8/50] - Loss: 3.8668
Epoch [9/50] - Loss: 3.7923
Epoch [10/50] - Loss: 3.7186
Epoch [11/50] - Loss: 3.6658
Epoch [12/50] - Loss: 3.6251
Epoch [13/50] - Loss: 3.5887
Epoch [14/50] - Loss: 3.5548
Epoch [15/50] - Loss: 3.5289
Epoch [16/50] - Loss: 3.5029
Epoch [17/50] - Loss: 3.4770
Epoch [18/50] - Loss: 3.4563
Epoch [19/50] - Loss: 3.4373
Epoch [20/50] - Loss: 3.4085
Epoch [21/50] - Loss: 3.4007
Epoch [22/50] - Loss: 3.3901
Epoch [23/50] - Loss: 3.3719
Epoch [24/50] - Loss: 3.3585
Epoch [25/50] - Loss: 3.3491
Epoch [26/50] - Loss: 3.3325
Epoch [27/50] - Loss: 3.3208
Epoch [28/50] - Loss: 3.3155
Epoch [29/50] - Loss: 3.3053
Epoch [30/50] - Loss: 3.2890
Epoch [31/50] - Loss: 3.2780
Epoch [32/50] - Loss: 3.2779
Epoch [33/50] - Loss: 3.2576
Epoch [34/50] - Loss: 3.2584
Epoch [35/50] - Loss: 3.2418
Epoch [36/50] - Loss: 3.2365
Epoch [37/50] - Loss: 3.2307
Epoch [38/50] - Loss: 3.2126
Epoch [39/50] - Loss: 3.2051
Epoch [40/50] - Loss: 3.2101
Epoch [41/50] - Loss: 3.1843
Epoch [42/50] - Loss: 3.1836
Epoch [43/50] - Loss: 3.1721
Epoch [44/50] - Loss: 3.1669
Epoch [45/50] - Loss: 3.1548
Epoch [46/50] - Loss: 3.1507
Epoch [47/50] - Loss: 3.1396
Epoch [48/50] - Loss: 3.1237
Epoch [49/50] - Loss: 3.1230
Epoch [50/50] - Loss: 3.1060
sum preds 0
sum labels 4725
 - Test Metrics: Accuracy=0.7148, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.5531
Epoch [2/50] - Loss: 4.6617
Epoch [3/50] - Loss: 4.2957
Epoch [4/50] - Loss: 4.1831
Epoch [5/50] - Loss: 4.0224
Epoch [6/50] - Loss: 3.9169
Epoch [7/50] - Loss: 3.7989
Epoch [8/50] - Loss: 3.7148
Epoch [9/50] - Loss: 3.6510
Epoch [10/50] - Loss: 3.5820
Epoch [11/50] - Loss: 3.5440
Epoch [12/50] - Loss: 3.5056
Epoch [13/50] - Loss: 3.4725
Epoch [14/50] - Loss: 3.4439
Epoch [15/50] - Loss: 3.4164
Epoch [16/50] - Loss: 3.3950
Epoch [17/50] - Loss: 3.3763
Epoch [18/50] - Loss: 3.3441
Epoch [19/50] - Loss: 3.3405
Epoch [20/50] - Loss: 3.3241
Epoch [21/50] - Loss: 3.3054
Epoch [22/50] - Loss: 3.3009
Epoch [23/50] - Loss: 3.2779
Epoch [24/50] - Loss: 3.2619
Epoch [25/50] - Loss: 3.2694
Epoch [26/50] - Loss: 3.2521
Epoch [27/50] - Loss: 3.2366
Epoch [28/50] - Loss: 3.2367
Epoch [29/50] - Loss: 3.2170
Epoch [30/50] - Loss: 3.2103
Epoch [31/50] - Loss: 3.1996
Epoch [32/50] - Loss: 3.1882
Epoch [33/50] - Loss: 3.1738
Epoch [34/50] - Loss: 3.1709
Epoch [35/50] - Loss: 3.1657
Epoch [36/50] - Loss: 3.1452
Epoch [37/50] - Loss: 3.1430
Epoch [38/50] - Loss: 3.1344
Epoch [39/50] - Loss: 3.1267
Epoch [40/50] - Loss: 3.1078
Epoch [41/50] - Loss: 3.0977
Epoch [42/50] - Loss: 3.0933
Epoch [43/50] - Loss: 3.0728
Epoch [44/50] - Loss: 3.0595
Epoch [45/50] - Loss: 3.0395
Epoch [46/50] - Loss: 3.0335
Epoch [47/50] - Loss: 3.0231
Epoch [48/50] - Loss: 3.0126
Epoch [49/50] - Loss: 2.9982
Epoch [50/50] - Loss: 2.9869
sum preds 590
sum labels 4725
 - Test Metrics: Accuracy=0.7480, F1=0.2145, Recall=0.1206, Precision=0.9661
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_naive_naive_1804185612.csv.
Average F1 over valid seeds: 0.1353 ± 0.0962
___________________________________________________________________________________
Avg F1 for pubmed with SAR and naive, MLP,0.4: 0.1353 ± 0.0962
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.8890
Epoch [2/50] - Loss: 4.5541
Epoch [3/50] - Loss: 4.3617
Epoch [4/50] - Loss: 4.1746
Epoch [5/50] - Loss: 4.0502
Epoch [6/50] - Loss: 3.9620
Epoch [7/50] - Loss: 3.8644
Epoch [8/50] - Loss: 3.8031
Epoch [9/50] - Loss: 3.7348
Epoch [10/50] - Loss: 3.6956
Epoch [11/50] - Loss: 3.6449
Epoch [12/50] - Loss: 3.6170
Epoch [13/50] - Loss: 3.5851
Epoch [14/50] - Loss: 3.5681
Epoch [15/50] - Loss: 3.5312
Epoch [16/50] - Loss: 3.5121
Epoch [17/50] - Loss: 3.4890
Epoch [18/50] - Loss: 3.4583
Epoch [19/50] - Loss: 3.4332
Epoch [20/50] - Loss: 3.4008
Epoch [21/50] - Loss: 3.3746
Epoch [22/50] - Loss: 3.3570
Epoch [23/50] - Loss: 3.3331
Epoch [24/50] - Loss: 3.3085
Epoch [25/50] - Loss: 3.2791
Epoch [26/50] - Loss: 3.2772
Epoch [27/50] - Loss: 3.2500
Epoch [28/50] - Loss: 3.2351
Epoch [29/50] - Loss: 3.2159
Epoch [30/50] - Loss: 3.1978
Epoch [31/50] - Loss: 3.1864
Epoch [32/50] - Loss: 3.1711
Epoch [33/50] - Loss: 3.1557
Epoch [34/50] - Loss: 3.1462
Epoch [35/50] - Loss: 3.1349
Epoch [36/50] - Loss: 3.1110
Epoch [37/50] - Loss: 3.1015
Epoch [38/50] - Loss: 3.0832
Epoch [39/50] - Loss: 3.0775
Epoch [40/50] - Loss: 3.0643
Epoch [41/50] - Loss: 3.0532
Epoch [42/50] - Loss: 3.0354
Epoch [43/50] - Loss: 3.0279
Epoch [44/50] - Loss: 3.0135
Epoch [45/50] - Loss: 3.0032
Epoch [46/50] - Loss: 2.9959
Epoch [47/50] - Loss: 2.9813
Epoch [48/50] - Loss: 2.9719
Epoch [49/50] - Loss: 2.9675
Epoch [50/50] - Loss: 2.9542
sum preds 341
sum labels 4725
 - Test Metrics: Accuracy=0.7326, F1=0.1255, Recall=0.0673, Precision=0.9326
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.9241
Epoch [2/50] - Loss: 4.5695
Epoch [3/50] - Loss: 4.3322
Epoch [4/50] - Loss: 4.1716
Epoch [5/50] - Loss: 4.0292
Epoch [6/50] - Loss: 3.9389
Epoch [7/50] - Loss: 3.8429
Epoch [8/50] - Loss: 3.7658
Epoch [9/50] - Loss: 3.7116
Epoch [10/50] - Loss: 3.6606
Epoch [11/50] - Loss: 3.6111
Epoch [12/50] - Loss: 3.5667
Epoch [13/50] - Loss: 3.5434
Epoch [14/50] - Loss: 3.5172
Epoch [15/50] - Loss: 3.4865
Epoch [16/50] - Loss: 3.4705
Epoch [17/50] - Loss: 3.4541
Epoch [18/50] - Loss: 3.4387
Epoch [19/50] - Loss: 3.4059
Epoch [20/50] - Loss: 3.3934
Epoch [21/50] - Loss: 3.3735
Epoch [22/50] - Loss: 3.3578
Epoch [23/50] - Loss: 3.3402
Epoch [24/50] - Loss: 3.3176
Epoch [25/50] - Loss: 3.3015
Epoch [26/50] - Loss: 3.2813
Epoch [27/50] - Loss: 3.2694
Epoch [28/50] - Loss: 3.2512
Epoch [29/50] - Loss: 3.2337
Epoch [30/50] - Loss: 3.2239
Epoch [31/50] - Loss: 3.2014
Epoch [32/50] - Loss: 3.1856
Epoch [33/50] - Loss: 3.1747
Epoch [34/50] - Loss: 3.1557
Epoch [35/50] - Loss: 3.1447
Epoch [36/50] - Loss: 3.1260
Epoch [37/50] - Loss: 3.1181
Epoch [38/50] - Loss: 3.1017
Epoch [39/50] - Loss: 3.1011
Epoch [40/50] - Loss: 3.0859
Epoch [41/50] - Loss: 3.0705
Epoch [42/50] - Loss: 3.0600
Epoch [43/50] - Loss: 3.0496
Epoch [44/50] - Loss: 3.0310
Epoch [45/50] - Loss: 3.0209
Epoch [46/50] - Loss: 3.0073
Epoch [47/50] - Loss: 3.0009
Epoch [48/50] - Loss: 2.9774
Epoch [49/50] - Loss: 2.9736
Epoch [50/50] - Loss: 2.9579
sum preds 403
sum labels 4725
 - Test Metrics: Accuracy=0.7363, F1=0.1482, Recall=0.0804, Precision=0.9429
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.1357
Epoch [2/50] - Loss: 4.8069
Epoch [3/50] - Loss: 4.3881
Epoch [4/50] - Loss: 4.2819
Epoch [5/50] - Loss: 4.1255
Epoch [6/50] - Loss: 4.0284
Epoch [7/50] - Loss: 3.9371
Epoch [8/50] - Loss: 3.8557
Epoch [9/50] - Loss: 3.8007
Epoch [10/50] - Loss: 3.7327
Epoch [11/50] - Loss: 3.6676
Epoch [12/50] - Loss: 3.6158
Epoch [13/50] - Loss: 3.5684
Epoch [14/50] - Loss: 3.5235
Epoch [15/50] - Loss: 3.4963
Epoch [16/50] - Loss: 3.4637
Epoch [17/50] - Loss: 3.4298
Epoch [18/50] - Loss: 3.4101
Epoch [19/50] - Loss: 3.3812
Epoch [20/50] - Loss: 3.3615
Epoch [21/50] - Loss: 3.3404
Epoch [22/50] - Loss: 3.3184
Epoch [23/50] - Loss: 3.2986
Epoch [24/50] - Loss: 3.2904
Epoch [25/50] - Loss: 3.2660
Epoch [26/50] - Loss: 3.2554
Epoch [27/50] - Loss: 3.2464
Epoch [28/50] - Loss: 3.2147
Epoch [29/50] - Loss: 3.2095
Epoch [30/50] - Loss: 3.1975
Epoch [31/50] - Loss: 3.1879
Epoch [32/50] - Loss: 3.1658
Epoch [33/50] - Loss: 3.1588
Epoch [34/50] - Loss: 3.1556
Epoch [35/50] - Loss: 3.1329
Epoch [36/50] - Loss: 3.1212
Epoch [37/50] - Loss: 3.1013
Epoch [38/50] - Loss: 3.0967
Epoch [39/50] - Loss: 3.0822
Epoch [40/50] - Loss: 3.0634
Epoch [41/50] - Loss: 3.0500
Epoch [42/50] - Loss: 3.0499
Epoch [43/50] - Loss: 3.0239
Epoch [44/50] - Loss: 3.0169
Epoch [45/50] - Loss: 3.0039
Epoch [46/50] - Loss: 2.9861
Epoch [47/50] - Loss: 2.9702
Epoch [48/50] - Loss: 2.9655
Epoch [49/50] - Loss: 2.9440
Epoch [50/50] - Loss: 2.9364
sum preds 372
sum labels 4725
 - Test Metrics: Accuracy=0.7344, F1=0.1366, Recall=0.0737, Precision=0.9355
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_naive_naive_1804192306.csv.
Average F1 over valid seeds: 0.1368 ± 0.0093
___________________________________________________________________________________
Avg F1 for pubmed with SAR and naive, GATConv,0.4: 0.1368 ± 0.0093
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.3220
Epoch [2/50] - Loss: 5.1419
Epoch [3/50] - Loss: 4.5517
Epoch [4/50] - Loss: 4.4203
Epoch [5/50] - Loss: 4.3200
Epoch [6/50] - Loss: 4.2156
Epoch [7/50] - Loss: 4.1342
Epoch [8/50] - Loss: 4.0617
Epoch [9/50] - Loss: 3.9944
Epoch [10/50] - Loss: 3.9416
Epoch [11/50] - Loss: 3.8869
Epoch [12/50] - Loss: 3.8386
Epoch [13/50] - Loss: 3.8005
Epoch [14/50] - Loss: 3.7636
Epoch [15/50] - Loss: 3.7298
Epoch [16/50] - Loss: 3.7045
Epoch [17/50] - Loss: 3.6857
Epoch [18/50] - Loss: 3.6599
Epoch [19/50] - Loss: 3.6474
Epoch [20/50] - Loss: 3.6239
Epoch [21/50] - Loss: 3.6203
Epoch [22/50] - Loss: 3.5998
Epoch [23/50] - Loss: 3.5900
Epoch [24/50] - Loss: 3.5754
Epoch [25/50] - Loss: 3.5613
Epoch [26/50] - Loss: 3.5564
Epoch [27/50] - Loss: 3.5392
Epoch [28/50] - Loss: 3.5303
Epoch [29/50] - Loss: 3.5311
Epoch [30/50] - Loss: 3.5200
Epoch [31/50] - Loss: 3.5117
Epoch [32/50] - Loss: 3.5065
Epoch [33/50] - Loss: 3.5022
Epoch [34/50] - Loss: 3.4949
Epoch [35/50] - Loss: 3.4874
Epoch [36/50] - Loss: 3.4823
Epoch [37/50] - Loss: 3.4684
Epoch [38/50] - Loss: 3.4664
Epoch [39/50] - Loss: 3.4569
Epoch [40/50] - Loss: 3.4662
Epoch [41/50] - Loss: 3.4648
Epoch [42/50] - Loss: 3.4527
Epoch [43/50] - Loss: 3.4491
Epoch [44/50] - Loss: 3.4457
Epoch [45/50] - Loss: 3.4327
Epoch [46/50] - Loss: 3.4328
Epoch [47/50] - Loss: 3.4295
Epoch [48/50] - Loss: 3.4234
Epoch [49/50] - Loss: 3.4279
Epoch [50/50] - Loss: 3.4200
sum preds 0
sum labels 4725
 - Test Metrics: Accuracy=0.7148, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.2041
Epoch [2/50] - Loss: 4.9873
Epoch [3/50] - Loss: 4.4753
Epoch [4/50] - Loss: 4.3637
Epoch [5/50] - Loss: 4.2671
Epoch [6/50] - Loss: 4.1655
Epoch [7/50] - Loss: 4.0805
Epoch [8/50] - Loss: 4.0067
Epoch [9/50] - Loss: 3.9365
Epoch [10/50] - Loss: 3.8829
Epoch [11/50] - Loss: 3.8274
Epoch [12/50] - Loss: 3.7786
Epoch [13/50] - Loss: 3.7447
Epoch [14/50] - Loss: 3.7119
Epoch [15/50] - Loss: 3.6870
Epoch [16/50] - Loss: 3.6609
Epoch [17/50] - Loss: 3.6391
Epoch [18/50] - Loss: 3.6186
Epoch [19/50] - Loss: 3.6010
Epoch [20/50] - Loss: 3.5841
Epoch [21/50] - Loss: 3.5681
Epoch [22/50] - Loss: 3.5619
Epoch [23/50] - Loss: 3.5371
Epoch [24/50] - Loss: 3.5312
Epoch [25/50] - Loss: 3.5127
Epoch [26/50] - Loss: 3.5081
Epoch [27/50] - Loss: 3.5027
Epoch [28/50] - Loss: 3.4890
Epoch [29/50] - Loss: 3.4834
Epoch [30/50] - Loss: 3.4803
Epoch [31/50] - Loss: 3.4773
Epoch [32/50] - Loss: 3.4670
Epoch [33/50] - Loss: 3.4547
Epoch [34/50] - Loss: 3.4473
Epoch [35/50] - Loss: 3.4463
Epoch [36/50] - Loss: 3.4388
Epoch [37/50] - Loss: 3.4292
Epoch [38/50] - Loss: 3.4300
Epoch [39/50] - Loss: 3.4260
Epoch [40/50] - Loss: 3.4224
Epoch [41/50] - Loss: 3.4175
Epoch [42/50] - Loss: 3.4102
Epoch [43/50] - Loss: 3.4057
Epoch [44/50] - Loss: 3.4021
Epoch [45/50] - Loss: 3.3907
Epoch [46/50] - Loss: 3.3980
Epoch [47/50] - Loss: 3.3931
Epoch [48/50] - Loss: 3.3846
Epoch [49/50] - Loss: 3.3866
Epoch [50/50] - Loss: 3.3752
sum preds 0
sum labels 4725
 - Test Metrics: Accuracy=0.7148, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.3810
Epoch [2/50] - Loss: 5.2528
Epoch [3/50] - Loss: 4.5941
Epoch [4/50] - Loss: 4.4308
Epoch [5/50] - Loss: 4.3390
Epoch [6/50] - Loss: 4.2421
Epoch [7/50] - Loss: 4.1522
Epoch [8/50] - Loss: 4.0621
Epoch [9/50] - Loss: 4.0003
Epoch [10/50] - Loss: 3.9410
Epoch [11/50] - Loss: 3.8831
Epoch [12/50] - Loss: 3.8409
Epoch [13/50] - Loss: 3.7845
Epoch [14/50] - Loss: 3.7555
Epoch [15/50] - Loss: 3.7232
Epoch [16/50] - Loss: 3.6956
Epoch [17/50] - Loss: 3.6698
Epoch [18/50] - Loss: 3.6510
Epoch [19/50] - Loss: 3.6307
Epoch [20/50] - Loss: 3.6183
Epoch [21/50] - Loss: 3.5953
Epoch [22/50] - Loss: 3.5947
Epoch [23/50] - Loss: 3.5772
Epoch [24/50] - Loss: 3.5676
Epoch [25/50] - Loss: 3.5591
Epoch [26/50] - Loss: 3.5459
Epoch [27/50] - Loss: 3.5399
Epoch [28/50] - Loss: 3.5297
Epoch [29/50] - Loss: 3.5135
Epoch [30/50] - Loss: 3.5181
Epoch [31/50] - Loss: 3.5023
Epoch [32/50] - Loss: 3.5010
Epoch [33/50] - Loss: 3.4971
Epoch [34/50] - Loss: 3.4852
Epoch [35/50] - Loss: 3.4857
Epoch [36/50] - Loss: 3.4724
Epoch [37/50] - Loss: 3.4644
Epoch [38/50] - Loss: 3.4643
Epoch [39/50] - Loss: 3.4596
Epoch [40/50] - Loss: 3.4589
Epoch [41/50] - Loss: 3.4481
Epoch [42/50] - Loss: 3.4453
Epoch [43/50] - Loss: 3.4410
Epoch [44/50] - Loss: 3.4365
Epoch [45/50] - Loss: 3.4252
Epoch [46/50] - Loss: 3.4257
Epoch [47/50] - Loss: 3.4247
Epoch [48/50] - Loss: 3.4117
Epoch [49/50] - Loss: 3.4032
Epoch [50/50] - Loss: 3.3923
sum preds 0
sum labels 4725
 - Test Metrics: Accuracy=0.7148, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_naive_naive_1804195008.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for pubmed with SAR and naive, GCNConv,0.4: 0.0000 ± 0.0000
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.4412
Epoch [2/50] - Loss: 4.3145
Epoch [3/50] - Loss: 3.7201
Epoch [4/50] - Loss: 3.6114
Epoch [5/50] - Loss: 3.4685
Epoch [6/50] - Loss: 3.3726
Epoch [7/50] - Loss: 3.2871
Epoch [8/50] - Loss: 3.2214
Epoch [9/50] - Loss: 3.1735
Epoch [10/50] - Loss: 3.1315
Epoch [11/50] - Loss: 3.1094
Epoch [12/50] - Loss: 3.0783
Epoch [13/50] - Loss: 3.0659
Epoch [14/50] - Loss: 3.0415
Epoch [15/50] - Loss: 3.0319
Epoch [16/50] - Loss: 3.0067
Epoch [17/50] - Loss: 2.9919
Epoch [18/50] - Loss: 2.9849
Epoch [19/50] - Loss: 2.9770
Epoch [20/50] - Loss: 2.9652
Epoch [21/50] - Loss: 2.9568
Epoch [22/50] - Loss: 2.9439
Epoch [23/50] - Loss: 2.9378
Epoch [24/50] - Loss: 2.9319
Epoch [25/50] - Loss: 2.9168
Epoch [26/50] - Loss: 2.9073
Epoch [27/50] - Loss: 2.9093
Epoch [28/50] - Loss: 2.8952
Epoch [29/50] - Loss: 2.8819
Epoch [30/50] - Loss: 2.8796
Epoch [31/50] - Loss: 2.8718
Epoch [32/50] - Loss: 2.8608
Epoch [33/50] - Loss: 2.8509
Epoch [34/50] - Loss: 2.8497
Epoch [35/50] - Loss: 2.8373
Epoch [36/50] - Loss: 2.8313
Epoch [37/50] - Loss: 2.8155
Epoch [38/50] - Loss: 2.8101
Epoch [39/50] - Loss: 2.7906
Epoch [40/50] - Loss: 2.7849
Epoch [41/50] - Loss: 2.7768
Epoch [42/50] - Loss: 2.7650
Epoch [43/50] - Loss: 2.7567
Epoch [44/50] - Loss: 2.7485
Epoch [45/50] - Loss: 2.7342
Epoch [46/50] - Loss: 2.7239
Epoch [47/50] - Loss: 2.7119
Epoch [48/50] - Loss: 2.7069
Epoch [49/50] - Loss: 2.6902
Epoch [50/50] - Loss: 2.6838
sum preds 144
sum labels 5513
 - Test Metrics: Accuracy=0.6896, F1=0.0477, Recall=0.0245, Precision=0.9375
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.4378
Epoch [2/50] - Loss: 4.5371
Epoch [3/50] - Loss: 3.8467
Epoch [4/50] - Loss: 3.6607
Epoch [5/50] - Loss: 3.5893
Epoch [6/50] - Loss: 3.4938
Epoch [7/50] - Loss: 3.4327
Epoch [8/50] - Loss: 3.3718
Epoch [9/50] - Loss: 3.3187
Epoch [10/50] - Loss: 3.2594
Epoch [11/50] - Loss: 3.2173
Epoch [12/50] - Loss: 3.1829
Epoch [13/50] - Loss: 3.1519
Epoch [14/50] - Loss: 3.1242
Epoch [15/50] - Loss: 3.1037
Epoch [16/50] - Loss: 3.0836
Epoch [17/50] - Loss: 3.0605
Epoch [18/50] - Loss: 3.0398
Epoch [19/50] - Loss: 3.0254
Epoch [20/50] - Loss: 3.0006
Epoch [21/50] - Loss: 2.9926
Epoch [22/50] - Loss: 2.9869
Epoch [23/50] - Loss: 2.9682
Epoch [24/50] - Loss: 2.9550
Epoch [25/50] - Loss: 2.9498
Epoch [26/50] - Loss: 2.9350
Epoch [27/50] - Loss: 2.9254
Epoch [28/50] - Loss: 2.9199
Epoch [29/50] - Loss: 2.9102
Epoch [30/50] - Loss: 2.8981
Epoch [31/50] - Loss: 2.8851
Epoch [32/50] - Loss: 2.8847
Epoch [33/50] - Loss: 2.8710
Epoch [34/50] - Loss: 2.8725
Epoch [35/50] - Loss: 2.8553
Epoch [36/50] - Loss: 2.8499
Epoch [37/50] - Loss: 2.8464
Epoch [38/50] - Loss: 2.8327
Epoch [39/50] - Loss: 2.8247
Epoch [40/50] - Loss: 2.8325
Epoch [41/50] - Loss: 2.8066
Epoch [42/50] - Loss: 2.8103
Epoch [43/50] - Loss: 2.8019
Epoch [44/50] - Loss: 2.7948
Epoch [45/50] - Loss: 2.7879
Epoch [46/50] - Loss: 2.7843
Epoch [47/50] - Loss: 2.7754
Epoch [48/50] - Loss: 2.7658
Epoch [49/50] - Loss: 2.7637
Epoch [50/50] - Loss: 2.7531
sum preds 0
sum labels 5513
 - Test Metrics: Accuracy=0.6823, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.3456
Epoch [2/50] - Loss: 4.2300
Epoch [3/50] - Loss: 3.6906
Epoch [4/50] - Loss: 3.6199
Epoch [5/50] - Loss: 3.4919
Epoch [6/50] - Loss: 3.4092
Epoch [7/50] - Loss: 3.3299
Epoch [8/50] - Loss: 3.2637
Epoch [9/50] - Loss: 3.2124
Epoch [10/50] - Loss: 3.1513
Epoch [11/50] - Loss: 3.1230
Epoch [12/50] - Loss: 3.0864
Epoch [13/50] - Loss: 3.0573
Epoch [14/50] - Loss: 3.0337
Epoch [15/50] - Loss: 3.0080
Epoch [16/50] - Loss: 2.9855
Epoch [17/50] - Loss: 2.9697
Epoch [18/50] - Loss: 2.9395
Epoch [19/50] - Loss: 2.9350
Epoch [20/50] - Loss: 2.9192
Epoch [21/50] - Loss: 2.9060
Epoch [22/50] - Loss: 2.8993
Epoch [23/50] - Loss: 2.8817
Epoch [24/50] - Loss: 2.8665
Epoch [25/50] - Loss: 2.8739
Epoch [26/50] - Loss: 2.8557
Epoch [27/50] - Loss: 2.8426
Epoch [28/50] - Loss: 2.8438
Epoch [29/50] - Loss: 2.8260
Epoch [30/50] - Loss: 2.8217
Epoch [31/50] - Loss: 2.8138
Epoch [32/50] - Loss: 2.8029
Epoch [33/50] - Loss: 2.7922
Epoch [34/50] - Loss: 2.7892
Epoch [35/50] - Loss: 2.7884
Epoch [36/50] - Loss: 2.7714
Epoch [37/50] - Loss: 2.7727
Epoch [38/50] - Loss: 2.7642
Epoch [39/50] - Loss: 2.7625
Epoch [40/50] - Loss: 2.7494
Epoch [41/50] - Loss: 2.7410
Epoch [42/50] - Loss: 2.7390
Epoch [43/50] - Loss: 2.7215
Epoch [44/50] - Loss: 2.7176
Epoch [45/50] - Loss: 2.6985
Epoch [46/50] - Loss: 2.6968
Epoch [47/50] - Loss: 2.6884
Epoch [48/50] - Loss: 2.6806
Epoch [49/50] - Loss: 2.6703
Epoch [50/50] - Loss: 2.6632
sum preds 0
sum labels 5513
 - Test Metrics: Accuracy=0.6823, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_naive_naive_1804201708.csv.
Average F1 over valid seeds: 0.0159 ± 0.0225
___________________________________________________________________________________
Avg F1 for pubmed with SAR and naive, MLP,0.3: 0.0159 ± 0.0225
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.7162
Epoch [2/50] - Loss: 3.9921
Epoch [3/50] - Loss: 3.7132
Epoch [4/50] - Loss: 3.6175
Epoch [5/50] - Loss: 3.4912
Epoch [6/50] - Loss: 3.4330
Epoch [7/50] - Loss: 3.3596
Epoch [8/50] - Loss: 3.3171
Epoch [9/50] - Loss: 3.2683
Epoch [10/50] - Loss: 3.2373
Epoch [11/50] - Loss: 3.1942
Epoch [12/50] - Loss: 3.1734
Epoch [13/50] - Loss: 3.1434
Epoch [14/50] - Loss: 3.1314
Epoch [15/50] - Loss: 3.1004
Epoch [16/50] - Loss: 3.0833
Epoch [17/50] - Loss: 3.0696
Epoch [18/50] - Loss: 3.0397
Epoch [19/50] - Loss: 3.0176
Epoch [20/50] - Loss: 2.9909
Epoch [21/50] - Loss: 2.9712
Epoch [22/50] - Loss: 2.9566
Epoch [23/50] - Loss: 2.9399
Epoch [24/50] - Loss: 2.9202
Epoch [25/50] - Loss: 2.8934
Epoch [26/50] - Loss: 2.8938
Epoch [27/50] - Loss: 2.8729
Epoch [28/50] - Loss: 2.8596
Epoch [29/50] - Loss: 2.8426
Epoch [30/50] - Loss: 2.8288
Epoch [31/50] - Loss: 2.8175
Epoch [32/50] - Loss: 2.8117
Epoch [33/50] - Loss: 2.7943
Epoch [34/50] - Loss: 2.7876
Epoch [35/50] - Loss: 2.7808
Epoch [36/50] - Loss: 2.7654
Epoch [37/50] - Loss: 2.7577
Epoch [38/50] - Loss: 2.7388
Epoch [39/50] - Loss: 2.7379
Epoch [40/50] - Loss: 2.7257
Epoch [41/50] - Loss: 2.7213
Epoch [42/50] - Loss: 2.7021
Epoch [43/50] - Loss: 2.7001
Epoch [44/50] - Loss: 2.6918
Epoch [45/50] - Loss: 2.6835
Epoch [46/50] - Loss: 2.6718
Epoch [47/50] - Loss: 2.6642
Epoch [48/50] - Loss: 2.6544
Epoch [49/50] - Loss: 2.6567
Epoch [50/50] - Loss: 2.6438
sum preds 122
sum labels 5513
 - Test Metrics: Accuracy=0.6883, F1=0.0401, Recall=0.0205, Precision=0.9262
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.7710
Epoch [2/50] - Loss: 4.0551
Epoch [3/50] - Loss: 3.6877
Epoch [4/50] - Loss: 3.6091
Epoch [5/50] - Loss: 3.4823
Epoch [6/50] - Loss: 3.4136
Epoch [7/50] - Loss: 3.3466
Epoch [8/50] - Loss: 3.2900
Epoch [9/50] - Loss: 3.2490
Epoch [10/50] - Loss: 3.2177
Epoch [11/50] - Loss: 3.1820
Epoch [12/50] - Loss: 3.1476
Epoch [13/50] - Loss: 3.1276
Epoch [14/50] - Loss: 3.1117
Epoch [15/50] - Loss: 3.0836
Epoch [16/50] - Loss: 3.0727
Epoch [17/50] - Loss: 3.0622
Epoch [18/50] - Loss: 3.0522
Epoch [19/50] - Loss: 3.0251
Epoch [20/50] - Loss: 3.0168
Epoch [21/50] - Loss: 3.0056
Epoch [22/50] - Loss: 2.9935
Epoch [23/50] - Loss: 2.9793
Epoch [24/50] - Loss: 2.9617
Epoch [25/50] - Loss: 2.9508
Epoch [26/50] - Loss: 2.9324
Epoch [27/50] - Loss: 2.9217
Epoch [28/50] - Loss: 2.9081
Epoch [29/50] - Loss: 2.8906
Epoch [30/50] - Loss: 2.8831
Epoch [31/50] - Loss: 2.8645
Epoch [32/50] - Loss: 2.8441
Epoch [33/50] - Loss: 2.8367
Epoch [34/50] - Loss: 2.8183
Epoch [35/50] - Loss: 2.8100
Epoch [36/50] - Loss: 2.7887
Epoch [37/50] - Loss: 2.7839
Epoch [38/50] - Loss: 2.7691
Epoch [39/50] - Loss: 2.7687
Epoch [40/50] - Loss: 2.7484
Epoch [41/50] - Loss: 2.7353
Epoch [42/50] - Loss: 2.7278
Epoch [43/50] - Loss: 2.7194
Epoch [44/50] - Loss: 2.7014
Epoch [45/50] - Loss: 2.7004
Epoch [46/50] - Loss: 2.6868
Epoch [47/50] - Loss: 2.6845
Epoch [48/50] - Loss: 2.6642
Epoch [49/50] - Loss: 2.6621
Epoch [50/50] - Loss: 2.6541
sum preds 107
sum labels 5513
 - Test Metrics: Accuracy=0.6880, F1=0.0367, Recall=0.0187, Precision=0.9626
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.0197
Epoch [2/50] - Loss: 4.3874
Epoch [3/50] - Loss: 3.7530
Epoch [4/50] - Loss: 3.6635
Epoch [5/50] - Loss: 3.5553
Epoch [6/50] - Loss: 3.4731
Epoch [7/50] - Loss: 3.4095
Epoch [8/50] - Loss: 3.3552
Epoch [9/50] - Loss: 3.3167
Epoch [10/50] - Loss: 3.2668
Epoch [11/50] - Loss: 3.2254
Epoch [12/50] - Loss: 3.1934
Epoch [13/50] - Loss: 3.1619
Epoch [14/50] - Loss: 3.1304
Epoch [15/50] - Loss: 3.1043
Epoch [16/50] - Loss: 3.0820
Epoch [17/50] - Loss: 3.0530
Epoch [18/50] - Loss: 3.0275
Epoch [19/50] - Loss: 3.0020
Epoch [20/50] - Loss: 2.9776
Epoch [21/50] - Loss: 2.9546
Epoch [22/50] - Loss: 2.9316
Epoch [23/50] - Loss: 2.9107
Epoch [24/50] - Loss: 2.8931
Epoch [25/50] - Loss: 2.8639
Epoch [26/50] - Loss: 2.8515
Epoch [27/50] - Loss: 2.8335
Epoch [28/50] - Loss: 2.8027
Epoch [29/50] - Loss: 2.7932
Epoch [30/50] - Loss: 2.7820
Epoch [31/50] - Loss: 2.7670
Epoch [32/50] - Loss: 2.7445
Epoch [33/50] - Loss: 2.7372
Epoch [34/50] - Loss: 2.7290
Epoch [35/50] - Loss: 2.7033
Epoch [36/50] - Loss: 2.6957
Epoch [37/50] - Loss: 2.6709
Epoch [38/50] - Loss: 2.6666
Epoch [39/50] - Loss: 2.6572
Epoch [40/50] - Loss: 2.6339
Epoch [41/50] - Loss: 2.6251
Epoch [42/50] - Loss: 2.6169
Epoch [43/50] - Loss: 2.5969
Epoch [44/50] - Loss: 2.5958
Epoch [45/50] - Loss: 2.5852
Epoch [46/50] - Loss: 2.5670
Epoch [47/50] - Loss: 2.5574
Epoch [48/50] - Loss: 2.5447
Epoch [49/50] - Loss: 2.5249
Epoch [50/50] - Loss: 2.5161
sum preds 126
sum labels 5513
 - Test Metrics: Accuracy=0.6889, F1=0.0426, Recall=0.0218, Precision=0.9524
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_naive_naive_1804204441.csv.
Average F1 over valid seeds: 0.0398 ± 0.0024
___________________________________________________________________________________
Avg F1 for pubmed with SAR and naive, GATConv,0.3: 0.0398 ± 0.0024
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.2366
Epoch [2/50] - Loss: 4.8194
Epoch [3/50] - Loss: 3.9920
Epoch [4/50] - Loss: 3.7712
Epoch [5/50] - Loss: 3.7196
Epoch [6/50] - Loss: 3.6431
Epoch [7/50] - Loss: 3.5806
Epoch [8/50] - Loss: 3.5276
Epoch [9/50] - Loss: 3.4838
Epoch [10/50] - Loss: 3.4454
Epoch [11/50] - Loss: 3.4085
Epoch [12/50] - Loss: 3.3698
Epoch [13/50] - Loss: 3.3456
Epoch [14/50] - Loss: 3.3186
Epoch [15/50] - Loss: 3.2860
Epoch [16/50] - Loss: 3.2680
Epoch [17/50] - Loss: 3.2502
Epoch [18/50] - Loss: 3.2255
Epoch [19/50] - Loss: 3.2162
Epoch [20/50] - Loss: 3.1991
Epoch [21/50] - Loss: 3.1940
Epoch [22/50] - Loss: 3.1763
Epoch [23/50] - Loss: 3.1636
Epoch [24/50] - Loss: 3.1499
Epoch [25/50] - Loss: 3.1385
Epoch [26/50] - Loss: 3.1351
Epoch [27/50] - Loss: 3.1197
Epoch [28/50] - Loss: 3.1132
Epoch [29/50] - Loss: 3.1130
Epoch [30/50] - Loss: 3.0995
Epoch [31/50] - Loss: 3.0962
Epoch [32/50] - Loss: 3.0894
Epoch [33/50] - Loss: 3.0862
Epoch [34/50] - Loss: 3.0800
Epoch [35/50] - Loss: 3.0688
Epoch [36/50] - Loss: 3.0634
Epoch [37/50] - Loss: 3.0526
Epoch [38/50] - Loss: 3.0546
Epoch [39/50] - Loss: 3.0408
Epoch [40/50] - Loss: 3.0513
Epoch [41/50] - Loss: 3.0472
Epoch [42/50] - Loss: 3.0349
Epoch [43/50] - Loss: 3.0336
Epoch [44/50] - Loss: 3.0299
Epoch [45/50] - Loss: 3.0169
Epoch [46/50] - Loss: 3.0161
Epoch [47/50] - Loss: 3.0161
Epoch [48/50] - Loss: 3.0107
Epoch [49/50] - Loss: 3.0110
Epoch [50/50] - Loss: 3.0056
sum preds 0
sum labels 5513
 - Test Metrics: Accuracy=0.6823, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.1022
Epoch [2/50] - Loss: 4.6304
Epoch [3/50] - Loss: 3.8931
Epoch [4/50] - Loss: 3.7249
Epoch [5/50] - Loss: 3.6769
Epoch [6/50] - Loss: 3.5956
Epoch [7/50] - Loss: 3.5284
Epoch [8/50] - Loss: 3.4819
Epoch [9/50] - Loss: 3.4297
Epoch [10/50] - Loss: 3.3923
Epoch [11/50] - Loss: 3.3516
Epoch [12/50] - Loss: 3.3164
Epoch [13/50] - Loss: 3.2908
Epoch [14/50] - Loss: 3.2646
Epoch [15/50] - Loss: 3.2478
Epoch [16/50] - Loss: 3.2255
Epoch [17/50] - Loss: 3.2087
Epoch [18/50] - Loss: 3.1856
Epoch [19/50] - Loss: 3.1732
Epoch [20/50] - Loss: 3.1579
Epoch [21/50] - Loss: 3.1406
Epoch [22/50] - Loss: 3.1348
Epoch [23/50] - Loss: 3.1150
Epoch [24/50] - Loss: 3.1148
Epoch [25/50] - Loss: 3.0970
Epoch [26/50] - Loss: 3.0928
Epoch [27/50] - Loss: 3.0869
Epoch [28/50] - Loss: 3.0760
Epoch [29/50] - Loss: 3.0676
Epoch [30/50] - Loss: 3.0663
Epoch [31/50] - Loss: 3.0676
Epoch [32/50] - Loss: 3.0558
Epoch [33/50] - Loss: 3.0449
Epoch [34/50] - Loss: 3.0364
Epoch [35/50] - Loss: 3.0371
Epoch [36/50] - Loss: 3.0245
Epoch [37/50] - Loss: 3.0176
Epoch [38/50] - Loss: 3.0192
Epoch [39/50] - Loss: 3.0119
Epoch [40/50] - Loss: 3.0094
Epoch [41/50] - Loss: 3.0032
Epoch [42/50] - Loss: 2.9980
Epoch [43/50] - Loss: 2.9905
Epoch [44/50] - Loss: 2.9904
Epoch [45/50] - Loss: 2.9792
Epoch [46/50] - Loss: 2.9852
Epoch [47/50] - Loss: 2.9817
Epoch [48/50] - Loss: 2.9726
Epoch [49/50] - Loss: 2.9744
Epoch [50/50] - Loss: 2.9632
sum preds 0
sum labels 5513
 - Test Metrics: Accuracy=0.6823, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.3089
Epoch [2/50] - Loss: 4.9675
Epoch [3/50] - Loss: 4.0696
Epoch [4/50] - Loss: 3.7884
Epoch [5/50] - Loss: 3.7300
Epoch [6/50] - Loss: 3.6717
Epoch [7/50] - Loss: 3.5980
Epoch [8/50] - Loss: 3.5320
Epoch [9/50] - Loss: 3.4944
Epoch [10/50] - Loss: 3.4545
Epoch [11/50] - Loss: 3.4125
Epoch [12/50] - Loss: 3.3786
Epoch [13/50] - Loss: 3.3392
Epoch [14/50] - Loss: 3.3185
Epoch [15/50] - Loss: 3.2925
Epoch [16/50] - Loss: 3.2682
Epoch [17/50] - Loss: 3.2441
Epoch [18/50] - Loss: 3.2236
Epoch [19/50] - Loss: 3.2088
Epoch [20/50] - Loss: 3.1996
Epoch [21/50] - Loss: 3.1755
Epoch [22/50] - Loss: 3.1776
Epoch [23/50] - Loss: 3.1599
Epoch [24/50] - Loss: 3.1538
Epoch [25/50] - Loss: 3.1451
Epoch [26/50] - Loss: 3.1377
Epoch [27/50] - Loss: 3.1246
Epoch [28/50] - Loss: 3.1204
Epoch [29/50] - Loss: 3.1050
Epoch [30/50] - Loss: 3.1059
Epoch [31/50] - Loss: 3.0947
Epoch [32/50] - Loss: 3.0914
Epoch [33/50] - Loss: 3.0904
Epoch [34/50] - Loss: 3.0777
Epoch [35/50] - Loss: 3.0737
Epoch [36/50] - Loss: 3.0604
Epoch [37/50] - Loss: 3.0593
Epoch [38/50] - Loss: 3.0573
Epoch [39/50] - Loss: 3.0510
Epoch [40/50] - Loss: 3.0466
Epoch [41/50] - Loss: 3.0403
Epoch [42/50] - Loss: 3.0396
Epoch [43/50] - Loss: 3.0359
Epoch [44/50] - Loss: 3.0287
Epoch [45/50] - Loss: 3.0201
Epoch [46/50] - Loss: 3.0218
Epoch [47/50] - Loss: 3.0240
Epoch [48/50] - Loss: 3.0127
Epoch [49/50] - Loss: 3.0102
Epoch [50/50] - Loss: 3.0058
sum preds 0
sum labels 5513
 - Test Metrics: Accuracy=0.6823, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_naive_naive_1804211206.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for pubmed with SAR and naive, GCNConv,0.3: 0.0000 ± 0.0000
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.2451
Epoch [2/50] - Loss: 3.8652
Epoch [3/50] - Loss: 2.9618
Epoch [4/50] - Loss: 2.8178
Epoch [5/50] - Loss: 2.7679
Epoch [6/50] - Loss: 2.6725
Epoch [7/50] - Loss: 2.6185
Epoch [8/50] - Loss: 2.5572
Epoch [9/50] - Loss: 2.5176
Epoch [10/50] - Loss: 2.4748
Epoch [11/50] - Loss: 2.4503
Epoch [12/50] - Loss: 2.4234
Epoch [13/50] - Loss: 2.4125
Epoch [14/50] - Loss: 2.3827
Epoch [15/50] - Loss: 2.3748
Epoch [16/50] - Loss: 2.3537
Epoch [17/50] - Loss: 2.3410
Epoch [18/50] - Loss: 2.3375
Epoch [19/50] - Loss: 2.3276
Epoch [20/50] - Loss: 2.3198
Epoch [21/50] - Loss: 2.3115
Epoch [22/50] - Loss: 2.3050
Epoch [23/50] - Loss: 2.3025
Epoch [24/50] - Loss: 2.3034
Epoch [25/50] - Loss: 2.2931
Epoch [26/50] - Loss: 2.2903
Epoch [27/50] - Loss: 2.2945
Epoch [28/50] - Loss: 2.2842
Epoch [29/50] - Loss: 2.2833
Epoch [30/50] - Loss: 2.2859
Epoch [31/50] - Loss: 2.2837
Epoch [32/50] - Loss: 2.2805
Epoch [33/50] - Loss: 2.2764
Epoch [34/50] - Loss: 2.2776
Epoch [35/50] - Loss: 2.2762
Epoch [36/50] - Loss: 2.2758
Epoch [37/50] - Loss: 2.2722
Epoch [38/50] - Loss: 2.2695
Epoch [39/50] - Loss: 2.2611
Epoch [40/50] - Loss: 2.2657
Epoch [41/50] - Loss: 2.2583
Epoch [42/50] - Loss: 2.2540
Epoch [43/50] - Loss: 2.2550
Epoch [44/50] - Loss: 2.2538
Epoch [45/50] - Loss: 2.2474
Epoch [46/50] - Loss: 2.2445
Epoch [47/50] - Loss: 2.2466
Epoch [48/50] - Loss: 2.2425
Epoch [49/50] - Loss: 2.2354
Epoch [50/50] - Loss: 2.2405
sum preds 59
sum labels 6300
 - Test Metrics: Accuracy=0.6556, F1=0.0173, Recall=0.0087, Precision=0.9322
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.2366
Epoch [2/50] - Loss: 4.1275
Epoch [3/50] - Loss: 3.1941
Epoch [4/50] - Loss: 2.8485
Epoch [5/50] - Loss: 2.7996
Epoch [6/50] - Loss: 2.7464
Epoch [7/50] - Loss: 2.6961
Epoch [8/50] - Loss: 2.6626
Epoch [9/50] - Loss: 2.6325
Epoch [10/50] - Loss: 2.5890
Epoch [11/50] - Loss: 2.5653
Epoch [12/50] - Loss: 2.5429
Epoch [13/50] - Loss: 2.5209
Epoch [14/50] - Loss: 2.5040
Epoch [15/50] - Loss: 2.4911
Epoch [16/50] - Loss: 2.4754
Epoch [17/50] - Loss: 2.4560
Epoch [18/50] - Loss: 2.4413
Epoch [19/50] - Loss: 2.4326
Epoch [20/50] - Loss: 2.4093
Epoch [21/50] - Loss: 2.4050
Epoch [22/50] - Loss: 2.4004
Epoch [23/50] - Loss: 2.3805
Epoch [24/50] - Loss: 2.3732
Epoch [25/50] - Loss: 2.3704
Epoch [26/50] - Loss: 2.3584
Epoch [27/50] - Loss: 2.3508
Epoch [28/50] - Loss: 2.3443
Epoch [29/50] - Loss: 2.3383
Epoch [30/50] - Loss: 2.3291
Epoch [31/50] - Loss: 2.3180
Epoch [32/50] - Loss: 2.3194
Epoch [33/50] - Loss: 2.3053
Epoch [34/50] - Loss: 2.3029
Epoch [35/50] - Loss: 2.2985
Epoch [36/50] - Loss: 2.2924
Epoch [37/50] - Loss: 2.2884
Epoch [38/50] - Loss: 2.2793
Epoch [39/50] - Loss: 2.2709
Epoch [40/50] - Loss: 2.2808
Epoch [41/50] - Loss: 2.2579
Epoch [42/50] - Loss: 2.2614
Epoch [43/50] - Loss: 2.2570
Epoch [44/50] - Loss: 2.2522
Epoch [45/50] - Loss: 2.2462
Epoch [46/50] - Loss: 2.2433
Epoch [47/50] - Loss: 2.2403
Epoch [48/50] - Loss: 2.2310
Epoch [49/50] - Loss: 2.2341
Epoch [50/50] - Loss: 2.2201
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1374
Epoch [2/50] - Loss: 3.7710
Epoch [3/50] - Loss: 2.9552
Epoch [4/50] - Loss: 2.8233
Epoch [5/50] - Loss: 2.7644
Epoch [6/50] - Loss: 2.6838
Epoch [7/50] - Loss: 2.6361
Epoch [8/50] - Loss: 2.5942
Epoch [9/50] - Loss: 2.5594
Epoch [10/50] - Loss: 2.5177
Epoch [11/50] - Loss: 2.5021
Epoch [12/50] - Loss: 2.4742
Epoch [13/50] - Loss: 2.4546
Epoch [14/50] - Loss: 2.4361
Epoch [15/50] - Loss: 2.4179
Epoch [16/50] - Loss: 2.3978
Epoch [17/50] - Loss: 2.3898
Epoch [18/50] - Loss: 2.3625
Epoch [19/50] - Loss: 2.3580
Epoch [20/50] - Loss: 2.3468
Epoch [21/50] - Loss: 2.3344
Epoch [22/50] - Loss: 2.3291
Epoch [23/50] - Loss: 2.3115
Epoch [24/50] - Loss: 2.2987
Epoch [25/50] - Loss: 2.2997
Epoch [26/50] - Loss: 2.2895
Epoch [27/50] - Loss: 2.2743
Epoch [28/50] - Loss: 2.2757
Epoch [29/50] - Loss: 2.2574
Epoch [30/50] - Loss: 2.2535
Epoch [31/50] - Loss: 2.2458
Epoch [32/50] - Loss: 2.2370
Epoch [33/50] - Loss: 2.2296
Epoch [34/50] - Loss: 2.2239
Epoch [35/50] - Loss: 2.2259
Epoch [36/50] - Loss: 2.2106
Epoch [37/50] - Loss: 2.2105
Epoch [38/50] - Loss: 2.2034
Epoch [39/50] - Loss: 2.2019
Epoch [40/50] - Loss: 2.1928
Epoch [41/50] - Loss: 2.1859
Epoch [42/50] - Loss: 2.1841
Epoch [43/50] - Loss: 2.1709
Epoch [44/50] - Loss: 2.1660
Epoch [45/50] - Loss: 2.1546
Epoch [46/50] - Loss: 2.1510
Epoch [47/50] - Loss: 2.1452
Epoch [48/50] - Loss: 2.1420
Epoch [49/50] - Loss: 2.1322
Epoch [50/50] - Loss: 2.1277
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_naive_naive_1804213955.csv.
Average F1 over valid seeds: 0.0058 ± 0.0082
___________________________________________________________________________________
Avg F1 for pubmed with SAR and naive, MLP,0.2: 0.0058 ± 0.0082
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.5468
Epoch [2/50] - Loss: 3.3906
Epoch [3/50] - Loss: 2.8535
Epoch [4/50] - Loss: 2.8401
Epoch [5/50] - Loss: 2.7490
Epoch [6/50] - Loss: 2.6885
Epoch [7/50] - Loss: 2.6521
Epoch [8/50] - Loss: 2.6189
Epoch [9/50] - Loss: 2.5808
Epoch [10/50] - Loss: 2.5650
Epoch [11/50] - Loss: 2.5327
Epoch [12/50] - Loss: 2.5224
Epoch [13/50] - Loss: 2.4968
Epoch [14/50] - Loss: 2.4911
Epoch [15/50] - Loss: 2.4675
Epoch [16/50] - Loss: 2.4574
Epoch [17/50] - Loss: 2.4506
Epoch [18/50] - Loss: 2.4287
Epoch [19/50] - Loss: 2.4125
Epoch [20/50] - Loss: 2.3967
Epoch [21/50] - Loss: 2.3781
Epoch [22/50] - Loss: 2.3682
Epoch [23/50] - Loss: 2.3559
Epoch [24/50] - Loss: 2.3336
Epoch [25/50] - Loss: 2.3143
Epoch [26/50] - Loss: 2.3121
Epoch [27/50] - Loss: 2.2887
Epoch [28/50] - Loss: 2.2718
Epoch [29/50] - Loss: 2.2537
Epoch [30/50] - Loss: 2.2410
Epoch [31/50] - Loss: 2.2267
Epoch [32/50] - Loss: 2.2200
Epoch [33/50] - Loss: 2.1974
Epoch [34/50] - Loss: 2.1916
Epoch [35/50] - Loss: 2.1801
Epoch [36/50] - Loss: 2.1623
Epoch [37/50] - Loss: 2.1557
Epoch [38/50] - Loss: 2.1418
Epoch [39/50] - Loss: 2.1358
Epoch [40/50] - Loss: 2.1297
Epoch [41/50] - Loss: 2.1200
Epoch [42/50] - Loss: 2.1052
Epoch [43/50] - Loss: 2.0986
Epoch [44/50] - Loss: 2.0932
Epoch [45/50] - Loss: 2.0820
Epoch [46/50] - Loss: 2.0737
Epoch [47/50] - Loss: 2.0617
Epoch [48/50] - Loss: 2.0531
Epoch [49/50] - Loss: 2.0534
Epoch [50/50] - Loss: 2.0354
sum preds 37
sum labels 6300
 - Test Metrics: Accuracy=0.6544, F1=0.0107, Recall=0.0054, Precision=0.9189
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.6189
Epoch [2/50] - Loss: 3.5044
Epoch [3/50] - Loss: 2.8669
Epoch [4/50] - Loss: 2.8262
Epoch [5/50] - Loss: 2.7599
Epoch [6/50] - Loss: 2.6880
Epoch [7/50] - Loss: 2.6405
Epoch [8/50] - Loss: 2.6041
Epoch [9/50] - Loss: 2.5795
Epoch [10/50] - Loss: 2.5582
Epoch [11/50] - Loss: 2.5326
Epoch [12/50] - Loss: 2.5063
Epoch [13/50] - Loss: 2.4918
Epoch [14/50] - Loss: 2.4797
Epoch [15/50] - Loss: 2.4593
Epoch [16/50] - Loss: 2.4461
Epoch [17/50] - Loss: 2.4418
Epoch [18/50] - Loss: 2.4338
Epoch [19/50] - Loss: 2.4107
Epoch [20/50] - Loss: 2.4065
Epoch [21/50] - Loss: 2.3980
Epoch [22/50] - Loss: 2.3908
Epoch [23/50] - Loss: 2.3811
Epoch [24/50] - Loss: 2.3702
Epoch [25/50] - Loss: 2.3636
Epoch [26/50] - Loss: 2.3546
Epoch [27/50] - Loss: 2.3444
Epoch [28/50] - Loss: 2.3370
Epoch [29/50] - Loss: 2.3215
Epoch [30/50] - Loss: 2.3176
Epoch [31/50] - Loss: 2.3038
Epoch [32/50] - Loss: 2.2898
Epoch [33/50] - Loss: 2.2796
Epoch [34/50] - Loss: 2.2721
Epoch [35/50] - Loss: 2.2674
Epoch [36/50] - Loss: 2.2462
Epoch [37/50] - Loss: 2.2384
Epoch [38/50] - Loss: 2.2314
Epoch [39/50] - Loss: 2.2274
Epoch [40/50] - Loss: 2.2118
Epoch [41/50] - Loss: 2.2010
Epoch [42/50] - Loss: 2.1925
Epoch [43/50] - Loss: 2.1842
Epoch [44/50] - Loss: 2.1733
Epoch [45/50] - Loss: 2.1651
Epoch [46/50] - Loss: 2.1582
Epoch [47/50] - Loss: 2.1466
Epoch [48/50] - Loss: 2.1334
Epoch [49/50] - Loss: 2.1282
Epoch [50/50] - Loss: 2.1213
sum preds 28
sum labels 6300
 - Test Metrics: Accuracy=0.6543, F1=0.0088, Recall=0.0044, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.9043
Epoch [2/50] - Loss: 3.9530
Epoch [3/50] - Loss: 3.0084
Epoch [4/50] - Loss: 2.8267
Epoch [5/50] - Loss: 2.7884
Epoch [6/50] - Loss: 2.7366
Epoch [7/50] - Loss: 2.6807
Epoch [8/50] - Loss: 2.6487
Epoch [9/50] - Loss: 2.6238
Epoch [10/50] - Loss: 2.5873
Epoch [11/50] - Loss: 2.5608
Epoch [12/50] - Loss: 2.5419
Epoch [13/50] - Loss: 2.5233
Epoch [14/50] - Loss: 2.4944
Epoch [15/50] - Loss: 2.4795
Epoch [16/50] - Loss: 2.4618
Epoch [17/50] - Loss: 2.4460
Epoch [18/50] - Loss: 2.4292
Epoch [19/50] - Loss: 2.4175
Epoch [20/50] - Loss: 2.3995
Epoch [21/50] - Loss: 2.3847
Epoch [22/50] - Loss: 2.3659
Epoch [23/50] - Loss: 2.3516
Epoch [24/50] - Loss: 2.3405
Epoch [25/50] - Loss: 2.3209
Epoch [26/50] - Loss: 2.3099
Epoch [27/50] - Loss: 2.2901
Epoch [28/50] - Loss: 2.2617
Epoch [29/50] - Loss: 2.2480
Epoch [30/50] - Loss: 2.2320
Epoch [31/50] - Loss: 2.2073
Epoch [32/50] - Loss: 2.1839
Epoch [33/50] - Loss: 2.1668
Epoch [34/50] - Loss: 2.1570
Epoch [35/50] - Loss: 2.1275
Epoch [36/50] - Loss: 2.1180
Epoch [37/50] - Loss: 2.0944
Epoch [38/50] - Loss: 2.0870
Epoch [39/50] - Loss: 2.0740
Epoch [40/50] - Loss: 2.0559
Epoch [41/50] - Loss: 2.0444
Epoch [42/50] - Loss: 2.0397
Epoch [43/50] - Loss: 2.0216
Epoch [44/50] - Loss: 2.0126
Epoch [45/50] - Loss: 2.0018
Epoch [46/50] - Loss: 1.9887
Epoch [47/50] - Loss: 1.9785
Epoch [48/50] - Loss: 1.9694
Epoch [49/50] - Loss: 1.9529
Epoch [50/50] - Loss: 1.9492
sum preds 55
sum labels 6300
 - Test Metrics: Accuracy=0.6551, F1=0.0154, Recall=0.0078, Precision=0.8909
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_naive_naive_1804221012.csv.
Average F1 over valid seeds: 0.0117 ± 0.0028
___________________________________________________________________________________
Avg F1 for pubmed with SAR and naive, GATConv,0.2: 0.0117 ± 0.0028
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.1518
Epoch [2/50] - Loss: 4.4979
Epoch [3/50] - Loss: 3.3860
Epoch [4/50] - Loss: 2.9623
Epoch [5/50] - Loss: 2.8830
Epoch [6/50] - Loss: 2.8654
Epoch [7/50] - Loss: 2.8188
Epoch [8/50] - Loss: 2.7811
Epoch [9/50] - Loss: 2.7546
Epoch [10/50] - Loss: 2.7340
Epoch [11/50] - Loss: 2.7076
Epoch [12/50] - Loss: 2.6827
Epoch [13/50] - Loss: 2.6693
Epoch [14/50] - Loss: 2.6458
Epoch [15/50] - Loss: 2.6246
Epoch [16/50] - Loss: 2.6122
Epoch [17/50] - Loss: 2.6002
Epoch [18/50] - Loss: 2.5830
Epoch [19/50] - Loss: 2.5745
Epoch [20/50] - Loss: 2.5626
Epoch [21/50] - Loss: 2.5548
Epoch [22/50] - Loss: 2.5424
Epoch [23/50] - Loss: 2.5317
Epoch [24/50] - Loss: 2.5216
Epoch [25/50] - Loss: 2.5100
Epoch [26/50] - Loss: 2.5106
Epoch [27/50] - Loss: 2.4914
Epoch [28/50] - Loss: 2.4900
Epoch [29/50] - Loss: 2.4906
Epoch [30/50] - Loss: 2.4825
Epoch [31/50] - Loss: 2.4782
Epoch [32/50] - Loss: 2.4715
Epoch [33/50] - Loss: 2.4698
Epoch [34/50] - Loss: 2.4611
Epoch [35/50] - Loss: 2.4572
Epoch [36/50] - Loss: 2.4518
Epoch [37/50] - Loss: 2.4428
Epoch [38/50] - Loss: 2.4462
Epoch [39/50] - Loss: 2.4324
Epoch [40/50] - Loss: 2.4447
Epoch [41/50] - Loss: 2.4343
Epoch [42/50] - Loss: 2.4277
Epoch [43/50] - Loss: 2.4318
Epoch [44/50] - Loss: 2.4237
Epoch [45/50] - Loss: 2.4114
Epoch [46/50] - Loss: 2.4108
Epoch [47/50] - Loss: 2.4124
Epoch [48/50] - Loss: 2.4076
Epoch [49/50] - Loss: 2.4073
Epoch [50/50] - Loss: 2.4029
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.9994
Epoch [2/50] - Loss: 4.2671
Epoch [3/50] - Loss: 3.2457
Epoch [4/50] - Loss: 2.9100
Epoch [5/50] - Loss: 2.8675
Epoch [6/50] - Loss: 2.8325
Epoch [7/50] - Loss: 2.7837
Epoch [8/50] - Loss: 2.7526
Epoch [9/50] - Loss: 2.7190
Epoch [10/50] - Loss: 2.6932
Epoch [11/50] - Loss: 2.6697
Epoch [12/50] - Loss: 2.6439
Epoch [13/50] - Loss: 2.6254
Epoch [14/50] - Loss: 2.6107
Epoch [15/50] - Loss: 2.5985
Epoch [16/50] - Loss: 2.5832
Epoch [17/50] - Loss: 2.5707
Epoch [18/50] - Loss: 2.5561
Epoch [19/50] - Loss: 2.5387
Epoch [20/50] - Loss: 2.5324
Epoch [21/50] - Loss: 2.5148
Epoch [22/50] - Loss: 2.5112
Epoch [23/50] - Loss: 2.4973
Epoch [24/50] - Loss: 2.4977
Epoch [25/50] - Loss: 2.4805
Epoch [26/50] - Loss: 2.4810
Epoch [27/50] - Loss: 2.4755
Epoch [28/50] - Loss: 2.4658
Epoch [29/50] - Loss: 2.4595
Epoch [30/50] - Loss: 2.4562
Epoch [31/50] - Loss: 2.4582
Epoch [32/50] - Loss: 2.4489
Epoch [33/50] - Loss: 2.4388
Epoch [34/50] - Loss: 2.4353
Epoch [35/50] - Loss: 2.4365
Epoch [36/50] - Loss: 2.4289
Epoch [37/50] - Loss: 2.4187
Epoch [38/50] - Loss: 2.4205
Epoch [39/50] - Loss: 2.4141
Epoch [40/50] - Loss: 2.4111
Epoch [41/50] - Loss: 2.4112
Epoch [42/50] - Loss: 2.4069
Epoch [43/50] - Loss: 2.3964
Epoch [44/50] - Loss: 2.3981
Epoch [45/50] - Loss: 2.3857
Epoch [46/50] - Loss: 2.3910
Epoch [47/50] - Loss: 2.3890
Epoch [48/50] - Loss: 2.3832
Epoch [49/50] - Loss: 2.3854
Epoch [50/50] - Loss: 2.3757
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 6.2373
Epoch [2/50] - Loss: 4.6822
Epoch [3/50] - Loss: 3.5133
Epoch [4/50] - Loss: 3.0070
Epoch [5/50] - Loss: 2.9023
Epoch [6/50] - Loss: 2.8844
Epoch [7/50] - Loss: 2.8391
Epoch [8/50] - Loss: 2.7878
Epoch [9/50] - Loss: 2.7664
Epoch [10/50] - Loss: 2.7384
Epoch [11/50] - Loss: 2.7123
Epoch [12/50] - Loss: 2.6900
Epoch [13/50] - Loss: 2.6621
Epoch [14/50] - Loss: 2.6490
Epoch [15/50] - Loss: 2.6315
Epoch [16/50] - Loss: 2.6153
Epoch [17/50] - Loss: 2.5978
Epoch [18/50] - Loss: 2.5772
Epoch [19/50] - Loss: 2.5653
Epoch [20/50] - Loss: 2.5576
Epoch [21/50] - Loss: 2.5383
Epoch [22/50] - Loss: 2.5370
Epoch [23/50] - Loss: 2.5264
Epoch [24/50] - Loss: 2.5207
Epoch [25/50] - Loss: 2.5140
Epoch [26/50] - Loss: 2.5092
Epoch [27/50] - Loss: 2.4981
Epoch [28/50] - Loss: 2.4942
Epoch [29/50] - Loss: 2.4810
Epoch [30/50] - Loss: 2.4782
Epoch [31/50] - Loss: 2.4742
Epoch [32/50] - Loss: 2.4743
Epoch [33/50] - Loss: 2.4704
Epoch [34/50] - Loss: 2.4622
Epoch [35/50] - Loss: 2.4587
Epoch [36/50] - Loss: 2.4489
Epoch [37/50] - Loss: 2.4428
Epoch [38/50] - Loss: 2.4509
Epoch [39/50] - Loss: 2.4382
Epoch [40/50] - Loss: 2.4359
Epoch [41/50] - Loss: 2.4282
Epoch [42/50] - Loss: 2.4314
Epoch [43/50] - Loss: 2.4268
Epoch [44/50] - Loss: 2.4214
Epoch [45/50] - Loss: 2.4179
Epoch [46/50] - Loss: 2.4167
Epoch [47/50] - Loss: 2.4197
Epoch [48/50] - Loss: 2.4051
Epoch [49/50] - Loss: 2.4048
Epoch [50/50] - Loss: 2.4040
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_naive_naive_1804224131.csv.
Average F1 over valid seeds: 0.0000 ± 0.0000
___________________________________________________________________________________
Avg F1 for pubmed with SAR and naive, GCNConv,0.2: 0.0000 ± 0.0000
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8490, F1=0.6747, Recall=0.5492, Precision=0.8746
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8384, F1=0.6455, Recall=0.5160, Precision=0.8618
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8459, F1=0.6640, Recall=0.5340, Precision=0.8779
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_NNIF_NNIF_1804231301.csv.
Average F1 over valid seeds: 0.6614 ± 0.0121
___________________________________________________________________________________
Avg F1 for pubmed with SAR and NNIF, MLP,0.4: 0.6614 ± 0.0121
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8284, F1=0.6582, Recall=0.5200, Precision=0.8962
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8191, F1=0.6364, Recall=0.4985, Precision=0.8799
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8228, F1=0.6449, Recall=0.5066, Precision=0.8869
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_NNIF_NNIF_1804231412.csv.
Average F1 over valid seeds: 0.6465 ± 0.0090
___________________________________________________________________________________
Avg F1 for pubmed with SAR and NNIF, MLP,0.3: 0.6465 ± 0.0090
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7947, F1=0.6052, Recall=0.4530, Precision=0.9112
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7715, F1=0.5415, Recall=0.3886, Precision=0.8928
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.7839, F1=0.5782, Recall=0.4265, Precision=0.8972
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_NNIF_NNIF_1804231458.csv.
Average F1 over valid seeds: 0.5749 ± 0.0261
___________________________________________________________________________________
Avg F1 for pubmed with SAR and NNIF, MLP,0.2: 0.5749 ± 0.0261
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.6876
Epoch [2/50] - Loss: 4.1383
Epoch [3/50] - Loss: 3.6734
Epoch [4/50] - Loss: 3.4130
Epoch [5/50] - Loss: 3.1483
Epoch [6/50] - Loss: 2.8909
Epoch [7/50] - Loss: 2.6582
Epoch [8/50] - Loss: 2.4496
Epoch [9/50] - Loss: 2.2877
Epoch [10/50] - Loss: 2.1614
Epoch [11/50] - Loss: 2.0765
Epoch [12/50] - Loss: 2.0122
Epoch [13/50] - Loss: 1.9552
Epoch [14/50] - Loss: 1.9104
Epoch [15/50] - Loss: 1.8837
Epoch [16/50] - Loss: 1.8560
Epoch [17/50] - Loss: 1.8375
Epoch [18/50] - Loss: 1.8223
Epoch [19/50] - Loss: 1.8049
Epoch [20/50] - Loss: 1.7923
Epoch [21/50] - Loss: 1.7770
Epoch [22/50] - Loss: 1.7765
Epoch [23/50] - Loss: 1.7684
Epoch [24/50] - Loss: 1.7485
Epoch [25/50] - Loss: 1.7464
Epoch [26/50] - Loss: 1.7424
Epoch [27/50] - Loss: 1.7407
Epoch [28/50] - Loss: 1.7326
Epoch [29/50] - Loss: 1.7315
Epoch [30/50] - Loss: 1.7217
Epoch [31/50] - Loss: 1.7204
Epoch [32/50] - Loss: 1.7212
Epoch [33/50] - Loss: 1.7139
Epoch [34/50] - Loss: 1.7142
Epoch [35/50] - Loss: 1.7120
Epoch [36/50] - Loss: 1.7100
Epoch [37/50] - Loss: 1.7061
Epoch [38/50] - Loss: 1.7091
Epoch [39/50] - Loss: 1.7066
Epoch [40/50] - Loss: 1.7045
Epoch [41/50] - Loss: 1.6998
Epoch [42/50] - Loss: 1.7034
Epoch [43/50] - Loss: 1.7036
Epoch [44/50] - Loss: 1.6949
Epoch [45/50] - Loss: 1.6944
Epoch [46/50] - Loss: 1.6984
Epoch [47/50] - Loss: 1.6964
Epoch [48/50] - Loss: 1.6939
Epoch [49/50] - Loss: 1.6994
Epoch [50/50] - Loss: 1.6844
sum preds 3419
sum labels 4725
 - Test Metrics: Accuracy=0.8522, F1=0.6994, Recall=0.6028, Precision=0.8330
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.6205
Epoch [2/50] - Loss: 4.1199
Epoch [3/50] - Loss: 3.6576
Epoch [4/50] - Loss: 3.3295
Epoch [5/50] - Loss: 3.0165
Epoch [6/50] - Loss: 2.7219
Epoch [7/50] - Loss: 2.4765
Epoch [8/50] - Loss: 2.2911
Epoch [9/50] - Loss: 2.1603
Epoch [10/50] - Loss: 2.0585
Epoch [11/50] - Loss: 1.9918
Epoch [12/50] - Loss: 1.9408
Epoch [13/50] - Loss: 1.8968
Epoch [14/50] - Loss: 1.8583
Epoch [15/50] - Loss: 1.8286
Epoch [16/50] - Loss: 1.8090
Epoch [17/50] - Loss: 1.7824
Epoch [18/50] - Loss: 1.7771
Epoch [19/50] - Loss: 1.7579
Epoch [20/50] - Loss: 1.7397
Epoch [21/50] - Loss: 1.7372
Epoch [22/50] - Loss: 1.7160
Epoch [23/50] - Loss: 1.7126
Epoch [24/50] - Loss: 1.7064
Epoch [25/50] - Loss: 1.6880
Epoch [26/50] - Loss: 1.6899
Epoch [27/50] - Loss: 1.6876
Epoch [28/50] - Loss: 1.6834
Epoch [29/50] - Loss: 1.6761
Epoch [30/50] - Loss: 1.6716
Epoch [31/50] - Loss: 1.6723
Epoch [32/50] - Loss: 1.6652
Epoch [33/50] - Loss: 1.6644
Epoch [34/50] - Loss: 1.6593
Epoch [35/50] - Loss: 1.6582
Epoch [36/50] - Loss: 1.6581
Epoch [37/50] - Loss: 1.6468
Epoch [38/50] - Loss: 1.6461
Epoch [39/50] - Loss: 1.6517
Epoch [40/50] - Loss: 1.6425
Epoch [41/50] - Loss: 1.6441
Epoch [42/50] - Loss: 1.6468
Epoch [43/50] - Loss: 1.6481
Epoch [44/50] - Loss: 1.6398
Epoch [45/50] - Loss: 1.6395
Epoch [46/50] - Loss: 1.6332
Epoch [47/50] - Loss: 1.6373
Epoch [48/50] - Loss: 1.6336
Epoch [49/50] - Loss: 1.6291
Epoch [50/50] - Loss: 1.6119
sum preds 3378
sum labels 4725
 - Test Metrics: Accuracy=0.8516, F1=0.6965, Recall=0.5972, Precision=0.8354
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.9685
Epoch [2/50] - Loss: 4.3468
Epoch [3/50] - Loss: 3.7865
Epoch [4/50] - Loss: 3.4950
Epoch [5/50] - Loss: 3.2725
Epoch [6/50] - Loss: 3.0127
Epoch [7/50] - Loss: 2.7775
Epoch [8/50] - Loss: 2.5641
Epoch [9/50] - Loss: 2.3770
Epoch [10/50] - Loss: 2.2270
Epoch [11/50] - Loss: 2.1187
Epoch [12/50] - Loss: 2.0290
Epoch [13/50] - Loss: 1.9686
Epoch [14/50] - Loss: 1.9279
Epoch [15/50] - Loss: 1.8856
Epoch [16/50] - Loss: 1.8602
Epoch [17/50] - Loss: 1.8313
Epoch [18/50] - Loss: 1.8071
Epoch [19/50] - Loss: 1.7885
Epoch [20/50] - Loss: 1.7768
Epoch [21/50] - Loss: 1.7575
Epoch [22/50] - Loss: 1.7517
Epoch [23/50] - Loss: 1.7418
Epoch [24/50] - Loss: 1.7352
Epoch [25/50] - Loss: 1.7320
Epoch [26/50] - Loss: 1.7200
Epoch [27/50] - Loss: 1.7158
Epoch [28/50] - Loss: 1.7159
Epoch [29/50] - Loss: 1.7028
Epoch [30/50] - Loss: 1.7067
Epoch [31/50] - Loss: 1.7021
Epoch [32/50] - Loss: 1.7010
Epoch [33/50] - Loss: 1.6949
Epoch [34/50] - Loss: 1.6957
Epoch [35/50] - Loss: 1.6934
Epoch [36/50] - Loss: 1.6938
Epoch [37/50] - Loss: 1.6966
Epoch [38/50] - Loss: 1.6880
Epoch [39/50] - Loss: 1.6841
Epoch [40/50] - Loss: 1.6865
Epoch [41/50] - Loss: 1.6800
Epoch [42/50] - Loss: 1.6774
Epoch [43/50] - Loss: 1.6832
Epoch [44/50] - Loss: 1.6748
Epoch [45/50] - Loss: 1.6782
Epoch [46/50] - Loss: 1.6807
Epoch [47/50] - Loss: 1.6747
Epoch [48/50] - Loss: 1.6842
Epoch [49/50] - Loss: 1.6812
Epoch [50/50] - Loss: 1.6689
sum preds 3379
sum labels 4725
 - Test Metrics: Accuracy=0.8562, F1=0.7061, Recall=0.6055, Precision=0.8467
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_two_nnif_two_nnif_1804231550.csv.
Average F1 over valid seeds: 0.7007 ± 0.0040
___________________________________________________________________________________
Avg F1 for pubmed with SAR and two_nnif, MLP,0.4: 0.7007 ± 0.0040
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.9322
Epoch [2/50] - Loss: 3.8916
Epoch [3/50] - Loss: 3.5009
Epoch [4/50] - Loss: 3.2633
Epoch [5/50] - Loss: 2.9894
Epoch [6/50] - Loss: 2.7939
Epoch [7/50] - Loss: 2.6335
Epoch [8/50] - Loss: 2.5117
Epoch [9/50] - Loss: 2.4153
Epoch [10/50] - Loss: 2.3480
Epoch [11/50] - Loss: 2.2853
Epoch [12/50] - Loss: 2.2722
Epoch [13/50] - Loss: 2.2415
Epoch [14/50] - Loss: 2.2128
Epoch [15/50] - Loss: 2.1900
Epoch [16/50] - Loss: 2.1703
Epoch [17/50] - Loss: 2.1451
Epoch [18/50] - Loss: 2.1255
Epoch [19/50] - Loss: 2.1105
Epoch [20/50] - Loss: 2.0951
Epoch [21/50] - Loss: 2.0747
Epoch [22/50] - Loss: 2.0654
Epoch [23/50] - Loss: 2.0521
Epoch [24/50] - Loss: 2.0389
Epoch [25/50] - Loss: 2.0250
Epoch [26/50] - Loss: 2.0061
Epoch [27/50] - Loss: 1.9944
Epoch [28/50] - Loss: 1.9770
Epoch [29/50] - Loss: 1.9671
Epoch [30/50] - Loss: 1.9557
Epoch [31/50] - Loss: 1.9445
Epoch [32/50] - Loss: 1.9278
Epoch [33/50] - Loss: 1.9221
Epoch [34/50] - Loss: 1.9087
Epoch [35/50] - Loss: 1.9111
Epoch [36/50] - Loss: 1.8945
Epoch [37/50] - Loss: 1.8867
Epoch [38/50] - Loss: 1.8846
Epoch [39/50] - Loss: 1.8737
Epoch [40/50] - Loss: 1.8667
Epoch [41/50] - Loss: 1.8524
Epoch [42/50] - Loss: 1.8464
Epoch [43/50] - Loss: 1.8478
Epoch [44/50] - Loss: 1.8459
Epoch [45/50] - Loss: 1.8407
Epoch [46/50] - Loss: 1.8284
Epoch [47/50] - Loss: 1.8238
Epoch [48/50] - Loss: 1.8114
Epoch [49/50] - Loss: 1.8084
Epoch [50/50] - Loss: 1.7996
sum preds 3192
sum labels 4725
 - Test Metrics: Accuracy=0.8553, F1=0.6972, Recall=0.5841, Precision=0.8647
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.0255
Epoch [2/50] - Loss: 4.0507
Epoch [3/50] - Loss: 3.6196
Epoch [4/50] - Loss: 3.4339
Epoch [5/50] - Loss: 3.2051
Epoch [6/50] - Loss: 2.9711
Epoch [7/50] - Loss: 2.7857
Epoch [8/50] - Loss: 2.6067
Epoch [9/50] - Loss: 2.4668
Epoch [10/50] - Loss: 2.3716
Epoch [11/50] - Loss: 2.3064
Epoch [12/50] - Loss: 2.2553
Epoch [13/50] - Loss: 2.2185
Epoch [14/50] - Loss: 2.1969
Epoch [15/50] - Loss: 2.1691
Epoch [16/50] - Loss: 2.1516
Epoch [17/50] - Loss: 2.1310
Epoch [18/50] - Loss: 2.1123
Epoch [19/50] - Loss: 2.0966
Epoch [20/50] - Loss: 2.0744
Epoch [21/50] - Loss: 2.0715
Epoch [22/50] - Loss: 2.0563
Epoch [23/50] - Loss: 2.0346
Epoch [24/50] - Loss: 2.0259
Epoch [25/50] - Loss: 2.0092
Epoch [26/50] - Loss: 1.9907
Epoch [27/50] - Loss: 1.9818
Epoch [28/50] - Loss: 1.9678
Epoch [29/50] - Loss: 1.9671
Epoch [30/50] - Loss: 1.9419
Epoch [31/50] - Loss: 1.9316
Epoch [32/50] - Loss: 1.9335
Epoch [33/50] - Loss: 1.9162
Epoch [34/50] - Loss: 1.9079
Epoch [35/50] - Loss: 1.9097
Epoch [36/50] - Loss: 1.9001
Epoch [37/50] - Loss: 1.8840
Epoch [38/50] - Loss: 1.8758
Epoch [39/50] - Loss: 1.8648
Epoch [40/50] - Loss: 1.8615
Epoch [41/50] - Loss: 1.8590
Epoch [42/50] - Loss: 1.8457
Epoch [43/50] - Loss: 1.8444
Epoch [44/50] - Loss: 1.8289
Epoch [45/50] - Loss: 1.8245
Epoch [46/50] - Loss: 1.8163
Epoch [47/50] - Loss: 1.8182
Epoch [48/50] - Loss: 1.8042
Epoch [49/50] - Loss: 1.8018
Epoch [50/50] - Loss: 1.7874
sum preds 3171
sum labels 4725
 - Test Metrics: Accuracy=0.8507, F1=0.6867, Recall=0.5738, Precision=0.8549
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1313
Epoch [2/50] - Loss: 4.2616
Epoch [3/50] - Loss: 3.7208
Epoch [4/50] - Loss: 3.4749
Epoch [5/50] - Loss: 3.2542
Epoch [6/50] - Loss: 3.0188
Epoch [7/50] - Loss: 2.8211
Epoch [8/50] - Loss: 2.6494
Epoch [9/50] - Loss: 2.5079
Epoch [10/50] - Loss: 2.3878
Epoch [11/50] - Loss: 2.2958
Epoch [12/50] - Loss: 2.2368
Epoch [13/50] - Loss: 2.1971
Epoch [14/50] - Loss: 2.1570
Epoch [15/50] - Loss: 2.1243
Epoch [16/50] - Loss: 2.1133
Epoch [17/50] - Loss: 2.0913
Epoch [18/50] - Loss: 2.0801
Epoch [19/50] - Loss: 2.0601
Epoch [20/50] - Loss: 2.0327
Epoch [21/50] - Loss: 2.0275
Epoch [22/50] - Loss: 2.0060
Epoch [23/50] - Loss: 1.9856
Epoch [24/50] - Loss: 1.9841
Epoch [25/50] - Loss: 1.9629
Epoch [26/50] - Loss: 1.9494
Epoch [27/50] - Loss: 1.9403
Epoch [28/50] - Loss: 1.9251
Epoch [29/50] - Loss: 1.9106
Epoch [30/50] - Loss: 1.9023
Epoch [31/50] - Loss: 1.8904
Epoch [32/50] - Loss: 1.8819
Epoch [33/50] - Loss: 1.8783
Epoch [34/50] - Loss: 1.8556
Epoch [35/50] - Loss: 1.8477
Epoch [36/50] - Loss: 1.8416
Epoch [37/50] - Loss: 1.8228
Epoch [38/50] - Loss: 1.8152
Epoch [39/50] - Loss: 1.8096
Epoch [40/50] - Loss: 1.8115
Epoch [41/50] - Loss: 1.7891
Epoch [42/50] - Loss: 1.7814
Epoch [43/50] - Loss: 1.7736
Epoch [44/50] - Loss: 1.7680
Epoch [45/50] - Loss: 1.7611
Epoch [46/50] - Loss: 1.7507
Epoch [47/50] - Loss: 1.7435
Epoch [48/50] - Loss: 1.7346
Epoch [49/50] - Loss: 1.7307
Epoch [50/50] - Loss: 1.7197
sum preds 3306
sum labels 4725
 - Test Metrics: Accuracy=0.8572, F1=0.7055, Recall=0.5996, Precision=0.8569
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_two_nnif_two_nnif_1804233856.csv.
Average F1 over valid seeds: 0.6965 ± 0.0077
___________________________________________________________________________________
Avg F1 for pubmed with SAR and two_nnif, GATConv,0.4: 0.6965 ± 0.0077
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1932
Epoch [2/50] - Loss: 4.4277
Epoch [3/50] - Loss: 3.8833
Epoch [4/50] - Loss: 3.5931
Epoch [5/50] - Loss: 3.3964
Epoch [6/50] - Loss: 3.1897
Epoch [7/50] - Loss: 2.9963
Epoch [8/50] - Loss: 2.8298
Epoch [9/50] - Loss: 2.6703
Epoch [10/50] - Loss: 2.5480
Epoch [11/50] - Loss: 2.4484
Epoch [12/50] - Loss: 2.3745
Epoch [13/50] - Loss: 2.3149
Epoch [14/50] - Loss: 2.2810
Epoch [15/50] - Loss: 2.2570
Epoch [16/50] - Loss: 2.2303
Epoch [17/50] - Loss: 2.2152
Epoch [18/50] - Loss: 2.1844
Epoch [19/50] - Loss: 2.1628
Epoch [20/50] - Loss: 2.1542
Epoch [21/50] - Loss: 2.1333
Epoch [22/50] - Loss: 2.1125
Epoch [23/50] - Loss: 2.1039
Epoch [24/50] - Loss: 2.0999
Epoch [25/50] - Loss: 2.0925
Epoch [26/50] - Loss: 2.0934
Epoch [27/50] - Loss: 2.0769
Epoch [28/50] - Loss: 2.0662
Epoch [29/50] - Loss: 2.0623
Epoch [30/50] - Loss: 2.0581
Epoch [31/50] - Loss: 2.0468
Epoch [32/50] - Loss: 2.0466
Epoch [33/50] - Loss: 2.0421
Epoch [34/50] - Loss: 2.0417
Epoch [35/50] - Loss: 2.0410
Epoch [36/50] - Loss: 2.0362
Epoch [37/50] - Loss: 2.0323
Epoch [38/50] - Loss: 2.0293
Epoch [39/50] - Loss: 2.0242
Epoch [40/50] - Loss: 2.0263
Epoch [41/50] - Loss: 2.0119
Epoch [42/50] - Loss: 2.0111
Epoch [43/50] - Loss: 2.0029
Epoch [44/50] - Loss: 2.0105
Epoch [45/50] - Loss: 2.0045
Epoch [46/50] - Loss: 1.9948
Epoch [47/50] - Loss: 1.9927
Epoch [48/50] - Loss: 1.9911
Epoch [49/50] - Loss: 1.9839
Epoch [50/50] - Loss: 1.9912
sum preds 3389
sum labels 4725
 - Test Metrics: Accuracy=0.8642, F1=0.7227, Recall=0.6205, Precision=0.8652
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.0377
Epoch [2/50] - Loss: 4.1509
Epoch [3/50] - Loss: 3.7321
Epoch [4/50] - Loss: 3.5843
Epoch [5/50] - Loss: 3.4017
Epoch [6/50] - Loss: 3.2085
Epoch [7/50] - Loss: 3.0541
Epoch [8/50] - Loss: 2.8901
Epoch [9/50] - Loss: 2.7402
Epoch [10/50] - Loss: 2.6080
Epoch [11/50] - Loss: 2.4879
Epoch [12/50] - Loss: 2.3974
Epoch [13/50] - Loss: 2.3395
Epoch [14/50] - Loss: 2.2869
Epoch [15/50] - Loss: 2.2506
Epoch [16/50] - Loss: 2.2311
Epoch [17/50] - Loss: 2.2034
Epoch [18/50] - Loss: 2.1922
Epoch [19/50] - Loss: 2.1712
Epoch [20/50] - Loss: 2.1658
Epoch [21/50] - Loss: 2.1519
Epoch [22/50] - Loss: 2.1313
Epoch [23/50] - Loss: 2.1252
Epoch [24/50] - Loss: 2.1169
Epoch [25/50] - Loss: 2.1109
Epoch [26/50] - Loss: 2.1078
Epoch [27/50] - Loss: 2.0955
Epoch [28/50] - Loss: 2.0850
Epoch [29/50] - Loss: 2.0850
Epoch [30/50] - Loss: 2.0838
Epoch [31/50] - Loss: 2.0716
Epoch [32/50] - Loss: 2.0663
Epoch [33/50] - Loss: 2.0553
Epoch [34/50] - Loss: 2.0630
Epoch [35/50] - Loss: 2.0557
Epoch [36/50] - Loss: 2.0440
Epoch [37/50] - Loss: 2.0449
Epoch [38/50] - Loss: 2.0462
Epoch [39/50] - Loss: 2.0462
Epoch [40/50] - Loss: 2.0417
Epoch [41/50] - Loss: 2.0371
Epoch [42/50] - Loss: 2.0349
Epoch [43/50] - Loss: 2.0276
Epoch [44/50] - Loss: 2.0332
Epoch [45/50] - Loss: 2.0275
Epoch [46/50] - Loss: 2.0274
Epoch [47/50] - Loss: 2.0228
Epoch [48/50] - Loss: 2.0270
Epoch [49/50] - Loss: 2.0065
Epoch [50/50] - Loss: 2.0068
sum preds 3450
sum labels 4725
 - Test Metrics: Accuracy=0.8664, F1=0.7293, Recall=0.6309, Precision=0.8641
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.0326
Epoch [2/50] - Loss: 4.0991
Epoch [3/50] - Loss: 3.7054
Epoch [4/50] - Loss: 3.5525
Epoch [5/50] - Loss: 3.3350
Epoch [6/50] - Loss: 3.1425
Epoch [7/50] - Loss: 2.9552
Epoch [8/50] - Loss: 2.7703
Epoch [9/50] - Loss: 2.6188
Epoch [10/50] - Loss: 2.4855
Epoch [11/50] - Loss: 2.3871
Epoch [12/50] - Loss: 2.3239
Epoch [13/50] - Loss: 2.2817
Epoch [14/50] - Loss: 2.2441
Epoch [15/50] - Loss: 2.2117
Epoch [16/50] - Loss: 2.1943
Epoch [17/50] - Loss: 2.1848
Epoch [18/50] - Loss: 2.1626
Epoch [19/50] - Loss: 2.1514
Epoch [20/50] - Loss: 2.1490
Epoch [21/50] - Loss: 2.1304
Epoch [22/50] - Loss: 2.1199
Epoch [23/50] - Loss: 2.1148
Epoch [24/50] - Loss: 2.0995
Epoch [25/50] - Loss: 2.0983
Epoch [26/50] - Loss: 2.0850
Epoch [27/50] - Loss: 2.0789
Epoch [28/50] - Loss: 2.0822
Epoch [29/50] - Loss: 2.0730
Epoch [30/50] - Loss: 2.0711
Epoch [31/50] - Loss: 2.0612
Epoch [32/50] - Loss: 2.0593
Epoch [33/50] - Loss: 2.0544
Epoch [34/50] - Loss: 2.0491
Epoch [35/50] - Loss: 2.0510
Epoch [36/50] - Loss: 2.0519
Epoch [37/50] - Loss: 2.0410
Epoch [38/50] - Loss: 2.0394
Epoch [39/50] - Loss: 2.0328
Epoch [40/50] - Loss: 2.0222
Epoch [41/50] - Loss: 2.0225
Epoch [42/50] - Loss: 2.0197
Epoch [43/50] - Loss: 2.0162
Epoch [44/50] - Loss: 2.0096
Epoch [45/50] - Loss: 2.0082
Epoch [46/50] - Loss: 1.9920
Epoch [47/50] - Loss: 1.9968
Epoch [48/50] - Loss: 1.9988
Epoch [49/50] - Loss: 1.9864
Epoch [50/50] - Loss: 1.9849
sum preds 3415
sum labels 4725
 - Test Metrics: Accuracy=0.8690, F1=0.7334, Recall=0.6317, Precision=0.8741
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_two_nnif_two_nnif_1904000227.csv.
Average F1 over valid seeds: 0.7285 ± 0.0044
___________________________________________________________________________________
Avg F1 for pubmed with SAR and two_nnif, GCNConv,0.4: 0.7285 ± 0.0044
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.5365
Epoch [2/50] - Loss: 3.8701
Epoch [3/50] - Loss: 3.2839
Epoch [4/50] - Loss: 3.0094
Epoch [5/50] - Loss: 2.7967
Epoch [6/50] - Loss: 2.5904
Epoch [7/50] - Loss: 2.4011
Epoch [8/50] - Loss: 2.2340
Epoch [9/50] - Loss: 2.0830
Epoch [10/50] - Loss: 1.9802
Epoch [11/50] - Loss: 1.8845
Epoch [12/50] - Loss: 1.8249
Epoch [13/50] - Loss: 1.7698
Epoch [14/50] - Loss: 1.7314
Epoch [15/50] - Loss: 1.6975
Epoch [16/50] - Loss: 1.6696
Epoch [17/50] - Loss: 1.6437
Epoch [18/50] - Loss: 1.6272
Epoch [19/50] - Loss: 1.6198
Epoch [20/50] - Loss: 1.6001
Epoch [21/50] - Loss: 1.5922
Epoch [22/50] - Loss: 1.5795
Epoch [23/50] - Loss: 1.5737
Epoch [24/50] - Loss: 1.5686
Epoch [25/50] - Loss: 1.5652
Epoch [26/50] - Loss: 1.5462
Epoch [27/50] - Loss: 1.5537
Epoch [28/50] - Loss: 1.5503
Epoch [29/50] - Loss: 1.5521
Epoch [30/50] - Loss: 1.5381
Epoch [31/50] - Loss: 1.5315
Epoch [32/50] - Loss: 1.5328
Epoch [33/50] - Loss: 1.5265
Epoch [34/50] - Loss: 1.5308
Epoch [35/50] - Loss: 1.5152
Epoch [36/50] - Loss: 1.5157
Epoch [37/50] - Loss: 1.5121
Epoch [38/50] - Loss: 1.5073
Epoch [39/50] - Loss: 1.5144
Epoch [40/50] - Loss: 1.5159
Epoch [41/50] - Loss: 1.5086
Epoch [42/50] - Loss: 1.5107
Epoch [43/50] - Loss: 1.5199
Epoch [44/50] - Loss: 1.5074
Epoch [45/50] - Loss: 1.4987
Epoch [46/50] - Loss: 1.4954
Epoch [47/50] - Loss: 1.4948
Epoch [48/50] - Loss: 1.4979
Epoch [49/50] - Loss: 1.4965
Epoch [50/50] - Loss: 1.4888
sum preds 3622
sum labels 5513
 - Test Metrics: Accuracy=0.8311, F1=0.6791, Recall=0.5627, Precision=0.8564
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.4680
Epoch [2/50] - Loss: 3.8787
Epoch [3/50] - Loss: 3.3095
Epoch [4/50] - Loss: 2.9713
Epoch [5/50] - Loss: 2.6853
Epoch [6/50] - Loss: 2.4315
Epoch [7/50] - Loss: 2.1976
Epoch [8/50] - Loss: 2.0233
Epoch [9/50] - Loss: 1.8835
Epoch [10/50] - Loss: 1.7902
Epoch [11/50] - Loss: 1.7243
Epoch [12/50] - Loss: 1.6678
Epoch [13/50] - Loss: 1.6227
Epoch [14/50] - Loss: 1.5812
Epoch [15/50] - Loss: 1.5563
Epoch [16/50] - Loss: 1.5425
Epoch [17/50] - Loss: 1.5157
Epoch [18/50] - Loss: 1.4988
Epoch [19/50] - Loss: 1.4773
Epoch [20/50] - Loss: 1.4665
Epoch [21/50] - Loss: 1.4569
Epoch [22/50] - Loss: 1.4449
Epoch [23/50] - Loss: 1.4402
Epoch [24/50] - Loss: 1.4194
Epoch [25/50] - Loss: 1.4171
Epoch [26/50] - Loss: 1.4074
Epoch [27/50] - Loss: 1.3960
Epoch [28/50] - Loss: 1.3792
Epoch [29/50] - Loss: 1.3723
Epoch [30/50] - Loss: 1.3613
Epoch [31/50] - Loss: 1.3439
Epoch [32/50] - Loss: 1.3334
Epoch [33/50] - Loss: 1.3310
Epoch [34/50] - Loss: 1.3142
Epoch [35/50] - Loss: 1.3115
Epoch [36/50] - Loss: 1.3072
Epoch [37/50] - Loss: 1.2975
Epoch [38/50] - Loss: 1.2861
Epoch [39/50] - Loss: 1.2790
Epoch [40/50] - Loss: 1.2701
Epoch [41/50] - Loss: 1.2607
Epoch [42/50] - Loss: 1.2568
Epoch [43/50] - Loss: 1.2462
Epoch [44/50] - Loss: 1.2424
Epoch [45/50] - Loss: 1.2332
Epoch [46/50] - Loss: 1.2241
Epoch [47/50] - Loss: 1.2226
Epoch [48/50] - Loss: 1.2144
Epoch [49/50] - Loss: 1.2102
Epoch [50/50] - Loss: 1.2021
sum preds 3576
sum labels 5513
 - Test Metrics: Accuracy=0.8293, F1=0.6740, Recall=0.5556, Precision=0.8565
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.8773
Epoch [2/50] - Loss: 4.1304
Epoch [3/50] - Loss: 3.4247
Epoch [4/50] - Loss: 3.0698
Epoch [5/50] - Loss: 2.9055
Epoch [6/50] - Loss: 2.7000
Epoch [7/50] - Loss: 2.5105
Epoch [8/50] - Loss: 2.3369
Epoch [9/50] - Loss: 2.1776
Epoch [10/50] - Loss: 2.0393
Epoch [11/50] - Loss: 1.9238
Epoch [12/50] - Loss: 1.8458
Epoch [13/50] - Loss: 1.7816
Epoch [14/50] - Loss: 1.7308
Epoch [15/50] - Loss: 1.6837
Epoch [16/50] - Loss: 1.6544
Epoch [17/50] - Loss: 1.6252
Epoch [18/50] - Loss: 1.6034
Epoch [19/50] - Loss: 1.5861
Epoch [20/50] - Loss: 1.5598
Epoch [21/50] - Loss: 1.5520
Epoch [22/50] - Loss: 1.5381
Epoch [23/50] - Loss: 1.5121
Epoch [24/50] - Loss: 1.5099
Epoch [25/50] - Loss: 1.5104
Epoch [26/50] - Loss: 1.4906
Epoch [27/50] - Loss: 1.4902
Epoch [28/50] - Loss: 1.4664
Epoch [29/50] - Loss: 1.4708
Epoch [30/50] - Loss: 1.4660
Epoch [31/50] - Loss: 1.4633
Epoch [32/50] - Loss: 1.4545
Epoch [33/50] - Loss: 1.4371
Epoch [34/50] - Loss: 1.4417
Epoch [35/50] - Loss: 1.4355
Epoch [36/50] - Loss: 1.4313
Epoch [37/50] - Loss: 1.4288
Epoch [38/50] - Loss: 1.4204
Epoch [39/50] - Loss: 1.4230
Epoch [40/50] - Loss: 1.4132
Epoch [41/50] - Loss: 1.4081
Epoch [42/50] - Loss: 1.4022
Epoch [43/50] - Loss: 1.3986
Epoch [44/50] - Loss: 1.3918
Epoch [45/50] - Loss: 1.3868
Epoch [46/50] - Loss: 1.3800
Epoch [47/50] - Loss: 1.3728
Epoch [48/50] - Loss: 1.3663
Epoch [49/50] - Loss: 1.3697
Epoch [50/50] - Loss: 1.3602
sum preds 3625
sum labels 5513
 - Test Metrics: Accuracy=0.8269, F1=0.6713, Recall=0.5563, Precision=0.8461
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_two_nnif_two_nnif_1904002508.csv.
Average F1 over valid seeds: 0.6748 ± 0.0033
___________________________________________________________________________________
Avg F1 for pubmed with SAR and two_nnif, MLP,0.3: 0.6748 ± 0.0033
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.8404
Epoch [2/50] - Loss: 3.5971
Epoch [3/50] - Loss: 3.1110
Epoch [4/50] - Loss: 2.9291
Epoch [5/50] - Loss: 2.7426
Epoch [6/50] - Loss: 2.5730
Epoch [7/50] - Loss: 2.4311
Epoch [8/50] - Loss: 2.3187
Epoch [9/50] - Loss: 2.2325
Epoch [10/50] - Loss: 2.1471
Epoch [11/50] - Loss: 2.1030
Epoch [12/50] - Loss: 2.0598
Epoch [13/50] - Loss: 2.0238
Epoch [14/50] - Loss: 1.9960
Epoch [15/50] - Loss: 1.9721
Epoch [16/50] - Loss: 1.9618
Epoch [17/50] - Loss: 1.9381
Epoch [18/50] - Loss: 1.9192
Epoch [19/50] - Loss: 1.8964
Epoch [20/50] - Loss: 1.8863
Epoch [21/50] - Loss: 1.8722
Epoch [22/50] - Loss: 1.8482
Epoch [23/50] - Loss: 1.8321
Epoch [24/50] - Loss: 1.8310
Epoch [25/50] - Loss: 1.8152
Epoch [26/50] - Loss: 1.8010
Epoch [27/50] - Loss: 1.7882
Epoch [28/50] - Loss: 1.7669
Epoch [29/50] - Loss: 1.7679
Epoch [30/50] - Loss: 1.7611
Epoch [31/50] - Loss: 1.7439
Epoch [32/50] - Loss: 1.7323
Epoch [33/50] - Loss: 1.7248
Epoch [34/50] - Loss: 1.7105
Epoch [35/50] - Loss: 1.7033
Epoch [36/50] - Loss: 1.7125
Epoch [37/50] - Loss: 1.6921
Epoch [38/50] - Loss: 1.6701
Epoch [39/50] - Loss: 1.6731
Epoch [40/50] - Loss: 1.6690
Epoch [41/50] - Loss: 1.6647
Epoch [42/50] - Loss: 1.6643
Epoch [43/50] - Loss: 1.6586
Epoch [44/50] - Loss: 1.6433
Epoch [45/50] - Loss: 1.6470
Epoch [46/50] - Loss: 1.6374
Epoch [47/50] - Loss: 1.6261
Epoch [48/50] - Loss: 1.6208
Epoch [49/50] - Loss: 1.6190
Epoch [50/50] - Loss: 1.6283
sum preds 3100
sum labels 5513
 - Test Metrics: Accuracy=0.8221, F1=0.6416, Recall=0.5012, Precision=0.8913
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.9437
Epoch [2/50] - Loss: 3.7802
Epoch [3/50] - Loss: 3.2187
Epoch [4/50] - Loss: 3.0524
Epoch [5/50] - Loss: 2.8849
Epoch [6/50] - Loss: 2.6859
Epoch [7/50] - Loss: 2.5243
Epoch [8/50] - Loss: 2.3755
Epoch [9/50] - Loss: 2.2529
Epoch [10/50] - Loss: 2.1542
Epoch [11/50] - Loss: 2.0826
Epoch [12/50] - Loss: 2.0152
Epoch [13/50] - Loss: 1.9833
Epoch [14/50] - Loss: 1.9586
Epoch [15/50] - Loss: 1.9249
Epoch [16/50] - Loss: 1.8996
Epoch [17/50] - Loss: 1.8928
Epoch [18/50] - Loss: 1.8696
Epoch [19/50] - Loss: 1.8581
Epoch [20/50] - Loss: 1.8383
Epoch [21/50] - Loss: 1.8238
Epoch [22/50] - Loss: 1.8022
Epoch [23/50] - Loss: 1.7954
Epoch [24/50] - Loss: 1.7725
Epoch [25/50] - Loss: 1.7610
Epoch [26/50] - Loss: 1.7498
Epoch [27/50] - Loss: 1.7423
Epoch [28/50] - Loss: 1.7521
Epoch [29/50] - Loss: 1.7180
Epoch [30/50] - Loss: 1.7185
Epoch [31/50] - Loss: 1.7062
Epoch [32/50] - Loss: 1.6913
Epoch [33/50] - Loss: 1.6919
Epoch [34/50] - Loss: 1.6803
Epoch [35/50] - Loss: 1.6720
Epoch [36/50] - Loss: 1.6497
Epoch [37/50] - Loss: 1.6500
Epoch [38/50] - Loss: 1.6362
Epoch [39/50] - Loss: 1.6360
Epoch [40/50] - Loss: 1.6346
Epoch [41/50] - Loss: 1.6251
Epoch [42/50] - Loss: 1.6194
Epoch [43/50] - Loss: 1.6104
Epoch [44/50] - Loss: 1.5993
Epoch [45/50] - Loss: 1.6037
Epoch [46/50] - Loss: 1.5904
Epoch [47/50] - Loss: 1.5959
Epoch [48/50] - Loss: 1.5900
Epoch [49/50] - Loss: 1.5729
Epoch [50/50] - Loss: 1.5734
sum preds 3377
sum labels 5513
 - Test Metrics: Accuracy=0.8290, F1=0.6661, Recall=0.5371, Precision=0.8768
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.0774
Epoch [2/50] - Loss: 4.0701
Epoch [3/50] - Loss: 3.3959
Epoch [4/50] - Loss: 3.1055
Epoch [5/50] - Loss: 2.9226
Epoch [6/50] - Loss: 2.7478
Epoch [7/50] - Loss: 2.5582
Epoch [8/50] - Loss: 2.4142
Epoch [9/50] - Loss: 2.2911
Epoch [10/50] - Loss: 2.1816
Epoch [11/50] - Loss: 2.1048
Epoch [12/50] - Loss: 2.0296
Epoch [13/50] - Loss: 1.9835
Epoch [14/50] - Loss: 1.9531
Epoch [15/50] - Loss: 1.9273
Epoch [16/50] - Loss: 1.8986
Epoch [17/50] - Loss: 1.8815
Epoch [18/50] - Loss: 1.8612
Epoch [19/50] - Loss: 1.8422
Epoch [20/50] - Loss: 1.8294
Epoch [21/50] - Loss: 1.7998
Epoch [22/50] - Loss: 1.8001
Epoch [23/50] - Loss: 1.7785
Epoch [24/50] - Loss: 1.7630
Epoch [25/50] - Loss: 1.7541
Epoch [26/50] - Loss: 1.7408
Epoch [27/50] - Loss: 1.7228
Epoch [28/50] - Loss: 1.7161
Epoch [29/50] - Loss: 1.7130
Epoch [30/50] - Loss: 1.6977
Epoch [31/50] - Loss: 1.6957
Epoch [32/50] - Loss: 1.6791
Epoch [33/50] - Loss: 1.6557
Epoch [34/50] - Loss: 1.6556
Epoch [35/50] - Loss: 1.6540
Epoch [36/50] - Loss: 1.6369
Epoch [37/50] - Loss: 1.6326
Epoch [38/50] - Loss: 1.6225
Epoch [39/50] - Loss: 1.6166
Epoch [40/50] - Loss: 1.6090
Epoch [41/50] - Loss: 1.5891
Epoch [42/50] - Loss: 1.5848
Epoch [43/50] - Loss: 1.5941
Epoch [44/50] - Loss: 1.5682
Epoch [45/50] - Loss: 1.5625
Epoch [46/50] - Loss: 1.5583
Epoch [47/50] - Loss: 1.5504
Epoch [48/50] - Loss: 1.5459
Epoch [49/50] - Loss: 1.5303
Epoch [50/50] - Loss: 1.5338
sum preds 3463
sum labels 5513
 - Test Metrics: Accuracy=0.8366, F1=0.6840, Recall=0.5569, Precision=0.8865
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_two_nnif_two_nnif_1904004548.csv.
Average F1 over valid seeds: 0.6639 ± 0.0174
___________________________________________________________________________________
Avg F1 for pubmed with SAR and two_nnif, GATConv,0.3: 0.6639 ± 0.0174
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1463
Epoch [2/50] - Loss: 4.2670
Epoch [3/50] - Loss: 3.5948
Epoch [4/50] - Loss: 3.2342
Epoch [5/50] - Loss: 3.0581
Epoch [6/50] - Loss: 2.9114
Epoch [7/50] - Loss: 2.7497
Epoch [8/50] - Loss: 2.6105
Epoch [9/50] - Loss: 2.4875
Epoch [10/50] - Loss: 2.3895
Epoch [11/50] - Loss: 2.2804
Epoch [12/50] - Loss: 2.2079
Epoch [13/50] - Loss: 2.1220
Epoch [14/50] - Loss: 2.0839
Epoch [15/50] - Loss: 2.0442
Epoch [16/50] - Loss: 2.0144
Epoch [17/50] - Loss: 1.9925
Epoch [18/50] - Loss: 1.9754
Epoch [19/50] - Loss: 1.9543
Epoch [20/50] - Loss: 1.9347
Epoch [21/50] - Loss: 1.9251
Epoch [22/50] - Loss: 1.9106
Epoch [23/50] - Loss: 1.9068
Epoch [24/50] - Loss: 1.8988
Epoch [25/50] - Loss: 1.8888
Epoch [26/50] - Loss: 1.8797
Epoch [27/50] - Loss: 1.8647
Epoch [28/50] - Loss: 1.8655
Epoch [29/50] - Loss: 1.8593
Epoch [30/50] - Loss: 1.8465
Epoch [31/50] - Loss: 1.8422
Epoch [32/50] - Loss: 1.8361
Epoch [33/50] - Loss: 1.8381
Epoch [34/50] - Loss: 1.8360
Epoch [35/50] - Loss: 1.8284
Epoch [36/50] - Loss: 1.8288
Epoch [37/50] - Loss: 1.8230
Epoch [38/50] - Loss: 1.8106
Epoch [39/50] - Loss: 1.8269
Epoch [40/50] - Loss: 1.8197
Epoch [41/50] - Loss: 1.8044
Epoch [42/50] - Loss: 1.8125
Epoch [43/50] - Loss: 1.8104
Epoch [44/50] - Loss: 1.8051
Epoch [45/50] - Loss: 1.8049
Epoch [46/50] - Loss: 1.8074
Epoch [47/50] - Loss: 1.8051
Epoch [48/50] - Loss: 1.8035
Epoch [49/50] - Loss: 1.8069
Epoch [50/50] - Loss: 1.7983
sum preds 3570
sum labels 5513
 - Test Metrics: Accuracy=0.8430, F1=0.7000, Recall=0.5766, Precision=0.8905
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.9634
Epoch [2/50] - Loss: 3.8929
Epoch [3/50] - Loss: 3.3299
Epoch [4/50] - Loss: 3.1556
Epoch [5/50] - Loss: 3.0568
Epoch [6/50] - Loss: 2.8869
Epoch [7/50] - Loss: 2.7485
Epoch [8/50] - Loss: 2.6522
Epoch [9/50] - Loss: 2.5162
Epoch [10/50] - Loss: 2.3904
Epoch [11/50] - Loss: 2.3003
Epoch [12/50] - Loss: 2.2014
Epoch [13/50] - Loss: 2.1146
Epoch [14/50] - Loss: 2.0639
Epoch [15/50] - Loss: 2.0207
Epoch [16/50] - Loss: 1.9982
Epoch [17/50] - Loss: 1.9745
Epoch [18/50] - Loss: 1.9576
Epoch [19/50] - Loss: 1.9486
Epoch [20/50] - Loss: 1.9429
Epoch [21/50] - Loss: 1.9199
Epoch [22/50] - Loss: 1.9089
Epoch [23/50] - Loss: 1.8999
Epoch [24/50] - Loss: 1.8927
Epoch [25/50] - Loss: 1.8894
Epoch [26/50] - Loss: 1.8782
Epoch [27/50] - Loss: 1.8692
Epoch [28/50] - Loss: 1.8653
Epoch [29/50] - Loss: 1.8694
Epoch [30/50] - Loss: 1.8495
Epoch [31/50] - Loss: 1.8548
Epoch [32/50] - Loss: 1.8555
Epoch [33/50] - Loss: 1.8420
Epoch [34/50] - Loss: 1.8447
Epoch [35/50] - Loss: 1.8342
Epoch [36/50] - Loss: 1.8277
Epoch [37/50] - Loss: 1.8248
Epoch [38/50] - Loss: 1.8238
Epoch [39/50] - Loss: 1.8171
Epoch [40/50] - Loss: 1.8335
Epoch [41/50] - Loss: 1.8146
Epoch [42/50] - Loss: 1.8150
Epoch [43/50] - Loss: 1.8131
Epoch [44/50] - Loss: 1.8176
Epoch [45/50] - Loss: 1.8101
Epoch [46/50] - Loss: 1.8186
Epoch [47/50] - Loss: 1.7967
Epoch [48/50] - Loss: 1.8048
Epoch [49/50] - Loss: 1.8000
Epoch [50/50] - Loss: 1.7990
sum preds 3532
sum labels 5513
 - Test Metrics: Accuracy=0.8388, F1=0.6908, Recall=0.5667, Precision=0.8845
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.9607
Epoch [2/50] - Loss: 3.8512
Epoch [3/50] - Loss: 3.3110
Epoch [4/50] - Loss: 3.1501
Epoch [5/50] - Loss: 3.0381
Epoch [6/50] - Loss: 2.9036
Epoch [7/50] - Loss: 2.7774
Epoch [8/50] - Loss: 2.6650
Epoch [9/50] - Loss: 2.5479
Epoch [10/50] - Loss: 2.4311
Epoch [11/50] - Loss: 2.3254
Epoch [12/50] - Loss: 2.2492
Epoch [13/50] - Loss: 2.1524
Epoch [14/50] - Loss: 2.1001
Epoch [15/50] - Loss: 2.0399
Epoch [16/50] - Loss: 2.0140
Epoch [17/50] - Loss: 1.9708
Epoch [18/50] - Loss: 1.9399
Epoch [19/50] - Loss: 1.9275
Epoch [20/50] - Loss: 1.9105
Epoch [21/50] - Loss: 1.8857
Epoch [22/50] - Loss: 1.8724
Epoch [23/50] - Loss: 1.8635
Epoch [24/50] - Loss: 1.8465
Epoch [25/50] - Loss: 1.8361
Epoch [26/50] - Loss: 1.8369
Epoch [27/50] - Loss: 1.8157
Epoch [28/50] - Loss: 1.8105
Epoch [29/50] - Loss: 1.7977
Epoch [30/50] - Loss: 1.8011
Epoch [31/50] - Loss: 1.7936
Epoch [32/50] - Loss: 1.7945
Epoch [33/50] - Loss: 1.7980
Epoch [34/50] - Loss: 1.7813
Epoch [35/50] - Loss: 1.7859
Epoch [36/50] - Loss: 1.7704
Epoch [37/50] - Loss: 1.7741
Epoch [38/50] - Loss: 1.7751
Epoch [39/50] - Loss: 1.7627
Epoch [40/50] - Loss: 1.7658
Epoch [41/50] - Loss: 1.7647
Epoch [42/50] - Loss: 1.7578
Epoch [43/50] - Loss: 1.7561
Epoch [44/50] - Loss: 1.7578
Epoch [45/50] - Loss: 1.7479
Epoch [46/50] - Loss: 1.7431
Epoch [47/50] - Loss: 1.7441
Epoch [48/50] - Loss: 1.7299
Epoch [49/50] - Loss: 1.7345
Epoch [50/50] - Loss: 1.7383
sum preds 3532
sum labels 5513
 - Test Metrics: Accuracy=0.8431, F1=0.6989, Recall=0.5734, Precision=0.8950
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_two_nnif_two_nnif_1904010616.csv.
Average F1 over valid seeds: 0.6966 ± 0.0041
___________________________________________________________________________________
Avg F1 for pubmed with SAR and two_nnif, GCNConv,0.3: 0.6966 ± 0.0041
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8781
Epoch [2/50] - Loss: 3.2841
Epoch [3/50] - Loss: 2.6556
Epoch [4/50] - Loss: 2.2614
Epoch [5/50] - Loss: 2.1015
Epoch [6/50] - Loss: 2.0063
Epoch [7/50] - Loss: 1.8734
Epoch [8/50] - Loss: 1.7669
Epoch [9/50] - Loss: 1.6766
Epoch [10/50] - Loss: 1.5846
Epoch [11/50] - Loss: 1.5155
Epoch [12/50] - Loss: 1.4548
Epoch [13/50] - Loss: 1.4008
Epoch [14/50] - Loss: 1.3605
Epoch [15/50] - Loss: 1.3276
Epoch [16/50] - Loss: 1.2986
Epoch [17/50] - Loss: 1.2730
Epoch [18/50] - Loss: 1.2506
Epoch [19/50] - Loss: 1.2392
Epoch [20/50] - Loss: 1.2111
Epoch [21/50] - Loss: 1.2017
Epoch [22/50] - Loss: 1.1915
Epoch [23/50] - Loss: 1.1841
Epoch [24/50] - Loss: 1.1680
Epoch [25/50] - Loss: 1.1659
Epoch [26/50] - Loss: 1.1525
Epoch [27/50] - Loss: 1.1455
Epoch [28/50] - Loss: 1.1434
Epoch [29/50] - Loss: 1.1323
Epoch [30/50] - Loss: 1.1309
Epoch [31/50] - Loss: 1.1231
Epoch [32/50] - Loss: 1.1122
Epoch [33/50] - Loss: 1.1097
Epoch [34/50] - Loss: 1.1156
Epoch [35/50] - Loss: 1.1097
Epoch [36/50] - Loss: 1.0999
Epoch [37/50] - Loss: 1.0998
Epoch [38/50] - Loss: 1.0958
Epoch [39/50] - Loss: 1.0940
Epoch [40/50] - Loss: 1.0930
Epoch [41/50] - Loss: 1.0894
Epoch [42/50] - Loss: 1.0899
Epoch [43/50] - Loss: 1.0848
Epoch [44/50] - Loss: 1.0877
Epoch [45/50] - Loss: 1.0806
Epoch [46/50] - Loss: 1.0831
Epoch [47/50] - Loss: 1.0731
Epoch [48/50] - Loss: 1.0726
Epoch [49/50] - Loss: 1.0778
Epoch [50/50] - Loss: 1.0756
sum preds 3620
sum labels 6300
 - Test Metrics: Accuracy=0.8027, F1=0.6391, Recall=0.5032, Precision=0.8757
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.9069
Epoch [2/50] - Loss: 4.0768
Epoch [3/50] - Loss: 3.1517
Epoch [4/50] - Loss: 2.4784
Epoch [5/50] - Loss: 2.1939
Epoch [6/50] - Loss: 2.1184
Epoch [7/50] - Loss: 2.0194
Epoch [8/50] - Loss: 1.9106
Epoch [9/50] - Loss: 1.8227
Epoch [10/50] - Loss: 1.7421
Epoch [11/50] - Loss: 1.6730
Epoch [12/50] - Loss: 1.6070
Epoch [13/50] - Loss: 1.5522
Epoch [14/50] - Loss: 1.4971
Epoch [15/50] - Loss: 1.4533
Epoch [16/50] - Loss: 1.4088
Epoch [17/50] - Loss: 1.3707
Epoch [18/50] - Loss: 1.3411
Epoch [19/50] - Loss: 1.3193
Epoch [20/50] - Loss: 1.2899
Epoch [21/50] - Loss: 1.2677
Epoch [22/50] - Loss: 1.2466
Epoch [23/50] - Loss: 1.2323
Epoch [24/50] - Loss: 1.2162
Epoch [25/50] - Loss: 1.2101
Epoch [26/50] - Loss: 1.1988
Epoch [27/50] - Loss: 1.1831
Epoch [28/50] - Loss: 1.1777
Epoch [29/50] - Loss: 1.1719
Epoch [30/50] - Loss: 1.1599
Epoch [31/50] - Loss: 1.1532
Epoch [32/50] - Loss: 1.1481
Epoch [33/50] - Loss: 1.1475
Epoch [34/50] - Loss: 1.1360
Epoch [35/50] - Loss: 1.1387
Epoch [36/50] - Loss: 1.1317
Epoch [37/50] - Loss: 1.1270
Epoch [38/50] - Loss: 1.1220
Epoch [39/50] - Loss: 1.1209
Epoch [40/50] - Loss: 1.1155
Epoch [41/50] - Loss: 1.1148
Epoch [42/50] - Loss: 1.1110
Epoch [43/50] - Loss: 1.1115
Epoch [44/50] - Loss: 1.1031
Epoch [45/50] - Loss: 1.0957
Epoch [46/50] - Loss: 1.0962
Epoch [47/50] - Loss: 1.0960
Epoch [48/50] - Loss: 1.0923
Epoch [49/50] - Loss: 1.0881
Epoch [50/50] - Loss: 1.0856
sum preds 3230
sum labels 6300
 - Test Metrics: Accuracy=0.7861, F1=0.5929, Recall=0.4484, Precision=0.8746
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9986
Epoch [2/50] - Loss: 3.3537
Epoch [3/50] - Loss: 2.7501
Epoch [4/50] - Loss: 2.3393
Epoch [5/50] - Loss: 2.1751
Epoch [6/50] - Loss: 2.0984
Epoch [7/50] - Loss: 1.9968
Epoch [8/50] - Loss: 1.8969
Epoch [9/50] - Loss: 1.8020
Epoch [10/50] - Loss: 1.7209
Epoch [11/50] - Loss: 1.6461
Epoch [12/50] - Loss: 1.5724
Epoch [13/50] - Loss: 1.4999
Epoch [14/50] - Loss: 1.4507
Epoch [15/50] - Loss: 1.4046
Epoch [16/50] - Loss: 1.3593
Epoch [17/50] - Loss: 1.3332
Epoch [18/50] - Loss: 1.3049
Epoch [19/50] - Loss: 1.2763
Epoch [20/50] - Loss: 1.2630
Epoch [21/50] - Loss: 1.2445
Epoch [22/50] - Loss: 1.2367
Epoch [23/50] - Loss: 1.2235
Epoch [24/50] - Loss: 1.2110
Epoch [25/50] - Loss: 1.1955
Epoch [26/50] - Loss: 1.1900
Epoch [27/50] - Loss: 1.1787
Epoch [28/50] - Loss: 1.1695
Epoch [29/50] - Loss: 1.1655
Epoch [30/50] - Loss: 1.1578
Epoch [31/50] - Loss: 1.1534
Epoch [32/50] - Loss: 1.1411
Epoch [33/50] - Loss: 1.1352
Epoch [34/50] - Loss: 1.1294
Epoch [35/50] - Loss: 1.1335
Epoch [36/50] - Loss: 1.1162
Epoch [37/50] - Loss: 1.1160
Epoch [38/50] - Loss: 1.1082
Epoch [39/50] - Loss: 1.1036
Epoch [40/50] - Loss: 1.1004
Epoch [41/50] - Loss: 1.0921
Epoch [42/50] - Loss: 1.0856
Epoch [43/50] - Loss: 1.0852
Epoch [44/50] - Loss: 1.0778
Epoch [45/50] - Loss: 1.0739
Epoch [46/50] - Loss: 1.0647
Epoch [47/50] - Loss: 1.0609
Epoch [48/50] - Loss: 1.0507
Epoch [49/50] - Loss: 1.0484
Epoch [50/50] - Loss: 1.0424
sum preds 3333
sum labels 6300
 - Test Metrics: Accuracy=0.7870, F1=0.5988, Recall=0.4578, Precision=0.8653
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_two_nnif_two_nnif_1904012518.csv.
Average F1 over valid seeds: 0.6103 ± 0.0206
___________________________________________________________________________________
Avg F1 for pubmed with SAR and two_nnif, MLP,0.2: 0.6103 ± 0.0206
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.2403
Epoch [2/50] - Loss: 3.0390
Epoch [3/50] - Loss: 2.3899
Epoch [4/50] - Loss: 2.1916
Epoch [5/50] - Loss: 2.1094
Epoch [6/50] - Loss: 2.0104
Epoch [7/50] - Loss: 1.8933
Epoch [8/50] - Loss: 1.8220
Epoch [9/50] - Loss: 1.7537
Epoch [10/50] - Loss: 1.6932
Epoch [11/50] - Loss: 1.6486
Epoch [12/50] - Loss: 1.6003
Epoch [13/50] - Loss: 1.5661
Epoch [14/50] - Loss: 1.5419
Epoch [15/50] - Loss: 1.5111
Epoch [16/50] - Loss: 1.4906
Epoch [17/50] - Loss: 1.4728
Epoch [18/50] - Loss: 1.4561
Epoch [19/50] - Loss: 1.4405
Epoch [20/50] - Loss: 1.4222
Epoch [21/50] - Loss: 1.4064
Epoch [22/50] - Loss: 1.4042
Epoch [23/50] - Loss: 1.3923
Epoch [24/50] - Loss: 1.3766
Epoch [25/50] - Loss: 1.3673
Epoch [26/50] - Loss: 1.3565
Epoch [27/50] - Loss: 1.3449
Epoch [28/50] - Loss: 1.3335
Epoch [29/50] - Loss: 1.3272
Epoch [30/50] - Loss: 1.3156
Epoch [31/50] - Loss: 1.3091
Epoch [32/50] - Loss: 1.3032
Epoch [33/50] - Loss: 1.2796
Epoch [34/50] - Loss: 1.2810
Epoch [35/50] - Loss: 1.2670
Epoch [36/50] - Loss: 1.2606
Epoch [37/50] - Loss: 1.2503
Epoch [38/50] - Loss: 1.2469
Epoch [39/50] - Loss: 1.2402
Epoch [40/50] - Loss: 1.2304
Epoch [41/50] - Loss: 1.2222
Epoch [42/50] - Loss: 1.2075
Epoch [43/50] - Loss: 1.2105
Epoch [44/50] - Loss: 1.1960
Epoch [45/50] - Loss: 1.1878
Epoch [46/50] - Loss: 1.1911
Epoch [47/50] - Loss: 1.1799
Epoch [48/50] - Loss: 1.1835
Epoch [49/50] - Loss: 1.1766
Epoch [50/50] - Loss: 1.1703
sum preds 3062
sum labels 6300
 - Test Metrics: Accuracy=0.7897, F1=0.5924, Recall=0.4402, Precision=0.9056
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.3882
Epoch [2/50] - Loss: 3.4456
Epoch [3/50] - Loss: 2.7795
Epoch [4/50] - Loss: 2.3988
Epoch [5/50] - Loss: 2.2210
Epoch [6/50] - Loss: 2.1479
Epoch [7/50] - Loss: 2.0581
Epoch [8/50] - Loss: 1.9516
Epoch [9/50] - Loss: 1.8642
Epoch [10/50] - Loss: 1.8154
Epoch [11/50] - Loss: 1.7587
Epoch [12/50] - Loss: 1.7181
Epoch [13/50] - Loss: 1.6752
Epoch [14/50] - Loss: 1.6339
Epoch [15/50] - Loss: 1.6071
Epoch [16/50] - Loss: 1.5781
Epoch [17/50] - Loss: 1.5556
Epoch [18/50] - Loss: 1.5376
Epoch [19/50] - Loss: 1.5205
Epoch [20/50] - Loss: 1.4932
Epoch [21/50] - Loss: 1.4932
Epoch [22/50] - Loss: 1.4771
Epoch [23/50] - Loss: 1.4638
Epoch [24/50] - Loss: 1.4599
Epoch [25/50] - Loss: 1.4355
Epoch [26/50] - Loss: 1.4310
Epoch [27/50] - Loss: 1.4160
Epoch [28/50] - Loss: 1.4029
Epoch [29/50] - Loss: 1.3908
Epoch [30/50] - Loss: 1.3864
Epoch [31/50] - Loss: 1.3741
Epoch [32/50] - Loss: 1.3674
Epoch [33/50] - Loss: 1.3539
Epoch [34/50] - Loss: 1.3434
Epoch [35/50] - Loss: 1.3427
Epoch [36/50] - Loss: 1.3323
Epoch [37/50] - Loss: 1.3274
Epoch [38/50] - Loss: 1.3267
Epoch [39/50] - Loss: 1.3066
Epoch [40/50] - Loss: 1.3027
Epoch [41/50] - Loss: 1.2942
Epoch [42/50] - Loss: 1.2948
Epoch [43/50] - Loss: 1.2907
Epoch [44/50] - Loss: 1.2858
Epoch [45/50] - Loss: 1.2726
Epoch [46/50] - Loss: 1.2732
Epoch [47/50] - Loss: 1.2679
Epoch [48/50] - Loss: 1.2597
Epoch [49/50] - Loss: 1.2570
Epoch [50/50] - Loss: 1.2517
sum preds 2844
sum labels 6300
 - Test Metrics: Accuracy=0.7772, F1=0.5580, Recall=0.4049, Precision=0.8970
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.3032
Epoch [2/50] - Loss: 3.1628
Epoch [3/50] - Loss: 2.4879
Epoch [4/50] - Loss: 2.2392
Epoch [5/50] - Loss: 2.1764
Epoch [6/50] - Loss: 2.1113
Epoch [7/50] - Loss: 2.0256
Epoch [8/50] - Loss: 1.9450
Epoch [9/50] - Loss: 1.8794
Epoch [10/50] - Loss: 1.8205
Epoch [11/50] - Loss: 1.7526
Epoch [12/50] - Loss: 1.7162
Epoch [13/50] - Loss: 1.6699
Epoch [14/50] - Loss: 1.6211
Epoch [15/50] - Loss: 1.5897
Epoch [16/50] - Loss: 1.5635
Epoch [17/50] - Loss: 1.5384
Epoch [18/50] - Loss: 1.5158
Epoch [19/50] - Loss: 1.5071
Epoch [20/50] - Loss: 1.4824
Epoch [21/50] - Loss: 1.4702
Epoch [22/50] - Loss: 1.4509
Epoch [23/50] - Loss: 1.4359
Epoch [24/50] - Loss: 1.4231
Epoch [25/50] - Loss: 1.4075
Epoch [26/50] - Loss: 1.3914
Epoch [27/50] - Loss: 1.3850
Epoch [28/50] - Loss: 1.3690
Epoch [29/50] - Loss: 1.3564
Epoch [30/50] - Loss: 1.3437
Epoch [31/50] - Loss: 1.3344
Epoch [32/50] - Loss: 1.3203
Epoch [33/50] - Loss: 1.3085
Epoch [34/50] - Loss: 1.2972
Epoch [35/50] - Loss: 1.2829
Epoch [36/50] - Loss: 1.2739
Epoch [37/50] - Loss: 1.2707
Epoch [38/50] - Loss: 1.2566
Epoch [39/50] - Loss: 1.2446
Epoch [40/50] - Loss: 1.2352
Epoch [41/50] - Loss: 1.2279
Epoch [42/50] - Loss: 1.2166
Epoch [43/50] - Loss: 1.2158
Epoch [44/50] - Loss: 1.2008
Epoch [45/50] - Loss: 1.1944
Epoch [46/50] - Loss: 1.1913
Epoch [47/50] - Loss: 1.1784
Epoch [48/50] - Loss: 1.1812
Epoch [49/50] - Loss: 1.1713
Epoch [50/50] - Loss: 1.1681
sum preds 3028
sum labels 6300
 - Test Metrics: Accuracy=0.7821, F1=0.5761, Recall=0.4265, Precision=0.8874
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_two_nnif_two_nnif_1904014219.csv.
Average F1 over valid seeds: 0.5755 ± 0.0141
___________________________________________________________________________________
Avg F1 for pubmed with SAR and two_nnif, GATConv,0.2: 0.5755 ± 0.0141
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.5121
Epoch [2/50] - Loss: 3.7195
Epoch [3/50] - Loss: 3.0425
Epoch [4/50] - Loss: 2.5756
Epoch [5/50] - Loss: 2.3331
Epoch [6/50] - Loss: 2.2277
Epoch [7/50] - Loss: 2.1440
Epoch [8/50] - Loss: 2.0589
Epoch [9/50] - Loss: 1.9771
Epoch [10/50] - Loss: 1.9027
Epoch [11/50] - Loss: 1.8371
Epoch [12/50] - Loss: 1.7673
Epoch [13/50] - Loss: 1.7241
Epoch [14/50] - Loss: 1.6762
Epoch [15/50] - Loss: 1.6445
Epoch [16/50] - Loss: 1.6146
Epoch [17/50] - Loss: 1.5854
Epoch [18/50] - Loss: 1.5596
Epoch [19/50] - Loss: 1.5348
Epoch [20/50] - Loss: 1.5209
Epoch [21/50] - Loss: 1.5042
Epoch [22/50] - Loss: 1.4922
Epoch [23/50] - Loss: 1.4768
Epoch [24/50] - Loss: 1.4670
Epoch [25/50] - Loss: 1.4570
Epoch [26/50] - Loss: 1.4618
Epoch [27/50] - Loss: 1.4432
Epoch [28/50] - Loss: 1.4386
Epoch [29/50] - Loss: 1.4309
Epoch [30/50] - Loss: 1.4280
Epoch [31/50] - Loss: 1.4171
Epoch [32/50] - Loss: 1.4167
Epoch [33/50] - Loss: 1.4073
Epoch [34/50] - Loss: 1.4074
Epoch [35/50] - Loss: 1.4063
Epoch [36/50] - Loss: 1.4016
Epoch [37/50] - Loss: 1.3890
Epoch [38/50] - Loss: 1.3932
Epoch [39/50] - Loss: 1.3920
Epoch [40/50] - Loss: 1.3836
Epoch [41/50] - Loss: 1.3710
Epoch [42/50] - Loss: 1.3769
Epoch [43/50] - Loss: 1.3763
Epoch [44/50] - Loss: 1.3674
Epoch [45/50] - Loss: 1.3689
Epoch [46/50] - Loss: 1.3638
Epoch [47/50] - Loss: 1.3547
Epoch [48/50] - Loss: 1.3609
Epoch [49/50] - Loss: 1.3545
Epoch [50/50] - Loss: 1.3502
sum preds 3310
sum labels 6300
 - Test Metrics: Accuracy=0.8044, F1=0.6308, Recall=0.4811, Precision=0.9157
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.5780
Epoch [2/50] - Loss: 3.8817
Epoch [3/50] - Loss: 3.2253
Epoch [4/50] - Loss: 2.7196
Epoch [5/50] - Loss: 2.4420
Epoch [6/50] - Loss: 2.3286
Epoch [7/50] - Loss: 2.2685
Epoch [8/50] - Loss: 2.2197
Epoch [9/50] - Loss: 2.1777
Epoch [10/50] - Loss: 2.1330
Epoch [11/50] - Loss: 2.0917
Epoch [12/50] - Loss: 2.0620
Epoch [13/50] - Loss: 2.0238
Epoch [14/50] - Loss: 1.9826
Epoch [15/50] - Loss: 1.9471
Epoch [16/50] - Loss: 1.9254
Epoch [17/50] - Loss: 1.8998
Epoch [18/50] - Loss: 1.8764
Epoch [19/50] - Loss: 1.8541
Epoch [20/50] - Loss: 1.8372
Epoch [21/50] - Loss: 1.8224
Epoch [22/50] - Loss: 1.8111
Epoch [23/50] - Loss: 1.7856
Epoch [24/50] - Loss: 1.7797
Epoch [25/50] - Loss: 1.7643
Epoch [26/50] - Loss: 1.7520
Epoch [27/50] - Loss: 1.7406
Epoch [28/50] - Loss: 1.7317
Epoch [29/50] - Loss: 1.7256
Epoch [30/50] - Loss: 1.7048
Epoch [31/50] - Loss: 1.6928
Epoch [32/50] - Loss: 1.6933
Epoch [33/50] - Loss: 1.6819
Epoch [34/50] - Loss: 1.6695
Epoch [35/50] - Loss: 1.6705
Epoch [36/50] - Loss: 1.6585
Epoch [37/50] - Loss: 1.6615
Epoch [38/50] - Loss: 1.6597
Epoch [39/50] - Loss: 1.6531
Epoch [40/50] - Loss: 1.6396
Epoch [41/50] - Loss: 1.6388
Epoch [42/50] - Loss: 1.6359
Epoch [43/50] - Loss: 1.6288
Epoch [44/50] - Loss: 1.6257
Epoch [45/50] - Loss: 1.6140
Epoch [46/50] - Loss: 1.6165
Epoch [47/50] - Loss: 1.6093
Epoch [48/50] - Loss: 1.6110
Epoch [49/50] - Loss: 1.6101
Epoch [50/50] - Loss: 1.5996
sum preds 0
sum labels 6300
 - Test Metrics: Accuracy=0.6527, F1=0.0000, Recall=0.0000, Precision=0.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.7106
Epoch [2/50] - Loss: 4.2877
Epoch [3/50] - Loss: 3.7873
Epoch [4/50] - Loss: 3.2668
Epoch [5/50] - Loss: 2.8304
Epoch [6/50] - Loss: 2.5133
Epoch [7/50] - Loss: 2.3409
Epoch [8/50] - Loss: 2.2588
Epoch [9/50] - Loss: 2.1904
Epoch [10/50] - Loss: 2.1339
Epoch [11/50] - Loss: 2.0676
Epoch [12/50] - Loss: 1.9974
Epoch [13/50] - Loss: 1.9462
Epoch [14/50] - Loss: 1.8936
Epoch [15/50] - Loss: 1.8407
Epoch [16/50] - Loss: 1.8021
Epoch [17/50] - Loss: 1.7632
Epoch [18/50] - Loss: 1.7173
Epoch [19/50] - Loss: 1.6822
Epoch [20/50] - Loss: 1.6538
Epoch [21/50] - Loss: 1.6223
Epoch [22/50] - Loss: 1.5972
Epoch [23/50] - Loss: 1.5729
Epoch [24/50] - Loss: 1.5379
Epoch [25/50] - Loss: 1.5178
Epoch [26/50] - Loss: 1.5056
Epoch [27/50] - Loss: 1.4856
Epoch [28/50] - Loss: 1.4769
Epoch [29/50] - Loss: 1.4619
Epoch [30/50] - Loss: 1.4518
Epoch [31/50] - Loss: 1.4387
Epoch [32/50] - Loss: 1.4321
Epoch [33/50] - Loss: 1.4247
Epoch [34/50] - Loss: 1.4138
Epoch [35/50] - Loss: 1.4128
Epoch [36/50] - Loss: 1.4104
Epoch [37/50] - Loss: 1.3999
Epoch [38/50] - Loss: 1.3923
Epoch [39/50] - Loss: 1.3987
Epoch [40/50] - Loss: 1.3789
Epoch [41/50] - Loss: 1.3733
Epoch [42/50] - Loss: 1.3740
Epoch [43/50] - Loss: 1.3741
Epoch [44/50] - Loss: 1.3719
Epoch [45/50] - Loss: 1.3720
Epoch [46/50] - Loss: 1.3605
Epoch [47/50] - Loss: 1.3525
Epoch [48/50] - Loss: 1.3602
Epoch [49/50] - Loss: 1.3584
Epoch [50/50] - Loss: 1.3524
sum preds 3116
sum labels 6300
 - Test Metrics: Accuracy=0.7933, F1=0.6017, Recall=0.4497, Precision=0.9092
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_two_nnif_two_nnif_1904015920.csv.
Average F1 over valid seeds: 0.4108 ± 0.2908
___________________________________________________________________________________
Avg F1 for pubmed with SAR and two_nnif, GCNConv,0.2: 0.4108 ± 0.2908
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.7080
Epoch [2/50] - Loss: 3.4846
Epoch [3/50] - Loss: 3.2321
Epoch [4/50] - Loss: 2.9816
Epoch [5/50] - Loss: 2.7605
Epoch [6/50] - Loss: 2.5155
Epoch [7/50] - Loss: 2.2589
Epoch [8/50] - Loss: 2.0273
Epoch [9/50] - Loss: 1.8024
Epoch [10/50] - Loss: 1.6166
Epoch [11/50] - Loss: 1.4704
Epoch [12/50] - Loss: 1.3590
Epoch [13/50] - Loss: 1.2689
Epoch [14/50] - Loss: 1.2056
Epoch [15/50] - Loss: 1.1531
Epoch [16/50] - Loss: 1.1138
Epoch [17/50] - Loss: 1.0789
Epoch [18/50] - Loss: 1.0499
Epoch [19/50] - Loss: 1.0279
Epoch [20/50] - Loss: 1.0071
Epoch [21/50] - Loss: 0.9849
Epoch [22/50] - Loss: 0.9716
Epoch [23/50] - Loss: 0.9518
Epoch [24/50] - Loss: 0.9398
Epoch [25/50] - Loss: 0.9263
Epoch [26/50] - Loss: 0.9213
Epoch [27/50] - Loss: 0.9097
Epoch [28/50] - Loss: 0.9024
Epoch [29/50] - Loss: 0.8932
Epoch [30/50] - Loss: 0.8904
Epoch [31/50] - Loss: 0.8829
Epoch [32/50] - Loss: 0.8697
Epoch [33/50] - Loss: 0.8666
Epoch [34/50] - Loss: 0.8622
Epoch [35/50] - Loss: 0.8548
Epoch [36/50] - Loss: 0.8533
Epoch [37/50] - Loss: 0.8434
Epoch [38/50] - Loss: 0.8400
Epoch [39/50] - Loss: 0.8381
Epoch [40/50] - Loss: 0.8399
Epoch [41/50] - Loss: 0.8343
Epoch [42/50] - Loss: 0.8234
Epoch [43/50] - Loss: 0.8251
Epoch [44/50] - Loss: 0.8269
Epoch [45/50] - Loss: 0.8178
Epoch [46/50] - Loss: 0.8239
Epoch [47/50] - Loss: 0.8130
Epoch [48/50] - Loss: 0.8177
Epoch [49/50] - Loss: 0.8116
Epoch [50/50] - Loss: 0.8159
sum preds 5751
sum labels 4725
 - Test Metrics: Accuracy=0.8385, F1=0.7446, Recall=0.8254, Precision=0.6781
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.0973
Epoch [2/50] - Loss: 3.8322
Epoch [3/50] - Loss: 3.5031
Epoch [4/50] - Loss: 3.1773
Epoch [5/50] - Loss: 2.8922
Epoch [6/50] - Loss: 2.6098
Epoch [7/50] - Loss: 2.3317
Epoch [8/50] - Loss: 2.0783
Epoch [9/50] - Loss: 1.8573
Epoch [10/50] - Loss: 1.6802
Epoch [11/50] - Loss: 1.5344
Epoch [12/50] - Loss: 1.4243
Epoch [13/50] - Loss: 1.3345
Epoch [14/50] - Loss: 1.2634
Epoch [15/50] - Loss: 1.2034
Epoch [16/50] - Loss: 1.1605
Epoch [17/50] - Loss: 1.1164
Epoch [18/50] - Loss: 1.0900
Epoch [19/50] - Loss: 1.0571
Epoch [20/50] - Loss: 1.0351
Epoch [21/50] - Loss: 1.0119
Epoch [22/50] - Loss: 0.9952
Epoch [23/50] - Loss: 0.9717
Epoch [24/50] - Loss: 0.9588
Epoch [25/50] - Loss: 0.9413
Epoch [26/50] - Loss: 0.9319
Epoch [27/50] - Loss: 0.9150
Epoch [28/50] - Loss: 0.9095
Epoch [29/50] - Loss: 0.8974
Epoch [30/50] - Loss: 0.8860
Epoch [31/50] - Loss: 0.8788
Epoch [32/50] - Loss: 0.8687
Epoch [33/50] - Loss: 0.8658
Epoch [34/50] - Loss: 0.8567
Epoch [35/50] - Loss: 0.8516
Epoch [36/50] - Loss: 0.8429
Epoch [37/50] - Loss: 0.8365
Epoch [38/50] - Loss: 0.8395
Epoch [39/50] - Loss: 0.8307
Epoch [40/50] - Loss: 0.8221
Epoch [41/50] - Loss: 0.8151
Epoch [42/50] - Loss: 0.8156
Epoch [43/50] - Loss: 0.8087
Epoch [44/50] - Loss: 0.8050
Epoch [45/50] - Loss: 0.8005
Epoch [46/50] - Loss: 0.7971
Epoch [47/50] - Loss: 0.7887
Epoch [48/50] - Loss: 0.7934
Epoch [49/50] - Loss: 0.7867
Epoch [50/50] - Loss: 0.7816
sum preds 5747
sum labels 4725
 - Test Metrics: Accuracy=0.8359, F1=0.7405, Recall=0.8205, Precision=0.6746
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.3951
Epoch [2/50] - Loss: 3.9918
Epoch [3/50] - Loss: 3.5470
Epoch [4/50] - Loss: 3.1832
Epoch [5/50] - Loss: 2.9187
Epoch [6/50] - Loss: 2.6722
Epoch [7/50] - Loss: 2.4012
Epoch [8/50] - Loss: 2.1578
Epoch [9/50] - Loss: 1.9419
Epoch [10/50] - Loss: 1.7483
Epoch [11/50] - Loss: 1.5913
Epoch [12/50] - Loss: 1.4755
Epoch [13/50] - Loss: 1.3805
Epoch [14/50] - Loss: 1.2950
Epoch [15/50] - Loss: 1.2366
Epoch [16/50] - Loss: 1.1887
Epoch [17/50] - Loss: 1.1454
Epoch [18/50] - Loss: 1.1109
Epoch [19/50] - Loss: 1.0801
Epoch [20/50] - Loss: 1.0569
Epoch [21/50] - Loss: 1.0280
Epoch [22/50] - Loss: 1.0107
Epoch [23/50] - Loss: 0.9910
Epoch [24/50] - Loss: 0.9843
Epoch [25/50] - Loss: 0.9616
Epoch [26/50] - Loss: 0.9469
Epoch [27/50] - Loss: 0.9394
Epoch [28/50] - Loss: 0.9271
Epoch [29/50] - Loss: 0.9207
Epoch [30/50] - Loss: 0.9093
Epoch [31/50] - Loss: 0.8958
Epoch [32/50] - Loss: 0.8926
Epoch [33/50] - Loss: 0.8829
Epoch [34/50] - Loss: 0.8717
Epoch [35/50] - Loss: 0.8694
Epoch [36/50] - Loss: 0.8595
Epoch [37/50] - Loss: 0.8504
Epoch [38/50] - Loss: 0.8523
Epoch [39/50] - Loss: 0.8426
Epoch [40/50] - Loss: 0.8419
Epoch [41/50] - Loss: 0.8330
Epoch [42/50] - Loss: 0.8253
Epoch [43/50] - Loss: 0.8246
Epoch [44/50] - Loss: 0.8212
Epoch [45/50] - Loss: 0.8138
Epoch [46/50] - Loss: 0.8082
Epoch [47/50] - Loss: 0.8094
Epoch [48/50] - Loss: 0.8062
Epoch [49/50] - Loss: 0.8009
Epoch [50/50] - Loss: 0.7938
sum preds 5745
sum labels 4725
 - Test Metrics: Accuracy=0.8396, F1=0.7461, Recall=0.8267, Precision=0.6799
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_spy_spy_1904021608.csv.
Average F1 over valid seeds: 0.7437 ± 0.0024
___________________________________________________________________________________
Avg F1 for pubmed with SAR and spy, MLP,0.4: 0.7437 ± 0.0024
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8856
Epoch [2/50] - Loss: 3.3437
Epoch [3/50] - Loss: 3.0029
Epoch [4/50] - Loss: 2.7381
Epoch [5/50] - Loss: 2.4865
Epoch [6/50] - Loss: 2.2609
Epoch [7/50] - Loss: 2.0879
Epoch [8/50] - Loss: 1.9389
Epoch [9/50] - Loss: 1.8085
Epoch [10/50] - Loss: 1.7079
Epoch [11/50] - Loss: 1.6235
Epoch [12/50] - Loss: 1.5780
Epoch [13/50] - Loss: 1.5329
Epoch [14/50] - Loss: 1.4950
Epoch [15/50] - Loss: 1.4666
Epoch [16/50] - Loss: 1.4335
Epoch [17/50] - Loss: 1.4078
Epoch [18/50] - Loss: 1.3963
Epoch [19/50] - Loss: 1.3724
Epoch [20/50] - Loss: 1.3558
Epoch [21/50] - Loss: 1.3392
Epoch [22/50] - Loss: 1.3283
Epoch [23/50] - Loss: 1.3057
Epoch [24/50] - Loss: 1.2844
Epoch [25/50] - Loss: 1.2671
Epoch [26/50] - Loss: 1.2555
Epoch [27/50] - Loss: 1.2465
Epoch [28/50] - Loss: 1.2272
Epoch [29/50] - Loss: 1.2199
Epoch [30/50] - Loss: 1.2068
Epoch [31/50] - Loss: 1.1924
Epoch [32/50] - Loss: 1.1790
Epoch [33/50] - Loss: 1.1679
Epoch [34/50] - Loss: 1.1556
Epoch [35/50] - Loss: 1.1437
Epoch [36/50] - Loss: 1.1323
Epoch [37/50] - Loss: 1.1284
Epoch [38/50] - Loss: 1.1256
Epoch [39/50] - Loss: 1.1199
Epoch [40/50] - Loss: 1.0984
Epoch [41/50] - Loss: 1.0990
Epoch [42/50] - Loss: 1.0842
Epoch [43/50] - Loss: 1.0771
Epoch [44/50] - Loss: 1.0589
Epoch [45/50] - Loss: 1.0609
Epoch [46/50] - Loss: 1.0547
Epoch [47/50] - Loss: 1.0578
Epoch [48/50] - Loss: 1.0414
Epoch [49/50] - Loss: 1.0322
Epoch [50/50] - Loss: 1.0301
sum preds 5026
sum labels 4725
 - Test Metrics: Accuracy=0.8779, F1=0.7925, Recall=0.8178, Precision=0.7688
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9704
Epoch [2/50] - Loss: 3.5451
Epoch [3/50] - Loss: 3.2329
Epoch [4/50] - Loss: 3.0155
Epoch [5/50] - Loss: 2.7899
Epoch [6/50] - Loss: 2.5179
Epoch [7/50] - Loss: 2.3008
Epoch [8/50] - Loss: 2.0893
Epoch [9/50] - Loss: 1.9395
Epoch [10/50] - Loss: 1.8168
Epoch [11/50] - Loss: 1.7316
Epoch [12/50] - Loss: 1.6637
Epoch [13/50] - Loss: 1.6096
Epoch [14/50] - Loss: 1.5659
Epoch [15/50] - Loss: 1.5190
Epoch [16/50] - Loss: 1.4940
Epoch [17/50] - Loss: 1.4681
Epoch [18/50] - Loss: 1.4459
Epoch [19/50] - Loss: 1.4325
Epoch [20/50] - Loss: 1.4059
Epoch [21/50] - Loss: 1.3902
Epoch [22/50] - Loss: 1.3720
Epoch [23/50] - Loss: 1.3507
Epoch [24/50] - Loss: 1.3422
Epoch [25/50] - Loss: 1.3255
Epoch [26/50] - Loss: 1.3180
Epoch [27/50] - Loss: 1.3041
Epoch [28/50] - Loss: 1.2929
Epoch [29/50] - Loss: 1.2867
Epoch [30/50] - Loss: 1.2794
Epoch [31/50] - Loss: 1.2571
Epoch [32/50] - Loss: 1.2535
Epoch [33/50] - Loss: 1.2452
Epoch [34/50] - Loss: 1.2395
Epoch [35/50] - Loss: 1.2287
Epoch [36/50] - Loss: 1.2192
Epoch [37/50] - Loss: 1.2155
Epoch [38/50] - Loss: 1.1925
Epoch [39/50] - Loss: 1.1856
Epoch [40/50] - Loss: 1.1824
Epoch [41/50] - Loss: 1.1710
Epoch [42/50] - Loss: 1.1639
Epoch [43/50] - Loss: 1.1623
Epoch [44/50] - Loss: 1.1503
Epoch [45/50] - Loss: 1.1347
Epoch [46/50] - Loss: 1.1407
Epoch [47/50] - Loss: 1.1319
Epoch [48/50] - Loss: 1.1157
Epoch [49/50] - Loss: 1.1101
Epoch [50/50] - Loss: 1.1054
sum preds 5081
sum labels 4725
 - Test Metrics: Accuracy=0.8764, F1=0.7911, Recall=0.8210, Precision=0.7634
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9233
Epoch [2/50] - Loss: 3.4245
Epoch [3/50] - Loss: 3.1010
Epoch [4/50] - Loss: 2.8919
Epoch [5/50] - Loss: 2.6632
Epoch [6/50] - Loss: 2.4255
Epoch [7/50] - Loss: 2.2314
Epoch [8/50] - Loss: 2.0445
Epoch [9/50] - Loss: 1.8916
Epoch [10/50] - Loss: 1.7684
Epoch [11/50] - Loss: 1.6774
Epoch [12/50] - Loss: 1.6107
Epoch [13/50] - Loss: 1.5642
Epoch [14/50] - Loss: 1.5304
Epoch [15/50] - Loss: 1.5049
Epoch [16/50] - Loss: 1.4807
Epoch [17/50] - Loss: 1.4646
Epoch [18/50] - Loss: 1.4437
Epoch [19/50] - Loss: 1.4276
Epoch [20/50] - Loss: 1.4086
Epoch [21/50] - Loss: 1.4018
Epoch [22/50] - Loss: 1.3873
Epoch [23/50] - Loss: 1.3797
Epoch [24/50] - Loss: 1.3626
Epoch [25/50] - Loss: 1.3580
Epoch [26/50] - Loss: 1.3395
Epoch [27/50] - Loss: 1.3274
Epoch [28/50] - Loss: 1.3177
Epoch [29/50] - Loss: 1.3180
Epoch [30/50] - Loss: 1.2960
Epoch [31/50] - Loss: 1.2932
Epoch [32/50] - Loss: 1.2782
Epoch [33/50] - Loss: 1.2736
Epoch [34/50] - Loss: 1.2617
Epoch [35/50] - Loss: 1.2563
Epoch [36/50] - Loss: 1.2505
Epoch [37/50] - Loss: 1.2423
Epoch [38/50] - Loss: 1.2266
Epoch [39/50] - Loss: 1.2257
Epoch [40/50] - Loss: 1.2189
Epoch [41/50] - Loss: 1.2026
Epoch [42/50] - Loss: 1.2028
Epoch [43/50] - Loss: 1.2001
Epoch [44/50] - Loss: 1.1888
Epoch [45/50] - Loss: 1.1804
Epoch [46/50] - Loss: 1.1775
Epoch [47/50] - Loss: 1.1714
Epoch [48/50] - Loss: 1.1701
Epoch [49/50] - Loss: 1.1630
Epoch [50/50] - Loss: 1.1520
sum preds 4777
sum labels 4725
 - Test Metrics: Accuracy=0.8781, F1=0.7874, Recall=0.7917, Precision=0.7831
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_spy_spy_1904022802.csv.
Average F1 over valid seeds: 0.7904 ± 0.0022
___________________________________________________________________________________
Avg F1 for pubmed with SAR and spy, GATConv,0.4: 0.7904 ± 0.0022
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.0008
Epoch [2/50] - Loss: 3.6390
Epoch [3/50] - Loss: 3.3275
Epoch [4/50] - Loss: 3.0897
Epoch [5/50] - Loss: 2.8899
Epoch [6/50] - Loss: 2.6853
Epoch [7/50] - Loss: 2.4652
Epoch [8/50] - Loss: 2.2714
Epoch [9/50] - Loss: 2.1000
Epoch [10/50] - Loss: 1.9591
Epoch [11/50] - Loss: 1.8424
Epoch [12/50] - Loss: 1.7340
Epoch [13/50] - Loss: 1.6511
Epoch [14/50] - Loss: 1.5850
Epoch [15/50] - Loss: 1.5293
Epoch [16/50] - Loss: 1.4791
Epoch [17/50] - Loss: 1.4485
Epoch [18/50] - Loss: 1.4250
Epoch [19/50] - Loss: 1.3991
Epoch [20/50] - Loss: 1.3798
Epoch [21/50] - Loss: 1.3645
Epoch [22/50] - Loss: 1.3448
Epoch [23/50] - Loss: 1.3383
Epoch [24/50] - Loss: 1.3168
Epoch [25/50] - Loss: 1.3067
Epoch [26/50] - Loss: 1.2954
Epoch [27/50] - Loss: 1.2835
Epoch [28/50] - Loss: 1.2773
Epoch [29/50] - Loss: 1.2718
Epoch [30/50] - Loss: 1.2622
Epoch [31/50] - Loss: 1.2578
Epoch [32/50] - Loss: 1.2455
Epoch [33/50] - Loss: 1.2378
Epoch [34/50] - Loss: 1.2335
Epoch [35/50] - Loss: 1.2343
Epoch [36/50] - Loss: 1.2198
Epoch [37/50] - Loss: 1.2309
Epoch [38/50] - Loss: 1.2115
Epoch [39/50] - Loss: 1.2083
Epoch [40/50] - Loss: 1.2130
Epoch [41/50] - Loss: 1.2033
Epoch [42/50] - Loss: 1.1984
Epoch [43/50] - Loss: 1.1983
Epoch [44/50] - Loss: 1.1857
Epoch [45/50] - Loss: 1.1926
Epoch [46/50] - Loss: 1.1872
Epoch [47/50] - Loss: 1.1847
Epoch [48/50] - Loss: 1.1813
Epoch [49/50] - Loss: 1.1798
Epoch [50/50] - Loss: 1.1727
sum preds 5120
sum labels 4725
 - Test Metrics: Accuracy=0.8780, F1=0.7947, Recall=0.8279, Precision=0.7641
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9033
Epoch [2/50] - Loss: 3.4310
Epoch [3/50] - Loss: 3.1609
Epoch [4/50] - Loss: 2.9721
Epoch [5/50] - Loss: 2.7542
Epoch [6/50] - Loss: 2.5395
Epoch [7/50] - Loss: 2.3499
Epoch [8/50] - Loss: 2.1664
Epoch [9/50] - Loss: 2.0074
Epoch [10/50] - Loss: 1.8722
Epoch [11/50] - Loss: 1.7556
Epoch [12/50] - Loss: 1.6809
Epoch [13/50] - Loss: 1.6058
Epoch [14/50] - Loss: 1.5511
Epoch [15/50] - Loss: 1.5076
Epoch [16/50] - Loss: 1.4815
Epoch [17/50] - Loss: 1.4436
Epoch [18/50] - Loss: 1.4260
Epoch [19/50] - Loss: 1.4102
Epoch [20/50] - Loss: 1.3952
Epoch [21/50] - Loss: 1.3778
Epoch [22/50] - Loss: 1.3632
Epoch [23/50] - Loss: 1.3551
Epoch [24/50] - Loss: 1.3412
Epoch [25/50] - Loss: 1.3304
Epoch [26/50] - Loss: 1.3253
Epoch [27/50] - Loss: 1.3172
Epoch [28/50] - Loss: 1.3056
Epoch [29/50] - Loss: 1.3070
Epoch [30/50] - Loss: 1.3012
Epoch [31/50] - Loss: 1.2881
Epoch [32/50] - Loss: 1.2812
Epoch [33/50] - Loss: 1.2779
Epoch [34/50] - Loss: 1.2723
Epoch [35/50] - Loss: 1.2679
Epoch [36/50] - Loss: 1.2699
Epoch [37/50] - Loss: 1.2601
Epoch [38/50] - Loss: 1.2561
Epoch [39/50] - Loss: 1.2539
Epoch [40/50] - Loss: 1.2493
Epoch [41/50] - Loss: 1.2395
Epoch [42/50] - Loss: 1.2422
Epoch [43/50] - Loss: 1.2313
Epoch [44/50] - Loss: 1.2267
Epoch [45/50] - Loss: 1.2333
Epoch [46/50] - Loss: 1.2204
Epoch [47/50] - Loss: 1.2194
Epoch [48/50] - Loss: 1.2244
Epoch [49/50] - Loss: 1.2121
Epoch [50/50] - Loss: 1.2090
sum preds 4949
sum labels 4725
 - Test Metrics: Accuracy=0.8819, F1=0.7978, Recall=0.8167, Precision=0.7798
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9615
Epoch [2/50] - Loss: 3.5280
Epoch [3/50] - Loss: 3.2423
Epoch [4/50] - Loss: 3.0323
Epoch [5/50] - Loss: 2.8158
Epoch [6/50] - Loss: 2.5969
Epoch [7/50] - Loss: 2.3926
Epoch [8/50] - Loss: 2.2160
Epoch [9/50] - Loss: 2.0399
Epoch [10/50] - Loss: 1.9083
Epoch [11/50] - Loss: 1.7833
Epoch [12/50] - Loss: 1.6790
Epoch [13/50] - Loss: 1.6151
Epoch [14/50] - Loss: 1.5593
Epoch [15/50] - Loss: 1.5125
Epoch [16/50] - Loss: 1.4779
Epoch [17/50] - Loss: 1.4496
Epoch [18/50] - Loss: 1.4241
Epoch [19/50] - Loss: 1.4109
Epoch [20/50] - Loss: 1.3945
Epoch [21/50] - Loss: 1.3751
Epoch [22/50] - Loss: 1.3660
Epoch [23/50] - Loss: 1.3535
Epoch [24/50] - Loss: 1.3411
Epoch [25/50] - Loss: 1.3287
Epoch [26/50] - Loss: 1.3304
Epoch [27/50] - Loss: 1.3176
Epoch [28/50] - Loss: 1.3096
Epoch [29/50] - Loss: 1.3055
Epoch [30/50] - Loss: 1.3002
Epoch [31/50] - Loss: 1.2921
Epoch [32/50] - Loss: 1.2846
Epoch [33/50] - Loss: 1.2921
Epoch [34/50] - Loss: 1.2761
Epoch [35/50] - Loss: 1.2729
Epoch [36/50] - Loss: 1.2661
Epoch [37/50] - Loss: 1.2593
Epoch [38/50] - Loss: 1.2550
Epoch [39/50] - Loss: 1.2472
Epoch [40/50] - Loss: 1.2374
Epoch [41/50] - Loss: 1.2405
Epoch [42/50] - Loss: 1.2409
Epoch [43/50] - Loss: 1.2412
Epoch [44/50] - Loss: 1.2285
Epoch [45/50] - Loss: 1.2318
Epoch [46/50] - Loss: 1.2265
Epoch [47/50] - Loss: 1.2208
Epoch [48/50] - Loss: 1.2224
Epoch [49/50] - Loss: 1.2261
Epoch [50/50] - Loss: 1.2151
sum preds 5057
sum labels 4725
 - Test Metrics: Accuracy=0.8766, F1=0.7910, Recall=0.8188, Precision=0.7651
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_spy_spy_1904023947.csv.
Average F1 over valid seeds: 0.7945 ± 0.0028
___________________________________________________________________________________
Avg F1 for pubmed with SAR and spy, GCNConv,0.4: 0.7945 ± 0.0028
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.5771
Epoch [2/50] - Loss: 3.2772
Epoch [3/50] - Loss: 2.9692
Epoch [4/50] - Loss: 2.7272
Epoch [5/50] - Loss: 2.5339
Epoch [6/50] - Loss: 2.3243
Epoch [7/50] - Loss: 2.1230
Epoch [8/50] - Loss: 1.9400
Epoch [9/50] - Loss: 1.7570
Epoch [10/50] - Loss: 1.5966
Epoch [11/50] - Loss: 1.4555
Epoch [12/50] - Loss: 1.3383
Epoch [13/50] - Loss: 1.2455
Epoch [14/50] - Loss: 1.1843
Epoch [15/50] - Loss: 1.1295
Epoch [16/50] - Loss: 1.0828
Epoch [17/50] - Loss: 1.0325
Epoch [18/50] - Loss: 1.0066
Epoch [19/50] - Loss: 0.9775
Epoch [20/50] - Loss: 0.9518
Epoch [21/50] - Loss: 0.9386
Epoch [22/50] - Loss: 0.9148
Epoch [23/50] - Loss: 0.8959
Epoch [24/50] - Loss: 0.8900
Epoch [25/50] - Loss: 0.8751
Epoch [26/50] - Loss: 0.8649
Epoch [27/50] - Loss: 0.8561
Epoch [28/50] - Loss: 0.8473
Epoch [29/50] - Loss: 0.8395
Epoch [30/50] - Loss: 0.8325
Epoch [31/50] - Loss: 0.8214
Epoch [32/50] - Loss: 0.8127
Epoch [33/50] - Loss: 0.8069
Epoch [34/50] - Loss: 0.8019
Epoch [35/50] - Loss: 0.7987
Epoch [36/50] - Loss: 0.7893
Epoch [37/50] - Loss: 0.7831
Epoch [38/50] - Loss: 0.7793
Epoch [39/50] - Loss: 0.7825
Epoch [40/50] - Loss: 0.7705
Epoch [41/50] - Loss: 0.7677
Epoch [42/50] - Loss: 0.7714
Epoch [43/50] - Loss: 0.7699
Epoch [44/50] - Loss: 0.7633
Epoch [45/50] - Loss: 0.7589
Epoch [46/50] - Loss: 0.7538
Epoch [47/50] - Loss: 0.7585
Epoch [48/50] - Loss: 0.7489
Epoch [49/50] - Loss: 0.7549
Epoch [50/50] - Loss: 0.7387
sum preds 6035
sum labels 5513
 - Test Metrics: Accuracy=0.8390, F1=0.7581, Recall=0.7939, Precision=0.7253
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.0842
Epoch [2/50] - Loss: 3.7704
Epoch [3/50] - Loss: 3.3850
Epoch [4/50] - Loss: 2.9979
Epoch [5/50] - Loss: 2.6835
Epoch [6/50] - Loss: 2.4311
Epoch [7/50] - Loss: 2.1782
Epoch [8/50] - Loss: 1.9365
Epoch [9/50] - Loss: 1.7198
Epoch [10/50] - Loss: 1.5568
Epoch [11/50] - Loss: 1.4069
Epoch [12/50] - Loss: 1.2914
Epoch [13/50] - Loss: 1.2002
Epoch [14/50] - Loss: 1.1291
Epoch [15/50] - Loss: 1.0632
Epoch [16/50] - Loss: 1.0287
Epoch [17/50] - Loss: 0.9880
Epoch [18/50] - Loss: 0.9488
Epoch [19/50] - Loss: 0.9200
Epoch [20/50] - Loss: 0.9011
Epoch [21/50] - Loss: 0.8725
Epoch [22/50] - Loss: 0.8540
Epoch [23/50] - Loss: 0.8404
Epoch [24/50] - Loss: 0.8267
Epoch [25/50] - Loss: 0.8070
Epoch [26/50] - Loss: 0.7977
Epoch [27/50] - Loss: 0.7819
Epoch [28/50] - Loss: 0.7720
Epoch [29/50] - Loss: 0.7694
Epoch [30/50] - Loss: 0.7482
Epoch [31/50] - Loss: 0.7489
Epoch [32/50] - Loss: 0.7377
Epoch [33/50] - Loss: 0.7307
Epoch [34/50] - Loss: 0.7188
Epoch [35/50] - Loss: 0.7147
Epoch [36/50] - Loss: 0.7119
Epoch [37/50] - Loss: 0.6998
Epoch [38/50] - Loss: 0.6957
Epoch [39/50] - Loss: 0.6938
Epoch [40/50] - Loss: 0.6875
Epoch [41/50] - Loss: 0.6837
Epoch [42/50] - Loss: 0.6735
Epoch [43/50] - Loss: 0.6754
Epoch [44/50] - Loss: 0.6697
Epoch [45/50] - Loss: 0.6636
Epoch [46/50] - Loss: 0.6605
Epoch [47/50] - Loss: 0.6584
Epoch [48/50] - Loss: 0.6499
Epoch [49/50] - Loss: 0.6513
Epoch [50/50] - Loss: 0.6462
sum preds 6092
sum labels 5513
 - Test Metrics: Accuracy=0.8333, F1=0.7507, Recall=0.7901, Precision=0.7150
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.4593
Epoch [2/50] - Loss: 3.9651
Epoch [3/50] - Loss: 3.4102
Epoch [4/50] - Loss: 2.9268
Epoch [5/50] - Loss: 2.6214
Epoch [6/50] - Loss: 2.4268
Epoch [7/50] - Loss: 2.2286
Epoch [8/50] - Loss: 2.0261
Epoch [9/50] - Loss: 1.8340
Epoch [10/50] - Loss: 1.6754
Epoch [11/50] - Loss: 1.5371
Epoch [12/50] - Loss: 1.4130
Epoch [13/50] - Loss: 1.3067
Epoch [14/50] - Loss: 1.2277
Epoch [15/50] - Loss: 1.1627
Epoch [16/50] - Loss: 1.1081
Epoch [17/50] - Loss: 1.0659
Epoch [18/50] - Loss: 1.0228
Epoch [19/50] - Loss: 0.9865
Epoch [20/50] - Loss: 0.9641
Epoch [21/50] - Loss: 0.9438
Epoch [22/50] - Loss: 0.9247
Epoch [23/50] - Loss: 0.9007
Epoch [24/50] - Loss: 0.8893
Epoch [25/50] - Loss: 0.8713
Epoch [26/50] - Loss: 0.8631
Epoch [27/50] - Loss: 0.8484
Epoch [28/50] - Loss: 0.8377
Epoch [29/50] - Loss: 0.8274
Epoch [30/50] - Loss: 0.8136
Epoch [31/50] - Loss: 0.8041
Epoch [32/50] - Loss: 0.8021
Epoch [33/50] - Loss: 0.7935
Epoch [34/50] - Loss: 0.7810
Epoch [35/50] - Loss: 0.7769
Epoch [36/50] - Loss: 0.7676
Epoch [37/50] - Loss: 0.7622
Epoch [38/50] - Loss: 0.7535
Epoch [39/50] - Loss: 0.7474
Epoch [40/50] - Loss: 0.7434
Epoch [41/50] - Loss: 0.7381
Epoch [42/50] - Loss: 0.7353
Epoch [43/50] - Loss: 0.7332
Epoch [44/50] - Loss: 0.7237
Epoch [45/50] - Loss: 0.7273
Epoch [46/50] - Loss: 0.7160
Epoch [47/50] - Loss: 0.7105
Epoch [48/50] - Loss: 0.7127
Epoch [49/50] - Loss: 0.7048
Epoch [50/50] - Loss: 0.7006
sum preds 5700
sum labels 5513
 - Test Metrics: Accuracy=0.8430, F1=0.7570, Recall=0.7698, Precision=0.7446
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_spy_spy_1904025126.csv.
Average F1 over valid seeds: 0.7552 ± 0.0032
___________________________________________________________________________________
Avg F1 for pubmed with SAR and spy, MLP,0.3: 0.7552 ± 0.0032
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8251
Epoch [2/50] - Loss: 3.1555
Epoch [3/50] - Loss: 2.7641
Epoch [4/50] - Loss: 2.5626
Epoch [5/50] - Loss: 2.3701
Epoch [6/50] - Loss: 2.1670
Epoch [7/50] - Loss: 2.0144
Epoch [8/50] - Loss: 1.8846
Epoch [9/50] - Loss: 1.7612
Epoch [10/50] - Loss: 1.6640
Epoch [11/50] - Loss: 1.5858
Epoch [12/50] - Loss: 1.5280
Epoch [13/50] - Loss: 1.4721
Epoch [14/50] - Loss: 1.4499
Epoch [15/50] - Loss: 1.4065
Epoch [16/50] - Loss: 1.3787
Epoch [17/50] - Loss: 1.3613
Epoch [18/50] - Loss: 1.3396
Epoch [19/50] - Loss: 1.3243
Epoch [20/50] - Loss: 1.3137
Epoch [21/50] - Loss: 1.2953
Epoch [22/50] - Loss: 1.2858
Epoch [23/50] - Loss: 1.2709
Epoch [24/50] - Loss: 1.2588
Epoch [25/50] - Loss: 1.2507
Epoch [26/50] - Loss: 1.2310
Epoch [27/50] - Loss: 1.2320
Epoch [28/50] - Loss: 1.2095
Epoch [29/50] - Loss: 1.2030
Epoch [30/50] - Loss: 1.1883
Epoch [31/50] - Loss: 1.1747
Epoch [32/50] - Loss: 1.1682
Epoch [33/50] - Loss: 1.1529
Epoch [34/50] - Loss: 1.1476
Epoch [35/50] - Loss: 1.1332
Epoch [36/50] - Loss: 1.1235
Epoch [37/50] - Loss: 1.1113
Epoch [38/50] - Loss: 1.0986
Epoch [39/50] - Loss: 1.0921
Epoch [40/50] - Loss: 1.0846
Epoch [41/50] - Loss: 1.0729
Epoch [42/50] - Loss: 1.0557
Epoch [43/50] - Loss: 1.0468
Epoch [44/50] - Loss: 1.0456
Epoch [45/50] - Loss: 1.0279
Epoch [46/50] - Loss: 1.0290
Epoch [47/50] - Loss: 1.0275
Epoch [48/50] - Loss: 1.0194
Epoch [49/50] - Loss: 1.0137
Epoch [50/50] - Loss: 1.0120
sum preds 5224
sum labels 5513
 - Test Metrics: Accuracy=0.8740, F1=0.7963, Recall=0.7754, Precision=0.8183
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9186
Epoch [2/50] - Loss: 3.3935
Epoch [3/50] - Loss: 3.0059
Epoch [4/50] - Loss: 2.7867
Epoch [5/50] - Loss: 2.6405
Epoch [6/50] - Loss: 2.4842
Epoch [7/50] - Loss: 2.2919
Epoch [8/50] - Loss: 2.1467
Epoch [9/50] - Loss: 1.9960
Epoch [10/50] - Loss: 1.8692
Epoch [11/50] - Loss: 1.7627
Epoch [12/50] - Loss: 1.6759
Epoch [13/50] - Loss: 1.5859
Epoch [14/50] - Loss: 1.5244
Epoch [15/50] - Loss: 1.4791
Epoch [16/50] - Loss: 1.4483
Epoch [17/50] - Loss: 1.4001
Epoch [18/50] - Loss: 1.3787
Epoch [19/50] - Loss: 1.3636
Epoch [20/50] - Loss: 1.3383
Epoch [21/50] - Loss: 1.3221
Epoch [22/50] - Loss: 1.2905
Epoch [23/50] - Loss: 1.2756
Epoch [24/50] - Loss: 1.2684
Epoch [25/50] - Loss: 1.2482
Epoch [26/50] - Loss: 1.2377
Epoch [27/50] - Loss: 1.2195
Epoch [28/50] - Loss: 1.1979
Epoch [29/50] - Loss: 1.1831
Epoch [30/50] - Loss: 1.1912
Epoch [31/50] - Loss: 1.1848
Epoch [32/50] - Loss: 1.1650
Epoch [33/50] - Loss: 1.1372
Epoch [34/50] - Loss: 1.1283
Epoch [35/50] - Loss: 1.1299
Epoch [36/50] - Loss: 1.1225
Epoch [37/50] - Loss: 1.1085
Epoch [38/50] - Loss: 1.1187
Epoch [39/50] - Loss: 1.0965
Epoch [40/50] - Loss: 1.0896
Epoch [41/50] - Loss: 1.0796
Epoch [42/50] - Loss: 1.0736
Epoch [43/50] - Loss: 1.0801
Epoch [44/50] - Loss: 1.0665
Epoch [45/50] - Loss: 1.0551
Epoch [46/50] - Loss: 1.0523
Epoch [47/50] - Loss: 1.0424
Epoch [48/50] - Loss: 1.0520
Epoch [49/50] - Loss: 1.0353
Epoch [50/50] - Loss: 1.0512
sum preds 5458
sum labels 5513
 - Test Metrics: Accuracy=0.8746, F1=0.8016, Recall=0.7976, Precision=0.8056
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8816
Epoch [2/50] - Loss: 3.2914
Epoch [3/50] - Loss: 2.8918
Epoch [4/50] - Loss: 2.6703
Epoch [5/50] - Loss: 2.5274
Epoch [6/50] - Loss: 2.3300
Epoch [7/50] - Loss: 2.1346
Epoch [8/50] - Loss: 1.9852
Epoch [9/50] - Loss: 1.8419
Epoch [10/50] - Loss: 1.7182
Epoch [11/50] - Loss: 1.6021
Epoch [12/50] - Loss: 1.5268
Epoch [13/50] - Loss: 1.4635
Epoch [14/50] - Loss: 1.4279
Epoch [15/50] - Loss: 1.3849
Epoch [16/50] - Loss: 1.3612
Epoch [17/50] - Loss: 1.3250
Epoch [18/50] - Loss: 1.3355
Epoch [19/50] - Loss: 1.2988
Epoch [20/50] - Loss: 1.2923
Epoch [21/50] - Loss: 1.2762
Epoch [22/50] - Loss: 1.2759
Epoch [23/50] - Loss: 1.2419
Epoch [24/50] - Loss: 1.2315
Epoch [25/50] - Loss: 1.2319
Epoch [26/50] - Loss: 1.2134
Epoch [27/50] - Loss: 1.2158
Epoch [28/50] - Loss: 1.1941
Epoch [29/50] - Loss: 1.1947
Epoch [30/50] - Loss: 1.1782
Epoch [31/50] - Loss: 1.1707
Epoch [32/50] - Loss: 1.1546
Epoch [33/50] - Loss: 1.1498
Epoch [34/50] - Loss: 1.1458
Epoch [35/50] - Loss: 1.1322
Epoch [36/50] - Loss: 1.1269
Epoch [37/50] - Loss: 1.1154
Epoch [38/50] - Loss: 1.1074
Epoch [39/50] - Loss: 1.0990
Epoch [40/50] - Loss: 1.0988
Epoch [41/50] - Loss: 1.1004
Epoch [42/50] - Loss: 1.0934
Epoch [43/50] - Loss: 1.0778
Epoch [44/50] - Loss: 1.0559
Epoch [45/50] - Loss: 1.0446
Epoch [46/50] - Loss: 1.0544
Epoch [47/50] - Loss: 1.0566
Epoch [48/50] - Loss: 1.0432
Epoch [49/50] - Loss: 1.0394
Epoch [50/50] - Loss: 1.0346
sum preds 5334
sum labels 5513
 - Test Metrics: Accuracy=0.8751, F1=0.8002, Recall=0.7872, Precision=0.8136
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_spy_spy_1904030256.csv.
Average F1 over valid seeds: 0.7994 ± 0.0022
___________________________________________________________________________________
Avg F1 for pubmed with SAR and spy, GATConv,0.3: 0.7994 ± 0.0022
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9678
Epoch [2/50] - Loss: 3.5277
Epoch [3/50] - Loss: 3.1432
Epoch [4/50] - Loss: 2.8689
Epoch [5/50] - Loss: 2.6837
Epoch [6/50] - Loss: 2.5384
Epoch [7/50] - Loss: 2.3806
Epoch [8/50] - Loss: 2.2347
Epoch [9/50] - Loss: 2.0974
Epoch [10/50] - Loss: 1.9694
Epoch [11/50] - Loss: 1.8580
Epoch [12/50] - Loss: 1.7692
Epoch [13/50] - Loss: 1.6760
Epoch [14/50] - Loss: 1.6083
Epoch [15/50] - Loss: 1.5380
Epoch [16/50] - Loss: 1.4892
Epoch [17/50] - Loss: 1.4474
Epoch [18/50] - Loss: 1.4196
Epoch [19/50] - Loss: 1.3958
Epoch [20/50] - Loss: 1.3645
Epoch [21/50] - Loss: 1.3476
Epoch [22/50] - Loss: 1.3187
Epoch [23/50] - Loss: 1.3109
Epoch [24/50] - Loss: 1.2913
Epoch [25/50] - Loss: 1.2822
Epoch [26/50] - Loss: 1.2605
Epoch [27/50] - Loss: 1.2406
Epoch [28/50] - Loss: 1.2345
Epoch [29/50] - Loss: 1.2306
Epoch [30/50] - Loss: 1.2260
Epoch [31/50] - Loss: 1.2089
Epoch [32/50] - Loss: 1.2034
Epoch [33/50] - Loss: 1.1939
Epoch [34/50] - Loss: 1.1919
Epoch [35/50] - Loss: 1.1821
Epoch [36/50] - Loss: 1.1715
Epoch [37/50] - Loss: 1.1630
Epoch [38/50] - Loss: 1.1605
Epoch [39/50] - Loss: 1.1550
Epoch [40/50] - Loss: 1.1565
Epoch [41/50] - Loss: 1.1553
Epoch [42/50] - Loss: 1.1506
Epoch [43/50] - Loss: 1.1497
Epoch [44/50] - Loss: 1.1376
Epoch [45/50] - Loss: 1.1294
Epoch [46/50] - Loss: 1.1311
Epoch [47/50] - Loss: 1.1279
Epoch [48/50] - Loss: 1.1346
Epoch [49/50] - Loss: 1.1299
Epoch [50/50] - Loss: 1.1212
sum preds 5312
sum labels 5513
 - Test Metrics: Accuracy=0.8764, F1=0.8018, Recall=0.7872, Precision=0.8170
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8445
Epoch [2/50] - Loss: 3.2567
Epoch [3/50] - Loss: 2.9054
Epoch [4/50] - Loss: 2.7303
Epoch [5/50] - Loss: 2.5704
Epoch [6/50] - Loss: 2.3976
Epoch [7/50] - Loss: 2.2560
Epoch [8/50] - Loss: 2.1166
Epoch [9/50] - Loss: 1.9838
Epoch [10/50] - Loss: 1.8689
Epoch [11/50] - Loss: 1.7620
Epoch [12/50] - Loss: 1.6733
Epoch [13/50] - Loss: 1.5851
Epoch [14/50] - Loss: 1.5198
Epoch [15/50] - Loss: 1.4727
Epoch [16/50] - Loss: 1.4227
Epoch [17/50] - Loss: 1.3893
Epoch [18/50] - Loss: 1.3665
Epoch [19/50] - Loss: 1.3586
Epoch [20/50] - Loss: 1.3348
Epoch [21/50] - Loss: 1.3078
Epoch [22/50] - Loss: 1.3038
Epoch [23/50] - Loss: 1.2836
Epoch [24/50] - Loss: 1.2598
Epoch [25/50] - Loss: 1.2635
Epoch [26/50] - Loss: 1.2459
Epoch [27/50] - Loss: 1.2358
Epoch [28/50] - Loss: 1.2382
Epoch [29/50] - Loss: 1.2185
Epoch [30/50] - Loss: 1.2170
Epoch [31/50] - Loss: 1.2098
Epoch [32/50] - Loss: 1.2073
Epoch [33/50] - Loss: 1.2013
Epoch [34/50] - Loss: 1.2006
Epoch [35/50] - Loss: 1.1850
Epoch [36/50] - Loss: 1.1876
Epoch [37/50] - Loss: 1.1827
Epoch [38/50] - Loss: 1.1787
Epoch [39/50] - Loss: 1.1699
Epoch [40/50] - Loss: 1.1690
Epoch [41/50] - Loss: 1.1621
Epoch [42/50] - Loss: 1.1589
Epoch [43/50] - Loss: 1.1601
Epoch [44/50] - Loss: 1.1461
Epoch [45/50] - Loss: 1.1391
Epoch [46/50] - Loss: 1.1529
Epoch [47/50] - Loss: 1.1386
Epoch [48/50] - Loss: 1.1479
Epoch [49/50] - Loss: 1.1292
Epoch [50/50] - Loss: 1.1354
sum preds 5346
sum labels 5513
 - Test Metrics: Accuracy=0.8738, F1=0.7982, Recall=0.7861, Precision=0.8107
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9103
Epoch [2/50] - Loss: 3.3474
Epoch [3/50] - Loss: 2.9745
Epoch [4/50] - Loss: 2.7687
Epoch [5/50] - Loss: 2.6287
Epoch [6/50] - Loss: 2.4853
Epoch [7/50] - Loss: 2.3243
Epoch [8/50] - Loss: 2.1920
Epoch [9/50] - Loss: 2.0537
Epoch [10/50] - Loss: 1.9265
Epoch [11/50] - Loss: 1.8071
Epoch [12/50] - Loss: 1.6855
Epoch [13/50] - Loss: 1.6014
Epoch [14/50] - Loss: 1.5096
Epoch [15/50] - Loss: 1.4590
Epoch [16/50] - Loss: 1.4020
Epoch [17/50] - Loss: 1.3621
Epoch [18/50] - Loss: 1.3286
Epoch [19/50] - Loss: 1.3075
Epoch [20/50] - Loss: 1.2834
Epoch [21/50] - Loss: 1.2681
Epoch [22/50] - Loss: 1.2529
Epoch [23/50] - Loss: 1.2258
Epoch [24/50] - Loss: 1.2164
Epoch [25/50] - Loss: 1.2133
Epoch [26/50] - Loss: 1.2010
Epoch [27/50] - Loss: 1.1826
Epoch [28/50] - Loss: 1.1788
Epoch [29/50] - Loss: 1.1801
Epoch [30/50] - Loss: 1.1628
Epoch [31/50] - Loss: 1.1624
Epoch [32/50] - Loss: 1.1576
Epoch [33/50] - Loss: 1.1430
Epoch [34/50] - Loss: 1.1300
Epoch [35/50] - Loss: 1.1284
Epoch [36/50] - Loss: 1.1248
Epoch [37/50] - Loss: 1.1275
Epoch [38/50] - Loss: 1.1313
Epoch [39/50] - Loss: 1.1129
Epoch [40/50] - Loss: 1.1097
Epoch [41/50] - Loss: 1.1114
Epoch [42/50] - Loss: 1.1074
Epoch [43/50] - Loss: 1.0995
Epoch [44/50] - Loss: 1.1072
Epoch [45/50] - Loss: 1.0998
Epoch [46/50] - Loss: 1.0884
Epoch [47/50] - Loss: 1.0954
Epoch [48/50] - Loss: 1.0802
Epoch [49/50] - Loss: 1.0909
Epoch [50/50] - Loss: 1.0796
sum preds 5177
sum labels 5513
 - Test Metrics: Accuracy=0.8763, F1=0.7993, Recall=0.7749, Precision=0.8252
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_spy_spy_1904031402.csv.
Average F1 over valid seeds: 0.7998 ± 0.0015
___________________________________________________________________________________
Avg F1 for pubmed with SAR and spy, GCNConv,0.3: 0.7998 ± 0.0015
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.9126
Epoch [2/50] - Loss: 2.6894
Epoch [3/50] - Loss: 2.4203
Epoch [4/50] - Loss: 2.1673
Epoch [5/50] - Loss: 1.9745
Epoch [6/50] - Loss: 1.8593
Epoch [7/50] - Loss: 1.7587
Epoch [8/50] - Loss: 1.6440
Epoch [9/50] - Loss: 1.5260
Epoch [10/50] - Loss: 1.4181
Epoch [11/50] - Loss: 1.3368
Epoch [12/50] - Loss: 1.2399
Epoch [13/50] - Loss: 1.1649
Epoch [14/50] - Loss: 1.0832
Epoch [15/50] - Loss: 1.0208
Epoch [16/50] - Loss: 0.9645
Epoch [17/50] - Loss: 0.9166
Epoch [18/50] - Loss: 0.8735
Epoch [19/50] - Loss: 0.8353
Epoch [20/50] - Loss: 0.8124
Epoch [21/50] - Loss: 0.7804
Epoch [22/50] - Loss: 0.7560
Epoch [23/50] - Loss: 0.7365
Epoch [24/50] - Loss: 0.7145
Epoch [25/50] - Loss: 0.7008
Epoch [26/50] - Loss: 0.6846
Epoch [27/50] - Loss: 0.6700
Epoch [28/50] - Loss: 0.6550
Epoch [29/50] - Loss: 0.6431
Epoch [30/50] - Loss: 0.6283
Epoch [31/50] - Loss: 0.6214
Epoch [32/50] - Loss: 0.6104
Epoch [33/50] - Loss: 0.6003
Epoch [34/50] - Loss: 0.5903
Epoch [35/50] - Loss: 0.5829
Epoch [36/50] - Loss: 0.5768
Epoch [37/50] - Loss: 0.5731
Epoch [38/50] - Loss: 0.5604
Epoch [39/50] - Loss: 0.5623
Epoch [40/50] - Loss: 0.5491
Epoch [41/50] - Loss: 0.5506
Epoch [42/50] - Loss: 0.5427
Epoch [43/50] - Loss: 0.5388
Epoch [44/50] - Loss: 0.5382
Epoch [45/50] - Loss: 0.5282
Epoch [46/50] - Loss: 0.5223
Epoch [47/50] - Loss: 0.5191
Epoch [48/50] - Loss: 0.5156
Epoch [49/50] - Loss: 0.5157
Epoch [50/50] - Loss: 0.5083
sum preds 6471
sum labels 6300
 - Test Metrics: Accuracy=0.8330, F1=0.7628, Recall=0.7732, Precision=0.7527
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.5655
Epoch [2/50] - Loss: 3.2651
Epoch [3/50] - Loss: 2.9173
Epoch [4/50] - Loss: 2.5734
Epoch [5/50] - Loss: 2.2745
Epoch [6/50] - Loss: 2.0641
Epoch [7/50] - Loss: 1.9342
Epoch [8/50] - Loss: 1.8525
Epoch [9/50] - Loss: 1.7901
Epoch [10/50] - Loss: 1.7085
Epoch [11/50] - Loss: 1.5894
Epoch [12/50] - Loss: 1.4942
Epoch [13/50] - Loss: 1.3943
Epoch [14/50] - Loss: 1.2997
Epoch [15/50] - Loss: 1.1971
Epoch [16/50] - Loss: 1.1129
Epoch [17/50] - Loss: 1.0315
Epoch [18/50] - Loss: 0.9660
Epoch [19/50] - Loss: 0.9050
Epoch [20/50] - Loss: 0.8592
Epoch [21/50] - Loss: 0.8135
Epoch [22/50] - Loss: 0.7793
Epoch [23/50] - Loss: 0.7466
Epoch [24/50] - Loss: 0.7130
Epoch [25/50] - Loss: 0.6936
Epoch [26/50] - Loss: 0.6734
Epoch [27/50] - Loss: 0.6544
Epoch [28/50] - Loss: 0.6348
Epoch [29/50] - Loss: 0.6260
Epoch [30/50] - Loss: 0.6101
Epoch [31/50] - Loss: 0.5984
Epoch [32/50] - Loss: 0.5852
Epoch [33/50] - Loss: 0.5718
Epoch [34/50] - Loss: 0.5584
Epoch [35/50] - Loss: 0.5549
Epoch [36/50] - Loss: 0.5441
Epoch [37/50] - Loss: 0.5327
Epoch [38/50] - Loss: 0.5299
Epoch [39/50] - Loss: 0.5230
Epoch [40/50] - Loss: 0.5137
Epoch [41/50] - Loss: 0.5150
Epoch [42/50] - Loss: 0.5042
Epoch [43/50] - Loss: 0.5001
Epoch [44/50] - Loss: 0.4974
Epoch [45/50] - Loss: 0.4880
Epoch [46/50] - Loss: 0.4936
Epoch [47/50] - Loss: 0.4837
Epoch [48/50] - Loss: 0.4772
Epoch [49/50] - Loss: 0.4730
Epoch [50/50] - Loss: 0.4753
sum preds 6238
sum labels 6300
 - Test Metrics: Accuracy=0.8360, F1=0.7626, Recall=0.7589, Precision=0.7664
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.7458
Epoch [2/50] - Loss: 2.4671
Epoch [3/50] - Loss: 2.1890
Epoch [4/50] - Loss: 1.9874
Epoch [5/50] - Loss: 1.8633
Epoch [6/50] - Loss: 1.7681
Epoch [7/50] - Loss: 1.6613
Epoch [8/50] - Loss: 1.5481
Epoch [9/50] - Loss: 1.4279
Epoch [10/50] - Loss: 1.3249
Epoch [11/50] - Loss: 1.2276
Epoch [12/50] - Loss: 1.1325
Epoch [13/50] - Loss: 1.0484
Epoch [14/50] - Loss: 0.9813
Epoch [15/50] - Loss: 0.9201
Epoch [16/50] - Loss: 0.8648
Epoch [17/50] - Loss: 0.8207
Epoch [18/50] - Loss: 0.7854
Epoch [19/50] - Loss: 0.7484
Epoch [20/50] - Loss: 0.7225
Epoch [21/50] - Loss: 0.6949
Epoch [22/50] - Loss: 0.6811
Epoch [23/50] - Loss: 0.6622
Epoch [24/50] - Loss: 0.6409
Epoch [25/50] - Loss: 0.6263
Epoch [26/50] - Loss: 0.6143
Epoch [27/50] - Loss: 0.6020
Epoch [28/50] - Loss: 0.5884
Epoch [29/50] - Loss: 0.5801
Epoch [30/50] - Loss: 0.5693
Epoch [31/50] - Loss: 0.5594
Epoch [32/50] - Loss: 0.5505
Epoch [33/50] - Loss: 0.5476
Epoch [34/50] - Loss: 0.5382
Epoch [35/50] - Loss: 0.5314
Epoch [36/50] - Loss: 0.5230
Epoch [37/50] - Loss: 0.5158
Epoch [38/50] - Loss: 0.5117
Epoch [39/50] - Loss: 0.5068
Epoch [40/50] - Loss: 0.5024
Epoch [41/50] - Loss: 0.4998
Epoch [42/50] - Loss: 0.5007
Epoch [43/50] - Loss: 0.4879
Epoch [44/50] - Loss: 0.4867
Epoch [45/50] - Loss: 0.4831
Epoch [46/50] - Loss: 0.4787
Epoch [47/50] - Loss: 0.4715
Epoch [48/50] - Loss: 0.4737
Epoch [49/50] - Loss: 0.4743
Epoch [50/50] - Loss: 0.4674
sum preds 6312
sum labels 6300
 - Test Metrics: Accuracy=0.8351, F1=0.7628, Recall=0.7635, Precision=0.7620
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_spy_spy_1904032512.csv.
Average F1 over valid seeds: 0.7627 ± 0.0001
___________________________________________________________________________________
Avg F1 for pubmed with SAR and spy, MLP,0.2: 0.7627 ± 0.0001
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.2039
Epoch [2/50] - Loss: 2.6252
Epoch [3/50] - Loss: 2.2079
Epoch [4/50] - Loss: 1.9846
Epoch [5/50] - Loss: 1.8908
Epoch [6/50] - Loss: 1.8035
Epoch [7/50] - Loss: 1.6966
Epoch [8/50] - Loss: 1.5919
Epoch [9/50] - Loss: 1.5018
Epoch [10/50] - Loss: 1.4251
Epoch [11/50] - Loss: 1.3500
Epoch [12/50] - Loss: 1.2938
Epoch [13/50] - Loss: 1.2449
Epoch [14/50] - Loss: 1.2013
Epoch [15/50] - Loss: 1.1619
Epoch [16/50] - Loss: 1.1158
Epoch [17/50] - Loss: 1.0894
Epoch [18/50] - Loss: 1.0674
Epoch [19/50] - Loss: 1.0466
Epoch [20/50] - Loss: 1.0265
Epoch [21/50] - Loss: 1.0118
Epoch [22/50] - Loss: 1.0037
Epoch [23/50] - Loss: 0.9838
Epoch [24/50] - Loss: 0.9669
Epoch [25/50] - Loss: 0.9591
Epoch [26/50] - Loss: 0.9521
Epoch [27/50] - Loss: 0.9383
Epoch [28/50] - Loss: 0.9270
Epoch [29/50] - Loss: 0.9277
Epoch [30/50] - Loss: 0.9144
Epoch [31/50] - Loss: 0.8959
Epoch [32/50] - Loss: 0.8978
Epoch [33/50] - Loss: 0.8813
Epoch [34/50] - Loss: 0.8765
Epoch [35/50] - Loss: 0.8628
Epoch [36/50] - Loss: 0.8553
Epoch [37/50] - Loss: 0.8522
Epoch [38/50] - Loss: 0.8487
Epoch [39/50] - Loss: 0.8307
Epoch [40/50] - Loss: 0.8220
Epoch [41/50] - Loss: 0.8141
Epoch [42/50] - Loss: 0.8030
Epoch [43/50] - Loss: 0.7980
Epoch [44/50] - Loss: 0.7815
Epoch [45/50] - Loss: 0.7818
Epoch [46/50] - Loss: 0.7770
Epoch [47/50] - Loss: 0.7699
Epoch [48/50] - Loss: 0.7578
Epoch [49/50] - Loss: 0.7538
Epoch [50/50] - Loss: 0.7379
sum preds 5481
sum labels 6300
 - Test Metrics: Accuracy=0.8656, F1=0.7930, Recall=0.7414, Precision=0.8522
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.2457
Epoch [2/50] - Loss: 2.6980
Epoch [3/50] - Loss: 2.2593
Epoch [4/50] - Loss: 2.0145
Epoch [5/50] - Loss: 1.8903
Epoch [6/50] - Loss: 1.8302
Epoch [7/50] - Loss: 1.7571
Epoch [8/50] - Loss: 1.6581
Epoch [9/50] - Loss: 1.5780
Epoch [10/50] - Loss: 1.5093
Epoch [11/50] - Loss: 1.4409
Epoch [12/50] - Loss: 1.3888
Epoch [13/50] - Loss: 1.3283
Epoch [14/50] - Loss: 1.2809
Epoch [15/50] - Loss: 1.2379
Epoch [16/50] - Loss: 1.1940
Epoch [17/50] - Loss: 1.1678
Epoch [18/50] - Loss: 1.1354
Epoch [19/50] - Loss: 1.1108
Epoch [20/50] - Loss: 1.0887
Epoch [21/50] - Loss: 1.0724
Epoch [22/50] - Loss: 1.0536
Epoch [23/50] - Loss: 1.0426
Epoch [24/50] - Loss: 1.0233
Epoch [25/50] - Loss: 1.0101
Epoch [26/50] - Loss: 1.0106
Epoch [27/50] - Loss: 1.0013
Epoch [28/50] - Loss: 0.9950
Epoch [29/50] - Loss: 0.9812
Epoch [30/50] - Loss: 0.9662
Epoch [31/50] - Loss: 0.9695
Epoch [32/50] - Loss: 0.9673
Epoch [33/50] - Loss: 0.9478
Epoch [34/50] - Loss: 0.9390
Epoch [35/50] - Loss: 0.9312
Epoch [36/50] - Loss: 0.9241
Epoch [37/50] - Loss: 0.9208
Epoch [38/50] - Loss: 0.9216
Epoch [39/50] - Loss: 0.9021
Epoch [40/50] - Loss: 0.8987
Epoch [41/50] - Loss: 0.8925
Epoch [42/50] - Loss: 0.8870
Epoch [43/50] - Loss: 0.8784
Epoch [44/50] - Loss: 0.8714
Epoch [45/50] - Loss: 0.8637
Epoch [46/50] - Loss: 0.8491
Epoch [47/50] - Loss: 0.8549
Epoch [48/50] - Loss: 0.8432
Epoch [49/50] - Loss: 0.8370
Epoch [50/50] - Loss: 0.8337
sum preds 5144
sum labels 6300
 - Test Metrics: Accuracy=0.8679, F1=0.7906, Recall=0.7181, Precision=0.8795
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8122
Epoch [2/50] - Loss: 3.0832
Epoch [3/50] - Loss: 2.4878
Epoch [4/50] - Loss: 2.1981
Epoch [5/50] - Loss: 2.0671
Epoch [6/50] - Loss: 1.9509
Epoch [7/50] - Loss: 1.7917
Epoch [8/50] - Loss: 1.6968
Epoch [9/50] - Loss: 1.5862
Epoch [10/50] - Loss: 1.5082
Epoch [11/50] - Loss: 1.4324
Epoch [12/50] - Loss: 1.3687
Epoch [13/50] - Loss: 1.3191
Epoch [14/50] - Loss: 1.2855
Epoch [15/50] - Loss: 1.2381
Epoch [16/50] - Loss: 1.2057
Epoch [17/50] - Loss: 1.1745
Epoch [18/50] - Loss: 1.1557
Epoch [19/50] - Loss: 1.1440
Epoch [20/50] - Loss: 1.1390
Epoch [21/50] - Loss: 1.1202
Epoch [22/50] - Loss: 1.1109
Epoch [23/50] - Loss: 1.0848
Epoch [24/50] - Loss: 1.0869
Epoch [25/50] - Loss: 1.0645
Epoch [26/50] - Loss: 1.0750
Epoch [27/50] - Loss: 1.0504
Epoch [28/50] - Loss: 1.0523
Epoch [29/50] - Loss: 1.0315
Epoch [30/50] - Loss: 1.0194
Epoch [31/50] - Loss: 1.0166
Epoch [32/50] - Loss: 1.0176
Epoch [33/50] - Loss: 1.0059
Epoch [34/50] - Loss: 1.0034
Epoch [35/50] - Loss: 0.9958
Epoch [36/50] - Loss: 0.9876
Epoch [37/50] - Loss: 0.9759
Epoch [38/50] - Loss: 0.9697
Epoch [39/50] - Loss: 0.9765
Epoch [40/50] - Loss: 0.9608
Epoch [41/50] - Loss: 0.9446
Epoch [42/50] - Loss: 0.9539
Epoch [43/50] - Loss: 0.9517
Epoch [44/50] - Loss: 0.9455
Epoch [45/50] - Loss: 0.9286
Epoch [46/50] - Loss: 0.9351
Epoch [47/50] - Loss: 0.9161
Epoch [48/50] - Loss: 0.9037
Epoch [49/50] - Loss: 0.9111
Epoch [50/50] - Loss: 0.9145
sum preds 5037
sum labels 6300
 - Test Metrics: Accuracy=0.8613, F1=0.7780, Recall=0.7000, Precision=0.8755
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_spy_spy_1904033425.csv.
Average F1 over valid seeds: 0.7872 ± 0.0066
___________________________________________________________________________________
Avg F1 for pubmed with SAR and spy, GATConv,0.2: 0.7872 ± 0.0066
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.3198
Epoch [2/50] - Loss: 2.9557
Epoch [3/50] - Loss: 2.6184
Epoch [4/50] - Loss: 2.3452
Epoch [5/50] - Loss: 2.1464
Epoch [6/50] - Loss: 2.0247
Epoch [7/50] - Loss: 1.9306
Epoch [8/50] - Loss: 1.8425
Epoch [9/50] - Loss: 1.7596
Epoch [10/50] - Loss: 1.6632
Epoch [11/50] - Loss: 1.5819
Epoch [12/50] - Loss: 1.5144
Epoch [13/50] - Loss: 1.4294
Epoch [14/50] - Loss: 1.3696
Epoch [15/50] - Loss: 1.3178
Epoch [16/50] - Loss: 1.2704
Epoch [17/50] - Loss: 1.2291
Epoch [18/50] - Loss: 1.1936
Epoch [19/50] - Loss: 1.1467
Epoch [20/50] - Loss: 1.1169
Epoch [21/50] - Loss: 1.0964
Epoch [22/50] - Loss: 1.0657
Epoch [23/50] - Loss: 1.0439
Epoch [24/50] - Loss: 1.0253
Epoch [25/50] - Loss: 1.0110
Epoch [26/50] - Loss: 0.9961
Epoch [27/50] - Loss: 0.9843
Epoch [28/50] - Loss: 0.9724
Epoch [29/50] - Loss: 0.9642
Epoch [30/50] - Loss: 0.9518
Epoch [31/50] - Loss: 0.9396
Epoch [32/50] - Loss: 0.9354
Epoch [33/50] - Loss: 0.9315
Epoch [34/50] - Loss: 0.9220
Epoch [35/50] - Loss: 0.9163
Epoch [36/50] - Loss: 0.9040
Epoch [37/50] - Loss: 0.9006
Epoch [38/50] - Loss: 0.9005
Epoch [39/50] - Loss: 0.8878
Epoch [40/50] - Loss: 0.8811
Epoch [41/50] - Loss: 0.8710
Epoch [42/50] - Loss: 0.8703
Epoch [43/50] - Loss: 0.8660
Epoch [44/50] - Loss: 0.8605
Epoch [45/50] - Loss: 0.8619
Epoch [46/50] - Loss: 0.8533
Epoch [47/50] - Loss: 0.8524
Epoch [48/50] - Loss: 0.8427
Epoch [49/50] - Loss: 0.8429
Epoch [50/50] - Loss: 0.8367
sum preds 5563
sum labels 6300
 - Test Metrics: Accuracy=0.8678, F1=0.7978, Recall=0.7511, Precision=0.8506
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.9166
Epoch [2/50] - Loss: 3.3472
Epoch [3/50] - Loss: 2.8357
Epoch [4/50] - Loss: 2.4587
Epoch [5/50] - Loss: 2.2253
Epoch [6/50] - Loss: 2.1188
Epoch [7/50] - Loss: 2.0589
Epoch [8/50] - Loss: 1.9988
Epoch [9/50] - Loss: 1.9244
Epoch [10/50] - Loss: 1.8525
Epoch [11/50] - Loss: 1.7804
Epoch [12/50] - Loss: 1.7251
Epoch [13/50] - Loss: 1.6643
Epoch [14/50] - Loss: 1.5979
Epoch [15/50] - Loss: 1.5361
Epoch [16/50] - Loss: 1.4655
Epoch [17/50] - Loss: 1.4082
Epoch [18/50] - Loss: 1.3477
Epoch [19/50] - Loss: 1.3015
Epoch [20/50] - Loss: 1.2639
Epoch [21/50] - Loss: 1.2233
Epoch [22/50] - Loss: 1.1993
Epoch [23/50] - Loss: 1.1655
Epoch [24/50] - Loss: 1.1450
Epoch [25/50] - Loss: 1.1313
Epoch [26/50] - Loss: 1.1219
Epoch [27/50] - Loss: 1.1055
Epoch [28/50] - Loss: 1.0972
Epoch [29/50] - Loss: 1.0864
Epoch [30/50] - Loss: 1.0834
Epoch [31/50] - Loss: 1.0703
Epoch [32/50] - Loss: 1.0606
Epoch [33/50] - Loss: 1.0595
Epoch [34/50] - Loss: 1.0457
Epoch [35/50] - Loss: 1.0409
Epoch [36/50] - Loss: 1.0413
Epoch [37/50] - Loss: 1.0383
Epoch [38/50] - Loss: 1.0282
Epoch [39/50] - Loss: 1.0214
Epoch [40/50] - Loss: 1.0114
Epoch [41/50] - Loss: 1.0115
Epoch [42/50] - Loss: 1.0094
Epoch [43/50] - Loss: 0.9992
Epoch [44/50] - Loss: 1.0028
Epoch [45/50] - Loss: 1.0008
Epoch [46/50] - Loss: 0.9981
Epoch [47/50] - Loss: 0.9905
Epoch [48/50] - Loss: 0.9886
Epoch [49/50] - Loss: 0.9888
Epoch [50/50] - Loss: 0.9814
sum preds 4572
sum labels 6300
 - Test Metrics: Accuracy=0.8535, F1=0.7555, Recall=0.6519, Precision=0.8983
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.8760
Epoch [2/50] - Loss: 3.2182
Epoch [3/50] - Loss: 2.6571
Epoch [4/50] - Loss: 2.3756
Epoch [5/50] - Loss: 2.2218
Epoch [6/50] - Loss: 2.1481
Epoch [7/50] - Loss: 2.0995
Epoch [8/50] - Loss: 1.9915
Epoch [9/50] - Loss: 1.9071
Epoch [10/50] - Loss: 1.8506
Epoch [11/50] - Loss: 1.7991
Epoch [12/50] - Loss: 1.7015
Epoch [13/50] - Loss: 1.6245
Epoch [14/50] - Loss: 1.5485
Epoch [15/50] - Loss: 1.4799
Epoch [16/50] - Loss: 1.3904
Epoch [17/50] - Loss: 1.3420
Epoch [18/50] - Loss: 1.2962
Epoch [19/50] - Loss: 1.2441
Epoch [20/50] - Loss: 1.2303
Epoch [21/50] - Loss: 1.2063
Epoch [22/50] - Loss: 1.1544
Epoch [23/50] - Loss: 1.1596
Epoch [24/50] - Loss: 1.1317
Epoch [25/50] - Loss: 1.1135
Epoch [26/50] - Loss: 1.1059
Epoch [27/50] - Loss: 1.1170
Epoch [28/50] - Loss: 1.0888
Epoch [29/50] - Loss: 1.0890
Epoch [30/50] - Loss: 1.0688
Epoch [31/50] - Loss: 1.0864
Epoch [32/50] - Loss: 1.0798
Epoch [33/50] - Loss: 1.0557
Epoch [34/50] - Loss: 1.0620
Epoch [35/50] - Loss: 1.0567
Epoch [36/50] - Loss: 1.0423
Epoch [37/50] - Loss: 1.0480
Epoch [38/50] - Loss: 1.0270
Epoch [39/50] - Loss: 1.0294
Epoch [40/50] - Loss: 1.0365
Epoch [41/50] - Loss: 1.0249
Epoch [42/50] - Loss: 1.0191
Epoch [43/50] - Loss: 1.0330
Epoch [44/50] - Loss: 1.0145
Epoch [45/50] - Loss: 1.0110
Epoch [46/50] - Loss: 1.0081
Epoch [47/50] - Loss: 1.0131
Epoch [48/50] - Loss: 1.0088
Epoch [49/50] - Loss: 0.9872
Epoch [50/50] - Loss: 1.0094
sum preds 4851
sum labels 6300
 - Test Metrics: Accuracy=0.8619, F1=0.7754, Recall=0.6862, Precision=0.8912
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_spy_spy_1904034429.csv.
Average F1 over valid seeds: 0.7762 ± 0.0173
___________________________________________________________________________________
Avg F1 for pubmed with SAR and spy, GCNConv,0.2: 0.7762 ± 0.0173
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4966
Epoch [2/50] - Loss: 0.4955
Epoch [3/50] - Loss: 0.4944
Epoch [4/50] - Loss: 0.4934
Epoch [5/50] - Loss: 0.4923
Epoch [6/50] - Loss: 0.4910
Epoch [7/50] - Loss: 0.4895
Epoch [8/50] - Loss: 0.4879
Epoch [9/50] - Loss: 0.4861
Epoch [10/50] - Loss: 0.4842
Epoch [11/50] - Loss: 0.4822
Epoch [12/50] - Loss: 0.4801
Epoch [13/50] - Loss: 0.4778
Epoch [14/50] - Loss: 0.4754
Epoch [15/50] - Loss: 0.4728
Epoch [16/50] - Loss: 0.4701
Epoch [17/50] - Loss: 0.4672
Epoch [18/50] - Loss: 0.4642
Epoch [19/50] - Loss: 0.4610
Epoch [20/50] - Loss: 0.4577
Epoch [21/50] - Loss: 0.4542
Epoch [22/50] - Loss: 0.4505
Epoch [23/50] - Loss: 0.4467
Epoch [24/50] - Loss: 0.4427
Epoch [25/50] - Loss: 0.4386
Epoch [26/50] - Loss: 0.4342
Epoch [27/50] - Loss: 0.4298
Epoch [28/50] - Loss: 0.4251
Epoch [29/50] - Loss: 0.4203
Epoch [30/50] - Loss: 0.4154
Epoch [31/50] - Loss: 0.4103
Epoch [32/50] - Loss: 0.4050
Epoch [33/50] - Loss: 0.3997
Epoch [34/50] - Loss: 0.3942
Epoch [35/50] - Loss: 0.3885
Epoch [36/50] - Loss: 0.3828
Epoch [37/50] - Loss: 0.3769
Epoch [38/50] - Loss: 0.3710
Epoch [39/50] - Loss: 0.3650
Epoch [40/50] - Loss: 0.3589
Epoch [41/50] - Loss: 0.3528
Epoch [42/50] - Loss: 0.3466
Epoch [43/50] - Loss: 0.3404
Epoch [44/50] - Loss: 0.3342
Epoch [45/50] - Loss: 0.3279
Epoch [46/50] - Loss: 0.3217
Epoch [47/50] - Loss: 0.3155
Epoch [48/50] - Loss: 0.3094
Epoch [49/50] - Loss: 0.3033
Epoch [50/50] - Loss: 0.2973
sum preds 3179
sum labels 4725
 - Test Metrics: Accuracy=0.8118, F1=0.6055, Recall=0.5065, Precision=0.7528
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5091
Epoch [2/50] - Loss: 0.5074
Epoch [3/50] - Loss: 0.5058
Epoch [4/50] - Loss: 0.5042
Epoch [5/50] - Loss: 0.5028
Epoch [6/50] - Loss: 0.5011
Epoch [7/50] - Loss: 0.4993
Epoch [8/50] - Loss: 0.4973
Epoch [9/50] - Loss: 0.4951
Epoch [10/50] - Loss: 0.4927
Epoch [11/50] - Loss: 0.4901
Epoch [12/50] - Loss: 0.4874
Epoch [13/50] - Loss: 0.4845
Epoch [14/50] - Loss: 0.4815
Epoch [15/50] - Loss: 0.4782
Epoch [16/50] - Loss: 0.4748
Epoch [17/50] - Loss: 0.4712
Epoch [18/50] - Loss: 0.4675
Epoch [19/50] - Loss: 0.4635
Epoch [20/50] - Loss: 0.4594
Epoch [21/50] - Loss: 0.4550
Epoch [22/50] - Loss: 0.4505
Epoch [23/50] - Loss: 0.4459
Epoch [24/50] - Loss: 0.4410
Epoch [25/50] - Loss: 0.4360
Epoch [26/50] - Loss: 0.4308
Epoch [27/50] - Loss: 0.4255
Epoch [28/50] - Loss: 0.4200
Epoch [29/50] - Loss: 0.4144
Epoch [30/50] - Loss: 0.4087
Epoch [31/50] - Loss: 0.4029
Epoch [32/50] - Loss: 0.3970
Epoch [33/50] - Loss: 0.3910
Epoch [34/50] - Loss: 0.3850
Epoch [35/50] - Loss: 0.3789
Epoch [36/50] - Loss: 0.3728
Epoch [37/50] - Loss: 0.3668
Epoch [38/50] - Loss: 0.3607
Epoch [39/50] - Loss: 0.3546
Epoch [40/50] - Loss: 0.3486
Epoch [41/50] - Loss: 0.3426
Epoch [42/50] - Loss: 0.3366
Epoch [43/50] - Loss: 0.3307
Epoch [44/50] - Loss: 0.3249
Epoch [45/50] - Loss: 0.3191
Epoch [46/50] - Loss: 0.3134
Epoch [47/50] - Loss: 0.3077
Epoch [48/50] - Loss: 0.3021
Epoch [49/50] - Loss: 0.2966
Epoch [50/50] - Loss: 0.2911
sum preds 2333
sum labels 4725
 - Test Metrics: Accuracy=0.7932, F1=0.5146, Recall=0.3843, Precision=0.7784
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4899
Epoch [2/50] - Loss: 0.4881
Epoch [3/50] - Loss: 0.4864
Epoch [4/50] - Loss: 0.4846
Epoch [5/50] - Loss: 0.4827
Epoch [6/50] - Loss: 0.4808
Epoch [7/50] - Loss: 0.4786
Epoch [8/50] - Loss: 0.4761
Epoch [9/50] - Loss: 0.4735
Epoch [10/50] - Loss: 0.4706
Epoch [11/50] - Loss: 0.4675
Epoch [12/50] - Loss: 0.4643
Epoch [13/50] - Loss: 0.4610
Epoch [14/50] - Loss: 0.4575
Epoch [15/50] - Loss: 0.4539
Epoch [16/50] - Loss: 0.4502
Epoch [17/50] - Loss: 0.4463
Epoch [18/50] - Loss: 0.4423
Epoch [19/50] - Loss: 0.4381
Epoch [20/50] - Loss: 0.4338
Epoch [21/50] - Loss: 0.4294
Epoch [22/50] - Loss: 0.4248
Epoch [23/50] - Loss: 0.4202
Epoch [24/50] - Loss: 0.4154
Epoch [25/50] - Loss: 0.4106
Epoch [26/50] - Loss: 0.4057
Epoch [27/50] - Loss: 0.4007
Epoch [28/50] - Loss: 0.3956
Epoch [29/50] - Loss: 0.3905
Epoch [30/50] - Loss: 0.3853
Epoch [31/50] - Loss: 0.3801
Epoch [32/50] - Loss: 0.3748
Epoch [33/50] - Loss: 0.3695
Epoch [34/50] - Loss: 0.3641
Epoch [35/50] - Loss: 0.3587
Epoch [36/50] - Loss: 0.3533
Epoch [37/50] - Loss: 0.3479
Epoch [38/50] - Loss: 0.3424
Epoch [39/50] - Loss: 0.3369
Epoch [40/50] - Loss: 0.3314
Epoch [41/50] - Loss: 0.3259
Epoch [42/50] - Loss: 0.3203
Epoch [43/50] - Loss: 0.3148
Epoch [44/50] - Loss: 0.3092
Epoch [45/50] - Loss: 0.3037
Epoch [46/50] - Loss: 0.2982
Epoch [47/50] - Loss: 0.2927
Epoch [48/50] - Loss: 0.2872
Epoch [49/50] - Loss: 0.2818
Epoch [50/50] - Loss: 0.2765
sum preds 2632
sum labels 4725
 - Test Metrics: Accuracy=0.8010, F1=0.5519, Recall=0.4296, Precision=0.7713
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_nnpu_nnpu_1904035501.csv.
Average F1 over valid seeds: 0.5573 ± 0.0373
___________________________________________________________________________________
Avg F1 for pubmed with SAR and nnpu, MLP,0.4: 0.5573 ± 0.0373
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4983
Epoch [3/50] - Loss: 0.4964
Epoch [4/50] - Loss: 0.4942
Epoch [5/50] - Loss: 0.4917
Epoch [6/50] - Loss: 0.4889
Epoch [7/50] - Loss: 0.4859
Epoch [8/50] - Loss: 0.4827
Epoch [9/50] - Loss: 0.4795
Epoch [10/50] - Loss: 0.4760
Epoch [11/50] - Loss: 0.4724
Epoch [12/50] - Loss: 0.4685
Epoch [13/50] - Loss: 0.4644
Epoch [14/50] - Loss: 0.4604
Epoch [15/50] - Loss: 0.4563
Epoch [16/50] - Loss: 0.4521
Epoch [17/50] - Loss: 0.4477
Epoch [18/50] - Loss: 0.4432
Epoch [19/50] - Loss: 0.4386
Epoch [20/50] - Loss: 0.4338
Epoch [21/50] - Loss: 0.4289
Epoch [22/50] - Loss: 0.4239
Epoch [23/50] - Loss: 0.4188
Epoch [24/50] - Loss: 0.4137
Epoch [25/50] - Loss: 0.4084
Epoch [26/50] - Loss: 0.4031
Epoch [27/50] - Loss: 0.3977
Epoch [28/50] - Loss: 0.3921
Epoch [29/50] - Loss: 0.3865
Epoch [30/50] - Loss: 0.3808
Epoch [31/50] - Loss: 0.3751
Epoch [32/50] - Loss: 0.3693
Epoch [33/50] - Loss: 0.3636
Epoch [34/50] - Loss: 0.3577
Epoch [35/50] - Loss: 0.3518
Epoch [36/50] - Loss: 0.3459
Epoch [37/50] - Loss: 0.3400
Epoch [38/50] - Loss: 0.3340
Epoch [39/50] - Loss: 0.3281
Epoch [40/50] - Loss: 0.3221
Epoch [41/50] - Loss: 0.3161
Epoch [42/50] - Loss: 0.3102
Epoch [43/50] - Loss: 0.3042
Epoch [44/50] - Loss: 0.2983
Epoch [45/50] - Loss: 0.2924
Epoch [46/50] - Loss: 0.2866
Epoch [47/50] - Loss: 0.2808
Epoch [48/50] - Loss: 0.2751
Epoch [49/50] - Loss: 0.2695
Epoch [50/50] - Loss: 0.2640
sum preds 3225
sum labels 4725
 - Test Metrics: Accuracy=0.8228, F1=0.6307, Recall=0.5306, Precision=0.7774
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4996
Epoch [2/50] - Loss: 0.4959
Epoch [3/50] - Loss: 0.4920
Epoch [4/50] - Loss: 0.4878
Epoch [5/50] - Loss: 0.4832
Epoch [6/50] - Loss: 0.4781
Epoch [7/50] - Loss: 0.4727
Epoch [8/50] - Loss: 0.4671
Epoch [9/50] - Loss: 0.4614
Epoch [10/50] - Loss: 0.4556
Epoch [11/50] - Loss: 0.4498
Epoch [12/50] - Loss: 0.4439
Epoch [13/50] - Loss: 0.4382
Epoch [14/50] - Loss: 0.4325
Epoch [15/50] - Loss: 0.4267
Epoch [16/50] - Loss: 0.4210
Epoch [17/50] - Loss: 0.4153
Epoch [18/50] - Loss: 0.4097
Epoch [19/50] - Loss: 0.4041
Epoch [20/50] - Loss: 0.3987
Epoch [21/50] - Loss: 0.3934
Epoch [22/50] - Loss: 0.3883
Epoch [23/50] - Loss: 0.3833
Epoch [24/50] - Loss: 0.3784
Epoch [25/50] - Loss: 0.3737
Epoch [26/50] - Loss: 0.3689
Epoch [27/50] - Loss: 0.3642
Epoch [28/50] - Loss: 0.3595
Epoch [29/50] - Loss: 0.3547
Epoch [30/50] - Loss: 0.3498
Epoch [31/50] - Loss: 0.3449
Epoch [32/50] - Loss: 0.3399
Epoch [33/50] - Loss: 0.3348
Epoch [34/50] - Loss: 0.3297
Epoch [35/50] - Loss: 0.3245
Epoch [36/50] - Loss: 0.3193
Epoch [37/50] - Loss: 0.3142
Epoch [38/50] - Loss: 0.3092
Epoch [39/50] - Loss: 0.3042
Epoch [40/50] - Loss: 0.2993
Epoch [41/50] - Loss: 0.2945
Epoch [42/50] - Loss: 0.2898
Epoch [43/50] - Loss: 0.2851
Epoch [44/50] - Loss: 0.2804
Epoch [45/50] - Loss: 0.2757
Epoch [46/50] - Loss: 0.2710
Epoch [47/50] - Loss: 0.2662
Epoch [48/50] - Loss: 0.2614
Epoch [49/50] - Loss: 0.2567
Epoch [50/50] - Loss: 0.2518
sum preds 3202
sum labels 4725
 - Test Metrics: Accuracy=0.8148, F1=0.6128, Recall=0.5141, Precision=0.7586
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4963
Epoch [3/50] - Loss: 0.4932
Epoch [4/50] - Loss: 0.4901
Epoch [5/50] - Loss: 0.4866
Epoch [6/50] - Loss: 0.4827
Epoch [7/50] - Loss: 0.4786
Epoch [8/50] - Loss: 0.4742
Epoch [9/50] - Loss: 0.4697
Epoch [10/50] - Loss: 0.4649
Epoch [11/50] - Loss: 0.4601
Epoch [12/50] - Loss: 0.4552
Epoch [13/50] - Loss: 0.4503
Epoch [14/50] - Loss: 0.4453
Epoch [15/50] - Loss: 0.4402
Epoch [16/50] - Loss: 0.4349
Epoch [17/50] - Loss: 0.4295
Epoch [18/50] - Loss: 0.4240
Epoch [19/50] - Loss: 0.4185
Epoch [20/50] - Loss: 0.4130
Epoch [21/50] - Loss: 0.4074
Epoch [22/50] - Loss: 0.4017
Epoch [23/50] - Loss: 0.3960
Epoch [24/50] - Loss: 0.3903
Epoch [25/50] - Loss: 0.3844
Epoch [26/50] - Loss: 0.3786
Epoch [27/50] - Loss: 0.3726
Epoch [28/50] - Loss: 0.3666
Epoch [29/50] - Loss: 0.3606
Epoch [30/50] - Loss: 0.3545
Epoch [31/50] - Loss: 0.3483
Epoch [32/50] - Loss: 0.3420
Epoch [33/50] - Loss: 0.3358
Epoch [34/50] - Loss: 0.3294
Epoch [35/50] - Loss: 0.3231
Epoch [36/50] - Loss: 0.3168
Epoch [37/50] - Loss: 0.3105
Epoch [38/50] - Loss: 0.3042
Epoch [39/50] - Loss: 0.2980
Epoch [40/50] - Loss: 0.2918
Epoch [41/50] - Loss: 0.2857
Epoch [42/50] - Loss: 0.2797
Epoch [43/50] - Loss: 0.2738
Epoch [44/50] - Loss: 0.2679
Epoch [45/50] - Loss: 0.2622
Epoch [46/50] - Loss: 0.2566
Epoch [47/50] - Loss: 0.2511
Epoch [48/50] - Loss: 0.2458
Epoch [49/50] - Loss: 0.2405
Epoch [50/50] - Loss: 0.2354
sum preds 3506
sum labels 4725
 - Test Metrics: Accuracy=0.8218, F1=0.6412, Recall=0.5585, Precision=0.7527
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_nnpu_nnpu_1904035505.csv.
Average F1 over valid seeds: 0.6283 ± 0.0117
___________________________________________________________________________________
Avg F1 for pubmed with SAR and nnpu, GATConv,0.4: 0.6283 ± 0.0117
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5008
Epoch [2/50] - Loss: 0.4987
Epoch [3/50] - Loss: 0.4970
Epoch [4/50] - Loss: 0.4950
Epoch [5/50] - Loss: 0.4925
Epoch [6/50] - Loss: 0.4898
Epoch [7/50] - Loss: 0.4868
Epoch [8/50] - Loss: 0.4836
Epoch [9/50] - Loss: 0.4804
Epoch [10/50] - Loss: 0.4771
Epoch [11/50] - Loss: 0.4736
Epoch [12/50] - Loss: 0.4700
Epoch [13/50] - Loss: 0.4663
Epoch [14/50] - Loss: 0.4625
Epoch [15/50] - Loss: 0.4586
Epoch [16/50] - Loss: 0.4546
Epoch [17/50] - Loss: 0.4505
Epoch [18/50] - Loss: 0.4464
Epoch [19/50] - Loss: 0.4421
Epoch [20/50] - Loss: 0.4378
Epoch [21/50] - Loss: 0.4335
Epoch [22/50] - Loss: 0.4290
Epoch [23/50] - Loss: 0.4245
Epoch [24/50] - Loss: 0.4199
Epoch [25/50] - Loss: 0.4152
Epoch [26/50] - Loss: 0.4105
Epoch [27/50] - Loss: 0.4058
Epoch [28/50] - Loss: 0.4010
Epoch [29/50] - Loss: 0.3961
Epoch [30/50] - Loss: 0.3912
Epoch [31/50] - Loss: 0.3863
Epoch [32/50] - Loss: 0.3814
Epoch [33/50] - Loss: 0.3764
Epoch [34/50] - Loss: 0.3715
Epoch [35/50] - Loss: 0.3665
Epoch [36/50] - Loss: 0.3615
Epoch [37/50] - Loss: 0.3565
Epoch [38/50] - Loss: 0.3515
Epoch [39/50] - Loss: 0.3465
Epoch [40/50] - Loss: 0.3415
Epoch [41/50] - Loss: 0.3365
Epoch [42/50] - Loss: 0.3316
Epoch [43/50] - Loss: 0.3267
Epoch [44/50] - Loss: 0.3218
Epoch [45/50] - Loss: 0.3169
Epoch [46/50] - Loss: 0.3121
Epoch [47/50] - Loss: 0.3073
Epoch [48/50] - Loss: 0.3026
Epoch [49/50] - Loss: 0.2980
Epoch [50/50] - Loss: 0.2933
sum preds 3107
sum labels 4725
 - Test Metrics: Accuracy=0.8250, F1=0.6297, Recall=0.5219, Precision=0.7937
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5012
Epoch [2/50] - Loss: 0.4988
Epoch [3/50] - Loss: 0.4967
Epoch [4/50] - Loss: 0.4946
Epoch [5/50] - Loss: 0.4922
Epoch [6/50] - Loss: 0.4896
Epoch [7/50] - Loss: 0.4867
Epoch [8/50] - Loss: 0.4837
Epoch [9/50] - Loss: 0.4805
Epoch [10/50] - Loss: 0.4773
Epoch [11/50] - Loss: 0.4740
Epoch [12/50] - Loss: 0.4706
Epoch [13/50] - Loss: 0.4671
Epoch [14/50] - Loss: 0.4635
Epoch [15/50] - Loss: 0.4598
Epoch [16/50] - Loss: 0.4559
Epoch [17/50] - Loss: 0.4518
Epoch [18/50] - Loss: 0.4476
Epoch [19/50] - Loss: 0.4433
Epoch [20/50] - Loss: 0.4390
Epoch [21/50] - Loss: 0.4346
Epoch [22/50] - Loss: 0.4302
Epoch [23/50] - Loss: 0.4256
Epoch [24/50] - Loss: 0.4209
Epoch [25/50] - Loss: 0.4161
Epoch [26/50] - Loss: 0.4113
Epoch [27/50] - Loss: 0.4064
Epoch [28/50] - Loss: 0.4016
Epoch [29/50] - Loss: 0.3967
Epoch [30/50] - Loss: 0.3917
Epoch [31/50] - Loss: 0.3867
Epoch [32/50] - Loss: 0.3816
Epoch [33/50] - Loss: 0.3766
Epoch [34/50] - Loss: 0.3715
Epoch [35/50] - Loss: 0.3664
Epoch [36/50] - Loss: 0.3614
Epoch [37/50] - Loss: 0.3563
Epoch [38/50] - Loss: 0.3513
Epoch [39/50] - Loss: 0.3462
Epoch [40/50] - Loss: 0.3412
Epoch [41/50] - Loss: 0.3362
Epoch [42/50] - Loss: 0.3312
Epoch [43/50] - Loss: 0.3263
Epoch [44/50] - Loss: 0.3214
Epoch [45/50] - Loss: 0.3166
Epoch [46/50] - Loss: 0.3118
Epoch [47/50] - Loss: 0.3071
Epoch [48/50] - Loss: 0.3024
Epoch [49/50] - Loss: 0.2978
Epoch [50/50] - Loss: 0.2932
sum preds 3108
sum labels 4725
 - Test Metrics: Accuracy=0.8239, F1=0.6276, Recall=0.5202, Precision=0.7909
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4967
Epoch [3/50] - Loss: 0.4933
Epoch [4/50] - Loss: 0.4896
Epoch [5/50] - Loss: 0.4858
Epoch [6/50] - Loss: 0.4819
Epoch [7/50] - Loss: 0.4779
Epoch [8/50] - Loss: 0.4736
Epoch [9/50] - Loss: 0.4692
Epoch [10/50] - Loss: 0.4647
Epoch [11/50] - Loss: 0.4601
Epoch [12/50] - Loss: 0.4554
Epoch [13/50] - Loss: 0.4507
Epoch [14/50] - Loss: 0.4459
Epoch [15/50] - Loss: 0.4411
Epoch [16/50] - Loss: 0.4363
Epoch [17/50] - Loss: 0.4315
Epoch [18/50] - Loss: 0.4267
Epoch [19/50] - Loss: 0.4218
Epoch [20/50] - Loss: 0.4170
Epoch [21/50] - Loss: 0.4121
Epoch [22/50] - Loss: 0.4072
Epoch [23/50] - Loss: 0.4024
Epoch [24/50] - Loss: 0.3976
Epoch [25/50] - Loss: 0.3929
Epoch [26/50] - Loss: 0.3881
Epoch [27/50] - Loss: 0.3834
Epoch [28/50] - Loss: 0.3787
Epoch [29/50] - Loss: 0.3740
Epoch [30/50] - Loss: 0.3693
Epoch [31/50] - Loss: 0.3646
Epoch [32/50] - Loss: 0.3600
Epoch [33/50] - Loss: 0.3553
Epoch [34/50] - Loss: 0.3506
Epoch [35/50] - Loss: 0.3460
Epoch [36/50] - Loss: 0.3413
Epoch [37/50] - Loss: 0.3367
Epoch [38/50] - Loss: 0.3320
Epoch [39/50] - Loss: 0.3274
Epoch [40/50] - Loss: 0.3229
Epoch [41/50] - Loss: 0.3183
Epoch [42/50] - Loss: 0.3138
Epoch [43/50] - Loss: 0.3093
Epoch [44/50] - Loss: 0.3049
Epoch [45/50] - Loss: 0.3005
Epoch [46/50] - Loss: 0.2962
Epoch [47/50] - Loss: 0.2919
Epoch [48/50] - Loss: 0.2877
Epoch [49/50] - Loss: 0.2835
Epoch [50/50] - Loss: 0.2793
sum preds 2944
sum labels 4725
 - Test Metrics: Accuracy=0.8204, F1=0.6121, Recall=0.4967, Precision=0.7972
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_nnpu_nnpu_1904035509.csv.
Average F1 over valid seeds: 0.6231 ± 0.0079
___________________________________________________________________________________
Avg F1 for pubmed with SAR and nnpu, GCNConv,0.4: 0.6231 ± 0.0079
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4966
Epoch [2/50] - Loss: 0.4955
Epoch [3/50] - Loss: 0.4945
Epoch [4/50] - Loss: 0.4935
Epoch [5/50] - Loss: 0.4924
Epoch [6/50] - Loss: 0.4911
Epoch [7/50] - Loss: 0.4897
Epoch [8/50] - Loss: 0.4881
Epoch [9/50] - Loss: 0.4864
Epoch [10/50] - Loss: 0.4845
Epoch [11/50] - Loss: 0.4826
Epoch [12/50] - Loss: 0.4805
Epoch [13/50] - Loss: 0.4783
Epoch [14/50] - Loss: 0.4760
Epoch [15/50] - Loss: 0.4735
Epoch [16/50] - Loss: 0.4709
Epoch [17/50] - Loss: 0.4681
Epoch [18/50] - Loss: 0.4652
Epoch [19/50] - Loss: 0.4622
Epoch [20/50] - Loss: 0.4590
Epoch [21/50] - Loss: 0.4556
Epoch [22/50] - Loss: 0.4521
Epoch [23/50] - Loss: 0.4485
Epoch [24/50] - Loss: 0.4446
Epoch [25/50] - Loss: 0.4407
Epoch [26/50] - Loss: 0.4366
Epoch [27/50] - Loss: 0.4323
Epoch [28/50] - Loss: 0.4279
Epoch [29/50] - Loss: 0.4233
Epoch [30/50] - Loss: 0.4186
Epoch [31/50] - Loss: 0.4138
Epoch [32/50] - Loss: 0.4088
Epoch [33/50] - Loss: 0.4038
Epoch [34/50] - Loss: 0.3986
Epoch [35/50] - Loss: 0.3932
Epoch [36/50] - Loss: 0.3878
Epoch [37/50] - Loss: 0.3823
Epoch [38/50] - Loss: 0.3767
Epoch [39/50] - Loss: 0.3711
Epoch [40/50] - Loss: 0.3653
Epoch [41/50] - Loss: 0.3596
Epoch [42/50] - Loss: 0.3538
Epoch [43/50] - Loss: 0.3479
Epoch [44/50] - Loss: 0.3421
Epoch [45/50] - Loss: 0.3362
Epoch [46/50] - Loss: 0.3304
Epoch [47/50] - Loss: 0.3246
Epoch [48/50] - Loss: 0.3189
Epoch [49/50] - Loss: 0.3132
Epoch [50/50] - Loss: 0.3075
sum preds 3299
sum labels 5513
 - Test Metrics: Accuracy=0.7944, F1=0.5951, Recall=0.4756, Precision=0.7948
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5091
Epoch [2/50] - Loss: 0.5075
Epoch [3/50] - Loss: 0.5058
Epoch [4/50] - Loss: 0.5043
Epoch [5/50] - Loss: 0.5029
Epoch [6/50] - Loss: 0.5012
Epoch [7/50] - Loss: 0.4994
Epoch [8/50] - Loss: 0.4973
Epoch [9/50] - Loss: 0.4951
Epoch [10/50] - Loss: 0.4927
Epoch [11/50] - Loss: 0.4902
Epoch [12/50] - Loss: 0.4875
Epoch [13/50] - Loss: 0.4847
Epoch [14/50] - Loss: 0.4817
Epoch [15/50] - Loss: 0.4785
Epoch [16/50] - Loss: 0.4751
Epoch [17/50] - Loss: 0.4715
Epoch [18/50] - Loss: 0.4677
Epoch [19/50] - Loss: 0.4637
Epoch [20/50] - Loss: 0.4595
Epoch [21/50] - Loss: 0.4551
Epoch [22/50] - Loss: 0.4505
Epoch [23/50] - Loss: 0.4457
Epoch [24/50] - Loss: 0.4408
Epoch [25/50] - Loss: 0.4357
Epoch [26/50] - Loss: 0.4304
Epoch [27/50] - Loss: 0.4250
Epoch [28/50] - Loss: 0.4195
Epoch [29/50] - Loss: 0.4138
Epoch [30/50] - Loss: 0.4080
Epoch [31/50] - Loss: 0.4021
Epoch [32/50] - Loss: 0.3961
Epoch [33/50] - Loss: 0.3901
Epoch [34/50] - Loss: 0.3840
Epoch [35/50] - Loss: 0.3779
Epoch [36/50] - Loss: 0.3718
Epoch [37/50] - Loss: 0.3657
Epoch [38/50] - Loss: 0.3596
Epoch [39/50] - Loss: 0.3536
Epoch [40/50] - Loss: 0.3476
Epoch [41/50] - Loss: 0.3417
Epoch [42/50] - Loss: 0.3358
Epoch [43/50] - Loss: 0.3300
Epoch [44/50] - Loss: 0.3242
Epoch [45/50] - Loss: 0.3186
Epoch [46/50] - Loss: 0.3130
Epoch [47/50] - Loss: 0.3074
Epoch [48/50] - Loss: 0.3020
Epoch [49/50] - Loss: 0.2966
Epoch [50/50] - Loss: 0.2913
sum preds 2578
sum labels 5513
 - Test Metrics: Accuracy=0.7743, F1=0.5159, Recall=0.3786, Precision=0.8095
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4899
Epoch [2/50] - Loss: 0.4881
Epoch [3/50] - Loss: 0.4864
Epoch [4/50] - Loss: 0.4847
Epoch [5/50] - Loss: 0.4829
Epoch [6/50] - Loss: 0.4810
Epoch [7/50] - Loss: 0.4788
Epoch [8/50] - Loss: 0.4765
Epoch [9/50] - Loss: 0.4740
Epoch [10/50] - Loss: 0.4712
Epoch [11/50] - Loss: 0.4683
Epoch [12/50] - Loss: 0.4651
Epoch [13/50] - Loss: 0.4619
Epoch [14/50] - Loss: 0.4585
Epoch [15/50] - Loss: 0.4550
Epoch [16/50] - Loss: 0.4514
Epoch [17/50] - Loss: 0.4477
Epoch [18/50] - Loss: 0.4437
Epoch [19/50] - Loss: 0.4397
Epoch [20/50] - Loss: 0.4355
Epoch [21/50] - Loss: 0.4312
Epoch [22/50] - Loss: 0.4268
Epoch [23/50] - Loss: 0.4223
Epoch [24/50] - Loss: 0.4177
Epoch [25/50] - Loss: 0.4130
Epoch [26/50] - Loss: 0.4083
Epoch [27/50] - Loss: 0.4034
Epoch [28/50] - Loss: 0.3985
Epoch [29/50] - Loss: 0.3935
Epoch [30/50] - Loss: 0.3885
Epoch [31/50] - Loss: 0.3835
Epoch [32/50] - Loss: 0.3784
Epoch [33/50] - Loss: 0.3732
Epoch [34/50] - Loss: 0.3680
Epoch [35/50] - Loss: 0.3628
Epoch [36/50] - Loss: 0.3576
Epoch [37/50] - Loss: 0.3524
Epoch [38/50] - Loss: 0.3471
Epoch [39/50] - Loss: 0.3418
Epoch [40/50] - Loss: 0.3365
Epoch [41/50] - Loss: 0.3312
Epoch [42/50] - Loss: 0.3258
Epoch [43/50] - Loss: 0.3205
Epoch [44/50] - Loss: 0.3151
Epoch [45/50] - Loss: 0.3098
Epoch [46/50] - Loss: 0.3045
Epoch [47/50] - Loss: 0.2992
Epoch [48/50] - Loss: 0.2940
Epoch [49/50] - Loss: 0.2888
Epoch [50/50] - Loss: 0.2837
sum preds 2902
sum labels 5513
 - Test Metrics: Accuracy=0.7811, F1=0.5485, Recall=0.4186, Precision=0.7953
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_nnpu_nnpu_1904035512.csv.
Average F1 over valid seeds: 0.5532 ± 0.0325
___________________________________________________________________________________
Avg F1 for pubmed with SAR and nnpu, MLP,0.3: 0.5532 ± 0.0325
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4984
Epoch [3/50] - Loss: 0.4965
Epoch [4/50] - Loss: 0.4944
Epoch [5/50] - Loss: 0.4920
Epoch [6/50] - Loss: 0.4893
Epoch [7/50] - Loss: 0.4864
Epoch [8/50] - Loss: 0.4834
Epoch [9/50] - Loss: 0.4802
Epoch [10/50] - Loss: 0.4769
Epoch [11/50] - Loss: 0.4734
Epoch [12/50] - Loss: 0.4697
Epoch [13/50] - Loss: 0.4659
Epoch [14/50] - Loss: 0.4621
Epoch [15/50] - Loss: 0.4582
Epoch [16/50] - Loss: 0.4541
Epoch [17/50] - Loss: 0.4500
Epoch [18/50] - Loss: 0.4457
Epoch [19/50] - Loss: 0.4412
Epoch [20/50] - Loss: 0.4367
Epoch [21/50] - Loss: 0.4321
Epoch [22/50] - Loss: 0.4273
Epoch [23/50] - Loss: 0.4225
Epoch [24/50] - Loss: 0.4176
Epoch [25/50] - Loss: 0.4127
Epoch [26/50] - Loss: 0.4076
Epoch [27/50] - Loss: 0.4024
Epoch [28/50] - Loss: 0.3972
Epoch [29/50] - Loss: 0.3919
Epoch [30/50] - Loss: 0.3865
Epoch [31/50] - Loss: 0.3811
Epoch [32/50] - Loss: 0.3756
Epoch [33/50] - Loss: 0.3702
Epoch [34/50] - Loss: 0.3646
Epoch [35/50] - Loss: 0.3591
Epoch [36/50] - Loss: 0.3535
Epoch [37/50] - Loss: 0.3480
Epoch [38/50] - Loss: 0.3423
Epoch [39/50] - Loss: 0.3367
Epoch [40/50] - Loss: 0.3311
Epoch [41/50] - Loss: 0.3255
Epoch [42/50] - Loss: 0.3199
Epoch [43/50] - Loss: 0.3143
Epoch [44/50] - Loss: 0.3087
Epoch [45/50] - Loss: 0.3032
Epoch [46/50] - Loss: 0.2977
Epoch [47/50] - Loss: 0.2923
Epoch [48/50] - Loss: 0.2870
Epoch [49/50] - Loss: 0.2817
Epoch [50/50] - Loss: 0.2765
sum preds 3653
sum labels 5513
 - Test Metrics: Accuracy=0.8114, F1=0.6428, Recall=0.5344, Precision=0.8065
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4996
Epoch [2/50] - Loss: 0.4960
Epoch [3/50] - Loss: 0.4922
Epoch [4/50] - Loss: 0.4880
Epoch [5/50] - Loss: 0.4834
Epoch [6/50] - Loss: 0.4784
Epoch [7/50] - Loss: 0.4731
Epoch [8/50] - Loss: 0.4677
Epoch [9/50] - Loss: 0.4621
Epoch [10/50] - Loss: 0.4565
Epoch [11/50] - Loss: 0.4507
Epoch [12/50] - Loss: 0.4449
Epoch [13/50] - Loss: 0.4392
Epoch [14/50] - Loss: 0.4335
Epoch [15/50] - Loss: 0.4278
Epoch [16/50] - Loss: 0.4221
Epoch [17/50] - Loss: 0.4165
Epoch [18/50] - Loss: 0.4110
Epoch [19/50] - Loss: 0.4057
Epoch [20/50] - Loss: 0.4005
Epoch [21/50] - Loss: 0.3955
Epoch [22/50] - Loss: 0.3905
Epoch [23/50] - Loss: 0.3857
Epoch [24/50] - Loss: 0.3810
Epoch [25/50] - Loss: 0.3763
Epoch [26/50] - Loss: 0.3717
Epoch [27/50] - Loss: 0.3672
Epoch [28/50] - Loss: 0.3626
Epoch [29/50] - Loss: 0.3580
Epoch [30/50] - Loss: 0.3534
Epoch [31/50] - Loss: 0.3487
Epoch [32/50] - Loss: 0.3439
Epoch [33/50] - Loss: 0.3391
Epoch [34/50] - Loss: 0.3342
Epoch [35/50] - Loss: 0.3293
Epoch [36/50] - Loss: 0.3244
Epoch [37/50] - Loss: 0.3196
Epoch [38/50] - Loss: 0.3148
Epoch [39/50] - Loss: 0.3102
Epoch [40/50] - Loss: 0.3055
Epoch [41/50] - Loss: 0.3010
Epoch [42/50] - Loss: 0.2965
Epoch [43/50] - Loss: 0.2920
Epoch [44/50] - Loss: 0.2876
Epoch [45/50] - Loss: 0.2832
Epoch [46/50] - Loss: 0.2788
Epoch [47/50] - Loss: 0.2744
Epoch [48/50] - Loss: 0.2699
Epoch [49/50] - Loss: 0.2655
Epoch [50/50] - Loss: 0.2610
sum preds 3616
sum labels 5513
 - Test Metrics: Accuracy=0.8017, F1=0.6231, Recall=0.5159, Precision=0.7865
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4964
Epoch [3/50] - Loss: 0.4934
Epoch [4/50] - Loss: 0.4902
Epoch [5/50] - Loss: 0.4867
Epoch [6/50] - Loss: 0.4828
Epoch [7/50] - Loss: 0.4788
Epoch [8/50] - Loss: 0.4745
Epoch [9/50] - Loss: 0.4700
Epoch [10/50] - Loss: 0.4654
Epoch [11/50] - Loss: 0.4607
Epoch [12/50] - Loss: 0.4559
Epoch [13/50] - Loss: 0.4511
Epoch [14/50] - Loss: 0.4462
Epoch [15/50] - Loss: 0.4413
Epoch [16/50] - Loss: 0.4362
Epoch [17/50] - Loss: 0.4310
Epoch [18/50] - Loss: 0.4256
Epoch [19/50] - Loss: 0.4201
Epoch [20/50] - Loss: 0.4147
Epoch [21/50] - Loss: 0.4093
Epoch [22/50] - Loss: 0.4038
Epoch [23/50] - Loss: 0.3983
Epoch [24/50] - Loss: 0.3928
Epoch [25/50] - Loss: 0.3871
Epoch [26/50] - Loss: 0.3814
Epoch [27/50] - Loss: 0.3757
Epoch [28/50] - Loss: 0.3698
Epoch [29/50] - Loss: 0.3640
Epoch [30/50] - Loss: 0.3580
Epoch [31/50] - Loss: 0.3520
Epoch [32/50] - Loss: 0.3460
Epoch [33/50] - Loss: 0.3400
Epoch [34/50] - Loss: 0.3338
Epoch [35/50] - Loss: 0.3277
Epoch [36/50] - Loss: 0.3216
Epoch [37/50] - Loss: 0.3155
Epoch [38/50] - Loss: 0.3094
Epoch [39/50] - Loss: 0.3033
Epoch [40/50] - Loss: 0.2973
Epoch [41/50] - Loss: 0.2914
Epoch [42/50] - Loss: 0.2856
Epoch [43/50] - Loss: 0.2798
Epoch [44/50] - Loss: 0.2742
Epoch [45/50] - Loss: 0.2687
Epoch [46/50] - Loss: 0.2632
Epoch [47/50] - Loss: 0.2579
Epoch [48/50] - Loss: 0.2527
Epoch [49/50] - Loss: 0.2476
Epoch [50/50] - Loss: 0.2427
sum preds 3874
sum labels 5513
 - Test Metrics: Accuracy=0.8067, F1=0.6426, Recall=0.5471, Precision=0.7785
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_nnpu_nnpu_1904035516.csv.
Average F1 over valid seeds: 0.6362 ± 0.0093
___________________________________________________________________________________
Avg F1 for pubmed with SAR and nnpu, GATConv,0.3: 0.6362 ± 0.0093
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5007
Epoch [2/50] - Loss: 0.4988
Epoch [3/50] - Loss: 0.4971
Epoch [4/50] - Loss: 0.4952
Epoch [5/50] - Loss: 0.4929
Epoch [6/50] - Loss: 0.4903
Epoch [7/50] - Loss: 0.4874
Epoch [8/50] - Loss: 0.4844
Epoch [9/50] - Loss: 0.4813
Epoch [10/50] - Loss: 0.4781
Epoch [11/50] - Loss: 0.4748
Epoch [12/50] - Loss: 0.4714
Epoch [13/50] - Loss: 0.4679
Epoch [14/50] - Loss: 0.4643
Epoch [15/50] - Loss: 0.4607
Epoch [16/50] - Loss: 0.4569
Epoch [17/50] - Loss: 0.4530
Epoch [18/50] - Loss: 0.4491
Epoch [19/50] - Loss: 0.4451
Epoch [20/50] - Loss: 0.4411
Epoch [21/50] - Loss: 0.4369
Epoch [22/50] - Loss: 0.4327
Epoch [23/50] - Loss: 0.4284
Epoch [24/50] - Loss: 0.4241
Epoch [25/50] - Loss: 0.4197
Epoch [26/50] - Loss: 0.4153
Epoch [27/50] - Loss: 0.4108
Epoch [28/50] - Loss: 0.4062
Epoch [29/50] - Loss: 0.4017
Epoch [30/50] - Loss: 0.3971
Epoch [31/50] - Loss: 0.3924
Epoch [32/50] - Loss: 0.3878
Epoch [33/50] - Loss: 0.3831
Epoch [34/50] - Loss: 0.3784
Epoch [35/50] - Loss: 0.3737
Epoch [36/50] - Loss: 0.3690
Epoch [37/50] - Loss: 0.3642
Epoch [38/50] - Loss: 0.3595
Epoch [39/50] - Loss: 0.3548
Epoch [40/50] - Loss: 0.3501
Epoch [41/50] - Loss: 0.3454
Epoch [42/50] - Loss: 0.3407
Epoch [43/50] - Loss: 0.3360
Epoch [44/50] - Loss: 0.3314
Epoch [45/50] - Loss: 0.3268
Epoch [46/50] - Loss: 0.3223
Epoch [47/50] - Loss: 0.3177
Epoch [48/50] - Loss: 0.3133
Epoch [49/50] - Loss: 0.3089
Epoch [50/50] - Loss: 0.3045
sum preds 3565
sum labels 5513
 - Test Metrics: Accuracy=0.8146, F1=0.6455, Recall=0.5315, Precision=0.8219
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5012
Epoch [2/50] - Loss: 0.4988
Epoch [3/50] - Loss: 0.4969
Epoch [4/50] - Loss: 0.4948
Epoch [5/50] - Loss: 0.4925
Epoch [6/50] - Loss: 0.4900
Epoch [7/50] - Loss: 0.4873
Epoch [8/50] - Loss: 0.4844
Epoch [9/50] - Loss: 0.4813
Epoch [10/50] - Loss: 0.4782
Epoch [11/50] - Loss: 0.4750
Epoch [12/50] - Loss: 0.4718
Epoch [13/50] - Loss: 0.4684
Epoch [14/50] - Loss: 0.4650
Epoch [15/50] - Loss: 0.4614
Epoch [16/50] - Loss: 0.4576
Epoch [17/50] - Loss: 0.4537
Epoch [18/50] - Loss: 0.4496
Epoch [19/50] - Loss: 0.4454
Epoch [20/50] - Loss: 0.4412
Epoch [21/50] - Loss: 0.4369
Epoch [22/50] - Loss: 0.4326
Epoch [23/50] - Loss: 0.4282
Epoch [24/50] - Loss: 0.4237
Epoch [25/50] - Loss: 0.4193
Epoch [26/50] - Loss: 0.4147
Epoch [27/50] - Loss: 0.4101
Epoch [28/50] - Loss: 0.4054
Epoch [29/50] - Loss: 0.4007
Epoch [30/50] - Loss: 0.3959
Epoch [31/50] - Loss: 0.3911
Epoch [32/50] - Loss: 0.3863
Epoch [33/50] - Loss: 0.3815
Epoch [34/50] - Loss: 0.3767
Epoch [35/50] - Loss: 0.3718
Epoch [36/50] - Loss: 0.3670
Epoch [37/50] - Loss: 0.3622
Epoch [38/50] - Loss: 0.3574
Epoch [39/50] - Loss: 0.3526
Epoch [40/50] - Loss: 0.3478
Epoch [41/50] - Loss: 0.3431
Epoch [42/50] - Loss: 0.3384
Epoch [43/50] - Loss: 0.3337
Epoch [44/50] - Loss: 0.3291
Epoch [45/50] - Loss: 0.3245
Epoch [46/50] - Loss: 0.3199
Epoch [47/50] - Loss: 0.3154
Epoch [48/50] - Loss: 0.3110
Epoch [49/50] - Loss: 0.3067
Epoch [50/50] - Loss: 0.3023
sum preds 3445
sum labels 5513
 - Test Metrics: Accuracy=0.8096, F1=0.6312, Recall=0.5128, Precision=0.8206
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4968
Epoch [3/50] - Loss: 0.4936
Epoch [4/50] - Loss: 0.4901
Epoch [5/50] - Loss: 0.4865
Epoch [6/50] - Loss: 0.4827
Epoch [7/50] - Loss: 0.4789
Epoch [8/50] - Loss: 0.4748
Epoch [9/50] - Loss: 0.4707
Epoch [10/50] - Loss: 0.4663
Epoch [11/50] - Loss: 0.4619
Epoch [12/50] - Loss: 0.4574
Epoch [13/50] - Loss: 0.4529
Epoch [14/50] - Loss: 0.4483
Epoch [15/50] - Loss: 0.4438
Epoch [16/50] - Loss: 0.4392
Epoch [17/50] - Loss: 0.4346
Epoch [18/50] - Loss: 0.4300
Epoch [19/50] - Loss: 0.4253
Epoch [20/50] - Loss: 0.4207
Epoch [21/50] - Loss: 0.4160
Epoch [22/50] - Loss: 0.4114
Epoch [23/50] - Loss: 0.4068
Epoch [24/50] - Loss: 0.4023
Epoch [25/50] - Loss: 0.3977
Epoch [26/50] - Loss: 0.3932
Epoch [27/50] - Loss: 0.3887
Epoch [28/50] - Loss: 0.3842
Epoch [29/50] - Loss: 0.3798
Epoch [30/50] - Loss: 0.3753
Epoch [31/50] - Loss: 0.3709
Epoch [32/50] - Loss: 0.3665
Epoch [33/50] - Loss: 0.3620
Epoch [34/50] - Loss: 0.3576
Epoch [35/50] - Loss: 0.3532
Epoch [36/50] - Loss: 0.3488
Epoch [37/50] - Loss: 0.3444
Epoch [38/50] - Loss: 0.3400
Epoch [39/50] - Loss: 0.3357
Epoch [40/50] - Loss: 0.3314
Epoch [41/50] - Loss: 0.3271
Epoch [42/50] - Loss: 0.3228
Epoch [43/50] - Loss: 0.3186
Epoch [44/50] - Loss: 0.3144
Epoch [45/50] - Loss: 0.3103
Epoch [46/50] - Loss: 0.3062
Epoch [47/50] - Loss: 0.3021
Epoch [48/50] - Loss: 0.2981
Epoch [49/50] - Loss: 0.2941
Epoch [50/50] - Loss: 0.2902
sum preds 3360
sum labels 5513
 - Test Metrics: Accuracy=0.8068, F1=0.6221, Recall=0.5006, Precision=0.8214
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_nnpu_nnpu_1904035520.csv.
Average F1 over valid seeds: 0.6329 ± 0.0096
___________________________________________________________________________________
Avg F1 for pubmed with SAR and nnpu, GCNConv,0.3: 0.6329 ± 0.0096
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4966
Epoch [2/50] - Loss: 0.4955
Epoch [3/50] - Loss: 0.4946
Epoch [4/50] - Loss: 0.4936
Epoch [5/50] - Loss: 0.4925
Epoch [6/50] - Loss: 0.4913
Epoch [7/50] - Loss: 0.4899
Epoch [8/50] - Loss: 0.4884
Epoch [9/50] - Loss: 0.4867
Epoch [10/50] - Loss: 0.4849
Epoch [11/50] - Loss: 0.4830
Epoch [12/50] - Loss: 0.4810
Epoch [13/50] - Loss: 0.4789
Epoch [14/50] - Loss: 0.4766
Epoch [15/50] - Loss: 0.4742
Epoch [16/50] - Loss: 0.4717
Epoch [17/50] - Loss: 0.4690
Epoch [18/50] - Loss: 0.4662
Epoch [19/50] - Loss: 0.4632
Epoch [20/50] - Loss: 0.4601
Epoch [21/50] - Loss: 0.4569
Epoch [22/50] - Loss: 0.4535
Epoch [23/50] - Loss: 0.4499
Epoch [24/50] - Loss: 0.4462
Epoch [25/50] - Loss: 0.4424
Epoch [26/50] - Loss: 0.4384
Epoch [27/50] - Loss: 0.4343
Epoch [28/50] - Loss: 0.4300
Epoch [29/50] - Loss: 0.4256
Epoch [30/50] - Loss: 0.4211
Epoch [31/50] - Loss: 0.4164
Epoch [32/50] - Loss: 0.4116
Epoch [33/50] - Loss: 0.4067
Epoch [34/50] - Loss: 0.4017
Epoch [35/50] - Loss: 0.3965
Epoch [36/50] - Loss: 0.3913
Epoch [37/50] - Loss: 0.3860
Epoch [38/50] - Loss: 0.3806
Epoch [39/50] - Loss: 0.3751
Epoch [40/50] - Loss: 0.3695
Epoch [41/50] - Loss: 0.3640
Epoch [42/50] - Loss: 0.3584
Epoch [43/50] - Loss: 0.3527
Epoch [44/50] - Loss: 0.3470
Epoch [45/50] - Loss: 0.3414
Epoch [46/50] - Loss: 0.3357
Epoch [47/50] - Loss: 0.3301
Epoch [48/50] - Loss: 0.3245
Epoch [49/50] - Loss: 0.3190
Epoch [50/50] - Loss: 0.3135
sum preds 3664
sum labels 6300
 - Test Metrics: Accuracy=0.7804, F1=0.6002, Recall=0.4746, Precision=0.8160
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5091
Epoch [2/50] - Loss: 0.5075
Epoch [3/50] - Loss: 0.5059
Epoch [4/50] - Loss: 0.5044
Epoch [5/50] - Loss: 0.5030
Epoch [6/50] - Loss: 0.5014
Epoch [7/50] - Loss: 0.4996
Epoch [8/50] - Loss: 0.4976
Epoch [9/50] - Loss: 0.4954
Epoch [10/50] - Loss: 0.4931
Epoch [11/50] - Loss: 0.4906
Epoch [12/50] - Loss: 0.4880
Epoch [13/50] - Loss: 0.4853
Epoch [14/50] - Loss: 0.4823
Epoch [15/50] - Loss: 0.4792
Epoch [16/50] - Loss: 0.4760
Epoch [17/50] - Loss: 0.4725
Epoch [18/50] - Loss: 0.4688
Epoch [19/50] - Loss: 0.4650
Epoch [20/50] - Loss: 0.4609
Epoch [21/50] - Loss: 0.4566
Epoch [22/50] - Loss: 0.4522
Epoch [23/50] - Loss: 0.4476
Epoch [24/50] - Loss: 0.4428
Epoch [25/50] - Loss: 0.4379
Epoch [26/50] - Loss: 0.4328
Epoch [27/50] - Loss: 0.4276
Epoch [28/50] - Loss: 0.4222
Epoch [29/50] - Loss: 0.4167
Epoch [30/50] - Loss: 0.4112
Epoch [31/50] - Loss: 0.4055
Epoch [32/50] - Loss: 0.3998
Epoch [33/50] - Loss: 0.3940
Epoch [34/50] - Loss: 0.3882
Epoch [35/50] - Loss: 0.3824
Epoch [36/50] - Loss: 0.3766
Epoch [37/50] - Loss: 0.3708
Epoch [38/50] - Loss: 0.3650
Epoch [39/50] - Loss: 0.3592
Epoch [40/50] - Loss: 0.3536
Epoch [41/50] - Loss: 0.3480
Epoch [42/50] - Loss: 0.3424
Epoch [43/50] - Loss: 0.3369
Epoch [44/50] - Loss: 0.3315
Epoch [45/50] - Loss: 0.3261
Epoch [46/50] - Loss: 0.3209
Epoch [47/50] - Loss: 0.3156
Epoch [48/50] - Loss: 0.3105
Epoch [49/50] - Loss: 0.3054
Epoch [50/50] - Loss: 0.3004
sum preds 2855
sum labels 6300
 - Test Metrics: Accuracy=0.7556, F1=0.5158, Recall=0.3748, Precision=0.8270
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4899
Epoch [2/50] - Loss: 0.4881
Epoch [3/50] - Loss: 0.4864
Epoch [4/50] - Loss: 0.4847
Epoch [5/50] - Loss: 0.4828
Epoch [6/50] - Loss: 0.4808
Epoch [7/50] - Loss: 0.4787
Epoch [8/50] - Loss: 0.4763
Epoch [9/50] - Loss: 0.4739
Epoch [10/50] - Loss: 0.4712
Epoch [11/50] - Loss: 0.4684
Epoch [12/50] - Loss: 0.4653
Epoch [13/50] - Loss: 0.4622
Epoch [14/50] - Loss: 0.4588
Epoch [15/50] - Loss: 0.4554
Epoch [16/50] - Loss: 0.4518
Epoch [17/50] - Loss: 0.4481
Epoch [18/50] - Loss: 0.4442
Epoch [19/50] - Loss: 0.4402
Epoch [20/50] - Loss: 0.4361
Epoch [21/50] - Loss: 0.4318
Epoch [22/50] - Loss: 0.4275
Epoch [23/50] - Loss: 0.4230
Epoch [24/50] - Loss: 0.4185
Epoch [25/50] - Loss: 0.4138
Epoch [26/50] - Loss: 0.4091
Epoch [27/50] - Loss: 0.4043
Epoch [28/50] - Loss: 0.3994
Epoch [29/50] - Loss: 0.3945
Epoch [30/50] - Loss: 0.3896
Epoch [31/50] - Loss: 0.3845
Epoch [32/50] - Loss: 0.3795
Epoch [33/50] - Loss: 0.3744
Epoch [34/50] - Loss: 0.3693
Epoch [35/50] - Loss: 0.3642
Epoch [36/50] - Loss: 0.3591
Epoch [37/50] - Loss: 0.3539
Epoch [38/50] - Loss: 0.3488
Epoch [39/50] - Loss: 0.3436
Epoch [40/50] - Loss: 0.3384
Epoch [41/50] - Loss: 0.3332
Epoch [42/50] - Loss: 0.3281
Epoch [43/50] - Loss: 0.3229
Epoch [44/50] - Loss: 0.3177
Epoch [45/50] - Loss: 0.3126
Epoch [46/50] - Loss: 0.3075
Epoch [47/50] - Loss: 0.3024
Epoch [48/50] - Loss: 0.2973
Epoch [49/50] - Loss: 0.2923
Epoch [50/50] - Loss: 0.2874
sum preds 2943
sum labels 6300
 - Test Metrics: Accuracy=0.7622, F1=0.5332, Recall=0.3911, Precision=0.8372
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_nnpu_nnpu_1904035524.csv.
Average F1 over valid seeds: 0.5497 ± 0.0364
___________________________________________________________________________________
Avg F1 for pubmed with SAR and nnpu, MLP,0.2: 0.5497 ± 0.0364
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4983
Epoch [3/50] - Loss: 0.4964
Epoch [4/50] - Loss: 0.4943
Epoch [5/50] - Loss: 0.4919
Epoch [6/50] - Loss: 0.4893
Epoch [7/50] - Loss: 0.4864
Epoch [8/50] - Loss: 0.4835
Epoch [9/50] - Loss: 0.4804
Epoch [10/50] - Loss: 0.4772
Epoch [11/50] - Loss: 0.4738
Epoch [12/50] - Loss: 0.4703
Epoch [13/50] - Loss: 0.4666
Epoch [14/50] - Loss: 0.4629
Epoch [15/50] - Loss: 0.4591
Epoch [16/50] - Loss: 0.4552
Epoch [17/50] - Loss: 0.4512
Epoch [18/50] - Loss: 0.4470
Epoch [19/50] - Loss: 0.4427
Epoch [20/50] - Loss: 0.4383
Epoch [21/50] - Loss: 0.4339
Epoch [22/50] - Loss: 0.4293
Epoch [23/50] - Loss: 0.4247
Epoch [24/50] - Loss: 0.4200
Epoch [25/50] - Loss: 0.4152
Epoch [26/50] - Loss: 0.4103
Epoch [27/50] - Loss: 0.4053
Epoch [28/50] - Loss: 0.4003
Epoch [29/50] - Loss: 0.3952
Epoch [30/50] - Loss: 0.3901
Epoch [31/50] - Loss: 0.3849
Epoch [32/50] - Loss: 0.3797
Epoch [33/50] - Loss: 0.3744
Epoch [34/50] - Loss: 0.3691
Epoch [35/50] - Loss: 0.3638
Epoch [36/50] - Loss: 0.3585
Epoch [37/50] - Loss: 0.3531
Epoch [38/50] - Loss: 0.3478
Epoch [39/50] - Loss: 0.3424
Epoch [40/50] - Loss: 0.3370
Epoch [41/50] - Loss: 0.3316
Epoch [42/50] - Loss: 0.3262
Epoch [43/50] - Loss: 0.3209
Epoch [44/50] - Loss: 0.3155
Epoch [45/50] - Loss: 0.3102
Epoch [46/50] - Loss: 0.3050
Epoch [47/50] - Loss: 0.2998
Epoch [48/50] - Loss: 0.2946
Epoch [49/50] - Loss: 0.2896
Epoch [50/50] - Loss: 0.2846
sum preds 4026
sum labels 6300
 - Test Metrics: Accuracy=0.7988, F1=0.6465, Recall=0.5298, Precision=0.8291
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4961
Epoch [3/50] - Loss: 0.4924
Epoch [4/50] - Loss: 0.4884
Epoch [5/50] - Loss: 0.4839
Epoch [6/50] - Loss: 0.4791
Epoch [7/50] - Loss: 0.4740
Epoch [8/50] - Loss: 0.4688
Epoch [9/50] - Loss: 0.4634
Epoch [10/50] - Loss: 0.4579
Epoch [11/50] - Loss: 0.4524
Epoch [12/50] - Loss: 0.4469
Epoch [13/50] - Loss: 0.4414
Epoch [14/50] - Loss: 0.4360
Epoch [15/50] - Loss: 0.4306
Epoch [16/50] - Loss: 0.4252
Epoch [17/50] - Loss: 0.4199
Epoch [18/50] - Loss: 0.4146
Epoch [19/50] - Loss: 0.4094
Epoch [20/50] - Loss: 0.4043
Epoch [21/50] - Loss: 0.3994
Epoch [22/50] - Loss: 0.3947
Epoch [23/50] - Loss: 0.3901
Epoch [24/50] - Loss: 0.3856
Epoch [25/50] - Loss: 0.3813
Epoch [26/50] - Loss: 0.3769
Epoch [27/50] - Loss: 0.3727
Epoch [28/50] - Loss: 0.3684
Epoch [29/50] - Loss: 0.3641
Epoch [30/50] - Loss: 0.3597
Epoch [31/50] - Loss: 0.3553
Epoch [32/50] - Loss: 0.3509
Epoch [33/50] - Loss: 0.3463
Epoch [34/50] - Loss: 0.3417
Epoch [35/50] - Loss: 0.3371
Epoch [36/50] - Loss: 0.3325
Epoch [37/50] - Loss: 0.3278
Epoch [38/50] - Loss: 0.3233
Epoch [39/50] - Loss: 0.3188
Epoch [40/50] - Loss: 0.3144
Epoch [41/50] - Loss: 0.3100
Epoch [42/50] - Loss: 0.3057
Epoch [43/50] - Loss: 0.3014
Epoch [44/50] - Loss: 0.2972
Epoch [45/50] - Loss: 0.2929
Epoch [46/50] - Loss: 0.2887
Epoch [47/50] - Loss: 0.2844
Epoch [48/50] - Loss: 0.2801
Epoch [49/50] - Loss: 0.2758
Epoch [50/50] - Loss: 0.2714
sum preds 4045
sum labels 6300
 - Test Metrics: Accuracy=0.7919, F1=0.6351, Recall=0.5214, Precision=0.8121
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4996
Epoch [2/50] - Loss: 0.4964
Epoch [3/50] - Loss: 0.4934
Epoch [4/50] - Loss: 0.4903
Epoch [5/50] - Loss: 0.4867
Epoch [6/50] - Loss: 0.4830
Epoch [7/50] - Loss: 0.4790
Epoch [8/50] - Loss: 0.4748
Epoch [9/50] - Loss: 0.4704
Epoch [10/50] - Loss: 0.4659
Epoch [11/50] - Loss: 0.4612
Epoch [12/50] - Loss: 0.4565
Epoch [13/50] - Loss: 0.4518
Epoch [14/50] - Loss: 0.4470
Epoch [15/50] - Loss: 0.4421
Epoch [16/50] - Loss: 0.4371
Epoch [17/50] - Loss: 0.4320
Epoch [18/50] - Loss: 0.4268
Epoch [19/50] - Loss: 0.4215
Epoch [20/50] - Loss: 0.4161
Epoch [21/50] - Loss: 0.4108
Epoch [22/50] - Loss: 0.4055
Epoch [23/50] - Loss: 0.4001
Epoch [24/50] - Loss: 0.3946
Epoch [25/50] - Loss: 0.3891
Epoch [26/50] - Loss: 0.3836
Epoch [27/50] - Loss: 0.3779
Epoch [28/50] - Loss: 0.3722
Epoch [29/50] - Loss: 0.3665
Epoch [30/50] - Loss: 0.3607
Epoch [31/50] - Loss: 0.3549
Epoch [32/50] - Loss: 0.3490
Epoch [33/50] - Loss: 0.3431
Epoch [34/50] - Loss: 0.3371
Epoch [35/50] - Loss: 0.3311
Epoch [36/50] - Loss: 0.3251
Epoch [37/50] - Loss: 0.3191
Epoch [38/50] - Loss: 0.3132
Epoch [39/50] - Loss: 0.3073
Epoch [40/50] - Loss: 0.3014
Epoch [41/50] - Loss: 0.2956
Epoch [42/50] - Loss: 0.2899
Epoch [43/50] - Loss: 0.2842
Epoch [44/50] - Loss: 0.2787
Epoch [45/50] - Loss: 0.2733
Epoch [46/50] - Loss: 0.2679
Epoch [47/50] - Loss: 0.2627
Epoch [48/50] - Loss: 0.2576
Epoch [49/50] - Loss: 0.2526
Epoch [50/50] - Loss: 0.2478
sum preds 4191
sum labels 6300
 - Test Metrics: Accuracy=0.7949, F1=0.6453, Recall=0.5373, Precision=0.8077
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_nnpu_nnpu_1904035528.csv.
Average F1 over valid seeds: 0.6423 ± 0.0051
___________________________________________________________________________________
Avg F1 for pubmed with SAR and nnpu, GATConv,0.2: 0.6423 ± 0.0051
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5007
Epoch [2/50] - Loss: 0.4987
Epoch [3/50] - Loss: 0.4970
Epoch [4/50] - Loss: 0.4949
Epoch [5/50] - Loss: 0.4926
Epoch [6/50] - Loss: 0.4900
Epoch [7/50] - Loss: 0.4872
Epoch [8/50] - Loss: 0.4843
Epoch [9/50] - Loss: 0.4813
Epoch [10/50] - Loss: 0.4782
Epoch [11/50] - Loss: 0.4751
Epoch [12/50] - Loss: 0.4718
Epoch [13/50] - Loss: 0.4684
Epoch [14/50] - Loss: 0.4649
Epoch [15/50] - Loss: 0.4613
Epoch [16/50] - Loss: 0.4577
Epoch [17/50] - Loss: 0.4540
Epoch [18/50] - Loss: 0.4503
Epoch [19/50] - Loss: 0.4464
Epoch [20/50] - Loss: 0.4425
Epoch [21/50] - Loss: 0.4385
Epoch [22/50] - Loss: 0.4345
Epoch [23/50] - Loss: 0.4304
Epoch [24/50] - Loss: 0.4263
Epoch [25/50] - Loss: 0.4221
Epoch [26/50] - Loss: 0.4179
Epoch [27/50] - Loss: 0.4136
Epoch [28/50] - Loss: 0.4093
Epoch [29/50] - Loss: 0.4049
Epoch [30/50] - Loss: 0.4006
Epoch [31/50] - Loss: 0.3962
Epoch [32/50] - Loss: 0.3917
Epoch [33/50] - Loss: 0.3873
Epoch [34/50] - Loss: 0.3828
Epoch [35/50] - Loss: 0.3784
Epoch [36/50] - Loss: 0.3739
Epoch [37/50] - Loss: 0.3694
Epoch [38/50] - Loss: 0.3649
Epoch [39/50] - Loss: 0.3604
Epoch [40/50] - Loss: 0.3559
Epoch [41/50] - Loss: 0.3514
Epoch [42/50] - Loss: 0.3469
Epoch [43/50] - Loss: 0.3425
Epoch [44/50] - Loss: 0.3380
Epoch [45/50] - Loss: 0.3336
Epoch [46/50] - Loss: 0.3292
Epoch [47/50] - Loss: 0.3248
Epoch [48/50] - Loss: 0.3205
Epoch [49/50] - Loss: 0.3162
Epoch [50/50] - Loss: 0.3119
sum preds 3923
sum labels 6300
 - Test Metrics: Accuracy=0.8033, F1=0.6509, Recall=0.5281, Precision=0.8481
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5012
Epoch [2/50] - Loss: 0.4988
Epoch [3/50] - Loss: 0.4969
Epoch [4/50] - Loss: 0.4950
Epoch [5/50] - Loss: 0.4927
Epoch [6/50] - Loss: 0.4902
Epoch [7/50] - Loss: 0.4876
Epoch [8/50] - Loss: 0.4848
Epoch [9/50] - Loss: 0.4819
Epoch [10/50] - Loss: 0.4788
Epoch [11/50] - Loss: 0.4756
Epoch [12/50] - Loss: 0.4725
Epoch [13/50] - Loss: 0.4693
Epoch [14/50] - Loss: 0.4660
Epoch [15/50] - Loss: 0.4626
Epoch [16/50] - Loss: 0.4590
Epoch [17/50] - Loss: 0.4553
Epoch [18/50] - Loss: 0.4515
Epoch [19/50] - Loss: 0.4476
Epoch [20/50] - Loss: 0.4437
Epoch [21/50] - Loss: 0.4396
Epoch [22/50] - Loss: 0.4355
Epoch [23/50] - Loss: 0.4313
Epoch [24/50] - Loss: 0.4271
Epoch [25/50] - Loss: 0.4228
Epoch [26/50] - Loss: 0.4185
Epoch [27/50] - Loss: 0.4141
Epoch [28/50] - Loss: 0.4096
Epoch [29/50] - Loss: 0.4050
Epoch [30/50] - Loss: 0.4004
Epoch [31/50] - Loss: 0.3958
Epoch [32/50] - Loss: 0.3912
Epoch [33/50] - Loss: 0.3867
Epoch [34/50] - Loss: 0.3822
Epoch [35/50] - Loss: 0.3776
Epoch [36/50] - Loss: 0.3730
Epoch [37/50] - Loss: 0.3684
Epoch [38/50] - Loss: 0.3638
Epoch [39/50] - Loss: 0.3592
Epoch [40/50] - Loss: 0.3546
Epoch [41/50] - Loss: 0.3501
Epoch [42/50] - Loss: 0.3456
Epoch [43/50] - Loss: 0.3411
Epoch [44/50] - Loss: 0.3367
Epoch [45/50] - Loss: 0.3323
Epoch [46/50] - Loss: 0.3280
Epoch [47/50] - Loss: 0.3237
Epoch [48/50] - Loss: 0.3195
Epoch [49/50] - Loss: 0.3153
Epoch [50/50] - Loss: 0.3112
sum preds 3590
sum labels 6300
 - Test Metrics: Accuracy=0.7889, F1=0.6127, Recall=0.4810, Precision=0.8440
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4997
Epoch [2/50] - Loss: 0.4970
Epoch [3/50] - Loss: 0.4938
Epoch [4/50] - Loss: 0.4904
Epoch [5/50] - Loss: 0.4869
Epoch [6/50] - Loss: 0.4833
Epoch [7/50] - Loss: 0.4796
Epoch [8/50] - Loss: 0.4757
Epoch [9/50] - Loss: 0.4717
Epoch [10/50] - Loss: 0.4675
Epoch [11/50] - Loss: 0.4633
Epoch [12/50] - Loss: 0.4590
Epoch [13/50] - Loss: 0.4546
Epoch [14/50] - Loss: 0.4502
Epoch [15/50] - Loss: 0.4457
Epoch [16/50] - Loss: 0.4413
Epoch [17/50] - Loss: 0.4368
Epoch [18/50] - Loss: 0.4324
Epoch [19/50] - Loss: 0.4279
Epoch [20/50] - Loss: 0.4234
Epoch [21/50] - Loss: 0.4189
Epoch [22/50] - Loss: 0.4144
Epoch [23/50] - Loss: 0.4100
Epoch [24/50] - Loss: 0.4055
Epoch [25/50] - Loss: 0.4011
Epoch [26/50] - Loss: 0.3968
Epoch [27/50] - Loss: 0.3924
Epoch [28/50] - Loss: 0.3881
Epoch [29/50] - Loss: 0.3837
Epoch [30/50] - Loss: 0.3794
Epoch [31/50] - Loss: 0.3752
Epoch [32/50] - Loss: 0.3709
Epoch [33/50] - Loss: 0.3666
Epoch [34/50] - Loss: 0.3623
Epoch [35/50] - Loss: 0.3580
Epoch [36/50] - Loss: 0.3537
Epoch [37/50] - Loss: 0.3494
Epoch [38/50] - Loss: 0.3452
Epoch [39/50] - Loss: 0.3409
Epoch [40/50] - Loss: 0.3367
Epoch [41/50] - Loss: 0.3325
Epoch [42/50] - Loss: 0.3283
Epoch [43/50] - Loss: 0.3242
Epoch [44/50] - Loss: 0.3201
Epoch [45/50] - Loss: 0.3160
Epoch [46/50] - Loss: 0.3120
Epoch [47/50] - Loss: 0.3080
Epoch [48/50] - Loss: 0.3041
Epoch [49/50] - Loss: 0.3002
Epoch [50/50] - Loss: 0.2964
sum preds 3765
sum labels 6300
 - Test Metrics: Accuracy=0.7956, F1=0.6315, Recall=0.5044, Precision=0.8441
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_nnpu_nnpu_1904035533.csv.
Average F1 over valid seeds: 0.6317 ± 0.0156
___________________________________________________________________________________
Avg F1 for pubmed with SAR and nnpu, GCNConv,0.2: 0.6317 ± 0.0156
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4996
Epoch [3/50] - Loss: 0.4989
Epoch [4/50] - Loss: 0.4981
Epoch [5/50] - Loss: 0.4971
Epoch [6/50] - Loss: 0.4960
Epoch [7/50] - Loss: 0.4948
Epoch [8/50] - Loss: 0.4934
Epoch [9/50] - Loss: 0.4918
Epoch [10/50] - Loss: 0.4901
Epoch [11/50] - Loss: 0.4882
Epoch [12/50] - Loss: 0.4863
Epoch [13/50] - Loss: 0.4842
Epoch [14/50] - Loss: 0.4819
Epoch [15/50] - Loss: 0.4795
Epoch [16/50] - Loss: 0.4769
Epoch [17/50] - Loss: 0.4741
Epoch [18/50] - Loss: 0.4712
Epoch [19/50] - Loss: 0.4682
Epoch [20/50] - Loss: 0.4650
Epoch [21/50] - Loss: 0.4616
Epoch [22/50] - Loss: 0.4580
Epoch [23/50] - Loss: 0.4543
Epoch [24/50] - Loss: 0.4504
Epoch [25/50] - Loss: 0.4463
Epoch [26/50] - Loss: 0.4421
Epoch [27/50] - Loss: 0.4377
Epoch [28/50] - Loss: 0.4332
Epoch [29/50] - Loss: 0.4285
Epoch [30/50] - Loss: 0.4236
Epoch [31/50] - Loss: 0.4186
Epoch [32/50] - Loss: 0.4135
Epoch [33/50] - Loss: 0.4082
Epoch [34/50] - Loss: 0.4029
Epoch [35/50] - Loss: 0.3974
Epoch [36/50] - Loss: 0.3918
Epoch [37/50] - Loss: 0.3861
Epoch [38/50] - Loss: 0.3804
Epoch [39/50] - Loss: 0.3746
Epoch [40/50] - Loss: 0.3687
Epoch [41/50] - Loss: 0.3628
Epoch [42/50] - Loss: 0.3569
Epoch [43/50] - Loss: 0.3510
Epoch [44/50] - Loss: 0.3451
Epoch [45/50] - Loss: 0.3392
Epoch [46/50] - Loss: 0.3333
Epoch [47/50] - Loss: 0.3275
Epoch [48/50] - Loss: 0.3217
Epoch [49/50] - Loss: 0.3160
Epoch [50/50] - Loss: 0.3103
sum preds 5517
sum labels 4725
 - Test Metrics: Accuracy=0.7960, F1=0.6700, Recall=0.7261, Precision=0.6219
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4989
Epoch [3/50] - Loss: 0.4978
Epoch [4/50] - Loss: 0.4966
Epoch [5/50] - Loss: 0.4953
Epoch [6/50] - Loss: 0.4939
Epoch [7/50] - Loss: 0.4924
Epoch [8/50] - Loss: 0.4907
Epoch [9/50] - Loss: 0.4889
Epoch [10/50] - Loss: 0.4870
Epoch [11/50] - Loss: 0.4849
Epoch [12/50] - Loss: 0.4827
Epoch [13/50] - Loss: 0.4803
Epoch [14/50] - Loss: 0.4778
Epoch [15/50] - Loss: 0.4751
Epoch [16/50] - Loss: 0.4723
Epoch [17/50] - Loss: 0.4693
Epoch [18/50] - Loss: 0.4662
Epoch [19/50] - Loss: 0.4629
Epoch [20/50] - Loss: 0.4595
Epoch [21/50] - Loss: 0.4559
Epoch [22/50] - Loss: 0.4521
Epoch [23/50] - Loss: 0.4482
Epoch [24/50] - Loss: 0.4441
Epoch [25/50] - Loss: 0.4399
Epoch [26/50] - Loss: 0.4355
Epoch [27/50] - Loss: 0.4309
Epoch [28/50] - Loss: 0.4262
Epoch [29/50] - Loss: 0.4214
Epoch [30/50] - Loss: 0.4164
Epoch [31/50] - Loss: 0.4113
Epoch [32/50] - Loss: 0.4061
Epoch [33/50] - Loss: 0.4007
Epoch [34/50] - Loss: 0.3953
Epoch [35/50] - Loss: 0.3897
Epoch [36/50] - Loss: 0.3841
Epoch [37/50] - Loss: 0.3784
Epoch [38/50] - Loss: 0.3726
Epoch [39/50] - Loss: 0.3668
Epoch [40/50] - Loss: 0.3609
Epoch [41/50] - Loss: 0.3550
Epoch [42/50] - Loss: 0.3492
Epoch [43/50] - Loss: 0.3433
Epoch [44/50] - Loss: 0.3374
Epoch [45/50] - Loss: 0.3316
Epoch [46/50] - Loss: 0.3258
Epoch [47/50] - Loss: 0.3200
Epoch [48/50] - Loss: 0.3144
Epoch [49/50] - Loss: 0.3087
Epoch [50/50] - Loss: 0.3032
sum preds 4887
sum labels 4725
 - Test Metrics: Accuracy=0.7969, F1=0.6500, Recall=0.6612, Precision=0.6392
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4989
Epoch [3/50] - Loss: 0.4976
Epoch [4/50] - Loss: 0.4962
Epoch [5/50] - Loss: 0.4947
Epoch [6/50] - Loss: 0.4930
Epoch [7/50] - Loss: 0.4912
Epoch [8/50] - Loss: 0.4892
Epoch [9/50] - Loss: 0.4871
Epoch [10/50] - Loss: 0.4848
Epoch [11/50] - Loss: 0.4824
Epoch [12/50] - Loss: 0.4798
Epoch [13/50] - Loss: 0.4771
Epoch [14/50] - Loss: 0.4742
Epoch [15/50] - Loss: 0.4711
Epoch [16/50] - Loss: 0.4679
Epoch [17/50] - Loss: 0.4645
Epoch [18/50] - Loss: 0.4609
Epoch [19/50] - Loss: 0.4572
Epoch [20/50] - Loss: 0.4533
Epoch [21/50] - Loss: 0.4493
Epoch [22/50] - Loss: 0.4451
Epoch [23/50] - Loss: 0.4408
Epoch [24/50] - Loss: 0.4363
Epoch [25/50] - Loss: 0.4316
Epoch [26/50] - Loss: 0.4268
Epoch [27/50] - Loss: 0.4219
Epoch [28/50] - Loss: 0.4168
Epoch [29/50] - Loss: 0.4116
Epoch [30/50] - Loss: 0.4062
Epoch [31/50] - Loss: 0.4008
Epoch [32/50] - Loss: 0.3952
Epoch [33/50] - Loss: 0.3896
Epoch [34/50] - Loss: 0.3838
Epoch [35/50] - Loss: 0.3780
Epoch [36/50] - Loss: 0.3721
Epoch [37/50] - Loss: 0.3662
Epoch [38/50] - Loss: 0.3602
Epoch [39/50] - Loss: 0.3542
Epoch [40/50] - Loss: 0.3482
Epoch [41/50] - Loss: 0.3422
Epoch [42/50] - Loss: 0.3362
Epoch [43/50] - Loss: 0.3302
Epoch [44/50] - Loss: 0.3243
Epoch [45/50] - Loss: 0.3184
Epoch [46/50] - Loss: 0.3126
Epoch [47/50] - Loss: 0.3069
Epoch [48/50] - Loss: 0.3012
Epoch [49/50] - Loss: 0.2957
Epoch [50/50] - Loss: 0.2902
sum preds 5068
sum labels 4725
 - Test Metrics: Accuracy=0.8009, F1=0.6631, Recall=0.6872, Precision=0.6407
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_imbnnpu_imbnnpu_1904035537.csv.
Average F1 over valid seeds: 0.6610 ± 0.0083
___________________________________________________________________________________
Avg F1 for pubmed with SAR and imbnnpu, MLP,0.4: 0.6610 ± 0.0083
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4985
Epoch [3/50] - Loss: 0.4968
Epoch [4/50] - Loss: 0.4947
Epoch [5/50] - Loss: 0.4923
Epoch [6/50] - Loss: 0.4898
Epoch [7/50] - Loss: 0.4871
Epoch [8/50] - Loss: 0.4843
Epoch [9/50] - Loss: 0.4814
Epoch [10/50] - Loss: 0.4784
Epoch [11/50] - Loss: 0.4753
Epoch [12/50] - Loss: 0.4720
Epoch [13/50] - Loss: 0.4686
Epoch [14/50] - Loss: 0.4651
Epoch [15/50] - Loss: 0.4615
Epoch [16/50] - Loss: 0.4578
Epoch [17/50] - Loss: 0.4540
Epoch [18/50] - Loss: 0.4501
Epoch [19/50] - Loss: 0.4460
Epoch [20/50] - Loss: 0.4419
Epoch [21/50] - Loss: 0.4376
Epoch [22/50] - Loss: 0.4331
Epoch [23/50] - Loss: 0.4285
Epoch [24/50] - Loss: 0.4239
Epoch [25/50] - Loss: 0.4191
Epoch [26/50] - Loss: 0.4142
Epoch [27/50] - Loss: 0.4091
Epoch [28/50] - Loss: 0.4040
Epoch [29/50] - Loss: 0.3988
Epoch [30/50] - Loss: 0.3935
Epoch [31/50] - Loss: 0.3880
Epoch [32/50] - Loss: 0.3825
Epoch [33/50] - Loss: 0.3769
Epoch [34/50] - Loss: 0.3713
Epoch [35/50] - Loss: 0.3655
Epoch [36/50] - Loss: 0.3597
Epoch [37/50] - Loss: 0.3539
Epoch [38/50] - Loss: 0.3480
Epoch [39/50] - Loss: 0.3421
Epoch [40/50] - Loss: 0.3361
Epoch [41/50] - Loss: 0.3302
Epoch [42/50] - Loss: 0.3242
Epoch [43/50] - Loss: 0.3183
Epoch [44/50] - Loss: 0.3124
Epoch [45/50] - Loss: 0.3065
Epoch [46/50] - Loss: 0.3007
Epoch [47/50] - Loss: 0.2949
Epoch [48/50] - Loss: 0.2892
Epoch [49/50] - Loss: 0.2836
Epoch [50/50] - Loss: 0.2780
sum preds 4706
sum labels 4725
 - Test Metrics: Accuracy=0.8292, F1=0.7000, Recall=0.6986, Precision=0.7014
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4983
Epoch [3/50] - Loss: 0.4963
Epoch [4/50] - Loss: 0.4940
Epoch [5/50] - Loss: 0.4913
Epoch [6/50] - Loss: 0.4883
Epoch [7/50] - Loss: 0.4850
Epoch [8/50] - Loss: 0.4816
Epoch [9/50] - Loss: 0.4781
Epoch [10/50] - Loss: 0.4745
Epoch [11/50] - Loss: 0.4708
Epoch [12/50] - Loss: 0.4667
Epoch [13/50] - Loss: 0.4623
Epoch [14/50] - Loss: 0.4577
Epoch [15/50] - Loss: 0.4529
Epoch [16/50] - Loss: 0.4482
Epoch [17/50] - Loss: 0.4435
Epoch [18/50] - Loss: 0.4386
Epoch [19/50] - Loss: 0.4336
Epoch [20/50] - Loss: 0.4285
Epoch [21/50] - Loss: 0.4232
Epoch [22/50] - Loss: 0.4178
Epoch [23/50] - Loss: 0.4123
Epoch [24/50] - Loss: 0.4066
Epoch [25/50] - Loss: 0.4009
Epoch [26/50] - Loss: 0.3951
Epoch [27/50] - Loss: 0.3892
Epoch [28/50] - Loss: 0.3832
Epoch [29/50] - Loss: 0.3772
Epoch [30/50] - Loss: 0.3712
Epoch [31/50] - Loss: 0.3650
Epoch [32/50] - Loss: 0.3588
Epoch [33/50] - Loss: 0.3526
Epoch [34/50] - Loss: 0.3463
Epoch [35/50] - Loss: 0.3400
Epoch [36/50] - Loss: 0.3336
Epoch [37/50] - Loss: 0.3273
Epoch [38/50] - Loss: 0.3209
Epoch [39/50] - Loss: 0.3145
Epoch [40/50] - Loss: 0.3082
Epoch [41/50] - Loss: 0.3018
Epoch [42/50] - Loss: 0.2955
Epoch [43/50] - Loss: 0.2893
Epoch [44/50] - Loss: 0.2831
Epoch [45/50] - Loss: 0.2769
Epoch [46/50] - Loss: 0.2708
Epoch [47/50] - Loss: 0.2648
Epoch [48/50] - Loss: 0.2589
Epoch [49/50] - Loss: 0.2531
Epoch [50/50] - Loss: 0.2474
sum preds 4540
sum labels 4725
 - Test Metrics: Accuracy=0.8370, F1=0.7085, Recall=0.6946, Precision=0.7229
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4976
Epoch [3/50] - Loss: 0.4957
Epoch [4/50] - Loss: 0.4934
Epoch [5/50] - Loss: 0.4906
Epoch [6/50] - Loss: 0.4876
Epoch [7/50] - Loss: 0.4844
Epoch [8/50] - Loss: 0.4812
Epoch [9/50] - Loss: 0.4778
Epoch [10/50] - Loss: 0.4743
Epoch [11/50] - Loss: 0.4706
Epoch [12/50] - Loss: 0.4669
Epoch [13/50] - Loss: 0.4630
Epoch [14/50] - Loss: 0.4589
Epoch [15/50] - Loss: 0.4547
Epoch [16/50] - Loss: 0.4504
Epoch [17/50] - Loss: 0.4458
Epoch [18/50] - Loss: 0.4409
Epoch [19/50] - Loss: 0.4359
Epoch [20/50] - Loss: 0.4305
Epoch [21/50] - Loss: 0.4251
Epoch [22/50] - Loss: 0.4196
Epoch [23/50] - Loss: 0.4141
Epoch [24/50] - Loss: 0.4085
Epoch [25/50] - Loss: 0.4028
Epoch [26/50] - Loss: 0.3970
Epoch [27/50] - Loss: 0.3910
Epoch [28/50] - Loss: 0.3850
Epoch [29/50] - Loss: 0.3789
Epoch [30/50] - Loss: 0.3727
Epoch [31/50] - Loss: 0.3664
Epoch [32/50] - Loss: 0.3601
Epoch [33/50] - Loss: 0.3537
Epoch [34/50] - Loss: 0.3473
Epoch [35/50] - Loss: 0.3409
Epoch [36/50] - Loss: 0.3344
Epoch [37/50] - Loss: 0.3280
Epoch [38/50] - Loss: 0.3217
Epoch [39/50] - Loss: 0.3153
Epoch [40/50] - Loss: 0.3089
Epoch [41/50] - Loss: 0.3027
Epoch [42/50] - Loss: 0.2964
Epoch [43/50] - Loss: 0.2903
Epoch [44/50] - Loss: 0.2842
Epoch [45/50] - Loss: 0.2782
Epoch [46/50] - Loss: 0.2722
Epoch [47/50] - Loss: 0.2664
Epoch [48/50] - Loss: 0.2606
Epoch [49/50] - Loss: 0.2550
Epoch [50/50] - Loss: 0.2494
sum preds 4935
sum labels 4725
 - Test Metrics: Accuracy=0.8287, F1=0.7062, Recall=0.7219, Precision=0.6912
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_imbnnpu_imbnnpu_1904035540.csv.
Average F1 over valid seeds: 0.7049 ± 0.0036
___________________________________________________________________________________
Avg F1 for pubmed with SAR and imbnnpu, GATConv,0.4: 0.7049 ± 0.0036
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4988
Epoch [3/50] - Loss: 0.4972
Epoch [4/50] - Loss: 0.4955
Epoch [5/50] - Loss: 0.4935
Epoch [6/50] - Loss: 0.4913
Epoch [7/50] - Loss: 0.4891
Epoch [8/50] - Loss: 0.4867
Epoch [9/50] - Loss: 0.4841
Epoch [10/50] - Loss: 0.4813
Epoch [11/50] - Loss: 0.4781
Epoch [12/50] - Loss: 0.4748
Epoch [13/50] - Loss: 0.4713
Epoch [14/50] - Loss: 0.4679
Epoch [15/50] - Loss: 0.4644
Epoch [16/50] - Loss: 0.4610
Epoch [17/50] - Loss: 0.4574
Epoch [18/50] - Loss: 0.4537
Epoch [19/50] - Loss: 0.4500
Epoch [20/50] - Loss: 0.4461
Epoch [21/50] - Loss: 0.4421
Epoch [22/50] - Loss: 0.4381
Epoch [23/50] - Loss: 0.4340
Epoch [24/50] - Loss: 0.4297
Epoch [25/50] - Loss: 0.4254
Epoch [26/50] - Loss: 0.4211
Epoch [27/50] - Loss: 0.4167
Epoch [28/50] - Loss: 0.4122
Epoch [29/50] - Loss: 0.4077
Epoch [30/50] - Loss: 0.4031
Epoch [31/50] - Loss: 0.3985
Epoch [32/50] - Loss: 0.3938
Epoch [33/50] - Loss: 0.3891
Epoch [34/50] - Loss: 0.3844
Epoch [35/50] - Loss: 0.3796
Epoch [36/50] - Loss: 0.3748
Epoch [37/50] - Loss: 0.3700
Epoch [38/50] - Loss: 0.3652
Epoch [39/50] - Loss: 0.3603
Epoch [40/50] - Loss: 0.3555
Epoch [41/50] - Loss: 0.3507
Epoch [42/50] - Loss: 0.3459
Epoch [43/50] - Loss: 0.3411
Epoch [44/50] - Loss: 0.3363
Epoch [45/50] - Loss: 0.3315
Epoch [46/50] - Loss: 0.3268
Epoch [47/50] - Loss: 0.3221
Epoch [48/50] - Loss: 0.3174
Epoch [49/50] - Loss: 0.3128
Epoch [50/50] - Loss: 0.3082
sum preds 4774
sum labels 4725
 - Test Metrics: Accuracy=0.8385, F1=0.7184, Recall=0.7221, Precision=0.7147
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4987
Epoch [3/50] - Loss: 0.4970
Epoch [4/50] - Loss: 0.4952
Epoch [5/50] - Loss: 0.4931
Epoch [6/50] - Loss: 0.4907
Epoch [7/50] - Loss: 0.4881
Epoch [8/50] - Loss: 0.4854
Epoch [9/50] - Loss: 0.4825
Epoch [10/50] - Loss: 0.4795
Epoch [11/50] - Loss: 0.4763
Epoch [12/50] - Loss: 0.4730
Epoch [13/50] - Loss: 0.4695
Epoch [14/50] - Loss: 0.4661
Epoch [15/50] - Loss: 0.4626
Epoch [16/50] - Loss: 0.4590
Epoch [17/50] - Loss: 0.4553
Epoch [18/50] - Loss: 0.4515
Epoch [19/50] - Loss: 0.4476
Epoch [20/50] - Loss: 0.4436
Epoch [21/50] - Loss: 0.4395
Epoch [22/50] - Loss: 0.4353
Epoch [23/50] - Loss: 0.4311
Epoch [24/50] - Loss: 0.4268
Epoch [25/50] - Loss: 0.4224
Epoch [26/50] - Loss: 0.4179
Epoch [27/50] - Loss: 0.4134
Epoch [28/50] - Loss: 0.4088
Epoch [29/50] - Loss: 0.4042
Epoch [30/50] - Loss: 0.3995
Epoch [31/50] - Loss: 0.3948
Epoch [32/50] - Loss: 0.3900
Epoch [33/50] - Loss: 0.3852
Epoch [34/50] - Loss: 0.3804
Epoch [35/50] - Loss: 0.3755
Epoch [36/50] - Loss: 0.3706
Epoch [37/50] - Loss: 0.3657
Epoch [38/50] - Loss: 0.3608
Epoch [39/50] - Loss: 0.3559
Epoch [40/50] - Loss: 0.3510
Epoch [41/50] - Loss: 0.3461
Epoch [42/50] - Loss: 0.3412
Epoch [43/50] - Loss: 0.3364
Epoch [44/50] - Loss: 0.3315
Epoch [45/50] - Loss: 0.3267
Epoch [46/50] - Loss: 0.3220
Epoch [47/50] - Loss: 0.3172
Epoch [48/50] - Loss: 0.3125
Epoch [49/50] - Loss: 0.3079
Epoch [50/50] - Loss: 0.3033
sum preds 4611
sum labels 4725
 - Test Metrics: Accuracy=0.8426, F1=0.7207, Recall=0.7120, Precision=0.7296
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4998
Epoch [2/50] - Loss: 0.4976
Epoch [3/50] - Loss: 0.4957
Epoch [4/50] - Loss: 0.4937
Epoch [5/50] - Loss: 0.4914
Epoch [6/50] - Loss: 0.4887
Epoch [7/50] - Loss: 0.4856
Epoch [8/50] - Loss: 0.4825
Epoch [9/50] - Loss: 0.4793
Epoch [10/50] - Loss: 0.4761
Epoch [11/50] - Loss: 0.4729
Epoch [12/50] - Loss: 0.4696
Epoch [13/50] - Loss: 0.4662
Epoch [14/50] - Loss: 0.4627
Epoch [15/50] - Loss: 0.4591
Epoch [16/50] - Loss: 0.4554
Epoch [17/50] - Loss: 0.4516
Epoch [18/50] - Loss: 0.4477
Epoch [19/50] - Loss: 0.4438
Epoch [20/50] - Loss: 0.4397
Epoch [21/50] - Loss: 0.4356
Epoch [22/50] - Loss: 0.4314
Epoch [23/50] - Loss: 0.4271
Epoch [24/50] - Loss: 0.4228
Epoch [25/50] - Loss: 0.4184
Epoch [26/50] - Loss: 0.4139
Epoch [27/50] - Loss: 0.4094
Epoch [28/50] - Loss: 0.4048
Epoch [29/50] - Loss: 0.4002
Epoch [30/50] - Loss: 0.3955
Epoch [31/50] - Loss: 0.3908
Epoch [32/50] - Loss: 0.3860
Epoch [33/50] - Loss: 0.3812
Epoch [34/50] - Loss: 0.3764
Epoch [35/50] - Loss: 0.3716
Epoch [36/50] - Loss: 0.3668
Epoch [37/50] - Loss: 0.3618
Epoch [38/50] - Loss: 0.3569
Epoch [39/50] - Loss: 0.3519
Epoch [40/50] - Loss: 0.3470
Epoch [41/50] - Loss: 0.3420
Epoch [42/50] - Loss: 0.3372
Epoch [43/50] - Loss: 0.3323
Epoch [44/50] - Loss: 0.3275
Epoch [45/50] - Loss: 0.3228
Epoch [46/50] - Loss: 0.3180
Epoch [47/50] - Loss: 0.3133
Epoch [48/50] - Loss: 0.3087
Epoch [49/50] - Loss: 0.3040
Epoch [50/50] - Loss: 0.2995
sum preds 4624
sum labels 4725
 - Test Metrics: Accuracy=0.8368, F1=0.7109, Recall=0.7033, Precision=0.7186
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_imbnnpu_imbnnpu_1904035545.csv.
Average F1 over valid seeds: 0.7166 ± 0.0042
___________________________________________________________________________________
Avg F1 for pubmed with SAR and imbnnpu, GCNConv,0.4: 0.7166 ± 0.0042
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4996
Epoch [3/50] - Loss: 0.4990
Epoch [4/50] - Loss: 0.4982
Epoch [5/50] - Loss: 0.4973
Epoch [6/50] - Loss: 0.4962
Epoch [7/50] - Loss: 0.4950
Epoch [8/50] - Loss: 0.4937
Epoch [9/50] - Loss: 0.4922
Epoch [10/50] - Loss: 0.4906
Epoch [11/50] - Loss: 0.4889
Epoch [12/50] - Loss: 0.4870
Epoch [13/50] - Loss: 0.4850
Epoch [14/50] - Loss: 0.4828
Epoch [15/50] - Loss: 0.4805
Epoch [16/50] - Loss: 0.4780
Epoch [17/50] - Loss: 0.4754
Epoch [18/50] - Loss: 0.4727
Epoch [19/50] - Loss: 0.4698
Epoch [20/50] - Loss: 0.4667
Epoch [21/50] - Loss: 0.4634
Epoch [22/50] - Loss: 0.4600
Epoch [23/50] - Loss: 0.4565
Epoch [24/50] - Loss: 0.4528
Epoch [25/50] - Loss: 0.4489
Epoch [26/50] - Loss: 0.4449
Epoch [27/50] - Loss: 0.4407
Epoch [28/50] - Loss: 0.4363
Epoch [29/50] - Loss: 0.4318
Epoch [30/50] - Loss: 0.4272
Epoch [31/50] - Loss: 0.4224
Epoch [32/50] - Loss: 0.4175
Epoch [33/50] - Loss: 0.4125
Epoch [34/50] - Loss: 0.4073
Epoch [35/50] - Loss: 0.4021
Epoch [36/50] - Loss: 0.3968
Epoch [37/50] - Loss: 0.3913
Epoch [38/50] - Loss: 0.3859
Epoch [39/50] - Loss: 0.3803
Epoch [40/50] - Loss: 0.3747
Epoch [41/50] - Loss: 0.3691
Epoch [42/50] - Loss: 0.3634
Epoch [43/50] - Loss: 0.3578
Epoch [44/50] - Loss: 0.3521
Epoch [45/50] - Loss: 0.3465
Epoch [46/50] - Loss: 0.3408
Epoch [47/50] - Loss: 0.3353
Epoch [48/50] - Loss: 0.3297
Epoch [49/50] - Loss: 0.3243
Epoch [50/50] - Loss: 0.3189
sum preds 6002
sum labels 5513
 - Test Metrics: Accuracy=0.7969, F1=0.6939, Recall=0.7247, Precision=0.6656
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4989
Epoch [3/50] - Loss: 0.4979
Epoch [4/50] - Loss: 0.4967
Epoch [5/50] - Loss: 0.4954
Epoch [6/50] - Loss: 0.4940
Epoch [7/50] - Loss: 0.4925
Epoch [8/50] - Loss: 0.4908
Epoch [9/50] - Loss: 0.4890
Epoch [10/50] - Loss: 0.4871
Epoch [11/50] - Loss: 0.4850
Epoch [12/50] - Loss: 0.4828
Epoch [13/50] - Loss: 0.4804
Epoch [14/50] - Loss: 0.4779
Epoch [15/50] - Loss: 0.4752
Epoch [16/50] - Loss: 0.4724
Epoch [17/50] - Loss: 0.4694
Epoch [18/50] - Loss: 0.4663
Epoch [19/50] - Loss: 0.4630
Epoch [20/50] - Loss: 0.4595
Epoch [21/50] - Loss: 0.4559
Epoch [22/50] - Loss: 0.4521
Epoch [23/50] - Loss: 0.4481
Epoch [24/50] - Loss: 0.4440
Epoch [25/50] - Loss: 0.4397
Epoch [26/50] - Loss: 0.4353
Epoch [27/50] - Loss: 0.4307
Epoch [28/50] - Loss: 0.4259
Epoch [29/50] - Loss: 0.4210
Epoch [30/50] - Loss: 0.4160
Epoch [31/50] - Loss: 0.4108
Epoch [32/50] - Loss: 0.4055
Epoch [33/50] - Loss: 0.4001
Epoch [34/50] - Loss: 0.3946
Epoch [35/50] - Loss: 0.3890
Epoch [36/50] - Loss: 0.3833
Epoch [37/50] - Loss: 0.3776
Epoch [38/50] - Loss: 0.3718
Epoch [39/50] - Loss: 0.3660
Epoch [40/50] - Loss: 0.3601
Epoch [41/50] - Loss: 0.3542
Epoch [42/50] - Loss: 0.3484
Epoch [43/50] - Loss: 0.3425
Epoch [44/50] - Loss: 0.3367
Epoch [45/50] - Loss: 0.3309
Epoch [46/50] - Loss: 0.3252
Epoch [47/50] - Loss: 0.3195
Epoch [48/50] - Loss: 0.3139
Epoch [49/50] - Loss: 0.3084
Epoch [50/50] - Loss: 0.3030
sum preds 5225
sum labels 5513
 - Test Metrics: Accuracy=0.7910, F1=0.6621, Recall=0.6448, Precision=0.6804
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4989
Epoch [3/50] - Loss: 0.4977
Epoch [4/50] - Loss: 0.4963
Epoch [5/50] - Loss: 0.4949
Epoch [6/50] - Loss: 0.4932
Epoch [7/50] - Loss: 0.4914
Epoch [8/50] - Loss: 0.4895
Epoch [9/50] - Loss: 0.4875
Epoch [10/50] - Loss: 0.4853
Epoch [11/50] - Loss: 0.4830
Epoch [12/50] - Loss: 0.4805
Epoch [13/50] - Loss: 0.4778
Epoch [14/50] - Loss: 0.4750
Epoch [15/50] - Loss: 0.4720
Epoch [16/50] - Loss: 0.4688
Epoch [17/50] - Loss: 0.4655
Epoch [18/50] - Loss: 0.4621
Epoch [19/50] - Loss: 0.4585
Epoch [20/50] - Loss: 0.4547
Epoch [21/50] - Loss: 0.4508
Epoch [22/50] - Loss: 0.4467
Epoch [23/50] - Loss: 0.4425
Epoch [24/50] - Loss: 0.4381
Epoch [25/50] - Loss: 0.4336
Epoch [26/50] - Loss: 0.4289
Epoch [27/50] - Loss: 0.4241
Epoch [28/50] - Loss: 0.4191
Epoch [29/50] - Loss: 0.4141
Epoch [30/50] - Loss: 0.4089
Epoch [31/50] - Loss: 0.4036
Epoch [32/50] - Loss: 0.3981
Epoch [33/50] - Loss: 0.3926
Epoch [34/50] - Loss: 0.3870
Epoch [35/50] - Loss: 0.3814
Epoch [36/50] - Loss: 0.3757
Epoch [37/50] - Loss: 0.3699
Epoch [38/50] - Loss: 0.3641
Epoch [39/50] - Loss: 0.3582
Epoch [40/50] - Loss: 0.3524
Epoch [41/50] - Loss: 0.3465
Epoch [42/50] - Loss: 0.3407
Epoch [43/50] - Loss: 0.3349
Epoch [44/50] - Loss: 0.3291
Epoch [45/50] - Loss: 0.3234
Epoch [46/50] - Loss: 0.3178
Epoch [47/50] - Loss: 0.3122
Epoch [48/50] - Loss: 0.3067
Epoch [49/50] - Loss: 0.3013
Epoch [50/50] - Loss: 0.2960
sum preds 5519
sum labels 5513
 - Test Metrics: Accuracy=0.7945, F1=0.6768, Recall=0.6771, Precision=0.6764
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_imbnnpu_imbnnpu_1904035549.csv.
Average F1 over valid seeds: 0.6776 ± 0.0130
___________________________________________________________________________________
Avg F1 for pubmed with SAR and imbnnpu, MLP,0.3: 0.6776 ± 0.0130
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4986
Epoch [3/50] - Loss: 0.4969
Epoch [4/50] - Loss: 0.4949
Epoch [5/50] - Loss: 0.4926
Epoch [6/50] - Loss: 0.4902
Epoch [7/50] - Loss: 0.4877
Epoch [8/50] - Loss: 0.4850
Epoch [9/50] - Loss: 0.4823
Epoch [10/50] - Loss: 0.4795
Epoch [11/50] - Loss: 0.4765
Epoch [12/50] - Loss: 0.4734
Epoch [13/50] - Loss: 0.4702
Epoch [14/50] - Loss: 0.4669
Epoch [15/50] - Loss: 0.4634
Epoch [16/50] - Loss: 0.4599
Epoch [17/50] - Loss: 0.4563
Epoch [18/50] - Loss: 0.4525
Epoch [19/50] - Loss: 0.4486
Epoch [20/50] - Loss: 0.4447
Epoch [21/50] - Loss: 0.4406
Epoch [22/50] - Loss: 0.4363
Epoch [23/50] - Loss: 0.4320
Epoch [24/50] - Loss: 0.4276
Epoch [25/50] - Loss: 0.4230
Epoch [26/50] - Loss: 0.4183
Epoch [27/50] - Loss: 0.4136
Epoch [28/50] - Loss: 0.4087
Epoch [29/50] - Loss: 0.4037
Epoch [30/50] - Loss: 0.3986
Epoch [31/50] - Loss: 0.3934
Epoch [32/50] - Loss: 0.3882
Epoch [33/50] - Loss: 0.3829
Epoch [34/50] - Loss: 0.3775
Epoch [35/50] - Loss: 0.3720
Epoch [36/50] - Loss: 0.3665
Epoch [37/50] - Loss: 0.3609
Epoch [38/50] - Loss: 0.3554
Epoch [39/50] - Loss: 0.3497
Epoch [40/50] - Loss: 0.3441
Epoch [41/50] - Loss: 0.3384
Epoch [42/50] - Loss: 0.3328
Epoch [43/50] - Loss: 0.3272
Epoch [44/50] - Loss: 0.3216
Epoch [45/50] - Loss: 0.3160
Epoch [46/50] - Loss: 0.3105
Epoch [47/50] - Loss: 0.3051
Epoch [48/50] - Loss: 0.2997
Epoch [49/50] - Loss: 0.2943
Epoch [50/50] - Loss: 0.2891
sum preds 5358
sum labels 5513
 - Test Metrics: Accuracy=0.8224, F1=0.7164, Recall=0.7063, Precision=0.7268
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4984
Epoch [3/50] - Loss: 0.4965
Epoch [4/50] - Loss: 0.4942
Epoch [5/50] - Loss: 0.4916
Epoch [6/50] - Loss: 0.4885
Epoch [7/50] - Loss: 0.4853
Epoch [8/50] - Loss: 0.4820
Epoch [9/50] - Loss: 0.4787
Epoch [10/50] - Loss: 0.4753
Epoch [11/50] - Loss: 0.4716
Epoch [12/50] - Loss: 0.4677
Epoch [13/50] - Loss: 0.4635
Epoch [14/50] - Loss: 0.4591
Epoch [15/50] - Loss: 0.4545
Epoch [16/50] - Loss: 0.4499
Epoch [17/50] - Loss: 0.4453
Epoch [18/50] - Loss: 0.4406
Epoch [19/50] - Loss: 0.4357
Epoch [20/50] - Loss: 0.4308
Epoch [21/50] - Loss: 0.4257
Epoch [22/50] - Loss: 0.4204
Epoch [23/50] - Loss: 0.4151
Epoch [24/50] - Loss: 0.4097
Epoch [25/50] - Loss: 0.4041
Epoch [26/50] - Loss: 0.3985
Epoch [27/50] - Loss: 0.3928
Epoch [28/50] - Loss: 0.3871
Epoch [29/50] - Loss: 0.3812
Epoch [30/50] - Loss: 0.3754
Epoch [31/50] - Loss: 0.3695
Epoch [32/50] - Loss: 0.3635
Epoch [33/50] - Loss: 0.3575
Epoch [34/50] - Loss: 0.3514
Epoch [35/50] - Loss: 0.3454
Epoch [36/50] - Loss: 0.3392
Epoch [37/50] - Loss: 0.3331
Epoch [38/50] - Loss: 0.3270
Epoch [39/50] - Loss: 0.3209
Epoch [40/50] - Loss: 0.3148
Epoch [41/50] - Loss: 0.3087
Epoch [42/50] - Loss: 0.3026
Epoch [43/50] - Loss: 0.2966
Epoch [44/50] - Loss: 0.2907
Epoch [45/50] - Loss: 0.2847
Epoch [46/50] - Loss: 0.2789
Epoch [47/50] - Loss: 0.2731
Epoch [48/50] - Loss: 0.2675
Epoch [49/50] - Loss: 0.2619
Epoch [50/50] - Loss: 0.2564
sum preds 5044
sum labels 5513
 - Test Metrics: Accuracy=0.8287, F1=0.7184, Recall=0.6878, Precision=0.7518
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4976
Epoch [3/50] - Loss: 0.4958
Epoch [4/50] - Loss: 0.4935
Epoch [5/50] - Loss: 0.4908
Epoch [6/50] - Loss: 0.4878
Epoch [7/50] - Loss: 0.4847
Epoch [8/50] - Loss: 0.4816
Epoch [9/50] - Loss: 0.4783
Epoch [10/50] - Loss: 0.4749
Epoch [11/50] - Loss: 0.4713
Epoch [12/50] - Loss: 0.4675
Epoch [13/50] - Loss: 0.4636
Epoch [14/50] - Loss: 0.4594
Epoch [15/50] - Loss: 0.4550
Epoch [16/50] - Loss: 0.4504
Epoch [17/50] - Loss: 0.4456
Epoch [18/50] - Loss: 0.4407
Epoch [19/50] - Loss: 0.4358
Epoch [20/50] - Loss: 0.4309
Epoch [21/50] - Loss: 0.4258
Epoch [22/50] - Loss: 0.4205
Epoch [23/50] - Loss: 0.4152
Epoch [24/50] - Loss: 0.4097
Epoch [25/50] - Loss: 0.4040
Epoch [26/50] - Loss: 0.3983
Epoch [27/50] - Loss: 0.3925
Epoch [28/50] - Loss: 0.3866
Epoch [29/50] - Loss: 0.3806
Epoch [30/50] - Loss: 0.3745
Epoch [31/50] - Loss: 0.3684
Epoch [32/50] - Loss: 0.3622
Epoch [33/50] - Loss: 0.3560
Epoch [34/50] - Loss: 0.3498
Epoch [35/50] - Loss: 0.3436
Epoch [36/50] - Loss: 0.3373
Epoch [37/50] - Loss: 0.3311
Epoch [38/50] - Loss: 0.3248
Epoch [39/50] - Loss: 0.3186
Epoch [40/50] - Loss: 0.3125
Epoch [41/50] - Loss: 0.3063
Epoch [42/50] - Loss: 0.3002
Epoch [43/50] - Loss: 0.2941
Epoch [44/50] - Loss: 0.2881
Epoch [45/50] - Loss: 0.2821
Epoch [46/50] - Loss: 0.2763
Epoch [47/50] - Loss: 0.2706
Epoch [48/50] - Loss: 0.2651
Epoch [49/50] - Loss: 0.2596
Epoch [50/50] - Loss: 0.2542
sum preds 5396
sum labels 5513
 - Test Metrics: Accuracy=0.8218, F1=0.7165, Recall=0.7089, Precision=0.7242
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_imbnnpu_imbnnpu_1904035552.csv.
Average F1 over valid seeds: 0.7171 ± 0.0009
___________________________________________________________________________________
Avg F1 for pubmed with SAR and imbnnpu, GATConv,0.3: 0.7171 ± 0.0009
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5004
Epoch [2/50] - Loss: 0.4988
Epoch [3/50] - Loss: 0.4973
Epoch [4/50] - Loss: 0.4956
Epoch [5/50] - Loss: 0.4937
Epoch [6/50] - Loss: 0.4916
Epoch [7/50] - Loss: 0.4895
Epoch [8/50] - Loss: 0.4872
Epoch [9/50] - Loss: 0.4847
Epoch [10/50] - Loss: 0.4820
Epoch [11/50] - Loss: 0.4791
Epoch [12/50] - Loss: 0.4759
Epoch [13/50] - Loss: 0.4727
Epoch [14/50] - Loss: 0.4694
Epoch [15/50] - Loss: 0.4661
Epoch [16/50] - Loss: 0.4628
Epoch [17/50] - Loss: 0.4594
Epoch [18/50] - Loss: 0.4559
Epoch [19/50] - Loss: 0.4523
Epoch [20/50] - Loss: 0.4487
Epoch [21/50] - Loss: 0.4449
Epoch [22/50] - Loss: 0.4411
Epoch [23/50] - Loss: 0.4371
Epoch [24/50] - Loss: 0.4331
Epoch [25/50] - Loss: 0.4291
Epoch [26/50] - Loss: 0.4249
Epoch [27/50] - Loss: 0.4208
Epoch [28/50] - Loss: 0.4165
Epoch [29/50] - Loss: 0.4122
Epoch [30/50] - Loss: 0.4079
Epoch [31/50] - Loss: 0.4035
Epoch [32/50] - Loss: 0.3991
Epoch [33/50] - Loss: 0.3946
Epoch [34/50] - Loss: 0.3901
Epoch [35/50] - Loss: 0.3856
Epoch [36/50] - Loss: 0.3810
Epoch [37/50] - Loss: 0.3765
Epoch [38/50] - Loss: 0.3719
Epoch [39/50] - Loss: 0.3673
Epoch [40/50] - Loss: 0.3627
Epoch [41/50] - Loss: 0.3581
Epoch [42/50] - Loss: 0.3535
Epoch [43/50] - Loss: 0.3489
Epoch [44/50] - Loss: 0.3444
Epoch [45/50] - Loss: 0.3399
Epoch [46/50] - Loss: 0.3353
Epoch [47/50] - Loss: 0.3309
Epoch [48/50] - Loss: 0.3264
Epoch [49/50] - Loss: 0.3220
Epoch [50/50] - Loss: 0.3177
sum preds 5466
sum labels 5513
 - Test Metrics: Accuracy=0.8338, F1=0.7372, Recall=0.7341, Precision=0.7404
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4987
Epoch [3/50] - Loss: 0.4971
Epoch [4/50] - Loss: 0.4953
Epoch [5/50] - Loss: 0.4933
Epoch [6/50] - Loss: 0.4910
Epoch [7/50] - Loss: 0.4885
Epoch [8/50] - Loss: 0.4859
Epoch [9/50] - Loss: 0.4832
Epoch [10/50] - Loss: 0.4803
Epoch [11/50] - Loss: 0.4772
Epoch [12/50] - Loss: 0.4740
Epoch [13/50] - Loss: 0.4707
Epoch [14/50] - Loss: 0.4674
Epoch [15/50] - Loss: 0.4640
Epoch [16/50] - Loss: 0.4605
Epoch [17/50] - Loss: 0.4570
Epoch [18/50] - Loss: 0.4533
Epoch [19/50] - Loss: 0.4496
Epoch [20/50] - Loss: 0.4457
Epoch [21/50] - Loss: 0.4418
Epoch [22/50] - Loss: 0.4377
Epoch [23/50] - Loss: 0.4336
Epoch [24/50] - Loss: 0.4295
Epoch [25/50] - Loss: 0.4253
Epoch [26/50] - Loss: 0.4209
Epoch [27/50] - Loss: 0.4166
Epoch [28/50] - Loss: 0.4122
Epoch [29/50] - Loss: 0.4077
Epoch [30/50] - Loss: 0.4032
Epoch [31/50] - Loss: 0.3987
Epoch [32/50] - Loss: 0.3941
Epoch [33/50] - Loss: 0.3894
Epoch [34/50] - Loss: 0.3848
Epoch [35/50] - Loss: 0.3801
Epoch [36/50] - Loss: 0.3754
Epoch [37/50] - Loss: 0.3707
Epoch [38/50] - Loss: 0.3660
Epoch [39/50] - Loss: 0.3613
Epoch [40/50] - Loss: 0.3565
Epoch [41/50] - Loss: 0.3519
Epoch [42/50] - Loss: 0.3472
Epoch [43/50] - Loss: 0.3425
Epoch [44/50] - Loss: 0.3379
Epoch [45/50] - Loss: 0.3333
Epoch [46/50] - Loss: 0.3287
Epoch [47/50] - Loss: 0.3242
Epoch [48/50] - Loss: 0.3197
Epoch [49/50] - Loss: 0.3152
Epoch [50/50] - Loss: 0.3108
sum preds 5178
sum labels 5513
 - Test Metrics: Accuracy=0.8378, F1=0.7367, Recall=0.7143, Precision=0.7605
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4977
Epoch [3/50] - Loss: 0.4959
Epoch [4/50] - Loss: 0.4940
Epoch [5/50] - Loss: 0.4918
Epoch [6/50] - Loss: 0.4892
Epoch [7/50] - Loss: 0.4864
Epoch [8/50] - Loss: 0.4834
Epoch [9/50] - Loss: 0.4803
Epoch [10/50] - Loss: 0.4773
Epoch [11/50] - Loss: 0.4742
Epoch [12/50] - Loss: 0.4711
Epoch [13/50] - Loss: 0.4678
Epoch [14/50] - Loss: 0.4645
Epoch [15/50] - Loss: 0.4610
Epoch [16/50] - Loss: 0.4575
Epoch [17/50] - Loss: 0.4538
Epoch [18/50] - Loss: 0.4501
Epoch [19/50] - Loss: 0.4463
Epoch [20/50] - Loss: 0.4424
Epoch [21/50] - Loss: 0.4385
Epoch [22/50] - Loss: 0.4345
Epoch [23/50] - Loss: 0.4304
Epoch [24/50] - Loss: 0.4262
Epoch [25/50] - Loss: 0.4220
Epoch [26/50] - Loss: 0.4177
Epoch [27/50] - Loss: 0.4134
Epoch [28/50] - Loss: 0.4090
Epoch [29/50] - Loss: 0.4046
Epoch [30/50] - Loss: 0.4001
Epoch [31/50] - Loss: 0.3955
Epoch [32/50] - Loss: 0.3909
Epoch [33/50] - Loss: 0.3862
Epoch [34/50] - Loss: 0.3815
Epoch [35/50] - Loss: 0.3767
Epoch [36/50] - Loss: 0.3720
Epoch [37/50] - Loss: 0.3672
Epoch [38/50] - Loss: 0.3625
Epoch [39/50] - Loss: 0.3578
Epoch [40/50] - Loss: 0.3531
Epoch [41/50] - Loss: 0.3484
Epoch [42/50] - Loss: 0.3437
Epoch [43/50] - Loss: 0.3391
Epoch [44/50] - Loss: 0.3344
Epoch [45/50] - Loss: 0.3298
Epoch [46/50] - Loss: 0.3252
Epoch [47/50] - Loss: 0.3207
Epoch [48/50] - Loss: 0.3162
Epoch [49/50] - Loss: 0.3118
Epoch [50/50] - Loss: 0.3074
sum preds 5335
sum labels 5513
 - Test Metrics: Accuracy=0.8319, F1=0.7310, Recall=0.7192, Precision=0.7432
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_imbnnpu_imbnnpu_1904035557.csv.
Average F1 over valid seeds: 0.7350 ± 0.0028
___________________________________________________________________________________
Avg F1 for pubmed with SAR and imbnnpu, GCNConv,0.3: 0.7350 ± 0.0028
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5001
Epoch [2/50] - Loss: 0.4996
Epoch [3/50] - Loss: 0.4990
Epoch [4/50] - Loss: 0.4983
Epoch [5/50] - Loss: 0.4974
Epoch [6/50] - Loss: 0.4964
Epoch [7/50] - Loss: 0.4953
Epoch [8/50] - Loss: 0.4940
Epoch [9/50] - Loss: 0.4926
Epoch [10/50] - Loss: 0.4910
Epoch [11/50] - Loss: 0.4893
Epoch [12/50] - Loss: 0.4875
Epoch [13/50] - Loss: 0.4855
Epoch [14/50] - Loss: 0.4834
Epoch [15/50] - Loss: 0.4812
Epoch [16/50] - Loss: 0.4788
Epoch [17/50] - Loss: 0.4763
Epoch [18/50] - Loss: 0.4736
Epoch [19/50] - Loss: 0.4707
Epoch [20/50] - Loss: 0.4677
Epoch [21/50] - Loss: 0.4646
Epoch [22/50] - Loss: 0.4613
Epoch [23/50] - Loss: 0.4578
Epoch [24/50] - Loss: 0.4542
Epoch [25/50] - Loss: 0.4505
Epoch [26/50] - Loss: 0.4466
Epoch [27/50] - Loss: 0.4425
Epoch [28/50] - Loss: 0.4383
Epoch [29/50] - Loss: 0.4339
Epoch [30/50] - Loss: 0.4294
Epoch [31/50] - Loss: 0.4248
Epoch [32/50] - Loss: 0.4200
Epoch [33/50] - Loss: 0.4152
Epoch [34/50] - Loss: 0.4102
Epoch [35/50] - Loss: 0.4051
Epoch [36/50] - Loss: 0.3999
Epoch [37/50] - Loss: 0.3947
Epoch [38/50] - Loss: 0.3893
Epoch [39/50] - Loss: 0.3840
Epoch [40/50] - Loss: 0.3785
Epoch [41/50] - Loss: 0.3731
Epoch [42/50] - Loss: 0.3676
Epoch [43/50] - Loss: 0.3621
Epoch [44/50] - Loss: 0.3565
Epoch [45/50] - Loss: 0.3511
Epoch [46/50] - Loss: 0.3456
Epoch [47/50] - Loss: 0.3402
Epoch [48/50] - Loss: 0.3348
Epoch [49/50] - Loss: 0.3294
Epoch [50/50] - Loss: 0.3242
sum preds 6541
sum labels 6300
 - Test Metrics: Accuracy=0.7940, F1=0.7090, Recall=0.7225, Precision=0.6959
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4990
Epoch [3/50] - Loss: 0.4980
Epoch [4/50] - Loss: 0.4968
Epoch [5/50] - Loss: 0.4956
Epoch [6/50] - Loss: 0.4943
Epoch [7/50] - Loss: 0.4929
Epoch [8/50] - Loss: 0.4913
Epoch [9/50] - Loss: 0.4896
Epoch [10/50] - Loss: 0.4877
Epoch [11/50] - Loss: 0.4858
Epoch [12/50] - Loss: 0.4837
Epoch [13/50] - Loss: 0.4815
Epoch [14/50] - Loss: 0.4791
Epoch [15/50] - Loss: 0.4765
Epoch [16/50] - Loss: 0.4738
Epoch [17/50] - Loss: 0.4709
Epoch [18/50] - Loss: 0.4679
Epoch [19/50] - Loss: 0.4647
Epoch [20/50] - Loss: 0.4614
Epoch [21/50] - Loss: 0.4579
Epoch [22/50] - Loss: 0.4542
Epoch [23/50] - Loss: 0.4504
Epoch [24/50] - Loss: 0.4464
Epoch [25/50] - Loss: 0.4423
Epoch [26/50] - Loss: 0.4380
Epoch [27/50] - Loss: 0.4335
Epoch [28/50] - Loss: 0.4289
Epoch [29/50] - Loss: 0.4242
Epoch [30/50] - Loss: 0.4193
Epoch [31/50] - Loss: 0.4143
Epoch [32/50] - Loss: 0.4092
Epoch [33/50] - Loss: 0.4040
Epoch [34/50] - Loss: 0.3987
Epoch [35/50] - Loss: 0.3932
Epoch [36/50] - Loss: 0.3877
Epoch [37/50] - Loss: 0.3822
Epoch [38/50] - Loss: 0.3766
Epoch [39/50] - Loss: 0.3709
Epoch [40/50] - Loss: 0.3652
Epoch [41/50] - Loss: 0.3595
Epoch [42/50] - Loss: 0.3538
Epoch [43/50] - Loss: 0.3481
Epoch [44/50] - Loss: 0.3425
Epoch [45/50] - Loss: 0.3368
Epoch [46/50] - Loss: 0.3312
Epoch [47/50] - Loss: 0.3257
Epoch [48/50] - Loss: 0.3202
Epoch [49/50] - Loss: 0.3148
Epoch [50/50] - Loss: 0.3095
sum preds 5791
sum labels 6300
 - Test Metrics: Accuracy=0.7838, F1=0.6755, Recall=0.6483, Precision=0.7052
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4989
Epoch [3/50] - Loss: 0.4977
Epoch [4/50] - Loss: 0.4963
Epoch [5/50] - Loss: 0.4947
Epoch [6/50] - Loss: 0.4930
Epoch [7/50] - Loss: 0.4912
Epoch [8/50] - Loss: 0.4893
Epoch [9/50] - Loss: 0.4873
Epoch [10/50] - Loss: 0.4851
Epoch [11/50] - Loss: 0.4829
Epoch [12/50] - Loss: 0.4804
Epoch [13/50] - Loss: 0.4779
Epoch [14/50] - Loss: 0.4751
Epoch [15/50] - Loss: 0.4722
Epoch [16/50] - Loss: 0.4692
Epoch [17/50] - Loss: 0.4659
Epoch [18/50] - Loss: 0.4625
Epoch [19/50] - Loss: 0.4590
Epoch [20/50] - Loss: 0.4553
Epoch [21/50] - Loss: 0.4515
Epoch [22/50] - Loss: 0.4475
Epoch [23/50] - Loss: 0.4433
Epoch [24/50] - Loss: 0.4390
Epoch [25/50] - Loss: 0.4346
Epoch [26/50] - Loss: 0.4300
Epoch [27/50] - Loss: 0.4253
Epoch [28/50] - Loss: 0.4205
Epoch [29/50] - Loss: 0.4155
Epoch [30/50] - Loss: 0.4104
Epoch [31/50] - Loss: 0.4052
Epoch [32/50] - Loss: 0.3999
Epoch [33/50] - Loss: 0.3945
Epoch [34/50] - Loss: 0.3890
Epoch [35/50] - Loss: 0.3835
Epoch [36/50] - Loss: 0.3779
Epoch [37/50] - Loss: 0.3722
Epoch [38/50] - Loss: 0.3665
Epoch [39/50] - Loss: 0.3608
Epoch [40/50] - Loss: 0.3551
Epoch [41/50] - Loss: 0.3494
Epoch [42/50] - Loss: 0.3437
Epoch [43/50] - Loss: 0.3380
Epoch [44/50] - Loss: 0.3324
Epoch [45/50] - Loss: 0.3268
Epoch [46/50] - Loss: 0.3213
Epoch [47/50] - Loss: 0.3158
Epoch [48/50] - Loss: 0.3105
Epoch [49/50] - Loss: 0.3052
Epoch [50/50] - Loss: 0.3000
sum preds 5931
sum labels 6300
 - Test Metrics: Accuracy=0.7948, F1=0.6956, Recall=0.6752, Precision=0.7172
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_imbnnpu_imbnnpu_1904035601.csv.
Average F1 over valid seeds: 0.6934 ± 0.0137
___________________________________________________________________________________
Avg F1 for pubmed with SAR and imbnnpu, MLP,0.2: 0.6934 ± 0.0137
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5000
Epoch [2/50] - Loss: 0.4986
Epoch [3/50] - Loss: 0.4970
Epoch [4/50] - Loss: 0.4951
Epoch [5/50] - Loss: 0.4929
Epoch [6/50] - Loss: 0.4906
Epoch [7/50] - Loss: 0.4881
Epoch [8/50] - Loss: 0.4856
Epoch [9/50] - Loss: 0.4829
Epoch [10/50] - Loss: 0.4802
Epoch [11/50] - Loss: 0.4773
Epoch [12/50] - Loss: 0.4743
Epoch [13/50] - Loss: 0.4712
Epoch [14/50] - Loss: 0.4679
Epoch [15/50] - Loss: 0.4646
Epoch [16/50] - Loss: 0.4612
Epoch [17/50] - Loss: 0.4576
Epoch [18/50] - Loss: 0.4540
Epoch [19/50] - Loss: 0.4502
Epoch [20/50] - Loss: 0.4463
Epoch [21/50] - Loss: 0.4423
Epoch [22/50] - Loss: 0.4381
Epoch [23/50] - Loss: 0.4339
Epoch [24/50] - Loss: 0.4295
Epoch [25/50] - Loss: 0.4251
Epoch [26/50] - Loss: 0.4205
Epoch [27/50] - Loss: 0.4158
Epoch [28/50] - Loss: 0.4110
Epoch [29/50] - Loss: 0.4061
Epoch [30/50] - Loss: 0.4011
Epoch [31/50] - Loss: 0.3960
Epoch [32/50] - Loss: 0.3909
Epoch [33/50] - Loss: 0.3856
Epoch [34/50] - Loss: 0.3803
Epoch [35/50] - Loss: 0.3750
Epoch [36/50] - Loss: 0.3696
Epoch [37/50] - Loss: 0.3641
Epoch [38/50] - Loss: 0.3586
Epoch [39/50] - Loss: 0.3531
Epoch [40/50] - Loss: 0.3476
Epoch [41/50] - Loss: 0.3421
Epoch [42/50] - Loss: 0.3365
Epoch [43/50] - Loss: 0.3311
Epoch [44/50] - Loss: 0.3256
Epoch [45/50] - Loss: 0.3202
Epoch [46/50] - Loss: 0.3148
Epoch [47/50] - Loss: 0.3095
Epoch [48/50] - Loss: 0.3043
Epoch [49/50] - Loss: 0.2991
Epoch [50/50] - Loss: 0.2940
sum preds 5913
sum labels 6300
 - Test Metrics: Accuracy=0.8151, F1=0.7253, Recall=0.7030, Precision=0.7490
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5005
Epoch [2/50] - Loss: 0.4986
Epoch [3/50] - Loss: 0.4967
Epoch [4/50] - Loss: 0.4946
Epoch [5/50] - Loss: 0.4921
Epoch [6/50] - Loss: 0.4893
Epoch [7/50] - Loss: 0.4863
Epoch [8/50] - Loss: 0.4831
Epoch [9/50] - Loss: 0.4799
Epoch [10/50] - Loss: 0.4766
Epoch [11/50] - Loss: 0.4731
Epoch [12/50] - Loss: 0.4694
Epoch [13/50] - Loss: 0.4654
Epoch [14/50] - Loss: 0.4612
Epoch [15/50] - Loss: 0.4568
Epoch [16/50] - Loss: 0.4524
Epoch [17/50] - Loss: 0.4480
Epoch [18/50] - Loss: 0.4434
Epoch [19/50] - Loss: 0.4388
Epoch [20/50] - Loss: 0.4340
Epoch [21/50] - Loss: 0.4291
Epoch [22/50] - Loss: 0.4241
Epoch [23/50] - Loss: 0.4189
Epoch [24/50] - Loss: 0.4137
Epoch [25/50] - Loss: 0.4083
Epoch [26/50] - Loss: 0.4029
Epoch [27/50] - Loss: 0.3974
Epoch [28/50] - Loss: 0.3918
Epoch [29/50] - Loss: 0.3862
Epoch [30/50] - Loss: 0.3805
Epoch [31/50] - Loss: 0.3748
Epoch [32/50] - Loss: 0.3690
Epoch [33/50] - Loss: 0.3631
Epoch [34/50] - Loss: 0.3573
Epoch [35/50] - Loss: 0.3513
Epoch [36/50] - Loss: 0.3454
Epoch [37/50] - Loss: 0.3394
Epoch [38/50] - Loss: 0.3334
Epoch [39/50] - Loss: 0.3274
Epoch [40/50] - Loss: 0.3214
Epoch [41/50] - Loss: 0.3154
Epoch [42/50] - Loss: 0.3095
Epoch [43/50] - Loss: 0.3036
Epoch [44/50] - Loss: 0.2977
Epoch [45/50] - Loss: 0.2918
Epoch [46/50] - Loss: 0.2861
Epoch [47/50] - Loss: 0.2804
Epoch [48/50] - Loss: 0.2748
Epoch [49/50] - Loss: 0.2692
Epoch [50/50] - Loss: 0.2638
sum preds 5684
sum labels 6300
 - Test Metrics: Accuracy=0.8242, F1=0.7338, Recall=0.6979, Precision=0.7736
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4976
Epoch [3/50] - Loss: 0.4958
Epoch [4/50] - Loss: 0.4936
Epoch [5/50] - Loss: 0.4909
Epoch [6/50] - Loss: 0.4881
Epoch [7/50] - Loss: 0.4851
Epoch [8/50] - Loss: 0.4820
Epoch [9/50] - Loss: 0.4788
Epoch [10/50] - Loss: 0.4755
Epoch [11/50] - Loss: 0.4720
Epoch [12/50] - Loss: 0.4683
Epoch [13/50] - Loss: 0.4645
Epoch [14/50] - Loss: 0.4604
Epoch [15/50] - Loss: 0.4561
Epoch [16/50] - Loss: 0.4516
Epoch [17/50] - Loss: 0.4469
Epoch [18/50] - Loss: 0.4421
Epoch [19/50] - Loss: 0.4373
Epoch [20/50] - Loss: 0.4325
Epoch [21/50] - Loss: 0.4275
Epoch [22/50] - Loss: 0.4224
Epoch [23/50] - Loss: 0.4171
Epoch [24/50] - Loss: 0.4117
Epoch [25/50] - Loss: 0.4062
Epoch [26/50] - Loss: 0.4006
Epoch [27/50] - Loss: 0.3948
Epoch [28/50] - Loss: 0.3890
Epoch [29/50] - Loss: 0.3831
Epoch [30/50] - Loss: 0.3771
Epoch [31/50] - Loss: 0.3710
Epoch [32/50] - Loss: 0.3648
Epoch [33/50] - Loss: 0.3585
Epoch [34/50] - Loss: 0.3523
Epoch [35/50] - Loss: 0.3460
Epoch [36/50] - Loss: 0.3398
Epoch [37/50] - Loss: 0.3337
Epoch [38/50] - Loss: 0.3275
Epoch [39/50] - Loss: 0.3213
Epoch [40/50] - Loss: 0.3152
Epoch [41/50] - Loss: 0.3092
Epoch [42/50] - Loss: 0.3032
Epoch [43/50] - Loss: 0.2973
Epoch [44/50] - Loss: 0.2914
Epoch [45/50] - Loss: 0.2857
Epoch [46/50] - Loss: 0.2800
Epoch [47/50] - Loss: 0.2745
Epoch [48/50] - Loss: 0.2691
Epoch [49/50] - Loss: 0.2637
Epoch [50/50] - Loss: 0.2585
sum preds 5729
sum labels 6300
 - Test Metrics: Accuracy=0.8164, F1=0.7231, Recall=0.6903, Precision=0.7591
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_imbnnpu_imbnnpu_1904035605.csv.
Average F1 over valid seeds: 0.7274 ± 0.0046
___________________________________________________________________________________
Avg F1 for pubmed with SAR and imbnnpu, GATConv,0.2: 0.7274 ± 0.0046
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5003
Epoch [2/50] - Loss: 0.4989
Epoch [3/50] - Loss: 0.4974
Epoch [4/50] - Loss: 0.4958
Epoch [5/50] - Loss: 0.4939
Epoch [6/50] - Loss: 0.4919
Epoch [7/50] - Loss: 0.4897
Epoch [8/50] - Loss: 0.4874
Epoch [9/50] - Loss: 0.4848
Epoch [10/50] - Loss: 0.4820
Epoch [11/50] - Loss: 0.4790
Epoch [12/50] - Loss: 0.4760
Epoch [13/50] - Loss: 0.4730
Epoch [14/50] - Loss: 0.4700
Epoch [15/50] - Loss: 0.4669
Epoch [16/50] - Loss: 0.4636
Epoch [17/50] - Loss: 0.4603
Epoch [18/50] - Loss: 0.4569
Epoch [19/50] - Loss: 0.4534
Epoch [20/50] - Loss: 0.4499
Epoch [21/50] - Loss: 0.4462
Epoch [22/50] - Loss: 0.4425
Epoch [23/50] - Loss: 0.4387
Epoch [24/50] - Loss: 0.4348
Epoch [25/50] - Loss: 0.4308
Epoch [26/50] - Loss: 0.4268
Epoch [27/50] - Loss: 0.4228
Epoch [28/50] - Loss: 0.4187
Epoch [29/50] - Loss: 0.4145
Epoch [30/50] - Loss: 0.4103
Epoch [31/50] - Loss: 0.4060
Epoch [32/50] - Loss: 0.4018
Epoch [33/50] - Loss: 0.3974
Epoch [34/50] - Loss: 0.3931
Epoch [35/50] - Loss: 0.3887
Epoch [36/50] - Loss: 0.3842
Epoch [37/50] - Loss: 0.3798
Epoch [38/50] - Loss: 0.3754
Epoch [39/50] - Loss: 0.3709
Epoch [40/50] - Loss: 0.3664
Epoch [41/50] - Loss: 0.3620
Epoch [42/50] - Loss: 0.3575
Epoch [43/50] - Loss: 0.3531
Epoch [44/50] - Loss: 0.3487
Epoch [45/50] - Loss: 0.3443
Epoch [46/50] - Loss: 0.3399
Epoch [47/50] - Loss: 0.3356
Epoch [48/50] - Loss: 0.3312
Epoch [49/50] - Loss: 0.3270
Epoch [50/50] - Loss: 0.3227
sum preds 6157
sum labels 6300
 - Test Metrics: Accuracy=0.8279, F1=0.7493, Recall=0.7408, Precision=0.7580
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5006
Epoch [2/50] - Loss: 0.4988
Epoch [3/50] - Loss: 0.4974
Epoch [4/50] - Loss: 0.4957
Epoch [5/50] - Loss: 0.4938
Epoch [6/50] - Loss: 0.4916
Epoch [7/50] - Loss: 0.4893
Epoch [8/50] - Loss: 0.4868
Epoch [9/50] - Loss: 0.4842
Epoch [10/50] - Loss: 0.4815
Epoch [11/50] - Loss: 0.4786
Epoch [12/50] - Loss: 0.4756
Epoch [13/50] - Loss: 0.4724
Epoch [14/50] - Loss: 0.4692
Epoch [15/50] - Loss: 0.4660
Epoch [16/50] - Loss: 0.4627
Epoch [17/50] - Loss: 0.4593
Epoch [18/50] - Loss: 0.4558
Epoch [19/50] - Loss: 0.4522
Epoch [20/50] - Loss: 0.4485
Epoch [21/50] - Loss: 0.4447
Epoch [22/50] - Loss: 0.4409
Epoch [23/50] - Loss: 0.4369
Epoch [24/50] - Loss: 0.4329
Epoch [25/50] - Loss: 0.4289
Epoch [26/50] - Loss: 0.4247
Epoch [27/50] - Loss: 0.4205
Epoch [28/50] - Loss: 0.4163
Epoch [29/50] - Loss: 0.4120
Epoch [30/50] - Loss: 0.4076
Epoch [31/50] - Loss: 0.4032
Epoch [32/50] - Loss: 0.3988
Epoch [33/50] - Loss: 0.3943
Epoch [34/50] - Loss: 0.3898
Epoch [35/50] - Loss: 0.3853
Epoch [36/50] - Loss: 0.3808
Epoch [37/50] - Loss: 0.3762
Epoch [38/50] - Loss: 0.3717
Epoch [39/50] - Loss: 0.3671
Epoch [40/50] - Loss: 0.3626
Epoch [41/50] - Loss: 0.3581
Epoch [42/50] - Loss: 0.3535
Epoch [43/50] - Loss: 0.3490
Epoch [44/50] - Loss: 0.3446
Epoch [45/50] - Loss: 0.3401
Epoch [46/50] - Loss: 0.3357
Epoch [47/50] - Loss: 0.3313
Epoch [48/50] - Loss: 0.3270
Epoch [49/50] - Loss: 0.3227
Epoch [50/50] - Loss: 0.3185
sum preds 5633
sum labels 6300
 - Test Metrics: Accuracy=0.8344, F1=0.7482, Recall=0.7086, Precision=0.7925
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4999
Epoch [2/50] - Loss: 0.4978
Epoch [3/50] - Loss: 0.4960
Epoch [4/50] - Loss: 0.4942
Epoch [5/50] - Loss: 0.4922
Epoch [6/50] - Loss: 0.4897
Epoch [7/50] - Loss: 0.4870
Epoch [8/50] - Loss: 0.4841
Epoch [9/50] - Loss: 0.4812
Epoch [10/50] - Loss: 0.4782
Epoch [11/50] - Loss: 0.4752
Epoch [12/50] - Loss: 0.4722
Epoch [13/50] - Loss: 0.4691
Epoch [14/50] - Loss: 0.4658
Epoch [15/50] - Loss: 0.4625
Epoch [16/50] - Loss: 0.4590
Epoch [17/50] - Loss: 0.4555
Epoch [18/50] - Loss: 0.4519
Epoch [19/50] - Loss: 0.4482
Epoch [20/50] - Loss: 0.4445
Epoch [21/50] - Loss: 0.4407
Epoch [22/50] - Loss: 0.4368
Epoch [23/50] - Loss: 0.4328
Epoch [24/50] - Loss: 0.4288
Epoch [25/50] - Loss: 0.4247
Epoch [26/50] - Loss: 0.4206
Epoch [27/50] - Loss: 0.4164
Epoch [28/50] - Loss: 0.4121
Epoch [29/50] - Loss: 0.4078
Epoch [30/50] - Loss: 0.4035
Epoch [31/50] - Loss: 0.3991
Epoch [32/50] - Loss: 0.3947
Epoch [33/50] - Loss: 0.3902
Epoch [34/50] - Loss: 0.3857
Epoch [35/50] - Loss: 0.3811
Epoch [36/50] - Loss: 0.3765
Epoch [37/50] - Loss: 0.3719
Epoch [38/50] - Loss: 0.3673
Epoch [39/50] - Loss: 0.3627
Epoch [40/50] - Loss: 0.3581
Epoch [41/50] - Loss: 0.3536
Epoch [42/50] - Loss: 0.3490
Epoch [43/50] - Loss: 0.3445
Epoch [44/50] - Loss: 0.3400
Epoch [45/50] - Loss: 0.3355
Epoch [46/50] - Loss: 0.3311
Epoch [47/50] - Loss: 0.3267
Epoch [48/50] - Loss: 0.3223
Epoch [49/50] - Loss: 0.3180
Epoch [50/50] - Loss: 0.3138
sum preds 5944
sum labels 6300
 - Test Metrics: Accuracy=0.8291, F1=0.7468, Recall=0.7257, Precision=0.7692
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_imbnnpu_imbnnpu_1904035610.csv.
Average F1 over valid seeds: 0.7481 ± 0.0010
___________________________________________________________________________________
Avg F1 for pubmed with SAR and imbnnpu, GCNConv,0.2: 0.7481 ± 0.0010
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 23.0320
Epoch 10 / 50, Loss: 19.5439
Epoch 20 / 50, Loss: 14.8180
Epoch 30 / 50, Loss: 10.2470
Epoch 40 / 50, Loss: 7.1457
sum preds 2958.0
sum labels 4725
 - Test Metrics: Accuracy=0.8361, F1=0.6466, Recall=0.5257, Precision=0.8398
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 23.4734
Epoch 10 / 50, Loss: 19.7186
Epoch 20 / 50, Loss: 14.8609
Epoch 30 / 50, Loss: 10.3912
Epoch 40 / 50, Loss: 7.2105
sum preds 2996.0
sum labels 4725
 - Test Metrics: Accuracy=0.8452, F1=0.6678, Recall=0.5456, Precision=0.8605
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.22206428826631608, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 23.4340
Epoch 10 / 50, Loss: 19.8448
Epoch 20 / 50, Loss: 14.9813
Epoch 30 / 50, Loss: 10.4258
Epoch 40 / 50, Loss: 7.2968
sum preds 3067.0
sum labels 4725
 - Test Metrics: Accuracy=0.8440, F1=0.6684, Recall=0.5511, Precision=0.8490
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_ours_1904035615.csv.
Average F1 over valid seeds: 0.6609 ± 0.0101
___________________________________________________________________________________
Avg F1 for pubmed with SAR and ours, GCNConv,0.4: 0.6609 ± 0.0101
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 26.0080
Epoch 10 / 50, Loss: 21.8505
Epoch 20 / 50, Loss: 16.2441
Epoch 30 / 50, Loss: 11.1431
Epoch 40 / 50, Loss: 7.7826
sum preds 3323.0
sum labels 5513
 - Test Metrics: Accuracy=0.8117, F1=0.6301, Recall=0.5050, Precision=0.8378
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 26.3177
Epoch 10 / 50, Loss: 21.8783
Epoch 20 / 50, Loss: 16.2161
Epoch 30 / 50, Loss: 11.1543
Epoch 40 / 50, Loss: 7.7893
sum preds 3275.0
sum labels 5513
 - Test Metrics: Accuracy=0.8170, F1=0.6386, Recall=0.5090, Precision=0.8568
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.2677331189755668, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 26.4676
Epoch 10 / 50, Loss: 22.1500
Epoch 20 / 50, Loss: 16.4276
Epoch 30 / 50, Loss: 11.2781
Epoch 40 / 50, Loss: 7.9113
sum preds 3293.0
sum labels 5513
 - Test Metrics: Accuracy=0.8148, F1=0.6350, Recall=0.5072, Precision=0.8491
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_ours_1904040254.csv.
Average F1 over valid seeds: 0.6346 ± 0.0035
___________________________________________________________________________________
Avg F1 for pubmed with SAR and ours, GCNConv,0.3: 0.6346 ± 0.0035
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 29.9316
Epoch 10 / 50, Loss: 24.7425
Epoch 20 / 50, Loss: 17.9952
Epoch 30 / 50, Loss: 12.3062
Epoch 40 / 50, Loss: 8.6600
sum preds 3180.0
sum labels 6300
 - Test Metrics: Accuracy=0.7790, F1=0.5770, Recall=0.4341, Precision=0.8601
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 30.3373
Epoch 10 / 50, Loss: 24.9029
Epoch 20 / 50, Loss: 17.9482
Epoch 30 / 50, Loss: 12.3034
Epoch 40 / 50, Loss: 8.6684
sum preds 3159.0
sum labels 6300
 - Test Metrics: Accuracy=0.7738, F1=0.5662, Recall=0.4251, Precision=0.8477
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=10, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.30833728092482293, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 29.9486
Epoch 10 / 50, Loss: 24.7633
Epoch 20 / 50, Loss: 17.9901
Epoch 30 / 50, Loss: 12.2844
Epoch 40 / 50, Loss: 8.6979
sum preds 3131.0
sum labels 6300
 - Test Metrics: Accuracy=0.7762, F1=0.5694, Recall=0.4262, Precision=0.8576
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to pubmed_experimentations\pubmed_SAR_ours_1904040913.csv.
Average F1 over valid seeds: 0.5709 ± 0.0045
___________________________________________________________________________________
Avg F1 for pubmed with SAR and ours, GCNConv,0.2: 0.5709 ± 0.0045
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.1241
Epoch [2/50] - Loss: 1.6309
Epoch [3/50] - Loss: 1.4498
Epoch [4/50] - Loss: 1.3465
Epoch [5/50] - Loss: 1.2647
Epoch [6/50] - Loss: 1.2200
Epoch [7/50] - Loss: 1.1818
Epoch [8/50] - Loss: 1.1500
Epoch [9/50] - Loss: 1.1217
Epoch [10/50] - Loss: 1.0981
Epoch [11/50] - Loss: 1.0747
Epoch [12/50] - Loss: 1.0516
Epoch [13/50] - Loss: 1.0301
Epoch [14/50] - Loss: 1.0089
Epoch [15/50] - Loss: 0.9888
Epoch [16/50] - Loss: 0.9703
Epoch [17/50] - Loss: 0.9496
Epoch [18/50] - Loss: 0.9300
Epoch [19/50] - Loss: 0.9114
Epoch [20/50] - Loss: 0.8918
Epoch [21/50] - Loss: 0.8717
Epoch [22/50] - Loss: 0.8514
Epoch [23/50] - Loss: 0.8305
Epoch [24/50] - Loss: 0.8104
Epoch [25/50] - Loss: 0.7902
Epoch [26/50] - Loss: 0.7691
Epoch [27/50] - Loss: 0.7491
Epoch [28/50] - Loss: 0.7290
Epoch [29/50] - Loss: 0.7101
Epoch [30/50] - Loss: 0.6906
Epoch [31/50] - Loss: 0.6723
Epoch [32/50] - Loss: 0.6542
Epoch [33/50] - Loss: 0.6353
Epoch [34/50] - Loss: 0.6181
Epoch [35/50] - Loss: 0.6019
Epoch [36/50] - Loss: 0.5857
Epoch [37/50] - Loss: 0.5687
Epoch [38/50] - Loss: 0.5530
Epoch [39/50] - Loss: 0.5386
Epoch [40/50] - Loss: 0.5238
Epoch [41/50] - Loss: 0.5095
Epoch [42/50] - Loss: 0.4954
Epoch [43/50] - Loss: 0.4815
Epoch [44/50] - Loss: 0.4673
Epoch [45/50] - Loss: 0.4559
Epoch [46/50] - Loss: 0.4422
Epoch [47/50] - Loss: 0.4300
Epoch [48/50] - Loss: 0.4181
Epoch [49/50] - Loss: 0.4060
Epoch [50/50] - Loss: 0.3940
sum preds 91
sum labels 1607
 - Test Metrics: Accuracy=0.8562, F1=0.1001, Recall=0.0529, Precision=0.9341
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.9812
Epoch [2/50] - Loss: 1.5415
Epoch [3/50] - Loss: 1.3654
Epoch [4/50] - Loss: 1.2958
Epoch [5/50] - Loss: 1.2254
Epoch [6/50] - Loss: 1.1798
Epoch [7/50] - Loss: 1.1473
Epoch [8/50] - Loss: 1.1195
Epoch [9/50] - Loss: 1.0974
Epoch [10/50] - Loss: 1.0739
Epoch [11/50] - Loss: 1.0524
Epoch [12/50] - Loss: 1.0318
Epoch [13/50] - Loss: 1.0095
Epoch [14/50] - Loss: 0.9879
Epoch [15/50] - Loss: 0.9659
Epoch [16/50] - Loss: 0.9441
Epoch [17/50] - Loss: 0.9211
Epoch [18/50] - Loss: 0.8988
Epoch [19/50] - Loss: 0.8766
Epoch [20/50] - Loss: 0.8539
Epoch [21/50] - Loss: 0.8309
Epoch [22/50] - Loss: 0.8075
Epoch [23/50] - Loss: 0.7833
Epoch [24/50] - Loss: 0.7593
Epoch [25/50] - Loss: 0.7371
Epoch [26/50] - Loss: 0.7135
Epoch [27/50] - Loss: 0.6908
Epoch [28/50] - Loss: 0.6690
Epoch [29/50] - Loss: 0.6472
Epoch [30/50] - Loss: 0.6254
Epoch [31/50] - Loss: 0.6050
Epoch [32/50] - Loss: 0.5843
Epoch [33/50] - Loss: 0.5644
Epoch [34/50] - Loss: 0.5454
Epoch [35/50] - Loss: 0.5265
Epoch [36/50] - Loss: 0.5075
Epoch [37/50] - Loss: 0.4901
Epoch [38/50] - Loss: 0.4735
Epoch [39/50] - Loss: 0.4578
Epoch [40/50] - Loss: 0.4409
Epoch [41/50] - Loss: 0.4256
Epoch [42/50] - Loss: 0.4105
Epoch [43/50] - Loss: 0.3973
Epoch [44/50] - Loss: 0.3824
Epoch [45/50] - Loss: 0.3684
Epoch [46/50] - Loss: 0.3559
Epoch [47/50] - Loss: 0.3433
Epoch [48/50] - Loss: 0.3325
Epoch [49/50] - Loss: 0.3205
Epoch [50/50] - Loss: 0.3091
sum preds 82
sum labels 1607
 - Test Metrics: Accuracy=0.8548, F1=0.0864, Recall=0.0454, Precision=0.8902
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1769
Epoch [2/50] - Loss: 1.4017
Epoch [3/50] - Loss: 1.2989
Epoch [4/50] - Loss: 1.2240
Epoch [5/50] - Loss: 1.1797
Epoch [6/50] - Loss: 1.1469
Epoch [7/50] - Loss: 1.1192
Epoch [8/50] - Loss: 1.0928
Epoch [9/50] - Loss: 1.0691
Epoch [10/50] - Loss: 1.0442
Epoch [11/50] - Loss: 1.0224
Epoch [12/50] - Loss: 0.9998
Epoch [13/50] - Loss: 0.9763
Epoch [14/50] - Loss: 0.9513
Epoch [15/50] - Loss: 0.9264
Epoch [16/50] - Loss: 0.9022
Epoch [17/50] - Loss: 0.8750
Epoch [18/50] - Loss: 0.8482
Epoch [19/50] - Loss: 0.8202
Epoch [20/50] - Loss: 0.7919
Epoch [21/50] - Loss: 0.7639
Epoch [22/50] - Loss: 0.7367
Epoch [23/50] - Loss: 0.7115
Epoch [24/50] - Loss: 0.6866
Epoch [25/50] - Loss: 0.6633
Epoch [26/50] - Loss: 0.6414
Epoch [27/50] - Loss: 0.6198
Epoch [28/50] - Loss: 0.5987
Epoch [29/50] - Loss: 0.5789
Epoch [30/50] - Loss: 0.5593
Epoch [31/50] - Loss: 0.5401
Epoch [32/50] - Loss: 0.5220
Epoch [33/50] - Loss: 0.5077
Epoch [34/50] - Loss: 0.4898
Epoch [35/50] - Loss: 0.4734
Epoch [36/50] - Loss: 0.4597
Epoch [37/50] - Loss: 0.4457
Epoch [38/50] - Loss: 0.4317
Epoch [39/50] - Loss: 0.4184
Epoch [40/50] - Loss: 0.4051
Epoch [41/50] - Loss: 0.3923
Epoch [42/50] - Loss: 0.3807
Epoch [43/50] - Loss: 0.3708
Epoch [44/50] - Loss: 0.3602
Epoch [45/50] - Loss: 0.3492
Epoch [46/50] - Loss: 0.3387
Epoch [47/50] - Loss: 0.3298
Epoch [48/50] - Loss: 0.3186
Epoch [49/50] - Loss: 0.3103
Epoch [50/50] - Loss: 0.3008
sum preds 78
sum labels 1607
 - Test Metrics: Accuracy=0.8552, F1=0.0866, Recall=0.0454, Precision=0.9359
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_naive_naive_1904041531.csv.
Average F1 over valid seeds: 0.0911 ± 0.0064
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and naive, MLP,0.4: 0.0911 ± 0.0064
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.3495
Epoch [2/50] - Loss: 1.5040
Epoch [3/50] - Loss: 1.3643
Epoch [4/50] - Loss: 1.2810
Epoch [5/50] - Loss: 1.2368
Epoch [6/50] - Loss: 1.2080
Epoch [7/50] - Loss: 1.1862
Epoch [8/50] - Loss: 1.1722
Epoch [9/50] - Loss: 1.1588
Epoch [10/50] - Loss: 1.1461
Epoch [11/50] - Loss: 1.1363
Epoch [12/50] - Loss: 1.1251
Epoch [13/50] - Loss: 1.1147
Epoch [14/50] - Loss: 1.1061
Epoch [15/50] - Loss: 1.1011
Epoch [16/50] - Loss: 1.0923
Epoch [17/50] - Loss: 1.0857
Epoch [18/50] - Loss: 1.0803
Epoch [19/50] - Loss: 1.0763
Epoch [20/50] - Loss: 1.0701
Epoch [21/50] - Loss: 1.0645
Epoch [22/50] - Loss: 1.0602
Epoch [23/50] - Loss: 1.0555
Epoch [24/50] - Loss: 1.0503
Epoch [25/50] - Loss: 1.0447
Epoch [26/50] - Loss: 1.0433
Epoch [27/50] - Loss: 1.0360
Epoch [28/50] - Loss: 1.0302
Epoch [29/50] - Loss: 1.0277
Epoch [30/50] - Loss: 1.0241
Epoch [31/50] - Loss: 1.0167
Epoch [32/50] - Loss: 1.0120
Epoch [33/50] - Loss: 1.0104
Epoch [34/50] - Loss: 1.0042
Epoch [35/50] - Loss: 0.9994
Epoch [36/50] - Loss: 0.9950
Epoch [37/50] - Loss: 0.9918
Epoch [38/50] - Loss: 0.9871
Epoch [39/50] - Loss: 0.9816
Epoch [40/50] - Loss: 0.9780
Epoch [41/50] - Loss: 0.9717
Epoch [42/50] - Loss: 0.9701
Epoch [43/50] - Loss: 0.9637
Epoch [44/50] - Loss: 0.9609
Epoch [45/50] - Loss: 0.9553
Epoch [46/50] - Loss: 0.9524
Epoch [47/50] - Loss: 0.9479
Epoch [48/50] - Loss: 0.9434
Epoch [49/50] - Loss: 0.9430
Epoch [50/50] - Loss: 0.9365
sum preds 205
sum labels 1607
 - Test Metrics: Accuracy=0.8651, F1=0.2086, Recall=0.1176, Precision=0.9220
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1998
Epoch [2/50] - Loss: 1.4433
Epoch [3/50] - Loss: 1.2883
Epoch [4/50] - Loss: 1.2253
Epoch [5/50] - Loss: 1.2006
Epoch [6/50] - Loss: 1.1784
Epoch [7/50] - Loss: 1.1580
Epoch [8/50] - Loss: 1.1426
Epoch [9/50] - Loss: 1.1301
Epoch [10/50] - Loss: 1.1186
Epoch [11/50] - Loss: 1.1087
Epoch [12/50] - Loss: 1.1003
Epoch [13/50] - Loss: 1.0890
Epoch [14/50] - Loss: 1.0820
Epoch [15/50] - Loss: 1.0746
Epoch [16/50] - Loss: 1.0682
Epoch [17/50] - Loss: 1.0616
Epoch [18/50] - Loss: 1.0532
Epoch [19/50] - Loss: 1.0502
Epoch [20/50] - Loss: 1.0437
Epoch [21/50] - Loss: 1.0400
Epoch [22/50] - Loss: 1.0341
Epoch [23/50] - Loss: 1.0280
Epoch [24/50] - Loss: 1.0237
Epoch [25/50] - Loss: 1.0177
Epoch [26/50] - Loss: 1.0122
Epoch [27/50] - Loss: 1.0082
Epoch [28/50] - Loss: 1.0033
Epoch [29/50] - Loss: 0.9960
Epoch [30/50] - Loss: 0.9937
Epoch [31/50] - Loss: 0.9886
Epoch [32/50] - Loss: 0.9837
Epoch [33/50] - Loss: 0.9775
Epoch [34/50] - Loss: 0.9717
Epoch [35/50] - Loss: 0.9660
Epoch [36/50] - Loss: 0.9619
Epoch [37/50] - Loss: 0.9563
Epoch [38/50] - Loss: 0.9536
Epoch [39/50] - Loss: 0.9496
Epoch [40/50] - Loss: 0.9422
Epoch [41/50] - Loss: 0.9390
Epoch [42/50] - Loss: 0.9366
Epoch [43/50] - Loss: 0.9337
Epoch [44/50] - Loss: 0.9240
Epoch [45/50] - Loss: 0.9234
Epoch [46/50] - Loss: 0.9189
Epoch [47/50] - Loss: 0.9110
Epoch [48/50] - Loss: 0.9103
Epoch [49/50] - Loss: 0.9064
Epoch [50/50] - Loss: 0.9010
sum preds 241
sum labels 1607
 - Test Metrics: Accuracy=0.8696, F1=0.2500, Recall=0.1437, Precision=0.9585
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.4980
Epoch [2/50] - Loss: 1.5193
Epoch [3/50] - Loss: 1.3707
Epoch [4/50] - Loss: 1.3141
Epoch [5/50] - Loss: 1.2558
Epoch [6/50] - Loss: 1.2278
Epoch [7/50] - Loss: 1.2057
Epoch [8/50] - Loss: 1.1920
Epoch [9/50] - Loss: 1.1744
Epoch [10/50] - Loss: 1.1564
Epoch [11/50] - Loss: 1.1454
Epoch [12/50] - Loss: 1.1323
Epoch [13/50] - Loss: 1.1195
Epoch [14/50] - Loss: 1.1106
Epoch [15/50] - Loss: 1.1023
Epoch [16/50] - Loss: 1.0950
Epoch [17/50] - Loss: 1.0879
Epoch [18/50] - Loss: 1.0831
Epoch [19/50] - Loss: 1.0758
Epoch [20/50] - Loss: 1.0673
Epoch [21/50] - Loss: 1.0603
Epoch [22/50] - Loss: 1.0571
Epoch [23/50] - Loss: 1.0474
Epoch [24/50] - Loss: 1.0448
Epoch [25/50] - Loss: 1.0389
Epoch [26/50] - Loss: 1.0340
Epoch [27/50] - Loss: 1.0277
Epoch [28/50] - Loss: 1.0231
Epoch [29/50] - Loss: 1.0198
Epoch [30/50] - Loss: 1.0133
Epoch [31/50] - Loss: 1.0096
Epoch [32/50] - Loss: 1.0060
Epoch [33/50] - Loss: 1.0020
Epoch [34/50] - Loss: 0.9971
Epoch [35/50] - Loss: 0.9925
Epoch [36/50] - Loss: 0.9898
Epoch [37/50] - Loss: 0.9865
Epoch [38/50] - Loss: 0.9806
Epoch [39/50] - Loss: 0.9802
Epoch [40/50] - Loss: 0.9724
Epoch [41/50] - Loss: 0.9696
Epoch [42/50] - Loss: 0.9628
Epoch [43/50] - Loss: 0.9621
Epoch [44/50] - Loss: 0.9541
Epoch [45/50] - Loss: 0.9534
Epoch [46/50] - Loss: 0.9464
Epoch [47/50] - Loss: 0.9427
Epoch [48/50] - Loss: 0.9419
Epoch [49/50] - Loss: 0.9372
Epoch [50/50] - Loss: 0.9297
sum preds 209
sum labels 1607
 - Test Metrics: Accuracy=0.8653, F1=0.2115, Recall=0.1195, Precision=0.9187
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_naive_naive_1904042426.csv.
Average F1 over valid seeds: 0.2234 ± 0.0189
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and naive, GATConv,0.4: 0.2234 ± 0.0189
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.7008
Epoch [2/50] - Loss: 1.5389
Epoch [3/50] - Loss: 1.3712
Epoch [4/50] - Loss: 1.3171
Epoch [5/50] - Loss: 1.2852
Epoch [6/50] - Loss: 1.2625
Epoch [7/50] - Loss: 1.2441
Epoch [8/50] - Loss: 1.2297
Epoch [9/50] - Loss: 1.2171
Epoch [10/50] - Loss: 1.2077
Epoch [11/50] - Loss: 1.1978
Epoch [12/50] - Loss: 1.1917
Epoch [13/50] - Loss: 1.1841
Epoch [14/50] - Loss: 1.1784
Epoch [15/50] - Loss: 1.1724
Epoch [16/50] - Loss: 1.1663
Epoch [17/50] - Loss: 1.1619
Epoch [18/50] - Loss: 1.1561
Epoch [19/50] - Loss: 1.1515
Epoch [20/50] - Loss: 1.1478
Epoch [21/50] - Loss: 1.1412
Epoch [22/50] - Loss: 1.1363
Epoch [23/50] - Loss: 1.1336
Epoch [24/50] - Loss: 1.1298
Epoch [25/50] - Loss: 1.1261
Epoch [26/50] - Loss: 1.1207
Epoch [27/50] - Loss: 1.1173
Epoch [28/50] - Loss: 1.1122
Epoch [29/50] - Loss: 1.1075
Epoch [30/50] - Loss: 1.1049
Epoch [31/50] - Loss: 1.1010
Epoch [32/50] - Loss: 1.0973
Epoch [33/50] - Loss: 1.0936
Epoch [34/50] - Loss: 1.0909
Epoch [35/50] - Loss: 1.0880
Epoch [36/50] - Loss: 1.0832
Epoch [37/50] - Loss: 1.0810
Epoch [38/50] - Loss: 1.0777
Epoch [39/50] - Loss: 1.0749
Epoch [40/50] - Loss: 1.0713
Epoch [41/50] - Loss: 1.0667
Epoch [42/50] - Loss: 1.0647
Epoch [43/50] - Loss: 1.0629
Epoch [44/50] - Loss: 1.0593
Epoch [45/50] - Loss: 1.0591
Epoch [46/50] - Loss: 1.0541
Epoch [47/50] - Loss: 1.0525
Epoch [48/50] - Loss: 1.0484
Epoch [49/50] - Loss: 1.0452
Epoch [50/50] - Loss: 1.0436
sum preds 258
sum labels 1607
 - Test Metrics: Accuracy=0.8720, F1=0.2702, Recall=0.1568, Precision=0.9767
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.5646
Epoch [2/50] - Loss: 1.8552
Epoch [3/50] - Loss: 1.4777
Epoch [4/50] - Loss: 1.3889
Epoch [5/50] - Loss: 1.3411
Epoch [6/50] - Loss: 1.3080
Epoch [7/50] - Loss: 1.2866
Epoch [8/50] - Loss: 1.2673
Epoch [9/50] - Loss: 1.2507
Epoch [10/50] - Loss: 1.2404
Epoch [11/50] - Loss: 1.2307
Epoch [12/50] - Loss: 1.2226
Epoch [13/50] - Loss: 1.2139
Epoch [14/50] - Loss: 1.2064
Epoch [15/50] - Loss: 1.2002
Epoch [16/50] - Loss: 1.1938
Epoch [17/50] - Loss: 1.1881
Epoch [18/50] - Loss: 1.1847
Epoch [19/50] - Loss: 1.1788
Epoch [20/50] - Loss: 1.1756
Epoch [21/50] - Loss: 1.1697
Epoch [22/50] - Loss: 1.1653
Epoch [23/50] - Loss: 1.1614
Epoch [24/50] - Loss: 1.1582
Epoch [25/50] - Loss: 1.1542
Epoch [26/50] - Loss: 1.1498
Epoch [27/50] - Loss: 1.1464
Epoch [28/50] - Loss: 1.1412
Epoch [29/50] - Loss: 1.1404
Epoch [30/50] - Loss: 1.1366
Epoch [31/50] - Loss: 1.1320
Epoch [32/50] - Loss: 1.1304
Epoch [33/50] - Loss: 1.1274
Epoch [34/50] - Loss: 1.1246
Epoch [35/50] - Loss: 1.1219
Epoch [36/50] - Loss: 1.1186
Epoch [37/50] - Loss: 1.1172
Epoch [38/50] - Loss: 1.1137
Epoch [39/50] - Loss: 1.1105
Epoch [40/50] - Loss: 1.1074
Epoch [41/50] - Loss: 1.1055
Epoch [42/50] - Loss: 1.1028
Epoch [43/50] - Loss: 1.0998
Epoch [44/50] - Loss: 1.0983
Epoch [45/50] - Loss: 1.0942
Epoch [46/50] - Loss: 1.0923
Epoch [47/50] - Loss: 1.0906
Epoch [48/50] - Loss: 1.0887
Epoch [49/50] - Loss: 1.0860
Epoch [50/50] - Loss: 1.0843
sum preds 192
sum labels 1607
 - Test Metrics: Accuracy=0.8665, F1=0.2112, Recall=0.1182, Precision=0.9896
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1983
Epoch [2/50] - Loss: 3.3700
Epoch [3/50] - Loss: 2.3610
Epoch [4/50] - Loss: 1.8285
Epoch [5/50] - Loss: 1.5573
Epoch [6/50] - Loss: 1.4272
Epoch [7/50] - Loss: 1.3538
Epoch [8/50] - Loss: 1.3102
Epoch [9/50] - Loss: 1.2759
Epoch [10/50] - Loss: 1.2525
Epoch [11/50] - Loss: 1.2366
Epoch [12/50] - Loss: 1.2224
Epoch [13/50] - Loss: 1.2117
Epoch [14/50] - Loss: 1.2017
Epoch [15/50] - Loss: 1.1951
Epoch [16/50] - Loss: 1.1879
Epoch [17/50] - Loss: 1.1807
Epoch [18/50] - Loss: 1.1767
Epoch [19/50] - Loss: 1.1717
Epoch [20/50] - Loss: 1.1683
Epoch [21/50] - Loss: 1.1636
Epoch [22/50] - Loss: 1.1619
Epoch [23/50] - Loss: 1.1565
Epoch [24/50] - Loss: 1.1542
Epoch [25/50] - Loss: 1.1516
Epoch [26/50] - Loss: 1.1493
Epoch [27/50] - Loss: 1.1458
Epoch [28/50] - Loss: 1.1433
Epoch [29/50] - Loss: 1.1405
Epoch [30/50] - Loss: 1.1375
Epoch [31/50] - Loss: 1.1355
Epoch [32/50] - Loss: 1.1320
Epoch [33/50] - Loss: 1.1312
Epoch [34/50] - Loss: 1.1292
Epoch [35/50] - Loss: 1.1263
Epoch [36/50] - Loss: 1.1233
Epoch [37/50] - Loss: 1.1206
Epoch [38/50] - Loss: 1.1190
Epoch [39/50] - Loss: 1.1177
Epoch [40/50] - Loss: 1.1138
Epoch [41/50] - Loss: 1.1137
Epoch [42/50] - Loss: 1.1104
Epoch [43/50] - Loss: 1.1089
Epoch [44/50] - Loss: 1.1070
Epoch [45/50] - Loss: 1.1038
Epoch [46/50] - Loss: 1.1042
Epoch [47/50] - Loss: 1.0996
Epoch [48/50] - Loss: 1.0977
Epoch [49/50] - Loss: 1.0959
Epoch [50/50] - Loss: 1.0945
sum preds 184
sum labels 1607
 - Test Metrics: Accuracy=0.8642, F1=0.1943, Recall=0.1083, Precision=0.9457
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_naive_naive_1904043342.csv.
Average F1 over valid seeds: 0.2253 ± 0.0325
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and naive, GCNConv,0.4: 0.2253 ± 0.0325
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.0840
Epoch [2/50] - Loss: 1.4569
Epoch [3/50] - Loss: 1.2640
Epoch [4/50] - Loss: 1.1879
Epoch [5/50] - Loss: 1.1103
Epoch [6/50] - Loss: 1.0671
Epoch [7/50] - Loss: 1.0351
Epoch [8/50] - Loss: 1.0056
Epoch [9/50] - Loss: 0.9794
Epoch [10/50] - Loss: 0.9573
Epoch [11/50] - Loss: 0.9353
Epoch [12/50] - Loss: 0.9151
Epoch [13/50] - Loss: 0.8964
Epoch [14/50] - Loss: 0.8781
Epoch [15/50] - Loss: 0.8597
Epoch [16/50] - Loss: 0.8437
Epoch [17/50] - Loss: 0.8265
Epoch [18/50] - Loss: 0.8097
Epoch [19/50] - Loss: 0.7947
Epoch [20/50] - Loss: 0.7786
Epoch [21/50] - Loss: 0.7624
Epoch [22/50] - Loss: 0.7464
Epoch [23/50] - Loss: 0.7295
Epoch [24/50] - Loss: 0.7136
Epoch [25/50] - Loss: 0.6981
Epoch [26/50] - Loss: 0.6818
Epoch [27/50] - Loss: 0.6668
Epoch [28/50] - Loss: 0.6515
Epoch [29/50] - Loss: 0.6358
Epoch [30/50] - Loss: 0.6202
Epoch [31/50] - Loss: 0.6054
Epoch [32/50] - Loss: 0.5897
Epoch [33/50] - Loss: 0.5732
Epoch [34/50] - Loss: 0.5591
Epoch [35/50] - Loss: 0.5447
Epoch [36/50] - Loss: 0.5296
Epoch [37/50] - Loss: 0.5144
Epoch [38/50] - Loss: 0.4991
Epoch [39/50] - Loss: 0.4857
Epoch [40/50] - Loss: 0.4703
Epoch [41/50] - Loss: 0.4563
Epoch [42/50] - Loss: 0.4435
Epoch [43/50] - Loss: 0.4297
Epoch [44/50] - Loss: 0.4161
Epoch [45/50] - Loss: 0.4045
Epoch [46/50] - Loss: 0.3917
Epoch [47/50] - Loss: 0.3812
Epoch [48/50] - Loss: 0.3700
Epoch [49/50] - Loss: 0.3594
Epoch [50/50] - Loss: 0.3495
sum preds 52
sum labels 1875
 - Test Metrics: Accuracy=0.8320, F1=0.0498, Recall=0.0256, Precision=0.9231
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.9436
Epoch [2/50] - Loss: 1.4096
Epoch [3/50] - Loss: 1.2150
Epoch [4/50] - Loss: 1.1660
Epoch [5/50] - Loss: 1.0995
Epoch [6/50] - Loss: 1.0464
Epoch [7/50] - Loss: 1.0134
Epoch [8/50] - Loss: 0.9903
Epoch [9/50] - Loss: 0.9693
Epoch [10/50] - Loss: 0.9482
Epoch [11/50] - Loss: 0.9298
Epoch [12/50] - Loss: 0.9125
Epoch [13/50] - Loss: 0.8940
Epoch [14/50] - Loss: 0.8763
Epoch [15/50] - Loss: 0.8578
Epoch [16/50] - Loss: 0.8404
Epoch [17/50] - Loss: 0.8216
Epoch [18/50] - Loss: 0.8031
Epoch [19/50] - Loss: 0.7843
Epoch [20/50] - Loss: 0.7658
Epoch [21/50] - Loss: 0.7472
Epoch [22/50] - Loss: 0.7282
Epoch [23/50] - Loss: 0.7083
Epoch [24/50] - Loss: 0.6881
Epoch [25/50] - Loss: 0.6695
Epoch [26/50] - Loss: 0.6492
Epoch [27/50] - Loss: 0.6296
Epoch [28/50] - Loss: 0.6109
Epoch [29/50] - Loss: 0.5914
Epoch [30/50] - Loss: 0.5713
Epoch [31/50] - Loss: 0.5531
Epoch [32/50] - Loss: 0.5343
Epoch [33/50] - Loss: 0.5155
Epoch [34/50] - Loss: 0.4972
Epoch [35/50] - Loss: 0.4786
Epoch [36/50] - Loss: 0.4589
Epoch [37/50] - Loss: 0.4410
Epoch [38/50] - Loss: 0.4238
Epoch [39/50] - Loss: 0.4066
Epoch [40/50] - Loss: 0.3902
Epoch [41/50] - Loss: 0.3742
Epoch [42/50] - Loss: 0.3589
Epoch [43/50] - Loss: 0.3444
Epoch [44/50] - Loss: 0.3305
Epoch [45/50] - Loss: 0.3175
Epoch [46/50] - Loss: 0.3054
Epoch [47/50] - Loss: 0.2927
Epoch [48/50] - Loss: 0.2816
Epoch [49/50] - Loss: 0.2711
Epoch [50/50] - Loss: 0.2598
sum preds 50
sum labels 1875
 - Test Metrics: Accuracy=0.8309, F1=0.0426, Recall=0.0219, Precision=0.8200
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.0678
Epoch [2/50] - Loss: 1.2423
Epoch [3/50] - Loss: 1.1569
Epoch [4/50] - Loss: 1.0915
Epoch [5/50] - Loss: 1.0408
Epoch [6/50] - Loss: 1.0094
Epoch [7/50] - Loss: 0.9846
Epoch [8/50] - Loss: 0.9612
Epoch [9/50] - Loss: 0.9398
Epoch [10/50] - Loss: 0.9181
Epoch [11/50] - Loss: 0.8981
Epoch [12/50] - Loss: 0.8776
Epoch [13/50] - Loss: 0.8566
Epoch [14/50] - Loss: 0.8356
Epoch [15/50] - Loss: 0.8150
Epoch [16/50] - Loss: 0.7952
Epoch [17/50] - Loss: 0.7733
Epoch [18/50] - Loss: 0.7510
Epoch [19/50] - Loss: 0.7276
Epoch [20/50] - Loss: 0.7032
Epoch [21/50] - Loss: 0.6778
Epoch [22/50] - Loss: 0.6528
Epoch [23/50] - Loss: 0.6281
Epoch [24/50] - Loss: 0.6028
Epoch [25/50] - Loss: 0.5780
Epoch [26/50] - Loss: 0.5544
Epoch [27/50] - Loss: 0.5298
Epoch [28/50] - Loss: 0.5067
Epoch [29/50] - Loss: 0.4850
Epoch [30/50] - Loss: 0.4653
Epoch [31/50] - Loss: 0.4431
Epoch [32/50] - Loss: 0.4236
Epoch [33/50] - Loss: 0.4057
Epoch [34/50] - Loss: 0.3872
Epoch [35/50] - Loss: 0.3692
Epoch [36/50] - Loss: 0.3560
Epoch [37/50] - Loss: 0.3408
Epoch [38/50] - Loss: 0.3261
Epoch [39/50] - Loss: 0.3121
Epoch [40/50] - Loss: 0.2994
Epoch [41/50] - Loss: 0.2869
Epoch [42/50] - Loss: 0.2754
Epoch [43/50] - Loss: 0.2643
Epoch [44/50] - Loss: 0.2541
Epoch [45/50] - Loss: 0.2458
Epoch [46/50] - Loss: 0.2349
Epoch [47/50] - Loss: 0.2253
Epoch [48/50] - Loss: 0.2162
Epoch [49/50] - Loss: 0.2082
Epoch [50/50] - Loss: 0.2004
sum preds 29
sum labels 1875
 - Test Metrics: Accuracy=0.8306, F1=0.0305, Recall=0.0155, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_naive_naive_1904044255.csv.
Average F1 over valid seeds: 0.0410 ± 0.0080
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and naive, MLP,0.3: 0.0410 ± 0.0080
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1502
Epoch [2/50] - Loss: 1.3210
Epoch [3/50] - Loss: 1.1846
Epoch [4/50] - Loss: 1.1277
Epoch [5/50] - Loss: 1.0794
Epoch [6/50] - Loss: 1.0458
Epoch [7/50] - Loss: 1.0238
Epoch [8/50] - Loss: 1.0136
Epoch [9/50] - Loss: 1.0014
Epoch [10/50] - Loss: 0.9896
Epoch [11/50] - Loss: 0.9831
Epoch [12/50] - Loss: 0.9748
Epoch [13/50] - Loss: 0.9670
Epoch [14/50] - Loss: 0.9595
Epoch [15/50] - Loss: 0.9563
Epoch [16/50] - Loss: 0.9477
Epoch [17/50] - Loss: 0.9423
Epoch [18/50] - Loss: 0.9362
Epoch [19/50] - Loss: 0.9330
Epoch [20/50] - Loss: 0.9272
Epoch [21/50] - Loss: 0.9213
Epoch [22/50] - Loss: 0.9168
Epoch [23/50] - Loss: 0.9121
Epoch [24/50] - Loss: 0.9078
Epoch [25/50] - Loss: 0.9020
Epoch [26/50] - Loss: 0.8995
Epoch [27/50] - Loss: 0.8945
Epoch [28/50] - Loss: 0.8901
Epoch [29/50] - Loss: 0.8860
Epoch [30/50] - Loss: 0.8836
Epoch [31/50] - Loss: 0.8773
Epoch [32/50] - Loss: 0.8731
Epoch [33/50] - Loss: 0.8717
Epoch [34/50] - Loss: 0.8660
Epoch [35/50] - Loss: 0.8611
Epoch [36/50] - Loss: 0.8595
Epoch [37/50] - Loss: 0.8517
Epoch [38/50] - Loss: 0.8516
Epoch [39/50] - Loss: 0.8474
Epoch [40/50] - Loss: 0.8431
Epoch [41/50] - Loss: 0.8378
Epoch [42/50] - Loss: 0.8343
Epoch [43/50] - Loss: 0.8316
Epoch [44/50] - Loss: 0.8286
Epoch [45/50] - Loss: 0.8265
Epoch [46/50] - Loss: 0.8207
Epoch [47/50] - Loss: 0.8188
Epoch [48/50] - Loss: 0.8116
Epoch [49/50] - Loss: 0.8120
Epoch [50/50] - Loss: 0.8046
sum preds 44
sum labels 1875
 - Test Metrics: Accuracy=0.8314, F1=0.0427, Recall=0.0219, Precision=0.9318
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.0653
Epoch [2/50] - Loss: 1.2954
Epoch [3/50] - Loss: 1.1601
Epoch [4/50] - Loss: 1.0944
Epoch [5/50] - Loss: 1.0603
Epoch [6/50] - Loss: 1.0390
Epoch [7/50] - Loss: 1.0200
Epoch [8/50] - Loss: 1.0070
Epoch [9/50] - Loss: 0.9975
Epoch [10/50] - Loss: 0.9866
Epoch [11/50] - Loss: 0.9790
Epoch [12/50] - Loss: 0.9725
Epoch [13/50] - Loss: 0.9656
Epoch [14/50] - Loss: 0.9592
Epoch [15/50] - Loss: 0.9539
Epoch [16/50] - Loss: 0.9489
Epoch [17/50] - Loss: 0.9441
Epoch [18/50] - Loss: 0.9395
Epoch [19/50] - Loss: 0.9362
Epoch [20/50] - Loss: 0.9316
Epoch [21/50] - Loss: 0.9274
Epoch [22/50] - Loss: 0.9231
Epoch [23/50] - Loss: 0.9243
Epoch [24/50] - Loss: 0.9289
Epoch [25/50] - Loss: 0.9192
Epoch [26/50] - Loss: 0.9110
Epoch [27/50] - Loss: 0.9070
Epoch [28/50] - Loss: 0.9035
Epoch [29/50] - Loss: 0.8959
Epoch [30/50] - Loss: 0.8979
Epoch [31/50] - Loss: 0.8961
Epoch [32/50] - Loss: 0.8929
Epoch [33/50] - Loss: 0.8890
Epoch [34/50] - Loss: 0.8828
Epoch [35/50] - Loss: 0.8781
Epoch [36/50] - Loss: 0.8758
Epoch [37/50] - Loss: 0.8725
Epoch [38/50] - Loss: 0.8687
Epoch [39/50] - Loss: 0.8687
Epoch [40/50] - Loss: 0.8622
Epoch [41/50] - Loss: 0.8591
Epoch [42/50] - Loss: 0.8579
Epoch [43/50] - Loss: 0.8505
Epoch [44/50] - Loss: 0.8477
Epoch [45/50] - Loss: 0.8481
Epoch [46/50] - Loss: 0.8412
Epoch [47/50] - Loss: 0.8371
Epoch [48/50] - Loss: 0.8334
Epoch [49/50] - Loss: 0.8318
Epoch [50/50] - Loss: 0.8276
sum preds 71
sum labels 1875
 - Test Metrics: Accuracy=0.8337, F1=0.0689, Recall=0.0357, Precision=0.9437
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.3499
Epoch [2/50] - Loss: 1.3659
Epoch [3/50] - Loss: 1.2061
Epoch [4/50] - Loss: 1.1355
Epoch [5/50] - Loss: 1.0958
Epoch [6/50] - Loss: 1.0646
Epoch [7/50] - Loss: 1.0444
Epoch [8/50] - Loss: 1.0338
Epoch [9/50] - Loss: 1.0186
Epoch [10/50] - Loss: 1.0050
Epoch [11/50] - Loss: 0.9967
Epoch [12/50] - Loss: 0.9868
Epoch [13/50] - Loss: 0.9755
Epoch [14/50] - Loss: 0.9691
Epoch [15/50] - Loss: 0.9619
Epoch [16/50] - Loss: 0.9552
Epoch [17/50] - Loss: 0.9488
Epoch [18/50] - Loss: 0.9454
Epoch [19/50] - Loss: 0.9384
Epoch [20/50] - Loss: 0.9329
Epoch [21/50] - Loss: 0.9272
Epoch [22/50] - Loss: 0.9219
Epoch [23/50] - Loss: 0.9155
Epoch [24/50] - Loss: 0.9102
Epoch [25/50] - Loss: 0.9056
Epoch [26/50] - Loss: 0.9019
Epoch [27/50] - Loss: 0.8978
Epoch [28/50] - Loss: 0.8922
Epoch [29/50] - Loss: 0.8872
Epoch [30/50] - Loss: 0.8823
Epoch [31/50] - Loss: 0.8799
Epoch [32/50] - Loss: 0.8756
Epoch [33/50] - Loss: 0.8728
Epoch [34/50] - Loss: 0.8678
Epoch [35/50] - Loss: 0.8659
Epoch [36/50] - Loss: 0.8615
Epoch [37/50] - Loss: 0.8597
Epoch [38/50] - Loss: 0.8538
Epoch [39/50] - Loss: 0.8520
Epoch [40/50] - Loss: 0.8472
Epoch [41/50] - Loss: 0.8457
Epoch [42/50] - Loss: 0.8392
Epoch [43/50] - Loss: 0.8402
Epoch [44/50] - Loss: 0.8334
Epoch [45/50] - Loss: 0.8324
Epoch [46/50] - Loss: 0.8272
Epoch [47/50] - Loss: 0.8220
Epoch [48/50] - Loss: 0.8223
Epoch [49/50] - Loss: 0.8185
Epoch [50/50] - Loss: 0.8123
sum preds 46
sum labels 1875
 - Test Metrics: Accuracy=0.8322, F1=0.0479, Recall=0.0245, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_naive_naive_1904045154.csv.
Average F1 over valid seeds: 0.0532 ± 0.0113
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and naive, GATConv,0.3: 0.0532 ± 0.0113
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.6455
Epoch [2/50] - Loss: 1.4028
Epoch [3/50] - Loss: 1.2113
Epoch [4/50] - Loss: 1.1624
Epoch [5/50] - Loss: 1.1312
Epoch [6/50] - Loss: 1.1090
Epoch [7/50] - Loss: 1.0945
Epoch [8/50] - Loss: 1.0800
Epoch [9/50] - Loss: 1.0692
Epoch [10/50] - Loss: 1.0611
Epoch [11/50] - Loss: 1.0512
Epoch [12/50] - Loss: 1.0451
Epoch [13/50] - Loss: 1.0398
Epoch [14/50] - Loss: 1.0340
Epoch [15/50] - Loss: 1.0294
Epoch [16/50] - Loss: 1.0234
Epoch [17/50] - Loss: 1.0198
Epoch [18/50] - Loss: 1.0153
Epoch [19/50] - Loss: 1.0117
Epoch [20/50] - Loss: 1.0072
Epoch [21/50] - Loss: 1.0013
Epoch [22/50] - Loss: 0.9975
Epoch [23/50] - Loss: 0.9949
Epoch [24/50] - Loss: 0.9909
Epoch [25/50] - Loss: 0.9882
Epoch [26/50] - Loss: 0.9832
Epoch [27/50] - Loss: 0.9797
Epoch [28/50] - Loss: 0.9762
Epoch [29/50] - Loss: 0.9719
Epoch [30/50] - Loss: 0.9691
Epoch [31/50] - Loss: 0.9657
Epoch [32/50] - Loss: 0.9622
Epoch [33/50] - Loss: 0.9595
Epoch [34/50] - Loss: 0.9573
Epoch [35/50] - Loss: 0.9544
Epoch [36/50] - Loss: 0.9507
Epoch [37/50] - Loss: 0.9477
Epoch [38/50] - Loss: 0.9448
Epoch [39/50] - Loss: 0.9417
Epoch [40/50] - Loss: 0.9387
Epoch [41/50] - Loss: 0.9348
Epoch [42/50] - Loss: 0.9333
Epoch [43/50] - Loss: 0.9311
Epoch [44/50] - Loss: 0.9287
Epoch [45/50] - Loss: 0.9269
Epoch [46/50] - Loss: 0.9225
Epoch [47/50] - Loss: 0.9208
Epoch [48/50] - Loss: 0.9174
Epoch [49/50] - Loss: 0.9147
Epoch [50/50] - Loss: 0.9131
sum preds 57
sum labels 1875
 - Test Metrics: Accuracy=0.8328, F1=0.0569, Recall=0.0293, Precision=0.9649
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.5319
Epoch [2/50] - Loss: 1.7574
Epoch [3/50] - Loss: 1.3426
Epoch [4/50] - Loss: 1.2468
Epoch [5/50] - Loss: 1.2032
Epoch [6/50] - Loss: 1.1715
Epoch [7/50] - Loss: 1.1520
Epoch [8/50] - Loss: 1.1384
Epoch [9/50] - Loss: 1.1237
Epoch [10/50] - Loss: 1.1128
Epoch [11/50] - Loss: 1.1035
Epoch [12/50] - Loss: 1.0961
Epoch [13/50] - Loss: 1.0884
Epoch [14/50] - Loss: 1.0823
Epoch [15/50] - Loss: 1.0763
Epoch [16/50] - Loss: 1.0696
Epoch [17/50] - Loss: 1.0656
Epoch [18/50] - Loss: 1.0621
Epoch [19/50] - Loss: 1.0556
Epoch [20/50] - Loss: 1.0529
Epoch [21/50] - Loss: 1.0477
Epoch [22/50] - Loss: 1.0429
Epoch [23/50] - Loss: 1.0404
Epoch [24/50] - Loss: 1.0364
Epoch [25/50] - Loss: 1.0330
Epoch [26/50] - Loss: 1.0292
Epoch [27/50] - Loss: 1.0262
Epoch [28/50] - Loss: 1.0214
Epoch [29/50] - Loss: 1.0212
Epoch [30/50] - Loss: 1.0168
Epoch [31/50] - Loss: 1.0131
Epoch [32/50] - Loss: 1.0118
Epoch [33/50] - Loss: 1.0095
Epoch [34/50] - Loss: 1.0068
Epoch [35/50] - Loss: 1.0040
Epoch [36/50] - Loss: 1.0015
Epoch [37/50] - Loss: 0.9996
Epoch [38/50] - Loss: 0.9969
Epoch [39/50] - Loss: 0.9938
Epoch [40/50] - Loss: 0.9908
Epoch [41/50] - Loss: 0.9884
Epoch [42/50] - Loss: 0.9860
Epoch [43/50] - Loss: 0.9843
Epoch [44/50] - Loss: 0.9821
Epoch [45/50] - Loss: 0.9788
Epoch [46/50] - Loss: 0.9775
Epoch [47/50] - Loss: 0.9740
Epoch [48/50] - Loss: 0.9725
Epoch [49/50] - Loss: 0.9701
Epoch [50/50] - Loss: 0.9683
sum preds 46
sum labels 1875
 - Test Metrics: Accuracy=0.8322, F1=0.0479, Recall=0.0245, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.2554
Epoch [2/50] - Loss: 3.3714
Epoch [3/50] - Loss: 2.3114
Epoch [4/50] - Loss: 1.7258
Epoch [5/50] - Loss: 1.4184
Epoch [6/50] - Loss: 1.2811
Epoch [7/50] - Loss: 1.2110
Epoch [8/50] - Loss: 1.1713
Epoch [9/50] - Loss: 1.1400
Epoch [10/50] - Loss: 1.1157
Epoch [11/50] - Loss: 1.0984
Epoch [12/50] - Loss: 1.0871
Epoch [13/50] - Loss: 1.0771
Epoch [14/50] - Loss: 1.0670
Epoch [15/50] - Loss: 1.0610
Epoch [16/50] - Loss: 1.0528
Epoch [17/50] - Loss: 1.0454
Epoch [18/50] - Loss: 1.0415
Epoch [19/50] - Loss: 1.0364
Epoch [20/50] - Loss: 1.0314
Epoch [21/50] - Loss: 1.0260
Epoch [22/50] - Loss: 1.0248
Epoch [23/50] - Loss: 1.0192
Epoch [24/50] - Loss: 1.0167
Epoch [25/50] - Loss: 1.0133
Epoch [26/50] - Loss: 1.0104
Epoch [27/50] - Loss: 1.0077
Epoch [28/50] - Loss: 1.0053
Epoch [29/50] - Loss: 1.0024
Epoch [30/50] - Loss: 0.9981
Epoch [31/50] - Loss: 0.9967
Epoch [32/50] - Loss: 0.9936
Epoch [33/50] - Loss: 0.9920
Epoch [34/50] - Loss: 0.9900
Epoch [35/50] - Loss: 0.9872
Epoch [36/50] - Loss: 0.9847
Epoch [37/50] - Loss: 0.9830
Epoch [38/50] - Loss: 0.9808
Epoch [39/50] - Loss: 0.9796
Epoch [40/50] - Loss: 0.9759
Epoch [41/50] - Loss: 0.9746
Epoch [42/50] - Loss: 0.9721
Epoch [43/50] - Loss: 0.9692
Epoch [44/50] - Loss: 0.9681
Epoch [45/50] - Loss: 0.9654
Epoch [46/50] - Loss: 0.9655
Epoch [47/50] - Loss: 0.9612
Epoch [48/50] - Loss: 0.9600
Epoch [49/50] - Loss: 0.9580
Epoch [50/50] - Loss: 0.9567
sum preds 53
sum labels 1875
 - Test Metrics: Accuracy=0.8321, F1=0.0508, Recall=0.0261, Precision=0.9245
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_naive_naive_1904050115.csv.
Average F1 over valid seeds: 0.0519 ± 0.0038
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and naive, GCNConv,0.3: 0.0519 ± 0.0038
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.0355
Epoch [2/50] - Loss: 1.2510
Epoch [3/50] - Loss: 1.0198
Epoch [4/50] - Loss: 0.9680
Epoch [5/50] - Loss: 0.9061
Epoch [6/50] - Loss: 0.8543
Epoch [7/50] - Loss: 0.8222
Epoch [8/50] - Loss: 0.7973
Epoch [9/50] - Loss: 0.7747
Epoch [10/50] - Loss: 0.7534
Epoch [11/50] - Loss: 0.7331
Epoch [12/50] - Loss: 0.7139
Epoch [13/50] - Loss: 0.6963
Epoch [14/50] - Loss: 0.6803
Epoch [15/50] - Loss: 0.6635
Epoch [16/50] - Loss: 0.6485
Epoch [17/50] - Loss: 0.6334
Epoch [18/50] - Loss: 0.6182
Epoch [19/50] - Loss: 0.6056
Epoch [20/50] - Loss: 0.5910
Epoch [21/50] - Loss: 0.5773
Epoch [22/50] - Loss: 0.5642
Epoch [23/50] - Loss: 0.5508
Epoch [24/50] - Loss: 0.5377
Epoch [25/50] - Loss: 0.5258
Epoch [26/50] - Loss: 0.5119
Epoch [27/50] - Loss: 0.4999
Epoch [28/50] - Loss: 0.4869
Epoch [29/50] - Loss: 0.4737
Epoch [30/50] - Loss: 0.4603
Epoch [31/50] - Loss: 0.4479
Epoch [32/50] - Loss: 0.4346
Epoch [33/50] - Loss: 0.4209
Epoch [34/50] - Loss: 0.4088
Epoch [35/50] - Loss: 0.3965
Epoch [36/50] - Loss: 0.3841
Epoch [37/50] - Loss: 0.3720
Epoch [38/50] - Loss: 0.3596
Epoch [39/50] - Loss: 0.3481
Epoch [40/50] - Loss: 0.3358
Epoch [41/50] - Loss: 0.3245
Epoch [42/50] - Loss: 0.3137
Epoch [43/50] - Loss: 0.3026
Epoch [44/50] - Loss: 0.2922
Epoch [45/50] - Loss: 0.2826
Epoch [46/50] - Loss: 0.2732
Epoch [47/50] - Loss: 0.2633
Epoch [48/50] - Loss: 0.2545
Epoch [49/50] - Loss: 0.2460
Epoch [50/50] - Loss: 0.2379
sum preds 15
sum labels 2143
 - Test Metrics: Accuracy=0.8092, F1=0.0130, Recall=0.0065, Precision=0.9333
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.8905
Epoch [2/50] - Loss: 1.2285
Epoch [3/50] - Loss: 0.9958
Epoch [4/50] - Loss: 0.9693
Epoch [5/50] - Loss: 0.9235
Epoch [6/50] - Loss: 0.8763
Epoch [7/50] - Loss: 0.8436
Epoch [8/50] - Loss: 0.8196
Epoch [9/50] - Loss: 0.8008
Epoch [10/50] - Loss: 0.7811
Epoch [11/50] - Loss: 0.7640
Epoch [12/50] - Loss: 0.7488
Epoch [13/50] - Loss: 0.7332
Epoch [14/50] - Loss: 0.7181
Epoch [15/50] - Loss: 0.7020
Epoch [16/50] - Loss: 0.6877
Epoch [17/50] - Loss: 0.6718
Epoch [18/50] - Loss: 0.6567
Epoch [19/50] - Loss: 0.6410
Epoch [20/50] - Loss: 0.6266
Epoch [21/50] - Loss: 0.6105
Epoch [22/50] - Loss: 0.5959
Epoch [23/50] - Loss: 0.5808
Epoch [24/50] - Loss: 0.5648
Epoch [25/50] - Loss: 0.5502
Epoch [26/50] - Loss: 0.5343
Epoch [27/50] - Loss: 0.5193
Epoch [28/50] - Loss: 0.5041
Epoch [29/50] - Loss: 0.4883
Epoch [30/50] - Loss: 0.4723
Epoch [31/50] - Loss: 0.4569
Epoch [32/50] - Loss: 0.4411
Epoch [33/50] - Loss: 0.4252
Epoch [34/50] - Loss: 0.4116
Epoch [35/50] - Loss: 0.3965
Epoch [36/50] - Loss: 0.3817
Epoch [37/50] - Loss: 0.3680
Epoch [38/50] - Loss: 0.3556
Epoch [39/50] - Loss: 0.3420
Epoch [40/50] - Loss: 0.3286
Epoch [41/50] - Loss: 0.3160
Epoch [42/50] - Loss: 0.3047
Epoch [43/50] - Loss: 0.2932
Epoch [44/50] - Loss: 0.2821
Epoch [45/50] - Loss: 0.2713
Epoch [46/50] - Loss: 0.2615
Epoch [47/50] - Loss: 0.2509
Epoch [48/50] - Loss: 0.2416
Epoch [49/50] - Loss: 0.2326
Epoch [50/50] - Loss: 0.2231
sum preds 20
sum labels 2143
 - Test Metrics: Accuracy=0.8088, F1=0.0129, Recall=0.0065, Precision=0.7000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9362
Epoch [2/50] - Loss: 1.0117
Epoch [3/50] - Loss: 0.9439
Epoch [4/50] - Loss: 0.8967
Epoch [5/50] - Loss: 0.8502
Epoch [6/50] - Loss: 0.8178
Epoch [7/50] - Loss: 0.7941
Epoch [8/50] - Loss: 0.7721
Epoch [9/50] - Loss: 0.7527
Epoch [10/50] - Loss: 0.7328
Epoch [11/50] - Loss: 0.7164
Epoch [12/50] - Loss: 0.6989
Epoch [13/50] - Loss: 0.6805
Epoch [14/50] - Loss: 0.6619
Epoch [15/50] - Loss: 0.6437
Epoch [16/50] - Loss: 0.6267
Epoch [17/50] - Loss: 0.6085
Epoch [18/50] - Loss: 0.5910
Epoch [19/50] - Loss: 0.5737
Epoch [20/50] - Loss: 0.5564
Epoch [21/50] - Loss: 0.5382
Epoch [22/50] - Loss: 0.5209
Epoch [23/50] - Loss: 0.5042
Epoch [24/50] - Loss: 0.4870
Epoch [25/50] - Loss: 0.4686
Epoch [26/50] - Loss: 0.4518
Epoch [27/50] - Loss: 0.4332
Epoch [28/50] - Loss: 0.4173
Epoch [29/50] - Loss: 0.4001
Epoch [30/50] - Loss: 0.3844
Epoch [31/50] - Loss: 0.3688
Epoch [32/50] - Loss: 0.3539
Epoch [33/50] - Loss: 0.3396
Epoch [34/50] - Loss: 0.3253
Epoch [35/50] - Loss: 0.3122
Epoch [36/50] - Loss: 0.3000
Epoch [37/50] - Loss: 0.2872
Epoch [38/50] - Loss: 0.2751
Epoch [39/50] - Loss: 0.2635
Epoch [40/50] - Loss: 0.2529
Epoch [41/50] - Loss: 0.2428
Epoch [42/50] - Loss: 0.2329
Epoch [43/50] - Loss: 0.2233
Epoch [44/50] - Loss: 0.2150
Epoch [45/50] - Loss: 0.2064
Epoch [46/50] - Loss: 0.1991
Epoch [47/50] - Loss: 0.1911
Epoch [48/50] - Loss: 0.1840
Epoch [49/50] - Loss: 0.1769
Epoch [50/50] - Loss: 0.1703
sum preds 8
sum labels 2143
 - Test Metrics: Accuracy=0.8088, F1=0.0074, Recall=0.0037, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_naive_naive_1904051032.csv.
Average F1 over valid seeds: 0.0111 ± 0.0026
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and naive, MLP,0.2: 0.0111 ± 0.0026
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8895
Epoch [2/50] - Loss: 1.1102
Epoch [3/50] - Loss: 0.9651
Epoch [4/50] - Loss: 0.9031
Epoch [5/50] - Loss: 0.8582
Epoch [6/50] - Loss: 0.8310
Epoch [7/50] - Loss: 0.8088
Epoch [8/50] - Loss: 0.7980
Epoch [9/50] - Loss: 0.7892
Epoch [10/50] - Loss: 0.7841
Epoch [11/50] - Loss: 0.7793
Epoch [12/50] - Loss: 0.7721
Epoch [13/50] - Loss: 0.7673
Epoch [14/50] - Loss: 0.7610
Epoch [15/50] - Loss: 0.7604
Epoch [16/50] - Loss: 0.7551
Epoch [17/50] - Loss: 0.7513
Epoch [18/50] - Loss: 0.7464
Epoch [19/50] - Loss: 0.7450
Epoch [20/50] - Loss: 0.7399
Epoch [21/50] - Loss: 0.7373
Epoch [22/50] - Loss: 0.7335
Epoch [23/50] - Loss: 0.7299
Epoch [24/50] - Loss: 0.7261
Epoch [25/50] - Loss: 0.7231
Epoch [26/50] - Loss: 0.7203
Epoch [27/50] - Loss: 0.7161
Epoch [28/50] - Loss: 0.7135
Epoch [29/50] - Loss: 0.7100
Epoch [30/50] - Loss: 0.7079
Epoch [31/50] - Loss: 0.7034
Epoch [32/50] - Loss: 0.7019
Epoch [33/50] - Loss: 0.6998
Epoch [34/50] - Loss: 0.6951
Epoch [35/50] - Loss: 0.6930
Epoch [36/50] - Loss: 0.6903
Epoch [37/50] - Loss: 0.6856
Epoch [38/50] - Loss: 0.6850
Epoch [39/50] - Loss: 0.6788
Epoch [40/50] - Loss: 0.6769
Epoch [41/50] - Loss: 0.6739
Epoch [42/50] - Loss: 0.6710
Epoch [43/50] - Loss: 0.6688
Epoch [44/50] - Loss: 0.6635
Epoch [45/50] - Loss: 0.6611
Epoch [46/50] - Loss: 0.6570
Epoch [47/50] - Loss: 0.6544
Epoch [48/50] - Loss: 0.6494
Epoch [49/50] - Loss: 0.6522
Epoch [50/50] - Loss: 0.6438
sum preds 20
sum labels 2143
 - Test Metrics: Accuracy=0.8091, F1=0.0148, Recall=0.0075, Precision=0.8000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8943
Epoch [2/50] - Loss: 1.0831
Epoch [3/50] - Loss: 0.9470
Epoch [4/50] - Loss: 0.9021
Epoch [5/50] - Loss: 0.8626
Epoch [6/50] - Loss: 0.8431
Epoch [7/50] - Loss: 0.8295
Epoch [8/50] - Loss: 0.8172
Epoch [9/50] - Loss: 0.8093
Epoch [10/50] - Loss: 0.8017
Epoch [11/50] - Loss: 0.7949
Epoch [12/50] - Loss: 0.7888
Epoch [13/50] - Loss: 0.7837
Epoch [14/50] - Loss: 0.7773
Epoch [15/50] - Loss: 0.7720
Epoch [16/50] - Loss: 0.7672
Epoch [17/50] - Loss: 0.7634
Epoch [18/50] - Loss: 0.7600
Epoch [19/50] - Loss: 0.7558
Epoch [20/50] - Loss: 0.7525
Epoch [21/50] - Loss: 0.7511
Epoch [22/50] - Loss: 0.7456
Epoch [23/50] - Loss: 0.7438
Epoch [24/50] - Loss: 0.7389
Epoch [25/50] - Loss: 0.7360
Epoch [26/50] - Loss: 0.7332
Epoch [27/50] - Loss: 0.7299
Epoch [28/50] - Loss: 0.7259
Epoch [29/50] - Loss: 0.7221
Epoch [30/50] - Loss: 0.7212
Epoch [31/50] - Loss: 0.7162
Epoch [32/50] - Loss: 0.7155
Epoch [33/50] - Loss: 0.7138
Epoch [34/50] - Loss: 0.7073
Epoch [35/50] - Loss: 0.7034
Epoch [36/50] - Loss: 0.7016
Epoch [37/50] - Loss: 0.6974
Epoch [38/50] - Loss: 0.6951
Epoch [39/50] - Loss: 0.6928
Epoch [40/50] - Loss: 0.6887
Epoch [41/50] - Loss: 0.6861
Epoch [42/50] - Loss: 0.6841
Epoch [43/50] - Loss: 0.6847
Epoch [44/50] - Loss: 0.6796
Epoch [45/50] - Loss: 0.6749
Epoch [46/50] - Loss: 0.6719
Epoch [47/50] - Loss: 0.6707
Epoch [48/50] - Loss: 0.6666
Epoch [49/50] - Loss: 0.6666
Epoch [50/50] - Loss: 0.6638
sum preds 17
sum labels 2143
 - Test Metrics: Accuracy=0.8094, F1=0.0148, Recall=0.0075, Precision=0.9412
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1318
Epoch [2/50] - Loss: 1.1306
Epoch [3/50] - Loss: 1.0099
Epoch [4/50] - Loss: 0.9357
Epoch [5/50] - Loss: 0.8909
Epoch [6/50] - Loss: 0.8676
Epoch [7/50] - Loss: 0.8440
Epoch [8/50] - Loss: 0.8338
Epoch [9/50] - Loss: 0.8198
Epoch [10/50] - Loss: 0.8085
Epoch [11/50] - Loss: 0.8011
Epoch [12/50] - Loss: 0.7935
Epoch [13/50] - Loss: 0.7871
Epoch [14/50] - Loss: 0.7817
Epoch [15/50] - Loss: 0.7779
Epoch [16/50] - Loss: 0.7707
Epoch [17/50] - Loss: 0.7658
Epoch [18/50] - Loss: 0.7631
Epoch [19/50] - Loss: 0.7587
Epoch [20/50] - Loss: 0.7535
Epoch [21/50] - Loss: 0.7481
Epoch [22/50] - Loss: 0.7446
Epoch [23/50] - Loss: 0.7404
Epoch [24/50] - Loss: 0.7371
Epoch [25/50] - Loss: 0.7323
Epoch [26/50] - Loss: 0.7294
Epoch [27/50] - Loss: 0.7249
Epoch [28/50] - Loss: 0.7204
Epoch [29/50] - Loss: 0.7171
Epoch [30/50] - Loss: 0.7127
Epoch [31/50] - Loss: 0.7109
Epoch [32/50] - Loss: 0.7082
Epoch [33/50] - Loss: 0.7044
Epoch [34/50] - Loss: 0.6997
Epoch [35/50] - Loss: 0.6988
Epoch [36/50] - Loss: 0.6961
Epoch [37/50] - Loss: 0.6921
Epoch [38/50] - Loss: 0.6893
Epoch [39/50] - Loss: 0.6881
Epoch [40/50] - Loss: 0.6840
Epoch [41/50] - Loss: 0.6809
Epoch [42/50] - Loss: 0.6786
Epoch [43/50] - Loss: 0.6773
Epoch [44/50] - Loss: 0.6720
Epoch [45/50] - Loss: 0.6712
Epoch [46/50] - Loss: 0.6664
Epoch [47/50] - Loss: 0.6633
Epoch [48/50] - Loss: 0.6618
Epoch [49/50] - Loss: 0.6578
Epoch [50/50] - Loss: 0.6544
sum preds 15
sum labels 2143
 - Test Metrics: Accuracy=0.8092, F1=0.0130, Recall=0.0065, Precision=0.9333
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_naive_naive_1904051930.csv.
Average F1 over valid seeds: 0.0142 ± 0.0009
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and naive, GATConv,0.2: 0.0142 ± 0.0009
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.5718
Epoch [2/50] - Loss: 1.2288
Epoch [3/50] - Loss: 0.9984
Epoch [4/50] - Loss: 0.9532
Epoch [5/50] - Loss: 0.9280
Epoch [6/50] - Loss: 0.9055
Epoch [7/50] - Loss: 0.8888
Epoch [8/50] - Loss: 0.8782
Epoch [9/50] - Loss: 0.8655
Epoch [10/50] - Loss: 0.8582
Epoch [11/50] - Loss: 0.8497
Epoch [12/50] - Loss: 0.8425
Epoch [13/50] - Loss: 0.8379
Epoch [14/50] - Loss: 0.8321
Epoch [15/50] - Loss: 0.8277
Epoch [16/50] - Loss: 0.8222
Epoch [17/50] - Loss: 0.8189
Epoch [18/50] - Loss: 0.8154
Epoch [19/50] - Loss: 0.8117
Epoch [20/50] - Loss: 0.8074
Epoch [21/50] - Loss: 0.8033
Epoch [22/50] - Loss: 0.7995
Epoch [23/50] - Loss: 0.7969
Epoch [24/50] - Loss: 0.7939
Epoch [25/50] - Loss: 0.7920
Epoch [26/50] - Loss: 0.7872
Epoch [27/50] - Loss: 0.7845
Epoch [28/50] - Loss: 0.7818
Epoch [29/50] - Loss: 0.7787
Epoch [30/50] - Loss: 0.7756
Epoch [31/50] - Loss: 0.7738
Epoch [32/50] - Loss: 0.7702
Epoch [33/50] - Loss: 0.7674
Epoch [34/50] - Loss: 0.7652
Epoch [35/50] - Loss: 0.7626
Epoch [36/50] - Loss: 0.7602
Epoch [37/50] - Loss: 0.7580
Epoch [38/50] - Loss: 0.7549
Epoch [39/50] - Loss: 0.7522
Epoch [40/50] - Loss: 0.7497
Epoch [41/50] - Loss: 0.7479
Epoch [42/50] - Loss: 0.7448
Epoch [43/50] - Loss: 0.7442
Epoch [44/50] - Loss: 0.7412
Epoch [45/50] - Loss: 0.7408
Epoch [46/50] - Loss: 0.7368
Epoch [47/50] - Loss: 0.7352
Epoch [48/50] - Loss: 0.7327
Epoch [49/50] - Loss: 0.7307
Epoch [50/50] - Loss: 0.7292
sum preds 12
sum labels 2143
 - Test Metrics: Accuracy=0.8086, F1=0.0084, Recall=0.0042, Precision=0.7500
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.4787
Epoch [2/50] - Loss: 1.6144
Epoch [3/50] - Loss: 1.1470
Epoch [4/50] - Loss: 1.0299
Epoch [5/50] - Loss: 0.9949
Epoch [6/50] - Loss: 0.9697
Epoch [7/50] - Loss: 0.9452
Epoch [8/50] - Loss: 0.9308
Epoch [9/50] - Loss: 0.9206
Epoch [10/50] - Loss: 0.9123
Epoch [11/50] - Loss: 0.9025
Epoch [12/50] - Loss: 0.8972
Epoch [13/50] - Loss: 0.8904
Epoch [14/50] - Loss: 0.8846
Epoch [15/50] - Loss: 0.8798
Epoch [16/50] - Loss: 0.8735
Epoch [17/50] - Loss: 0.8710
Epoch [18/50] - Loss: 0.8675
Epoch [19/50] - Loss: 0.8615
Epoch [20/50] - Loss: 0.8593
Epoch [21/50] - Loss: 0.8558
Epoch [22/50] - Loss: 0.8511
Epoch [23/50] - Loss: 0.8498
Epoch [24/50] - Loss: 0.8460
Epoch [25/50] - Loss: 0.8421
Epoch [26/50] - Loss: 0.8397
Epoch [27/50] - Loss: 0.8373
Epoch [28/50] - Loss: 0.8328
Epoch [29/50] - Loss: 0.8331
Epoch [30/50] - Loss: 0.8288
Epoch [31/50] - Loss: 0.8253
Epoch [32/50] - Loss: 0.8237
Epoch [33/50] - Loss: 0.8220
Epoch [34/50] - Loss: 0.8197
Epoch [35/50] - Loss: 0.8163
Epoch [36/50] - Loss: 0.8144
Epoch [37/50] - Loss: 0.8122
Epoch [38/50] - Loss: 0.8106
Epoch [39/50] - Loss: 0.8078
Epoch [40/50] - Loss: 0.8048
Epoch [41/50] - Loss: 0.8025
Epoch [42/50] - Loss: 0.8015
Epoch [43/50] - Loss: 0.7989
Epoch [44/50] - Loss: 0.7973
Epoch [45/50] - Loss: 0.7945
Epoch [46/50] - Loss: 0.7933
Epoch [47/50] - Loss: 0.7900
Epoch [48/50] - Loss: 0.7894
Epoch [49/50] - Loss: 0.7869
Epoch [50/50] - Loss: 0.7850
sum preds 10
sum labels 2143
 - Test Metrics: Accuracy=0.8088, F1=0.0084, Recall=0.0042, Precision=0.9000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.3077
Epoch [2/50] - Loss: 3.3546
Epoch [3/50] - Loss: 2.2310
Epoch [4/50] - Loss: 1.5802
Epoch [5/50] - Loss: 1.2251
Epoch [6/50] - Loss: 1.0733
Epoch [7/50] - Loss: 1.0075
Epoch [8/50] - Loss: 0.9691
Epoch [9/50] - Loss: 0.9428
Epoch [10/50] - Loss: 0.9236
Epoch [11/50] - Loss: 0.9062
Epoch [12/50] - Loss: 0.8950
Epoch [13/50] - Loss: 0.8851
Epoch [14/50] - Loss: 0.8762
Epoch [15/50] - Loss: 0.8698
Epoch [16/50] - Loss: 0.8637
Epoch [17/50] - Loss: 0.8569
Epoch [18/50] - Loss: 0.8533
Epoch [19/50] - Loss: 0.8485
Epoch [20/50] - Loss: 0.8442
Epoch [21/50] - Loss: 0.8394
Epoch [22/50] - Loss: 0.8382
Epoch [23/50] - Loss: 0.8337
Epoch [24/50] - Loss: 0.8318
Epoch [25/50] - Loss: 0.8288
Epoch [26/50] - Loss: 0.8260
Epoch [27/50] - Loss: 0.8240
Epoch [28/50] - Loss: 0.8220
Epoch [29/50] - Loss: 0.8193
Epoch [30/50] - Loss: 0.8162
Epoch [31/50] - Loss: 0.8141
Epoch [32/50] - Loss: 0.8116
Epoch [33/50] - Loss: 0.8102
Epoch [34/50] - Loss: 0.8081
Epoch [35/50] - Loss: 0.8063
Epoch [36/50] - Loss: 0.8036
Epoch [37/50] - Loss: 0.8021
Epoch [38/50] - Loss: 0.7996
Epoch [39/50] - Loss: 0.7979
Epoch [40/50] - Loss: 0.7947
Epoch [41/50] - Loss: 0.7940
Epoch [42/50] - Loss: 0.7914
Epoch [43/50] - Loss: 0.7887
Epoch [44/50] - Loss: 0.7875
Epoch [45/50] - Loss: 0.7852
Epoch [46/50] - Loss: 0.7854
Epoch [47/50] - Loss: 0.7812
Epoch [48/50] - Loss: 0.7799
Epoch [49/50] - Loss: 0.7775
Epoch [50/50] - Loss: 0.7764
sum preds 12
sum labels 2143
 - Test Metrics: Accuracy=0.8090, F1=0.0102, Recall=0.0051, Precision=0.9167
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_naive_naive_1904052856.csv.
Average F1 over valid seeds: 0.0090 ± 0.0009
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and naive, GCNConv,0.2: 0.0090 ± 0.0009
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8975, F1=0.4982, Recall=0.3367, Precision=0.9575
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8929, F1=0.4702, Recall=0.3143, Precision=0.9335
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8969, F1=0.4945, Recall=0.3335, Precision=0.9554
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_NNIF_NNIF_1904053817.csv.
Average F1 over valid seeds: 0.4876 ± 0.0124
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and NNIF, MLP,0.4: 0.4876 ± 0.0124
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8768, F1=0.4518, Recall=0.2949, Precision=0.9651
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8762, F1=0.4523, Recall=0.2971, Precision=0.9473
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8785, F1=0.4674, Recall=0.3099, Precision=0.9509
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_NNIF_NNIF_1904053906.csv.
Average F1 over valid seeds: 0.4572 ± 0.0072
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and NNIF, MLP,0.3: 0.4572 ± 0.0072
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8373, F1=0.2706, Recall=0.1573, Precision=0.9684
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8371, F1=0.2680, Recall=0.1554, Precision=0.9737
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8406, F1=0.3003, Recall=0.1783, Precision=0.9526
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_NNIF_NNIF_1904053933.csv.
Average F1 over valid seeds: 0.2796 ± 0.0147
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and NNIF, MLP,0.2: 0.2796 ± 0.0147
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.0168
Epoch [2/50] - Loss: 1.4471
Epoch [3/50] - Loss: 1.2452
Epoch [4/50] - Loss: 1.1533
Epoch [5/50] - Loss: 1.0786
Epoch [6/50] - Loss: 1.0168
Epoch [7/50] - Loss: 0.9766
Epoch [8/50] - Loss: 0.9473
Epoch [9/50] - Loss: 0.9191
Epoch [10/50] - Loss: 0.8942
Epoch [11/50] - Loss: 0.8706
Epoch [12/50] - Loss: 0.8491
Epoch [13/50] - Loss: 0.8264
Epoch [14/50] - Loss: 0.8069
Epoch [15/50] - Loss: 0.7852
Epoch [16/50] - Loss: 0.7650
Epoch [17/50] - Loss: 0.7431
Epoch [18/50] - Loss: 0.7238
Epoch [19/50] - Loss: 0.7035
Epoch [20/50] - Loss: 0.6837
Epoch [21/50] - Loss: 0.6647
Epoch [22/50] - Loss: 0.6458
Epoch [23/50] - Loss: 0.6258
Epoch [24/50] - Loss: 0.6081
Epoch [25/50] - Loss: 0.5906
Epoch [26/50] - Loss: 0.5728
Epoch [27/50] - Loss: 0.5558
Epoch [28/50] - Loss: 0.5390
Epoch [29/50] - Loss: 0.5213
Epoch [30/50] - Loss: 0.5041
Epoch [31/50] - Loss: 0.4865
Epoch [32/50] - Loss: 0.4701
Epoch [33/50] - Loss: 0.4539
Epoch [34/50] - Loss: 0.4373
Epoch [35/50] - Loss: 0.4198
Epoch [36/50] - Loss: 0.4039
Epoch [37/50] - Loss: 0.3881
Epoch [38/50] - Loss: 0.3728
Epoch [39/50] - Loss: 0.3574
Epoch [40/50] - Loss: 0.3436
Epoch [41/50] - Loss: 0.3302
Epoch [42/50] - Loss: 0.3177
Epoch [43/50] - Loss: 0.3041
Epoch [44/50] - Loss: 0.2921
Epoch [45/50] - Loss: 0.2805
Epoch [46/50] - Loss: 0.2681
Epoch [47/50] - Loss: 0.2572
Epoch [48/50] - Loss: 0.2459
Epoch [49/50] - Loss: 0.2375
Epoch [50/50] - Loss: 0.2277
sum preds 510
sum labels 1607
 - Test Metrics: Accuracy=0.8915, F1=0.4554, Recall=0.2999, Precision=0.9451
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.8800
Epoch [2/50] - Loss: 1.3532
Epoch [3/50] - Loss: 1.1693
Epoch [4/50] - Loss: 1.1062
Epoch [5/50] - Loss: 1.0543
Epoch [6/50] - Loss: 1.0084
Epoch [7/50] - Loss: 0.9748
Epoch [8/50] - Loss: 0.9436
Epoch [9/50] - Loss: 0.9171
Epoch [10/50] - Loss: 0.8925
Epoch [11/50] - Loss: 0.8688
Epoch [12/50] - Loss: 0.8481
Epoch [13/50] - Loss: 0.8243
Epoch [14/50] - Loss: 0.8003
Epoch [15/50] - Loss: 0.7777
Epoch [16/50] - Loss: 0.7538
Epoch [17/50] - Loss: 0.7290
Epoch [18/50] - Loss: 0.7039
Epoch [19/50] - Loss: 0.6819
Epoch [20/50] - Loss: 0.6581
Epoch [21/50] - Loss: 0.6350
Epoch [22/50] - Loss: 0.6116
Epoch [23/50] - Loss: 0.5900
Epoch [24/50] - Loss: 0.5678
Epoch [25/50] - Loss: 0.5451
Epoch [26/50] - Loss: 0.5247
Epoch [27/50] - Loss: 0.5030
Epoch [28/50] - Loss: 0.4838
Epoch [29/50] - Loss: 0.4638
Epoch [30/50] - Loss: 0.4442
Epoch [31/50] - Loss: 0.4247
Epoch [32/50] - Loss: 0.4062
Epoch [33/50] - Loss: 0.3889
Epoch [34/50] - Loss: 0.3712
Epoch [35/50] - Loss: 0.3546
Epoch [36/50] - Loss: 0.3379
Epoch [37/50] - Loss: 0.3227
Epoch [38/50] - Loss: 0.3092
Epoch [39/50] - Loss: 0.2949
Epoch [40/50] - Loss: 0.2812
Epoch [41/50] - Loss: 0.2682
Epoch [42/50] - Loss: 0.2561
Epoch [43/50] - Loss: 0.2446
Epoch [44/50] - Loss: 0.2337
Epoch [45/50] - Loss: 0.2236
Epoch [46/50] - Loss: 0.2132
Epoch [47/50] - Loss: 0.2037
Epoch [48/50] - Loss: 0.1945
Epoch [49/50] - Loss: 0.1860
Epoch [50/50] - Loss: 0.1773
sum preds 507
sum labels 1607
 - Test Metrics: Accuracy=0.8867, F1=0.4305, Recall=0.2831, Precision=0.8974
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1263
Epoch [2/50] - Loss: 1.2157
Epoch [3/50] - Loss: 1.1038
Epoch [4/50] - Loss: 1.0578
Epoch [5/50] - Loss: 1.0025
Epoch [6/50] - Loss: 0.9670
Epoch [7/50] - Loss: 0.9382
Epoch [8/50] - Loss: 0.9099
Epoch [9/50] - Loss: 0.8820
Epoch [10/50] - Loss: 0.8581
Epoch [11/50] - Loss: 0.8341
Epoch [12/50] - Loss: 0.8082
Epoch [13/50] - Loss: 0.7828
Epoch [14/50] - Loss: 0.7570
Epoch [15/50] - Loss: 0.7329
Epoch [16/50] - Loss: 0.7069
Epoch [17/50] - Loss: 0.6827
Epoch [18/50] - Loss: 0.6566
Epoch [19/50] - Loss: 0.6326
Epoch [20/50] - Loss: 0.6083
Epoch [21/50] - Loss: 0.5843
Epoch [22/50] - Loss: 0.5600
Epoch [23/50] - Loss: 0.5363
Epoch [24/50] - Loss: 0.5137
Epoch [25/50] - Loss: 0.4911
Epoch [26/50] - Loss: 0.4678
Epoch [27/50] - Loss: 0.4473
Epoch [28/50] - Loss: 0.4259
Epoch [29/50] - Loss: 0.4056
Epoch [30/50] - Loss: 0.3852
Epoch [31/50] - Loss: 0.3671
Epoch [32/50] - Loss: 0.3481
Epoch [33/50] - Loss: 0.3314
Epoch [34/50] - Loss: 0.3144
Epoch [35/50] - Loss: 0.2979
Epoch [36/50] - Loss: 0.2825
Epoch [37/50] - Loss: 0.2684
Epoch [38/50] - Loss: 0.2541
Epoch [39/50] - Loss: 0.2414
Epoch [40/50] - Loss: 0.2281
Epoch [41/50] - Loss: 0.2169
Epoch [42/50] - Loss: 0.2054
Epoch [43/50] - Loss: 0.1948
Epoch [44/50] - Loss: 0.1851
Epoch [45/50] - Loss: 0.1756
Epoch [46/50] - Loss: 0.1668
Epoch [47/50] - Loss: 0.1586
Epoch [48/50] - Loss: 0.1503
Epoch [49/50] - Loss: 0.1426
Epoch [50/50] - Loss: 0.1351
sum preds 507
sum labels 1607
 - Test Metrics: Accuracy=0.8912, F1=0.4532, Recall=0.2981, Precision=0.9448
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_two_nnif_two_nnif_1904054001.csv.
Average F1 over valid seeds: 0.4463 ± 0.0113
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and two_nnif, MLP,0.4: 0.4463 ± 0.0113
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.3191
Epoch [2/50] - Loss: 1.4129
Epoch [3/50] - Loss: 1.2672
Epoch [4/50] - Loss: 1.1407
Epoch [5/50] - Loss: 1.1009
Epoch [6/50] - Loss: 1.0637
Epoch [7/50] - Loss: 1.0445
Epoch [8/50] - Loss: 1.0272
Epoch [9/50] - Loss: 1.0132
Epoch [10/50] - Loss: 1.0010
Epoch [11/50] - Loss: 0.9908
Epoch [12/50] - Loss: 0.9761
Epoch [13/50] - Loss: 0.9727
Epoch [14/50] - Loss: 0.9636
Epoch [15/50] - Loss: 0.9591
Epoch [16/50] - Loss: 0.9500
Epoch [17/50] - Loss: 0.9439
Epoch [18/50] - Loss: 0.9400
Epoch [19/50] - Loss: 0.9350
Epoch [20/50] - Loss: 0.9262
Epoch [21/50] - Loss: 0.9218
Epoch [22/50] - Loss: 0.9164
Epoch [23/50] - Loss: 0.9144
Epoch [24/50] - Loss: 0.9097
Epoch [25/50] - Loss: 0.9047
Epoch [26/50] - Loss: 0.8980
Epoch [27/50] - Loss: 0.8974
Epoch [28/50] - Loss: 0.8910
Epoch [29/50] - Loss: 0.8851
Epoch [30/50] - Loss: 0.8790
Epoch [31/50] - Loss: 0.8753
Epoch [32/50] - Loss: 0.8721
Epoch [33/50] - Loss: 0.8660
Epoch [34/50] - Loss: 0.8630
Epoch [35/50] - Loss: 0.8610
Epoch [36/50] - Loss: 0.8521
Epoch [37/50] - Loss: 0.8482
Epoch [38/50] - Loss: 0.8437
Epoch [39/50] - Loss: 0.8417
Epoch [40/50] - Loss: 0.8352
Epoch [41/50] - Loss: 0.8390
Epoch [42/50] - Loss: 0.8342
Epoch [43/50] - Loss: 0.8313
Epoch [44/50] - Loss: 0.8230
Epoch [45/50] - Loss: 0.8197
Epoch [46/50] - Loss: 0.8174
Epoch [47/50] - Loss: 0.8116
Epoch [48/50] - Loss: 0.8058
Epoch [49/50] - Loss: 0.8030
Epoch [50/50] - Loss: 0.8018
sum preds 901
sum labels 1607
 - Test Metrics: Accuracy=0.9242, F1=0.6786, Recall=0.5296, Precision=0.9445
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.0688
Epoch [2/50] - Loss: 1.3295
Epoch [3/50] - Loss: 1.1426
Epoch [4/50] - Loss: 1.0783
Epoch [5/50] - Loss: 1.0495
Epoch [6/50] - Loss: 1.0225
Epoch [7/50] - Loss: 1.0048
Epoch [8/50] - Loss: 0.9870
Epoch [9/50] - Loss: 0.9748
Epoch [10/50] - Loss: 0.9637
Epoch [11/50] - Loss: 0.9533
Epoch [12/50] - Loss: 0.9445
Epoch [13/50] - Loss: 0.9422
Epoch [14/50] - Loss: 0.9300
Epoch [15/50] - Loss: 0.9245
Epoch [16/50] - Loss: 0.9188
Epoch [17/50] - Loss: 0.9130
Epoch [18/50] - Loss: 0.9065
Epoch [19/50] - Loss: 0.9030
Epoch [20/50] - Loss: 0.8969
Epoch [21/50] - Loss: 0.8920
Epoch [22/50] - Loss: 0.8847
Epoch [23/50] - Loss: 0.8803
Epoch [24/50] - Loss: 0.8748
Epoch [25/50] - Loss: 0.8682
Epoch [26/50] - Loss: 0.8624
Epoch [27/50] - Loss: 0.8577
Epoch [28/50] - Loss: 0.8496
Epoch [29/50] - Loss: 0.8527
Epoch [30/50] - Loss: 0.8473
Epoch [31/50] - Loss: 0.8449
Epoch [32/50] - Loss: 0.8377
Epoch [33/50] - Loss: 0.8325
Epoch [34/50] - Loss: 0.8268
Epoch [35/50] - Loss: 0.8234
Epoch [36/50] - Loss: 0.8260
Epoch [37/50] - Loss: 0.8209
Epoch [38/50] - Loss: 0.8148
Epoch [39/50] - Loss: 0.8047
Epoch [40/50] - Loss: 0.7980
Epoch [41/50] - Loss: 0.7975
Epoch [42/50] - Loss: 0.7967
Epoch [43/50] - Loss: 0.7914
Epoch [44/50] - Loss: 0.7938
Epoch [45/50] - Loss: 0.7971
Epoch [46/50] - Loss: 0.7819
Epoch [47/50] - Loss: 0.7902
Epoch [48/50] - Loss: 0.7908
Epoch [49/50] - Loss: 0.7870
Epoch [50/50] - Loss: 0.7858
sum preds 1025
sum labels 1607
 - Test Metrics: Accuracy=0.9323, F1=0.7264, Recall=0.5949, Precision=0.9327
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.4661
Epoch [2/50] - Loss: 1.3762
Epoch [3/50] - Loss: 1.2118
Epoch [4/50] - Loss: 1.1464
Epoch [5/50] - Loss: 1.1059
Epoch [6/50] - Loss: 1.0777
Epoch [7/50] - Loss: 1.0584
Epoch [8/50] - Loss: 1.0368
Epoch [9/50] - Loss: 1.0166
Epoch [10/50] - Loss: 1.0042
Epoch [11/50] - Loss: 0.9885
Epoch [12/50] - Loss: 0.9722
Epoch [13/50] - Loss: 0.9627
Epoch [14/50] - Loss: 0.9507
Epoch [15/50] - Loss: 0.9426
Epoch [16/50] - Loss: 0.9333
Epoch [17/50] - Loss: 0.9252
Epoch [18/50] - Loss: 0.9200
Epoch [19/50] - Loss: 0.9116
Epoch [20/50] - Loss: 0.9125
Epoch [21/50] - Loss: 0.9018
Epoch [22/50] - Loss: 0.8966
Epoch [23/50] - Loss: 0.8929
Epoch [24/50] - Loss: 0.8859
Epoch [25/50] - Loss: 0.8807
Epoch [26/50] - Loss: 0.8776
Epoch [27/50] - Loss: 0.8733
Epoch [28/50] - Loss: 0.8693
Epoch [29/50] - Loss: 0.8634
Epoch [30/50] - Loss: 0.8561
Epoch [31/50] - Loss: 0.8548
Epoch [32/50] - Loss: 0.8492
Epoch [33/50] - Loss: 0.8469
Epoch [34/50] - Loss: 0.8477
Epoch [35/50] - Loss: 0.8414
Epoch [36/50] - Loss: 0.8376
Epoch [37/50] - Loss: 0.8362
Epoch [38/50] - Loss: 0.8319
Epoch [39/50] - Loss: 0.8259
Epoch [40/50] - Loss: 0.8260
Epoch [41/50] - Loss: 0.8236
Epoch [42/50] - Loss: 0.8199
Epoch [43/50] - Loss: 0.8126
Epoch [44/50] - Loss: 0.8095
Epoch [45/50] - Loss: 0.8045
Epoch [46/50] - Loss: 0.8022
Epoch [47/50] - Loss: 0.8011
Epoch [48/50] - Loss: 0.7981
Epoch [49/50] - Loss: 0.7930
Epoch [50/50] - Loss: 0.7931
sum preds 866
sum labels 1607
 - Test Metrics: Accuracy=0.9214, F1=0.6624, Recall=0.5096, Precision=0.9457
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_two_nnif_two_nnif_1904054850.csv.
Average F1 over valid seeds: 0.6891 ± 0.0272
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and two_nnif, GATConv,0.4: 0.6891 ± 0.0272
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.5904
Epoch [2/50] - Loss: 1.3621
Epoch [3/50] - Loss: 1.1850
Epoch [4/50] - Loss: 1.1445
Epoch [5/50] - Loss: 1.1107
Epoch [6/50] - Loss: 1.0828
Epoch [7/50] - Loss: 1.0637
Epoch [8/50] - Loss: 1.0502
Epoch [9/50] - Loss: 1.0391
Epoch [10/50] - Loss: 1.0282
Epoch [11/50] - Loss: 1.0205
Epoch [12/50] - Loss: 1.0139
Epoch [13/50] - Loss: 1.0049
Epoch [14/50] - Loss: 1.0020
Epoch [15/50] - Loss: 0.9937
Epoch [16/50] - Loss: 0.9914
Epoch [17/50] - Loss: 0.9846
Epoch [18/50] - Loss: 0.9802
Epoch [19/50] - Loss: 0.9747
Epoch [20/50] - Loss: 0.9702
Epoch [21/50] - Loss: 0.9671
Epoch [22/50] - Loss: 0.9644
Epoch [23/50] - Loss: 0.9590
Epoch [24/50] - Loss: 0.9549
Epoch [25/50] - Loss: 0.9532
Epoch [26/50] - Loss: 0.9480
Epoch [27/50] - Loss: 0.9486
Epoch [28/50] - Loss: 0.9401
Epoch [29/50] - Loss: 0.9386
Epoch [30/50] - Loss: 0.9361
Epoch [31/50] - Loss: 0.9335
Epoch [32/50] - Loss: 0.9309
Epoch [33/50] - Loss: 0.9285
Epoch [34/50] - Loss: 0.9259
Epoch [35/50] - Loss: 0.9219
Epoch [36/50] - Loss: 0.9171
Epoch [37/50] - Loss: 0.9156
Epoch [38/50] - Loss: 0.9155
Epoch [39/50] - Loss: 0.9096
Epoch [40/50] - Loss: 0.9052
Epoch [41/50] - Loss: 0.9034
Epoch [42/50] - Loss: 0.9031
Epoch [43/50] - Loss: 0.9001
Epoch [44/50] - Loss: 0.8981
Epoch [45/50] - Loss: 0.8955
Epoch [46/50] - Loss: 0.8962
Epoch [47/50] - Loss: 0.8939
Epoch [48/50] - Loss: 0.8902
Epoch [49/50] - Loss: 0.8885
Epoch [50/50] - Loss: 0.8856
sum preds 767
sum labels 1607
 - Test Metrics: Accuracy=0.9172, F1=0.6293, Recall=0.4648, Precision=0.9739
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.5072
Epoch [2/50] - Loss: 1.7093
Epoch [3/50] - Loss: 1.3078
Epoch [4/50] - Loss: 1.2071
Epoch [5/50] - Loss: 1.1698
Epoch [6/50] - Loss: 1.1405
Epoch [7/50] - Loss: 1.1185
Epoch [8/50] - Loss: 1.0980
Epoch [9/50] - Loss: 1.0876
Epoch [10/50] - Loss: 1.0761
Epoch [11/50] - Loss: 1.0673
Epoch [12/50] - Loss: 1.0587
Epoch [13/50] - Loss: 1.0493
Epoch [14/50] - Loss: 1.0442
Epoch [15/50] - Loss: 1.0372
Epoch [16/50] - Loss: 1.0322
Epoch [17/50] - Loss: 1.0293
Epoch [18/50] - Loss: 1.0236
Epoch [19/50] - Loss: 1.0170
Epoch [20/50] - Loss: 1.0150
Epoch [21/50] - Loss: 1.0103
Epoch [22/50] - Loss: 1.0063
Epoch [23/50] - Loss: 1.0020
Epoch [24/50] - Loss: 0.9994
Epoch [25/50] - Loss: 0.9953
Epoch [26/50] - Loss: 0.9914
Epoch [27/50] - Loss: 0.9889
Epoch [28/50] - Loss: 0.9852
Epoch [29/50] - Loss: 0.9821
Epoch [30/50] - Loss: 0.9788
Epoch [31/50] - Loss: 0.9765
Epoch [32/50] - Loss: 0.9720
Epoch [33/50] - Loss: 0.9706
Epoch [34/50] - Loss: 0.9700
Epoch [35/50] - Loss: 0.9654
Epoch [36/50] - Loss: 0.9634
Epoch [37/50] - Loss: 0.9593
Epoch [38/50] - Loss: 0.9565
Epoch [39/50] - Loss: 0.9539
Epoch [40/50] - Loss: 0.9543
Epoch [41/50] - Loss: 0.9509
Epoch [42/50] - Loss: 0.9488
Epoch [43/50] - Loss: 0.9438
Epoch [44/50] - Loss: 0.9431
Epoch [45/50] - Loss: 0.9384
Epoch [46/50] - Loss: 0.9378
Epoch [47/50] - Loss: 0.9344
Epoch [48/50] - Loss: 0.9325
Epoch [49/50] - Loss: 0.9278
Epoch [50/50] - Loss: 0.9271
sum preds 783
sum labels 1607
 - Test Metrics: Accuracy=0.9161, F1=0.6268, Recall=0.4661, Precision=0.9566
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.0642
Epoch [2/50] - Loss: 3.2308
Epoch [3/50] - Loss: 2.2483
Epoch [4/50] - Loss: 1.6961
Epoch [5/50] - Loss: 1.4089
Epoch [6/50] - Loss: 1.2442
Epoch [7/50] - Loss: 1.1520
Epoch [8/50] - Loss: 1.1073
Epoch [9/50] - Loss: 1.0828
Epoch [10/50] - Loss: 1.0679
Epoch [11/50] - Loss: 1.0531
Epoch [12/50] - Loss: 1.0435
Epoch [13/50] - Loss: 1.0348
Epoch [14/50] - Loss: 1.0246
Epoch [15/50] - Loss: 1.0235
Epoch [16/50] - Loss: 1.0137
Epoch [17/50] - Loss: 1.0081
Epoch [18/50] - Loss: 1.0041
Epoch [19/50] - Loss: 1.0008
Epoch [20/50] - Loss: 0.9972
Epoch [21/50] - Loss: 0.9938
Epoch [22/50] - Loss: 0.9889
Epoch [23/50] - Loss: 0.9877
Epoch [24/50] - Loss: 0.9811
Epoch [25/50] - Loss: 0.9798
Epoch [26/50] - Loss: 0.9770
Epoch [27/50] - Loss: 0.9737
Epoch [28/50] - Loss: 0.9711
Epoch [29/50] - Loss: 0.9683
Epoch [30/50] - Loss: 0.9668
Epoch [31/50] - Loss: 0.9643
Epoch [32/50] - Loss: 0.9618
Epoch [33/50] - Loss: 0.9583
Epoch [34/50] - Loss: 0.9571
Epoch [35/50] - Loss: 0.9546
Epoch [36/50] - Loss: 0.9518
Epoch [37/50] - Loss: 0.9482
Epoch [38/50] - Loss: 0.9470
Epoch [39/50] - Loss: 0.9444
Epoch [40/50] - Loss: 0.9421
Epoch [41/50] - Loss: 0.9403
Epoch [42/50] - Loss: 0.9369
Epoch [43/50] - Loss: 0.9336
Epoch [44/50] - Loss: 0.9341
Epoch [45/50] - Loss: 0.9324
Epoch [46/50] - Loss: 0.9287
Epoch [47/50] - Loss: 0.9264
Epoch [48/50] - Loss: 0.9248
Epoch [49/50] - Loss: 0.9203
Epoch [50/50] - Loss: 0.9204
sum preds 865
sum labels 1607
 - Test Metrics: Accuracy=0.9232, F1=0.6699, Recall=0.5152, Precision=0.9572
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_two_nnif_two_nnif_1904055802.csv.
Average F1 over valid seeds: 0.6420 ± 0.0198
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and two_nnif, GCNConv,0.4: 0.6420 ± 0.0198
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.0056
Epoch [2/50] - Loss: 1.3509
Epoch [3/50] - Loss: 1.1387
Epoch [4/50] - Loss: 1.0612
Epoch [5/50] - Loss: 0.9870
Epoch [6/50] - Loss: 0.9291
Epoch [7/50] - Loss: 0.8868
Epoch [8/50] - Loss: 0.8577
Epoch [9/50] - Loss: 0.8316
Epoch [10/50] - Loss: 0.8081
Epoch [11/50] - Loss: 0.7857
Epoch [12/50] - Loss: 0.7653
Epoch [13/50] - Loss: 0.7443
Epoch [14/50] - Loss: 0.7241
Epoch [15/50] - Loss: 0.7057
Epoch [16/50] - Loss: 0.6882
Epoch [17/50] - Loss: 0.6710
Epoch [18/50] - Loss: 0.6539
Epoch [19/50] - Loss: 0.6371
Epoch [20/50] - Loss: 0.6197
Epoch [21/50] - Loss: 0.6024
Epoch [22/50] - Loss: 0.5827
Epoch [23/50] - Loss: 0.5664
Epoch [24/50] - Loss: 0.5498
Epoch [25/50] - Loss: 0.5316
Epoch [26/50] - Loss: 0.5137
Epoch [27/50] - Loss: 0.4969
Epoch [28/50] - Loss: 0.4805
Epoch [29/50] - Loss: 0.4628
Epoch [30/50] - Loss: 0.4460
Epoch [31/50] - Loss: 0.4296
Epoch [32/50] - Loss: 0.4125
Epoch [33/50] - Loss: 0.3982
Epoch [34/50] - Loss: 0.3810
Epoch [35/50] - Loss: 0.3671
Epoch [36/50] - Loss: 0.3514
Epoch [37/50] - Loss: 0.3386
Epoch [38/50] - Loss: 0.3237
Epoch [39/50] - Loss: 0.3102
Epoch [40/50] - Loss: 0.2988
Epoch [41/50] - Loss: 0.2870
Epoch [42/50] - Loss: 0.2750
Epoch [43/50] - Loss: 0.2648
Epoch [44/50] - Loss: 0.2538
Epoch [45/50] - Loss: 0.2428
Epoch [46/50] - Loss: 0.2331
Epoch [47/50] - Loss: 0.2233
Epoch [48/50] - Loss: 0.2150
Epoch [49/50] - Loss: 0.2062
Epoch [50/50] - Loss: 0.1970
sum preds 511
sum labels 1875
 - Test Metrics: Accuracy=0.8682, F1=0.3982, Recall=0.2533, Precision=0.9295
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.8653
Epoch [2/50] - Loss: 1.2610
Epoch [3/50] - Loss: 1.0534
Epoch [4/50] - Loss: 0.9978
Epoch [5/50] - Loss: 0.9467
Epoch [6/50] - Loss: 0.9052
Epoch [7/50] - Loss: 0.8725
Epoch [8/50] - Loss: 0.8449
Epoch [9/50] - Loss: 0.8206
Epoch [10/50] - Loss: 0.7972
Epoch [11/50] - Loss: 0.7740
Epoch [12/50] - Loss: 0.7499
Epoch [13/50] - Loss: 0.7284
Epoch [14/50] - Loss: 0.7078
Epoch [15/50] - Loss: 0.6872
Epoch [16/50] - Loss: 0.6660
Epoch [17/50] - Loss: 0.6452
Epoch [18/50] - Loss: 0.6244
Epoch [19/50] - Loss: 0.6040
Epoch [20/50] - Loss: 0.5851
Epoch [21/50] - Loss: 0.5661
Epoch [22/50] - Loss: 0.5466
Epoch [23/50] - Loss: 0.5289
Epoch [24/50] - Loss: 0.5106
Epoch [25/50] - Loss: 0.4920
Epoch [26/50] - Loss: 0.4759
Epoch [27/50] - Loss: 0.4580
Epoch [28/50] - Loss: 0.4404
Epoch [29/50] - Loss: 0.4231
Epoch [30/50] - Loss: 0.4066
Epoch [31/50] - Loss: 0.3908
Epoch [32/50] - Loss: 0.3747
Epoch [33/50] - Loss: 0.3589
Epoch [34/50] - Loss: 0.3436
Epoch [35/50] - Loss: 0.3287
Epoch [36/50] - Loss: 0.3143
Epoch [37/50] - Loss: 0.3002
Epoch [38/50] - Loss: 0.2862
Epoch [39/50] - Loss: 0.2727
Epoch [40/50] - Loss: 0.2605
Epoch [41/50] - Loss: 0.2482
Epoch [42/50] - Loss: 0.2367
Epoch [43/50] - Loss: 0.2254
Epoch [44/50] - Loss: 0.2151
Epoch [45/50] - Loss: 0.2045
Epoch [46/50] - Loss: 0.1949
Epoch [47/50] - Loss: 0.1853
Epoch [48/50] - Loss: 0.1766
Epoch [49/50] - Loss: 0.1687
Epoch [50/50] - Loss: 0.1603
sum preds 537
sum labels 1875
 - Test Metrics: Accuracy=0.8684, F1=0.4055, Recall=0.2608, Precision=0.9106
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.0414
Epoch [2/50] - Loss: 1.1131
Epoch [3/50] - Loss: 0.9964
Epoch [4/50] - Loss: 0.9585
Epoch [5/50] - Loss: 0.9078
Epoch [6/50] - Loss: 0.8695
Epoch [7/50] - Loss: 0.8411
Epoch [8/50] - Loss: 0.8148
Epoch [9/50] - Loss: 0.7879
Epoch [10/50] - Loss: 0.7641
Epoch [11/50] - Loss: 0.7412
Epoch [12/50] - Loss: 0.7174
Epoch [13/50] - Loss: 0.6928
Epoch [14/50] - Loss: 0.6721
Epoch [15/50] - Loss: 0.6481
Epoch [16/50] - Loss: 0.6249
Epoch [17/50] - Loss: 0.5999
Epoch [18/50] - Loss: 0.5749
Epoch [19/50] - Loss: 0.5508
Epoch [20/50] - Loss: 0.5269
Epoch [21/50] - Loss: 0.5017
Epoch [22/50] - Loss: 0.4762
Epoch [23/50] - Loss: 0.4539
Epoch [24/50] - Loss: 0.4313
Epoch [25/50] - Loss: 0.4085
Epoch [26/50] - Loss: 0.3887
Epoch [27/50] - Loss: 0.3694
Epoch [28/50] - Loss: 0.3505
Epoch [29/50] - Loss: 0.3313
Epoch [30/50] - Loss: 0.3141
Epoch [31/50] - Loss: 0.2984
Epoch [32/50] - Loss: 0.2825
Epoch [33/50] - Loss: 0.2673
Epoch [34/50] - Loss: 0.2525
Epoch [35/50] - Loss: 0.2388
Epoch [36/50] - Loss: 0.2265
Epoch [37/50] - Loss: 0.2146
Epoch [38/50] - Loss: 0.2026
Epoch [39/50] - Loss: 0.1922
Epoch [40/50] - Loss: 0.1810
Epoch [41/50] - Loss: 0.1713
Epoch [42/50] - Loss: 0.1624
Epoch [43/50] - Loss: 0.1531
Epoch [44/50] - Loss: 0.1448
Epoch [45/50] - Loss: 0.1378
Epoch [46/50] - Loss: 0.1300
Epoch [47/50] - Loss: 0.1236
Epoch [48/50] - Loss: 0.1172
Epoch [49/50] - Loss: 0.1106
Epoch [50/50] - Loss: 0.1054
sum preds 520
sum labels 1875
 - Test Metrics: Accuracy=0.8689, F1=0.4033, Recall=0.2576, Precision=0.9288
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_two_nnif_two_nnif_1904060712.csv.
Average F1 over valid seeds: 0.4023 ± 0.0031
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and two_nnif, MLP,0.3: 0.4023 ± 0.0031
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1717
Epoch [2/50] - Loss: 1.2535
Epoch [3/50] - Loss: 1.1288
Epoch [4/50] - Loss: 1.0826
Epoch [5/50] - Loss: 1.0002
Epoch [6/50] - Loss: 0.9571
Epoch [7/50] - Loss: 0.9316
Epoch [8/50] - Loss: 0.9154
Epoch [9/50] - Loss: 0.9003
Epoch [10/50] - Loss: 0.8919
Epoch [11/50] - Loss: 0.8797
Epoch [12/50] - Loss: 0.8753
Epoch [13/50] - Loss: 0.8682
Epoch [14/50] - Loss: 0.8608
Epoch [15/50] - Loss: 0.8536
Epoch [16/50] - Loss: 0.8518
Epoch [17/50] - Loss: 0.8447
Epoch [18/50] - Loss: 0.8354
Epoch [19/50] - Loss: 0.8279
Epoch [20/50] - Loss: 0.8244
Epoch [21/50] - Loss: 0.8215
Epoch [22/50] - Loss: 0.8169
Epoch [23/50] - Loss: 0.8112
Epoch [24/50] - Loss: 0.8092
Epoch [25/50] - Loss: 0.8055
Epoch [26/50] - Loss: 0.7978
Epoch [27/50] - Loss: 0.7931
Epoch [28/50] - Loss: 0.7879
Epoch [29/50] - Loss: 0.7856
Epoch [30/50] - Loss: 0.7834
Epoch [31/50] - Loss: 0.7838
Epoch [32/50] - Loss: 0.7765
Epoch [33/50] - Loss: 0.7745
Epoch [34/50] - Loss: 0.7682
Epoch [35/50] - Loss: 0.7686
Epoch [36/50] - Loss: 0.7614
Epoch [37/50] - Loss: 0.7590
Epoch [38/50] - Loss: 0.7564
Epoch [39/50] - Loss: 0.7566
Epoch [40/50] - Loss: 0.7479
Epoch [41/50] - Loss: 0.7411
Epoch [42/50] - Loss: 0.7399
Epoch [43/50] - Loss: 0.7365
Epoch [44/50] - Loss: 0.7370
Epoch [45/50] - Loss: 0.7366
Epoch [46/50] - Loss: 0.7338
Epoch [47/50] - Loss: 0.7273
Epoch [48/50] - Loss: 0.7180
Epoch [49/50] - Loss: 0.7262
Epoch [50/50] - Loss: 0.7201
sum preds 688
sum labels 1875
 - Test Metrics: Accuracy=0.8850, F1=0.5111, Recall=0.3493, Precision=0.9520
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9285
Epoch [2/50] - Loss: 1.1990
Epoch [3/50] - Loss: 1.0441
Epoch [4/50] - Loss: 0.9779
Epoch [5/50] - Loss: 0.9478
Epoch [6/50] - Loss: 0.9237
Epoch [7/50] - Loss: 0.9037
Epoch [8/50] - Loss: 0.8977
Epoch [9/50] - Loss: 0.8807
Epoch [10/50] - Loss: 0.8723
Epoch [11/50] - Loss: 0.8609
Epoch [12/50] - Loss: 0.8510
Epoch [13/50] - Loss: 0.8492
Epoch [14/50] - Loss: 0.8446
Epoch [15/50] - Loss: 0.8474
Epoch [16/50] - Loss: 0.8409
Epoch [17/50] - Loss: 0.8318
Epoch [18/50] - Loss: 0.8236
Epoch [19/50] - Loss: 0.8137
Epoch [20/50] - Loss: 0.8117
Epoch [21/50] - Loss: 0.8088
Epoch [22/50] - Loss: 0.8049
Epoch [23/50] - Loss: 0.7960
Epoch [24/50] - Loss: 0.7909
Epoch [25/50] - Loss: 0.7834
Epoch [26/50] - Loss: 0.7813
Epoch [27/50] - Loss: 0.7750
Epoch [28/50] - Loss: 0.7749
Epoch [29/50] - Loss: 0.7848
Epoch [30/50] - Loss: 0.7768
Epoch [31/50] - Loss: 0.7707
Epoch [32/50] - Loss: 0.7695
Epoch [33/50] - Loss: 0.7686
Epoch [34/50] - Loss: 0.7654
Epoch [35/50] - Loss: 0.7608
Epoch [36/50] - Loss: 0.7493
Epoch [37/50] - Loss: 0.7549
Epoch [38/50] - Loss: 0.7538
Epoch [39/50] - Loss: 0.7518
Epoch [40/50] - Loss: 0.7447
Epoch [41/50] - Loss: 0.7343
Epoch [42/50] - Loss: 0.7337
Epoch [43/50] - Loss: 0.7181
Epoch [44/50] - Loss: 0.7156
Epoch [45/50] - Loss: 0.7163
Epoch [46/50] - Loss: 0.7221
Epoch [47/50] - Loss: 0.7159
Epoch [48/50] - Loss: 0.7064
Epoch [49/50] - Loss: 0.7098
Epoch [50/50] - Loss: 0.7198
sum preds 854
sum labels 1875
 - Test Metrics: Accuracy=0.8977, F1=0.5914, Recall=0.4304, Precision=0.9450
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.3533
Epoch [2/50] - Loss: 1.2811
Epoch [3/50] - Loss: 1.1195
Epoch [4/50] - Loss: 1.0346
Epoch [5/50] - Loss: 0.9942
Epoch [6/50] - Loss: 0.9709
Epoch [7/50] - Loss: 0.9525
Epoch [8/50] - Loss: 0.9318
Epoch [9/50] - Loss: 0.9182
Epoch [10/50] - Loss: 0.9049
Epoch [11/50] - Loss: 0.8953
Epoch [12/50] - Loss: 0.8807
Epoch [13/50] - Loss: 0.8723
Epoch [14/50] - Loss: 0.8660
Epoch [15/50] - Loss: 0.8574
Epoch [16/50] - Loss: 0.8465
Epoch [17/50] - Loss: 0.8406
Epoch [18/50] - Loss: 0.8395
Epoch [19/50] - Loss: 0.8308
Epoch [20/50] - Loss: 0.8214
Epoch [21/50] - Loss: 0.8206
Epoch [22/50] - Loss: 0.8181
Epoch [23/50] - Loss: 0.8093
Epoch [24/50] - Loss: 0.8067
Epoch [25/50] - Loss: 0.7971
Epoch [26/50] - Loss: 0.7926
Epoch [27/50] - Loss: 0.7948
Epoch [28/50] - Loss: 0.7914
Epoch [29/50] - Loss: 0.7897
Epoch [30/50] - Loss: 0.7792
Epoch [31/50] - Loss: 0.7774
Epoch [32/50] - Loss: 0.7718
Epoch [33/50] - Loss: 0.7693
Epoch [34/50] - Loss: 0.7660
Epoch [35/50] - Loss: 0.7599
Epoch [36/50] - Loss: 0.7622
Epoch [37/50] - Loss: 0.7559
Epoch [38/50] - Loss: 0.7508
Epoch [39/50] - Loss: 0.7442
Epoch [40/50] - Loss: 0.7419
Epoch [41/50] - Loss: 0.7395
Epoch [42/50] - Loss: 0.7333
Epoch [43/50] - Loss: 0.7305
Epoch [44/50] - Loss: 0.7298
Epoch [45/50] - Loss: 0.7266
Epoch [46/50] - Loss: 0.7228
Epoch [47/50] - Loss: 0.7256
Epoch [48/50] - Loss: 0.7251
Epoch [49/50] - Loss: 0.7190
Epoch [50/50] - Loss: 0.7147
sum preds 643
sum labels 1875
 - Test Metrics: Accuracy=0.8803, F1=0.4821, Recall=0.3237, Precision=0.9440
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_two_nnif_two_nnif_1904061559.csv.
Average F1 over valid seeds: 0.5282 ± 0.0462
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and two_nnif, GATConv,0.3: 0.5282 ± 0.0462
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.5538
Epoch [2/50] - Loss: 1.2755
Epoch [3/50] - Loss: 1.0786
Epoch [4/50] - Loss: 1.0345
Epoch [5/50] - Loss: 1.0015
Epoch [6/50] - Loss: 0.9786
Epoch [7/50] - Loss: 0.9608
Epoch [8/50] - Loss: 0.9453
Epoch [9/50] - Loss: 0.9335
Epoch [10/50] - Loss: 0.9229
Epoch [11/50] - Loss: 0.9184
Epoch [12/50] - Loss: 0.9092
Epoch [13/50] - Loss: 0.9038
Epoch [14/50] - Loss: 0.8999
Epoch [15/50] - Loss: 0.8936
Epoch [16/50] - Loss: 0.8874
Epoch [17/50] - Loss: 0.8832
Epoch [18/50] - Loss: 0.8797
Epoch [19/50] - Loss: 0.8749
Epoch [20/50] - Loss: 0.8706
Epoch [21/50] - Loss: 0.8682
Epoch [22/50] - Loss: 0.8639
Epoch [23/50] - Loss: 0.8592
Epoch [24/50] - Loss: 0.8571
Epoch [25/50] - Loss: 0.8546
Epoch [26/50] - Loss: 0.8509
Epoch [27/50] - Loss: 0.8479
Epoch [28/50] - Loss: 0.8459
Epoch [29/50] - Loss: 0.8434
Epoch [30/50] - Loss: 0.8400
Epoch [31/50] - Loss: 0.8357
Epoch [32/50] - Loss: 0.8352
Epoch [33/50] - Loss: 0.8338
Epoch [34/50] - Loss: 0.8306
Epoch [35/50] - Loss: 0.8277
Epoch [36/50] - Loss: 0.8212
Epoch [37/50] - Loss: 0.8230
Epoch [38/50] - Loss: 0.8199
Epoch [39/50] - Loss: 0.8181
Epoch [40/50] - Loss: 0.8158
Epoch [41/50] - Loss: 0.8118
Epoch [42/50] - Loss: 0.8096
Epoch [43/50] - Loss: 0.8068
Epoch [44/50] - Loss: 0.8067
Epoch [45/50] - Loss: 0.8052
Epoch [46/50] - Loss: 0.8025
Epoch [47/50] - Loss: 0.8007
Epoch [48/50] - Loss: 0.7998
Epoch [49/50] - Loss: 0.7979
Epoch [50/50] - Loss: 0.7981
sum preds 821
sum labels 1875
 - Test Metrics: Accuracy=0.8989, F1=0.5912, Recall=0.4251, Precision=0.9708
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.5015
Epoch [2/50] - Loss: 1.6571
Epoch [3/50] - Loss: 1.2183
Epoch [4/50] - Loss: 1.1089
Epoch [5/50] - Loss: 1.0715
Epoch [6/50] - Loss: 1.0392
Epoch [7/50] - Loss: 1.0172
Epoch [8/50] - Loss: 0.9980
Epoch [9/50] - Loss: 0.9851
Epoch [10/50] - Loss: 0.9756
Epoch [11/50] - Loss: 0.9671
Epoch [12/50] - Loss: 0.9586
Epoch [13/50] - Loss: 0.9526
Epoch [14/50] - Loss: 0.9475
Epoch [15/50] - Loss: 0.9444
Epoch [16/50] - Loss: 0.9374
Epoch [17/50] - Loss: 0.9344
Epoch [18/50] - Loss: 0.9297
Epoch [19/50] - Loss: 0.9231
Epoch [20/50] - Loss: 0.9217
Epoch [21/50] - Loss: 0.9172
Epoch [22/50] - Loss: 0.9152
Epoch [23/50] - Loss: 0.9123
Epoch [24/50] - Loss: 0.9089
Epoch [25/50] - Loss: 0.9062
Epoch [26/50] - Loss: 0.9031
Epoch [27/50] - Loss: 0.8997
Epoch [28/50] - Loss: 0.8957
Epoch [29/50] - Loss: 0.8930
Epoch [30/50] - Loss: 0.8901
Epoch [31/50] - Loss: 0.8868
Epoch [32/50] - Loss: 0.8843
Epoch [33/50] - Loss: 0.8824
Epoch [34/50] - Loss: 0.8807
Epoch [35/50] - Loss: 0.8754
Epoch [36/50] - Loss: 0.8725
Epoch [37/50] - Loss: 0.8716
Epoch [38/50] - Loss: 0.8690
Epoch [39/50] - Loss: 0.8665
Epoch [40/50] - Loss: 0.8651
Epoch [41/50] - Loss: 0.8622
Epoch [42/50] - Loss: 0.8602
Epoch [43/50] - Loss: 0.8589
Epoch [44/50] - Loss: 0.8541
Epoch [45/50] - Loss: 0.8531
Epoch [46/50] - Loss: 0.8520
Epoch [47/50] - Loss: 0.8495
Epoch [48/50] - Loss: 0.8494
Epoch [49/50] - Loss: 0.8462
Epoch [50/50] - Loss: 0.8442
sum preds 684
sum labels 1875
 - Test Metrics: Accuracy=0.8867, F1=0.5174, Recall=0.3531, Precision=0.9678
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1157
Epoch [2/50] - Loss: 3.2641
Epoch [3/50] - Loss: 2.2360
Epoch [4/50] - Loss: 1.6390
Epoch [5/50] - Loss: 1.3355
Epoch [6/50] - Loss: 1.1600
Epoch [7/50] - Loss: 1.0614
Epoch [8/50] - Loss: 1.0104
Epoch [9/50] - Loss: 0.9831
Epoch [10/50] - Loss: 0.9688
Epoch [11/50] - Loss: 0.9489
Epoch [12/50] - Loss: 0.9393
Epoch [13/50] - Loss: 0.9304
Epoch [14/50] - Loss: 0.9237
Epoch [15/50] - Loss: 0.9190
Epoch [16/50] - Loss: 0.9128
Epoch [17/50] - Loss: 0.9102
Epoch [18/50] - Loss: 0.9032
Epoch [19/50] - Loss: 0.8994
Epoch [20/50] - Loss: 0.8974
Epoch [21/50] - Loss: 0.8934
Epoch [22/50] - Loss: 0.8890
Epoch [23/50] - Loss: 0.8847
Epoch [24/50] - Loss: 0.8829
Epoch [25/50] - Loss: 0.8778
Epoch [26/50] - Loss: 0.8771
Epoch [27/50] - Loss: 0.8742
Epoch [28/50] - Loss: 0.8724
Epoch [29/50] - Loss: 0.8703
Epoch [30/50] - Loss: 0.8675
Epoch [31/50] - Loss: 0.8668
Epoch [32/50] - Loss: 0.8632
Epoch [33/50] - Loss: 0.8610
Epoch [34/50] - Loss: 0.8596
Epoch [35/50] - Loss: 0.8571
Epoch [36/50] - Loss: 0.8565
Epoch [37/50] - Loss: 0.8530
Epoch [38/50] - Loss: 0.8510
Epoch [39/50] - Loss: 0.8504
Epoch [40/50] - Loss: 0.8482
Epoch [41/50] - Loss: 0.8470
Epoch [42/50] - Loss: 0.8451
Epoch [43/50] - Loss: 0.8424
Epoch [44/50] - Loss: 0.8416
Epoch [45/50] - Loss: 0.8401
Epoch [46/50] - Loss: 0.8397
Epoch [47/50] - Loss: 0.8372
Epoch [48/50] - Loss: 0.8364
Epoch [49/50] - Loss: 0.8336
Epoch [50/50] - Loss: 0.8313
sum preds 703
sum labels 1875
 - Test Metrics: Accuracy=0.8866, F1=0.5206, Recall=0.3579, Precision=0.9545
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_two_nnif_two_nnif_1904062512.csv.
Average F1 over valid seeds: 0.5431 ± 0.0341
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and two_nnif, GCNConv,0.3: 0.5431 ± 0.0341
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.0094
Epoch [2/50] - Loss: 1.2402
Epoch [3/50] - Loss: 1.0006
Epoch [4/50] - Loss: 0.9442
Epoch [5/50] - Loss: 0.8815
Epoch [6/50] - Loss: 0.8276
Epoch [7/50] - Loss: 0.7886
Epoch [8/50] - Loss: 0.7577
Epoch [9/50] - Loss: 0.7312
Epoch [10/50] - Loss: 0.7053
Epoch [11/50] - Loss: 0.6863
Epoch [12/50] - Loss: 0.6650
Epoch [13/50] - Loss: 0.6477
Epoch [14/50] - Loss: 0.6280
Epoch [15/50] - Loss: 0.6076
Epoch [16/50] - Loss: 0.5907
Epoch [17/50] - Loss: 0.5763
Epoch [18/50] - Loss: 0.5551
Epoch [19/50] - Loss: 0.5426
Epoch [20/50] - Loss: 0.5231
Epoch [21/50] - Loss: 0.5111
Epoch [22/50] - Loss: 0.4960
Epoch [23/50] - Loss: 0.4804
Epoch [24/50] - Loss: 0.4648
Epoch [25/50] - Loss: 0.4502
Epoch [26/50] - Loss: 0.4367
Epoch [27/50] - Loss: 0.4176
Epoch [28/50] - Loss: 0.4071
Epoch [29/50] - Loss: 0.3902
Epoch [30/50] - Loss: 0.3785
Epoch [31/50] - Loss: 0.3610
Epoch [32/50] - Loss: 0.3512
Epoch [33/50] - Loss: 0.3360
Epoch [34/50] - Loss: 0.3242
Epoch [35/50] - Loss: 0.3117
Epoch [36/50] - Loss: 0.3011
Epoch [37/50] - Loss: 0.2881
Epoch [38/50] - Loss: 0.2765
Epoch [39/50] - Loss: 0.2653
Epoch [40/50] - Loss: 0.2547
Epoch [41/50] - Loss: 0.2438
Epoch [42/50] - Loss: 0.2345
Epoch [43/50] - Loss: 0.2258
Epoch [44/50] - Loss: 0.2159
Epoch [45/50] - Loss: 0.2057
Epoch [46/50] - Loss: 0.1974
Epoch [47/50] - Loss: 0.1896
Epoch [48/50] - Loss: 0.1803
Epoch [49/50] - Loss: 0.1722
Epoch [50/50] - Loss: 0.1641
sum preds 285
sum labels 2143
 - Test Metrics: Accuracy=0.8304, F1=0.2199, Recall=0.1246, Precision=0.9368
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.8704
Epoch [2/50] - Loss: 1.1858
Epoch [3/50] - Loss: 0.9527
Epoch [4/50] - Loss: 0.9099
Epoch [5/50] - Loss: 0.8714
Epoch [6/50] - Loss: 0.8263
Epoch [7/50] - Loss: 0.7973
Epoch [8/50] - Loss: 0.7709
Epoch [9/50] - Loss: 0.7491
Epoch [10/50] - Loss: 0.7266
Epoch [11/50] - Loss: 0.7077
Epoch [12/50] - Loss: 0.6877
Epoch [13/50] - Loss: 0.6686
Epoch [14/50] - Loss: 0.6482
Epoch [15/50] - Loss: 0.6327
Epoch [16/50] - Loss: 0.6118
Epoch [17/50] - Loss: 0.5934
Epoch [18/50] - Loss: 0.5759
Epoch [19/50] - Loss: 0.5575
Epoch [20/50] - Loss: 0.5394
Epoch [21/50] - Loss: 0.5207
Epoch [22/50] - Loss: 0.5008
Epoch [23/50] - Loss: 0.4832
Epoch [24/50] - Loss: 0.4667
Epoch [25/50] - Loss: 0.4452
Epoch [26/50] - Loss: 0.4303
Epoch [27/50] - Loss: 0.4124
Epoch [28/50] - Loss: 0.3949
Epoch [29/50] - Loss: 0.3802
Epoch [30/50] - Loss: 0.3629
Epoch [31/50] - Loss: 0.3464
Epoch [32/50] - Loss: 0.3317
Epoch [33/50] - Loss: 0.3151
Epoch [34/50] - Loss: 0.3023
Epoch [35/50] - Loss: 0.2878
Epoch [36/50] - Loss: 0.2752
Epoch [37/50] - Loss: 0.2611
Epoch [38/50] - Loss: 0.2495
Epoch [39/50] - Loss: 0.2373
Epoch [40/50] - Loss: 0.2264
Epoch [41/50] - Loss: 0.2153
Epoch [42/50] - Loss: 0.2048
Epoch [43/50] - Loss: 0.1953
Epoch [44/50] - Loss: 0.1849
Epoch [45/50] - Loss: 0.1774
Epoch [46/50] - Loss: 0.1685
Epoch [47/50] - Loss: 0.1602
Epoch [48/50] - Loss: 0.1525
Epoch [49/50] - Loss: 0.1452
Epoch [50/50] - Loss: 0.1386
sum preds 303
sum labels 2143
 - Test Metrics: Accuracy=0.8300, F1=0.2240, Recall=0.1279, Precision=0.9043
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9532
Epoch [2/50] - Loss: 0.9939
Epoch [3/50] - Loss: 0.8997
Epoch [4/50] - Loss: 0.8502
Epoch [5/50] - Loss: 0.8047
Epoch [6/50] - Loss: 0.7737
Epoch [7/50] - Loss: 0.7457
Epoch [8/50] - Loss: 0.7186
Epoch [9/50] - Loss: 0.6905
Epoch [10/50] - Loss: 0.6670
Epoch [11/50] - Loss: 0.6434
Epoch [12/50] - Loss: 0.6212
Epoch [13/50] - Loss: 0.5969
Epoch [14/50] - Loss: 0.5774
Epoch [15/50] - Loss: 0.5571
Epoch [16/50] - Loss: 0.5364
Epoch [17/50] - Loss: 0.5134
Epoch [18/50] - Loss: 0.4925
Epoch [19/50] - Loss: 0.4708
Epoch [20/50] - Loss: 0.4517
Epoch [21/50] - Loss: 0.4292
Epoch [22/50] - Loss: 0.4069
Epoch [23/50] - Loss: 0.3849
Epoch [24/50] - Loss: 0.3624
Epoch [25/50] - Loss: 0.3409
Epoch [26/50] - Loss: 0.3193
Epoch [27/50] - Loss: 0.2989
Epoch [28/50] - Loss: 0.2812
Epoch [29/50] - Loss: 0.2605
Epoch [30/50] - Loss: 0.2435
Epoch [31/50] - Loss: 0.2280
Epoch [32/50] - Loss: 0.2138
Epoch [33/50] - Loss: 0.1993
Epoch [34/50] - Loss: 0.1854
Epoch [35/50] - Loss: 0.1742
Epoch [36/50] - Loss: 0.1629
Epoch [37/50] - Loss: 0.1527
Epoch [38/50] - Loss: 0.1422
Epoch [39/50] - Loss: 0.1325
Epoch [40/50] - Loss: 0.1258
Epoch [41/50] - Loss: 0.1174
Epoch [42/50] - Loss: 0.1106
Epoch [43/50] - Loss: 0.1039
Epoch [44/50] - Loss: 0.0969
Epoch [45/50] - Loss: 0.0914
Epoch [46/50] - Loss: 0.0867
Epoch [47/50] - Loss: 0.0813
Epoch [48/50] - Loss: 0.0768
Epoch [49/50] - Loss: 0.0722
Epoch [50/50] - Loss: 0.0682
sum preds 332
sum labels 2143
 - Test Metrics: Accuracy=0.8328, F1=0.2457, Recall=0.1419, Precision=0.9157
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_two_nnif_two_nnif_1904063425.csv.
Average F1 over valid seeds: 0.2299 ± 0.0113
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and two_nnif, MLP,0.2: 0.2299 ± 0.0113
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9432
Epoch [2/50] - Loss: 1.1258
Epoch [3/50] - Loss: 0.9611
Epoch [4/50] - Loss: 0.9244
Epoch [5/50] - Loss: 0.8642
Epoch [6/50] - Loss: 0.8406
Epoch [7/50] - Loss: 0.8246
Epoch [8/50] - Loss: 0.8019
Epoch [9/50] - Loss: 0.7937
Epoch [10/50] - Loss: 0.7864
Epoch [11/50] - Loss: 0.7800
Epoch [12/50] - Loss: 0.7673
Epoch [13/50] - Loss: 0.7650
Epoch [14/50] - Loss: 0.7595
Epoch [15/50] - Loss: 0.7600
Epoch [16/50] - Loss: 0.7536
Epoch [17/50] - Loss: 0.7387
Epoch [18/50] - Loss: 0.7432
Epoch [19/50] - Loss: 0.7383
Epoch [20/50] - Loss: 0.7296
Epoch [21/50] - Loss: 0.7242
Epoch [22/50] - Loss: 0.7262
Epoch [23/50] - Loss: 0.7299
Epoch [24/50] - Loss: 0.7138
Epoch [25/50] - Loss: 0.7128
Epoch [26/50] - Loss: 0.7193
Epoch [27/50] - Loss: 0.7155
Epoch [28/50] - Loss: 0.7033
Epoch [29/50] - Loss: 0.7032
Epoch [30/50] - Loss: 0.7012
Epoch [31/50] - Loss: 0.6957
Epoch [32/50] - Loss: 0.6892
Epoch [33/50] - Loss: 0.6834
Epoch [34/50] - Loss: 0.6892
Epoch [35/50] - Loss: 0.6856
Epoch [36/50] - Loss: 0.6798
Epoch [37/50] - Loss: 0.6722
Epoch [38/50] - Loss: 0.6786
Epoch [39/50] - Loss: 0.6737
Epoch [40/50] - Loss: 0.6684
Epoch [41/50] - Loss: 0.6708
Epoch [42/50] - Loss: 0.6603
Epoch [43/50] - Loss: 0.6628
Epoch [44/50] - Loss: 0.6661
Epoch [45/50] - Loss: 0.6644
Epoch [46/50] - Loss: 0.6519
Epoch [47/50] - Loss: 0.6524
Epoch [48/50] - Loss: 0.6632
Epoch [49/50] - Loss: 0.6484
Epoch [50/50] - Loss: 0.6519
sum preds 226
sum labels 2143
 - Test Metrics: Accuracy=0.8256, F1=0.1781, Recall=0.0985, Precision=0.9336
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8230
Epoch [2/50] - Loss: 1.0668
Epoch [3/50] - Loss: 0.9346
Epoch [4/50] - Loss: 0.8857
Epoch [5/50] - Loss: 0.8536
Epoch [6/50] - Loss: 0.8268
Epoch [7/50] - Loss: 0.8144
Epoch [8/50] - Loss: 0.8183
Epoch [9/50] - Loss: 0.7885
Epoch [10/50] - Loss: 0.7893
Epoch [11/50] - Loss: 0.7774
Epoch [12/50] - Loss: 0.7672
Epoch [13/50] - Loss: 0.7632
Epoch [14/50] - Loss: 0.7575
Epoch [15/50] - Loss: 0.7689
Epoch [16/50] - Loss: 0.7570
Epoch [17/50] - Loss: 0.7514
Epoch [18/50] - Loss: 0.7486
Epoch [19/50] - Loss: 0.7507
Epoch [20/50] - Loss: 0.7405
Epoch [21/50] - Loss: 0.7337
Epoch [22/50] - Loss: 0.7375
Epoch [23/50] - Loss: 0.7308
Epoch [24/50] - Loss: 0.7317
Epoch [25/50] - Loss: 0.7250
Epoch [26/50] - Loss: 0.7226
Epoch [27/50] - Loss: 0.7228
Epoch [28/50] - Loss: 0.7267
Epoch [29/50] - Loss: 0.7237
Epoch [30/50] - Loss: 0.7124
Epoch [31/50] - Loss: 0.7128
Epoch [32/50] - Loss: 0.7024
Epoch [33/50] - Loss: 0.7066
Epoch [34/50] - Loss: 0.7022
Epoch [35/50] - Loss: 0.7031
Epoch [36/50] - Loss: 0.6915
Epoch [37/50] - Loss: 0.6980
Epoch [38/50] - Loss: 0.6954
Epoch [39/50] - Loss: 0.6949
Epoch [40/50] - Loss: 0.6870
Epoch [41/50] - Loss: 0.6772
Epoch [42/50] - Loss: 0.6807
Epoch [43/50] - Loss: 0.6758
Epoch [44/50] - Loss: 0.6776
Epoch [45/50] - Loss: 0.6714
Epoch [46/50] - Loss: 0.6710
Epoch [47/50] - Loss: 0.6712
Epoch [48/50] - Loss: 0.6671
Epoch [49/50] - Loss: 0.6657
Epoch [50/50] - Loss: 0.6661
sum preds 182
sum labels 2143
 - Test Metrics: Accuracy=0.8220, F1=0.1454, Recall=0.0789, Precision=0.9286
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1479
Epoch [2/50] - Loss: 1.1165
Epoch [3/50] - Loss: 1.0054
Epoch [4/50] - Loss: 0.9253
Epoch [5/50] - Loss: 0.8948
Epoch [6/50] - Loss: 0.8682
Epoch [7/50] - Loss: 0.8406
Epoch [8/50] - Loss: 0.8298
Epoch [9/50] - Loss: 0.8210
Epoch [10/50] - Loss: 0.8072
Epoch [11/50] - Loss: 0.7983
Epoch [12/50] - Loss: 0.7890
Epoch [13/50] - Loss: 0.7781
Epoch [14/50] - Loss: 0.7792
Epoch [15/50] - Loss: 0.7731
Epoch [16/50] - Loss: 0.7629
Epoch [17/50] - Loss: 0.7523
Epoch [18/50] - Loss: 0.7527
Epoch [19/50] - Loss: 0.7471
Epoch [20/50] - Loss: 0.7478
Epoch [21/50] - Loss: 0.7388
Epoch [22/50] - Loss: 0.7376
Epoch [23/50] - Loss: 0.7292
Epoch [24/50] - Loss: 0.7273
Epoch [25/50] - Loss: 0.7229
Epoch [26/50] - Loss: 0.7184
Epoch [27/50] - Loss: 0.7130
Epoch [28/50] - Loss: 0.7061
Epoch [29/50] - Loss: 0.7127
Epoch [30/50] - Loss: 0.7005
Epoch [31/50] - Loss: 0.6961
Epoch [32/50] - Loss: 0.6902
Epoch [33/50] - Loss: 0.6943
Epoch [34/50] - Loss: 0.6893
Epoch [35/50] - Loss: 0.6799
Epoch [36/50] - Loss: 0.6884
Epoch [37/50] - Loss: 0.6752
Epoch [38/50] - Loss: 0.6727
Epoch [39/50] - Loss: 0.6810
Epoch [40/50] - Loss: 0.6699
Epoch [41/50] - Loss: 0.6614
Epoch [42/50] - Loss: 0.6572
Epoch [43/50] - Loss: 0.6597
Epoch [44/50] - Loss: 0.6573
Epoch [45/50] - Loss: 0.6476
Epoch [46/50] - Loss: 0.6472
Epoch [47/50] - Loss: 0.6430
Epoch [48/50] - Loss: 0.6399
Epoch [49/50] - Loss: 0.6342
Epoch [50/50] - Loss: 0.6317
sum preds 181
sum labels 2143
 - Test Metrics: Accuracy=0.8219, F1=0.1446, Recall=0.0784, Precision=0.9282
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_two_nnif_two_nnif_1904064309.csv.
Average F1 over valid seeds: 0.1560 ± 0.0156
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and two_nnif, GATConv,0.2: 0.1560 ± 0.0156
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.5512
Epoch [2/50] - Loss: 1.1916
Epoch [3/50] - Loss: 0.9647
Epoch [4/50] - Loss: 0.9187
Epoch [5/50] - Loss: 0.8949
Epoch [6/50] - Loss: 0.8633
Epoch [7/50] - Loss: 0.8482
Epoch [8/50] - Loss: 0.8370
Epoch [9/50] - Loss: 0.8267
Epoch [10/50] - Loss: 0.8147
Epoch [11/50] - Loss: 0.8119
Epoch [12/50] - Loss: 0.8050
Epoch [13/50] - Loss: 0.8005
Epoch [14/50] - Loss: 0.7956
Epoch [15/50] - Loss: 0.7817
Epoch [16/50] - Loss: 0.7806
Epoch [17/50] - Loss: 0.7805
Epoch [18/50] - Loss: 0.7703
Epoch [19/50] - Loss: 0.7627
Epoch [20/50] - Loss: 0.7646
Epoch [21/50] - Loss: 0.7608
Epoch [22/50] - Loss: 0.7590
Epoch [23/50] - Loss: 0.7550
Epoch [24/50] - Loss: 0.7518
Epoch [25/50] - Loss: 0.7457
Epoch [26/50] - Loss: 0.7475
Epoch [27/50] - Loss: 0.7454
Epoch [28/50] - Loss: 0.7417
Epoch [29/50] - Loss: 0.7352
Epoch [30/50] - Loss: 0.7397
Epoch [31/50] - Loss: 0.7332
Epoch [32/50] - Loss: 0.7271
Epoch [33/50] - Loss: 0.7277
Epoch [34/50] - Loss: 0.7281
Epoch [35/50] - Loss: 0.7246
Epoch [36/50] - Loss: 0.7204
Epoch [37/50] - Loss: 0.7208
Epoch [38/50] - Loss: 0.7166
Epoch [39/50] - Loss: 0.7119
Epoch [40/50] - Loss: 0.7123
Epoch [41/50] - Loss: 0.7195
Epoch [42/50] - Loss: 0.7099
Epoch [43/50] - Loss: 0.7134
Epoch [44/50] - Loss: 0.7117
Epoch [45/50] - Loss: 0.7057
Epoch [46/50] - Loss: 0.7043
Epoch [47/50] - Loss: 0.7053
Epoch [48/50] - Loss: 0.7001
Epoch [49/50] - Loss: 0.6959
Epoch [50/50] - Loss: 0.6937
sum preds 229
sum labels 2143
 - Test Metrics: Accuracy=0.8261, F1=0.1813, Recall=0.1003, Precision=0.9389
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.5023
Epoch [2/50] - Loss: 1.5982
Epoch [3/50] - Loss: 1.1240
Epoch [4/50] - Loss: 0.9914
Epoch [5/50] - Loss: 0.9626
Epoch [6/50] - Loss: 0.9389
Epoch [7/50] - Loss: 0.9147
Epoch [8/50] - Loss: 0.8992
Epoch [9/50] - Loss: 0.8812
Epoch [10/50] - Loss: 0.8732
Epoch [11/50] - Loss: 0.8677
Epoch [12/50] - Loss: 0.8600
Epoch [13/50] - Loss: 0.8496
Epoch [14/50] - Loss: 0.8473
Epoch [15/50] - Loss: 0.8423
Epoch [16/50] - Loss: 0.8327
Epoch [17/50] - Loss: 0.8321
Epoch [18/50] - Loss: 0.8230
Epoch [19/50] - Loss: 0.8246
Epoch [20/50] - Loss: 0.8177
Epoch [21/50] - Loss: 0.8151
Epoch [22/50] - Loss: 0.8167
Epoch [23/50] - Loss: 0.8038
Epoch [24/50] - Loss: 0.8064
Epoch [25/50] - Loss: 0.8038
Epoch [26/50] - Loss: 0.8043
Epoch [27/50] - Loss: 0.7951
Epoch [28/50] - Loss: 0.7953
Epoch [29/50] - Loss: 0.7936
Epoch [30/50] - Loss: 0.7929
Epoch [31/50] - Loss: 0.7892
Epoch [32/50] - Loss: 0.7854
Epoch [33/50] - Loss: 0.7826
Epoch [34/50] - Loss: 0.7798
Epoch [35/50] - Loss: 0.7818
Epoch [36/50] - Loss: 0.7759
Epoch [37/50] - Loss: 0.7715
Epoch [38/50] - Loss: 0.7724
Epoch [39/50] - Loss: 0.7739
Epoch [40/50] - Loss: 0.7671
Epoch [41/50] - Loss: 0.7646
Epoch [42/50] - Loss: 0.7645
Epoch [43/50] - Loss: 0.7629
Epoch [44/50] - Loss: 0.7572
Epoch [45/50] - Loss: 0.7584
Epoch [46/50] - Loss: 0.7539
Epoch [47/50] - Loss: 0.7557
Epoch [48/50] - Loss: 0.7519
Epoch [49/50] - Loss: 0.7469
Epoch [50/50] - Loss: 0.7464
sum preds 289
sum labels 2143
 - Test Metrics: Accuracy=0.8316, F1=0.2270, Recall=0.1288, Precision=0.9550
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 5.1808
Epoch [2/50] - Loss: 3.3187
Epoch [3/50] - Loss: 2.2652
Epoch [4/50] - Loss: 1.6063
Epoch [5/50] - Loss: 1.2469
Epoch [6/50] - Loss: 1.0555
Epoch [7/50] - Loss: 0.9623
Epoch [8/50] - Loss: 0.9006
Epoch [9/50] - Loss: 0.8813
Epoch [10/50] - Loss: 0.8585
Epoch [11/50] - Loss: 0.8455
Epoch [12/50] - Loss: 0.8367
Epoch [13/50] - Loss: 0.8271
Epoch [14/50] - Loss: 0.8188
Epoch [15/50] - Loss: 0.8105
Epoch [16/50] - Loss: 0.8062
Epoch [17/50] - Loss: 0.8128
Epoch [18/50] - Loss: 0.7995
Epoch [19/50] - Loss: 0.7995
Epoch [20/50] - Loss: 0.7971
Epoch [21/50] - Loss: 0.7917
Epoch [22/50] - Loss: 0.7872
Epoch [23/50] - Loss: 0.7853
Epoch [24/50] - Loss: 0.7817
Epoch [25/50] - Loss: 0.7800
Epoch [26/50] - Loss: 0.7787
Epoch [27/50] - Loss: 0.7745
Epoch [28/50] - Loss: 0.7711
Epoch [29/50] - Loss: 0.7689
Epoch [30/50] - Loss: 0.7657
Epoch [31/50] - Loss: 0.7618
Epoch [32/50] - Loss: 0.7604
Epoch [33/50] - Loss: 0.7617
Epoch [34/50] - Loss: 0.7568
Epoch [35/50] - Loss: 0.7555
Epoch [36/50] - Loss: 0.7549
Epoch [37/50] - Loss: 0.7534
Epoch [38/50] - Loss: 0.7545
Epoch [39/50] - Loss: 0.7511
Epoch [40/50] - Loss: 0.7475
Epoch [41/50] - Loss: 0.7455
Epoch [42/50] - Loss: 0.7446
Epoch [43/50] - Loss: 0.7412
Epoch [44/50] - Loss: 0.7395
Epoch [45/50] - Loss: 0.7376
Epoch [46/50] - Loss: 0.7363
Epoch [47/50] - Loss: 0.7318
Epoch [48/50] - Loss: 0.7305
Epoch [49/50] - Loss: 0.7289
Epoch [50/50] - Loss: 0.7303
sum preds 271
sum labels 2143
 - Test Metrics: Accuracy=0.8275, F1=0.2022, Recall=0.1139, Precision=0.9004
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_two_nnif_two_nnif_1904065219.csv.
Average F1 over valid seeds: 0.2035 ± 0.0187
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and two_nnif, GCNConv,0.2: 0.2035 ± 0.0187
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8966
Epoch [2/50] - Loss: 0.6675
Epoch [3/50] - Loss: 0.4174
Epoch [4/50] - Loss: 0.3347
Epoch [5/50] - Loss: 0.2918
Epoch [6/50] - Loss: 0.2639
Epoch [7/50] - Loss: 0.2438
Epoch [8/50] - Loss: 0.2253
Epoch [9/50] - Loss: 0.2099
Epoch [10/50] - Loss: 0.1958
Epoch [11/50] - Loss: 0.1832
Epoch [12/50] - Loss: 0.1720
Epoch [13/50] - Loss: 0.1624
Epoch [14/50] - Loss: 0.1525
Epoch [15/50] - Loss: 0.1450
Epoch [16/50] - Loss: 0.1368
Epoch [17/50] - Loss: 0.1294
Epoch [18/50] - Loss: 0.1228
Epoch [19/50] - Loss: 0.1158
Epoch [20/50] - Loss: 0.1095
Epoch [21/50] - Loss: 0.1042
Epoch [22/50] - Loss: 0.0990
Epoch [23/50] - Loss: 0.0937
Epoch [24/50] - Loss: 0.0883
Epoch [25/50] - Loss: 0.0833
Epoch [26/50] - Loss: 0.0786
Epoch [27/50] - Loss: 0.0742
Epoch [28/50] - Loss: 0.0699
Epoch [29/50] - Loss: 0.0661
Epoch [30/50] - Loss: 0.0622
Epoch [31/50] - Loss: 0.0583
Epoch [32/50] - Loss: 0.0548
Epoch [33/50] - Loss: 0.0518
Epoch [34/50] - Loss: 0.0488
Epoch [35/50] - Loss: 0.0457
Epoch [36/50] - Loss: 0.0430
Epoch [37/50] - Loss: 0.0405
Epoch [38/50] - Loss: 0.0380
Epoch [39/50] - Loss: 0.0358
Epoch [40/50] - Loss: 0.0336
Epoch [41/50] - Loss: 0.0316
Epoch [42/50] - Loss: 0.0297
Epoch [43/50] - Loss: 0.0280
Epoch [44/50] - Loss: 0.0263
Epoch [45/50] - Loss: 0.0249
Epoch [46/50] - Loss: 0.0235
Epoch [47/50] - Loss: 0.0223
Epoch [48/50] - Loss: 0.0211
Epoch [49/50] - Loss: 0.0201
Epoch [50/50] - Loss: 0.0191
sum preds 2858
sum labels 1607
 - Test Metrics: Accuracy=0.8531, F1=0.6504, Recall=0.9035, Precision=0.5080
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.3836
Epoch [2/50] - Loss: 1.9653
Epoch [3/50] - Loss: 1.0453
Epoch [4/50] - Loss: 0.6326
Epoch [5/50] - Loss: 0.5019
Epoch [6/50] - Loss: 0.4455
Epoch [7/50] - Loss: 0.4091
Epoch [8/50] - Loss: 0.3790
Epoch [9/50] - Loss: 0.3497
Epoch [10/50] - Loss: 0.3208
Epoch [11/50] - Loss: 0.2982
Epoch [12/50] - Loss: 0.2773
Epoch [13/50] - Loss: 0.2602
Epoch [14/50] - Loss: 0.2439
Epoch [15/50] - Loss: 0.2301
Epoch [16/50] - Loss: 0.2172
Epoch [17/50] - Loss: 0.2048
Epoch [18/50] - Loss: 0.1925
Epoch [19/50] - Loss: 0.1812
Epoch [20/50] - Loss: 0.1688
Epoch [21/50] - Loss: 0.1589
Epoch [22/50] - Loss: 0.1492
Epoch [23/50] - Loss: 0.1405
Epoch [24/50] - Loss: 0.1322
Epoch [25/50] - Loss: 0.1242
Epoch [26/50] - Loss: 0.1168
Epoch [27/50] - Loss: 0.1097
Epoch [28/50] - Loss: 0.1028
Epoch [29/50] - Loss: 0.0967
Epoch [30/50] - Loss: 0.0910
Epoch [31/50] - Loss: 0.0856
Epoch [32/50] - Loss: 0.0804
Epoch [33/50] - Loss: 0.0755
Epoch [34/50] - Loss: 0.0713
Epoch [35/50] - Loss: 0.0674
Epoch [36/50] - Loss: 0.0637
Epoch [37/50] - Loss: 0.0602
Epoch [38/50] - Loss: 0.0568
Epoch [39/50] - Loss: 0.0538
Epoch [40/50] - Loss: 0.0508
Epoch [41/50] - Loss: 0.0482
Epoch [42/50] - Loss: 0.0457
Epoch [43/50] - Loss: 0.0434
Epoch [44/50] - Loss: 0.0412
Epoch [45/50] - Loss: 0.0391
Epoch [46/50] - Loss: 0.0373
Epoch [47/50] - Loss: 0.0356
Epoch [48/50] - Loss: 0.0339
Epoch [49/50] - Loss: 0.0325
Epoch [50/50] - Loss: 0.0311
sum preds 2224
sum labels 1607
 - Test Metrics: Accuracy=0.8938, F1=0.7053, Recall=0.8407, Precision=0.6075
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.2388
Epoch [2/50] - Loss: 1.0887
Epoch [3/50] - Loss: 0.6622
Epoch [4/50] - Loss: 0.5046
Epoch [5/50] - Loss: 0.4434
Epoch [6/50] - Loss: 0.4155
Epoch [7/50] - Loss: 0.3846
Epoch [8/50] - Loss: 0.3568
Epoch [9/50] - Loss: 0.3332
Epoch [10/50] - Loss: 0.3146
Epoch [11/50] - Loss: 0.2987
Epoch [12/50] - Loss: 0.2836
Epoch [13/50] - Loss: 0.2707
Epoch [14/50] - Loss: 0.2589
Epoch [15/50] - Loss: 0.2469
Epoch [16/50] - Loss: 0.2357
Epoch [17/50] - Loss: 0.2245
Epoch [18/50] - Loss: 0.2140
Epoch [19/50] - Loss: 0.2041
Epoch [20/50] - Loss: 0.1945
Epoch [21/50] - Loss: 0.1852
Epoch [22/50] - Loss: 0.1763
Epoch [23/50] - Loss: 0.1682
Epoch [24/50] - Loss: 0.1594
Epoch [25/50] - Loss: 0.1525
Epoch [26/50] - Loss: 0.1449
Epoch [27/50] - Loss: 0.1381
Epoch [28/50] - Loss: 0.1317
Epoch [29/50] - Loss: 0.1258
Epoch [30/50] - Loss: 0.1201
Epoch [31/50] - Loss: 0.1150
Epoch [32/50] - Loss: 0.1095
Epoch [33/50] - Loss: 0.1048
Epoch [34/50] - Loss: 0.1000
Epoch [35/50] - Loss: 0.0958
Epoch [36/50] - Loss: 0.0910
Epoch [37/50] - Loss: 0.0871
Epoch [38/50] - Loss: 0.0833
Epoch [39/50] - Loss: 0.0798
Epoch [40/50] - Loss: 0.0763
Epoch [41/50] - Loss: 0.0732
Epoch [42/50] - Loss: 0.0702
Epoch [43/50] - Loss: 0.0675
Epoch [44/50] - Loss: 0.0648
Epoch [45/50] - Loss: 0.0624
Epoch [46/50] - Loss: 0.0604
Epoch [47/50] - Loss: 0.0583
Epoch [48/50] - Loss: 0.0564
Epoch [49/50] - Loss: 0.0545
Epoch [50/50] - Loss: 0.0527
sum preds 1931
sum labels 1607
 - Test Metrics: Accuracy=0.9116, F1=0.7343, Recall=0.8083, Precision=0.6727
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_spy_spy_1904070129.csv.
Average F1 over valid seeds: 0.6967 ± 0.0348
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and spy, MLP,0.4: 0.6967 ± 0.0348
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.6595
Epoch [2/50] - Loss: 0.6642
Epoch [3/50] - Loss: 0.5629
Epoch [4/50] - Loss: 0.4979
Epoch [5/50] - Loss: 0.4611
Epoch [6/50] - Loss: 0.4119
Epoch [7/50] - Loss: 0.3882
Epoch [8/50] - Loss: 0.3687
Epoch [9/50] - Loss: 0.3596
Epoch [10/50] - Loss: 0.3428
Epoch [11/50] - Loss: 0.3300
Epoch [12/50] - Loss: 0.3277
Epoch [13/50] - Loss: 0.3192
Epoch [14/50] - Loss: 0.3078
Epoch [15/50] - Loss: 0.3033
Epoch [16/50] - Loss: 0.3000
Epoch [17/50] - Loss: 0.2891
Epoch [18/50] - Loss: 0.2884
Epoch [19/50] - Loss: 0.2829
Epoch [20/50] - Loss: 0.2845
Epoch [21/50] - Loss: 0.2799
Epoch [22/50] - Loss: 0.2700
Epoch [23/50] - Loss: 0.2704
Epoch [24/50] - Loss: 0.2621
Epoch [25/50] - Loss: 0.2638
Epoch [26/50] - Loss: 0.2557
Epoch [27/50] - Loss: 0.2511
Epoch [28/50] - Loss: 0.2483
Epoch [29/50] - Loss: 0.2452
Epoch [30/50] - Loss: 0.2437
Epoch [31/50] - Loss: 0.2435
Epoch [32/50] - Loss: 0.2382
Epoch [33/50] - Loss: 0.2375
Epoch [34/50] - Loss: 0.2344
Epoch [35/50] - Loss: 0.2321
Epoch [36/50] - Loss: 0.2402
Epoch [37/50] - Loss: 0.2325
Epoch [38/50] - Loss: 0.2278
Epoch [39/50] - Loss: 0.2215
Epoch [40/50] - Loss: 0.2271
Epoch [41/50] - Loss: 0.2182
Epoch [42/50] - Loss: 0.2158
Epoch [43/50] - Loss: 0.2115
Epoch [44/50] - Loss: 0.2116
Epoch [45/50] - Loss: 0.2050
Epoch [46/50] - Loss: 0.2062
Epoch [47/50] - Loss: 0.2037
Epoch [48/50] - Loss: 0.2021
Epoch [49/50] - Loss: 0.2006
Epoch [50/50] - Loss: 0.2008
sum preds 2100
sum labels 1607
 - Test Metrics: Accuracy=0.9220, F1=0.7764, Recall=0.8955, Precision=0.6852
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.1103
Epoch [2/50] - Loss: 1.1417
Epoch [3/50] - Loss: 0.7777
Epoch [4/50] - Loss: 0.6932
Epoch [5/50] - Loss: 0.6231
Epoch [6/50] - Loss: 0.5777
Epoch [7/50] - Loss: 0.5468
Epoch [8/50] - Loss: 0.5250
Epoch [9/50] - Loss: 0.5130
Epoch [10/50] - Loss: 0.5020
Epoch [11/50] - Loss: 0.4876
Epoch [12/50] - Loss: 0.4762
Epoch [13/50] - Loss: 0.4769
Epoch [14/50] - Loss: 0.4612
Epoch [15/50] - Loss: 0.4537
Epoch [16/50] - Loss: 0.4461
Epoch [17/50] - Loss: 0.4409
Epoch [18/50] - Loss: 0.4357
Epoch [19/50] - Loss: 0.4270
Epoch [20/50] - Loss: 0.4228
Epoch [21/50] - Loss: 0.4118
Epoch [22/50] - Loss: 0.4128
Epoch [23/50] - Loss: 0.4097
Epoch [24/50] - Loss: 0.3954
Epoch [25/50] - Loss: 0.3893
Epoch [26/50] - Loss: 0.3906
Epoch [27/50] - Loss: 0.3908
Epoch [28/50] - Loss: 0.3785
Epoch [29/50] - Loss: 0.3722
Epoch [30/50] - Loss: 0.3708
Epoch [31/50] - Loss: 0.3631
Epoch [32/50] - Loss: 0.3636
Epoch [33/50] - Loss: 0.3636
Epoch [34/50] - Loss: 0.3482
Epoch [35/50] - Loss: 0.3581
Epoch [36/50] - Loss: 0.3513
Epoch [37/50] - Loss: 0.3554
Epoch [38/50] - Loss: 0.3454
Epoch [39/50] - Loss: 0.3453
Epoch [40/50] - Loss: 0.3355
Epoch [41/50] - Loss: 0.3317
Epoch [42/50] - Loss: 0.3337
Epoch [43/50] - Loss: 0.3238
Epoch [44/50] - Loss: 0.3305
Epoch [45/50] - Loss: 0.3140
Epoch [46/50] - Loss: 0.3140
Epoch [47/50] - Loss: 0.3234
Epoch [48/50] - Loss: 0.3181
Epoch [49/50] - Loss: 0.3163
Epoch [50/50] - Loss: 0.3143
sum preds 1760
sum labels 1607
 - Test Metrics: Accuracy=0.9325, F1=0.7871, Recall=0.8245, Precision=0.7528
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8745
Epoch [2/50] - Loss: 0.7303
Epoch [3/50] - Loss: 0.6883
Epoch [4/50] - Loss: 0.5956
Epoch [5/50] - Loss: 0.5518
Epoch [6/50] - Loss: 0.5160
Epoch [7/50] - Loss: 0.4927
Epoch [8/50] - Loss: 0.4770
Epoch [9/50] - Loss: 0.4613
Epoch [10/50] - Loss: 0.4495
Epoch [11/50] - Loss: 0.4406
Epoch [12/50] - Loss: 0.4327
Epoch [13/50] - Loss: 0.4277
Epoch [14/50] - Loss: 0.4256
Epoch [15/50] - Loss: 0.4153
Epoch [16/50] - Loss: 0.4114
Epoch [17/50] - Loss: 0.4068
Epoch [18/50] - Loss: 0.4067
Epoch [19/50] - Loss: 0.4020
Epoch [20/50] - Loss: 0.3959
Epoch [21/50] - Loss: 0.3893
Epoch [22/50] - Loss: 0.3903
Epoch [23/50] - Loss: 0.3842
Epoch [24/50] - Loss: 0.3845
Epoch [25/50] - Loss: 0.3823
Epoch [26/50] - Loss: 0.3795
Epoch [27/50] - Loss: 0.3753
Epoch [28/50] - Loss: 0.3753
Epoch [29/50] - Loss: 0.3725
Epoch [30/50] - Loss: 0.3671
Epoch [31/50] - Loss: 0.3677
Epoch [32/50] - Loss: 0.3643
Epoch [33/50] - Loss: 0.3620
Epoch [34/50] - Loss: 0.3609
Epoch [35/50] - Loss: 0.3612
Epoch [36/50] - Loss: 0.3583
Epoch [37/50] - Loss: 0.3541
Epoch [38/50] - Loss: 0.3556
Epoch [39/50] - Loss: 0.3529
Epoch [40/50] - Loss: 0.3460
Epoch [41/50] - Loss: 0.3419
Epoch [42/50] - Loss: 0.3428
Epoch [43/50] - Loss: 0.3420
Epoch [44/50] - Loss: 0.3385
Epoch [45/50] - Loss: 0.3406
Epoch [46/50] - Loss: 0.3341
Epoch [47/50] - Loss: 0.3333
Epoch [48/50] - Loss: 0.3303
Epoch [49/50] - Loss: 0.3265
Epoch [50/50] - Loss: 0.3249
sum preds 1659
sum labels 1607
 - Test Metrics: Accuracy=0.9443, F1=0.8187, Recall=0.8320, Precision=0.8059
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_spy_spy_1904070736.csv.
Average F1 over valid seeds: 0.7941 ± 0.0180
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and spy, GATConv,0.4: 0.7941 ± 0.0180
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.6951
Epoch [2/50] - Loss: 0.7025
Epoch [3/50] - Loss: 0.4883
Epoch [4/50] - Loss: 0.4087
Epoch [5/50] - Loss: 0.3764
Epoch [6/50] - Loss: 0.3614
Epoch [7/50] - Loss: 0.3499
Epoch [8/50] - Loss: 0.3396
Epoch [9/50] - Loss: 0.3326
Epoch [10/50] - Loss: 0.3271
Epoch [11/50] - Loss: 0.3246
Epoch [12/50] - Loss: 0.3178
Epoch [13/50] - Loss: 0.3144
Epoch [14/50] - Loss: 0.3098
Epoch [15/50] - Loss: 0.3060
Epoch [16/50] - Loss: 0.3002
Epoch [17/50] - Loss: 0.2986
Epoch [18/50] - Loss: 0.2945
Epoch [19/50] - Loss: 0.2918
Epoch [20/50] - Loss: 0.2915
Epoch [21/50] - Loss: 0.2855
Epoch [22/50] - Loss: 0.2829
Epoch [23/50] - Loss: 0.2804
Epoch [24/50] - Loss: 0.2809
Epoch [25/50] - Loss: 0.2778
Epoch [26/50] - Loss: 0.2751
Epoch [27/50] - Loss: 0.2735
Epoch [28/50] - Loss: 0.2703
Epoch [29/50] - Loss: 0.2693
Epoch [30/50] - Loss: 0.2664
Epoch [31/50] - Loss: 0.2646
Epoch [32/50] - Loss: 0.2661
Epoch [33/50] - Loss: 0.2589
Epoch [34/50] - Loss: 0.2581
Epoch [35/50] - Loss: 0.2570
Epoch [36/50] - Loss: 0.2553
Epoch [37/50] - Loss: 0.2512
Epoch [38/50] - Loss: 0.2508
Epoch [39/50] - Loss: 0.2498
Epoch [40/50] - Loss: 0.2477
Epoch [41/50] - Loss: 0.2467
Epoch [42/50] - Loss: 0.2441
Epoch [43/50] - Loss: 0.2412
Epoch [44/50] - Loss: 0.2407
Epoch [45/50] - Loss: 0.2393
Epoch [46/50] - Loss: 0.2378
Epoch [47/50] - Loss: 0.2362
Epoch [48/50] - Loss: 0.2318
Epoch [49/50] - Loss: 0.2305
Epoch [50/50] - Loss: 0.2290
sum preds 2193
sum labels 1607
 - Test Metrics: Accuracy=0.9185, F1=0.7721, Recall=0.9129, Precision=0.6689
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.3184
Epoch [2/50] - Loss: 1.5870
Epoch [3/50] - Loss: 0.9996
Epoch [4/50] - Loss: 0.7358
Epoch [5/50] - Loss: 0.6090
Epoch [6/50] - Loss: 0.5560
Epoch [7/50] - Loss: 0.5313
Epoch [8/50] - Loss: 0.5156
Epoch [9/50] - Loss: 0.5062
Epoch [10/50] - Loss: 0.5008
Epoch [11/50] - Loss: 0.4985
Epoch [12/50] - Loss: 0.4927
Epoch [13/50] - Loss: 0.4849
Epoch [14/50] - Loss: 0.4758
Epoch [15/50] - Loss: 0.4710
Epoch [16/50] - Loss: 0.4686
Epoch [17/50] - Loss: 0.4655
Epoch [18/50] - Loss: 0.4612
Epoch [19/50] - Loss: 0.4568
Epoch [20/50] - Loss: 0.4539
Epoch [21/50] - Loss: 0.4576
Epoch [22/50] - Loss: 0.4494
Epoch [23/50] - Loss: 0.4427
Epoch [24/50] - Loss: 0.4457
Epoch [25/50] - Loss: 0.4351
Epoch [26/50] - Loss: 0.4395
Epoch [27/50] - Loss: 0.4332
Epoch [28/50] - Loss: 0.4282
Epoch [29/50] - Loss: 0.4281
Epoch [30/50] - Loss: 0.4332
Epoch [31/50] - Loss: 0.4191
Epoch [32/50] - Loss: 0.4217
Epoch [33/50] - Loss: 0.4169
Epoch [34/50] - Loss: 0.4146
Epoch [35/50] - Loss: 0.4122
Epoch [36/50] - Loss: 0.4103
Epoch [37/50] - Loss: 0.4126
Epoch [38/50] - Loss: 0.4039
Epoch [39/50] - Loss: 0.4022
Epoch [40/50] - Loss: 0.4002
Epoch [41/50] - Loss: 0.4070
Epoch [42/50] - Loss: 0.3964
Epoch [43/50] - Loss: 0.3971
Epoch [44/50] - Loss: 0.3898
Epoch [45/50] - Loss: 0.3908
Epoch [46/50] - Loss: 0.3864
Epoch [47/50] - Loss: 0.3854
Epoch [48/50] - Loss: 0.3858
Epoch [49/50] - Loss: 0.3836
Epoch [50/50] - Loss: 0.3843
sum preds 1894
sum labels 1607
 - Test Metrics: Accuracy=0.9286, F1=0.7832, Recall=0.8531, Precision=0.7239
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.6671
Epoch [2/50] - Loss: 1.1607
Epoch [3/50] - Loss: 0.7780
Epoch [4/50] - Loss: 0.6610
Epoch [5/50] - Loss: 0.6103
Epoch [6/50] - Loss: 0.5756
Epoch [7/50] - Loss: 0.5562
Epoch [8/50] - Loss: 0.5400
Epoch [9/50] - Loss: 0.5321
Epoch [10/50] - Loss: 0.5253
Epoch [11/50] - Loss: 0.5166
Epoch [12/50] - Loss: 0.5082
Epoch [13/50] - Loss: 0.5036
Epoch [14/50] - Loss: 0.4961
Epoch [15/50] - Loss: 0.4907
Epoch [16/50] - Loss: 0.4837
Epoch [17/50] - Loss: 0.4825
Epoch [18/50] - Loss: 0.4786
Epoch [19/50] - Loss: 0.4747
Epoch [20/50] - Loss: 0.4708
Epoch [21/50] - Loss: 0.4678
Epoch [22/50] - Loss: 0.4657
Epoch [23/50] - Loss: 0.4620
Epoch [24/50] - Loss: 0.4589
Epoch [25/50] - Loss: 0.4559
Epoch [26/50] - Loss: 0.4512
Epoch [27/50] - Loss: 0.4501
Epoch [28/50] - Loss: 0.4462
Epoch [29/50] - Loss: 0.4452
Epoch [30/50] - Loss: 0.4435
Epoch [31/50] - Loss: 0.4383
Epoch [32/50] - Loss: 0.4358
Epoch [33/50] - Loss: 0.4326
Epoch [34/50] - Loss: 0.4302
Epoch [35/50] - Loss: 0.4263
Epoch [36/50] - Loss: 0.4248
Epoch [37/50] - Loss: 0.4214
Epoch [38/50] - Loss: 0.4199
Epoch [39/50] - Loss: 0.4194
Epoch [40/50] - Loss: 0.4165
Epoch [41/50] - Loss: 0.4099
Epoch [42/50] - Loss: 0.4096
Epoch [43/50] - Loss: 0.4079
Epoch [44/50] - Loss: 0.4079
Epoch [45/50] - Loss: 0.4050
Epoch [46/50] - Loss: 0.4035
Epoch [47/50] - Loss: 0.3984
Epoch [48/50] - Loss: 0.3998
Epoch [49/50] - Loss: 0.3972
Epoch [50/50] - Loss: 0.3940
sum preds 1642
sum labels 1607
 - Test Metrics: Accuracy=0.9459, F1=0.8230, Recall=0.8320, Precision=0.8143
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_spy_spy_1904071422.csv.
Average F1 over valid seeds: 0.7928 ± 0.0219
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and spy, GCNConv,0.4: 0.7928 ± 0.0219
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.4363
Epoch [2/50] - Loss: 0.9150
Epoch [3/50] - Loss: 0.6175
Epoch [4/50] - Loss: 0.5473
Epoch [5/50] - Loss: 0.5028
Epoch [6/50] - Loss: 0.4629
Epoch [7/50] - Loss: 0.4309
Epoch [8/50] - Loss: 0.3998
Epoch [9/50] - Loss: 0.3723
Epoch [10/50] - Loss: 0.3529
Epoch [11/50] - Loss: 0.3375
Epoch [12/50] - Loss: 0.3235
Epoch [13/50] - Loss: 0.3089
Epoch [14/50] - Loss: 0.2979
Epoch [15/50] - Loss: 0.2857
Epoch [16/50] - Loss: 0.2741
Epoch [17/50] - Loss: 0.2622
Epoch [18/50] - Loss: 0.2531
Epoch [19/50] - Loss: 0.2415
Epoch [20/50] - Loss: 0.2319
Epoch [21/50] - Loss: 0.2225
Epoch [22/50] - Loss: 0.2122
Epoch [23/50] - Loss: 0.2046
Epoch [24/50] - Loss: 0.1949
Epoch [25/50] - Loss: 0.1873
Epoch [26/50] - Loss: 0.1782
Epoch [27/50] - Loss: 0.1705
Epoch [28/50] - Loss: 0.1637
Epoch [29/50] - Loss: 0.1560
Epoch [30/50] - Loss: 0.1471
Epoch [31/50] - Loss: 0.1419
Epoch [32/50] - Loss: 0.1350
Epoch [33/50] - Loss: 0.1284
Epoch [34/50] - Loss: 0.1222
Epoch [35/50] - Loss: 0.1154
Epoch [36/50] - Loss: 0.1095
Epoch [37/50] - Loss: 0.1037
Epoch [38/50] - Loss: 0.0989
Epoch [39/50] - Loss: 0.0935
Epoch [40/50] - Loss: 0.0883
Epoch [41/50] - Loss: 0.0838
Epoch [42/50] - Loss: 0.0788
Epoch [43/50] - Loss: 0.0746
Epoch [44/50] - Loss: 0.0706
Epoch [45/50] - Loss: 0.0671
Epoch [46/50] - Loss: 0.0628
Epoch [47/50] - Loss: 0.0597
Epoch [48/50] - Loss: 0.0567
Epoch [49/50] - Loss: 0.0533
Epoch [50/50] - Loss: 0.0507
sum preds 1926
sum labels 1875
 - Test Metrics: Accuracy=0.9050, F1=0.7277, Recall=0.7376, Precision=0.7181
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.0153
Epoch [2/50] - Loss: 1.2520
Epoch [3/50] - Loss: 0.6945
Epoch [4/50] - Loss: 0.5262
Epoch [5/50] - Loss: 0.4608
Epoch [6/50] - Loss: 0.4269
Epoch [7/50] - Loss: 0.3985
Epoch [8/50] - Loss: 0.3704
Epoch [9/50] - Loss: 0.3485
Epoch [10/50] - Loss: 0.3288
Epoch [11/50] - Loss: 0.3123
Epoch [12/50] - Loss: 0.2990
Epoch [13/50] - Loss: 0.2844
Epoch [14/50] - Loss: 0.2716
Epoch [15/50] - Loss: 0.2606
Epoch [16/50] - Loss: 0.2485
Epoch [17/50] - Loss: 0.2378
Epoch [18/50] - Loss: 0.2270
Epoch [19/50] - Loss: 0.2167
Epoch [20/50] - Loss: 0.2054
Epoch [21/50] - Loss: 0.1957
Epoch [22/50] - Loss: 0.1861
Epoch [23/50] - Loss: 0.1766
Epoch [24/50] - Loss: 0.1674
Epoch [25/50] - Loss: 0.1587
Epoch [26/50] - Loss: 0.1501
Epoch [27/50] - Loss: 0.1424
Epoch [28/50] - Loss: 0.1350
Epoch [29/50] - Loss: 0.1278
Epoch [30/50] - Loss: 0.1212
Epoch [31/50] - Loss: 0.1144
Epoch [32/50] - Loss: 0.1085
Epoch [33/50] - Loss: 0.1025
Epoch [34/50] - Loss: 0.0971
Epoch [35/50] - Loss: 0.0923
Epoch [36/50] - Loss: 0.0873
Epoch [37/50] - Loss: 0.0828
Epoch [38/50] - Loss: 0.0783
Epoch [39/50] - Loss: 0.0742
Epoch [40/50] - Loss: 0.0704
Epoch [41/50] - Loss: 0.0666
Epoch [42/50] - Loss: 0.0633
Epoch [43/50] - Loss: 0.0601
Epoch [44/50] - Loss: 0.0571
Epoch [45/50] - Loss: 0.0543
Epoch [46/50] - Loss: 0.0518
Epoch [47/50] - Loss: 0.0493
Epoch [48/50] - Loss: 0.0471
Epoch [49/50] - Loss: 0.0451
Epoch [50/50] - Loss: 0.0432
sum preds 2114
sum labels 1875
 - Test Metrics: Accuracy=0.9076, F1=0.7476, Recall=0.7952, Precision=0.7053
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1011
Epoch [2/50] - Loss: 0.6977
Epoch [3/50] - Loss: 0.4516
Epoch [4/50] - Loss: 0.4000
Epoch [5/50] - Loss: 0.3638
Epoch [6/50] - Loss: 0.3292
Epoch [7/50] - Loss: 0.3056
Epoch [8/50] - Loss: 0.2899
Epoch [9/50] - Loss: 0.2717
Epoch [10/50] - Loss: 0.2518
Epoch [11/50] - Loss: 0.2406
Epoch [12/50] - Loss: 0.2282
Epoch [13/50] - Loss: 0.2165
Epoch [14/50] - Loss: 0.2047
Epoch [15/50] - Loss: 0.1964
Epoch [16/50] - Loss: 0.1854
Epoch [17/50] - Loss: 0.1743
Epoch [18/50] - Loss: 0.1680
Epoch [19/50] - Loss: 0.1599
Epoch [20/50] - Loss: 0.1558
Epoch [21/50] - Loss: 0.1460
Epoch [22/50] - Loss: 0.1404
Epoch [23/50] - Loss: 0.1321
Epoch [24/50] - Loss: 0.1266
Epoch [25/50] - Loss: 0.1196
Epoch [26/50] - Loss: 0.1144
Epoch [27/50] - Loss: 0.1099
Epoch [28/50] - Loss: 0.1046
Epoch [29/50] - Loss: 0.0997
Epoch [30/50] - Loss: 0.0944
Epoch [31/50] - Loss: 0.0905
Epoch [32/50] - Loss: 0.0862
Epoch [33/50] - Loss: 0.0822
Epoch [34/50] - Loss: 0.0774
Epoch [35/50] - Loss: 0.0740
Epoch [36/50] - Loss: 0.0699
Epoch [37/50] - Loss: 0.0661
Epoch [38/50] - Loss: 0.0628
Epoch [39/50] - Loss: 0.0592
Epoch [40/50] - Loss: 0.0561
Epoch [41/50] - Loss: 0.0533
Epoch [42/50] - Loss: 0.0499
Epoch [43/50] - Loss: 0.0473
Epoch [44/50] - Loss: 0.0451
Epoch [45/50] - Loss: 0.0432
Epoch [46/50] - Loss: 0.0407
Epoch [47/50] - Loss: 0.0388
Epoch [48/50] - Loss: 0.0366
Epoch [49/50] - Loss: 0.0346
Epoch [50/50] - Loss: 0.0331
sum preds 2241
sum labels 1875
 - Test Metrics: Accuracy=0.9027, F1=0.7425, Recall=0.8149, Precision=0.6818
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_spy_spy_1904072049.csv.
Average F1 over valid seeds: 0.7392 ± 0.0084
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and spy, MLP,0.3: 0.7392 ± 0.0084
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8602
Epoch [2/50] - Loss: 0.8814
Epoch [3/50] - Loss: 0.7417
Epoch [4/50] - Loss: 0.6658
Epoch [5/50] - Loss: 0.6021
Epoch [6/50] - Loss: 0.5701
Epoch [7/50] - Loss: 0.5535
Epoch [8/50] - Loss: 0.5362
Epoch [9/50] - Loss: 0.5278
Epoch [10/50] - Loss: 0.5196
Epoch [11/50] - Loss: 0.5026
Epoch [12/50] - Loss: 0.4975
Epoch [13/50] - Loss: 0.4899
Epoch [14/50] - Loss: 0.4808
Epoch [15/50] - Loss: 0.4732
Epoch [16/50] - Loss: 0.4709
Epoch [17/50] - Loss: 0.4590
Epoch [18/50] - Loss: 0.4566
Epoch [19/50] - Loss: 0.4506
Epoch [20/50] - Loss: 0.4527
Epoch [21/50] - Loss: 0.4425
Epoch [22/50] - Loss: 0.4356
Epoch [23/50] - Loss: 0.4335
Epoch [24/50] - Loss: 0.4270
Epoch [25/50] - Loss: 0.4245
Epoch [26/50] - Loss: 0.4203
Epoch [27/50] - Loss: 0.4163
Epoch [28/50] - Loss: 0.4080
Epoch [29/50] - Loss: 0.4014
Epoch [30/50] - Loss: 0.4025
Epoch [31/50] - Loss: 0.3960
Epoch [32/50] - Loss: 0.3910
Epoch [33/50] - Loss: 0.3897
Epoch [34/50] - Loss: 0.3855
Epoch [35/50] - Loss: 0.3736
Epoch [36/50] - Loss: 0.3724
Epoch [37/50] - Loss: 0.3720
Epoch [38/50] - Loss: 0.3660
Epoch [39/50] - Loss: 0.3606
Epoch [40/50] - Loss: 0.3611
Epoch [41/50] - Loss: 0.3594
Epoch [42/50] - Loss: 0.3561
Epoch [43/50] - Loss: 0.3568
Epoch [44/50] - Loss: 0.3478
Epoch [45/50] - Loss: 0.3469
Epoch [46/50] - Loss: 0.3477
Epoch [47/50] - Loss: 0.3377
Epoch [48/50] - Loss: 0.3319
Epoch [49/50] - Loss: 0.3330
Epoch [50/50] - Loss: 0.3353
sum preds 1586
sum labels 1875
 - Test Metrics: Accuracy=0.9351, F1=0.7957, Recall=0.7344, Precision=0.8682
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.4930
Epoch [2/50] - Loss: 1.3966
Epoch [3/50] - Loss: 1.1588
Epoch [4/50] - Loss: 0.9980
Epoch [5/50] - Loss: 0.8868
Epoch [6/50] - Loss: 0.8078
Epoch [7/50] - Loss: 0.7578
Epoch [8/50] - Loss: 0.7089
Epoch [9/50] - Loss: 0.6618
Epoch [10/50] - Loss: 0.6317
Epoch [11/50] - Loss: 0.6061
Epoch [12/50] - Loss: 0.5831
Epoch [13/50] - Loss: 0.5583
Epoch [14/50] - Loss: 0.5438
Epoch [15/50] - Loss: 0.5346
Epoch [16/50] - Loss: 0.5186
Epoch [17/50] - Loss: 0.5096
Epoch [18/50] - Loss: 0.4992
Epoch [19/50] - Loss: 0.4833
Epoch [20/50] - Loss: 0.4855
Epoch [21/50] - Loss: 0.4650
Epoch [22/50] - Loss: 0.4656
Epoch [23/50] - Loss: 0.4577
Epoch [24/50] - Loss: 0.4514
Epoch [25/50] - Loss: 0.4505
Epoch [26/50] - Loss: 0.4426
Epoch [27/50] - Loss: 0.4393
Epoch [28/50] - Loss: 0.4270
Epoch [29/50] - Loss: 0.4243
Epoch [30/50] - Loss: 0.4205
Epoch [31/50] - Loss: 0.4105
Epoch [32/50] - Loss: 0.4052
Epoch [33/50] - Loss: 0.4057
Epoch [34/50] - Loss: 0.3952
Epoch [35/50] - Loss: 0.3918
Epoch [36/50] - Loss: 0.3876
Epoch [37/50] - Loss: 0.3833
Epoch [38/50] - Loss: 0.3817
Epoch [39/50] - Loss: 0.3787
Epoch [40/50] - Loss: 0.3685
Epoch [41/50] - Loss: 0.3693
Epoch [42/50] - Loss: 0.3709
Epoch [43/50] - Loss: 0.3628
Epoch [44/50] - Loss: 0.3579
Epoch [45/50] - Loss: 0.3538
Epoch [46/50] - Loss: 0.3531
Epoch [47/50] - Loss: 0.3512
Epoch [48/50] - Loss: 0.3430
Epoch [49/50] - Loss: 0.3441
Epoch [50/50] - Loss: 0.3407
sum preds 1723
sum labels 1875
 - Test Metrics: Accuracy=0.9348, F1=0.8027, Recall=0.7701, Precision=0.8381
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8391
Epoch [2/50] - Loss: 0.8387
Epoch [3/50] - Loss: 0.6450
Epoch [4/50] - Loss: 0.6226
Epoch [5/50] - Loss: 0.5514
Epoch [6/50] - Loss: 0.5440
Epoch [7/50] - Loss: 0.5772
Epoch [8/50] - Loss: 0.4943
Epoch [9/50] - Loss: 0.5066
Epoch [10/50] - Loss: 0.5009
Epoch [11/50] - Loss: 0.5203
Epoch [12/50] - Loss: 0.4840
Epoch [13/50] - Loss: 0.4519
Epoch [14/50] - Loss: 0.4978
Epoch [15/50] - Loss: 0.5762
Epoch [16/50] - Loss: 0.5340
Epoch [17/50] - Loss: 0.5083
Epoch [18/50] - Loss: 0.4486
Epoch [19/50] - Loss: 0.5096
Epoch [20/50] - Loss: 0.4576
Epoch [21/50] - Loss: 0.4734
Epoch [22/50] - Loss: 0.4647
Epoch [23/50] - Loss: 0.4490
Epoch [24/50] - Loss: 0.4343
Epoch [25/50] - Loss: 0.4240
Epoch [26/50] - Loss: 0.4153
Epoch [27/50] - Loss: 0.3852
Epoch [28/50] - Loss: 0.4032
Epoch [29/50] - Loss: 0.3690
Epoch [30/50] - Loss: 0.3802
Epoch [31/50] - Loss: 0.4207
Epoch [32/50] - Loss: 0.3776
Epoch [33/50] - Loss: 0.3929
Epoch [34/50] - Loss: 0.3596
Epoch [35/50] - Loss: 0.3684
Epoch [36/50] - Loss: 0.3719
Epoch [37/50] - Loss: 0.3652
Epoch [38/50] - Loss: 0.3594
Epoch [39/50] - Loss: 0.3545
Epoch [40/50] - Loss: 0.3479
Epoch [41/50] - Loss: 0.3549
Epoch [42/50] - Loss: 0.3526
Epoch [43/50] - Loss: 0.3274
Epoch [44/50] - Loss: 0.3356
Epoch [45/50] - Loss: 0.3545
Epoch [46/50] - Loss: 0.3231
Epoch [47/50] - Loss: 0.3498
Epoch [48/50] - Loss: 0.3421
Epoch [49/50] - Loss: 0.3270
Epoch [50/50] - Loss: 0.3450
sum preds 1859
sum labels 1875
 - Test Metrics: Accuracy=0.9389, F1=0.8216, Recall=0.8181, Precision=0.8252
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_spy_spy_1904072730.csv.
Average F1 over valid seeds: 0.8067 ± 0.0110
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and spy, GATConv,0.3: 0.8067 ± 0.0110
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.0810
Epoch [2/50] - Loss: 0.9029
Epoch [3/50] - Loss: 0.6506
Epoch [4/50] - Loss: 0.5906
Epoch [5/50] - Loss: 0.5712
Epoch [6/50] - Loss: 0.5579
Epoch [7/50] - Loss: 0.5503
Epoch [8/50] - Loss: 0.5366
Epoch [9/50] - Loss: 0.5276
Epoch [10/50] - Loss: 0.5190
Epoch [11/50] - Loss: 0.5138
Epoch [12/50] - Loss: 0.5068
Epoch [13/50] - Loss: 0.4999
Epoch [14/50] - Loss: 0.4937
Epoch [15/50] - Loss: 0.4901
Epoch [16/50] - Loss: 0.4873
Epoch [17/50] - Loss: 0.4811
Epoch [18/50] - Loss: 0.4789
Epoch [19/50] - Loss: 0.4752
Epoch [20/50] - Loss: 0.4708
Epoch [21/50] - Loss: 0.4677
Epoch [22/50] - Loss: 0.4663
Epoch [23/50] - Loss: 0.4600
Epoch [24/50] - Loss: 0.4586
Epoch [25/50] - Loss: 0.4569
Epoch [26/50] - Loss: 0.4531
Epoch [27/50] - Loss: 0.4512
Epoch [28/50] - Loss: 0.4493
Epoch [29/50] - Loss: 0.4483
Epoch [30/50] - Loss: 0.4438
Epoch [31/50] - Loss: 0.4441
Epoch [32/50] - Loss: 0.4387
Epoch [33/50] - Loss: 0.4368
Epoch [34/50] - Loss: 0.4328
Epoch [35/50] - Loss: 0.4324
Epoch [36/50] - Loss: 0.4291
Epoch [37/50] - Loss: 0.4275
Epoch [38/50] - Loss: 0.4259
Epoch [39/50] - Loss: 0.4252
Epoch [40/50] - Loss: 0.4224
Epoch [41/50] - Loss: 0.4189
Epoch [42/50] - Loss: 0.4170
Epoch [43/50] - Loss: 0.4166
Epoch [44/50] - Loss: 0.4141
Epoch [45/50] - Loss: 0.4128
Epoch [46/50] - Loss: 0.4091
Epoch [47/50] - Loss: 0.4095
Epoch [48/50] - Loss: 0.4072
Epoch [49/50] - Loss: 0.4051
Epoch [50/50] - Loss: 0.4028
sum preds 1680
sum labels 1875
 - Test Metrics: Accuracy=0.9346, F1=0.7994, Recall=0.7579, Precision=0.8458
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4524
Epoch [2/50] - Loss: 0.6903
Epoch [3/50] - Loss: 0.5630
Epoch [4/50] - Loss: 0.5177
Epoch [5/50] - Loss: 0.5071
Epoch [6/50] - Loss: 0.5032
Epoch [7/50] - Loss: 0.5005
Epoch [8/50] - Loss: 0.4847
Epoch [9/50] - Loss: 0.4745
Epoch [10/50] - Loss: 0.4628
Epoch [11/50] - Loss: 0.4564
Epoch [12/50] - Loss: 0.4498
Epoch [13/50] - Loss: 0.4478
Epoch [14/50] - Loss: 0.4419
Epoch [15/50] - Loss: 0.4358
Epoch [16/50] - Loss: 0.4321
Epoch [17/50] - Loss: 0.4262
Epoch [18/50] - Loss: 0.4236
Epoch [19/50] - Loss: 0.4205
Epoch [20/50] - Loss: 0.4169
Epoch [21/50] - Loss: 0.4112
Epoch [22/50] - Loss: 0.4124
Epoch [23/50] - Loss: 0.4061
Epoch [24/50] - Loss: 0.4046
Epoch [25/50] - Loss: 0.4026
Epoch [26/50] - Loss: 0.3954
Epoch [27/50] - Loss: 0.3958
Epoch [28/50] - Loss: 0.3907
Epoch [29/50] - Loss: 0.3900
Epoch [30/50] - Loss: 0.3895
Epoch [31/50] - Loss: 0.3856
Epoch [32/50] - Loss: 0.3808
Epoch [33/50] - Loss: 0.3809
Epoch [34/50] - Loss: 0.3799
Epoch [35/50] - Loss: 0.3752
Epoch [36/50] - Loss: 0.3727
Epoch [37/50] - Loss: 0.3702
Epoch [38/50] - Loss: 0.3717
Epoch [39/50] - Loss: 0.3667
Epoch [40/50] - Loss: 0.3686
Epoch [41/50] - Loss: 0.3634
Epoch [42/50] - Loss: 0.3627
Epoch [43/50] - Loss: 0.3574
Epoch [44/50] - Loss: 0.3587
Epoch [45/50] - Loss: 0.3565
Epoch [46/50] - Loss: 0.3521
Epoch [47/50] - Loss: 0.3537
Epoch [48/50] - Loss: 0.3510
Epoch [49/50] - Loss: 0.3499
Epoch [50/50] - Loss: 0.3437
sum preds 1925
sum labels 1875
 - Test Metrics: Accuracy=0.9345, F1=0.8121, Recall=0.8229, Precision=0.8016
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.8789
Epoch [2/50] - Loss: 1.3276
Epoch [3/50] - Loss: 0.8300
Epoch [4/50] - Loss: 0.6424
Epoch [5/50] - Loss: 0.5457
Epoch [6/50] - Loss: 0.5241
Epoch [7/50] - Loss: 0.5259
Epoch [8/50] - Loss: 0.5029
Epoch [9/50] - Loss: 0.4762
Epoch [10/50] - Loss: 0.4922
Epoch [11/50] - Loss: 0.4667
Epoch [12/50] - Loss: 0.4689
Epoch [13/50] - Loss: 0.4670
Epoch [14/50] - Loss: 0.4586
Epoch [15/50] - Loss: 0.4671
Epoch [16/50] - Loss: 0.4626
Epoch [17/50] - Loss: 0.4601
Epoch [18/50] - Loss: 0.4387
Epoch [19/50] - Loss: 0.4395
Epoch [20/50] - Loss: 0.4591
Epoch [21/50] - Loss: 0.4446
Epoch [22/50] - Loss: 0.4311
Epoch [23/50] - Loss: 0.4242
Epoch [24/50] - Loss: 0.4128
Epoch [25/50] - Loss: 0.4361
Epoch [26/50] - Loss: 0.4159
Epoch [27/50] - Loss: 0.4286
Epoch [28/50] - Loss: 0.4321
Epoch [29/50] - Loss: 0.4066
Epoch [30/50] - Loss: 0.3920
Epoch [31/50] - Loss: 0.4071
Epoch [32/50] - Loss: 0.3927
Epoch [33/50] - Loss: 0.3879
Epoch [34/50] - Loss: 0.4038
Epoch [35/50] - Loss: 0.4134
Epoch [36/50] - Loss: 0.4060
Epoch [37/50] - Loss: 0.3869
Epoch [38/50] - Loss: 0.3999
Epoch [39/50] - Loss: 0.3729
Epoch [40/50] - Loss: 0.3911
Epoch [41/50] - Loss: 0.3999
Epoch [42/50] - Loss: 0.3777
Epoch [43/50] - Loss: 0.3851
Epoch [44/50] - Loss: 0.3928
Epoch [45/50] - Loss: 0.3834
Epoch [46/50] - Loss: 0.3819
Epoch [47/50] - Loss: 0.3736
Epoch [48/50] - Loss: 0.3667
Epoch [49/50] - Loss: 0.3787
Epoch [50/50] - Loss: 0.3816
sum preds 1904
sum labels 1875
 - Test Metrics: Accuracy=0.9395, F1=0.8256, Recall=0.8320, Precision=0.8193
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_spy_spy_1904073433.csv.
Average F1 over valid seeds: 0.8124 ± 0.0107
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and spy, GCNConv,0.3: 0.8124 ± 0.0107
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9767
Epoch [2/50] - Loss: 0.6860
Epoch [3/50] - Loss: 0.3810
Epoch [4/50] - Loss: 0.2915
Epoch [5/50] - Loss: 0.2591
Epoch [6/50] - Loss: 0.2338
Epoch [7/50] - Loss: 0.2134
Epoch [8/50] - Loss: 0.1965
Epoch [9/50] - Loss: 0.1805
Epoch [10/50] - Loss: 0.1687
Epoch [11/50] - Loss: 0.1546
Epoch [12/50] - Loss: 0.1451
Epoch [13/50] - Loss: 0.1353
Epoch [14/50] - Loss: 0.1282
Epoch [15/50] - Loss: 0.1216
Epoch [16/50] - Loss: 0.1156
Epoch [17/50] - Loss: 0.1096
Epoch [18/50] - Loss: 0.1043
Epoch [19/50] - Loss: 0.0998
Epoch [20/50] - Loss: 0.0938
Epoch [21/50] - Loss: 0.0900
Epoch [22/50] - Loss: 0.0856
Epoch [23/50] - Loss: 0.0821
Epoch [24/50] - Loss: 0.0771
Epoch [25/50] - Loss: 0.0741
Epoch [26/50] - Loss: 0.0704
Epoch [27/50] - Loss: 0.0667
Epoch [28/50] - Loss: 0.0639
Epoch [29/50] - Loss: 0.0612
Epoch [30/50] - Loss: 0.0581
Epoch [31/50] - Loss: 0.0551
Epoch [32/50] - Loss: 0.0529
Epoch [33/50] - Loss: 0.0501
Epoch [34/50] - Loss: 0.0477
Epoch [35/50] - Loss: 0.0453
Epoch [36/50] - Loss: 0.0428
Epoch [37/50] - Loss: 0.0414
Epoch [38/50] - Loss: 0.0391
Epoch [39/50] - Loss: 0.0374
Epoch [40/50] - Loss: 0.0346
Epoch [41/50] - Loss: 0.0335
Epoch [42/50] - Loss: 0.0313
Epoch [43/50] - Loss: 0.0297
Epoch [44/50] - Loss: 0.0286
Epoch [45/50] - Loss: 0.0270
Epoch [46/50] - Loss: 0.0254
Epoch [47/50] - Loss: 0.0244
Epoch [48/50] - Loss: 0.0229
Epoch [49/50] - Loss: 0.0220
Epoch [50/50] - Loss: 0.0207
sum preds 2692
sum labels 2143
 - Test Metrics: Accuracy=0.8881, F1=0.7417, Recall=0.8367, Precision=0.6660
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.5625
Epoch [2/50] - Loss: 2.1067
Epoch [3/50] - Loss: 1.0559
Epoch [4/50] - Loss: 0.6401
Epoch [5/50] - Loss: 0.5155
Epoch [6/50] - Loss: 0.4508
Epoch [7/50] - Loss: 0.4217
Epoch [8/50] - Loss: 0.4004
Epoch [9/50] - Loss: 0.3781
Epoch [10/50] - Loss: 0.3556
Epoch [11/50] - Loss: 0.3366
Epoch [12/50] - Loss: 0.3194
Epoch [13/50] - Loss: 0.3057
Epoch [14/50] - Loss: 0.2919
Epoch [15/50] - Loss: 0.2793
Epoch [16/50] - Loss: 0.2676
Epoch [17/50] - Loss: 0.2545
Epoch [18/50] - Loss: 0.2451
Epoch [19/50] - Loss: 0.2338
Epoch [20/50] - Loss: 0.2228
Epoch [21/50] - Loss: 0.2128
Epoch [22/50] - Loss: 0.2040
Epoch [23/50] - Loss: 0.1944
Epoch [24/50] - Loss: 0.1847
Epoch [25/50] - Loss: 0.1770
Epoch [26/50] - Loss: 0.1685
Epoch [27/50] - Loss: 0.1602
Epoch [28/50] - Loss: 0.1524
Epoch [29/50] - Loss: 0.1446
Epoch [30/50] - Loss: 0.1374
Epoch [31/50] - Loss: 0.1297
Epoch [32/50] - Loss: 0.1231
Epoch [33/50] - Loss: 0.1169
Epoch [34/50] - Loss: 0.1101
Epoch [35/50] - Loss: 0.1038
Epoch [36/50] - Loss: 0.0980
Epoch [37/50] - Loss: 0.0925
Epoch [38/50] - Loss: 0.0870
Epoch [39/50] - Loss: 0.0817
Epoch [40/50] - Loss: 0.0770
Epoch [41/50] - Loss: 0.0722
Epoch [42/50] - Loss: 0.0678
Epoch [43/50] - Loss: 0.0639
Epoch [44/50] - Loss: 0.0601
Epoch [45/50] - Loss: 0.0565
Epoch [46/50] - Loss: 0.0529
Epoch [47/50] - Loss: 0.0498
Epoch [48/50] - Loss: 0.0468
Epoch [49/50] - Loss: 0.0441
Epoch [50/50] - Loss: 0.0413
sum preds 1869
sum labels 2143
 - Test Metrics: Accuracy=0.9092, F1=0.7473, Recall=0.6995, Precision=0.8020
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.7936
Epoch [2/50] - Loss: 0.8536
Epoch [3/50] - Loss: 0.4745
Epoch [4/50] - Loss: 0.3422
Epoch [5/50] - Loss: 0.2777
Epoch [6/50] - Loss: 0.2396
Epoch [7/50] - Loss: 0.2166
Epoch [8/50] - Loss: 0.2018
Epoch [9/50] - Loss: 0.1894
Epoch [10/50] - Loss: 0.1767
Epoch [11/50] - Loss: 0.1643
Epoch [12/50] - Loss: 0.1542
Epoch [13/50] - Loss: 0.1445
Epoch [14/50] - Loss: 0.1368
Epoch [15/50] - Loss: 0.1290
Epoch [16/50] - Loss: 0.1231
Epoch [17/50] - Loss: 0.1175
Epoch [18/50] - Loss: 0.1116
Epoch [19/50] - Loss: 0.1061
Epoch [20/50] - Loss: 0.1004
Epoch [21/50] - Loss: 0.0957
Epoch [22/50] - Loss: 0.0912
Epoch [23/50] - Loss: 0.0872
Epoch [24/50] - Loss: 0.0832
Epoch [25/50] - Loss: 0.0789
Epoch [26/50] - Loss: 0.0754
Epoch [27/50] - Loss: 0.0717
Epoch [28/50] - Loss: 0.0684
Epoch [29/50] - Loss: 0.0653
Epoch [30/50] - Loss: 0.0619
Epoch [31/50] - Loss: 0.0587
Epoch [32/50] - Loss: 0.0557
Epoch [33/50] - Loss: 0.0531
Epoch [34/50] - Loss: 0.0506
Epoch [35/50] - Loss: 0.0482
Epoch [36/50] - Loss: 0.0460
Epoch [37/50] - Loss: 0.0438
Epoch [38/50] - Loss: 0.0418
Epoch [39/50] - Loss: 0.0400
Epoch [40/50] - Loss: 0.0384
Epoch [41/50] - Loss: 0.0367
Epoch [42/50] - Loss: 0.0351
Epoch [43/50] - Loss: 0.0337
Epoch [44/50] - Loss: 0.0325
Epoch [45/50] - Loss: 0.0312
Epoch [46/50] - Loss: 0.0301
Epoch [47/50] - Loss: 0.0290
Epoch [48/50] - Loss: 0.0278
Epoch [49/50] - Loss: 0.0270
Epoch [50/50] - Loss: 0.0260
sum preds 2527
sum labels 2143
 - Test Metrics: Accuracy=0.8972, F1=0.7542, Recall=0.8217, Precision=0.6969
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_spy_spy_1904074135.csv.
Average F1 over valid seeds: 0.7477 ± 0.0051
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and spy, MLP,0.2: 0.7477 ± 0.0051
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.4782
Epoch [2/50] - Loss: 0.6226
Epoch [3/50] - Loss: 0.4567
Epoch [4/50] - Loss: 0.3997
Epoch [5/50] - Loss: 0.3656
Epoch [6/50] - Loss: 0.3295
Epoch [7/50] - Loss: 0.3158
Epoch [8/50] - Loss: 0.3023
Epoch [9/50] - Loss: 0.2941
Epoch [10/50] - Loss: 0.2852
Epoch [11/50] - Loss: 0.2773
Epoch [12/50] - Loss: 0.2752
Epoch [13/50] - Loss: 0.2644
Epoch [14/50] - Loss: 0.2612
Epoch [15/50] - Loss: 0.2583
Epoch [16/50] - Loss: 0.2581
Epoch [17/50] - Loss: 0.2522
Epoch [18/50] - Loss: 0.2450
Epoch [19/50] - Loss: 0.2398
Epoch [20/50] - Loss: 0.2382
Epoch [21/50] - Loss: 0.2393
Epoch [22/50] - Loss: 0.2290
Epoch [23/50] - Loss: 0.2281
Epoch [24/50] - Loss: 0.2229
Epoch [25/50] - Loss: 0.2231
Epoch [26/50] - Loss: 0.2150
Epoch [27/50] - Loss: 0.2110
Epoch [28/50] - Loss: 0.2054
Epoch [29/50] - Loss: 0.2055
Epoch [30/50] - Loss: 0.2053
Epoch [31/50] - Loss: 0.2043
Epoch [32/50] - Loss: 0.1980
Epoch [33/50] - Loss: 0.1939
Epoch [34/50] - Loss: 0.1946
Epoch [35/50] - Loss: 0.1906
Epoch [36/50] - Loss: 0.1840
Epoch [37/50] - Loss: 0.1851
Epoch [38/50] - Loss: 0.1770
Epoch [39/50] - Loss: 0.1818
Epoch [40/50] - Loss: 0.1748
Epoch [41/50] - Loss: 0.1743
Epoch [42/50] - Loss: 0.1746
Epoch [43/50] - Loss: 0.1752
Epoch [44/50] - Loss: 0.1703
Epoch [45/50] - Loss: 0.1632
Epoch [46/50] - Loss: 0.1658
Epoch [47/50] - Loss: 0.1660
Epoch [48/50] - Loss: 0.1652
Epoch [49/50] - Loss: 0.1566
Epoch [50/50] - Loss: 0.1557
sum preds 2226
sum labels 2143
 - Test Metrics: Accuracy=0.9256, F1=0.8098, Recall=0.8255, Precision=0.7947
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.6106
Epoch [2/50] - Loss: 0.8381
Epoch [3/50] - Loss: 0.6381
Epoch [4/50] - Loss: 0.5606
Epoch [5/50] - Loss: 0.5193
Epoch [6/50] - Loss: 0.4942
Epoch [7/50] - Loss: 0.4736
Epoch [8/50] - Loss: 0.4621
Epoch [9/50] - Loss: 0.4488
Epoch [10/50] - Loss: 0.4402
Epoch [11/50] - Loss: 0.4339
Epoch [12/50] - Loss: 0.4292
Epoch [13/50] - Loss: 0.4186
Epoch [14/50] - Loss: 0.4139
Epoch [15/50] - Loss: 0.4033
Epoch [16/50] - Loss: 0.4001
Epoch [17/50] - Loss: 0.3915
Epoch [18/50] - Loss: 0.3867
Epoch [19/50] - Loss: 0.3843
Epoch [20/50] - Loss: 0.3745
Epoch [21/50] - Loss: 0.3690
Epoch [22/50] - Loss: 0.3650
Epoch [23/50] - Loss: 0.3579
Epoch [24/50] - Loss: 0.3561
Epoch [25/50] - Loss: 0.3474
Epoch [26/50] - Loss: 0.3457
Epoch [27/50] - Loss: 0.3417
Epoch [28/50] - Loss: 0.3365
Epoch [29/50] - Loss: 0.3318
Epoch [30/50] - Loss: 0.3259
Epoch [31/50] - Loss: 0.3181
Epoch [32/50] - Loss: 0.3152
Epoch [33/50] - Loss: 0.3127
Epoch [34/50] - Loss: 0.3093
Epoch [35/50] - Loss: 0.3060
Epoch [36/50] - Loss: 0.3034
Epoch [37/50] - Loss: 0.3004
Epoch [38/50] - Loss: 0.2912
Epoch [39/50] - Loss: 0.2890
Epoch [40/50] - Loss: 0.2880
Epoch [41/50] - Loss: 0.2856
Epoch [42/50] - Loss: 0.2833
Epoch [43/50] - Loss: 0.2776
Epoch [44/50] - Loss: 0.2734
Epoch [45/50] - Loss: 0.2702
Epoch [46/50] - Loss: 0.2683
Epoch [47/50] - Loss: 0.2635
Epoch [48/50] - Loss: 0.2607
Epoch [49/50] - Loss: 0.2551
Epoch [50/50] - Loss: 0.2606
sum preds 1645
sum labels 2143
 - Test Metrics: Accuracy=0.9224, F1=0.7714, Recall=0.6818, Precision=0.8881
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.5898
Epoch [2/50] - Loss: 0.5055
Epoch [3/50] - Loss: 0.4033
Epoch [4/50] - Loss: 0.3940
Epoch [5/50] - Loss: 0.3672
Epoch [6/50] - Loss: 0.3176
Epoch [7/50] - Loss: 0.3016
Epoch [8/50] - Loss: 0.2832
Epoch [9/50] - Loss: 0.2769
Epoch [10/50] - Loss: 0.2646
Epoch [11/50] - Loss: 0.2594
Epoch [12/50] - Loss: 0.2479
Epoch [13/50] - Loss: 0.2411
Epoch [14/50] - Loss: 0.2357
Epoch [15/50] - Loss: 0.2310
Epoch [16/50] - Loss: 0.2289
Epoch [17/50] - Loss: 0.2225
Epoch [18/50] - Loss: 0.2213
Epoch [19/50] - Loss: 0.2153
Epoch [20/50] - Loss: 0.2130
Epoch [21/50] - Loss: 0.2089
Epoch [22/50] - Loss: 0.2082
Epoch [23/50] - Loss: 0.2038
Epoch [24/50] - Loss: 0.2008
Epoch [25/50] - Loss: 0.1983
Epoch [26/50] - Loss: 0.1978
Epoch [27/50] - Loss: 0.1965
Epoch [28/50] - Loss: 0.1940
Epoch [29/50] - Loss: 0.1915
Epoch [30/50] - Loss: 0.1855
Epoch [31/50] - Loss: 0.1858
Epoch [32/50] - Loss: 0.1864
Epoch [33/50] - Loss: 0.1832
Epoch [34/50] - Loss: 0.1814
Epoch [35/50] - Loss: 0.1765
Epoch [36/50] - Loss: 0.1760
Epoch [37/50] - Loss: 0.1737
Epoch [38/50] - Loss: 0.1797
Epoch [39/50] - Loss: 0.1734
Epoch [40/50] - Loss: 0.1691
Epoch [41/50] - Loss: 0.1701
Epoch [42/50] - Loss: 0.1697
Epoch [43/50] - Loss: 0.1649
Epoch [44/50] - Loss: 0.1670
Epoch [45/50] - Loss: 0.1630
Epoch [46/50] - Loss: 0.1634
Epoch [47/50] - Loss: 0.1631
Epoch [48/50] - Loss: 0.1610
Epoch [49/50] - Loss: 0.1585
Epoch [50/50] - Loss: 0.1567
sum preds 2024
sum labels 2143
 - Test Metrics: Accuracy=0.9361, F1=0.8289, Recall=0.8059, Precision=0.8533
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_spy_spy_1904074726.csv.
Average F1 over valid seeds: 0.8034 ± 0.0239
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and spy, GATConv,0.2: 0.8034 ± 0.0239
___________________________________________________________________________________
spy
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.7161
Epoch [2/50] - Loss: 0.6837
Epoch [3/50] - Loss: 0.4406
Epoch [4/50] - Loss: 0.3580
Epoch [5/50] - Loss: 0.3293
Epoch [6/50] - Loss: 0.3168
Epoch [7/50] - Loss: 0.3077
Epoch [8/50] - Loss: 0.3008
Epoch [9/50] - Loss: 0.2950
Epoch [10/50] - Loss: 0.2915
Epoch [11/50] - Loss: 0.2842
Epoch [12/50] - Loss: 0.2825
Epoch [13/50] - Loss: 0.2767
Epoch [14/50] - Loss: 0.2712
Epoch [15/50] - Loss: 0.2716
Epoch [16/50] - Loss: 0.2675
Epoch [17/50] - Loss: 0.2644
Epoch [18/50] - Loss: 0.2613
Epoch [19/50] - Loss: 0.2595
Epoch [20/50] - Loss: 0.2571
Epoch [21/50] - Loss: 0.2546
Epoch [22/50] - Loss: 0.2522
Epoch [23/50] - Loss: 0.2498
Epoch [24/50] - Loss: 0.2501
Epoch [25/50] - Loss: 0.2464
Epoch [26/50] - Loss: 0.2449
Epoch [27/50] - Loss: 0.2433
Epoch [28/50] - Loss: 0.2412
Epoch [29/50] - Loss: 0.2383
Epoch [30/50] - Loss: 0.2379
Epoch [31/50] - Loss: 0.2350
Epoch [32/50] - Loss: 0.2351
Epoch [33/50] - Loss: 0.2302
Epoch [34/50] - Loss: 0.2312
Epoch [35/50] - Loss: 0.2277
Epoch [36/50] - Loss: 0.2272
Epoch [37/50] - Loss: 0.2253
Epoch [38/50] - Loss: 0.2234
Epoch [39/50] - Loss: 0.2226
Epoch [40/50] - Loss: 0.2210
Epoch [41/50] - Loss: 0.2197
Epoch [42/50] - Loss: 0.2174
Epoch [43/50] - Loss: 0.2150
Epoch [44/50] - Loss: 0.2128
Epoch [45/50] - Loss: 0.2160
Epoch [46/50] - Loss: 0.2112
Epoch [47/50] - Loss: 0.2124
Epoch [48/50] - Loss: 0.2076
Epoch [49/50] - Loss: 0.2086
Epoch [50/50] - Loss: 0.2038
sum preds 2296
sum labels 2143
 - Test Metrics: Accuracy=0.9220, F1=0.8038, Recall=0.8325, Precision=0.7770
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.4705
Epoch [2/50] - Loss: 1.7490
Epoch [3/50] - Loss: 1.0760
Epoch [4/50] - Loss: 0.7361
Epoch [5/50] - Loss: 0.5897
Epoch [6/50] - Loss: 0.5361
Epoch [7/50] - Loss: 0.5144
Epoch [8/50] - Loss: 0.5001
Epoch [9/50] - Loss: 0.4880
Epoch [10/50] - Loss: 0.4810
Epoch [11/50] - Loss: 0.4789
Epoch [12/50] - Loss: 0.4750
Epoch [13/50] - Loss: 0.4716
Epoch [14/50] - Loss: 0.4651
Epoch [15/50] - Loss: 0.4627
Epoch [16/50] - Loss: 0.4615
Epoch [17/50] - Loss: 0.4536
Epoch [18/50] - Loss: 0.4522
Epoch [19/50] - Loss: 0.4501
Epoch [20/50] - Loss: 0.4473
Epoch [21/50] - Loss: 0.4441
Epoch [22/50] - Loss: 0.4405
Epoch [23/50] - Loss: 0.4388
Epoch [24/50] - Loss: 0.4367
Epoch [25/50] - Loss: 0.4314
Epoch [26/50] - Loss: 0.4324
Epoch [27/50] - Loss: 0.4294
Epoch [28/50] - Loss: 0.4286
Epoch [29/50] - Loss: 0.4237
Epoch [30/50] - Loss: 0.4230
Epoch [31/50] - Loss: 0.4235
Epoch [32/50] - Loss: 0.4199
Epoch [33/50] - Loss: 0.4182
Epoch [34/50] - Loss: 0.4133
Epoch [35/50] - Loss: 0.4144
Epoch [36/50] - Loss: 0.4122
Epoch [37/50] - Loss: 0.4104
Epoch [38/50] - Loss: 0.4079
Epoch [39/50] - Loss: 0.4071
Epoch [40/50] - Loss: 0.4064
Epoch [41/50] - Loss: 0.4035
Epoch [42/50] - Loss: 0.4007
Epoch [43/50] - Loss: 0.4010
Epoch [44/50] - Loss: 0.3980
Epoch [45/50] - Loss: 0.3959
Epoch [46/50] - Loss: 0.3963
Epoch [47/50] - Loss: 0.3947
Epoch [48/50] - Loss: 0.3926
Epoch [49/50] - Loss: 0.3921
Epoch [50/50] - Loss: 0.3910
sum preds 1648
sum labels 2143
 - Test Metrics: Accuracy=0.9290, F1=0.7908, Recall=0.6995, Precision=0.9096
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=spy
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.2890
Epoch [2/50] - Loss: 1.0058
Epoch [3/50] - Loss: 0.5870
Epoch [4/50] - Loss: 0.4385
Epoch [5/50] - Loss: 0.3817
Epoch [6/50] - Loss: 0.3562
Epoch [7/50] - Loss: 0.3385
Epoch [8/50] - Loss: 0.3252
Epoch [9/50] - Loss: 0.3177
Epoch [10/50] - Loss: 0.3100
Epoch [11/50] - Loss: 0.3053
Epoch [12/50] - Loss: 0.2984
Epoch [13/50] - Loss: 0.2977
Epoch [14/50] - Loss: 0.2927
Epoch [15/50] - Loss: 0.2882
Epoch [16/50] - Loss: 0.2868
Epoch [17/50] - Loss: 0.2815
Epoch [18/50] - Loss: 0.2792
Epoch [19/50] - Loss: 0.2762
Epoch [20/50] - Loss: 0.2731
Epoch [21/50] - Loss: 0.2714
Epoch [22/50] - Loss: 0.2681
Epoch [23/50] - Loss: 0.2667
Epoch [24/50] - Loss: 0.2658
Epoch [25/50] - Loss: 0.2627
Epoch [26/50] - Loss: 0.2591
Epoch [27/50] - Loss: 0.2591
Epoch [28/50] - Loss: 0.2553
Epoch [29/50] - Loss: 0.2530
Epoch [30/50] - Loss: 0.2520
Epoch [31/50] - Loss: 0.2497
Epoch [32/50] - Loss: 0.2507
Epoch [33/50] - Loss: 0.2464
Epoch [34/50] - Loss: 0.2461
Epoch [35/50] - Loss: 0.2449
Epoch [36/50] - Loss: 0.2443
Epoch [37/50] - Loss: 0.2411
Epoch [38/50] - Loss: 0.2391
Epoch [39/50] - Loss: 0.2381
Epoch [40/50] - Loss: 0.2358
Epoch [41/50] - Loss: 0.2344
Epoch [42/50] - Loss: 0.2339
Epoch [43/50] - Loss: 0.2314
Epoch [44/50] - Loss: 0.2323
Epoch [45/50] - Loss: 0.2292
Epoch [46/50] - Loss: 0.2285
Epoch [47/50] - Loss: 0.2287
Epoch [48/50] - Loss: 0.2255
Epoch [49/50] - Loss: 0.2258
Epoch [50/50] - Loss: 0.2248
sum preds 2005
sum labels 2143
 - Test Metrics: Accuracy=0.9375, F1=0.8317, Recall=0.8049, Precision=0.8603
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_spy_spy_1904075336.csv.
Average F1 over valid seeds: 0.8088 ± 0.0171
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and spy, GCNConv,0.2: 0.8088 ± 0.0171
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4930
Epoch [2/50] - Loss: 0.4200
Epoch [3/50] - Loss: 0.3588
Epoch [4/50] - Loss: 0.3082
Epoch [5/50] - Loss: 0.2660
Epoch [6/50] - Loss: 0.2306
Epoch [7/50] - Loss: 0.2007
Epoch [8/50] - Loss: 0.1754
Epoch [9/50] - Loss: 0.1537
Epoch [10/50] - Loss: 0.1352
Epoch [11/50] - Loss: 0.1192
Epoch [12/50] - Loss: 0.1054
Epoch [13/50] - Loss: 0.0934
Epoch [14/50] - Loss: 0.0830
Epoch [15/50] - Loss: 0.0740
Epoch [16/50] - Loss: 0.0662
Epoch [17/50] - Loss: 0.0595
Epoch [18/50] - Loss: 0.0537
Epoch [19/50] - Loss: 0.0487
Epoch [20/50] - Loss: 0.0443
Epoch [21/50] - Loss: 0.0428
Epoch [22/50] - Loss: 0.0425
Epoch [23/50] - Loss: 0.0418
Epoch [24/50] - Loss: 0.0408
Epoch [25/50] - Loss: 0.0396
Epoch [26/50] - Loss: 0.0382
Epoch [27/50] - Loss: 0.0366
Epoch [28/50] - Loss: 0.0350
Epoch [29/50] - Loss: 0.0334
Epoch [30/50] - Loss: 0.0318
Epoch [31/50] - Loss: 0.0302
Epoch [32/50] - Loss: 0.0288
Epoch [33/50] - Loss: 0.0279
Epoch [34/50] - Loss: 0.0278
Epoch [35/50] - Loss: 0.0265
Epoch [36/50] - Loss: 0.0249
Epoch [37/50] - Loss: 0.0243
Epoch [38/50] - Loss: 0.0237
Epoch [39/50] - Loss: 0.0231
Epoch [40/50] - Loss: 0.0225
Epoch [41/50] - Loss: 0.0228
Epoch [42/50] - Loss: 0.0225
Epoch [43/50] - Loss: 0.0215
Epoch [44/50] - Loss: 0.0213
Epoch [45/50] - Loss: 0.0210
Epoch [46/50] - Loss: 0.0207
Epoch [47/50] - Loss: 0.0203
Epoch [48/50] - Loss: 0.0198
Epoch [49/50] - Loss: 0.0198
Epoch [50/50] - Loss: 0.0191
sum preds 2120
sum labels 1607
 - Test Metrics: Accuracy=0.9169, F1=0.7631, Recall=0.8849, Precision=0.6708
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5500
Epoch [2/50] - Loss: 0.4915
Epoch [3/50] - Loss: 0.4411
Epoch [4/50] - Loss: 0.3973
Epoch [5/50] - Loss: 0.3573
Epoch [6/50] - Loss: 0.3200
Epoch [7/50] - Loss: 0.2854
Epoch [8/50] - Loss: 0.2535
Epoch [9/50] - Loss: 0.2247
Epoch [10/50] - Loss: 0.1988
Epoch [11/50] - Loss: 0.1761
Epoch [12/50] - Loss: 0.1561
Epoch [13/50] - Loss: 0.1386
Epoch [14/50] - Loss: 0.1234
Epoch [15/50] - Loss: 0.1102
Epoch [16/50] - Loss: 0.0986
Epoch [17/50] - Loss: 0.0886
Epoch [18/50] - Loss: 0.0798
Epoch [19/50] - Loss: 0.0722
Epoch [20/50] - Loss: 0.0655
Epoch [21/50] - Loss: 0.0597
Epoch [22/50] - Loss: 0.0546
Epoch [23/50] - Loss: 0.0501
Epoch [24/50] - Loss: 0.0462
Epoch [25/50] - Loss: 0.0428
Epoch [26/50] - Loss: 0.0426
Epoch [27/50] - Loss: 0.0421
Epoch [28/50] - Loss: 0.0412
Epoch [29/50] - Loss: 0.0401
Epoch [30/50] - Loss: 0.0387
Epoch [31/50] - Loss: 0.0372
Epoch [32/50] - Loss: 0.0357
Epoch [33/50] - Loss: 0.0341
Epoch [34/50] - Loss: 0.0326
Epoch [35/50] - Loss: 0.0311
Epoch [36/50] - Loss: 0.0305
Epoch [37/50] - Loss: 0.0309
Epoch [38/50] - Loss: 0.0304
Epoch [39/50] - Loss: 0.0291
Epoch [40/50] - Loss: 0.0280
Epoch [41/50] - Loss: 0.0279
Epoch [42/50] - Loss: 0.0277
Epoch [43/50] - Loss: 0.0274
Epoch [44/50] - Loss: 0.0270
Epoch [45/50] - Loss: 0.0266
Epoch [46/50] - Loss: 0.0260
Epoch [47/50] - Loss: 0.0255
Epoch [48/50] - Loss: 0.0255
Epoch [49/50] - Loss: 0.0253
Epoch [50/50] - Loss: 0.0243
sum preds 2056
sum labels 1607
 - Test Metrics: Accuracy=0.9190, F1=0.7649, Recall=0.8718, Precision=0.6814
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5279
Epoch [2/50] - Loss: 0.4600
Epoch [3/50] - Loss: 0.3991
Epoch [4/50] - Loss: 0.3450
Epoch [5/50] - Loss: 0.2970
Epoch [6/50] - Loss: 0.2558
Epoch [7/50] - Loss: 0.2211
Epoch [8/50] - Loss: 0.1920
Epoch [9/50] - Loss: 0.1676
Epoch [10/50] - Loss: 0.1470
Epoch [11/50] - Loss: 0.1295
Epoch [12/50] - Loss: 0.1145
Epoch [13/50] - Loss: 0.1016
Epoch [14/50] - Loss: 0.0906
Epoch [15/50] - Loss: 0.0811
Epoch [16/50] - Loss: 0.0729
Epoch [17/50] - Loss: 0.0658
Epoch [18/50] - Loss: 0.0597
Epoch [19/50] - Loss: 0.0544
Epoch [20/50] - Loss: 0.0498
Epoch [21/50] - Loss: 0.0458
Epoch [22/50] - Loss: 0.0444
Epoch [23/50] - Loss: 0.0443
Epoch [24/50] - Loss: 0.0438
Epoch [25/50] - Loss: 0.0431
Epoch [26/50] - Loss: 0.0421
Epoch [27/50] - Loss: 0.0410
Epoch [28/50] - Loss: 0.0397
Epoch [29/50] - Loss: 0.0383
Epoch [30/50] - Loss: 0.0368
Epoch [31/50] - Loss: 0.0354
Epoch [32/50] - Loss: 0.0339
Epoch [33/50] - Loss: 0.0324
Epoch [34/50] - Loss: 0.0309
Epoch [35/50] - Loss: 0.0300
Epoch [36/50] - Loss: 0.0299
Epoch [37/50] - Loss: 0.0289
Epoch [38/50] - Loss: 0.0273
Epoch [39/50] - Loss: 0.0263
Epoch [40/50] - Loss: 0.0258
Epoch [41/50] - Loss: 0.0254
Epoch [42/50] - Loss: 0.0250
Epoch [43/50] - Loss: 0.0247
Epoch [44/50] - Loss: 0.0244
Epoch [45/50] - Loss: 0.0240
Epoch [46/50] - Loss: 0.0237
Epoch [47/50] - Loss: 0.0233
Epoch [48/50] - Loss: 0.0228
Epoch [49/50] - Loss: 0.0223
Epoch [50/50] - Loss: 0.0219
sum preds 2113
sum labels 1607
 - Test Metrics: Accuracy=0.9170, F1=0.7629, Recall=0.8830, Precision=0.6716
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_nnpu_nnpu_1904075946.csv.
Average F1 over valid seeds: 0.7636 ± 0.0009
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and nnpu, MLP,0.4: 0.7636 ± 0.0009
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5366
Epoch [2/50] - Loss: 0.3887
Epoch [3/50] - Loss: 0.2565
Epoch [4/50] - Loss: 0.2284
Epoch [5/50] - Loss: 0.2196
Epoch [6/50] - Loss: 0.2111
Epoch [7/50] - Loss: 0.2003
Epoch [8/50] - Loss: 0.1888
Epoch [9/50] - Loss: 0.1785
Epoch [10/50] - Loss: 0.1718
Epoch [11/50] - Loss: 0.1671
Epoch [12/50] - Loss: 0.1633
Epoch [13/50] - Loss: 0.1591
Epoch [14/50] - Loss: 0.1537
Epoch [15/50] - Loss: 0.1475
Epoch [16/50] - Loss: 0.1401
Epoch [17/50] - Loss: 0.1366
Epoch [18/50] - Loss: 0.1330
Epoch [19/50] - Loss: 0.1293
Epoch [20/50] - Loss: 0.1257
Epoch [21/50] - Loss: 0.1225
Epoch [22/50] - Loss: 0.1228
Epoch [23/50] - Loss: 0.1220
Epoch [24/50] - Loss: 0.1196
Epoch [25/50] - Loss: 0.1177
Epoch [26/50] - Loss: 0.1165
Epoch [27/50] - Loss: 0.1159
Epoch [28/50] - Loss: 0.1151
Epoch [29/50] - Loss: 0.1146
Epoch [30/50] - Loss: 0.1140
Epoch [31/50] - Loss: 0.1143
Epoch [32/50] - Loss: 0.1143
Epoch [33/50] - Loss: 0.1142
Epoch [34/50] - Loss: 0.1137
Epoch [35/50] - Loss: 0.1131
Epoch [36/50] - Loss: 0.1123
Epoch [37/50] - Loss: 0.1116
Epoch [38/50] - Loss: 0.1110
Epoch [39/50] - Loss: 0.1103
Epoch [40/50] - Loss: 0.1097
Epoch [41/50] - Loss: 0.1101
Epoch [42/50] - Loss: 0.1104
Epoch [43/50] - Loss: 0.1089
Epoch [44/50] - Loss: 0.1086
Epoch [45/50] - Loss: 0.1086
Epoch [46/50] - Loss: 0.1088
Epoch [47/50] - Loss: 0.1087
Epoch [48/50] - Loss: 0.1085
Epoch [49/50] - Loss: 0.1080
Epoch [50/50] - Loss: 0.1076
sum preds 1208
sum labels 1607
 - Test Metrics: Accuracy=0.8868, F1=0.5726, Recall=0.5016, Precision=0.6672
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4348
Epoch [2/50] - Loss: 0.2954
Epoch [3/50] - Loss: 0.2176
Epoch [4/50] - Loss: 0.1724
Epoch [5/50] - Loss: 0.1363
Epoch [6/50] - Loss: 0.1069
Epoch [7/50] - Loss: 0.0974
Epoch [8/50] - Loss: 0.0880
Epoch [9/50] - Loss: 0.0761
Epoch [10/50] - Loss: 0.0723
Epoch [11/50] - Loss: 0.0717
Epoch [12/50] - Loss: 0.0636
Epoch [13/50] - Loss: 0.0581
Epoch [14/50] - Loss: 0.0561
Epoch [15/50] - Loss: 0.0522
Epoch [16/50] - Loss: 0.0467
Epoch [17/50] - Loss: 0.0456
Epoch [18/50] - Loss: 0.0402
Epoch [19/50] - Loss: 0.0419
Epoch [20/50] - Loss: 0.0423
Epoch [21/50] - Loss: 0.0376
Epoch [22/50] - Loss: 0.0349
Epoch [23/50] - Loss: 0.0359
Epoch [24/50] - Loss: 0.0346
Epoch [25/50] - Loss: 0.0320
Epoch [26/50] - Loss: 0.0308
Epoch [27/50] - Loss: 0.0307
Epoch [28/50] - Loss: 0.0281
Epoch [29/50] - Loss: 0.0298
Epoch [30/50] - Loss: 0.0306
Epoch [31/50] - Loss: 0.0301
Epoch [32/50] - Loss: 0.0284
Epoch [33/50] - Loss: 0.0261
Epoch [34/50] - Loss: 0.0275
Epoch [35/50] - Loss: 0.0282
Epoch [36/50] - Loss: 0.0259
Epoch [37/50] - Loss: 0.0246
Epoch [38/50] - Loss: 0.0254
Epoch [39/50] - Loss: 0.0254
Epoch [40/50] - Loss: 0.0245
Epoch [41/50] - Loss: 0.0230
Epoch [42/50] - Loss: 0.0212
Epoch [43/50] - Loss: 0.0245
Epoch [44/50] - Loss: 0.0243
Epoch [45/50] - Loss: 0.0203
Epoch [46/50] - Loss: 0.0216
Epoch [47/50] - Loss: 0.0229
Epoch [48/50] - Loss: 0.0236
Epoch [49/50] - Loss: 0.0235
Epoch [50/50] - Loss: 0.0226
sum preds 2076
sum labels 1607
 - Test Metrics: Accuracy=0.9226, F1=0.7765, Recall=0.8899, Precision=0.6888
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4371
Epoch [2/50] - Loss: 0.2951
Epoch [3/50] - Loss: 0.2013
Epoch [4/50] - Loss: 0.1482
Epoch [5/50] - Loss: 0.1087
Epoch [6/50] - Loss: 0.0855
Epoch [7/50] - Loss: 0.0878
Epoch [8/50] - Loss: 0.0688
Epoch [9/50] - Loss: 0.0623
Epoch [10/50] - Loss: 0.0605
Epoch [11/50] - Loss: 0.0544
Epoch [12/50] - Loss: 0.0468
Epoch [13/50] - Loss: 0.0453
Epoch [14/50] - Loss: 0.0431
Epoch [15/50] - Loss: 0.0391
Epoch [16/50] - Loss: 0.0389
Epoch [17/50] - Loss: 0.0383
Epoch [18/50] - Loss: 0.0351
Epoch [19/50] - Loss: 0.0361
Epoch [20/50] - Loss: 0.0366
Epoch [21/50] - Loss: 0.0340
Epoch [22/50] - Loss: 0.0321
Epoch [23/50] - Loss: 0.0325
Epoch [24/50] - Loss: 0.0315
Epoch [25/50] - Loss: 0.0294
Epoch [26/50] - Loss: 0.0287
Epoch [27/50] - Loss: 0.0280
Epoch [28/50] - Loss: 0.0265
Epoch [29/50] - Loss: 0.0264
Epoch [30/50] - Loss: 0.0256
Epoch [31/50] - Loss: 0.0243
Epoch [32/50] - Loss: 0.0249
Epoch [33/50] - Loss: 0.0229
Epoch [34/50] - Loss: 0.0238
Epoch [35/50] - Loss: 0.0245
Epoch [36/50] - Loss: 0.0244
Epoch [37/50] - Loss: 0.0236
Epoch [38/50] - Loss: 0.0224
Epoch [39/50] - Loss: 0.0209
Epoch [40/50] - Loss: 0.0223
Epoch [41/50] - Loss: 0.0211
Epoch [42/50] - Loss: 0.0205
Epoch [43/50] - Loss: 0.0213
Epoch [44/50] - Loss: 0.0217
Epoch [45/50] - Loss: 0.0215
Epoch [46/50] - Loss: 0.0208
Epoch [47/50] - Loss: 0.0197
Epoch [48/50] - Loss: 0.0184
Epoch [49/50] - Loss: 0.0195
Epoch [50/50] - Loss: 0.0175
sum preds 2131
sum labels 1607
 - Test Metrics: Accuracy=0.9215, F1=0.7769, Recall=0.9035, Precision=0.6814
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_nnpu_nnpu_1904075948.csv.
Average F1 over valid seeds: 0.7087 ± 0.0962
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and nnpu, GATConv,0.4: 0.7087 ± 0.0962
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4845
Epoch [2/50] - Loss: 0.4064
Epoch [3/50] - Loss: 0.3383
Epoch [4/50] - Loss: 0.2840
Epoch [5/50] - Loss: 0.2410
Epoch [6/50] - Loss: 0.2065
Epoch [7/50] - Loss: 0.1785
Epoch [8/50] - Loss: 0.1552
Epoch [9/50] - Loss: 0.1357
Epoch [10/50] - Loss: 0.1192
Epoch [11/50] - Loss: 0.1052
Epoch [12/50] - Loss: 0.0932
Epoch [13/50] - Loss: 0.0829
Epoch [14/50] - Loss: 0.0739
Epoch [15/50] - Loss: 0.0662
Epoch [16/50] - Loss: 0.0595
Epoch [17/50] - Loss: 0.0537
Epoch [18/50] - Loss: 0.0485
Epoch [19/50] - Loss: 0.0456
Epoch [20/50] - Loss: 0.0447
Epoch [21/50] - Loss: 0.0435
Epoch [22/50] - Loss: 0.0421
Epoch [23/50] - Loss: 0.0406
Epoch [24/50] - Loss: 0.0390
Epoch [25/50] - Loss: 0.0374
Epoch [26/50] - Loss: 0.0358
Epoch [27/50] - Loss: 0.0342
Epoch [28/50] - Loss: 0.0327
Epoch [29/50] - Loss: 0.0313
Epoch [30/50] - Loss: 0.0299
Epoch [31/50] - Loss: 0.0287
Epoch [32/50] - Loss: 0.0288
Epoch [33/50] - Loss: 0.0277
Epoch [34/50] - Loss: 0.0268
Epoch [35/50] - Loss: 0.0265
Epoch [36/50] - Loss: 0.0261
Epoch [37/50] - Loss: 0.0256
Epoch [38/50] - Loss: 0.0251
Epoch [39/50] - Loss: 0.0246
Epoch [40/50] - Loss: 0.0240
Epoch [41/50] - Loss: 0.0234
Epoch [42/50] - Loss: 0.0238
Epoch [43/50] - Loss: 0.0235
Epoch [44/50] - Loss: 0.0226
Epoch [45/50] - Loss: 0.0224
Epoch [46/50] - Loss: 0.0223
Epoch [47/50] - Loss: 0.0222
Epoch [48/50] - Loss: 0.0220
Epoch [49/50] - Loss: 0.0217
Epoch [50/50] - Loss: 0.0213
sum preds 1997
sum labels 1607
 - Test Metrics: Accuracy=0.9383, F1=0.8180, Recall=0.9172, Precision=0.7381
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4731
Epoch [2/50] - Loss: 0.3954
Epoch [3/50] - Loss: 0.3336
Epoch [4/50] - Loss: 0.2868
Epoch [5/50] - Loss: 0.2501
Epoch [6/50] - Loss: 0.2197
Epoch [7/50] - Loss: 0.1936
Epoch [8/50] - Loss: 0.1707
Epoch [9/50] - Loss: 0.1506
Epoch [10/50] - Loss: 0.1328
Epoch [11/50] - Loss: 0.1174
Epoch [12/50] - Loss: 0.1040
Epoch [13/50] - Loss: 0.0925
Epoch [14/50] - Loss: 0.0827
Epoch [15/50] - Loss: 0.0742
Epoch [16/50] - Loss: 0.0668
Epoch [17/50] - Loss: 0.0603
Epoch [18/50] - Loss: 0.0546
Epoch [19/50] - Loss: 0.0496
Epoch [20/50] - Loss: 0.0451
Epoch [21/50] - Loss: 0.0410
Epoch [22/50] - Loss: 0.0373
Epoch [23/50] - Loss: 0.0362
Epoch [24/50] - Loss: 0.0360
Epoch [25/50] - Loss: 0.0355
Epoch [26/50] - Loss: 0.0349
Epoch [27/50] - Loss: 0.0342
Epoch [28/50] - Loss: 0.0334
Epoch [29/50] - Loss: 0.0325
Epoch [30/50] - Loss: 0.0316
Epoch [31/50] - Loss: 0.0306
Epoch [32/50] - Loss: 0.0296
Epoch [33/50] - Loss: 0.0287
Epoch [34/50] - Loss: 0.0277
Epoch [35/50] - Loss: 0.0267
Epoch [36/50] - Loss: 0.0258
Epoch [37/50] - Loss: 0.0249
Epoch [38/50] - Loss: 0.0241
Epoch [39/50] - Loss: 0.0243
Epoch [40/50] - Loss: 0.0246
Epoch [41/50] - Loss: 0.0236
Epoch [42/50] - Loss: 0.0227
Epoch [43/50] - Loss: 0.0227
Epoch [44/50] - Loss: 0.0226
Epoch [45/50] - Loss: 0.0225
Epoch [46/50] - Loss: 0.0223
Epoch [47/50] - Loss: 0.0221
Epoch [48/50] - Loss: 0.0218
Epoch [49/50] - Loss: 0.0215
Epoch [50/50] - Loss: 0.0212
sum preds 1989
sum labels 1607
 - Test Metrics: Accuracy=0.9358, F1=0.8103, Recall=0.9067, Precision=0.7325
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4184
Epoch [2/50] - Loss: 0.3442
Epoch [3/50] - Loss: 0.2864
Epoch [4/50] - Loss: 0.2411
Epoch [5/50] - Loss: 0.2053
Epoch [6/50] - Loss: 0.1762
Epoch [7/50] - Loss: 0.1523
Epoch [8/50] - Loss: 0.1324
Epoch [9/50] - Loss: 0.1157
Epoch [10/50] - Loss: 0.1014
Epoch [11/50] - Loss: 0.0893
Epoch [12/50] - Loss: 0.0789
Epoch [13/50] - Loss: 0.0700
Epoch [14/50] - Loss: 0.0624
Epoch [15/50] - Loss: 0.0557
Epoch [16/50] - Loss: 0.0499
Epoch [17/50] - Loss: 0.0448
Epoch [18/50] - Loss: 0.0428
Epoch [19/50] - Loss: 0.0420
Epoch [20/50] - Loss: 0.0411
Epoch [21/50] - Loss: 0.0400
Epoch [22/50] - Loss: 0.0388
Epoch [23/50] - Loss: 0.0376
Epoch [24/50] - Loss: 0.0364
Epoch [25/50] - Loss: 0.0351
Epoch [26/50] - Loss: 0.0338
Epoch [27/50] - Loss: 0.0326
Epoch [28/50] - Loss: 0.0314
Epoch [29/50] - Loss: 0.0303
Epoch [30/50] - Loss: 0.0291
Epoch [31/50] - Loss: 0.0281
Epoch [32/50] - Loss: 0.0270
Epoch [33/50] - Loss: 0.0260
Epoch [34/50] - Loss: 0.0251
Epoch [35/50] - Loss: 0.0241
Epoch [36/50] - Loss: 0.0254
Epoch [37/50] - Loss: 0.0256
Epoch [38/50] - Loss: 0.0248
Epoch [39/50] - Loss: 0.0231
Epoch [40/50] - Loss: 0.0220
Epoch [41/50] - Loss: 0.0219
Epoch [42/50] - Loss: 0.0217
Epoch [43/50] - Loss: 0.0215
Epoch [44/50] - Loss: 0.0212
Epoch [45/50] - Loss: 0.0209
Epoch [46/50] - Loss: 0.0205
Epoch [47/50] - Loss: 0.0201
Epoch [48/50] - Loss: 0.0196
Epoch [49/50] - Loss: 0.0192
Epoch [50/50] - Loss: 0.0187
sum preds 2035
sum labels 1607
 - Test Metrics: Accuracy=0.9358, F1=0.8127, Recall=0.9210, Precision=0.7273
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_nnpu_nnpu_1904075951.csv.
Average F1 over valid seeds: 0.8137 ± 0.0032
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and nnpu, GCNConv,0.4: 0.8137 ± 0.0032
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4932
Epoch [2/50] - Loss: 0.4224
Epoch [3/50] - Loss: 0.3634
Epoch [4/50] - Loss: 0.3146
Epoch [5/50] - Loss: 0.2737
Epoch [6/50] - Loss: 0.2393
Epoch [7/50] - Loss: 0.2101
Epoch [8/50] - Loss: 0.1852
Epoch [9/50] - Loss: 0.1638
Epoch [10/50] - Loss: 0.1454
Epoch [11/50] - Loss: 0.1295
Epoch [12/50] - Loss: 0.1158
Epoch [13/50] - Loss: 0.1040
Epoch [14/50] - Loss: 0.0936
Epoch [15/50] - Loss: 0.0847
Epoch [16/50] - Loss: 0.0770
Epoch [17/50] - Loss: 0.0704
Epoch [18/50] - Loss: 0.0646
Epoch [19/50] - Loss: 0.0597
Epoch [20/50] - Loss: 0.0553
Epoch [21/50] - Loss: 0.0515
Epoch [22/50] - Loss: 0.0480
Epoch [23/50] - Loss: 0.0449
Epoch [24/50] - Loss: 0.0419
Epoch [25/50] - Loss: 0.0410
Epoch [26/50] - Loss: 0.0400
Epoch [27/50] - Loss: 0.0387
Epoch [28/50] - Loss: 0.0371
Epoch [29/50] - Loss: 0.0353
Epoch [30/50] - Loss: 0.0334
Epoch [31/50] - Loss: 0.0315
Epoch [32/50] - Loss: 0.0296
Epoch [33/50] - Loss: 0.0281
Epoch [34/50] - Loss: 0.0280
Epoch [35/50] - Loss: 0.0276
Epoch [36/50] - Loss: 0.0268
Epoch [37/50] - Loss: 0.0256
Epoch [38/50] - Loss: 0.0242
Epoch [39/50] - Loss: 0.0239
Epoch [40/50] - Loss: 0.0235
Epoch [41/50] - Loss: 0.0230
Epoch [42/50] - Loss: 0.0225
Epoch [43/50] - Loss: 0.0221
Epoch [44/50] - Loss: 0.0217
Epoch [45/50] - Loss: 0.0213
Epoch [46/50] - Loss: 0.0211
Epoch [47/50] - Loss: 0.0207
Epoch [48/50] - Loss: 0.0204
Epoch [49/50] - Loss: 0.0199
Epoch [50/50] - Loss: 0.0197
sum preds 2194
sum labels 1875
 - Test Metrics: Accuracy=0.9221, F1=0.7913, Recall=0.8587, Precision=0.7338
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5492
Epoch [2/50] - Loss: 0.4934
Epoch [3/50] - Loss: 0.4451
Epoch [4/50] - Loss: 0.4029
Epoch [5/50] - Loss: 0.3642
Epoch [6/50] - Loss: 0.3280
Epoch [7/50] - Loss: 0.2942
Epoch [8/50] - Loss: 0.2630
Epoch [9/50] - Loss: 0.2344
Epoch [10/50] - Loss: 0.2089
Epoch [11/50] - Loss: 0.1863
Epoch [12/50] - Loss: 0.1664
Epoch [13/50] - Loss: 0.1491
Epoch [14/50] - Loss: 0.1340
Epoch [15/50] - Loss: 0.1208
Epoch [16/50] - Loss: 0.1094
Epoch [17/50] - Loss: 0.0996
Epoch [18/50] - Loss: 0.0909
Epoch [19/50] - Loss: 0.0835
Epoch [20/50] - Loss: 0.0770
Epoch [21/50] - Loss: 0.0714
Epoch [22/50] - Loss: 0.0665
Epoch [23/50] - Loss: 0.0623
Epoch [24/50] - Loss: 0.0585
Epoch [25/50] - Loss: 0.0551
Epoch [26/50] - Loss: 0.0521
Epoch [27/50] - Loss: 0.0494
Epoch [28/50] - Loss: 0.0469
Epoch [29/50] - Loss: 0.0445
Epoch [30/50] - Loss: 0.0424
Epoch [31/50] - Loss: 0.0418
Epoch [32/50] - Loss: 0.0409
Epoch [33/50] - Loss: 0.0397
Epoch [34/50] - Loss: 0.0383
Epoch [35/50] - Loss: 0.0368
Epoch [36/50] - Loss: 0.0352
Epoch [37/50] - Loss: 0.0344
Epoch [38/50] - Loss: 0.0343
Epoch [39/50] - Loss: 0.0339
Epoch [40/50] - Loss: 0.0330
Epoch [41/50] - Loss: 0.0318
Epoch [42/50] - Loss: 0.0306
Epoch [43/50] - Loss: 0.0304
Epoch [44/50] - Loss: 0.0300
Epoch [45/50] - Loss: 0.0295
Epoch [46/50] - Loss: 0.0290
Epoch [47/50] - Loss: 0.0283
Epoch [48/50] - Loss: 0.0283
Epoch [49/50] - Loss: 0.0281
Epoch [50/50] - Loss: 0.0273
sum preds 2113
sum labels 1875
 - Test Metrics: Accuracy=0.9255, F1=0.7964, Recall=0.8469, Precision=0.7515
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5273
Epoch [2/50] - Loss: 0.4615
Epoch [3/50] - Loss: 0.4028
Epoch [4/50] - Loss: 0.3505
Epoch [5/50] - Loss: 0.3040
Epoch [6/50] - Loss: 0.2637
Epoch [7/50] - Loss: 0.2296
Epoch [8/50] - Loss: 0.2008
Epoch [9/50] - Loss: 0.1766
Epoch [10/50] - Loss: 0.1562
Epoch [11/50] - Loss: 0.1388
Epoch [12/50] - Loss: 0.1239
Epoch [13/50] - Loss: 0.1110
Epoch [14/50] - Loss: 0.1000
Epoch [15/50] - Loss: 0.0905
Epoch [16/50] - Loss: 0.0824
Epoch [17/50] - Loss: 0.0753
Epoch [18/50] - Loss: 0.0692
Epoch [19/50] - Loss: 0.0639
Epoch [20/50] - Loss: 0.0593
Epoch [21/50] - Loss: 0.0552
Epoch [22/50] - Loss: 0.0516
Epoch [23/50] - Loss: 0.0484
Epoch [24/50] - Loss: 0.0455
Epoch [25/50] - Loss: 0.0451
Epoch [26/50] - Loss: 0.0445
Epoch [27/50] - Loss: 0.0437
Epoch [28/50] - Loss: 0.0426
Epoch [29/50] - Loss: 0.0414
Epoch [30/50] - Loss: 0.0400
Epoch [31/50] - Loss: 0.0386
Epoch [32/50] - Loss: 0.0371
Epoch [33/50] - Loss: 0.0357
Epoch [34/50] - Loss: 0.0344
Epoch [35/50] - Loss: 0.0331
Epoch [36/50] - Loss: 0.0336
Epoch [37/50] - Loss: 0.0340
Epoch [38/50] - Loss: 0.0337
Epoch [39/50] - Loss: 0.0329
Epoch [40/50] - Loss: 0.0316
Epoch [41/50] - Loss: 0.0301
Epoch [42/50] - Loss: 0.0296
Epoch [43/50] - Loss: 0.0295
Epoch [44/50] - Loss: 0.0292
Epoch [45/50] - Loss: 0.0288
Epoch [46/50] - Loss: 0.0282
Epoch [47/50] - Loss: 0.0274
Epoch [48/50] - Loss: 0.0266
Epoch [49/50] - Loss: 0.0257
Epoch [50/50] - Loss: 0.0254
sum preds 2181
sum labels 1875
 - Test Metrics: Accuracy=0.9244, F1=0.7968, Recall=0.8619, Precision=0.7409
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_nnpu_nnpu_1904075953.csv.
Average F1 over valid seeds: 0.7949 ± 0.0025
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and nnpu, MLP,0.3: 0.7949 ± 0.0025
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5395
Epoch [2/50] - Loss: 0.3901
Epoch [3/50] - Loss: 0.2557
Epoch [4/50] - Loss: 0.2273
Epoch [5/50] - Loss: 0.2187
Epoch [6/50] - Loss: 0.2105
Epoch [7/50] - Loss: 0.2011
Epoch [8/50] - Loss: 0.1918
Epoch [9/50] - Loss: 0.1836
Epoch [10/50] - Loss: 0.1766
Epoch [11/50] - Loss: 0.1716
Epoch [12/50] - Loss: 0.1672
Epoch [13/50] - Loss: 0.1623
Epoch [14/50] - Loss: 0.1567
Epoch [15/50] - Loss: 0.1517
Epoch [16/50] - Loss: 0.1466
Epoch [17/50] - Loss: 0.1400
Epoch [18/50] - Loss: 0.1356
Epoch [19/50] - Loss: 0.1321
Epoch [20/50] - Loss: 0.1286
Epoch [21/50] - Loss: 0.1244
Epoch [22/50] - Loss: 0.1211
Epoch [23/50] - Loss: 0.1189
Epoch [24/50] - Loss: 0.1166
Epoch [25/50] - Loss: 0.1143
Epoch [26/50] - Loss: 0.1142
Epoch [27/50] - Loss: 0.1130
Epoch [28/50] - Loss: 0.1108
Epoch [29/50] - Loss: 0.1080
Epoch [30/50] - Loss: 0.1091
Epoch [31/50] - Loss: 0.1083
Epoch [32/50] - Loss: 0.1066
Epoch [33/50] - Loss: 0.1055
Epoch [34/50] - Loss: 0.1022
Epoch [35/50] - Loss: 0.1030
Epoch [36/50] - Loss: 0.1017
Epoch [37/50] - Loss: 0.1002
Epoch [38/50] - Loss: 0.0995
Epoch [39/50] - Loss: 0.0989
Epoch [40/50] - Loss: 0.0986
Epoch [41/50] - Loss: 0.0989
Epoch [42/50] - Loss: 0.0981
Epoch [43/50] - Loss: 0.0981
Epoch [44/50] - Loss: 0.0979
Epoch [45/50] - Loss: 0.0976
Epoch [46/50] - Loss: 0.0972
Epoch [47/50] - Loss: 0.0967
Epoch [48/50] - Loss: 0.0960
Epoch [49/50] - Loss: 0.0954
Epoch [50/50] - Loss: 0.0950
sum preds 1411
sum labels 1875
 - Test Metrics: Accuracy=0.8803, F1=0.6032, Recall=0.5285, Precision=0.7023
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4362
Epoch [2/50] - Loss: 0.3011
Epoch [3/50] - Loss: 0.2262
Epoch [4/50] - Loss: 0.1837
Epoch [5/50] - Loss: 0.1493
Epoch [6/50] - Loss: 0.1189
Epoch [7/50] - Loss: 0.1091
Epoch [8/50] - Loss: 0.1021
Epoch [9/50] - Loss: 0.0886
Epoch [10/50] - Loss: 0.0839
Epoch [11/50] - Loss: 0.0834
Epoch [12/50] - Loss: 0.0790
Epoch [13/50] - Loss: 0.0723
Epoch [14/50] - Loss: 0.0660
Epoch [15/50] - Loss: 0.0647
Epoch [16/50] - Loss: 0.0626
Epoch [17/50] - Loss: 0.0570
Epoch [18/50] - Loss: 0.0542
Epoch [19/50] - Loss: 0.0538
Epoch [20/50] - Loss: 0.0495
Epoch [21/50] - Loss: 0.0491
Epoch [22/50] - Loss: 0.0484
Epoch [23/50] - Loss: 0.0466
Epoch [24/50] - Loss: 0.0440
Epoch [25/50] - Loss: 0.0470
Epoch [26/50] - Loss: 0.0461
Epoch [27/50] - Loss: 0.0420
Epoch [28/50] - Loss: 0.0433
Epoch [29/50] - Loss: 0.0445
Epoch [30/50] - Loss: 0.0442
Epoch [31/50] - Loss: 0.0423
Epoch [32/50] - Loss: 0.0393
Epoch [33/50] - Loss: 0.0378
Epoch [34/50] - Loss: 0.0388
Epoch [35/50] - Loss: 0.0381
Epoch [36/50] - Loss: 0.0360
Epoch [37/50] - Loss: 0.0342
Epoch [38/50] - Loss: 0.0345
Epoch [39/50] - Loss: 0.0334
Epoch [40/50] - Loss: 0.0320
Epoch [41/50] - Loss: 0.0316
Epoch [42/50] - Loss: 0.0306
Epoch [43/50] - Loss: 0.0299
Epoch [44/50] - Loss: 0.0299
Epoch [45/50] - Loss: 0.0288
Epoch [46/50] - Loss: 0.0296
Epoch [47/50] - Loss: 0.0294
Epoch [48/50] - Loss: 0.0282
Epoch [49/50] - Loss: 0.0270
Epoch [50/50] - Loss: 0.0268
sum preds 2185
sum labels 1875
 - Test Metrics: Accuracy=0.9301, F1=0.8123, Recall=0.8795, Precision=0.7547
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4366
Epoch [2/50] - Loss: 0.2974
Epoch [3/50] - Loss: 0.2066
Epoch [4/50] - Loss: 0.1561
Epoch [5/50] - Loss: 0.1193
Epoch [6/50] - Loss: 0.0947
Epoch [7/50] - Loss: 0.1011
Epoch [8/50] - Loss: 0.0794
Epoch [9/50] - Loss: 0.0735
Epoch [10/50] - Loss: 0.0686
Epoch [11/50] - Loss: 0.0619
Epoch [12/50] - Loss: 0.0568
Epoch [13/50] - Loss: 0.0530
Epoch [14/50] - Loss: 0.0510
Epoch [15/50] - Loss: 0.0492
Epoch [16/50] - Loss: 0.0467
Epoch [17/50] - Loss: 0.0440
Epoch [18/50] - Loss: 0.0436
Epoch [19/50] - Loss: 0.0406
Epoch [20/50] - Loss: 0.0393
Epoch [21/50] - Loss: 0.0375
Epoch [22/50] - Loss: 0.0377
Epoch [23/50] - Loss: 0.0364
Epoch [24/50] - Loss: 0.0347
Epoch [25/50] - Loss: 0.0337
Epoch [26/50] - Loss: 0.0325
Epoch [27/50] - Loss: 0.0309
Epoch [28/50] - Loss: 0.0323
Epoch [29/50] - Loss: 0.0322
Epoch [30/50] - Loss: 0.0306
Epoch [31/50] - Loss: 0.0282
Epoch [32/50] - Loss: 0.0278
Epoch [33/50] - Loss: 0.0276
Epoch [34/50] - Loss: 0.0274
Epoch [35/50] - Loss: 0.0272
Epoch [36/50] - Loss: 0.0260
Epoch [37/50] - Loss: 0.0252
Epoch [38/50] - Loss: 0.0238
Epoch [39/50] - Loss: 0.0239
Epoch [40/50] - Loss: 0.0235
Epoch [41/50] - Loss: 0.0233
Epoch [42/50] - Loss: 0.0222
Epoch [43/50] - Loss: 0.0231
Epoch [44/50] - Loss: 0.0211
Epoch [45/50] - Loss: 0.0209
Epoch [46/50] - Loss: 0.0216
Epoch [47/50] - Loss: 0.0211
Epoch [48/50] - Loss: 0.0214
Epoch [49/50] - Loss: 0.0209
Epoch [50/50] - Loss: 0.0199
sum preds 2288
sum labels 1875
 - Test Metrics: Accuracy=0.9243, F1=0.8018, Recall=0.8901, Precision=0.7295
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_nnpu_nnpu_1904075954.csv.
Average F1 over valid seeds: 0.7391 ± 0.0962
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and nnpu, GATConv,0.3: 0.7391 ± 0.0962
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4835
Epoch [2/50] - Loss: 0.4072
Epoch [3/50] - Loss: 0.3409
Epoch [4/50] - Loss: 0.2883
Epoch [5/50] - Loss: 0.2468
Epoch [6/50] - Loss: 0.2136
Epoch [7/50] - Loss: 0.1867
Epoch [8/50] - Loss: 0.1644
Epoch [9/50] - Loss: 0.1457
Epoch [10/50] - Loss: 0.1299
Epoch [11/50] - Loss: 0.1164
Epoch [12/50] - Loss: 0.1049
Epoch [13/50] - Loss: 0.0949
Epoch [14/50] - Loss: 0.0863
Epoch [15/50] - Loss: 0.0789
Epoch [16/50] - Loss: 0.0724
Epoch [17/50] - Loss: 0.0668
Epoch [18/50] - Loss: 0.0620
Epoch [19/50] - Loss: 0.0577
Epoch [20/50] - Loss: 0.0538
Epoch [21/50] - Loss: 0.0505
Epoch [22/50] - Loss: 0.0474
Epoch [23/50] - Loss: 0.0447
Epoch [24/50] - Loss: 0.0440
Epoch [25/50] - Loss: 0.0432
Epoch [26/50] - Loss: 0.0422
Epoch [27/50] - Loss: 0.0410
Epoch [28/50] - Loss: 0.0396
Epoch [29/50] - Loss: 0.0382
Epoch [30/50] - Loss: 0.0367
Epoch [31/50] - Loss: 0.0351
Epoch [32/50] - Loss: 0.0335
Epoch [33/50] - Loss: 0.0320
Epoch [34/50] - Loss: 0.0316
Epoch [35/50] - Loss: 0.0317
Epoch [36/50] - Loss: 0.0315
Epoch [37/50] - Loss: 0.0310
Epoch [38/50] - Loss: 0.0302
Epoch [39/50] - Loss: 0.0291
Epoch [40/50] - Loss: 0.0278
Epoch [41/50] - Loss: 0.0275
Epoch [42/50] - Loss: 0.0274
Epoch [43/50] - Loss: 0.0273
Epoch [44/50] - Loss: 0.0270
Epoch [45/50] - Loss: 0.0267
Epoch [46/50] - Loss: 0.0262
Epoch [47/50] - Loss: 0.0256
Epoch [48/50] - Loss: 0.0250
Epoch [49/50] - Loss: 0.0243
Epoch [50/50] - Loss: 0.0239
sum preds 2095
sum labels 1875
 - Test Metrics: Accuracy=0.9437, F1=0.8453, Recall=0.8949, Precision=0.8010
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4747
Epoch [2/50] - Loss: 0.4000
Epoch [3/50] - Loss: 0.3400
Epoch [4/50] - Loss: 0.2943
Epoch [5/50] - Loss: 0.2585
Epoch [6/50] - Loss: 0.2288
Epoch [7/50] - Loss: 0.2032
Epoch [8/50] - Loss: 0.1809
Epoch [9/50] - Loss: 0.1612
Epoch [10/50] - Loss: 0.1440
Epoch [11/50] - Loss: 0.1291
Epoch [12/50] - Loss: 0.1163
Epoch [13/50] - Loss: 0.1053
Epoch [14/50] - Loss: 0.0958
Epoch [15/50] - Loss: 0.0876
Epoch [16/50] - Loss: 0.0804
Epoch [17/50] - Loss: 0.0740
Epoch [18/50] - Loss: 0.0685
Epoch [19/50] - Loss: 0.0636
Epoch [20/50] - Loss: 0.0591
Epoch [21/50] - Loss: 0.0551
Epoch [22/50] - Loss: 0.0515
Epoch [23/50] - Loss: 0.0482
Epoch [24/50] - Loss: 0.0452
Epoch [25/50] - Loss: 0.0425
Epoch [26/50] - Loss: 0.0399
Epoch [27/50] - Loss: 0.0377
Epoch [28/50] - Loss: 0.0358
Epoch [29/50] - Loss: 0.0355
Epoch [30/50] - Loss: 0.0350
Epoch [31/50] - Loss: 0.0344
Epoch [32/50] - Loss: 0.0337
Epoch [33/50] - Loss: 0.0329
Epoch [34/50] - Loss: 0.0321
Epoch [35/50] - Loss: 0.0312
Epoch [36/50] - Loss: 0.0302
Epoch [37/50] - Loss: 0.0293
Epoch [38/50] - Loss: 0.0283
Epoch [39/50] - Loss: 0.0273
Epoch [40/50] - Loss: 0.0275
Epoch [41/50] - Loss: 0.0277
Epoch [42/50] - Loss: 0.0277
Epoch [43/50] - Loss: 0.0273
Epoch [44/50] - Loss: 0.0266
Epoch [45/50] - Loss: 0.0256
Epoch [46/50] - Loss: 0.0250
Epoch [47/50] - Loss: 0.0250
Epoch [48/50] - Loss: 0.0250
Epoch [49/50] - Loss: 0.0248
Epoch [50/50] - Loss: 0.0246
sum preds 2081
sum labels 1875
 - Test Metrics: Accuracy=0.9413, F1=0.8382, Recall=0.8843, Precision=0.7967
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4200
Epoch [2/50] - Loss: 0.3480
Epoch [3/50] - Loss: 0.2917
Epoch [4/50] - Loss: 0.2477
Epoch [5/50] - Loss: 0.2128
Epoch [6/50] - Loss: 0.1844
Epoch [7/50] - Loss: 0.1611
Epoch [8/50] - Loss: 0.1417
Epoch [9/50] - Loss: 0.1254
Epoch [10/50] - Loss: 0.1116
Epoch [11/50] - Loss: 0.1000
Epoch [12/50] - Loss: 0.0900
Epoch [13/50] - Loss: 0.0815
Epoch [14/50] - Loss: 0.0742
Epoch [15/50] - Loss: 0.0678
Epoch [16/50] - Loss: 0.0622
Epoch [17/50] - Loss: 0.0572
Epoch [18/50] - Loss: 0.0528
Epoch [19/50] - Loss: 0.0488
Epoch [20/50] - Loss: 0.0452
Epoch [21/50] - Loss: 0.0420
Epoch [22/50] - Loss: 0.0404
Epoch [23/50] - Loss: 0.0396
Epoch [24/50] - Loss: 0.0386
Epoch [25/50] - Loss: 0.0375
Epoch [26/50] - Loss: 0.0363
Epoch [27/50] - Loss: 0.0351
Epoch [28/50] - Loss: 0.0339
Epoch [29/50] - Loss: 0.0326
Epoch [30/50] - Loss: 0.0314
Epoch [31/50] - Loss: 0.0302
Epoch [32/50] - Loss: 0.0291
Epoch [33/50] - Loss: 0.0279
Epoch [34/50] - Loss: 0.0268
Epoch [35/50] - Loss: 0.0269
Epoch [36/50] - Loss: 0.0270
Epoch [37/50] - Loss: 0.0267
Epoch [38/50] - Loss: 0.0259
Epoch [39/50] - Loss: 0.0248
Epoch [40/50] - Loss: 0.0237
Epoch [41/50] - Loss: 0.0235
Epoch [42/50] - Loss: 0.0232
Epoch [43/50] - Loss: 0.0229
Epoch [44/50] - Loss: 0.0225
Epoch [45/50] - Loss: 0.0220
Epoch [46/50] - Loss: 0.0216
Epoch [47/50] - Loss: 0.0210
Epoch [48/50] - Loss: 0.0213
Epoch [49/50] - Loss: 0.0213
Epoch [50/50] - Loss: 0.0209
sum preds 2140
sum labels 1875
 - Test Metrics: Accuracy=0.9414, F1=0.8408, Recall=0.9003, Precision=0.7888
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_nnpu_nnpu_1904075957.csv.
Average F1 over valid seeds: 0.8415 ± 0.0029
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and nnpu, GCNConv,0.3: 0.8415 ± 0.0029
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4943
Epoch [2/50] - Loss: 0.4267
Epoch [3/50] - Loss: 0.3700
Epoch [4/50] - Loss: 0.3222
Epoch [5/50] - Loss: 0.2819
Epoch [6/50] - Loss: 0.2478
Epoch [7/50] - Loss: 0.2189
Epoch [8/50] - Loss: 0.1943
Epoch [9/50] - Loss: 0.1734
Epoch [10/50] - Loss: 0.1554
Epoch [11/50] - Loss: 0.1399
Epoch [12/50] - Loss: 0.1265
Epoch [13/50] - Loss: 0.1149
Epoch [14/50] - Loss: 0.1048
Epoch [15/50] - Loss: 0.0961
Epoch [16/50] - Loss: 0.0884
Epoch [17/50] - Loss: 0.0818
Epoch [18/50] - Loss: 0.0760
Epoch [19/50] - Loss: 0.0708
Epoch [20/50] - Loss: 0.0662
Epoch [21/50] - Loss: 0.0621
Epoch [22/50] - Loss: 0.0584
Epoch [23/50] - Loss: 0.0551
Epoch [24/50] - Loss: 0.0519
Epoch [25/50] - Loss: 0.0490
Epoch [26/50] - Loss: 0.0463
Epoch [27/50] - Loss: 0.0437
Epoch [28/50] - Loss: 0.0413
Epoch [29/50] - Loss: 0.0391
Epoch [30/50] - Loss: 0.0374
Epoch [31/50] - Loss: 0.0363
Epoch [32/50] - Loss: 0.0350
Epoch [33/50] - Loss: 0.0335
Epoch [34/50] - Loss: 0.0319
Epoch [35/50] - Loss: 0.0308
Epoch [36/50] - Loss: 0.0303
Epoch [37/50] - Loss: 0.0296
Epoch [38/50] - Loss: 0.0287
Epoch [39/50] - Loss: 0.0275
Epoch [40/50] - Loss: 0.0273
Epoch [41/50] - Loss: 0.0269
Epoch [42/50] - Loss: 0.0264
Epoch [43/50] - Loss: 0.0258
Epoch [44/50] - Loss: 0.0250
Epoch [45/50] - Loss: 0.0241
Epoch [46/50] - Loss: 0.0239
Epoch [47/50] - Loss: 0.0237
Epoch [48/50] - Loss: 0.0231
Epoch [49/50] - Loss: 0.0221
Epoch [50/50] - Loss: 0.0220
sum preds 2220
sum labels 2143
 - Test Metrics: Accuracy=0.9249, F1=0.8077, Recall=0.8222, Precision=0.7937
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5489
Epoch [2/50] - Loss: 0.4948
Epoch [3/50] - Loss: 0.4483
Epoch [4/50] - Loss: 0.4078
Epoch [5/50] - Loss: 0.3705
Epoch [6/50] - Loss: 0.3354
Epoch [7/50] - Loss: 0.3026
Epoch [8/50] - Loss: 0.2722
Epoch [9/50] - Loss: 0.2445
Epoch [10/50] - Loss: 0.2196
Epoch [11/50] - Loss: 0.1975
Epoch [12/50] - Loss: 0.1782
Epoch [13/50] - Loss: 0.1612
Epoch [14/50] - Loss: 0.1466
Epoch [15/50] - Loss: 0.1339
Epoch [16/50] - Loss: 0.1229
Epoch [17/50] - Loss: 0.1134
Epoch [18/50] - Loss: 0.1051
Epoch [19/50] - Loss: 0.0979
Epoch [20/50] - Loss: 0.0916
Epoch [21/50] - Loss: 0.0861
Epoch [22/50] - Loss: 0.0812
Epoch [23/50] - Loss: 0.0769
Epoch [24/50] - Loss: 0.0730
Epoch [25/50] - Loss: 0.0694
Epoch [26/50] - Loss: 0.0662
Epoch [27/50] - Loss: 0.0632
Epoch [28/50] - Loss: 0.0604
Epoch [29/50] - Loss: 0.0578
Epoch [30/50] - Loss: 0.0553
Epoch [31/50] - Loss: 0.0530
Epoch [32/50] - Loss: 0.0509
Epoch [33/50] - Loss: 0.0488
Epoch [34/50] - Loss: 0.0469
Epoch [35/50] - Loss: 0.0451
Epoch [36/50] - Loss: 0.0434
Epoch [37/50] - Loss: 0.0418
Epoch [38/50] - Loss: 0.0402
Epoch [39/50] - Loss: 0.0387
Epoch [40/50] - Loss: 0.0373
Epoch [41/50] - Loss: 0.0360
Epoch [42/50] - Loss: 0.0347
Epoch [43/50] - Loss: 0.0338
Epoch [44/50] - Loss: 0.0332
Epoch [45/50] - Loss: 0.0323
Epoch [46/50] - Loss: 0.0312
Epoch [47/50] - Loss: 0.0308
Epoch [48/50] - Loss: 0.0305
Epoch [49/50] - Loss: 0.0299
Epoch [50/50] - Loss: 0.0289
sum preds 2171
sum labels 2143
 - Test Metrics: Accuracy=0.9262, F1=0.8090, Recall=0.8143, Precision=0.8038
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5265
Epoch [2/50] - Loss: 0.4642
Epoch [3/50] - Loss: 0.4083
Epoch [4/50] - Loss: 0.3581
Epoch [5/50] - Loss: 0.3130
Epoch [6/50] - Loss: 0.2739
Epoch [7/50] - Loss: 0.2405
Epoch [8/50] - Loss: 0.2124
Epoch [9/50] - Loss: 0.1886
Epoch [10/50] - Loss: 0.1684
Epoch [11/50] - Loss: 0.1513
Epoch [12/50] - Loss: 0.1367
Epoch [13/50] - Loss: 0.1242
Epoch [14/50] - Loss: 0.1135
Epoch [15/50] - Loss: 0.1043
Epoch [16/50] - Loss: 0.0963
Epoch [17/50] - Loss: 0.0895
Epoch [18/50] - Loss: 0.0835
Epoch [19/50] - Loss: 0.0784
Epoch [20/50] - Loss: 0.0738
Epoch [21/50] - Loss: 0.0698
Epoch [22/50] - Loss: 0.0663
Epoch [23/50] - Loss: 0.0632
Epoch [24/50] - Loss: 0.0603
Epoch [25/50] - Loss: 0.0577
Epoch [26/50] - Loss: 0.0553
Epoch [27/50] - Loss: 0.0530
Epoch [28/50] - Loss: 0.0509
Epoch [29/50] - Loss: 0.0489
Epoch [30/50] - Loss: 0.0469
Epoch [31/50] - Loss: 0.0451
Epoch [32/50] - Loss: 0.0433
Epoch [33/50] - Loss: 0.0422
Epoch [34/50] - Loss: 0.0412
Epoch [35/50] - Loss: 0.0399
Epoch [36/50] - Loss: 0.0384
Epoch [37/50] - Loss: 0.0368
Epoch [38/50] - Loss: 0.0363
Epoch [39/50] - Loss: 0.0357
Epoch [40/50] - Loss: 0.0350
Epoch [41/50] - Loss: 0.0341
Epoch [42/50] - Loss: 0.0330
Epoch [43/50] - Loss: 0.0318
Epoch [44/50] - Loss: 0.0306
Epoch [45/50] - Loss: 0.0303
Epoch [46/50] - Loss: 0.0299
Epoch [47/50] - Loss: 0.0293
Epoch [48/50] - Loss: 0.0290
Epoch [49/50] - Loss: 0.0286
Epoch [50/50] - Loss: 0.0278
sum preds 2175
sum labels 2143
 - Test Metrics: Accuracy=0.9278, F1=0.8133, Recall=0.8194, Precision=0.8074
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_nnpu_nnpu_1904080000.csv.
Average F1 over valid seeds: 0.8100 ± 0.0024
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and nnpu, MLP,0.2: 0.8100 ± 0.0024
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5415
Epoch [2/50] - Loss: 0.3939
Epoch [3/50] - Loss: 0.2611
Epoch [4/50] - Loss: 0.2330
Epoch [5/50] - Loss: 0.2235
Epoch [6/50] - Loss: 0.2160
Epoch [7/50] - Loss: 0.2081
Epoch [8/50] - Loss: 0.2007
Epoch [9/50] - Loss: 0.1945
Epoch [10/50] - Loss: 0.1898
Epoch [11/50] - Loss: 0.1861
Epoch [12/50] - Loss: 0.1827
Epoch [13/50] - Loss: 0.1789
Epoch [14/50] - Loss: 0.1743
Epoch [15/50] - Loss: 0.1699
Epoch [16/50] - Loss: 0.1649
Epoch [17/50] - Loss: 0.1600
Epoch [18/50] - Loss: 0.1546
Epoch [19/50] - Loss: 0.1492
Epoch [20/50] - Loss: 0.1437
Epoch [21/50] - Loss: 0.1375
Epoch [22/50] - Loss: 0.1335
Epoch [23/50] - Loss: 0.1296
Epoch [24/50] - Loss: 0.1248
Epoch [25/50] - Loss: 0.1219
Epoch [26/50] - Loss: 0.1192
Epoch [27/50] - Loss: 0.1164
Epoch [28/50] - Loss: 0.1141
Epoch [29/50] - Loss: 0.1120
Epoch [30/50] - Loss: 0.1097
Epoch [31/50] - Loss: 0.1082
Epoch [32/50] - Loss: 0.1064
Epoch [33/50] - Loss: 0.1058
Epoch [34/50] - Loss: 0.1055
Epoch [35/50] - Loss: 0.1048
Epoch [36/50] - Loss: 0.1035
Epoch [37/50] - Loss: 0.1023
Epoch [38/50] - Loss: 0.1022
Epoch [39/50] - Loss: 0.1017
Epoch [40/50] - Loss: 0.1011
Epoch [41/50] - Loss: 0.1005
Epoch [42/50] - Loss: 0.1001
Epoch [43/50] - Loss: 0.0999
Epoch [44/50] - Loss: 0.0999
Epoch [45/50] - Loss: 0.0999
Epoch [46/50] - Loss: 0.0998
Epoch [47/50] - Loss: 0.0996
Epoch [48/50] - Loss: 0.0993
Epoch [49/50] - Loss: 0.0988
Epoch [50/50] - Loss: 0.0991
sum preds 1408
sum labels 2143
 - Test Metrics: Accuracy=0.8736, F1=0.6026, Recall=0.4993, Precision=0.7599
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4346
Epoch [2/50] - Loss: 0.3049
Epoch [3/50] - Loss: 0.2335
Epoch [4/50] - Loss: 0.1942
Epoch [5/50] - Loss: 0.1631
Epoch [6/50] - Loss: 0.1325
Epoch [7/50] - Loss: 0.1222
Epoch [8/50] - Loss: 0.1168
Epoch [9/50] - Loss: 0.1029
Epoch [10/50] - Loss: 0.0978
Epoch [11/50] - Loss: 0.0975
Epoch [12/50] - Loss: 0.0936
Epoch [13/50] - Loss: 0.0859
Epoch [14/50] - Loss: 0.0782
Epoch [15/50] - Loss: 0.0783
Epoch [16/50] - Loss: 0.0765
Epoch [17/50] - Loss: 0.0705
Epoch [18/50] - Loss: 0.0663
Epoch [19/50] - Loss: 0.0656
Epoch [20/50] - Loss: 0.0634
Epoch [21/50] - Loss: 0.0597
Epoch [22/50] - Loss: 0.0573
Epoch [23/50] - Loss: 0.0552
Epoch [24/50] - Loss: 0.0536
Epoch [25/50] - Loss: 0.0516
Epoch [26/50] - Loss: 0.0491
Epoch [27/50] - Loss: 0.0475
Epoch [28/50] - Loss: 0.0487
Epoch [29/50] - Loss: 0.0449
Epoch [30/50] - Loss: 0.0439
Epoch [31/50] - Loss: 0.0432
Epoch [32/50] - Loss: 0.0418
Epoch [33/50] - Loss: 0.0399
Epoch [34/50] - Loss: 0.0413
Epoch [35/50] - Loss: 0.0392
Epoch [36/50] - Loss: 0.0379
Epoch [37/50] - Loss: 0.0381
Epoch [38/50] - Loss: 0.0365
Epoch [39/50] - Loss: 0.0349
Epoch [40/50] - Loss: 0.0344
Epoch [41/50] - Loss: 0.0330
Epoch [42/50] - Loss: 0.0323
Epoch [43/50] - Loss: 0.0320
Epoch [44/50] - Loss: 0.0308
Epoch [45/50] - Loss: 0.0314
Epoch [46/50] - Loss: 0.0307
Epoch [47/50] - Loss: 0.0288
Epoch [48/50] - Loss: 0.0283
Epoch [49/50] - Loss: 0.0286
Epoch [50/50] - Loss: 0.0277
sum preds 2238
sum labels 2143
 - Test Metrics: Accuracy=0.9329, F1=0.8290, Recall=0.8474, Precision=0.8114
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4373
Epoch [2/50] - Loss: 0.3016
Epoch [3/50] - Loss: 0.2150
Epoch [4/50] - Loss: 0.1687
Epoch [5/50] - Loss: 0.1361
Epoch [6/50] - Loss: 0.1108
Epoch [7/50] - Loss: 0.1204
Epoch [8/50] - Loss: 0.0994
Epoch [9/50] - Loss: 0.0916
Epoch [10/50] - Loss: 0.0895
Epoch [11/50] - Loss: 0.0854
Epoch [12/50] - Loss: 0.0789
Epoch [13/50] - Loss: 0.0731
Epoch [14/50] - Loss: 0.0704
Epoch [15/50] - Loss: 0.0694
Epoch [16/50] - Loss: 0.0671
Epoch [17/50] - Loss: 0.0631
Epoch [18/50] - Loss: 0.0592
Epoch [19/50] - Loss: 0.0567
Epoch [20/50] - Loss: 0.0547
Epoch [21/50] - Loss: 0.0522
Epoch [22/50] - Loss: 0.0489
Epoch [23/50] - Loss: 0.0461
Epoch [24/50] - Loss: 0.0444
Epoch [25/50] - Loss: 0.0430
Epoch [26/50] - Loss: 0.0413
Epoch [27/50] - Loss: 0.0395
Epoch [28/50] - Loss: 0.0390
Epoch [29/50] - Loss: 0.0377
Epoch [30/50] - Loss: 0.0367
Epoch [31/50] - Loss: 0.0346
Epoch [32/50] - Loss: 0.0336
Epoch [33/50] - Loss: 0.0329
Epoch [34/50] - Loss: 0.0314
Epoch [35/50] - Loss: 0.0304
Epoch [36/50] - Loss: 0.0289
Epoch [37/50] - Loss: 0.0298
Epoch [38/50] - Loss: 0.0296
Epoch [39/50] - Loss: 0.0269
Epoch [40/50] - Loss: 0.0291
Epoch [41/50] - Loss: 0.0294
Epoch [42/50] - Loss: 0.0272
Epoch [43/50] - Loss: 0.0248
Epoch [44/50] - Loss: 0.0252
Epoch [45/50] - Loss: 0.0233
Epoch [46/50] - Loss: 0.0242
Epoch [47/50] - Loss: 0.0241
Epoch [48/50] - Loss: 0.0227
Epoch [49/50] - Loss: 0.0204
Epoch [50/50] - Loss: 0.0246
sum preds 2408
sum labels 2143
 - Test Metrics: Accuracy=0.9261, F1=0.8187, Recall=0.8693, Precision=0.7737
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_nnpu_nnpu_1904080002.csv.
Average F1 over valid seeds: 0.7501 ± 0.1044
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and nnpu, GATConv,0.2: 0.7501 ± 0.1044
___________________________________________________________________________________
nnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4817
Epoch [2/50] - Loss: 0.4079
Epoch [3/50] - Loss: 0.3439
Epoch [4/50] - Loss: 0.2933
Epoch [5/50] - Loss: 0.2532
Epoch [6/50] - Loss: 0.2210
Epoch [7/50] - Loss: 0.1949
Epoch [8/50] - Loss: 0.1732
Epoch [9/50] - Loss: 0.1550
Epoch [10/50] - Loss: 0.1396
Epoch [11/50] - Loss: 0.1266
Epoch [12/50] - Loss: 0.1153
Epoch [13/50] - Loss: 0.1056
Epoch [14/50] - Loss: 0.0972
Epoch [15/50] - Loss: 0.0899
Epoch [16/50] - Loss: 0.0835
Epoch [17/50] - Loss: 0.0780
Epoch [18/50] - Loss: 0.0732
Epoch [19/50] - Loss: 0.0689
Epoch [20/50] - Loss: 0.0651
Epoch [21/50] - Loss: 0.0618
Epoch [22/50] - Loss: 0.0587
Epoch [23/50] - Loss: 0.0559
Epoch [24/50] - Loss: 0.0534
Epoch [25/50] - Loss: 0.0512
Epoch [26/50] - Loss: 0.0490
Epoch [27/50] - Loss: 0.0471
Epoch [28/50] - Loss: 0.0453
Epoch [29/50] - Loss: 0.0436
Epoch [30/50] - Loss: 0.0420
Epoch [31/50] - Loss: 0.0406
Epoch [32/50] - Loss: 0.0392
Epoch [33/50] - Loss: 0.0379
Epoch [34/50] - Loss: 0.0366
Epoch [35/50] - Loss: 0.0359
Epoch [36/50] - Loss: 0.0352
Epoch [37/50] - Loss: 0.0342
Epoch [38/50] - Loss: 0.0331
Epoch [39/50] - Loss: 0.0319
Epoch [40/50] - Loss: 0.0313
Epoch [41/50] - Loss: 0.0308
Epoch [42/50] - Loss: 0.0304
Epoch [43/50] - Loss: 0.0300
Epoch [44/50] - Loss: 0.0295
Epoch [45/50] - Loss: 0.0290
Epoch [46/50] - Loss: 0.0284
Epoch [47/50] - Loss: 0.0277
Epoch [48/50] - Loss: 0.0270
Epoch [49/50] - Loss: 0.0267
Epoch [50/50] - Loss: 0.0266
sum preds 2132
sum labels 2143
 - Test Metrics: Accuracy=0.9474, F1=0.8627, Recall=0.8605, Precision=0.8649
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4754
Epoch [2/50] - Loss: 0.4040
Epoch [3/50] - Loss: 0.3468
Epoch [4/50] - Loss: 0.3030
Epoch [5/50] - Loss: 0.2685
Epoch [6/50] - Loss: 0.2396
Epoch [7/50] - Loss: 0.2145
Epoch [8/50] - Loss: 0.1925
Epoch [9/50] - Loss: 0.1732
Epoch [10/50] - Loss: 0.1565
Epoch [11/50] - Loss: 0.1421
Epoch [12/50] - Loss: 0.1297
Epoch [13/50] - Loss: 0.1190
Epoch [14/50] - Loss: 0.1098
Epoch [15/50] - Loss: 0.1017
Epoch [16/50] - Loss: 0.0947
Epoch [17/50] - Loss: 0.0885
Epoch [18/50] - Loss: 0.0830
Epoch [19/50] - Loss: 0.0781
Epoch [20/50] - Loss: 0.0737
Epoch [21/50] - Loss: 0.0697
Epoch [22/50] - Loss: 0.0661
Epoch [23/50] - Loss: 0.0628
Epoch [24/50] - Loss: 0.0599
Epoch [25/50] - Loss: 0.0571
Epoch [26/50] - Loss: 0.0546
Epoch [27/50] - Loss: 0.0523
Epoch [28/50] - Loss: 0.0502
Epoch [29/50] - Loss: 0.0482
Epoch [30/50] - Loss: 0.0464
Epoch [31/50] - Loss: 0.0448
Epoch [32/50] - Loss: 0.0432
Epoch [33/50] - Loss: 0.0418
Epoch [34/50] - Loss: 0.0406
Epoch [35/50] - Loss: 0.0394
Epoch [36/50] - Loss: 0.0383
Epoch [37/50] - Loss: 0.0372
Epoch [38/50] - Loss: 0.0363
Epoch [39/50] - Loss: 0.0353
Epoch [40/50] - Loss: 0.0347
Epoch [41/50] - Loss: 0.0344
Epoch [42/50] - Loss: 0.0340
Epoch [43/50] - Loss: 0.0334
Epoch [44/50] - Loss: 0.0328
Epoch [45/50] - Loss: 0.0321
Epoch [46/50] - Loss: 0.0315
Epoch [47/50] - Loss: 0.0314
Epoch [48/50] - Loss: 0.0311
Epoch [49/50] - Loss: 0.0308
Epoch [50/50] - Loss: 0.0305
sum preds 2135
sum labels 2143
 - Test Metrics: Accuracy=0.9459, F1=0.8588, Recall=0.8572, Precision=0.8604
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=nnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4218
Epoch [2/50] - Loss: 0.3521
Epoch [3/50] - Loss: 0.2980
Epoch [4/50] - Loss: 0.2558
Epoch [5/50] - Loss: 0.2224
Epoch [6/50] - Loss: 0.1951
Epoch [7/50] - Loss: 0.1727
Epoch [8/50] - Loss: 0.1541
Epoch [9/50] - Loss: 0.1386
Epoch [10/50] - Loss: 0.1254
Epoch [11/50] - Loss: 0.1144
Epoch [12/50] - Loss: 0.1050
Epoch [13/50] - Loss: 0.0970
Epoch [14/50] - Loss: 0.0901
Epoch [15/50] - Loss: 0.0840
Epoch [16/50] - Loss: 0.0787
Epoch [17/50] - Loss: 0.0740
Epoch [18/50] - Loss: 0.0697
Epoch [19/50] - Loss: 0.0659
Epoch [20/50] - Loss: 0.0624
Epoch [21/50] - Loss: 0.0592
Epoch [22/50] - Loss: 0.0563
Epoch [23/50] - Loss: 0.0536
Epoch [24/50] - Loss: 0.0512
Epoch [25/50] - Loss: 0.0489
Epoch [26/50] - Loss: 0.0468
Epoch [27/50] - Loss: 0.0448
Epoch [28/50] - Loss: 0.0430
Epoch [29/50] - Loss: 0.0413
Epoch [30/50] - Loss: 0.0398
Epoch [31/50] - Loss: 0.0383
Epoch [32/50] - Loss: 0.0369
Epoch [33/50] - Loss: 0.0356
Epoch [34/50] - Loss: 0.0343
Epoch [35/50] - Loss: 0.0331
Epoch [36/50] - Loss: 0.0321
Epoch [37/50] - Loss: 0.0313
Epoch [38/50] - Loss: 0.0303
Epoch [39/50] - Loss: 0.0292
Epoch [40/50] - Loss: 0.0283
Epoch [41/50] - Loss: 0.0277
Epoch [42/50] - Loss: 0.0271
Epoch [43/50] - Loss: 0.0265
Epoch [44/50] - Loss: 0.0258
Epoch [45/50] - Loss: 0.0251
Epoch [46/50] - Loss: 0.0244
Epoch [47/50] - Loss: 0.0238
Epoch [48/50] - Loss: 0.0234
Epoch [49/50] - Loss: 0.0230
Epoch [50/50] - Loss: 0.0227
sum preds 2219
sum labels 2143
 - Test Metrics: Accuracy=0.9498, F1=0.8716, Recall=0.8871, Precision=0.8567
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_nnpu_nnpu_1904080005.csv.
Average F1 over valid seeds: 0.8644 ± 0.0054
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and nnpu, GCNConv,0.2: 0.8644 ± 0.0054
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4968
Epoch [2/50] - Loss: 0.4181
Epoch [3/50] - Loss: 0.3489
Epoch [4/50] - Loss: 0.2940
Epoch [5/50] - Loss: 0.2529
Epoch [6/50] - Loss: 0.2223
Epoch [7/50] - Loss: 0.1989
Epoch [8/50] - Loss: 0.1804
Epoch [9/50] - Loss: 0.1654
Epoch [10/50] - Loss: 0.1530
Epoch [11/50] - Loss: 0.1425
Epoch [12/50] - Loss: 0.1334
Epoch [13/50] - Loss: 0.1254
Epoch [14/50] - Loss: 0.1183
Epoch [15/50] - Loss: 0.1118
Epoch [16/50] - Loss: 0.1058
Epoch [17/50] - Loss: 0.1002
Epoch [18/50] - Loss: 0.0948
Epoch [19/50] - Loss: 0.0898
Epoch [20/50] - Loss: 0.0851
Epoch [21/50] - Loss: 0.0805
Epoch [22/50] - Loss: 0.0762
Epoch [23/50] - Loss: 0.0722
Epoch [24/50] - Loss: 0.0684
Epoch [25/50] - Loss: 0.0650
Epoch [26/50] - Loss: 0.0619
Epoch [27/50] - Loss: 0.0591
Epoch [28/50] - Loss: 0.0566
Epoch [29/50] - Loss: 0.0544
Epoch [30/50] - Loss: 0.0525
Epoch [31/50] - Loss: 0.0507
Epoch [32/50] - Loss: 0.0491
Epoch [33/50] - Loss: 0.0475
Epoch [34/50] - Loss: 0.0458
Epoch [35/50] - Loss: 0.0442
Epoch [36/50] - Loss: 0.0426
Epoch [37/50] - Loss: 0.0410
Epoch [38/50] - Loss: 0.0395
Epoch [39/50] - Loss: 0.0380
Epoch [40/50] - Loss: 0.0366
Epoch [41/50] - Loss: 0.0353
Epoch [42/50] - Loss: 0.0341
Epoch [43/50] - Loss: 0.0330
Epoch [44/50] - Loss: 0.0319
Epoch [45/50] - Loss: 0.0309
Epoch [46/50] - Loss: 0.0300
Epoch [47/50] - Loss: 0.0290
Epoch [48/50] - Loss: 0.0281
Epoch [49/50] - Loss: 0.0272
Epoch [50/50] - Loss: 0.0263
sum preds 2079
sum labels 1607
 - Test Metrics: Accuracy=0.9227, F1=0.7770, Recall=0.8911, Precision=0.6888
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5139
Epoch [2/50] - Loss: 0.4491
Epoch [3/50] - Loss: 0.3917
Epoch [4/50] - Loss: 0.3439
Epoch [5/50] - Loss: 0.3052
Epoch [6/50] - Loss: 0.2735
Epoch [7/50] - Loss: 0.2472
Epoch [8/50] - Loss: 0.2252
Epoch [9/50] - Loss: 0.2066
Epoch [10/50] - Loss: 0.1909
Epoch [11/50] - Loss: 0.1776
Epoch [12/50] - Loss: 0.1662
Epoch [13/50] - Loss: 0.1564
Epoch [14/50] - Loss: 0.1478
Epoch [15/50] - Loss: 0.1403
Epoch [16/50] - Loss: 0.1335
Epoch [17/50] - Loss: 0.1274
Epoch [18/50] - Loss: 0.1219
Epoch [19/50] - Loss: 0.1168
Epoch [20/50] - Loss: 0.1120
Epoch [21/50] - Loss: 0.1076
Epoch [22/50] - Loss: 0.1035
Epoch [23/50] - Loss: 0.0997
Epoch [24/50] - Loss: 0.0961
Epoch [25/50] - Loss: 0.0927
Epoch [26/50] - Loss: 0.0895
Epoch [27/50] - Loss: 0.0865
Epoch [28/50] - Loss: 0.0836
Epoch [29/50] - Loss: 0.0807
Epoch [30/50] - Loss: 0.0780
Epoch [31/50] - Loss: 0.0753
Epoch [32/50] - Loss: 0.0726
Epoch [33/50] - Loss: 0.0699
Epoch [34/50] - Loss: 0.0674
Epoch [35/50] - Loss: 0.0649
Epoch [36/50] - Loss: 0.0624
Epoch [37/50] - Loss: 0.0601
Epoch [38/50] - Loss: 0.0579
Epoch [39/50] - Loss: 0.0559
Epoch [40/50] - Loss: 0.0539
Epoch [41/50] - Loss: 0.0520
Epoch [42/50] - Loss: 0.0502
Epoch [43/50] - Loss: 0.0486
Epoch [44/50] - Loss: 0.0470
Epoch [45/50] - Loss: 0.0455
Epoch [46/50] - Loss: 0.0440
Epoch [47/50] - Loss: 0.0425
Epoch [48/50] - Loss: 0.0411
Epoch [49/50] - Loss: 0.0398
Epoch [50/50] - Loss: 0.0385
sum preds 2089
sum labels 1607
 - Test Metrics: Accuracy=0.9210, F1=0.7727, Recall=0.8886, Precision=0.6836
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5079
Epoch [2/50] - Loss: 0.4298
Epoch [3/50] - Loss: 0.3663
Epoch [4/50] - Loss: 0.3146
Epoch [5/50] - Loss: 0.2735
Epoch [6/50] - Loss: 0.2415
Epoch [7/50] - Loss: 0.2166
Epoch [8/50] - Loss: 0.1970
Epoch [9/50] - Loss: 0.1813
Epoch [10/50] - Loss: 0.1682
Epoch [11/50] - Loss: 0.1571
Epoch [12/50] - Loss: 0.1472
Epoch [13/50] - Loss: 0.1384
Epoch [14/50] - Loss: 0.1304
Epoch [15/50] - Loss: 0.1229
Epoch [16/50] - Loss: 0.1161
Epoch [17/50] - Loss: 0.1099
Epoch [18/50] - Loss: 0.1041
Epoch [19/50] - Loss: 0.0988
Epoch [20/50] - Loss: 0.0938
Epoch [21/50] - Loss: 0.0892
Epoch [22/50] - Loss: 0.0849
Epoch [23/50] - Loss: 0.0811
Epoch [24/50] - Loss: 0.0775
Epoch [25/50] - Loss: 0.0743
Epoch [26/50] - Loss: 0.0714
Epoch [27/50] - Loss: 0.0688
Epoch [28/50] - Loss: 0.0664
Epoch [29/50] - Loss: 0.0643
Epoch [30/50] - Loss: 0.0623
Epoch [31/50] - Loss: 0.0604
Epoch [32/50] - Loss: 0.0586
Epoch [33/50] - Loss: 0.0569
Epoch [34/50] - Loss: 0.0552
Epoch [35/50] - Loss: 0.0536
Epoch [36/50] - Loss: 0.0520
Epoch [37/50] - Loss: 0.0505
Epoch [38/50] - Loss: 0.0490
Epoch [39/50] - Loss: 0.0476
Epoch [40/50] - Loss: 0.0463
Epoch [41/50] - Loss: 0.0451
Epoch [42/50] - Loss: 0.0439
Epoch [43/50] - Loss: 0.0428
Epoch [44/50] - Loss: 0.0417
Epoch [45/50] - Loss: 0.0407
Epoch [46/50] - Loss: 0.0397
Epoch [47/50] - Loss: 0.0387
Epoch [48/50] - Loss: 0.0378
Epoch [49/50] - Loss: 0.0369
Epoch [50/50] - Loss: 0.0360
sum preds 2133
sum labels 1607
 - Test Metrics: Accuracy=0.9223, F1=0.7791, Recall=0.9067, Precision=0.6831
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_imbnnpu_imbnnpu_1904080008.csv.
Average F1 over valid seeds: 0.7763 ± 0.0027
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and imbnnpu, MLP,0.4: 0.7763 ± 0.0027
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4408
Epoch [2/50] - Loss: 0.3562
Epoch [3/50] - Loss: 0.3063
Epoch [4/50] - Loss: 0.2533
Epoch [5/50] - Loss: 0.2416
Epoch [6/50] - Loss: 0.2331
Epoch [7/50] - Loss: 0.2252
Epoch [8/50] - Loss: 0.2162
Epoch [9/50] - Loss: 0.2078
Epoch [10/50] - Loss: 0.2021
Epoch [11/50] - Loss: 0.2002
Epoch [12/50] - Loss: 0.1887
Epoch [13/50] - Loss: 0.1839
Epoch [14/50] - Loss: 0.1805
Epoch [15/50] - Loss: 0.1769
Epoch [16/50] - Loss: 0.1723
Epoch [17/50] - Loss: 0.1675
Epoch [18/50] - Loss: 0.1627
Epoch [19/50] - Loss: 0.1582
Epoch [20/50] - Loss: 0.1537
Epoch [21/50] - Loss: 0.1492
Epoch [22/50] - Loss: 0.1440
Epoch [23/50] - Loss: 0.1376
Epoch [24/50] - Loss: 0.1333
Epoch [25/50] - Loss: 0.1298
Epoch [26/50] - Loss: 0.1254
Epoch [27/50] - Loss: 0.1171
Epoch [28/50] - Loss: 0.1035
Epoch [29/50] - Loss: 0.1021
Epoch [30/50] - Loss: 0.0994
Epoch [31/50] - Loss: 0.1022
Epoch [32/50] - Loss: 0.1010
Epoch [33/50] - Loss: 0.0985
Epoch [34/50] - Loss: 0.0952
Epoch [35/50] - Loss: 0.0910
Epoch [36/50] - Loss: 0.0870
Epoch [37/50] - Loss: 0.0827
Epoch [38/50] - Loss: 0.0793
Epoch [39/50] - Loss: 0.0763
Epoch [40/50] - Loss: 0.0738
Epoch [41/50] - Loss: 0.0707
Epoch [42/50] - Loss: 0.0689
Epoch [43/50] - Loss: 0.0669
Epoch [44/50] - Loss: 0.0656
Epoch [45/50] - Loss: 0.0640
Epoch [46/50] - Loss: 0.0618
Epoch [47/50] - Loss: 0.0591
Epoch [48/50] - Loss: 0.0573
Epoch [49/50] - Loss: 0.0554
Epoch [50/50] - Loss: 0.0538
sum preds 2092
sum labels 1607
 - Test Metrics: Accuracy=0.9118, F1=0.7467, Recall=0.8594, Precision=0.6601
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5240
Epoch [2/50] - Loss: 0.3932
Epoch [3/50] - Loss: 0.2963
Epoch [4/50] - Loss: 0.2347
Epoch [5/50] - Loss: 0.1898
Epoch [6/50] - Loss: 0.1530
Epoch [7/50] - Loss: 0.1314
Epoch [8/50] - Loss: 0.1208
Epoch [9/50] - Loss: 0.1171
Epoch [10/50] - Loss: 0.1131
Epoch [11/50] - Loss: 0.1110
Epoch [12/50] - Loss: 0.1045
Epoch [13/50] - Loss: 0.0988
Epoch [14/50] - Loss: 0.0940
Epoch [15/50] - Loss: 0.0906
Epoch [16/50] - Loss: 0.0870
Epoch [17/50] - Loss: 0.0852
Epoch [18/50] - Loss: 0.0829
Epoch [19/50] - Loss: 0.0816
Epoch [20/50] - Loss: 0.0792
Epoch [21/50] - Loss: 0.0782
Epoch [22/50] - Loss: 0.0757
Epoch [23/50] - Loss: 0.0742
Epoch [24/50] - Loss: 0.0722
Epoch [25/50] - Loss: 0.0708
Epoch [26/50] - Loss: 0.0687
Epoch [27/50] - Loss: 0.0671
Epoch [28/50] - Loss: 0.0656
Epoch [29/50] - Loss: 0.0637
Epoch [30/50] - Loss: 0.0615
Epoch [31/50] - Loss: 0.0593
Epoch [32/50] - Loss: 0.0564
Epoch [33/50] - Loss: 0.0539
Epoch [34/50] - Loss: 0.0513
Epoch [35/50] - Loss: 0.0488
Epoch [36/50] - Loss: 0.0463
Epoch [37/50] - Loss: 0.0443
Epoch [38/50] - Loss: 0.0424
Epoch [39/50] - Loss: 0.0407
Epoch [40/50] - Loss: 0.0393
Epoch [41/50] - Loss: 0.0382
Epoch [42/50] - Loss: 0.0372
Epoch [43/50] - Loss: 0.0360
Epoch [44/50] - Loss: 0.0348
Epoch [45/50] - Loss: 0.0335
Epoch [46/50] - Loss: 0.0322
Epoch [47/50] - Loss: 0.0312
Epoch [48/50] - Loss: 0.0302
Epoch [49/50] - Loss: 0.0292
Epoch [50/50] - Loss: 0.0283
sum preds 2152
sum labels 1607
 - Test Metrics: Accuracy=0.9243, F1=0.7858, Recall=0.9191, Precision=0.6863
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4733
Epoch [2/50] - Loss: 0.3460
Epoch [3/50] - Loss: 0.2587
Epoch [4/50] - Loss: 0.1902
Epoch [5/50] - Loss: 0.1448
Epoch [6/50] - Loss: 0.1195
Epoch [7/50] - Loss: 0.1083
Epoch [8/50] - Loss: 0.0999
Epoch [9/50] - Loss: 0.0978
Epoch [10/50] - Loss: 0.0907
Epoch [11/50] - Loss: 0.0891
Epoch [12/50] - Loss: 0.0836
Epoch [13/50] - Loss: 0.0805
Epoch [14/50] - Loss: 0.0767
Epoch [15/50] - Loss: 0.0750
Epoch [16/50] - Loss: 0.0734
Epoch [17/50] - Loss: 0.0706
Epoch [18/50] - Loss: 0.0675
Epoch [19/50] - Loss: 0.0648
Epoch [20/50] - Loss: 0.0622
Epoch [21/50] - Loss: 0.0598
Epoch [22/50] - Loss: 0.0576
Epoch [23/50] - Loss: 0.0556
Epoch [24/50] - Loss: 0.0538
Epoch [25/50] - Loss: 0.0519
Epoch [26/50] - Loss: 0.0497
Epoch [27/50] - Loss: 0.0473
Epoch [28/50] - Loss: 0.0451
Epoch [29/50] - Loss: 0.0427
Epoch [30/50] - Loss: 0.0403
Epoch [31/50] - Loss: 0.0385
Epoch [32/50] - Loss: 0.0374
Epoch [33/50] - Loss: 0.0363
Epoch [34/50] - Loss: 0.0349
Epoch [35/50] - Loss: 0.0330
Epoch [36/50] - Loss: 0.0321
Epoch [37/50] - Loss: 0.0314
Epoch [38/50] - Loss: 0.0304
Epoch [39/50] - Loss: 0.0291
Epoch [40/50] - Loss: 0.0278
Epoch [41/50] - Loss: 0.0265
Epoch [42/50] - Loss: 0.0254
Epoch [43/50] - Loss: 0.0244
Epoch [44/50] - Loss: 0.0238
Epoch [45/50] - Loss: 0.0232
Epoch [46/50] - Loss: 0.0223
Epoch [47/50] - Loss: 0.0214
Epoch [48/50] - Loss: 0.0208
Epoch [49/50] - Loss: 0.0201
Epoch [50/50] - Loss: 0.0194
sum preds 2187
sum labels 1607
 - Test Metrics: Accuracy=0.9172, F1=0.7681, Recall=0.9067, Precision=0.6662
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_imbnnpu_imbnnpu_1904080009.csv.
Average F1 over valid seeds: 0.7669 ± 0.0160
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and imbnnpu, GATConv,0.4: 0.7669 ± 0.0160
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5311
Epoch [2/50] - Loss: 0.4435
Epoch [3/50] - Loss: 0.3649
Epoch [4/50] - Loss: 0.3049
Epoch [5/50] - Loss: 0.2602
Epoch [6/50] - Loss: 0.2267
Epoch [7/50] - Loss: 0.2012
Epoch [8/50] - Loss: 0.1816
Epoch [9/50] - Loss: 0.1664
Epoch [10/50] - Loss: 0.1543
Epoch [11/50] - Loss: 0.1444
Epoch [12/50] - Loss: 0.1361
Epoch [13/50] - Loss: 0.1290
Epoch [14/50] - Loss: 0.1228
Epoch [15/50] - Loss: 0.1174
Epoch [16/50] - Loss: 0.1124
Epoch [17/50] - Loss: 0.1078
Epoch [18/50] - Loss: 0.1036
Epoch [19/50] - Loss: 0.0996
Epoch [20/50] - Loss: 0.0957
Epoch [21/50] - Loss: 0.0921
Epoch [22/50] - Loss: 0.0886
Epoch [23/50] - Loss: 0.0852
Epoch [24/50] - Loss: 0.0820
Epoch [25/50] - Loss: 0.0789
Epoch [26/50] - Loss: 0.0760
Epoch [27/50] - Loss: 0.0732
Epoch [28/50] - Loss: 0.0705
Epoch [29/50] - Loss: 0.0679
Epoch [30/50] - Loss: 0.0655
Epoch [31/50] - Loss: 0.0632
Epoch [32/50] - Loss: 0.0610
Epoch [33/50] - Loss: 0.0587
Epoch [34/50] - Loss: 0.0564
Epoch [35/50] - Loss: 0.0539
Epoch [36/50] - Loss: 0.0515
Epoch [37/50] - Loss: 0.0493
Epoch [38/50] - Loss: 0.0474
Epoch [39/50] - Loss: 0.0459
Epoch [40/50] - Loss: 0.0447
Epoch [41/50] - Loss: 0.0437
Epoch [42/50] - Loss: 0.0428
Epoch [43/50] - Loss: 0.0420
Epoch [44/50] - Loss: 0.0412
Epoch [45/50] - Loss: 0.0403
Epoch [46/50] - Loss: 0.0395
Epoch [47/50] - Loss: 0.0386
Epoch [48/50] - Loss: 0.0377
Epoch [49/50] - Loss: 0.0367
Epoch [50/50] - Loss: 0.0358
sum preds 1953
sum labels 1607
 - Test Metrics: Accuracy=0.9430, F1=0.8298, Recall=0.9191, Precision=0.7563
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4888
Epoch [2/50] - Loss: 0.4003
Epoch [3/50] - Loss: 0.3294
Epoch [4/50] - Loss: 0.2788
Epoch [5/50] - Loss: 0.2416
Epoch [6/50] - Loss: 0.2133
Epoch [7/50] - Loss: 0.1912
Epoch [8/50] - Loss: 0.1736
Epoch [9/50] - Loss: 0.1593
Epoch [10/50] - Loss: 0.1474
Epoch [11/50] - Loss: 0.1373
Epoch [12/50] - Loss: 0.1288
Epoch [13/50] - Loss: 0.1213
Epoch [14/50] - Loss: 0.1148
Epoch [15/50] - Loss: 0.1091
Epoch [16/50] - Loss: 0.1039
Epoch [17/50] - Loss: 0.0991
Epoch [18/50] - Loss: 0.0948
Epoch [19/50] - Loss: 0.0907
Epoch [20/50] - Loss: 0.0870
Epoch [21/50] - Loss: 0.0835
Epoch [22/50] - Loss: 0.0803
Epoch [23/50] - Loss: 0.0773
Epoch [24/50] - Loss: 0.0746
Epoch [25/50] - Loss: 0.0721
Epoch [26/50] - Loss: 0.0698
Epoch [27/50] - Loss: 0.0678
Epoch [28/50] - Loss: 0.0659
Epoch [29/50] - Loss: 0.0641
Epoch [30/50] - Loss: 0.0624
Epoch [31/50] - Loss: 0.0608
Epoch [32/50] - Loss: 0.0592
Epoch [33/50] - Loss: 0.0577
Epoch [34/50] - Loss: 0.0562
Epoch [35/50] - Loss: 0.0547
Epoch [36/50] - Loss: 0.0532
Epoch [37/50] - Loss: 0.0518
Epoch [38/50] - Loss: 0.0505
Epoch [39/50] - Loss: 0.0493
Epoch [40/50] - Loss: 0.0482
Epoch [41/50] - Loss: 0.0472
Epoch [42/50] - Loss: 0.0462
Epoch [43/50] - Loss: 0.0452
Epoch [44/50] - Loss: 0.0442
Epoch [45/50] - Loss: 0.0433
Epoch [46/50] - Loss: 0.0423
Epoch [47/50] - Loss: 0.0413
Epoch [48/50] - Loss: 0.0403
Epoch [49/50] - Loss: 0.0393
Epoch [50/50] - Loss: 0.0383
sum preds 1990
sum labels 1607
 - Test Metrics: Accuracy=0.9388, F1=0.8190, Recall=0.9166, Precision=0.7402
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4386
Epoch [2/50] - Loss: 0.3650
Epoch [3/50] - Loss: 0.3055
Epoch [4/50] - Loss: 0.2588
Epoch [5/50] - Loss: 0.2228
Epoch [6/50] - Loss: 0.1953
Epoch [7/50] - Loss: 0.1740
Epoch [8/50] - Loss: 0.1572
Epoch [9/50] - Loss: 0.1436
Epoch [10/50] - Loss: 0.1324
Epoch [11/50] - Loss: 0.1229
Epoch [12/50] - Loss: 0.1147
Epoch [13/50] - Loss: 0.1075
Epoch [14/50] - Loss: 0.1010
Epoch [15/50] - Loss: 0.0953
Epoch [16/50] - Loss: 0.0902
Epoch [17/50] - Loss: 0.0856
Epoch [18/50] - Loss: 0.0815
Epoch [19/50] - Loss: 0.0778
Epoch [20/50] - Loss: 0.0744
Epoch [21/50] - Loss: 0.0712
Epoch [22/50] - Loss: 0.0684
Epoch [23/50] - Loss: 0.0657
Epoch [24/50] - Loss: 0.0633
Epoch [25/50] - Loss: 0.0610
Epoch [26/50] - Loss: 0.0588
Epoch [27/50] - Loss: 0.0568
Epoch [28/50] - Loss: 0.0549
Epoch [29/50] - Loss: 0.0530
Epoch [30/50] - Loss: 0.0513
Epoch [31/50] - Loss: 0.0497
Epoch [32/50] - Loss: 0.0481
Epoch [33/50] - Loss: 0.0467
Epoch [34/50] - Loss: 0.0454
Epoch [35/50] - Loss: 0.0442
Epoch [36/50] - Loss: 0.0431
Epoch [37/50] - Loss: 0.0420
Epoch [38/50] - Loss: 0.0409
Epoch [39/50] - Loss: 0.0399
Epoch [40/50] - Loss: 0.0388
Epoch [41/50] - Loss: 0.0377
Epoch [42/50] - Loss: 0.0366
Epoch [43/50] - Loss: 0.0355
Epoch [44/50] - Loss: 0.0345
Epoch [45/50] - Loss: 0.0335
Epoch [46/50] - Loss: 0.0325
Epoch [47/50] - Loss: 0.0316
Epoch [48/50] - Loss: 0.0308
Epoch [49/50] - Loss: 0.0300
Epoch [50/50] - Loss: 0.0292
sum preds 1917
sum labels 1607
 - Test Metrics: Accuracy=0.9424, F1=0.8263, Recall=0.9060, Precision=0.7595
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_imbnnpu_imbnnpu_1904080013.csv.
Average F1 over valid seeds: 0.8250 ± 0.0045
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and imbnnpu, GCNConv,0.4: 0.8250 ± 0.0045
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4970
Epoch [2/50] - Loss: 0.4194
Epoch [3/50] - Loss: 0.3514
Epoch [4/50] - Loss: 0.2972
Epoch [5/50] - Loss: 0.2569
Epoch [6/50] - Loss: 0.2272
Epoch [7/50] - Loss: 0.2046
Epoch [8/50] - Loss: 0.1869
Epoch [9/50] - Loss: 0.1724
Epoch [10/50] - Loss: 0.1604
Epoch [11/50] - Loss: 0.1500
Epoch [12/50] - Loss: 0.1410
Epoch [13/50] - Loss: 0.1328
Epoch [14/50] - Loss: 0.1254
Epoch [15/50] - Loss: 0.1186
Epoch [16/50] - Loss: 0.1123
Epoch [17/50] - Loss: 0.1063
Epoch [18/50] - Loss: 0.1006
Epoch [19/50] - Loss: 0.0953
Epoch [20/50] - Loss: 0.0903
Epoch [21/50] - Loss: 0.0856
Epoch [22/50] - Loss: 0.0813
Epoch [23/50] - Loss: 0.0772
Epoch [24/50] - Loss: 0.0736
Epoch [25/50] - Loss: 0.0703
Epoch [26/50] - Loss: 0.0674
Epoch [27/50] - Loss: 0.0649
Epoch [28/50] - Loss: 0.0626
Epoch [29/50] - Loss: 0.0605
Epoch [30/50] - Loss: 0.0586
Epoch [31/50] - Loss: 0.0569
Epoch [32/50] - Loss: 0.0551
Epoch [33/50] - Loss: 0.0534
Epoch [34/50] - Loss: 0.0518
Epoch [35/50] - Loss: 0.0501
Epoch [36/50] - Loss: 0.0485
Epoch [37/50] - Loss: 0.0469
Epoch [38/50] - Loss: 0.0453
Epoch [39/50] - Loss: 0.0439
Epoch [40/50] - Loss: 0.0425
Epoch [41/50] - Loss: 0.0412
Epoch [42/50] - Loss: 0.0400
Epoch [43/50] - Loss: 0.0388
Epoch [44/50] - Loss: 0.0378
Epoch [45/50] - Loss: 0.0367
Epoch [46/50] - Loss: 0.0357
Epoch [47/50] - Loss: 0.0347
Epoch [48/50] - Loss: 0.0337
Epoch [49/50] - Loss: 0.0328
Epoch [50/50] - Loss: 0.0318
sum preds 2249
sum labels 1875
 - Test Metrics: Accuracy=0.9235, F1=0.7978, Recall=0.8773, Precision=0.7314
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5133
Epoch [2/50] - Loss: 0.4504
Epoch [3/50] - Loss: 0.3946
Epoch [4/50] - Loss: 0.3484
Epoch [5/50] - Loss: 0.3108
Epoch [6/50] - Loss: 0.2799
Epoch [7/50] - Loss: 0.2542
Epoch [8/50] - Loss: 0.2327
Epoch [9/50] - Loss: 0.2144
Epoch [10/50] - Loss: 0.1989
Epoch [11/50] - Loss: 0.1857
Epoch [12/50] - Loss: 0.1743
Epoch [13/50] - Loss: 0.1645
Epoch [14/50] - Loss: 0.1560
Epoch [15/50] - Loss: 0.1485
Epoch [16/50] - Loss: 0.1418
Epoch [17/50] - Loss: 0.1358
Epoch [18/50] - Loss: 0.1304
Epoch [19/50] - Loss: 0.1254
Epoch [20/50] - Loss: 0.1208
Epoch [21/50] - Loss: 0.1166
Epoch [22/50] - Loss: 0.1127
Epoch [23/50] - Loss: 0.1091
Epoch [24/50] - Loss: 0.1058
Epoch [25/50] - Loss: 0.1026
Epoch [26/50] - Loss: 0.0996
Epoch [27/50] - Loss: 0.0967
Epoch [28/50] - Loss: 0.0940
Epoch [29/50] - Loss: 0.0913
Epoch [30/50] - Loss: 0.0886
Epoch [31/50] - Loss: 0.0860
Epoch [32/50] - Loss: 0.0834
Epoch [33/50] - Loss: 0.0809
Epoch [34/50] - Loss: 0.0784
Epoch [35/50] - Loss: 0.0759
Epoch [36/50] - Loss: 0.0735
Epoch [37/50] - Loss: 0.0711
Epoch [38/50] - Loss: 0.0688
Epoch [39/50] - Loss: 0.0665
Epoch [40/50] - Loss: 0.0643
Epoch [41/50] - Loss: 0.0621
Epoch [42/50] - Loss: 0.0600
Epoch [43/50] - Loss: 0.0580
Epoch [44/50] - Loss: 0.0561
Epoch [45/50] - Loss: 0.0543
Epoch [46/50] - Loss: 0.0525
Epoch [47/50] - Loss: 0.0508
Epoch [48/50] - Loss: 0.0493
Epoch [49/50] - Loss: 0.0478
Epoch [50/50] - Loss: 0.0464
sum preds 2329
sum labels 1875
 - Test Metrics: Accuracy=0.9198, F1=0.7921, Recall=0.8880, Precision=0.7149
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5073
Epoch [2/50] - Loss: 0.4306
Epoch [3/50] - Loss: 0.3684
Epoch [4/50] - Loss: 0.3182
Epoch [5/50] - Loss: 0.2783
Epoch [6/50] - Loss: 0.2472
Epoch [7/50] - Loss: 0.2230
Epoch [8/50] - Loss: 0.2039
Epoch [9/50] - Loss: 0.1885
Epoch [10/50] - Loss: 0.1757
Epoch [11/50] - Loss: 0.1648
Epoch [12/50] - Loss: 0.1551
Epoch [13/50] - Loss: 0.1464
Epoch [14/50] - Loss: 0.1384
Epoch [15/50] - Loss: 0.1311
Epoch [16/50] - Loss: 0.1243
Epoch [17/50] - Loss: 0.1180
Epoch [18/50] - Loss: 0.1122
Epoch [19/50] - Loss: 0.1068
Epoch [20/50] - Loss: 0.1018
Epoch [21/50] - Loss: 0.0972
Epoch [22/50] - Loss: 0.0929
Epoch [23/50] - Loss: 0.0888
Epoch [24/50] - Loss: 0.0851
Epoch [25/50] - Loss: 0.0817
Epoch [26/50] - Loss: 0.0786
Epoch [27/50] - Loss: 0.0758
Epoch [28/50] - Loss: 0.0732
Epoch [29/50] - Loss: 0.0710
Epoch [30/50] - Loss: 0.0689
Epoch [31/50] - Loss: 0.0670
Epoch [32/50] - Loss: 0.0652
Epoch [33/50] - Loss: 0.0635
Epoch [34/50] - Loss: 0.0618
Epoch [35/50] - Loss: 0.0602
Epoch [36/50] - Loss: 0.0586
Epoch [37/50] - Loss: 0.0571
Epoch [38/50] - Loss: 0.0556
Epoch [39/50] - Loss: 0.0543
Epoch [40/50] - Loss: 0.0529
Epoch [41/50] - Loss: 0.0517
Epoch [42/50] - Loss: 0.0506
Epoch [43/50] - Loss: 0.0495
Epoch [44/50] - Loss: 0.0485
Epoch [45/50] - Loss: 0.0476
Epoch [46/50] - Loss: 0.0467
Epoch [47/50] - Loss: 0.0458
Epoch [48/50] - Loss: 0.0450
Epoch [49/50] - Loss: 0.0442
Epoch [50/50] - Loss: 0.0434
sum preds 2280
sum labels 1875
 - Test Metrics: Accuracy=0.9250, F1=0.8034, Recall=0.8901, Precision=0.7320
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_imbnnpu_imbnnpu_1904080015.csv.
Average F1 over valid seeds: 0.7977 ± 0.0046
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and imbnnpu, MLP,0.3: 0.7977 ± 0.0046
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4432
Epoch [2/50] - Loss: 0.3572
Epoch [3/50] - Loss: 0.3015
Epoch [4/50] - Loss: 0.2563
Epoch [5/50] - Loss: 0.2456
Epoch [6/50] - Loss: 0.2380
Epoch [7/50] - Loss: 0.2313
Epoch [8/50] - Loss: 0.2262
Epoch [9/50] - Loss: 0.2201
Epoch [10/50] - Loss: 0.2140
Epoch [11/50] - Loss: 0.2076
Epoch [12/50] - Loss: 0.2016
Epoch [13/50] - Loss: 0.1964
Epoch [14/50] - Loss: 0.1910
Epoch [15/50] - Loss: 0.1862
Epoch [16/50] - Loss: 0.1808
Epoch [17/50] - Loss: 0.1759
Epoch [18/50] - Loss: 0.1768
Epoch [19/50] - Loss: 0.1715
Epoch [20/50] - Loss: 0.1615
Epoch [21/50] - Loss: 0.1600
Epoch [22/50] - Loss: 0.1558
Epoch [23/50] - Loss: 0.1533
Epoch [24/50] - Loss: 0.1509
Epoch [25/50] - Loss: 0.1489
Epoch [26/50] - Loss: 0.1466
Epoch [27/50] - Loss: 0.1443
Epoch [28/50] - Loss: 0.1421
Epoch [29/50] - Loss: 0.1397
Epoch [30/50] - Loss: 0.1217
Epoch [31/50] - Loss: 0.1143
Epoch [32/50] - Loss: 0.1109
Epoch [33/50] - Loss: 0.1094
Epoch [34/50] - Loss: 0.1060
Epoch [35/50] - Loss: 0.1008
Epoch [36/50] - Loss: 0.0966
Epoch [37/50] - Loss: 0.0967
Epoch [38/50] - Loss: 0.0934
Epoch [39/50] - Loss: 0.0938
Epoch [40/50] - Loss: 0.0943
Epoch [41/50] - Loss: 0.0921
Epoch [42/50] - Loss: 0.0889
Epoch [43/50] - Loss: 0.0866
Epoch [44/50] - Loss: 0.0828
Epoch [45/50] - Loss: 0.0786
Epoch [46/50] - Loss: 0.0763
Epoch [47/50] - Loss: 0.0734
Epoch [48/50] - Loss: 0.0712
Epoch [49/50] - Loss: 0.0696
Epoch [50/50] - Loss: 0.0672
sum preds 2245
sum labels 1875
 - Test Metrics: Accuracy=0.9057, F1=0.7505, Recall=0.8245, Precision=0.6886
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5264
Epoch [2/50] - Loss: 0.3987
Epoch [3/50] - Loss: 0.3032
Epoch [4/50] - Loss: 0.2410
Epoch [5/50] - Loss: 0.1968
Epoch [6/50] - Loss: 0.1602
Epoch [7/50] - Loss: 0.1387
Epoch [8/50] - Loss: 0.1280
Epoch [9/50] - Loss: 0.1244
Epoch [10/50] - Loss: 0.1190
Epoch [11/50] - Loss: 0.1153
Epoch [12/50] - Loss: 0.1093
Epoch [13/50] - Loss: 0.1043
Epoch [14/50] - Loss: 0.1018
Epoch [15/50] - Loss: 0.0995
Epoch [16/50] - Loss: 0.0973
Epoch [17/50] - Loss: 0.0952
Epoch [18/50] - Loss: 0.0935
Epoch [19/50] - Loss: 0.0917
Epoch [20/50] - Loss: 0.0899
Epoch [21/50] - Loss: 0.0879
Epoch [22/50] - Loss: 0.0858
Epoch [23/50] - Loss: 0.0841
Epoch [24/50] - Loss: 0.0822
Epoch [25/50] - Loss: 0.0804
Epoch [26/50] - Loss: 0.0778
Epoch [27/50] - Loss: 0.0765
Epoch [28/50] - Loss: 0.0753
Epoch [29/50] - Loss: 0.0742
Epoch [30/50] - Loss: 0.0728
Epoch [31/50] - Loss: 0.0715
Epoch [32/50] - Loss: 0.0706
Epoch [33/50] - Loss: 0.0695
Epoch [34/50] - Loss: 0.0685
Epoch [35/50] - Loss: 0.0677
Epoch [36/50] - Loss: 0.0659
Epoch [37/50] - Loss: 0.0652
Epoch [38/50] - Loss: 0.0650
Epoch [39/50] - Loss: 0.0634
Epoch [40/50] - Loss: 0.0641
Epoch [41/50] - Loss: 0.0621
Epoch [42/50] - Loss: 0.0622
Epoch [43/50] - Loss: 0.0601
Epoch [44/50] - Loss: 0.0586
Epoch [45/50] - Loss: 0.0578
Epoch [46/50] - Loss: 0.0559
Epoch [47/50] - Loss: 0.0556
Epoch [48/50] - Loss: 0.0538
Epoch [49/50] - Loss: 0.0526
Epoch [50/50] - Loss: 0.0516
sum preds 2599
sum labels 1875
 - Test Metrics: Accuracy=0.8970, F1=0.7492, Recall=0.8939, Precision=0.6449
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4720
Epoch [2/50] - Loss: 0.3463
Epoch [3/50] - Loss: 0.2604
Epoch [4/50] - Loss: 0.1935
Epoch [5/50] - Loss: 0.1493
Epoch [6/50] - Loss: 0.1255
Epoch [7/50] - Loss: 0.1151
Epoch [8/50] - Loss: 0.1085
Epoch [9/50] - Loss: 0.1056
Epoch [10/50] - Loss: 0.0985
Epoch [11/50] - Loss: 0.0959
Epoch [12/50] - Loss: 0.0905
Epoch [13/50] - Loss: 0.0890
Epoch [14/50] - Loss: 0.0860
Epoch [15/50] - Loss: 0.0838
Epoch [16/50] - Loss: 0.0821
Epoch [17/50] - Loss: 0.0788
Epoch [18/50] - Loss: 0.0759
Epoch [19/50] - Loss: 0.0739
Epoch [20/50] - Loss: 0.0714
Epoch [21/50] - Loss: 0.0692
Epoch [22/50] - Loss: 0.0674
Epoch [23/50] - Loss: 0.0653
Epoch [24/50] - Loss: 0.0632
Epoch [25/50] - Loss: 0.0610
Epoch [26/50] - Loss: 0.0582
Epoch [27/50] - Loss: 0.0556
Epoch [28/50] - Loss: 0.0533
Epoch [29/50] - Loss: 0.0517
Epoch [30/50] - Loss: 0.0498
Epoch [31/50] - Loss: 0.0483
Epoch [32/50] - Loss: 0.0469
Epoch [33/50] - Loss: 0.0452
Epoch [34/50] - Loss: 0.0434
Epoch [35/50] - Loss: 0.0420
Epoch [36/50] - Loss: 0.0408
Epoch [37/50] - Loss: 0.0391
Epoch [38/50] - Loss: 0.0375
Epoch [39/50] - Loss: 0.0366
Epoch [40/50] - Loss: 0.0354
Epoch [41/50] - Loss: 0.0363
Epoch [42/50] - Loss: 0.0329
Epoch [43/50] - Loss: 0.0331
Epoch [44/50] - Loss: 0.0315
Epoch [45/50] - Loss: 0.0311
Epoch [46/50] - Loss: 0.0287
Epoch [47/50] - Loss: 0.0193
Epoch [48/50] - Loss: 0.0193
Epoch [49/50] - Loss: 0.0181
Epoch [50/50] - Loss: 0.0178
sum preds 2160
sum labels 1875
 - Test Metrics: Accuracy=0.9333, F1=0.8198, Recall=0.8821, Precision=0.7657
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_imbnnpu_imbnnpu_1904080017.csv.
Average F1 over valid seeds: 0.7732 ± 0.0330
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and imbnnpu, GATConv,0.3: 0.7732 ± 0.0330
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5306
Epoch [2/50] - Loss: 0.4441
Epoch [3/50] - Loss: 0.3663
Epoch [4/50] - Loss: 0.3075
Epoch [5/50] - Loss: 0.2643
Epoch [6/50] - Loss: 0.2320
Epoch [7/50] - Loss: 0.2073
Epoch [8/50] - Loss: 0.1881
Epoch [9/50] - Loss: 0.1732
Epoch [10/50] - Loss: 0.1614
Epoch [11/50] - Loss: 0.1516
Epoch [12/50] - Loss: 0.1435
Epoch [13/50] - Loss: 0.1366
Epoch [14/50] - Loss: 0.1305
Epoch [15/50] - Loss: 0.1251
Epoch [16/50] - Loss: 0.1202
Epoch [17/50] - Loss: 0.1157
Epoch [18/50] - Loss: 0.1115
Epoch [19/50] - Loss: 0.1075
Epoch [20/50] - Loss: 0.1037
Epoch [21/50] - Loss: 0.1000
Epoch [22/50] - Loss: 0.0964
Epoch [23/50] - Loss: 0.0929
Epoch [24/50] - Loss: 0.0894
Epoch [25/50] - Loss: 0.0859
Epoch [26/50] - Loss: 0.0824
Epoch [27/50] - Loss: 0.0789
Epoch [28/50] - Loss: 0.0754
Epoch [29/50] - Loss: 0.0721
Epoch [30/50] - Loss: 0.0691
Epoch [31/50] - Loss: 0.0664
Epoch [32/50] - Loss: 0.0641
Epoch [33/50] - Loss: 0.0622
Epoch [34/50] - Loss: 0.0606
Epoch [35/50] - Loss: 0.0591
Epoch [36/50] - Loss: 0.0578
Epoch [37/50] - Loss: 0.0566
Epoch [38/50] - Loss: 0.0555
Epoch [39/50] - Loss: 0.0544
Epoch [40/50] - Loss: 0.0534
Epoch [41/50] - Loss: 0.0523
Epoch [42/50] - Loss: 0.0513
Epoch [43/50] - Loss: 0.0502
Epoch [44/50] - Loss: 0.0491
Epoch [45/50] - Loss: 0.0480
Epoch [46/50] - Loss: 0.0470
Epoch [47/50] - Loss: 0.0459
Epoch [48/50] - Loss: 0.0450
Epoch [49/50] - Loss: 0.0440
Epoch [50/50] - Loss: 0.0432
sum preds 2194
sum labels 1875
 - Test Metrics: Accuracy=0.9417, F1=0.8439, Recall=0.9157, Precision=0.7826
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4907
Epoch [2/50] - Loss: 0.4037
Epoch [3/50] - Loss: 0.3337
Epoch [4/50] - Loss: 0.2839
Epoch [5/50] - Loss: 0.2473
Epoch [6/50] - Loss: 0.2197
Epoch [7/50] - Loss: 0.1982
Epoch [8/50] - Loss: 0.1811
Epoch [9/50] - Loss: 0.1672
Epoch [10/50] - Loss: 0.1556
Epoch [11/50] - Loss: 0.1458
Epoch [12/50] - Loss: 0.1374
Epoch [13/50] - Loss: 0.1301
Epoch [14/50] - Loss: 0.1236
Epoch [15/50] - Loss: 0.1179
Epoch [16/50] - Loss: 0.1127
Epoch [17/50] - Loss: 0.1079
Epoch [18/50] - Loss: 0.1036
Epoch [19/50] - Loss: 0.0995
Epoch [20/50] - Loss: 0.0958
Epoch [21/50] - Loss: 0.0923
Epoch [22/50] - Loss: 0.0891
Epoch [23/50] - Loss: 0.0862
Epoch [24/50] - Loss: 0.0835
Epoch [25/50] - Loss: 0.0811
Epoch [26/50] - Loss: 0.0789
Epoch [27/50] - Loss: 0.0769
Epoch [28/50] - Loss: 0.0750
Epoch [29/50] - Loss: 0.0732
Epoch [30/50] - Loss: 0.0715
Epoch [31/50] - Loss: 0.0699
Epoch [32/50] - Loss: 0.0683
Epoch [33/50] - Loss: 0.0668
Epoch [34/50] - Loss: 0.0653
Epoch [35/50] - Loss: 0.0639
Epoch [36/50] - Loss: 0.0627
Epoch [37/50] - Loss: 0.0616
Epoch [38/50] - Loss: 0.0606
Epoch [39/50] - Loss: 0.0596
Epoch [40/50] - Loss: 0.0588
Epoch [41/50] - Loss: 0.0579
Epoch [42/50] - Loss: 0.0571
Epoch [43/50] - Loss: 0.0563
Epoch [44/50] - Loss: 0.0555
Epoch [45/50] - Loss: 0.0547
Epoch [46/50] - Loss: 0.0538
Epoch [47/50] - Loss: 0.0530
Epoch [48/50] - Loss: 0.0522
Epoch [49/50] - Loss: 0.0513
Epoch [50/50] - Loss: 0.0504
sum preds 2230
sum labels 1875
 - Test Metrics: Accuracy=0.9364, F1=0.8312, Recall=0.9099, Precision=0.7650
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4392
Epoch [2/50] - Loss: 0.3668
Epoch [3/50] - Loss: 0.3081
Epoch [4/50] - Loss: 0.2622
Epoch [5/50] - Loss: 0.2269
Epoch [6/50] - Loss: 0.2000
Epoch [7/50] - Loss: 0.1792
Epoch [8/50] - Loss: 0.1627
Epoch [9/50] - Loss: 0.1493
Epoch [10/50] - Loss: 0.1382
Epoch [11/50] - Loss: 0.1288
Epoch [12/50] - Loss: 0.1207
Epoch [13/50] - Loss: 0.1135
Epoch [14/50] - Loss: 0.1072
Epoch [15/50] - Loss: 0.1015
Epoch [16/50] - Loss: 0.0965
Epoch [17/50] - Loss: 0.0920
Epoch [18/50] - Loss: 0.0879
Epoch [19/50] - Loss: 0.0843
Epoch [20/50] - Loss: 0.0809
Epoch [21/50] - Loss: 0.0779
Epoch [22/50] - Loss: 0.0750
Epoch [23/50] - Loss: 0.0724
Epoch [24/50] - Loss: 0.0700
Epoch [25/50] - Loss: 0.0678
Epoch [26/50] - Loss: 0.0656
Epoch [27/50] - Loss: 0.0637
Epoch [28/50] - Loss: 0.0618
Epoch [29/50] - Loss: 0.0600
Epoch [30/50] - Loss: 0.0584
Epoch [31/50] - Loss: 0.0569
Epoch [32/50] - Loss: 0.0555
Epoch [33/50] - Loss: 0.0542
Epoch [34/50] - Loss: 0.0530
Epoch [35/50] - Loss: 0.0518
Epoch [36/50] - Loss: 0.0507
Epoch [37/50] - Loss: 0.0496
Epoch [38/50] - Loss: 0.0485
Epoch [39/50] - Loss: 0.0474
Epoch [40/50] - Loss: 0.0463
Epoch [41/50] - Loss: 0.0452
Epoch [42/50] - Loss: 0.0442
Epoch [43/50] - Loss: 0.0431
Epoch [44/50] - Loss: 0.0421
Epoch [45/50] - Loss: 0.0411
Epoch [46/50] - Loss: 0.0401
Epoch [47/50] - Loss: 0.0392
Epoch [48/50] - Loss: 0.0384
Epoch [49/50] - Loss: 0.0376
Epoch [50/50] - Loss: 0.0368
sum preds 2140
sum labels 1875
 - Test Metrics: Accuracy=0.9432, F1=0.8458, Recall=0.9056, Precision=0.7935
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_imbnnpu_imbnnpu_1904080020.csv.
Average F1 over valid seeds: 0.8403 ± 0.0065
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and imbnnpu, GCNConv,0.3: 0.8403 ± 0.0065
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4983
Epoch [2/50] - Loss: 0.4234
Epoch [3/50] - Loss: 0.3571
Epoch [4/50] - Loss: 0.3034
Epoch [5/50] - Loss: 0.2629
Epoch [6/50] - Loss: 0.2331
Epoch [7/50] - Loss: 0.2105
Epoch [8/50] - Loss: 0.1927
Epoch [9/50] - Loss: 0.1783
Epoch [10/50] - Loss: 0.1662
Epoch [11/50] - Loss: 0.1558
Epoch [12/50] - Loss: 0.1466
Epoch [13/50] - Loss: 0.1384
Epoch [14/50] - Loss: 0.1310
Epoch [15/50] - Loss: 0.1243
Epoch [16/50] - Loss: 0.1180
Epoch [17/50] - Loss: 0.1121
Epoch [18/50] - Loss: 0.1064
Epoch [19/50] - Loss: 0.1011
Epoch [20/50] - Loss: 0.0960
Epoch [21/50] - Loss: 0.0912
Epoch [22/50] - Loss: 0.0867
Epoch [23/50] - Loss: 0.0825
Epoch [24/50] - Loss: 0.0786
Epoch [25/50] - Loss: 0.0751
Epoch [26/50] - Loss: 0.0719
Epoch [27/50] - Loss: 0.0690
Epoch [28/50] - Loss: 0.0662
Epoch [29/50] - Loss: 0.0636
Epoch [30/50] - Loss: 0.0612
Epoch [31/50] - Loss: 0.0589
Epoch [32/50] - Loss: 0.0568
Epoch [33/50] - Loss: 0.0547
Epoch [34/50] - Loss: 0.0527
Epoch [35/50] - Loss: 0.0508
Epoch [36/50] - Loss: 0.0489
Epoch [37/50] - Loss: 0.0471
Epoch [38/50] - Loss: 0.0453
Epoch [39/50] - Loss: 0.0437
Epoch [40/50] - Loss: 0.0421
Epoch [41/50] - Loss: 0.0406
Epoch [42/50] - Loss: 0.0393
Epoch [43/50] - Loss: 0.0380
Epoch [44/50] - Loss: 0.0368
Epoch [45/50] - Loss: 0.0356
Epoch [46/50] - Loss: 0.0344
Epoch [47/50] - Loss: 0.0332
Epoch [48/50] - Loss: 0.0321
Epoch [49/50] - Loss: 0.0310
Epoch [50/50] - Loss: 0.0300
sum preds 2432
sum labels 2143
 - Test Metrics: Accuracy=0.9249, F1=0.8166, Recall=0.8717, Precision=0.7681
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5132
Epoch [2/50] - Loss: 0.4516
Epoch [3/50] - Loss: 0.3976
Epoch [4/50] - Loss: 0.3526
Epoch [5/50] - Loss: 0.3158
Epoch [6/50] - Loss: 0.2855
Epoch [7/50] - Loss: 0.2604
Epoch [8/50] - Loss: 0.2393
Epoch [9/50] - Loss: 0.2213
Epoch [10/50] - Loss: 0.2060
Epoch [11/50] - Loss: 0.1930
Epoch [12/50] - Loss: 0.1817
Epoch [13/50] - Loss: 0.1719
Epoch [14/50] - Loss: 0.1633
Epoch [15/50] - Loss: 0.1557
Epoch [16/50] - Loss: 0.1489
Epoch [17/50] - Loss: 0.1427
Epoch [18/50] - Loss: 0.1371
Epoch [19/50] - Loss: 0.1320
Epoch [20/50] - Loss: 0.1273
Epoch [21/50] - Loss: 0.1230
Epoch [22/50] - Loss: 0.1190
Epoch [23/50] - Loss: 0.1153
Epoch [24/50] - Loss: 0.1118
Epoch [25/50] - Loss: 0.1086
Epoch [26/50] - Loss: 0.1054
Epoch [27/50] - Loss: 0.1025
Epoch [28/50] - Loss: 0.0996
Epoch [29/50] - Loss: 0.0968
Epoch [30/50] - Loss: 0.0940
Epoch [31/50] - Loss: 0.0912
Epoch [32/50] - Loss: 0.0884
Epoch [33/50] - Loss: 0.0856
Epoch [34/50] - Loss: 0.0829
Epoch [35/50] - Loss: 0.0802
Epoch [36/50] - Loss: 0.0776
Epoch [37/50] - Loss: 0.0751
Epoch [38/50] - Loss: 0.0727
Epoch [39/50] - Loss: 0.0703
Epoch [40/50] - Loss: 0.0680
Epoch [41/50] - Loss: 0.0657
Epoch [42/50] - Loss: 0.0635
Epoch [43/50] - Loss: 0.0613
Epoch [44/50] - Loss: 0.0593
Epoch [45/50] - Loss: 0.0573
Epoch [46/50] - Loss: 0.0555
Epoch [47/50] - Loss: 0.0537
Epoch [48/50] - Loss: 0.0521
Epoch [49/50] - Loss: 0.0505
Epoch [50/50] - Loss: 0.0490
sum preds 2598
sum labels 2143
 - Test Metrics: Accuracy=0.9166, F1=0.8036, Recall=0.8889, Precision=0.7333
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5064
Epoch [2/50] - Loss: 0.4329
Epoch [3/50] - Loss: 0.3729
Epoch [4/50] - Loss: 0.3238
Epoch [5/50] - Loss: 0.2845
Epoch [6/50] - Loss: 0.2537
Epoch [7/50] - Loss: 0.2296
Epoch [8/50] - Loss: 0.2107
Epoch [9/50] - Loss: 0.1955
Epoch [10/50] - Loss: 0.1830
Epoch [11/50] - Loss: 0.1723
Epoch [12/50] - Loss: 0.1628
Epoch [13/50] - Loss: 0.1543
Epoch [14/50] - Loss: 0.1465
Epoch [15/50] - Loss: 0.1394
Epoch [16/50] - Loss: 0.1328
Epoch [17/50] - Loss: 0.1268
Epoch [18/50] - Loss: 0.1212
Epoch [19/50] - Loss: 0.1160
Epoch [20/50] - Loss: 0.1112
Epoch [21/50] - Loss: 0.1067
Epoch [22/50] - Loss: 0.1025
Epoch [23/50] - Loss: 0.0988
Epoch [24/50] - Loss: 0.0953
Epoch [25/50] - Loss: 0.0921
Epoch [26/50] - Loss: 0.0891
Epoch [27/50] - Loss: 0.0863
Epoch [28/50] - Loss: 0.0837
Epoch [29/50] - Loss: 0.0813
Epoch [30/50] - Loss: 0.0790
Epoch [31/50] - Loss: 0.0769
Epoch [32/50] - Loss: 0.0747
Epoch [33/50] - Loss: 0.0727
Epoch [34/50] - Loss: 0.0706
Epoch [35/50] - Loss: 0.0687
Epoch [36/50] - Loss: 0.0667
Epoch [37/50] - Loss: 0.0649
Epoch [38/50] - Loss: 0.0631
Epoch [39/50] - Loss: 0.0614
Epoch [40/50] - Loss: 0.0598
Epoch [41/50] - Loss: 0.0582
Epoch [42/50] - Loss: 0.0567
Epoch [43/50] - Loss: 0.0552
Epoch [44/50] - Loss: 0.0538
Epoch [45/50] - Loss: 0.0525
Epoch [46/50] - Loss: 0.0511
Epoch [47/50] - Loss: 0.0499
Epoch [48/50] - Loss: 0.0486
Epoch [49/50] - Loss: 0.0474
Epoch [50/50] - Loss: 0.0463
sum preds 2499
sum labels 2143
 - Test Metrics: Accuracy=0.9242, F1=0.8178, Recall=0.8857, Precision=0.7595
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_imbnnpu_imbnnpu_1904080023.csv.
Average F1 over valid seeds: 0.8127 ± 0.0064
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and imbnnpu, MLP,0.2: 0.8127 ± 0.0064
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4444
Epoch [2/50] - Loss: 0.3590
Epoch [3/50] - Loss: 0.3082
Epoch [4/50] - Loss: 0.2643
Epoch [5/50] - Loss: 0.2507
Epoch [6/50] - Loss: 0.2639
Epoch [7/50] - Loss: 0.2518
Epoch [8/50] - Loss: 0.2380
Epoch [9/50] - Loss: 0.2242
Epoch [10/50] - Loss: 0.2097
Epoch [11/50] - Loss: 0.1996
Epoch [12/50] - Loss: 0.1933
Epoch [13/50] - Loss: 0.1846
Epoch [14/50] - Loss: 0.1778
Epoch [15/50] - Loss: 0.1719
Epoch [16/50] - Loss: 0.1624
Epoch [17/50] - Loss: 0.1580
Epoch [18/50] - Loss: 0.1534
Epoch [19/50] - Loss: 0.1493
Epoch [20/50] - Loss: 0.1465
Epoch [21/50] - Loss: 0.1413
Epoch [22/50] - Loss: 0.1374
Epoch [23/50] - Loss: 0.1345
Epoch [24/50] - Loss: 0.1312
Epoch [25/50] - Loss: 0.1285
Epoch [26/50] - Loss: 0.1255
Epoch [27/50] - Loss: 0.1224
Epoch [28/50] - Loss: 0.1191
Epoch [29/50] - Loss: 0.1168
Epoch [30/50] - Loss: 0.1143
Epoch [31/50] - Loss: 0.1116
Epoch [32/50] - Loss: 0.1094
Epoch [33/50] - Loss: 0.1074
Epoch [34/50] - Loss: 0.1055
Epoch [35/50] - Loss: 0.1038
Epoch [36/50] - Loss: 0.1032
Epoch [37/50] - Loss: 0.1013
Epoch [38/50] - Loss: 0.0896
Epoch [39/50] - Loss: 0.0877
Epoch [40/50] - Loss: 0.0894
Epoch [41/50] - Loss: 0.0841
Epoch [42/50] - Loss: 0.0823
Epoch [43/50] - Loss: 0.0807
Epoch [44/50] - Loss: 0.0778
Epoch [45/50] - Loss: 0.0744
Epoch [46/50] - Loss: 0.0715
Epoch [47/50] - Loss: 0.0700
Epoch [48/50] - Loss: 0.0691
Epoch [49/50] - Loss: 0.0669
Epoch [50/50] - Loss: 0.0641
sum preds 2639
sum labels 2143
 - Test Metrics: Accuracy=0.8991, F1=0.7645, Recall=0.8530, Precision=0.6927
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5250
Epoch [2/50] - Loss: 0.4010
Epoch [3/50] - Loss: 0.3091
Epoch [4/50] - Loss: 0.2493
Epoch [5/50] - Loss: 0.2076
Epoch [6/50] - Loss: 0.1704
Epoch [7/50] - Loss: 0.1475
Epoch [8/50] - Loss: 0.1352
Epoch [9/50] - Loss: 0.1322
Epoch [10/50] - Loss: 0.1268
Epoch [11/50] - Loss: 0.1244
Epoch [12/50] - Loss: 0.1194
Epoch [13/50] - Loss: 0.1151
Epoch [14/50] - Loss: 0.1133
Epoch [15/50] - Loss: 0.1104
Epoch [16/50] - Loss: 0.1080
Epoch [17/50] - Loss: 0.1064
Epoch [18/50] - Loss: 0.1048
Epoch [19/50] - Loss: 0.1018
Epoch [20/50] - Loss: 0.1016
Epoch [21/50] - Loss: 0.0950
Epoch [22/50] - Loss: 0.0927
Epoch [23/50] - Loss: 0.0911
Epoch [24/50] - Loss: 0.0886
Epoch [25/50] - Loss: 0.0874
Epoch [26/50] - Loss: 0.0853
Epoch [27/50] - Loss: 0.0836
Epoch [28/50] - Loss: 0.0820
Epoch [29/50] - Loss: 0.0796
Epoch [30/50] - Loss: 0.0783
Epoch [31/50] - Loss: 0.0775
Epoch [32/50] - Loss: 0.0752
Epoch [33/50] - Loss: 0.0743
Epoch [34/50] - Loss: 0.0724
Epoch [35/50] - Loss: 0.0695
Epoch [36/50] - Loss: 0.0692
Epoch [37/50] - Loss: 0.0677
Epoch [38/50] - Loss: 0.0646
Epoch [39/50] - Loss: 0.0659
Epoch [40/50] - Loss: 0.0619
Epoch [41/50] - Loss: 0.0605
Epoch [42/50] - Loss: 0.0600
Epoch [43/50] - Loss: 0.0584
Epoch [44/50] - Loss: 0.0564
Epoch [45/50] - Loss: 0.0563
Epoch [46/50] - Loss: 0.0558
Epoch [47/50] - Loss: 0.0547
Epoch [48/50] - Loss: 0.0535
Epoch [49/50] - Loss: 0.0533
Epoch [50/50] - Loss: 0.0518
sum preds 2668
sum labels 2143
 - Test Metrics: Accuracy=0.9114, F1=0.7944, Recall=0.8917, Precision=0.7163
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4721
Epoch [2/50] - Loss: 0.3501
Epoch [3/50] - Loss: 0.2657
Epoch [4/50] - Loss: 0.2018
Epoch [5/50] - Loss: 0.1609
Epoch [6/50] - Loss: 0.1382
Epoch [7/50] - Loss: 0.1276
Epoch [8/50] - Loss: 0.1205
Epoch [9/50] - Loss: 0.1169
Epoch [10/50] - Loss: 0.1104
Epoch [11/50] - Loss: 0.1062
Epoch [12/50] - Loss: 0.1005
Epoch [13/50] - Loss: 0.0964
Epoch [14/50] - Loss: 0.0932
Epoch [15/50] - Loss: 0.0897
Epoch [16/50] - Loss: 0.0863
Epoch [17/50] - Loss: 0.0833
Epoch [18/50] - Loss: 0.0798
Epoch [19/50] - Loss: 0.0756
Epoch [20/50] - Loss: 0.0730
Epoch [21/50] - Loss: 0.0708
Epoch [22/50] - Loss: 0.0687
Epoch [23/50] - Loss: 0.0664
Epoch [24/50] - Loss: 0.0616
Epoch [25/50] - Loss: 0.0585
Epoch [26/50] - Loss: 0.0519
Epoch [27/50] - Loss: 0.0524
Epoch [28/50] - Loss: 0.0500
Epoch [29/50] - Loss: 0.0475
Epoch [30/50] - Loss: 0.0479
Epoch [31/50] - Loss: 0.0447
Epoch [32/50] - Loss: 0.0438
Epoch [33/50] - Loss: 0.0429
Epoch [34/50] - Loss: 0.0408
Epoch [35/50] - Loss: 0.0401
Epoch [36/50] - Loss: 0.0392
Epoch [37/50] - Loss: 0.0376
Epoch [38/50] - Loss: 0.0369
Epoch [39/50] - Loss: 0.0358
Epoch [40/50] - Loss: 0.0343
Epoch [41/50] - Loss: 0.0336
Epoch [42/50] - Loss: 0.0329
Epoch [43/50] - Loss: 0.0315
Epoch [44/50] - Loss: 0.0308
Epoch [45/50] - Loss: 0.0298
Epoch [46/50] - Loss: 0.0285
Epoch [47/50] - Loss: 0.0280
Epoch [48/50] - Loss: 0.0268
Epoch [49/50] - Loss: 0.0260
Epoch [50/50] - Loss: 0.0253
sum preds 2422
sum labels 2143
 - Test Metrics: Accuracy=0.9288, F1=0.8258, Recall=0.8796, Precision=0.7783
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_imbnnpu_imbnnpu_1904080025.csv.
Average F1 over valid seeds: 0.7949 ± 0.0250
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and imbnnpu, GATConv,0.2: 0.7949 ± 0.0250
___________________________________________________________________________________
imbnnpu
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.5290
Epoch [2/50] - Loss: 0.4433
Epoch [3/50] - Loss: 0.3667
Epoch [4/50] - Loss: 0.3094
Epoch [5/50] - Loss: 0.2671
Epoch [6/50] - Loss: 0.2356
Epoch [7/50] - Loss: 0.2113
Epoch [8/50] - Loss: 0.1925
Epoch [9/50] - Loss: 0.1777
Epoch [10/50] - Loss: 0.1658
Epoch [11/50] - Loss: 0.1561
Epoch [12/50] - Loss: 0.1480
Epoch [13/50] - Loss: 0.1412
Epoch [14/50] - Loss: 0.1351
Epoch [15/50] - Loss: 0.1297
Epoch [16/50] - Loss: 0.1249
Epoch [17/50] - Loss: 0.1204
Epoch [18/50] - Loss: 0.1162
Epoch [19/50] - Loss: 0.1122
Epoch [20/50] - Loss: 0.1085
Epoch [21/50] - Loss: 0.1049
Epoch [22/50] - Loss: 0.1014
Epoch [23/50] - Loss: 0.0980
Epoch [24/50] - Loss: 0.0947
Epoch [25/50] - Loss: 0.0915
Epoch [26/50] - Loss: 0.0883
Epoch [27/50] - Loss: 0.0852
Epoch [28/50] - Loss: 0.0822
Epoch [29/50] - Loss: 0.0792
Epoch [30/50] - Loss: 0.0763
Epoch [31/50] - Loss: 0.0734
Epoch [32/50] - Loss: 0.0707
Epoch [33/50] - Loss: 0.0682
Epoch [34/50] - Loss: 0.0661
Epoch [35/50] - Loss: 0.0643
Epoch [36/50] - Loss: 0.0628
Epoch [37/50] - Loss: 0.0615
Epoch [38/50] - Loss: 0.0603
Epoch [39/50] - Loss: 0.0592
Epoch [40/50] - Loss: 0.0581
Epoch [41/50] - Loss: 0.0571
Epoch [42/50] - Loss: 0.0561
Epoch [43/50] - Loss: 0.0551
Epoch [44/50] - Loss: 0.0541
Epoch [45/50] - Loss: 0.0531
Epoch [46/50] - Loss: 0.0521
Epoch [47/50] - Loss: 0.0511
Epoch [48/50] - Loss: 0.0502
Epoch [49/50] - Loss: 0.0493
Epoch [50/50] - Loss: 0.0484
sum preds 2410
sum labels 2143
 - Test Metrics: Accuracy=0.9422, F1=0.8583, Recall=0.9118, Precision=0.8108
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4915
Epoch [2/50] - Loss: 0.4072
Epoch [3/50] - Loss: 0.3388
Epoch [4/50] - Loss: 0.2900
Epoch [5/50] - Loss: 0.2542
Epoch [6/50] - Loss: 0.2273
Epoch [7/50] - Loss: 0.2064
Epoch [8/50] - Loss: 0.1898
Epoch [9/50] - Loss: 0.1762
Epoch [10/50] - Loss: 0.1648
Epoch [11/50] - Loss: 0.1551
Epoch [12/50] - Loss: 0.1467
Epoch [13/50] - Loss: 0.1394
Epoch [14/50] - Loss: 0.1330
Epoch [15/50] - Loss: 0.1272
Epoch [16/50] - Loss: 0.1220
Epoch [17/50] - Loss: 0.1173
Epoch [18/50] - Loss: 0.1129
Epoch [19/50] - Loss: 0.1089
Epoch [20/50] - Loss: 0.1052
Epoch [21/50] - Loss: 0.1019
Epoch [22/50] - Loss: 0.0987
Epoch [23/50] - Loss: 0.0959
Epoch [24/50] - Loss: 0.0932
Epoch [25/50] - Loss: 0.0907
Epoch [26/50] - Loss: 0.0885
Epoch [27/50] - Loss: 0.0863
Epoch [28/50] - Loss: 0.0843
Epoch [29/50] - Loss: 0.0825
Epoch [30/50] - Loss: 0.0807
Epoch [31/50] - Loss: 0.0791
Epoch [32/50] - Loss: 0.0776
Epoch [33/50] - Loss: 0.0764
Epoch [34/50] - Loss: 0.0752
Epoch [35/50] - Loss: 0.0742
Epoch [36/50] - Loss: 0.0733
Epoch [37/50] - Loss: 0.0724
Epoch [38/50] - Loss: 0.0715
Epoch [39/50] - Loss: 0.0706
Epoch [40/50] - Loss: 0.0697
Epoch [41/50] - Loss: 0.0688
Epoch [42/50] - Loss: 0.0679
Epoch [43/50] - Loss: 0.0670
Epoch [44/50] - Loss: 0.0662
Epoch [45/50] - Loss: 0.0653
Epoch [46/50] - Loss: 0.0645
Epoch [47/50] - Loss: 0.0638
Epoch [48/50] - Loss: 0.0631
Epoch [49/50] - Loss: 0.0624
Epoch [50/50] - Loss: 0.0617
sum preds 2540
sum labels 2143
 - Test Metrics: Accuracy=0.9326, F1=0.8392, Recall=0.9169, Precision=0.7736
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=imbnnpu
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 0.4399
Epoch [2/50] - Loss: 0.3696
Epoch [3/50] - Loss: 0.3128
Epoch [4/50] - Loss: 0.2685
Epoch [5/50] - Loss: 0.2343
Epoch [6/50] - Loss: 0.2082
Epoch [7/50] - Loss: 0.1878
Epoch [8/50] - Loss: 0.1716
Epoch [9/50] - Loss: 0.1585
Epoch [10/50] - Loss: 0.1475
Epoch [11/50] - Loss: 0.1383
Epoch [12/50] - Loss: 0.1302
Epoch [13/50] - Loss: 0.1232
Epoch [14/50] - Loss: 0.1169
Epoch [15/50] - Loss: 0.1113
Epoch [16/50] - Loss: 0.1063
Epoch [17/50] - Loss: 0.1017
Epoch [18/50] - Loss: 0.0975
Epoch [19/50] - Loss: 0.0938
Epoch [20/50] - Loss: 0.0903
Epoch [21/50] - Loss: 0.0872
Epoch [22/50] - Loss: 0.0843
Epoch [23/50] - Loss: 0.0817
Epoch [24/50] - Loss: 0.0792
Epoch [25/50] - Loss: 0.0770
Epoch [26/50] - Loss: 0.0749
Epoch [27/50] - Loss: 0.0729
Epoch [28/50] - Loss: 0.0710
Epoch [29/50] - Loss: 0.0691
Epoch [30/50] - Loss: 0.0674
Epoch [31/50] - Loss: 0.0658
Epoch [32/50] - Loss: 0.0643
Epoch [33/50] - Loss: 0.0629
Epoch [34/50] - Loss: 0.0616
Epoch [35/50] - Loss: 0.0603
Epoch [36/50] - Loss: 0.0592
Epoch [37/50] - Loss: 0.0581
Epoch [38/50] - Loss: 0.0570
Epoch [39/50] - Loss: 0.0560
Epoch [40/50] - Loss: 0.0550
Epoch [41/50] - Loss: 0.0539
Epoch [42/50] - Loss: 0.0528
Epoch [43/50] - Loss: 0.0516
Epoch [44/50] - Loss: 0.0504
Epoch [45/50] - Loss: 0.0492
Epoch [46/50] - Loss: 0.0480
Epoch [47/50] - Loss: 0.0469
Epoch [48/50] - Loss: 0.0458
Epoch [49/50] - Loss: 0.0448
Epoch [50/50] - Loss: 0.0439
sum preds 2389
sum labels 2143
 - Test Metrics: Accuracy=0.9436, F1=0.8610, Recall=0.9104, Precision=0.8167
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_imbnnpu_imbnnpu_1904080028.csv.
Average F1 over valid seeds: 0.8528 ± 0.0097
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and imbnnpu, GCNConv,0.2: 0.8528 ± 0.0097
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=6, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 22.7402
Epoch 10 / 50, Loss: 20.1259
Epoch 20 / 50, Loss: 17.1819
Epoch 30 / 50, Loss: 14.1325
Epoch 40 / 50, Loss: 11.4513
sum preds 572.0
sum labels 1607
 - Test Metrics: Accuracy=0.8989, F1=0.5067, Recall=0.3435, Precision=0.9650
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=6, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 22.7342
Epoch 10 / 50, Loss: 19.9121
Epoch 20 / 50, Loss: 16.8211
Epoch 30 / 50, Loss: 13.8468
Epoch 40 / 50, Loss: 11.2902
sum preds 590.0
sum labels 1607
 - Test Metrics: Accuracy=0.8981, F1=0.5071, Recall=0.3466, Precision=0.9441
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=6, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 22.3154
Epoch 10 / 50, Loss: 19.5624
Epoch 20 / 50, Loss: 16.8364
Epoch 30 / 50, Loss: 13.6882
Epoch 40 / 50, Loss: 11.1698
sum preds 586.0
sum labels 1607
 - Test Metrics: Accuracy=0.8964, F1=0.4979, Recall=0.3398, Precision=0.9317
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_ours_1904080031.csv.
Average F1 over valid seeds: 0.5039 ± 0.0042
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and ours, GCNConv,0.4: 0.5039 ± 0.0042
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=6, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 25.9774
Epoch 10 / 50, Loss: 22.9332
Epoch 20 / 50, Loss: 19.4168
Epoch 30 / 50, Loss: 15.7985
Epoch 40 / 50, Loss: 12.7954
sum preds 684.0
sum labels 1875
 - Test Metrics: Accuracy=0.8861, F1=0.5150, Recall=0.3515, Precision=0.9635
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=6, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 26.0126
Epoch 10 / 50, Loss: 22.6413
Epoch 20 / 50, Loss: 18.9340
Epoch 30 / 50, Loss: 15.5521
Epoch 40 / 50, Loss: 12.6443
sum preds 593.0
sum labels 1875
 - Test Metrics: Accuracy=0.8767, F1=0.4554, Recall=0.2997, Precision=0.9477
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=6, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 25.3285
Epoch 10 / 50, Loss: 22.0878
Epoch 20 / 50, Loss: 18.7743
Epoch 30 / 50, Loss: 15.3145
Epoch 40 / 50, Loss: 12.3566
sum preds 643.0
sum labels 1875
 - Test Metrics: Accuracy=0.8825, F1=0.4917, Recall=0.3301, Precision=0.9627
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_ours_1904080353.csv.
Average F1 over valid seeds: 0.4874 ± 0.0245
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and ours, GCNConv,0.3: 0.4874 ± 0.0245
___________________________________________________________________________________
ours
Running experiment with seed=654:
 - K=6, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 30.4770
Epoch 10 / 50, Loss: 26.4707
Epoch 20 / 50, Loss: 22.1595
Epoch 30 / 50, Loss: 18.0036
Epoch 40 / 50, Loss: 14.5660
sum preds 583.0
sum labels 2143
 - Test Metrics: Accuracy=0.8565, F1=0.4123, Recall=0.2622, Precision=0.9640
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=6, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 29.7884
Epoch 10 / 50, Loss: 25.5055
Epoch 20 / 50, Loss: 21.2808
Epoch 30 / 50, Loss: 17.3332
Epoch 40 / 50, Loss: 14.1008
sum preds 469.0
sum labels 2143
 - Test Metrics: Accuracy=0.8476, F1=0.3484, Recall=0.2123, Precision=0.9701
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=6, layers=2, hidden=256, out=256
 - norm=None, dropout=0, batch_size=2048, methodology=ours
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch 0 / 50, Loss: 29.6233
Epoch 10 / 50, Loss: 25.6227
Epoch 20 / 50, Loss: 21.3391
Epoch 30 / 50, Loss: 17.3801
Epoch 40 / 50, Loss: 14.0843
sum preds 485.0
sum labels 2143
 - Test Metrics: Accuracy=0.8492, F1=0.3592, Recall=0.2203, Precision=0.9732
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SCAR_ours_1904080648.csv.
Average F1 over valid seeds: 0.3733 ± 0.0279
___________________________________________________________________________________
Avg F1 for wiki-cs with SCAR and ours, GCNConv,0.2: 0.3733 ± 0.0279
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.1860
Epoch [2/50] - Loss: 1.6040
Epoch [3/50] - Loss: 1.3978
Epoch [4/50] - Loss: 1.3150
Epoch [5/50] - Loss: 1.2317
Epoch [6/50] - Loss: 1.1831
Epoch [7/50] - Loss: 1.1492
Epoch [8/50] - Loss: 1.1163
Epoch [9/50] - Loss: 1.0887
Epoch [10/50] - Loss: 1.0653
Epoch [11/50] - Loss: 1.0418
Epoch [12/50] - Loss: 1.0198
Epoch [13/50] - Loss: 0.9973
Epoch [14/50] - Loss: 0.9752
Epoch [15/50] - Loss: 0.9529
Epoch [16/50] - Loss: 0.9305
Epoch [17/50] - Loss: 0.9093
Epoch [18/50] - Loss: 0.8859
Epoch [19/50] - Loss: 0.8634
Epoch [20/50] - Loss: 0.8404
Epoch [21/50] - Loss: 0.8175
Epoch [22/50] - Loss: 0.7956
Epoch [23/50] - Loss: 0.7733
Epoch [24/50] - Loss: 0.7504
Epoch [25/50] - Loss: 0.7282
Epoch [26/50] - Loss: 0.7048
Epoch [27/50] - Loss: 0.6835
Epoch [28/50] - Loss: 0.6605
Epoch [29/50] - Loss: 0.6402
Epoch [30/50] - Loss: 0.6198
Epoch [31/50] - Loss: 0.5989
Epoch [32/50] - Loss: 0.5795
Epoch [33/50] - Loss: 0.5613
Epoch [34/50] - Loss: 0.5428
Epoch [35/50] - Loss: 0.5258
Epoch [36/50] - Loss: 0.5105
Epoch [37/50] - Loss: 0.4934
Epoch [38/50] - Loss: 0.4792
Epoch [39/50] - Loss: 0.4646
Epoch [40/50] - Loss: 0.4495
Epoch [41/50] - Loss: 0.4348
Epoch [42/50] - Loss: 0.4227
Epoch [43/50] - Loss: 0.4096
Epoch [44/50] - Loss: 0.3971
Epoch [45/50] - Loss: 0.3875
Epoch [46/50] - Loss: 0.3757
Epoch [47/50] - Loss: 0.3642
Epoch [48/50] - Loss: 0.3533
Epoch [49/50] - Loss: 0.3423
Epoch [50/50] - Loss: 0.3326
sum preds 66
sum labels 1607
 - Test Metrics: Accuracy=0.8537, F1=0.0705, Recall=0.0367, Precision=0.8939
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.6954
Epoch [2/50] - Loss: 1.5312
Epoch [3/50] - Loss: 1.3575
Epoch [4/50] - Loss: 1.2797
Epoch [5/50] - Loss: 1.2141
Epoch [6/50] - Loss: 1.1663
Epoch [7/50] - Loss: 1.1322
Epoch [8/50] - Loss: 1.1022
Epoch [9/50] - Loss: 1.0761
Epoch [10/50] - Loss: 1.0522
Epoch [11/50] - Loss: 1.0265
Epoch [12/50] - Loss: 1.0031
Epoch [13/50] - Loss: 0.9780
Epoch [14/50] - Loss: 0.9538
Epoch [15/50] - Loss: 0.9291
Epoch [16/50] - Loss: 0.9054
Epoch [17/50] - Loss: 0.8816
Epoch [18/50] - Loss: 0.8573
Epoch [19/50] - Loss: 0.8329
Epoch [20/50] - Loss: 0.8098
Epoch [21/50] - Loss: 0.7846
Epoch [22/50] - Loss: 0.7615
Epoch [23/50] - Loss: 0.7378
Epoch [24/50] - Loss: 0.7127
Epoch [25/50] - Loss: 0.6891
Epoch [26/50] - Loss: 0.6652
Epoch [27/50] - Loss: 0.6404
Epoch [28/50] - Loss: 0.6169
Epoch [29/50] - Loss: 0.5934
Epoch [30/50] - Loss: 0.5687
Epoch [31/50] - Loss: 0.5473
Epoch [32/50] - Loss: 0.5254
Epoch [33/50] - Loss: 0.5047
Epoch [34/50] - Loss: 0.4848
Epoch [35/50] - Loss: 0.4647
Epoch [36/50] - Loss: 0.4456
Epoch [37/50] - Loss: 0.4270
Epoch [38/50] - Loss: 0.4082
Epoch [39/50] - Loss: 0.3921
Epoch [40/50] - Loss: 0.3772
Epoch [41/50] - Loss: 0.3613
Epoch [42/50] - Loss: 0.3482
Epoch [43/50] - Loss: 0.3360
Epoch [44/50] - Loss: 0.3211
Epoch [45/50] - Loss: 0.3081
Epoch [46/50] - Loss: 0.2965
Epoch [47/50] - Loss: 0.2848
Epoch [48/50] - Loss: 0.2738
Epoch [49/50] - Loss: 0.2638
Epoch [50/50] - Loss: 0.2553
sum preds 34
sum labels 1607
 - Test Metrics: Accuracy=0.8507, F1=0.0329, Recall=0.0168, Precision=0.7941
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1083
Epoch [2/50] - Loss: 1.3986
Epoch [3/50] - Loss: 1.2719
Epoch [4/50] - Loss: 1.1951
Epoch [5/50] - Loss: 1.1551
Epoch [6/50] - Loss: 1.1235
Epoch [7/50] - Loss: 1.0978
Epoch [8/50] - Loss: 1.0724
Epoch [9/50] - Loss: 1.0480
Epoch [10/50] - Loss: 1.0227
Epoch [11/50] - Loss: 0.9965
Epoch [12/50] - Loss: 0.9695
Epoch [13/50] - Loss: 0.9395
Epoch [14/50] - Loss: 0.9086
Epoch [15/50] - Loss: 0.8778
Epoch [16/50] - Loss: 0.8475
Epoch [17/50] - Loss: 0.8183
Epoch [18/50] - Loss: 0.7896
Epoch [19/50] - Loss: 0.7621
Epoch [20/50] - Loss: 0.7361
Epoch [21/50] - Loss: 0.7111
Epoch [22/50] - Loss: 0.6875
Epoch [23/50] - Loss: 0.6634
Epoch [24/50] - Loss: 0.6405
Epoch [25/50] - Loss: 0.6177
Epoch [26/50] - Loss: 0.5956
Epoch [27/50] - Loss: 0.5725
Epoch [28/50] - Loss: 0.5517
Epoch [29/50] - Loss: 0.5305
Epoch [30/50] - Loss: 0.5091
Epoch [31/50] - Loss: 0.4892
Epoch [32/50] - Loss: 0.4692
Epoch [33/50] - Loss: 0.4516
Epoch [34/50] - Loss: 0.4345
Epoch [35/50] - Loss: 0.4163
Epoch [36/50] - Loss: 0.4010
Epoch [37/50] - Loss: 0.3861
Epoch [38/50] - Loss: 0.3707
Epoch [39/50] - Loss: 0.3558
Epoch [40/50] - Loss: 0.3422
Epoch [41/50] - Loss: 0.3283
Epoch [42/50] - Loss: 0.3164
Epoch [43/50] - Loss: 0.3041
Epoch [44/50] - Loss: 0.2926
Epoch [45/50] - Loss: 0.2816
Epoch [46/50] - Loss: 0.2708
Epoch [47/50] - Loss: 0.2615
Epoch [48/50] - Loss: 0.2527
Epoch [49/50] - Loss: 0.2429
Epoch [50/50] - Loss: 0.2337
sum preds 40
sum labels 1607
 - Test Metrics: Accuracy=0.8516, F1=0.0425, Recall=0.0218, Precision=0.8750
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_naive_naive_1904080944.csv.
Average F1 over valid seeds: 0.0486 ± 0.0160
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and naive, MLP,0.4: 0.0486 ± 0.0160
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.5207
Epoch [2/50] - Loss: 1.4550
Epoch [3/50] - Loss: 1.3204
Epoch [4/50] - Loss: 1.2518
Epoch [5/50] - Loss: 1.2153
Epoch [6/50] - Loss: 1.1851
Epoch [7/50] - Loss: 1.1599
Epoch [8/50] - Loss: 1.1457
Epoch [9/50] - Loss: 1.1338
Epoch [10/50] - Loss: 1.1163
Epoch [11/50] - Loss: 1.1065
Epoch [12/50] - Loss: 1.0971
Epoch [13/50] - Loss: 1.0880
Epoch [14/50] - Loss: 1.0796
Epoch [15/50] - Loss: 1.0734
Epoch [16/50] - Loss: 1.0635
Epoch [17/50] - Loss: 1.0564
Epoch [18/50] - Loss: 1.0463
Epoch [19/50] - Loss: 1.0390
Epoch [20/50] - Loss: 1.0332
Epoch [21/50] - Loss: 1.0231
Epoch [22/50] - Loss: 1.0156
Epoch [23/50] - Loss: 1.0089
Epoch [24/50] - Loss: 1.0033
Epoch [25/50] - Loss: 0.9985
Epoch [26/50] - Loss: 0.9909
Epoch [27/50] - Loss: 0.9852
Epoch [28/50] - Loss: 0.9806
Epoch [29/50] - Loss: 0.9729
Epoch [30/50] - Loss: 0.9676
Epoch [31/50] - Loss: 0.9624
Epoch [32/50] - Loss: 0.9561
Epoch [33/50] - Loss: 0.9488
Epoch [34/50] - Loss: 0.9491
Epoch [35/50] - Loss: 0.9423
Epoch [36/50] - Loss: 0.9344
Epoch [37/50] - Loss: 0.9308
Epoch [38/50] - Loss: 0.9239
Epoch [39/50] - Loss: 0.9200
Epoch [40/50] - Loss: 0.9139
Epoch [41/50] - Loss: 0.9075
Epoch [42/50] - Loss: 0.9081
Epoch [43/50] - Loss: 0.9040
Epoch [44/50] - Loss: 0.9011
Epoch [45/50] - Loss: 0.8928
Epoch [46/50] - Loss: 0.8892
Epoch [47/50] - Loss: 0.8868
Epoch [48/50] - Loss: 0.8814
Epoch [49/50] - Loss: 0.8813
Epoch [50/50] - Loss: 0.8764
sum preds 198
sum labels 1607
 - Test Metrics: Accuracy=0.8650, F1=0.2050, Recall=0.1151, Precision=0.9343
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9868
Epoch [2/50] - Loss: 1.3247
Epoch [3/50] - Loss: 1.2420
Epoch [4/50] - Loss: 1.1981
Epoch [5/50] - Loss: 1.1686
Epoch [6/50] - Loss: 1.1387
Epoch [7/50] - Loss: 1.1221
Epoch [8/50] - Loss: 1.1057
Epoch [9/50] - Loss: 1.0913
Epoch [10/50] - Loss: 1.0823
Epoch [11/50] - Loss: 1.0718
Epoch [12/50] - Loss: 1.0646
Epoch [13/50] - Loss: 1.0554
Epoch [14/50] - Loss: 1.0510
Epoch [15/50] - Loss: 1.0436
Epoch [16/50] - Loss: 1.0374
Epoch [17/50] - Loss: 1.0297
Epoch [18/50] - Loss: 1.0246
Epoch [19/50] - Loss: 1.0172
Epoch [20/50] - Loss: 1.0126
Epoch [21/50] - Loss: 1.0074
Epoch [22/50] - Loss: 1.0007
Epoch [23/50] - Loss: 0.9940
Epoch [24/50] - Loss: 0.9893
Epoch [25/50] - Loss: 0.9824
Epoch [26/50] - Loss: 0.9780
Epoch [27/50] - Loss: 0.9711
Epoch [28/50] - Loss: 0.9638
Epoch [29/50] - Loss: 0.9619
Epoch [30/50] - Loss: 0.9581
Epoch [31/50] - Loss: 0.9529
Epoch [32/50] - Loss: 0.9460
Epoch [33/50] - Loss: 0.9457
Epoch [34/50] - Loss: 0.9409
Epoch [35/50] - Loss: 0.9347
Epoch [36/50] - Loss: 0.9292
Epoch [37/50] - Loss: 0.9238
Epoch [38/50] - Loss: 0.9213
Epoch [39/50] - Loss: 0.9170
Epoch [40/50] - Loss: 0.9150
Epoch [41/50] - Loss: 0.9127
Epoch [42/50] - Loss: 0.9087
Epoch [43/50] - Loss: 0.9084
Epoch [44/50] - Loss: 0.9086
Epoch [45/50] - Loss: 0.9026
Epoch [46/50] - Loss: 0.8996
Epoch [47/50] - Loss: 0.8900
Epoch [48/50] - Loss: 0.8868
Epoch [49/50] - Loss: 0.8942
Epoch [50/50] - Loss: 0.8921
sum preds 120
sum labels 1607
 - Test Metrics: Accuracy=0.8580, F1=0.1262, Recall=0.0678, Precision=0.9083
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1193
Epoch [2/50] - Loss: 1.4942
Epoch [3/50] - Loss: 1.2950
Epoch [4/50] - Loss: 1.2287
Epoch [5/50] - Loss: 1.1956
Epoch [6/50] - Loss: 1.1727
Epoch [7/50] - Loss: 1.1544
Epoch [8/50] - Loss: 1.1401
Epoch [9/50] - Loss: 1.1253
Epoch [10/50] - Loss: 1.1144
Epoch [11/50] - Loss: 1.1021
Epoch [12/50] - Loss: 1.0920
Epoch [13/50] - Loss: 1.0832
Epoch [14/50] - Loss: 1.0754
Epoch [15/50] - Loss: 1.0695
Epoch [16/50] - Loss: 1.0633
Epoch [17/50] - Loss: 1.0568
Epoch [18/50] - Loss: 1.0519
Epoch [19/50] - Loss: 1.0454
Epoch [20/50] - Loss: 1.0390
Epoch [21/50] - Loss: 1.0345
Epoch [22/50] - Loss: 1.0306
Epoch [23/50] - Loss: 1.0270
Epoch [24/50] - Loss: 1.0216
Epoch [25/50] - Loss: 1.0162
Epoch [26/50] - Loss: 1.0103
Epoch [27/50] - Loss: 1.0056
Epoch [28/50] - Loss: 1.0025
Epoch [29/50] - Loss: 0.9967
Epoch [30/50] - Loss: 0.9923
Epoch [31/50] - Loss: 0.9866
Epoch [32/50] - Loss: 0.9811
Epoch [33/50] - Loss: 0.9782
Epoch [34/50] - Loss: 0.9700
Epoch [35/50] - Loss: 0.9669
Epoch [36/50] - Loss: 0.9632
Epoch [37/50] - Loss: 0.9580
Epoch [38/50] - Loss: 0.9539
Epoch [39/50] - Loss: 0.9488
Epoch [40/50] - Loss: 0.9440
Epoch [41/50] - Loss: 0.9386
Epoch [42/50] - Loss: 0.9347
Epoch [43/50] - Loss: 0.9318
Epoch [44/50] - Loss: 0.9288
Epoch [45/50] - Loss: 0.9233
Epoch [46/50] - Loss: 0.9181
Epoch [47/50] - Loss: 0.9141
Epoch [48/50] - Loss: 0.9114
Epoch [49/50] - Loss: 0.9060
Epoch [50/50] - Loss: 0.9038
sum preds 119
sum labels 1607
 - Test Metrics: Accuracy=0.8585, F1=0.1286, Recall=0.0691, Precision=0.9328
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_naive_naive_1904081844.csv.
Average F1 over valid seeds: 0.1533 ± 0.0366
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and naive, GATConv,0.4: 0.1533 ± 0.0366
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.8336
Epoch [2/50] - Loss: 1.6055
Epoch [3/50] - Loss: 1.4109
Epoch [4/50] - Loss: 1.3224
Epoch [5/50] - Loss: 1.2706
Epoch [6/50] - Loss: 1.2479
Epoch [7/50] - Loss: 1.2344
Epoch [8/50] - Loss: 1.2212
Epoch [9/50] - Loss: 1.2094
Epoch [10/50] - Loss: 1.1994
Epoch [11/50] - Loss: 1.1917
Epoch [12/50] - Loss: 1.1831
Epoch [13/50] - Loss: 1.1805
Epoch [14/50] - Loss: 1.1735
Epoch [15/50] - Loss: 1.1681
Epoch [16/50] - Loss: 1.1644
Epoch [17/50] - Loss: 1.1598
Epoch [18/50] - Loss: 1.1566
Epoch [19/50] - Loss: 1.1526
Epoch [20/50] - Loss: 1.1488
Epoch [21/50] - Loss: 1.1446
Epoch [22/50] - Loss: 1.1431
Epoch [23/50] - Loss: 1.1385
Epoch [24/50] - Loss: 1.1346
Epoch [25/50] - Loss: 1.1337
Epoch [26/50] - Loss: 1.1285
Epoch [27/50] - Loss: 1.1252
Epoch [28/50] - Loss: 1.1207
Epoch [29/50] - Loss: 1.1180
Epoch [30/50] - Loss: 1.1154
Epoch [31/50] - Loss: 1.1121
Epoch [32/50] - Loss: 1.1087
Epoch [33/50] - Loss: 1.1069
Epoch [34/50] - Loss: 1.1032
Epoch [35/50] - Loss: 1.0983
Epoch [36/50] - Loss: 1.0950
Epoch [37/50] - Loss: 1.0923
Epoch [38/50] - Loss: 1.0883
Epoch [39/50] - Loss: 1.0847
Epoch [40/50] - Loss: 1.0818
Epoch [41/50] - Loss: 1.0795
Epoch [42/50] - Loss: 1.0764
Epoch [43/50] - Loss: 1.0737
Epoch [44/50] - Loss: 1.0717
Epoch [45/50] - Loss: 1.0680
Epoch [46/50] - Loss: 1.0645
Epoch [47/50] - Loss: 1.0632
Epoch [48/50] - Loss: 1.0595
Epoch [49/50] - Loss: 1.0576
Epoch [50/50] - Loss: 1.0537
sum preds 201
sum labels 1607
 - Test Metrics: Accuracy=0.8668, F1=0.2168, Recall=0.1220, Precision=0.9751
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.9676
Epoch [2/50] - Loss: 1.6994
Epoch [3/50] - Loss: 1.4278
Epoch [4/50] - Loss: 1.3365
Epoch [5/50] - Loss: 1.2916
Epoch [6/50] - Loss: 1.2685
Epoch [7/50] - Loss: 1.2536
Epoch [8/50] - Loss: 1.2373
Epoch [9/50] - Loss: 1.2244
Epoch [10/50] - Loss: 1.2154
Epoch [11/50] - Loss: 1.2075
Epoch [12/50] - Loss: 1.1981
Epoch [13/50] - Loss: 1.1904
Epoch [14/50] - Loss: 1.1842
Epoch [15/50] - Loss: 1.1794
Epoch [16/50] - Loss: 1.1746
Epoch [17/50] - Loss: 1.1691
Epoch [18/50] - Loss: 1.1635
Epoch [19/50] - Loss: 1.1589
Epoch [20/50] - Loss: 1.1552
Epoch [21/50] - Loss: 1.1511
Epoch [22/50] - Loss: 1.1473
Epoch [23/50] - Loss: 1.1439
Epoch [24/50] - Loss: 1.1414
Epoch [25/50] - Loss: 1.1354
Epoch [26/50] - Loss: 1.1317
Epoch [27/50] - Loss: 1.1290
Epoch [28/50] - Loss: 1.1262
Epoch [29/50] - Loss: 1.1234
Epoch [30/50] - Loss: 1.1188
Epoch [31/50] - Loss: 1.1152
Epoch [32/50] - Loss: 1.1126
Epoch [33/50] - Loss: 1.1104
Epoch [34/50] - Loss: 1.1052
Epoch [35/50] - Loss: 1.1034
Epoch [36/50] - Loss: 1.0997
Epoch [37/50] - Loss: 1.0963
Epoch [38/50] - Loss: 1.0940
Epoch [39/50] - Loss: 1.0899
Epoch [40/50] - Loss: 1.0868
Epoch [41/50] - Loss: 1.0835
Epoch [42/50] - Loss: 1.0818
Epoch [43/50] - Loss: 1.0789
Epoch [44/50] - Loss: 1.0751
Epoch [45/50] - Loss: 1.0719
Epoch [46/50] - Loss: 1.0706
Epoch [47/50] - Loss: 1.0676
Epoch [48/50] - Loss: 1.0642
Epoch [49/50] - Loss: 1.0616
Epoch [50/50] - Loss: 1.0582
sum preds 168
sum labels 1607
 - Test Metrics: Accuracy=0.8639, F1=0.1848, Recall=0.1021, Precision=0.9762
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.6526
Epoch [2/50] - Loss: 2.5104
Epoch [3/50] - Loss: 1.7385
Epoch [4/50] - Loss: 1.4826
Epoch [5/50] - Loss: 1.3784
Epoch [6/50] - Loss: 1.3275
Epoch [7/50] - Loss: 1.2907
Epoch [8/50] - Loss: 1.2678
Epoch [9/50] - Loss: 1.2532
Epoch [10/50] - Loss: 1.2424
Epoch [11/50] - Loss: 1.2336
Epoch [12/50] - Loss: 1.2253
Epoch [13/50] - Loss: 1.2179
Epoch [14/50] - Loss: 1.2126
Epoch [15/50] - Loss: 1.2053
Epoch [16/50] - Loss: 1.1989
Epoch [17/50] - Loss: 1.1956
Epoch [18/50] - Loss: 1.1918
Epoch [19/50] - Loss: 1.1854
Epoch [20/50] - Loss: 1.1820
Epoch [21/50] - Loss: 1.1779
Epoch [22/50] - Loss: 1.1750
Epoch [23/50] - Loss: 1.1713
Epoch [24/50] - Loss: 1.1680
Epoch [25/50] - Loss: 1.1654
Epoch [26/50] - Loss: 1.1639
Epoch [27/50] - Loss: 1.1596
Epoch [28/50] - Loss: 1.1578
Epoch [29/50] - Loss: 1.1541
Epoch [30/50] - Loss: 1.1520
Epoch [31/50] - Loss: 1.1500
Epoch [32/50] - Loss: 1.1483
Epoch [33/50] - Loss: 1.1456
Epoch [34/50] - Loss: 1.1435
Epoch [35/50] - Loss: 1.1434
Epoch [36/50] - Loss: 1.1372
Epoch [37/50] - Loss: 1.1368
Epoch [38/50] - Loss: 1.1353
Epoch [39/50] - Loss: 1.1328
Epoch [40/50] - Loss: 1.1308
Epoch [41/50] - Loss: 1.1287
Epoch [42/50] - Loss: 1.1263
Epoch [43/50] - Loss: 1.1242
Epoch [44/50] - Loss: 1.1227
Epoch [45/50] - Loss: 1.1226
Epoch [46/50] - Loss: 1.1196
Epoch [47/50] - Loss: 1.1195
Epoch [48/50] - Loss: 1.1166
Epoch [49/50] - Loss: 1.1155
Epoch [50/50] - Loss: 1.1141
sum preds 182
sum labels 1607
 - Test Metrics: Accuracy=0.8644, F1=0.1945, Recall=0.1083, Precision=0.9560
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_naive_naive_1904082806.csv.
Average F1 over valid seeds: 0.1987 ± 0.0134
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and naive, GCNConv,0.4: 0.1987 ± 0.0134
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.1616
Epoch [2/50] - Loss: 1.4787
Epoch [3/50] - Loss: 1.2546
Epoch [4/50] - Loss: 1.2022
Epoch [5/50] - Loss: 1.1259
Epoch [6/50] - Loss: 1.0704
Epoch [7/50] - Loss: 1.0301
Epoch [8/50] - Loss: 1.0006
Epoch [9/50] - Loss: 0.9721
Epoch [10/50] - Loss: 0.9504
Epoch [11/50] - Loss: 0.9292
Epoch [12/50] - Loss: 0.9107
Epoch [13/50] - Loss: 0.8924
Epoch [14/50] - Loss: 0.8747
Epoch [15/50] - Loss: 0.8561
Epoch [16/50] - Loss: 0.8375
Epoch [17/50] - Loss: 0.8199
Epoch [18/50] - Loss: 0.8000
Epoch [19/50] - Loss: 0.7809
Epoch [20/50] - Loss: 0.7615
Epoch [21/50] - Loss: 0.7417
Epoch [22/50] - Loss: 0.7233
Epoch [23/50] - Loss: 0.7040
Epoch [24/50] - Loss: 0.6844
Epoch [25/50] - Loss: 0.6657
Epoch [26/50] - Loss: 0.6457
Epoch [27/50] - Loss: 0.6279
Epoch [28/50] - Loss: 0.6080
Epoch [29/50] - Loss: 0.5905
Epoch [30/50] - Loss: 0.5729
Epoch [31/50] - Loss: 0.5539
Epoch [32/50] - Loss: 0.5364
Epoch [33/50] - Loss: 0.5196
Epoch [34/50] - Loss: 0.5028
Epoch [35/50] - Loss: 0.4881
Epoch [36/50] - Loss: 0.4722
Epoch [37/50] - Loss: 0.4568
Epoch [38/50] - Loss: 0.4422
Epoch [39/50] - Loss: 0.4278
Epoch [40/50] - Loss: 0.4144
Epoch [41/50] - Loss: 0.4004
Epoch [42/50] - Loss: 0.3881
Epoch [43/50] - Loss: 0.3755
Epoch [44/50] - Loss: 0.3635
Epoch [45/50] - Loss: 0.3516
Epoch [46/50] - Loss: 0.3404
Epoch [47/50] - Loss: 0.3301
Epoch [48/50] - Loss: 0.3192
Epoch [49/50] - Loss: 0.3106
Epoch [50/50] - Loss: 0.3010
sum preds 38
sum labels 1875
 - Test Metrics: Accuracy=0.8305, F1=0.0345, Recall=0.0176, Precision=0.8684
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.6341
Epoch [2/50] - Loss: 1.4011
Epoch [3/50] - Loss: 1.2241
Epoch [4/50] - Loss: 1.1554
Epoch [5/50] - Loss: 1.0969
Epoch [6/50] - Loss: 1.0458
Epoch [7/50] - Loss: 1.0082
Epoch [8/50] - Loss: 0.9780
Epoch [9/50] - Loss: 0.9525
Epoch [10/50] - Loss: 0.9284
Epoch [11/50] - Loss: 0.9037
Epoch [12/50] - Loss: 0.8821
Epoch [13/50] - Loss: 0.8587
Epoch [14/50] - Loss: 0.8375
Epoch [15/50] - Loss: 0.8167
Epoch [16/50] - Loss: 0.7964
Epoch [17/50] - Loss: 0.7767
Epoch [18/50] - Loss: 0.7555
Epoch [19/50] - Loss: 0.7347
Epoch [20/50] - Loss: 0.7150
Epoch [21/50] - Loss: 0.6949
Epoch [22/50] - Loss: 0.6744
Epoch [23/50] - Loss: 0.6538
Epoch [24/50] - Loss: 0.6336
Epoch [25/50] - Loss: 0.6135
Epoch [26/50] - Loss: 0.5931
Epoch [27/50] - Loss: 0.5727
Epoch [28/50] - Loss: 0.5528
Epoch [29/50] - Loss: 0.5330
Epoch [30/50] - Loss: 0.5131
Epoch [31/50] - Loss: 0.4952
Epoch [32/50] - Loss: 0.4770
Epoch [33/50] - Loss: 0.4596
Epoch [34/50] - Loss: 0.4435
Epoch [35/50] - Loss: 0.4272
Epoch [36/50] - Loss: 0.4114
Epoch [37/50] - Loss: 0.3965
Epoch [38/50] - Loss: 0.3804
Epoch [39/50] - Loss: 0.3670
Epoch [40/50] - Loss: 0.3543
Epoch [41/50] - Loss: 0.3404
Epoch [42/50] - Loss: 0.3276
Epoch [43/50] - Loss: 0.3153
Epoch [44/50] - Loss: 0.3052
Epoch [45/50] - Loss: 0.2934
Epoch [46/50] - Loss: 0.2810
Epoch [47/50] - Loss: 0.2702
Epoch [48/50] - Loss: 0.2601
Epoch [49/50] - Loss: 0.2500
Epoch [50/50] - Loss: 0.2395
sum preds 26
sum labels 1875
 - Test Metrics: Accuracy=0.8300, F1=0.0252, Recall=0.0128, Precision=0.9231
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9851
Epoch [2/50] - Loss: 1.2436
Epoch [3/50] - Loss: 1.1339
Epoch [4/50] - Loss: 1.0645
Epoch [5/50] - Loss: 1.0202
Epoch [6/50] - Loss: 0.9908
Epoch [7/50] - Loss: 0.9673
Epoch [8/50] - Loss: 0.9449
Epoch [9/50] - Loss: 0.9230
Epoch [10/50] - Loss: 0.9014
Epoch [11/50] - Loss: 0.8799
Epoch [12/50] - Loss: 0.8590
Epoch [13/50] - Loss: 0.8358
Epoch [14/50] - Loss: 0.8140
Epoch [15/50] - Loss: 0.7905
Epoch [16/50] - Loss: 0.7674
Epoch [17/50] - Loss: 0.7432
Epoch [18/50] - Loss: 0.7178
Epoch [19/50] - Loss: 0.6918
Epoch [20/50] - Loss: 0.6664
Epoch [21/50] - Loss: 0.6388
Epoch [22/50] - Loss: 0.6119
Epoch [23/50] - Loss: 0.5846
Epoch [24/50] - Loss: 0.5586
Epoch [25/50] - Loss: 0.5331
Epoch [26/50] - Loss: 0.5081
Epoch [27/50] - Loss: 0.4836
Epoch [28/50] - Loss: 0.4615
Epoch [29/50] - Loss: 0.4392
Epoch [30/50] - Loss: 0.4192
Epoch [31/50] - Loss: 0.3998
Epoch [32/50] - Loss: 0.3825
Epoch [33/50] - Loss: 0.3665
Epoch [34/50] - Loss: 0.3503
Epoch [35/50] - Loss: 0.3349
Epoch [36/50] - Loss: 0.3215
Epoch [37/50] - Loss: 0.3092
Epoch [38/50] - Loss: 0.2961
Epoch [39/50] - Loss: 0.2842
Epoch [40/50] - Loss: 0.2714
Epoch [41/50] - Loss: 0.2617
Epoch [42/50] - Loss: 0.2509
Epoch [43/50] - Loss: 0.2407
Epoch [44/50] - Loss: 0.2313
Epoch [45/50] - Loss: 0.2223
Epoch [46/50] - Loss: 0.2138
Epoch [47/50] - Loss: 0.2062
Epoch [48/50] - Loss: 0.1985
Epoch [49/50] - Loss: 0.1899
Epoch [50/50] - Loss: 0.1828
sum preds 29
sum labels 1875
 - Test Metrics: Accuracy=0.8304, F1=0.0294, Recall=0.0149, Precision=0.9655
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_naive_naive_1904083729.csv.
Average F1 over valid seeds: 0.0297 ± 0.0038
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and naive, MLP,0.3: 0.0297 ± 0.0038
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.3699
Epoch [2/50] - Loss: 1.3272
Epoch [3/50] - Loss: 1.1813
Epoch [4/50] - Loss: 1.1154
Epoch [5/50] - Loss: 1.0880
Epoch [6/50] - Loss: 1.0605
Epoch [7/50] - Loss: 1.0334
Epoch [8/50] - Loss: 1.0158
Epoch [9/50] - Loss: 1.0059
Epoch [10/50] - Loss: 0.9914
Epoch [11/50] - Loss: 0.9814
Epoch [12/50] - Loss: 0.9750
Epoch [13/50] - Loss: 0.9663
Epoch [14/50] - Loss: 0.9587
Epoch [15/50] - Loss: 0.9520
Epoch [16/50] - Loss: 0.9438
Epoch [17/50] - Loss: 0.9376
Epoch [18/50] - Loss: 0.9297
Epoch [19/50] - Loss: 0.9255
Epoch [20/50] - Loss: 0.9191
Epoch [21/50] - Loss: 0.9127
Epoch [22/50] - Loss: 0.9073
Epoch [23/50] - Loss: 0.9004
Epoch [24/50] - Loss: 0.8964
Epoch [25/50] - Loss: 0.8930
Epoch [26/50] - Loss: 0.8870
Epoch [27/50] - Loss: 0.8824
Epoch [28/50] - Loss: 0.8802
Epoch [29/50] - Loss: 0.8752
Epoch [30/50] - Loss: 0.8718
Epoch [31/50] - Loss: 0.8672
Epoch [32/50] - Loss: 0.8629
Epoch [33/50] - Loss: 0.8561
Epoch [34/50] - Loss: 0.8550
Epoch [35/50] - Loss: 0.8508
Epoch [36/50] - Loss: 0.8438
Epoch [37/50] - Loss: 0.8406
Epoch [38/50] - Loss: 0.8364
Epoch [39/50] - Loss: 0.8330
Epoch [40/50] - Loss: 0.8276
Epoch [41/50] - Loss: 0.8220
Epoch [42/50] - Loss: 0.8198
Epoch [43/50] - Loss: 0.8144
Epoch [44/50] - Loss: 0.8123
Epoch [45/50] - Loss: 0.8048
Epoch [46/50] - Loss: 0.8004
Epoch [47/50] - Loss: 0.7983
Epoch [48/50] - Loss: 0.7946
Epoch [49/50] - Loss: 0.7902
Epoch [50/50] - Loss: 0.7868
sum preds 61
sum labels 1875
 - Test Metrics: Accuracy=0.8326, F1=0.0579, Recall=0.0299, Precision=0.9180
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8359
Epoch [2/50] - Loss: 1.1850
Epoch [3/50] - Loss: 1.1082
Epoch [4/50] - Loss: 1.0684
Epoch [5/50] - Loss: 1.0375
Epoch [6/50] - Loss: 1.0152
Epoch [7/50] - Loss: 0.9975
Epoch [8/50] - Loss: 0.9842
Epoch [9/50] - Loss: 0.9703
Epoch [10/50] - Loss: 0.9634
Epoch [11/50] - Loss: 0.9533
Epoch [12/50] - Loss: 0.9475
Epoch [13/50] - Loss: 0.9419
Epoch [14/50] - Loss: 0.9375
Epoch [15/50] - Loss: 0.9309
Epoch [16/50] - Loss: 0.9253
Epoch [17/50] - Loss: 0.9198
Epoch [18/50] - Loss: 0.9144
Epoch [19/50] - Loss: 0.9082
Epoch [20/50] - Loss: 0.9054
Epoch [21/50] - Loss: 0.9035
Epoch [22/50] - Loss: 0.8966
Epoch [23/50] - Loss: 0.8929
Epoch [24/50] - Loss: 0.8896
Epoch [25/50] - Loss: 0.8842
Epoch [26/50] - Loss: 0.8822
Epoch [27/50] - Loss: 0.8759
Epoch [28/50] - Loss: 0.8707
Epoch [29/50] - Loss: 0.8669
Epoch [30/50] - Loss: 0.8646
Epoch [31/50] - Loss: 0.8596
Epoch [32/50] - Loss: 0.8531
Epoch [33/50] - Loss: 0.8505
Epoch [34/50] - Loss: 0.8461
Epoch [35/50] - Loss: 0.8429
Epoch [36/50] - Loss: 0.8374
Epoch [37/50] - Loss: 0.8339
Epoch [38/50] - Loss: 0.8301
Epoch [39/50] - Loss: 0.8243
Epoch [40/50] - Loss: 0.8211
Epoch [41/50] - Loss: 0.8164
Epoch [42/50] - Loss: 0.8135
Epoch [43/50] - Loss: 0.8049
Epoch [44/50] - Loss: 0.8029
Epoch [45/50] - Loss: 0.7986
Epoch [46/50] - Loss: 0.7931
Epoch [47/50] - Loss: 0.7854
Epoch [48/50] - Loss: 0.7841
Epoch [49/50] - Loss: 0.7843
Epoch [50/50] - Loss: 0.7790
sum preds 68
sum labels 1875
 - Test Metrics: Accuracy=0.8331, F1=0.0638, Recall=0.0331, Precision=0.9118
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.0012
Epoch [2/50] - Loss: 1.3337
Epoch [3/50] - Loss: 1.1610
Epoch [4/50] - Loss: 1.0950
Epoch [5/50] - Loss: 1.0571
Epoch [6/50] - Loss: 1.0319
Epoch [7/50] - Loss: 1.0186
Epoch [8/50] - Loss: 1.0064
Epoch [9/50] - Loss: 0.9928
Epoch [10/50] - Loss: 0.9840
Epoch [11/50] - Loss: 0.9730
Epoch [12/50] - Loss: 0.9648
Epoch [13/50] - Loss: 0.9570
Epoch [14/50] - Loss: 0.9502
Epoch [15/50] - Loss: 0.9456
Epoch [16/50] - Loss: 0.9395
Epoch [17/50] - Loss: 0.9344
Epoch [18/50] - Loss: 0.9284
Epoch [19/50] - Loss: 0.9237
Epoch [20/50] - Loss: 0.9172
Epoch [21/50] - Loss: 0.9136
Epoch [22/50] - Loss: 0.9110
Epoch [23/50] - Loss: 0.9081
Epoch [24/50] - Loss: 0.9034
Epoch [25/50] - Loss: 0.8989
Epoch [26/50] - Loss: 0.8937
Epoch [27/50] - Loss: 0.8888
Epoch [28/50] - Loss: 0.8865
Epoch [29/50] - Loss: 0.8818
Epoch [30/50] - Loss: 0.8763
Epoch [31/50] - Loss: 0.8726
Epoch [32/50] - Loss: 0.8685
Epoch [33/50] - Loss: 0.8664
Epoch [34/50] - Loss: 0.8603
Epoch [35/50] - Loss: 0.8576
Epoch [36/50] - Loss: 0.8542
Epoch [37/50] - Loss: 0.8506
Epoch [38/50] - Loss: 0.8457
Epoch [39/50] - Loss: 0.8418
Epoch [40/50] - Loss: 0.8399
Epoch [41/50] - Loss: 0.8353
Epoch [42/50] - Loss: 0.8335
Epoch [43/50] - Loss: 0.8296
Epoch [44/50] - Loss: 0.8256
Epoch [45/50] - Loss: 0.8228
Epoch [46/50] - Loss: 0.8201
Epoch [47/50] - Loss: 0.8164
Epoch [48/50] - Loss: 0.8138
Epoch [49/50] - Loss: 0.8089
Epoch [50/50] - Loss: 0.8068
sum preds 31
sum labels 1875
 - Test Metrics: Accuracy=0.8304, F1=0.0304, Recall=0.0155, Precision=0.9355
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_naive_naive_1904084701.csv.
Average F1 over valid seeds: 0.0507 ± 0.0145
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and naive, GATConv,0.3: 0.0507 ± 0.0145
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.7957
Epoch [2/50] - Loss: 1.4815
Epoch [3/50] - Loss: 1.2739
Epoch [4/50] - Loss: 1.1915
Epoch [5/50] - Loss: 1.1387
Epoch [6/50] - Loss: 1.1109
Epoch [7/50] - Loss: 1.0989
Epoch [8/50] - Loss: 1.0872
Epoch [9/50] - Loss: 1.0748
Epoch [10/50] - Loss: 1.0652
Epoch [11/50] - Loss: 1.0583
Epoch [12/50] - Loss: 1.0484
Epoch [13/50] - Loss: 1.0454
Epoch [14/50] - Loss: 1.0379
Epoch [15/50] - Loss: 1.0326
Epoch [16/50] - Loss: 1.0275
Epoch [17/50] - Loss: 1.0237
Epoch [18/50] - Loss: 1.0202
Epoch [19/50] - Loss: 1.0157
Epoch [20/50] - Loss: 1.0124
Epoch [21/50] - Loss: 1.0089
Epoch [22/50] - Loss: 1.0063
Epoch [23/50] - Loss: 1.0026
Epoch [24/50] - Loss: 0.9980
Epoch [25/50] - Loss: 0.9975
Epoch [26/50] - Loss: 0.9928
Epoch [27/50] - Loss: 0.9895
Epoch [28/50] - Loss: 0.9854
Epoch [29/50] - Loss: 0.9827
Epoch [30/50] - Loss: 0.9802
Epoch [31/50] - Loss: 0.9781
Epoch [32/50] - Loss: 0.9741
Epoch [33/50] - Loss: 0.9725
Epoch [34/50] - Loss: 0.9692
Epoch [35/50] - Loss: 0.9658
Epoch [36/50] - Loss: 0.9630
Epoch [37/50] - Loss: 0.9600
Epoch [38/50] - Loss: 0.9567
Epoch [39/50] - Loss: 0.9527
Epoch [40/50] - Loss: 0.9511
Epoch [41/50] - Loss: 0.9481
Epoch [42/50] - Loss: 0.9453
Epoch [43/50] - Loss: 0.9438
Epoch [44/50] - Loss: 0.9425
Epoch [45/50] - Loss: 0.9385
Epoch [46/50] - Loss: 0.9353
Epoch [47/50] - Loss: 0.9344
Epoch [48/50] - Loss: 0.9297
Epoch [49/50] - Loss: 0.9283
Epoch [50/50] - Loss: 0.9253
sum preds 42
sum labels 1875
 - Test Metrics: Accuracy=0.8314, F1=0.0417, Recall=0.0213, Precision=0.9524
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.9394
Epoch [2/50] - Loss: 1.5937
Epoch [3/50] - Loss: 1.2947
Epoch [4/50] - Loss: 1.2017
Epoch [5/50] - Loss: 1.1543
Epoch [6/50] - Loss: 1.1255
Epoch [7/50] - Loss: 1.1128
Epoch [8/50] - Loss: 1.1000
Epoch [9/50] - Loss: 1.0900
Epoch [10/50] - Loss: 1.0805
Epoch [11/50] - Loss: 1.0735
Epoch [12/50] - Loss: 1.0650
Epoch [13/50] - Loss: 1.0574
Epoch [14/50] - Loss: 1.0524
Epoch [15/50] - Loss: 1.0480
Epoch [16/50] - Loss: 1.0441
Epoch [17/50] - Loss: 1.0388
Epoch [18/50] - Loss: 1.0342
Epoch [19/50] - Loss: 1.0296
Epoch [20/50] - Loss: 1.0268
Epoch [21/50] - Loss: 1.0235
Epoch [22/50] - Loss: 1.0202
Epoch [23/50] - Loss: 1.0173
Epoch [24/50] - Loss: 1.0159
Epoch [25/50] - Loss: 1.0106
Epoch [26/50] - Loss: 1.0074
Epoch [27/50] - Loss: 1.0053
Epoch [28/50] - Loss: 1.0036
Epoch [29/50] - Loss: 1.0007
Epoch [30/50] - Loss: 0.9969
Epoch [31/50] - Loss: 0.9937
Epoch [32/50] - Loss: 0.9923
Epoch [33/50] - Loss: 0.9900
Epoch [34/50] - Loss: 0.9861
Epoch [35/50] - Loss: 0.9846
Epoch [36/50] - Loss: 0.9823
Epoch [37/50] - Loss: 0.9788
Epoch [38/50] - Loss: 0.9767
Epoch [39/50] - Loss: 0.9740
Epoch [40/50] - Loss: 0.9721
Epoch [41/50] - Loss: 0.9697
Epoch [42/50] - Loss: 0.9679
Epoch [43/50] - Loss: 0.9650
Epoch [44/50] - Loss: 0.9621
Epoch [45/50] - Loss: 0.9595
Epoch [46/50] - Loss: 0.9586
Epoch [47/50] - Loss: 0.9552
Epoch [48/50] - Loss: 0.9532
Epoch [49/50] - Loss: 0.9513
Epoch [50/50] - Loss: 0.9484
sum preds 41
sum labels 1875
 - Test Metrics: Accuracy=0.8311, F1=0.0397, Recall=0.0203, Precision=0.9268
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.7253
Epoch [2/50] - Loss: 2.4785
Epoch [3/50] - Loss: 1.6474
Epoch [4/50] - Loss: 1.3592
Epoch [5/50] - Loss: 1.2457
Epoch [6/50] - Loss: 1.1879
Epoch [7/50] - Loss: 1.1523
Epoch [8/50] - Loss: 1.1249
Epoch [9/50] - Loss: 1.1074
Epoch [10/50] - Loss: 1.0937
Epoch [11/50] - Loss: 1.0854
Epoch [12/50] - Loss: 1.0786
Epoch [13/50] - Loss: 1.0706
Epoch [14/50] - Loss: 1.0658
Epoch [15/50] - Loss: 1.0593
Epoch [16/50] - Loss: 1.0536
Epoch [17/50] - Loss: 1.0508
Epoch [18/50] - Loss: 1.0474
Epoch [19/50] - Loss: 1.0411
Epoch [20/50] - Loss: 1.0382
Epoch [21/50] - Loss: 1.0345
Epoch [22/50] - Loss: 1.0322
Epoch [23/50] - Loss: 1.0284
Epoch [24/50] - Loss: 1.0252
Epoch [25/50] - Loss: 1.0230
Epoch [26/50] - Loss: 1.0210
Epoch [27/50] - Loss: 1.0184
Epoch [28/50] - Loss: 1.0163
Epoch [29/50] - Loss: 1.0127
Epoch [30/50] - Loss: 1.0113
Epoch [31/50] - Loss: 1.0094
Epoch [32/50] - Loss: 1.0086
Epoch [33/50] - Loss: 1.0060
Epoch [34/50] - Loss: 1.0038
Epoch [35/50] - Loss: 1.0037
Epoch [36/50] - Loss: 0.9986
Epoch [37/50] - Loss: 0.9981
Epoch [38/50] - Loss: 0.9968
Epoch [39/50] - Loss: 0.9942
Epoch [40/50] - Loss: 0.9926
Epoch [41/50] - Loss: 0.9909
Epoch [42/50] - Loss: 0.9879
Epoch [43/50] - Loss: 0.9865
Epoch [44/50] - Loss: 0.9853
Epoch [45/50] - Loss: 0.9850
Epoch [46/50] - Loss: 0.9825
Epoch [47/50] - Loss: 0.9819
Epoch [48/50] - Loss: 0.9788
Epoch [49/50] - Loss: 0.9785
Epoch [50/50] - Loss: 0.9766
sum preds 61
sum labels 1875
 - Test Metrics: Accuracy=0.8333, F1=0.0620, Recall=0.0320, Precision=0.9836
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_naive_naive_1904085755.csv.
Average F1 over valid seeds: 0.0478 ± 0.0101
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and naive, GCNConv,0.3: 0.0478 ± 0.0101
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.1252
Epoch [2/50] - Loss: 1.2931
Epoch [3/50] - Loss: 1.0201
Epoch [4/50] - Loss: 0.9912
Epoch [5/50] - Loss: 0.9348
Epoch [6/50] - Loss: 0.8801
Epoch [7/50] - Loss: 0.8430
Epoch [8/50] - Loss: 0.8165
Epoch [9/50] - Loss: 0.7927
Epoch [10/50] - Loss: 0.7719
Epoch [11/50] - Loss: 0.7525
Epoch [12/50] - Loss: 0.7353
Epoch [13/50] - Loss: 0.7179
Epoch [14/50] - Loss: 0.7021
Epoch [15/50] - Loss: 0.6867
Epoch [16/50] - Loss: 0.6713
Epoch [17/50] - Loss: 0.6574
Epoch [18/50] - Loss: 0.6406
Epoch [19/50] - Loss: 0.6257
Epoch [20/50] - Loss: 0.6097
Epoch [21/50] - Loss: 0.5928
Epoch [22/50] - Loss: 0.5778
Epoch [23/50] - Loss: 0.5627
Epoch [24/50] - Loss: 0.5466
Epoch [25/50] - Loss: 0.5309
Epoch [26/50] - Loss: 0.5143
Epoch [27/50] - Loss: 0.4997
Epoch [28/50] - Loss: 0.4839
Epoch [29/50] - Loss: 0.4696
Epoch [30/50] - Loss: 0.4558
Epoch [31/50] - Loss: 0.4414
Epoch [32/50] - Loss: 0.4272
Epoch [33/50] - Loss: 0.4137
Epoch [34/50] - Loss: 0.4001
Epoch [35/50] - Loss: 0.3875
Epoch [36/50] - Loss: 0.3749
Epoch [37/50] - Loss: 0.3630
Epoch [38/50] - Loss: 0.3513
Epoch [39/50] - Loss: 0.3396
Epoch [40/50] - Loss: 0.3293
Epoch [41/50] - Loss: 0.3179
Epoch [42/50] - Loss: 0.3079
Epoch [43/50] - Loss: 0.2979
Epoch [44/50] - Loss: 0.2883
Epoch [45/50] - Loss: 0.2793
Epoch [46/50] - Loss: 0.2699
Epoch [47/50] - Loss: 0.2619
Epoch [48/50] - Loss: 0.2533
Epoch [49/50] - Loss: 0.2439
Epoch [50/50] - Loss: 0.2361
sum preds 10
sum labels 2143
 - Test Metrics: Accuracy=0.8086, F1=0.0074, Recall=0.0037, Precision=0.8000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.5537
Epoch [2/50] - Loss: 1.2064
Epoch [3/50] - Loss: 1.0103
Epoch [4/50] - Loss: 0.9569
Epoch [5/50] - Loss: 0.9091
Epoch [6/50] - Loss: 0.8675
Epoch [7/50] - Loss: 0.8323
Epoch [8/50] - Loss: 0.8018
Epoch [9/50] - Loss: 0.7760
Epoch [10/50] - Loss: 0.7529
Epoch [11/50] - Loss: 0.7313
Epoch [12/50] - Loss: 0.7122
Epoch [13/50] - Loss: 0.6921
Epoch [14/50] - Loss: 0.6730
Epoch [15/50] - Loss: 0.6550
Epoch [16/50] - Loss: 0.6372
Epoch [17/50] - Loss: 0.6195
Epoch [18/50] - Loss: 0.6009
Epoch [19/50] - Loss: 0.5825
Epoch [20/50] - Loss: 0.5652
Epoch [21/50] - Loss: 0.5474
Epoch [22/50] - Loss: 0.5292
Epoch [23/50] - Loss: 0.5097
Epoch [24/50] - Loss: 0.4911
Epoch [25/50] - Loss: 0.4729
Epoch [26/50] - Loss: 0.4543
Epoch [27/50] - Loss: 0.4360
Epoch [28/50] - Loss: 0.4174
Epoch [29/50] - Loss: 0.4001
Epoch [30/50] - Loss: 0.3827
Epoch [31/50] - Loss: 0.3666
Epoch [32/50] - Loss: 0.3507
Epoch [33/50] - Loss: 0.3357
Epoch [34/50] - Loss: 0.3211
Epoch [35/50] - Loss: 0.3066
Epoch [36/50] - Loss: 0.2930
Epoch [37/50] - Loss: 0.2797
Epoch [38/50] - Loss: 0.2664
Epoch [39/50] - Loss: 0.2551
Epoch [40/50] - Loss: 0.2456
Epoch [41/50] - Loss: 0.2329
Epoch [42/50] - Loss: 0.2229
Epoch [43/50] - Loss: 0.2130
Epoch [44/50] - Loss: 0.2031
Epoch [45/50] - Loss: 0.1947
Epoch [46/50] - Loss: 0.1856
Epoch [47/50] - Loss: 0.1769
Epoch [48/50] - Loss: 0.1688
Epoch [49/50] - Loss: 0.1617
Epoch [50/50] - Loss: 0.1543
sum preds 11
sum labels 2143
 - Test Metrics: Accuracy=0.8089, F1=0.0093, Recall=0.0047, Precision=0.9091
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8430
Epoch [2/50] - Loss: 1.0367
Epoch [3/50] - Loss: 0.9506
Epoch [4/50] - Loss: 0.8873
Epoch [5/50] - Loss: 0.8394
Epoch [6/50] - Loss: 0.8056
Epoch [7/50] - Loss: 0.7806
Epoch [8/50] - Loss: 0.7574
Epoch [9/50] - Loss: 0.7361
Epoch [10/50] - Loss: 0.7146
Epoch [11/50] - Loss: 0.6944
Epoch [12/50] - Loss: 0.6745
Epoch [13/50] - Loss: 0.6535
Epoch [14/50] - Loss: 0.6349
Epoch [15/50] - Loss: 0.6154
Epoch [16/50] - Loss: 0.5963
Epoch [17/50] - Loss: 0.5769
Epoch [18/50] - Loss: 0.5568
Epoch [19/50] - Loss: 0.5372
Epoch [20/50] - Loss: 0.5187
Epoch [21/50] - Loss: 0.4991
Epoch [22/50] - Loss: 0.4807
Epoch [23/50] - Loss: 0.4618
Epoch [24/50] - Loss: 0.4445
Epoch [25/50] - Loss: 0.4263
Epoch [26/50] - Loss: 0.4095
Epoch [27/50] - Loss: 0.3933
Epoch [28/50] - Loss: 0.3787
Epoch [29/50] - Loss: 0.3632
Epoch [30/50] - Loss: 0.3489
Epoch [31/50] - Loss: 0.3343
Epoch [32/50] - Loss: 0.3200
Epoch [33/50] - Loss: 0.3068
Epoch [34/50] - Loss: 0.2935
Epoch [35/50] - Loss: 0.2815
Epoch [36/50] - Loss: 0.2703
Epoch [37/50] - Loss: 0.2598
Epoch [38/50] - Loss: 0.2495
Epoch [39/50] - Loss: 0.2398
Epoch [40/50] - Loss: 0.2294
Epoch [41/50] - Loss: 0.2207
Epoch [42/50] - Loss: 0.2120
Epoch [43/50] - Loss: 0.2037
Epoch [44/50] - Loss: 0.1961
Epoch [45/50] - Loss: 0.1885
Epoch [46/50] - Loss: 0.1819
Epoch [47/50] - Loss: 0.1758
Epoch [48/50] - Loss: 0.1702
Epoch [49/50] - Loss: 0.1643
Epoch [50/50] - Loss: 0.1582
sum preds 3
sum labels 2143
 - Test Metrics: Accuracy=0.8083, F1=0.0028, Recall=0.0014, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_naive_naive_1904090854.csv.
Average F1 over valid seeds: 0.0065 ± 0.0027
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and naive, MLP,0.2: 0.0065 ± 0.0027
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.1468
Epoch [2/50] - Loss: 1.1155
Epoch [3/50] - Loss: 0.9814
Epoch [4/50] - Loss: 0.9150
Epoch [5/50] - Loss: 0.8761
Epoch [6/50] - Loss: 0.8584
Epoch [7/50] - Loss: 0.8412
Epoch [8/50] - Loss: 0.8282
Epoch [9/50] - Loss: 0.8191
Epoch [10/50] - Loss: 0.8066
Epoch [11/50] - Loss: 0.7989
Epoch [12/50] - Loss: 0.7925
Epoch [13/50] - Loss: 0.7840
Epoch [14/50] - Loss: 0.7790
Epoch [15/50] - Loss: 0.7736
Epoch [16/50] - Loss: 0.7682
Epoch [17/50] - Loss: 0.7625
Epoch [18/50] - Loss: 0.7558
Epoch [19/50] - Loss: 0.7510
Epoch [20/50] - Loss: 0.7450
Epoch [21/50] - Loss: 0.7409
Epoch [22/50] - Loss: 0.7377
Epoch [23/50] - Loss: 0.7337
Epoch [24/50] - Loss: 0.7293
Epoch [25/50] - Loss: 0.7257
Epoch [26/50] - Loss: 0.7219
Epoch [27/50] - Loss: 0.7189
Epoch [28/50] - Loss: 0.7158
Epoch [29/50] - Loss: 0.7129
Epoch [30/50] - Loss: 0.7106
Epoch [31/50] - Loss: 0.7057
Epoch [32/50] - Loss: 0.7049
Epoch [33/50] - Loss: 0.6990
Epoch [34/50] - Loss: 0.6991
Epoch [35/50] - Loss: 0.6971
Epoch [36/50] - Loss: 0.6910
Epoch [37/50] - Loss: 0.6886
Epoch [38/50] - Loss: 0.6832
Epoch [39/50] - Loss: 0.6808
Epoch [40/50] - Loss: 0.6761
Epoch [41/50] - Loss: 0.6736
Epoch [42/50] - Loss: 0.6702
Epoch [43/50] - Loss: 0.6661
Epoch [44/50] - Loss: 0.6645
Epoch [45/50] - Loss: 0.6601
Epoch [46/50] - Loss: 0.6547
Epoch [47/50] - Loss: 0.6520
Epoch [48/50] - Loss: 0.6502
Epoch [49/50] - Loss: 0.6487
Epoch [50/50] - Loss: 0.6472
sum preds 22
sum labels 2143
 - Test Metrics: Accuracy=0.8091, F1=0.0157, Recall=0.0079, Precision=0.7727
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.6412
Epoch [2/50] - Loss: 0.9816
Epoch [3/50] - Loss: 0.9035
Epoch [4/50] - Loss: 0.8562
Epoch [5/50] - Loss: 0.8306
Epoch [6/50] - Loss: 0.8031
Epoch [7/50] - Loss: 0.7840
Epoch [8/50] - Loss: 0.7719
Epoch [9/50] - Loss: 0.7560
Epoch [10/50] - Loss: 0.7510
Epoch [11/50] - Loss: 0.7410
Epoch [12/50] - Loss: 0.7346
Epoch [13/50] - Loss: 0.7284
Epoch [14/50] - Loss: 0.7239
Epoch [15/50] - Loss: 0.7182
Epoch [16/50] - Loss: 0.7132
Epoch [17/50] - Loss: 0.7078
Epoch [18/50] - Loss: 0.7024
Epoch [19/50] - Loss: 0.7004
Epoch [20/50] - Loss: 0.6969
Epoch [21/50] - Loss: 0.6963
Epoch [22/50] - Loss: 0.6896
Epoch [23/50] - Loss: 0.6863
Epoch [24/50] - Loss: 0.6852
Epoch [25/50] - Loss: 0.6804
Epoch [26/50] - Loss: 0.6788
Epoch [27/50] - Loss: 0.6736
Epoch [28/50] - Loss: 0.6690
Epoch [29/50] - Loss: 0.6648
Epoch [30/50] - Loss: 0.6636
Epoch [31/50] - Loss: 0.6600
Epoch [32/50] - Loss: 0.6520
Epoch [33/50] - Loss: 0.6502
Epoch [34/50] - Loss: 0.6467
Epoch [35/50] - Loss: 0.6468
Epoch [36/50] - Loss: 0.6386
Epoch [37/50] - Loss: 0.6363
Epoch [38/50] - Loss: 0.6336
Epoch [39/50] - Loss: 0.6316
Epoch [40/50] - Loss: 0.6262
Epoch [41/50] - Loss: 0.6225
Epoch [42/50] - Loss: 0.6197
Epoch [43/50] - Loss: 0.6145
Epoch [44/50] - Loss: 0.6076
Epoch [45/50] - Loss: 0.6072
Epoch [46/50] - Loss: 0.6036
Epoch [47/50] - Loss: 0.6002
Epoch [48/50] - Loss: 0.5957
Epoch [49/50] - Loss: 0.5947
Epoch [50/50] - Loss: 0.5856
sum preds 33
sum labels 2143
 - Test Metrics: Accuracy=0.8099, F1=0.0248, Recall=0.0126, Precision=0.8182
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8182
Epoch [2/50] - Loss: 1.0634
Epoch [3/50] - Loss: 0.9383
Epoch [4/50] - Loss: 0.8814
Epoch [5/50] - Loss: 0.8523
Epoch [6/50] - Loss: 0.8319
Epoch [7/50] - Loss: 0.8165
Epoch [8/50] - Loss: 0.8037
Epoch [9/50] - Loss: 0.7898
Epoch [10/50] - Loss: 0.7801
Epoch [11/50] - Loss: 0.7713
Epoch [12/50] - Loss: 0.7643
Epoch [13/50] - Loss: 0.7576
Epoch [14/50] - Loss: 0.7523
Epoch [15/50] - Loss: 0.7482
Epoch [16/50] - Loss: 0.7432
Epoch [17/50] - Loss: 0.7386
Epoch [18/50] - Loss: 0.7336
Epoch [19/50] - Loss: 0.7296
Epoch [20/50] - Loss: 0.7239
Epoch [21/50] - Loss: 0.7208
Epoch [22/50] - Loss: 0.7189
Epoch [23/50] - Loss: 0.7160
Epoch [24/50] - Loss: 0.7107
Epoch [25/50] - Loss: 0.7079
Epoch [26/50] - Loss: 0.7036
Epoch [27/50] - Loss: 0.6996
Epoch [28/50] - Loss: 0.6977
Epoch [29/50] - Loss: 0.6934
Epoch [30/50] - Loss: 0.6903
Epoch [31/50] - Loss: 0.6863
Epoch [32/50] - Loss: 0.6837
Epoch [33/50] - Loss: 0.6820
Epoch [34/50] - Loss: 0.6766
Epoch [35/50] - Loss: 0.6751
Epoch [36/50] - Loss: 0.6732
Epoch [37/50] - Loss: 0.6704
Epoch [38/50] - Loss: 0.6679
Epoch [39/50] - Loss: 0.6632
Epoch [40/50] - Loss: 0.6612
Epoch [41/50] - Loss: 0.6571
Epoch [42/50] - Loss: 0.6538
Epoch [43/50] - Loss: 0.6526
Epoch [44/50] - Loss: 0.6500
Epoch [45/50] - Loss: 0.6468
Epoch [46/50] - Loss: 0.6434
Epoch [47/50] - Loss: 0.6415
Epoch [48/50] - Loss: 0.6392
Epoch [49/50] - Loss: 0.6357
Epoch [50/50] - Loss: 0.6331
sum preds 18
sum labels 2143
 - Test Metrics: Accuracy=0.8090, F1=0.0130, Recall=0.0065, Precision=0.7778
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_naive_naive_1904091919.csv.
Average F1 over valid seeds: 0.0178 ± 0.0051
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and naive, GATConv,0.2: 0.0178 ± 0.0051
___________________________________________________________________________________
naive
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.7475
Epoch [2/50] - Loss: 1.3134
Epoch [3/50] - Loss: 1.0723
Epoch [4/50] - Loss: 1.0078
Epoch [5/50] - Loss: 0.9609
Epoch [6/50] - Loss: 0.9277
Epoch [7/50] - Loss: 0.9109
Epoch [8/50] - Loss: 0.9011
Epoch [9/50] - Loss: 0.8926
Epoch [10/50] - Loss: 0.8835
Epoch [11/50] - Loss: 0.8758
Epoch [12/50] - Loss: 0.8675
Epoch [13/50] - Loss: 0.8645
Epoch [14/50] - Loss: 0.8589
Epoch [15/50] - Loss: 0.8536
Epoch [16/50] - Loss: 0.8490
Epoch [17/50] - Loss: 0.8457
Epoch [18/50] - Loss: 0.8417
Epoch [19/50] - Loss: 0.8367
Epoch [20/50] - Loss: 0.8340
Epoch [21/50] - Loss: 0.8314
Epoch [22/50] - Loss: 0.8284
Epoch [23/50] - Loss: 0.8246
Epoch [24/50] - Loss: 0.8217
Epoch [25/50] - Loss: 0.8205
Epoch [26/50] - Loss: 0.8166
Epoch [27/50] - Loss: 0.8134
Epoch [28/50] - Loss: 0.8096
Epoch [29/50] - Loss: 0.8071
Epoch [30/50] - Loss: 0.8047
Epoch [31/50] - Loss: 0.8026
Epoch [32/50] - Loss: 0.7998
Epoch [33/50] - Loss: 0.7986
Epoch [34/50] - Loss: 0.7963
Epoch [35/50] - Loss: 0.7923
Epoch [36/50] - Loss: 0.7897
Epoch [37/50] - Loss: 0.7880
Epoch [38/50] - Loss: 0.7854
Epoch [39/50] - Loss: 0.7818
Epoch [40/50] - Loss: 0.7811
Epoch [41/50] - Loss: 0.7784
Epoch [42/50] - Loss: 0.7755
Epoch [43/50] - Loss: 0.7749
Epoch [44/50] - Loss: 0.7733
Epoch [45/50] - Loss: 0.7705
Epoch [46/50] - Loss: 0.7678
Epoch [47/50] - Loss: 0.7657
Epoch [48/50] - Loss: 0.7623
Epoch [49/50] - Loss: 0.7621
Epoch [50/50] - Loss: 0.7587
sum preds 5
sum labels 2143
 - Test Metrics: Accuracy=0.8083, F1=0.0037, Recall=0.0019, Precision=0.8000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.8999
Epoch [2/50] - Loss: 1.4575
Epoch [3/50] - Loss: 1.1090
Epoch [4/50] - Loss: 1.0063
Epoch [5/50] - Loss: 0.9553
Epoch [6/50] - Loss: 0.9187
Epoch [7/50] - Loss: 0.8982
Epoch [8/50] - Loss: 0.8862
Epoch [9/50] - Loss: 0.8811
Epoch [10/50] - Loss: 0.8730
Epoch [11/50] - Loss: 0.8661
Epoch [12/50] - Loss: 0.8596
Epoch [13/50] - Loss: 0.8541
Epoch [14/50] - Loss: 0.8498
Epoch [15/50] - Loss: 0.8471
Epoch [16/50] - Loss: 0.8438
Epoch [17/50] - Loss: 0.8394
Epoch [18/50] - Loss: 0.8350
Epoch [19/50] - Loss: 0.8321
Epoch [20/50] - Loss: 0.8292
Epoch [21/50] - Loss: 0.8264
Epoch [22/50] - Loss: 0.8238
Epoch [23/50] - Loss: 0.8210
Epoch [24/50] - Loss: 0.8196
Epoch [25/50] - Loss: 0.8155
Epoch [26/50] - Loss: 0.8123
Epoch [27/50] - Loss: 0.8112
Epoch [28/50] - Loss: 0.8088
Epoch [29/50] - Loss: 0.8063
Epoch [30/50] - Loss: 0.8024
Epoch [31/50] - Loss: 0.8001
Epoch [32/50] - Loss: 0.7983
Epoch [33/50] - Loss: 0.7960
Epoch [34/50] - Loss: 0.7927
Epoch [35/50] - Loss: 0.7915
Epoch [36/50] - Loss: 0.7887
Epoch [37/50] - Loss: 0.7852
Epoch [38/50] - Loss: 0.7834
Epoch [39/50] - Loss: 0.7813
Epoch [40/50] - Loss: 0.7785
Epoch [41/50] - Loss: 0.7759
Epoch [42/50] - Loss: 0.7738
Epoch [43/50] - Loss: 0.7720
Epoch [44/50] - Loss: 0.7688
Epoch [45/50] - Loss: 0.7670
Epoch [46/50] - Loss: 0.7654
Epoch [47/50] - Loss: 0.7625
Epoch [48/50] - Loss: 0.7602
Epoch [49/50] - Loss: 0.7583
Epoch [50/50] - Loss: 0.7559
sum preds 14
sum labels 2143
 - Test Metrics: Accuracy=0.8090, F1=0.0111, Recall=0.0056, Precision=0.8571
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=naive
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.7846
Epoch [2/50] - Loss: 2.4298
Epoch [3/50] - Loss: 1.5390
Epoch [4/50] - Loss: 1.2046
Epoch [5/50] - Loss: 1.0743
Epoch [6/50] - Loss: 1.0158
Epoch [7/50] - Loss: 0.9792
Epoch [8/50] - Loss: 0.9510
Epoch [9/50] - Loss: 0.9337
Epoch [10/50] - Loss: 0.9160
Epoch [11/50] - Loss: 0.9049
Epoch [12/50] - Loss: 0.8977
Epoch [13/50] - Loss: 0.8902
Epoch [14/50] - Loss: 0.8865
Epoch [15/50] - Loss: 0.8806
Epoch [16/50] - Loss: 0.8760
Epoch [17/50] - Loss: 0.8738
Epoch [18/50] - Loss: 0.8715
Epoch [19/50] - Loss: 0.8665
Epoch [20/50] - Loss: 0.8631
Epoch [21/50] - Loss: 0.8611
Epoch [22/50] - Loss: 0.8582
Epoch [23/50] - Loss: 0.8559
Epoch [24/50] - Loss: 0.8524
Epoch [25/50] - Loss: 0.8498
Epoch [26/50] - Loss: 0.8484
Epoch [27/50] - Loss: 0.8460
Epoch [28/50] - Loss: 0.8439
Epoch [29/50] - Loss: 0.8412
Epoch [30/50] - Loss: 0.8391
Epoch [31/50] - Loss: 0.8372
Epoch [32/50] - Loss: 0.8363
Epoch [33/50] - Loss: 0.8342
Epoch [34/50] - Loss: 0.8320
Epoch [35/50] - Loss: 0.8316
Epoch [36/50] - Loss: 0.8264
Epoch [37/50] - Loss: 0.8261
Epoch [38/50] - Loss: 0.8252
Epoch [39/50] - Loss: 0.8231
Epoch [40/50] - Loss: 0.8214
Epoch [41/50] - Loss: 0.8190
Epoch [42/50] - Loss: 0.8164
Epoch [43/50] - Loss: 0.8147
Epoch [44/50] - Loss: 0.8139
Epoch [45/50] - Loss: 0.8132
Epoch [46/50] - Loss: 0.8104
Epoch [47/50] - Loss: 0.8101
Epoch [48/50] - Loss: 0.8072
Epoch [49/50] - Loss: 0.8068
Epoch [50/50] - Loss: 0.8038
sum preds 8
sum labels 2143
 - Test Metrics: Accuracy=0.8088, F1=0.0074, Recall=0.0037, Precision=1.0000
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_naive_naive_1904093032.csv.
Average F1 over valid seeds: 0.0074 ± 0.0030
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and naive, GCNConv,0.2: 0.0074 ± 0.0030
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8920, F1=0.4660, Recall=0.3118, Precision=0.9227
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8923, F1=0.4637, Recall=0.3080, Precision=0.9375
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8973, F1=0.5014, Recall=0.3416, Precision=0.9417
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_NNIF_NNIF_1904094139.csv.
Average F1 over valid seeds: 0.4770 ± 0.0172
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and NNIF, MLP,0.4: 0.4770 ± 0.0172
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8743, F1=0.4435, Recall=0.2912, Precision=0.9302
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8751, F1=0.4483, Recall=0.2949, Precision=0.9341
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8724, F1=0.4275, Recall=0.2768, Precision=0.9385
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_NNIF_NNIF_1904094234.csv.
Average F1 over valid seeds: 0.4398 ± 0.0089
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and NNIF, MLP,0.3: 0.4398 ± 0.0089
___________________________________________________________________________________
NNIF
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8436, F1=0.3238, Recall=0.1951, Precision=0.9522
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8395, F1=0.2917, Recall=0.1722, Precision=0.9535
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=1
 - norm=None, dropout=0, batch_size=2048, methodology=NNIF
 - ratio=0.12196931419847329, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
 - Test Metrics: Accuracy=0.8425, F1=0.3154, Recall=0.1890, Precision=0.9529
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_NNIF_NNIF_1904094306.csv.
Average F1 over valid seeds: 0.3103 ± 0.0136
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and NNIF, MLP,0.2: 0.3103 ± 0.0136
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.0710
Epoch [2/50] - Loss: 1.4226
Epoch [3/50] - Loss: 1.1981
Epoch [4/50] - Loss: 1.1198
Epoch [5/50] - Loss: 1.0558
Epoch [6/50] - Loss: 0.9993
Epoch [7/50] - Loss: 0.9626
Epoch [8/50] - Loss: 0.9295
Epoch [9/50] - Loss: 0.9013
Epoch [10/50] - Loss: 0.8744
Epoch [11/50] - Loss: 0.8504
Epoch [12/50] - Loss: 0.8261
Epoch [13/50] - Loss: 0.8059
Epoch [14/50] - Loss: 0.7829
Epoch [15/50] - Loss: 0.7622
Epoch [16/50] - Loss: 0.7406
Epoch [17/50] - Loss: 0.7184
Epoch [18/50] - Loss: 0.6993
Epoch [19/50] - Loss: 0.6771
Epoch [20/50] - Loss: 0.6589
Epoch [21/50] - Loss: 0.6397
Epoch [22/50] - Loss: 0.6200
Epoch [23/50] - Loss: 0.6000
Epoch [24/50] - Loss: 0.5813
Epoch [25/50] - Loss: 0.5627
Epoch [26/50] - Loss: 0.5436
Epoch [27/50] - Loss: 0.5253
Epoch [28/50] - Loss: 0.5068
Epoch [29/50] - Loss: 0.4886
Epoch [30/50] - Loss: 0.4709
Epoch [31/50] - Loss: 0.4536
Epoch [32/50] - Loss: 0.4355
Epoch [33/50] - Loss: 0.4202
Epoch [34/50] - Loss: 0.4043
Epoch [35/50] - Loss: 0.3877
Epoch [36/50] - Loss: 0.3726
Epoch [37/50] - Loss: 0.3571
Epoch [38/50] - Loss: 0.3424
Epoch [39/50] - Loss: 0.3284
Epoch [40/50] - Loss: 0.3144
Epoch [41/50] - Loss: 0.3011
Epoch [42/50] - Loss: 0.2889
Epoch [43/50] - Loss: 0.2768
Epoch [44/50] - Loss: 0.2649
Epoch [45/50] - Loss: 0.2535
Epoch [46/50] - Loss: 0.2425
Epoch [47/50] - Loss: 0.2323
Epoch [48/50] - Loss: 0.2220
Epoch [49/50] - Loss: 0.2127
Epoch [50/50] - Loss: 0.2034
sum preds 476
sum labels 1607
 - Test Metrics: Accuracy=0.8849, F1=0.4129, Recall=0.2676, Precision=0.9034
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.6085
Epoch [2/50] - Loss: 1.3605
Epoch [3/50] - Loss: 1.1799
Epoch [4/50] - Loss: 1.1062
Epoch [5/50] - Loss: 1.0434
Epoch [6/50] - Loss: 0.9951
Epoch [7/50] - Loss: 0.9586
Epoch [8/50] - Loss: 0.9244
Epoch [9/50] - Loss: 0.8932
Epoch [10/50] - Loss: 0.8635
Epoch [11/50] - Loss: 0.8355
Epoch [12/50] - Loss: 0.8084
Epoch [13/50] - Loss: 0.7796
Epoch [14/50] - Loss: 0.7540
Epoch [15/50] - Loss: 0.7281
Epoch [16/50] - Loss: 0.7018
Epoch [17/50] - Loss: 0.6781
Epoch [18/50] - Loss: 0.6541
Epoch [19/50] - Loss: 0.6309
Epoch [20/50] - Loss: 0.6077
Epoch [21/50] - Loss: 0.5861
Epoch [22/50] - Loss: 0.5641
Epoch [23/50] - Loss: 0.5428
Epoch [24/50] - Loss: 0.5220
Epoch [25/50] - Loss: 0.5023
Epoch [26/50] - Loss: 0.4822
Epoch [27/50] - Loss: 0.4640
Epoch [28/50] - Loss: 0.4459
Epoch [29/50] - Loss: 0.4274
Epoch [30/50] - Loss: 0.4093
Epoch [31/50] - Loss: 0.3923
Epoch [32/50] - Loss: 0.3756
Epoch [33/50] - Loss: 0.3623
Epoch [34/50] - Loss: 0.3466
Epoch [35/50] - Loss: 0.3307
Epoch [36/50] - Loss: 0.3185
Epoch [37/50] - Loss: 0.3042
Epoch [38/50] - Loss: 0.2928
Epoch [39/50] - Loss: 0.2806
Epoch [40/50] - Loss: 0.2689
Epoch [41/50] - Loss: 0.2576
Epoch [42/50] - Loss: 0.2460
Epoch [43/50] - Loss: 0.2366
Epoch [44/50] - Loss: 0.2267
Epoch [45/50] - Loss: 0.2171
Epoch [46/50] - Loss: 0.2083
Epoch [47/50] - Loss: 0.1997
Epoch [48/50] - Loss: 0.1914
Epoch [49/50] - Loss: 0.1838
Epoch [50/50] - Loss: 0.1755
sum preds 482
sum labels 1607
 - Test Metrics: Accuracy=0.8849, F1=0.4146, Recall=0.2694, Precision=0.8983
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.0889
Epoch [2/50] - Loss: 1.2557
Epoch [3/50] - Loss: 1.0957
Epoch [4/50] - Loss: 1.0304
Epoch [5/50] - Loss: 0.9720
Epoch [6/50] - Loss: 0.9359
Epoch [7/50] - Loss: 0.9000
Epoch [8/50] - Loss: 0.8675
Epoch [9/50] - Loss: 0.8355
Epoch [10/50] - Loss: 0.8051
Epoch [11/50] - Loss: 0.7780
Epoch [12/50] - Loss: 0.7506
Epoch [13/50] - Loss: 0.7236
Epoch [14/50] - Loss: 0.6983
Epoch [15/50] - Loss: 0.6709
Epoch [16/50] - Loss: 0.6455
Epoch [17/50] - Loss: 0.6190
Epoch [18/50] - Loss: 0.5939
Epoch [19/50] - Loss: 0.5701
Epoch [20/50] - Loss: 0.5464
Epoch [21/50] - Loss: 0.5246
Epoch [22/50] - Loss: 0.5027
Epoch [23/50] - Loss: 0.4824
Epoch [24/50] - Loss: 0.4610
Epoch [25/50] - Loss: 0.4418
Epoch [26/50] - Loss: 0.4225
Epoch [27/50] - Loss: 0.4044
Epoch [28/50] - Loss: 0.3865
Epoch [29/50] - Loss: 0.3701
Epoch [30/50] - Loss: 0.3543
Epoch [31/50] - Loss: 0.3380
Epoch [32/50] - Loss: 0.3226
Epoch [33/50] - Loss: 0.3081
Epoch [34/50] - Loss: 0.2947
Epoch [35/50] - Loss: 0.2809
Epoch [36/50] - Loss: 0.2683
Epoch [37/50] - Loss: 0.2562
Epoch [38/50] - Loss: 0.2438
Epoch [39/50] - Loss: 0.2317
Epoch [40/50] - Loss: 0.2210
Epoch [41/50] - Loss: 0.2108
Epoch [42/50] - Loss: 0.2010
Epoch [43/50] - Loss: 0.1916
Epoch [44/50] - Loss: 0.1828
Epoch [45/50] - Loss: 0.1740
Epoch [46/50] - Loss: 0.1654
Epoch [47/50] - Loss: 0.1579
Epoch [48/50] - Loss: 0.1505
Epoch [49/50] - Loss: 0.1437
Epoch [50/50] - Loss: 0.1369
sum preds 493
sum labels 1607
 - Test Metrics: Accuracy=0.8873, F1=0.4295, Recall=0.2806, Precision=0.9148
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_two_nnif_two_nnif_1904094341.csv.
Average F1 over valid seeds: 0.4190 ± 0.0075
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and two_nnif, MLP,0.4: 0.4190 ± 0.0075
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.5773
Epoch [2/50] - Loss: 1.3116
Epoch [3/50] - Loss: 1.1931
Epoch [4/50] - Loss: 1.1168
Epoch [5/50] - Loss: 1.0815
Epoch [6/50] - Loss: 1.0557
Epoch [7/50] - Loss: 1.0328
Epoch [8/50] - Loss: 1.0113
Epoch [9/50] - Loss: 0.9963
Epoch [10/50] - Loss: 0.9787
Epoch [11/50] - Loss: 0.9678
Epoch [12/50] - Loss: 0.9564
Epoch [13/50] - Loss: 0.9483
Epoch [14/50] - Loss: 0.9402
Epoch [15/50] - Loss: 0.9312
Epoch [16/50] - Loss: 0.9217
Epoch [17/50] - Loss: 0.9139
Epoch [18/50] - Loss: 0.9061
Epoch [19/50] - Loss: 0.9003
Epoch [20/50] - Loss: 0.8952
Epoch [21/50] - Loss: 0.8868
Epoch [22/50] - Loss: 0.8794
Epoch [23/50] - Loss: 0.8724
Epoch [24/50] - Loss: 0.8690
Epoch [25/50] - Loss: 0.8629
Epoch [26/50] - Loss: 0.8573
Epoch [27/50] - Loss: 0.8525
Epoch [28/50] - Loss: 0.8468
Epoch [29/50] - Loss: 0.8412
Epoch [30/50] - Loss: 0.8351
Epoch [31/50] - Loss: 0.8297
Epoch [32/50] - Loss: 0.8224
Epoch [33/50] - Loss: 0.8222
Epoch [34/50] - Loss: 0.8194
Epoch [35/50] - Loss: 0.8186
Epoch [36/50] - Loss: 0.8121
Epoch [37/50] - Loss: 0.8096
Epoch [38/50] - Loss: 0.8065
Epoch [39/50] - Loss: 0.7956
Epoch [40/50] - Loss: 0.7933
Epoch [41/50] - Loss: 0.7894
Epoch [42/50] - Loss: 0.7840
Epoch [43/50] - Loss: 0.7822
Epoch [44/50] - Loss: 0.7805
Epoch [45/50] - Loss: 0.7787
Epoch [46/50] - Loss: 0.7810
Epoch [47/50] - Loss: 0.7773
Epoch [48/50] - Loss: 0.7695
Epoch [49/50] - Loss: 0.7624
Epoch [50/50] - Loss: 0.7573
sum preds 860
sum labels 1607
 - Test Metrics: Accuracy=0.9192, F1=0.6518, Recall=0.5003, Precision=0.9349
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9507
Epoch [2/50] - Loss: 1.2072
Epoch [3/50] - Loss: 1.1241
Epoch [4/50] - Loss: 1.0639
Epoch [5/50] - Loss: 1.0364
Epoch [6/50] - Loss: 1.0082
Epoch [7/50] - Loss: 0.9858
Epoch [8/50] - Loss: 0.9710
Epoch [9/50] - Loss: 0.9576
Epoch [10/50] - Loss: 0.9437
Epoch [11/50] - Loss: 0.9318
Epoch [12/50] - Loss: 0.9206
Epoch [13/50] - Loss: 0.9114
Epoch [14/50] - Loss: 0.9040
Epoch [15/50] - Loss: 0.8973
Epoch [16/50] - Loss: 0.8886
Epoch [17/50] - Loss: 0.8818
Epoch [18/50] - Loss: 0.8718
Epoch [19/50] - Loss: 0.8653
Epoch [20/50] - Loss: 0.8579
Epoch [21/50] - Loss: 0.8529
Epoch [22/50] - Loss: 0.8456
Epoch [23/50] - Loss: 0.8478
Epoch [24/50] - Loss: 0.8437
Epoch [25/50] - Loss: 0.8343
Epoch [26/50] - Loss: 0.8249
Epoch [27/50] - Loss: 0.8178
Epoch [28/50] - Loss: 0.8180
Epoch [29/50] - Loss: 0.8193
Epoch [30/50] - Loss: 0.8118
Epoch [31/50] - Loss: 0.8036
Epoch [32/50] - Loss: 0.8037
Epoch [33/50] - Loss: 0.8000
Epoch [34/50] - Loss: 0.7933
Epoch [35/50] - Loss: 0.7909
Epoch [36/50] - Loss: 0.7812
Epoch [37/50] - Loss: 0.7769
Epoch [38/50] - Loss: 0.7758
Epoch [39/50] - Loss: 0.7769
Epoch [40/50] - Loss: 0.7673
Epoch [41/50] - Loss: 0.7655
Epoch [42/50] - Loss: 0.7619
Epoch [43/50] - Loss: 0.7611
Epoch [44/50] - Loss: 0.7606
Epoch [45/50] - Loss: 0.7564
Epoch [46/50] - Loss: 0.7521
Epoch [47/50] - Loss: 0.7571
Epoch [48/50] - Loss: 0.7530
Epoch [49/50] - Loss: 0.7528
Epoch [50/50] - Loss: 0.7442
sum preds 998
sum labels 1607
 - Test Metrics: Accuracy=0.9301, F1=0.7148, Recall=0.5793, Precision=0.9329
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9308
Epoch [2/50] - Loss: 1.2935
Epoch [3/50] - Loss: 1.1302
Epoch [4/50] - Loss: 1.0841
Epoch [5/50] - Loss: 1.0535
Epoch [6/50] - Loss: 1.0358
Epoch [7/50] - Loss: 1.0174
Epoch [8/50] - Loss: 1.0013
Epoch [9/50] - Loss: 0.9870
Epoch [10/50] - Loss: 0.9748
Epoch [11/50] - Loss: 0.9660
Epoch [12/50] - Loss: 0.9589
Epoch [13/50] - Loss: 0.9474
Epoch [14/50] - Loss: 0.9369
Epoch [15/50] - Loss: 0.9310
Epoch [16/50] - Loss: 0.9251
Epoch [17/50] - Loss: 0.9133
Epoch [18/50] - Loss: 0.9089
Epoch [19/50] - Loss: 0.9060
Epoch [20/50] - Loss: 0.9005
Epoch [21/50] - Loss: 0.8890
Epoch [22/50] - Loss: 0.8830
Epoch [23/50] - Loss: 0.8791
Epoch [24/50] - Loss: 0.8700
Epoch [25/50] - Loss: 0.8647
Epoch [26/50] - Loss: 0.8593
Epoch [27/50] - Loss: 0.8582
Epoch [28/50] - Loss: 0.8543
Epoch [29/50] - Loss: 0.8497
Epoch [30/50] - Loss: 0.8407
Epoch [31/50] - Loss: 0.8355
Epoch [32/50] - Loss: 0.8307
Epoch [33/50] - Loss: 0.8241
Epoch [34/50] - Loss: 0.8218
Epoch [35/50] - Loss: 0.8172
Epoch [36/50] - Loss: 0.8093
Epoch [37/50] - Loss: 0.8049
Epoch [38/50] - Loss: 0.7975
Epoch [39/50] - Loss: 0.7993
Epoch [40/50] - Loss: 0.7954
Epoch [41/50] - Loss: 0.7900
Epoch [42/50] - Loss: 0.7890
Epoch [43/50] - Loss: 0.7788
Epoch [44/50] - Loss: 0.7725
Epoch [45/50] - Loss: 0.7749
Epoch [46/50] - Loss: 0.7712
Epoch [47/50] - Loss: 0.7620
Epoch [48/50] - Loss: 0.7589
Epoch [49/50] - Loss: 0.7524
Epoch [50/50] - Loss: 0.7541
sum preds 858
sum labels 1607
 - Test Metrics: Accuracy=0.9197, F1=0.6540, Recall=0.5016, Precision=0.9394
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_two_nnif_two_nnif_1904095359.csv.
Average F1 over valid seeds: 0.6735 ± 0.0292
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and two_nnif, GATConv,0.4: 0.6735 ± 0.0292
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.6970
Epoch [2/50] - Loss: 1.4384
Epoch [3/50] - Loss: 1.2275
Epoch [4/50] - Loss: 1.1557
Epoch [5/50] - Loss: 1.1095
Epoch [6/50] - Loss: 1.0842
Epoch [7/50] - Loss: 1.0702
Epoch [8/50] - Loss: 1.0580
Epoch [9/50] - Loss: 1.0484
Epoch [10/50] - Loss: 1.0406
Epoch [11/50] - Loss: 1.0298
Epoch [12/50] - Loss: 1.0246
Epoch [13/50] - Loss: 1.0195
Epoch [14/50] - Loss: 1.0140
Epoch [15/50] - Loss: 1.0095
Epoch [16/50] - Loss: 1.0061
Epoch [17/50] - Loss: 1.0007
Epoch [18/50] - Loss: 0.9956
Epoch [19/50] - Loss: 0.9926
Epoch [20/50] - Loss: 0.9907
Epoch [21/50] - Loss: 0.9850
Epoch [22/50] - Loss: 0.9800
Epoch [23/50] - Loss: 0.9792
Epoch [24/50] - Loss: 0.9762
Epoch [25/50] - Loss: 0.9710
Epoch [26/50] - Loss: 0.9692
Epoch [27/50] - Loss: 0.9650
Epoch [28/50] - Loss: 0.9642
Epoch [29/50] - Loss: 0.9608
Epoch [30/50] - Loss: 0.9566
Epoch [31/50] - Loss: 0.9544
Epoch [32/50] - Loss: 0.9514
Epoch [33/50] - Loss: 0.9493
Epoch [34/50] - Loss: 0.9460
Epoch [35/50] - Loss: 0.9453
Epoch [36/50] - Loss: 0.9412
Epoch [37/50] - Loss: 0.9404
Epoch [38/50] - Loss: 0.9358
Epoch [39/50] - Loss: 0.9335
Epoch [40/50] - Loss: 0.9335
Epoch [41/50] - Loss: 0.9281
Epoch [42/50] - Loss: 0.9261
Epoch [43/50] - Loss: 0.9232
Epoch [44/50] - Loss: 0.9193
Epoch [45/50] - Loss: 0.9175
Epoch [46/50] - Loss: 0.9136
Epoch [47/50] - Loss: 0.9130
Epoch [48/50] - Loss: 0.9103
Epoch [49/50] - Loss: 0.9085
Epoch [50/50] - Loss: 0.9069
sum preds 714
sum labels 1607
 - Test Metrics: Accuracy=0.9090, F1=0.5834, Recall=0.4213, Precision=0.9482
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.8499
Epoch [2/50] - Loss: 1.5675
Epoch [3/50] - Loss: 1.2831
Epoch [4/50] - Loss: 1.1929
Epoch [5/50] - Loss: 1.1443
Epoch [6/50] - Loss: 1.1193
Epoch [7/50] - Loss: 1.0985
Epoch [8/50] - Loss: 1.0846
Epoch [9/50] - Loss: 1.0714
Epoch [10/50] - Loss: 1.0589
Epoch [11/50] - Loss: 1.0486
Epoch [12/50] - Loss: 1.0389
Epoch [13/50] - Loss: 1.0329
Epoch [14/50] - Loss: 1.0276
Epoch [15/50] - Loss: 1.0198
Epoch [16/50] - Loss: 1.0138
Epoch [17/50] - Loss: 1.0080
Epoch [18/50] - Loss: 1.0036
Epoch [19/50] - Loss: 0.9980
Epoch [20/50] - Loss: 0.9942
Epoch [21/50] - Loss: 0.9909
Epoch [22/50] - Loss: 0.9843
Epoch [23/50] - Loss: 0.9785
Epoch [24/50] - Loss: 0.9743
Epoch [25/50] - Loss: 0.9728
Epoch [26/50] - Loss: 0.9683
Epoch [27/50] - Loss: 0.9635
Epoch [28/50] - Loss: 0.9621
Epoch [29/50] - Loss: 0.9550
Epoch [30/50] - Loss: 0.9524
Epoch [31/50] - Loss: 0.9497
Epoch [32/50] - Loss: 0.9443
Epoch [33/50] - Loss: 0.9449
Epoch [34/50] - Loss: 0.9384
Epoch [35/50] - Loss: 0.9354
Epoch [36/50] - Loss: 0.9352
Epoch [37/50] - Loss: 0.9313
Epoch [38/50] - Loss: 0.9275
Epoch [39/50] - Loss: 0.9236
Epoch [40/50] - Loss: 0.9217
Epoch [41/50] - Loss: 0.9191
Epoch [42/50] - Loss: 0.9141
Epoch [43/50] - Loss: 0.9120
Epoch [44/50] - Loss: 0.9109
Epoch [45/50] - Loss: 0.9072
Epoch [46/50] - Loss: 0.9096
Epoch [47/50] - Loss: 0.9050
Epoch [48/50] - Loss: 0.9018
Epoch [49/50] - Loss: 0.8969
Epoch [50/50] - Loss: 0.8958
sum preds 825
sum labels 1607
 - Test Metrics: Accuracy=0.9187, F1=0.6447, Recall=0.4879, Precision=0.9503
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.07130460889223814, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 4.4833
Epoch [2/50] - Loss: 2.3994
Epoch [3/50] - Loss: 1.6134
Epoch [4/50] - Loss: 1.3370
Epoch [5/50] - Loss: 1.2260
Epoch [6/50] - Loss: 1.1726
Epoch [7/50] - Loss: 1.1415
Epoch [8/50] - Loss: 1.1180
Epoch [9/50] - Loss: 1.1024
Epoch [10/50] - Loss: 1.0903
Epoch [11/50] - Loss: 1.0804
Epoch [12/50] - Loss: 1.0732
Epoch [13/50] - Loss: 1.0683
Epoch [14/50] - Loss: 1.0612
Epoch [15/50] - Loss: 1.0571
Epoch [16/50] - Loss: 1.0516
Epoch [17/50] - Loss: 1.0463
Epoch [18/50] - Loss: 1.0414
Epoch [19/50] - Loss: 1.0388
Epoch [20/50] - Loss: 1.0341
Epoch [21/50] - Loss: 1.0308
Epoch [22/50] - Loss: 1.0262
Epoch [23/50] - Loss: 1.0216
Epoch [24/50] - Loss: 1.0197
Epoch [25/50] - Loss: 1.0157
Epoch [26/50] - Loss: 1.0142
Epoch [27/50] - Loss: 1.0096
Epoch [28/50] - Loss: 1.0070
Epoch [29/50] - Loss: 1.0054
Epoch [30/50] - Loss: 1.0040
Epoch [31/50] - Loss: 1.0010
Epoch [32/50] - Loss: 0.9973
Epoch [33/50] - Loss: 0.9948
Epoch [34/50] - Loss: 0.9939
Epoch [35/50] - Loss: 0.9913
Epoch [36/50] - Loss: 0.9882
Epoch [37/50] - Loss: 0.9848
Epoch [38/50] - Loss: 0.9844
Epoch [39/50] - Loss: 0.9836
Epoch [40/50] - Loss: 0.9798
Epoch [41/50] - Loss: 0.9778
Epoch [42/50] - Loss: 0.9785
Epoch [43/50] - Loss: 0.9753
Epoch [44/50] - Loss: 0.9716
Epoch [45/50] - Loss: 0.9698
Epoch [46/50] - Loss: 0.9696
Epoch [47/50] - Loss: 0.9662
Epoch [48/50] - Loss: 0.9629
Epoch [49/50] - Loss: 0.9627
Epoch [50/50] - Loss: 0.9591
sum preds 868
sum labels 1607
 - Test Metrics: Accuracy=0.9226, F1=0.6675, Recall=0.5140, Precision=0.9516
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_two_nnif_two_nnif_1904100503.csv.
Average F1 over valid seeds: 0.6319 ± 0.0355
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and two_nnif, GCNConv,0.4: 0.6319 ± 0.0355
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 3.0746
Epoch [2/50] - Loss: 1.3578
Epoch [3/50] - Loss: 1.1071
Epoch [4/50] - Loss: 1.0441
Epoch [5/50] - Loss: 0.9795
Epoch [6/50] - Loss: 0.9258
Epoch [7/50] - Loss: 0.8839
Epoch [8/50] - Loss: 0.8537
Epoch [9/50] - Loss: 0.8251
Epoch [10/50] - Loss: 0.7999
Epoch [11/50] - Loss: 0.7775
Epoch [12/50] - Loss: 0.7545
Epoch [13/50] - Loss: 0.7341
Epoch [14/50] - Loss: 0.7139
Epoch [15/50] - Loss: 0.6938
Epoch [16/50] - Loss: 0.6754
Epoch [17/50] - Loss: 0.6575
Epoch [18/50] - Loss: 0.6378
Epoch [19/50] - Loss: 0.6201
Epoch [20/50] - Loss: 0.6012
Epoch [21/50] - Loss: 0.5847
Epoch [22/50] - Loss: 0.5661
Epoch [23/50] - Loss: 0.5488
Epoch [24/50] - Loss: 0.5316
Epoch [25/50] - Loss: 0.5142
Epoch [26/50] - Loss: 0.4972
Epoch [27/50] - Loss: 0.4806
Epoch [28/50] - Loss: 0.4634
Epoch [29/50] - Loss: 0.4472
Epoch [30/50] - Loss: 0.4313
Epoch [31/50] - Loss: 0.4152
Epoch [32/50] - Loss: 0.4001
Epoch [33/50] - Loss: 0.3844
Epoch [34/50] - Loss: 0.3696
Epoch [35/50] - Loss: 0.3551
Epoch [36/50] - Loss: 0.3402
Epoch [37/50] - Loss: 0.3263
Epoch [38/50] - Loss: 0.3129
Epoch [39/50] - Loss: 0.2994
Epoch [40/50] - Loss: 0.2877
Epoch [41/50] - Loss: 0.2748
Epoch [42/50] - Loss: 0.2627
Epoch [43/50] - Loss: 0.2512
Epoch [44/50] - Loss: 0.2402
Epoch [45/50] - Loss: 0.2289
Epoch [46/50] - Loss: 0.2184
Epoch [47/50] - Loss: 0.2081
Epoch [48/50] - Loss: 0.1986
Epoch [49/50] - Loss: 0.1897
Epoch [50/50] - Loss: 0.1805
sum preds 514
sum labels 1875
 - Test Metrics: Accuracy=0.8663, F1=0.3901, Recall=0.2485, Precision=0.9066
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.5839
Epoch [2/50] - Loss: 1.2931
Epoch [3/50] - Loss: 1.1087
Epoch [4/50] - Loss: 1.0450
Epoch [5/50] - Loss: 0.9867
Epoch [6/50] - Loss: 0.9436
Epoch [7/50] - Loss: 0.9090
Epoch [8/50] - Loss: 0.8778
Epoch [9/50] - Loss: 0.8471
Epoch [10/50] - Loss: 0.8153
Epoch [11/50] - Loss: 0.7876
Epoch [12/50] - Loss: 0.7636
Epoch [13/50] - Loss: 0.7360
Epoch [14/50] - Loss: 0.7104
Epoch [15/50] - Loss: 0.6837
Epoch [16/50] - Loss: 0.6603
Epoch [17/50] - Loss: 0.6357
Epoch [18/50] - Loss: 0.6125
Epoch [19/50] - Loss: 0.5883
Epoch [20/50] - Loss: 0.5655
Epoch [21/50] - Loss: 0.5440
Epoch [22/50] - Loss: 0.5218
Epoch [23/50] - Loss: 0.4998
Epoch [24/50] - Loss: 0.4791
Epoch [25/50] - Loss: 0.4579
Epoch [26/50] - Loss: 0.4384
Epoch [27/50] - Loss: 0.4181
Epoch [28/50] - Loss: 0.3995
Epoch [29/50] - Loss: 0.3807
Epoch [30/50] - Loss: 0.3625
Epoch [31/50] - Loss: 0.3455
Epoch [32/50] - Loss: 0.3289
Epoch [33/50] - Loss: 0.3127
Epoch [34/50] - Loss: 0.2984
Epoch [35/50] - Loss: 0.2833
Epoch [36/50] - Loss: 0.2689
Epoch [37/50] - Loss: 0.2561
Epoch [38/50] - Loss: 0.2439
Epoch [39/50] - Loss: 0.2318
Epoch [40/50] - Loss: 0.2217
Epoch [41/50] - Loss: 0.2113
Epoch [42/50] - Loss: 0.2020
Epoch [43/50] - Loss: 0.1921
Epoch [44/50] - Loss: 0.1832
Epoch [45/50] - Loss: 0.1748
Epoch [46/50] - Loss: 0.1666
Epoch [47/50] - Loss: 0.1581
Epoch [48/50] - Loss: 0.1512
Epoch [49/50] - Loss: 0.1443
Epoch [50/50] - Loss: 0.1376
sum preds 442
sum labels 1875
 - Test Metrics: Accuracy=0.8591, F1=0.3375, Recall=0.2085, Precision=0.8846
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=MLP, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.9892
Epoch [2/50] - Loss: 1.1683
Epoch [3/50] - Loss: 1.0140
Epoch [4/50] - Loss: 0.9554
Epoch [5/50] - Loss: 0.9100
Epoch [6/50] - Loss: 0.8750
Epoch [7/50] - Loss: 0.8435
Epoch [8/50] - Loss: 0.8132
Epoch [9/50] - Loss: 0.7828
Epoch [10/50] - Loss: 0.7529
Epoch [11/50] - Loss: 0.7215
Epoch [12/50] - Loss: 0.6889
Epoch [13/50] - Loss: 0.6581
Epoch [14/50] - Loss: 0.6275
Epoch [15/50] - Loss: 0.5966
Epoch [16/50] - Loss: 0.5667
Epoch [17/50] - Loss: 0.5383
Epoch [18/50] - Loss: 0.5101
Epoch [19/50] - Loss: 0.4824
Epoch [20/50] - Loss: 0.4565
Epoch [21/50] - Loss: 0.4318
Epoch [22/50] - Loss: 0.4089
Epoch [23/50] - Loss: 0.3866
Epoch [24/50] - Loss: 0.3654
Epoch [25/50] - Loss: 0.3457
Epoch [26/50] - Loss: 0.3266
Epoch [27/50] - Loss: 0.3092
Epoch [28/50] - Loss: 0.2924
Epoch [29/50] - Loss: 0.2763
Epoch [30/50] - Loss: 0.2602
Epoch [31/50] - Loss: 0.2453
Epoch [32/50] - Loss: 0.2314
Epoch [33/50] - Loss: 0.2193
Epoch [34/50] - Loss: 0.2060
Epoch [35/50] - Loss: 0.1941
Epoch [36/50] - Loss: 0.1829
Epoch [37/50] - Loss: 0.1719
Epoch [38/50] - Loss: 0.1623
Epoch [39/50] - Loss: 0.1527
Epoch [40/50] - Loss: 0.1444
Epoch [41/50] - Loss: 0.1356
Epoch [42/50] - Loss: 0.1279
Epoch [43/50] - Loss: 0.1207
Epoch [44/50] - Loss: 0.1140
Epoch [45/50] - Loss: 0.1072
Epoch [46/50] - Loss: 0.1011
Epoch [47/50] - Loss: 0.0953
Epoch [48/50] - Loss: 0.0901
Epoch [49/50] - Loss: 0.0851
Epoch [50/50] - Loss: 0.0807
sum preds 466
sum labels 1875
 - Test Metrics: Accuracy=0.8612, F1=0.3537, Recall=0.2208, Precision=0.8884
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_two_nnif_two_nnif_1904101721.csv.
Average F1 over valid seeds: 0.3604 ± 0.0220
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and two_nnif, MLP,0.3: 0.3604 ± 0.0220
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.4435
Epoch [2/50] - Loss: 1.2422
Epoch [3/50] - Loss: 1.1047
Epoch [4/50] - Loss: 1.0297
Epoch [5/50] - Loss: 0.9910
Epoch [6/50] - Loss: 0.9681
Epoch [7/50] - Loss: 0.9422
Epoch [8/50] - Loss: 0.9241
Epoch [9/50] - Loss: 0.9095
Epoch [10/50] - Loss: 0.9006
Epoch [11/50] - Loss: 0.8881
Epoch [12/50] - Loss: 0.8797
Epoch [13/50] - Loss: 0.8698
Epoch [14/50] - Loss: 0.8644
Epoch [15/50] - Loss: 0.8541
Epoch [16/50] - Loss: 0.8487
Epoch [17/50] - Loss: 0.8433
Epoch [18/50] - Loss: 0.8401
Epoch [19/50] - Loss: 0.8366
Epoch [20/50] - Loss: 0.8264
Epoch [21/50] - Loss: 0.8229
Epoch [22/50] - Loss: 0.8120
Epoch [23/50] - Loss: 0.8079
Epoch [24/50] - Loss: 0.8016
Epoch [25/50] - Loss: 0.7989
Epoch [26/50] - Loss: 0.7934
Epoch [27/50] - Loss: 0.7920
Epoch [28/50] - Loss: 0.7865
Epoch [29/50] - Loss: 0.7803
Epoch [30/50] - Loss: 0.7737
Epoch [31/50] - Loss: 0.7667
Epoch [32/50] - Loss: 0.7570
Epoch [33/50] - Loss: 0.7560
Epoch [34/50] - Loss: 0.7593
Epoch [35/50] - Loss: 0.7498
Epoch [36/50] - Loss: 0.7475
Epoch [37/50] - Loss: 0.7432
Epoch [38/50] - Loss: 0.7440
Epoch [39/50] - Loss: 0.7377
Epoch [40/50] - Loss: 0.7304
Epoch [41/50] - Loss: 0.7231
Epoch [42/50] - Loss: 0.7240
Epoch [43/50] - Loss: 0.7174
Epoch [44/50] - Loss: 0.7195
Epoch [45/50] - Loss: 0.7122
Epoch [46/50] - Loss: 0.7106
Epoch [47/50] - Loss: 0.7037
Epoch [48/50] - Loss: 0.7025
Epoch [49/50] - Loss: 0.6994
Epoch [50/50] - Loss: 0.6981
sum preds 620
sum labels 1875
 - Test Metrics: Accuracy=0.8775, F1=0.4649, Recall=0.3093, Precision=0.9355
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=114:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8376
Epoch [2/50] - Loss: 1.1202
Epoch [3/50] - Loss: 1.0391
Epoch [4/50] - Loss: 0.9947
Epoch [5/50] - Loss: 0.9602
Epoch [6/50] - Loss: 0.9339
Epoch [7/50] - Loss: 0.9179
Epoch [8/50] - Loss: 0.9049
Epoch [9/50] - Loss: 0.8919
Epoch [10/50] - Loss: 0.8834
Epoch [11/50] - Loss: 0.8747
Epoch [12/50] - Loss: 0.8667
Epoch [13/50] - Loss: 0.8585
Epoch [14/50] - Loss: 0.8539
Epoch [15/50] - Loss: 0.8458
Epoch [16/50] - Loss: 0.8454
Epoch [17/50] - Loss: 0.8367
Epoch [18/50] - Loss: 0.8299
Epoch [19/50] - Loss: 0.8255
Epoch [20/50] - Loss: 0.8182
Epoch [21/50] - Loss: 0.8113
Epoch [22/50] - Loss: 0.8067
Epoch [23/50] - Loss: 0.8021
Epoch [24/50] - Loss: 0.7942
Epoch [25/50] - Loss: 0.7907
Epoch [26/50] - Loss: 0.7865
Epoch [27/50] - Loss: 0.7809
Epoch [28/50] - Loss: 0.7763
Epoch [29/50] - Loss: 0.7760
Epoch [30/50] - Loss: 0.7710
Epoch [31/50] - Loss: 0.7690
Epoch [32/50] - Loss: 0.7588
Epoch [33/50] - Loss: 0.7612
Epoch [34/50] - Loss: 0.7692
Epoch [35/50] - Loss: 0.7592
Epoch [36/50] - Loss: 0.7506
Epoch [37/50] - Loss: 0.7431
Epoch [38/50] - Loss: 0.7426
Epoch [39/50] - Loss: 0.7403
Epoch [40/50] - Loss: 0.7362
Epoch [41/50] - Loss: 0.7270
Epoch [42/50] - Loss: 0.7236
Epoch [43/50] - Loss: 0.7168
Epoch [44/50] - Loss: 0.7245
Epoch [45/50] - Loss: 0.7152
Epoch [46/50] - Loss: 0.7296
Epoch [47/50] - Loss: 0.7231
Epoch [48/50] - Loss: 0.7232
Epoch [49/50] - Loss: 0.7095
Epoch [50/50] - Loss: 0.6990
sum preds 485
sum labels 1875
 - Test Metrics: Accuracy=0.8691, F1=0.3958, Recall=0.2491, Precision=0.9629
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Running experiment with seed=25:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GATConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 1.8326
Epoch [2/50] - Loss: 1.2199
Epoch [3/50] - Loss: 1.0454
Epoch [4/50] - Loss: 0.9853
Epoch [5/50] - Loss: 0.9671
Epoch [6/50] - Loss: 0.9508
Epoch [7/50] - Loss: 0.9328
Epoch [8/50] - Loss: 0.9187
Epoch [9/50] - Loss: 0.9064
Epoch [10/50] - Loss: 0.8972
Epoch [11/50] - Loss: 0.8874
Epoch [12/50] - Loss: 0.8781
Epoch [13/50] - Loss: 0.8695
Epoch [14/50] - Loss: 0.8631
Epoch [15/50] - Loss: 0.8565
Epoch [16/50] - Loss: 0.8509
Epoch [17/50] - Loss: 0.8437
Epoch [18/50] - Loss: 0.8398
Epoch [19/50] - Loss: 0.8330
Epoch [20/50] - Loss: 0.8257
Epoch [21/50] - Loss: 0.8232
Epoch [22/50] - Loss: 0.8165
Epoch [23/50] - Loss: 0.8120
Epoch [24/50] - Loss: 0.8085
Epoch [25/50] - Loss: 0.8025
Epoch [26/50] - Loss: 0.7978
Epoch [27/50] - Loss: 0.7909
Epoch [28/50] - Loss: 0.7862
Epoch [29/50] - Loss: 0.7821
Epoch [30/50] - Loss: 0.7761
Epoch [31/50] - Loss: 0.7756
Epoch [32/50] - Loss: 0.7635
Epoch [33/50] - Loss: 0.7652
Epoch [34/50] - Loss: 0.7620
Epoch [35/50] - Loss: 0.7578
Epoch [36/50] - Loss: 0.7525
Epoch [37/50] - Loss: 0.7435
Epoch [38/50] - Loss: 0.7384
Epoch [39/50] - Loss: 0.7341
Epoch [40/50] - Loss: 0.7286
Epoch [41/50] - Loss: 0.7250
Epoch [42/50] - Loss: 0.7253
Epoch [43/50] - Loss: 0.7262
Epoch [44/50] - Loss: 0.7231
Epoch [45/50] - Loss: 0.7210
Epoch [46/50] - Loss: 0.7149
Epoch [47/50] - Loss: 0.7155
Epoch [48/50] - Loss: 0.7056
Epoch [49/50] - Loss: 0.6958
Epoch [50/50] - Loss: 0.6927
sum preds 449
sum labels 1875
 - Test Metrics: Accuracy=0.8638, F1=0.3614, Recall=0.2240, Precision=0.9354
 - Validation Metrics: Accuracy=nan, F1=0.0000, Recall=0.0000, Precision=0.0000
Done. Results written to wiki-cs_experimentations\wiki-cs_SAR_two_nnif_two_nnif_1904102837.csv.
Average F1 over valid seeds: 0.4074 ± 0.0430
___________________________________________________________________________________
Avg F1 for wiki-cs with SAR and two_nnif, GATConv,0.3: 0.4074 ± 0.0430
___________________________________________________________________________________
two_nnif
Running experiment with seed=654:
 - K=1, layers=2, hidden=16, out=2
 - norm=None, dropout=0, batch_size=2048, methodology=two_nnif
 - ratio=0.09734733828607303, aggregation=mean, treatment=removal, anomaly_detector=nearest_neighbors, sampling=sage
 - model_type=GCNConv, rate_pairs=10, clusters=50, lr=0.005
Epoch [1/50] - Loss: 2.6807
Epoch [2/50] - Loss: 1.3622
Epoch [3/50] - Loss: 1.1276
Epoch [4/50] - Loss: 1.0555
Epoch [5/50] - Loss: 1.0079
Epoch [6/50] - Loss: 0.9768
Epoch [7/50] - Loss: 0.9616
Epoch [8/50] - Loss: 0.9521
Epoch [9/50] - Loss: 0.9436
Epoch [10/50] - Loss: 0.9347
Epoch [11/50] - Loss: 0.9282
Epoch [12/50] - Loss: 0.9215
Epoch [13/50] - Loss: 0.9148
Epoch [14/50] - Loss: 0.9111
Epoch [15/50] - Loss: 0.9066
Epoch [16/50] - Loss: 0.9006
Epoch [17/50] - Loss: 0.8978
Epoch [18/50] - Loss: 0.8946
Epoch [19/50] - Loss: 0.8897
Epoch [20/50] - Loss: 0.8878
Epoch [21/50] - Loss: 0.8844
Epoch [22/50] - Loss: 0.8801
Epoch [23/50] - Loss: 0.8765
Epoch [24/50] - Loss: 0.8751
Epoch [25/50] - Loss: 0.8707
Epoch [26/50] - Loss: 0.8688
Epoch [27/50] - Loss: 0.8655
Epoch [28/50] - Loss: 0.8616
Epoch [29/50] - Loss: 0.8598
Epoch [30/50] - Loss: 0.8572
Epoch [31/50] - Loss: 0.8554
Epoch [32/50] - Loss: 0.8513
Epoch [33/50] - Loss: 0.8495
Epoch [34/50] - Loss: 0.8493
Epoch [35/50] - Loss: 0.8454
Epoch [36/50] - Loss: 0.8410
Epoch [37/50] - Loss: 0.8385
Epoch [38/50] - Loss: 0.8361
Epoch [39/50] - Loss: 0.8337
Epoch [40/50] - Loss: 0.8312
