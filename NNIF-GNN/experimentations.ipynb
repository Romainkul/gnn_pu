{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def format_pytorch_version(version_str):\n",
    "    # Example input: \"2.0.1+cu118\" -> returns \"2.0.1\"\n",
    "    return version_str.split('+')[0]\n",
    "\n",
    "def format_cuda_version(cuda_str):\n",
    "    # If CUDA is None (CPU-only PyTorch), return \"cpu\"\n",
    "    if cuda_str is None:\n",
    "        return \"cpu\"\n",
    "    # Example: \"11.8\" -> \"cu118\"\n",
    "    return \"cu\" + cuda_str.replace('.', '')\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "print(f\"Installing packages for torch-{TORCH}+{CUDA}...\")\n",
    "\n",
    "%pip install --upgrade --no-cache-dir pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "\n",
    "%pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Citeseer\n",
    "#### SCAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"citeseer\",      \n",
    "        \"mechanism\": \"SCAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 15, 25),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\", \"max\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"citeseer_scar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Citeseer\n",
    "#### SAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"citeseer\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 15, 25),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\", \"max\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"citeseer_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Cora\n",
    "#### SCAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"cora\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\", \"max\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"cora_scar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Cora\n",
    "#### SAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"cora\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\", \"max\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"cora_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Pubmed\n",
    "#### SCAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"pubmed\",      \n",
    "        \"mechanism\": \"SCAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\", \"max\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"pubmed_scar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Pubmed\n",
    "#### SAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"pubmed\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\", \"max\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"pubmed_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization WikiCS\n",
    "#### SCAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"wiki-cs\",      \n",
    "        \"mechanism\": \"SCAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\", \"max\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"wikics_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization WikiCS\n",
    "#### SAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"wiki-cs\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\", \"max\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"wikics_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
