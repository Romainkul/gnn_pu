{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch==2.5.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-win_amd64.whl (2510.8 MB)\n",
      "     ---------------------------------------- 0.0/2.5 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.5 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.5 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.5 GB 796.8 kB/s eta 0:52:31\n",
      "     ---------------------------------------- 0.0/2.5 GB 796.8 kB/s eta 0:52:31\n",
      "     ---------------------------------------- 0.0/2.5 GB 744.7 kB/s eta 0:56:11\n",
      "     ---------------------------------------- 0.0/2.5 GB 824.4 kB/s eta 0:50:45\n",
      "     ---------------------------------------- 0.0/2.5 GB 849.0 kB/s eta 0:49:16\n",
      "     ---------------------------------------- 0.0/2.5 GB 855.6 kB/s eta 0:48:53\n",
      "     ---------------------------------------- 0.0/2.5 GB 898.8 kB/s eta 0:46:32\n",
      "     ---------------------------------------- 0.0/2.5 GB 898.8 kB/s eta 0:46:32\n",
      "     ---------------------------------------- 0.0/2.5 GB 924.4 kB/s eta 0:45:14\n",
      "     ---------------------------------------- 0.0/2.5 GB 919.0 kB/s eta 0:45:30\n",
      "     ---------------------------------------- 0.0/2.5 GB 937.7 kB/s eta 0:44:35\n",
      "     ---------------------------------------- 0.0/2.5 GB 958.5 kB/s eta 0:43:37\n",
      "     ---------------------------------------- 0.0/2.5 GB 961.2 kB/s eta 0:43:29\n",
      "     ---------------------------------------- 0.0/2.5 GB 961.2 kB/s eta 0:43:29\n",
      "     ---------------------------------------- 0.0/2.5 GB 954.1 kB/s eta 0:43:48\n",
      "     ---------------------------------------- 0.0/2.5 GB 964.9 kB/s eta 0:43:19\n",
      "     ---------------------------------------- 0.0/2.5 GB 978.7 kB/s eta 0:42:42\n",
      "     ---------------------------------------- 0.0/2.5 GB 994.5 kB/s eta 0:42:01\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:15\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:19\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:49\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:45\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:27\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:32\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:32\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:37\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:22\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:22\n",
      "     ---------------------------------------- 0.0/2.5 GB 999.1 kB/s eta 0:41:47\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:24\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:32\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:00\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:41\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:39:42\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:39:13\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:39:00\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:39:00\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:39:00\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:54\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:54\n",
      "     ---------------------------------------- 0.0/2.5 GB 999.0 kB/s eta 0:41:45\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:17\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:10\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:04\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 839.9 kB/s eta 0:49:37\n",
      "     ---------------------------------------- 0.0/2.5 GB 839.9 kB/s eta 0:49:37\n",
      "     ---------------------------------------- 0.0/2.5 GB 839.9 kB/s eta 0:49:37\n",
      "     ---------------------------------------- 0.0/2.5 GB 812.1 kB/s eta 0:51:19\n",
      "     ---------------------------------------- 0.0/2.5 GB 820.3 kB/s eta 0:50:48\n",
      "     ---------------------------------------- 0.0/2.5 GB 820.3 kB/s eta 0:50:48\n",
      "     ---------------------------------------- 0.0/2.5 GB 812.4 kB/s eta 0:51:17\n",
      "     ---------------------------------------- 0.0/2.5 GB 821.1 kB/s eta 0:50:44\n",
      "     ---------------------------------------- 0.0/2.5 GB 830.5 kB/s eta 0:50:09\n",
      "     ---------------------------------------- 0.0/2.5 GB 850.6 kB/s eta 0:48:57\n",
      "     ---------------------------------------- 0.0/2.5 GB 861.3 kB/s eta 0:48:21\n",
      "     ---------------------------------------- 0.0/2.5 GB 861.3 kB/s eta 0:48:21\n",
      "     ---------------------------------------- 0.0/2.5 GB 861.3 kB/s eta 0:48:21\n",
      "     ---------------------------------------- 0.0/2.5 GB 861.3 kB/s eta 0:48:21\n",
      "     ---------------------------------------- 0.0/2.5 GB 861.3 kB/s eta 0:48:21\n",
      "     ---------------------------------------- 0.0/2.5 GB 814.7 kB/s eta 0:51:06\n",
      "     ---------------------------------------- 0.0/2.5 GB 814.7 kB/s eta 0:51:06\n",
      "     ---------------------------------------- 0.0/2.5 GB 814.7 kB/s eta 0:51:06\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.8 kB/s eta 0:51:40\n",
      "     ---------------------------------------- 0.0/2.5 GB 801.9 kB/s eta 0:51:54\n",
      "     ---------------------------------------- 0.0/2.5 GB 801.9 kB/s eta 0:51:54\n",
      "     ---------------------------------------- 0.0/2.5 GB 798.1 kB/s eta 0:52:09\n",
      "     ---------------------------------------- 0.0/2.5 GB 798.1 kB/s eta 0:52:09\n",
      "     ---------------------------------------- 0.0/2.5 GB 798.1 kB/s eta 0:52:09\n",
      "     ---------------------------------------- 0.0/2.5 GB 787.6 kB/s eta 0:52:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 787.6 kB/s eta 0:52:50\n",
      "     ---------------------------------------- 0.0/2.5 GB 783.0 kB/s eta 0:53:09\n",
      "     ---------------------------------------- 0.0/2.5 GB 783.0 kB/s eta 0:53:09\n",
      "     ---------------------------------------- 0.0/2.5 GB 782.6 kB/s eta 0:53:10\n",
      "     ---------------------------------------- 0.0/2.5 GB 782.6 kB/s eta 0:53:10\n",
      "     ---------------------------------------- 0.0/2.5 GB 782.6 kB/s eta 0:53:10\n",
      "     ---------------------------------------- 0.0/2.5 GB 765.7 kB/s eta 0:54:20\n",
      "     ---------------------------------------- 0.0/2.5 GB 769.3 kB/s eta 0:54:04\n",
      "     ---------------------------------------- 0.0/2.5 GB 769.3 kB/s eta 0:54:04\n",
      "     ---------------------------------------- 0.0/2.5 GB 772.3 kB/s eta 0:53:52\n",
      "     ---------------------------------------- 0.0/2.5 GB 772.3 kB/s eta 0:53:52\n",
      "     ---------------------------------------- 0.0/2.5 GB 772.3 kB/s eta 0:53:52\n",
      "     ---------------------------------------- 0.0/2.5 GB 772.3 kB/s eta 0:53:52\n",
      "     ---------------------------------------- 0.0/2.5 GB 772.3 kB/s eta 0:53:52\n",
      "     ---------------------------------------- 0.0/2.5 GB 772.3 kB/s eta 0:53:52\n",
      "     ---------------------------------------- 0.0/2.5 GB 772.3 kB/s eta 0:53:52\n",
      "     ---------------------------------------- 0.0/2.5 GB 772.3 kB/s eta 0:53:52\n",
      "     ---------------------------------------- 0.0/2.5 GB 719.4 kB/s eta 0:57:49\n",
      "     ---------------------------------------- 0.0/2.5 GB 719.4 kB/s eta 0:57:49\n",
      "     ---------------------------------------- 0.0/2.5 GB 721.6 kB/s eta 0:57:38\n",
      "     ---------------------------------------- 0.0/2.5 GB 725.8 kB/s eta 0:57:17\n",
      "     ---------------------------------------- 0.0/2.5 GB 728.9 kB/s eta 0:57:02\n",
      "     ---------------------------------------- 0.0/2.5 GB 734.0 kB/s eta 0:56:38\n",
      "     ---------------------------------------- 0.0/2.5 GB 738.5 kB/s eta 0:56:17\n",
      "     ---------------------------------------- 0.0/2.5 GB 743.8 kB/s eta 0:55:53\n",
      "     ---------------------------------------- 0.0/2.5 GB 755.4 kB/s eta 0:55:01\n",
      "     ---------------------------------------- 0.0/2.5 GB 762.6 kB/s eta 0:54:29\n",
      "     ---------------------------------------- 0.0/2.5 GB 776.7 kB/s eta 0:53:29\n",
      "     ---------------------------------------- 0.0/2.5 GB 793.1 kB/s eta 0:52:22\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.6 kB/s eta 0:51:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.6 kB/s eta 0:51:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.6 kB/s eta 0:51:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.6 kB/s eta 0:51:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.6 kB/s eta 0:51:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.6 kB/s eta 0:51:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.6 kB/s eta 0:51:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.6 kB/s eta 0:51:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 763.5 kB/s eta 0:54:23\n",
      "     ---------------------------------------- 0.0/2.5 GB 777.3 kB/s eta 0:53:24\n",
      "     ---------------------------------------- 0.0/2.5 GB 791.3 kB/s eta 0:52:27\n",
      "     ---------------------------------------- 0.0/2.5 GB 805.1 kB/s eta 0:51:32\n",
      "     ---------------------------------------- 0.0/2.5 GB 819.1 kB/s eta 0:50:39\n",
      "     ---------------------------------------- 0.0/2.5 GB 840.3 kB/s eta 0:49:21\n",
      "     ---------------------------------------- 0.0/2.5 GB 853.9 kB/s eta 0:48:34\n",
      "     ---------------------------------------- 0.0/2.5 GB 867.8 kB/s eta 0:47:46\n",
      "     ---------------------------------------- 0.0/2.5 GB 888.0 kB/s eta 0:46:40\n",
      "     ---------------------------------------- 0.0/2.5 GB 901.5 kB/s eta 0:45:58\n",
      "     ---------------------------------------- 0.0/2.5 GB 921.1 kB/s eta 0:44:58\n",
      "     ---------------------------------------- 0.0/2.5 GB 941.4 kB/s eta 0:43:59\n",
      "     ---------------------------------------- 0.0/2.5 GB 954.2 kB/s eta 0:43:23\n",
      "     ---------------------------------------- 0.0/2.5 GB 972.8 kB/s eta 0:42:33\n",
      "     ---------------------------------------- 0.0/2.5 GB 985.3 kB/s eta 0:42:00\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:41:12\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:42\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:39:59\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:39:59\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:39:59\n",
      "     ---------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:40:21\n",
      "      --------------------------------------- 0.0/2.5 GB 1.0 MB/s eta 0:39:40\n",
      "      --------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:39:02\n",
      "      --------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:38:23\n",
      "      --------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:37:45\n",
      "      --------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:37:18\n",
      "      --------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:36:37\n",
      "      --------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:36:17\n",
      "      --------------------------------------- 0.0/2.5 GB 1.1 MB/s eta 0:35:57\n",
      "      --------------------------------------- 0.0/2.5 GB 1.2 MB/s eta 0:35:37\n",
      "      --------------------------------------- 0.0/2.5 GB 1.2 MB/s eta 0:35:04\n",
      "      --------------------------------------- 0.0/2.5 GB 1.2 MB/s eta 0:34:31\n",
      "      --------------------------------------- 0.0/2.5 GB 1.2 MB/s eta 0:34:14\n",
      "      --------------------------------------- 0.0/2.5 GB 1.2 MB/s eta 0:33:40\n",
      "      --------------------------------------- 0.0/2.5 GB 1.2 MB/s eta 0:33:22\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:32:54\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:32:25\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:32:08\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:31:43\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:31:21\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:31:21\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:31:21\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:31:39\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:31:13\n",
      "      --------------------------------------- 0.0/2.5 GB 1.3 MB/s eta 0:30:44\n",
      "      --------------------------------------- 0.0/2.5 GB 1.4 MB/s eta 0:30:18\n",
      "      --------------------------------------- 0.0/2.5 GB 1.4 MB/s eta 0:30:05\n",
      "      --------------------------------------- 0.0/2.5 GB 1.4 MB/s eta 0:29:40\n",
      "      --------------------------------------- 0.0/2.5 GB 1.4 MB/s eta 0:29:14\n",
      "      --------------------------------------- 0.0/2.5 GB 1.4 MB/s eta 0:29:12\n",
      "      --------------------------------------- 0.0/2.5 GB 1.4 MB/s eta 0:29:06\n",
      "      --------------------------------------- 0.0/2.5 GB 1.4 MB/s eta 0:28:58\n",
      "      --------------------------------------- 0.0/2.5 GB 1.4 MB/s eta 0:28:51\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:43\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:40\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:33\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:27\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:53\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:45\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:38\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:34\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:14\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:06\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:03\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:26:54\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:26:54\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:26:44\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:26:42\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:39\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:35\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:35\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:32\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:29\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:23\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:22\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:22\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:25\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:27\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:30\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:36\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:12\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:12\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:19\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:20\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:20\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:20\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:20\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:20\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:20\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:20\n",
      "      --------------------------------------- 0.1/2.5 GB 1.7 MB/s eta 0:24:20\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:24:46\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.6 MB/s eta 0:26:10\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.5 MB/s eta 0:27:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.4 MB/s eta 0:28:41\n",
      "      --------------------------------------- 0.1/2.5 GB 1.2 MB/s eta 0:34:33\n",
      "      --------------------------------------- 0.1/2.5 GB 1.2 MB/s eta 0:34:33\n",
      "      --------------------------------------- 0.1/2.5 GB 1.2 MB/s eta 0:34:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.1 MB/s eta 0:35:52\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.1 MB/s eta 0:35:52\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.1 MB/s eta 0:37:02\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.1 MB/s eta 0:37:02\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.1 MB/s eta 0:37:12\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.1 MB/s eta 0:37:12\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.1 MB/s eta 0:37:38\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.1 MB/s eta 0:37:38\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.1 MB/s eta 0:38:50\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.0 MB/s eta 0:39:51\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.0 MB/s eta 0:40:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 1.0 MB/s eta 0:40:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 979.7 kB/s eta 0:41:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 969.9 kB/s eta 0:42:02\n",
      "     - -------------------------------------- 0.1/2.5 GB 955.5 kB/s eta 0:42:40\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 952.5 kB/s eta 0:42:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 740.2 kB/s eta 0:55:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 740.2 kB/s eta 0:55:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 740.2 kB/s eta 0:55:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 740.2 kB/s eta 0:55:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 740.2 kB/s eta 0:55:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:05:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:05:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:05:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:05:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:05:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:05:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:05:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:05:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.9 kB/s eta 1:17:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 376.5 kB/s eta 1:48:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 376.5 kB/s eta 1:48:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 376.5 kB/s eta 1:48:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 376.5 kB/s eta 1:48:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 332.2 kB/s eta 2:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 204.6 kB/s eta 3:19:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 229.0 kB/s eta 2:57:50\n",
      "     - -------------------------------------- 0.1/2.5 GB 229.0 kB/s eta 2:57:50\n",
      "     - -------------------------------------- 0.1/2.5 GB 236.2 kB/s eta 2:52:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 243.6 kB/s eta 2:47:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 251.0 kB/s eta 2:42:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 251.0 kB/s eta 2:42:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 258.6 kB/s eta 2:37:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 266.0 kB/s eta 2:33:00\n",
      "     - -------------------------------------- 0.1/2.5 GB 273.1 kB/s eta 2:29:00\n",
      "     - -------------------------------------- 0.1/2.5 GB 280.6 kB/s eta 2:25:01\n",
      "     - -------------------------------------- 0.1/2.5 GB 287.9 kB/s eta 2:21:18\n",
      "     - -------------------------------------- 0.1/2.5 GB 294.7 kB/s eta 2:18:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 302.5 kB/s eta 2:14:29\n",
      "     - -------------------------------------- 0.1/2.5 GB 309.5 kB/s eta 2:11:26\n",
      "     - -------------------------------------- 0.1/2.5 GB 316.7 kB/s eta 2:08:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 323.5 kB/s eta 2:05:41\n",
      "     - -------------------------------------- 0.1/2.5 GB 331.1 kB/s eta 2:02:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 344.8 kB/s eta 1:57:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 352.0 kB/s eta 1:55:29\n",
      "     - -------------------------------------- 0.1/2.5 GB 358.1 kB/s eta 1:53:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 364.5 kB/s eta 1:51:29\n",
      "     - -------------------------------------- 0.1/2.5 GB 370.1 kB/s eta 1:49:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 370.1 kB/s eta 1:49:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 409.9 kB/s eta 1:39:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 409.9 kB/s eta 1:39:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 415.1 kB/s eta 1:37:53\n",
      "     - -------------------------------------- 0.1/2.5 GB 415.1 kB/s eta 1:37:53\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 418.5 kB/s eta 1:37:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 402.6 kB/s eta 1:40:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 402.6 kB/s eta 1:40:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 402.6 kB/s eta 1:40:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 402.6 kB/s eta 1:40:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 397.7 kB/s eta 1:42:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 397.7 kB/s eta 1:42:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 397.7 kB/s eta 1:42:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 399.9 kB/s eta 1:41:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 399.9 kB/s eta 1:41:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 402.2 kB/s eta 1:40:58\n",
      "     - -------------------------------------- 0.1/2.5 GB 402.2 kB/s eta 1:40:58\n",
      "     - -------------------------------------- 0.1/2.5 GB 403.8 kB/s eta 1:40:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 403.8 kB/s eta 1:40:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 404.7 kB/s eta 1:40:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 404.7 kB/s eta 1:40:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 404.7 kB/s eta 1:40:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 404.7 kB/s eta 1:40:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 404.7 kB/s eta 1:40:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 404.7 kB/s eta 1:40:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 404.7 kB/s eta 1:40:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 404.7 kB/s eta 1:40:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 369.1 kB/s eta 1:49:58\n",
      "     - -------------------------------------- 0.1/2.5 GB 369.1 kB/s eta 1:49:58\n",
      "     - -------------------------------------- 0.1/2.5 GB 369.1 kB/s eta 1:49:58\n",
      "     - -------------------------------------- 0.1/2.5 GB 351.7 kB/s eta 1:55:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 351.7 kB/s eta 1:55:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 351.7 kB/s eta 1:55:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 351.7 kB/s eta 1:55:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 351.7 kB/s eta 1:55:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 351.7 kB/s eta 1:55:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 352.6 kB/s eta 1:55:05\n",
      "     - -------------------------------------- 0.1/2.5 GB 352.6 kB/s eta 1:55:05\n",
      "     - -------------------------------------- 0.1/2.5 GB 352.6 kB/s eta 1:55:05\n",
      "     - -------------------------------------- 0.1/2.5 GB 352.6 kB/s eta 1:55:05\n",
      "     - -------------------------------------- 0.1/2.5 GB 352.6 kB/s eta 1:55:05\n",
      "     - -------------------------------------- 0.1/2.5 GB 352.6 kB/s eta 1:55:05\n",
      "     - -------------------------------------- 0.1/2.5 GB 352.6 kB/s eta 1:55:05\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.8 kB/s eta 1:58:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.8 kB/s eta 1:58:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.8 kB/s eta 1:58:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.8 kB/s eta 1:58:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.8 kB/s eta 1:58:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.8 kB/s eta 1:58:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.8 kB/s eta 1:58:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 341.5 kB/s eta 1:58:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 341.5 kB/s eta 1:58:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 341.5 kB/s eta 1:58:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 341.5 kB/s eta 1:58:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 341.5 kB/s eta 1:58:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 341.5 kB/s eta 1:58:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 341.5 kB/s eta 1:58:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 341.5 kB/s eta 1:58:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 341.5 kB/s eta 1:58:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 354.2 kB/s eta 1:54:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 335.4 kB/s eta 2:00:57\n",
      "     - -------------------------------------- 0.1/2.5 GB 335.4 kB/s eta 2:00:57\n",
      "     - -------------------------------------- 0.1/2.5 GB 335.4 kB/s eta 2:00:57\n",
      "     - -------------------------------------- 0.1/2.5 GB 335.4 kB/s eta 2:00:57\n",
      "     - -------------------------------------- 0.1/2.5 GB 362.2 kB/s eta 1:51:58\n",
      "     - -------------------------------------- 0.1/2.5 GB 362.2 kB/s eta 1:51:58\n",
      "     - -------------------------------------- 0.1/2.5 GB 367.4 kB/s eta 1:50:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 367.4 kB/s eta 1:50:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 371.8 kB/s eta 1:49:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 384.8 kB/s eta 1:45:21\n",
      "     - -------------------------------------- 0.1/2.5 GB 391.0 kB/s eta 1:43:40\n",
      "     - -------------------------------------- 0.1/2.5 GB 397.3 kB/s eta 1:42:01\n",
      "     - -------------------------------------- 0.1/2.5 GB 403.7 kB/s eta 1:40:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 409.6 kB/s eta 1:38:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 409.6 kB/s eta 1:38:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 409.6 kB/s eta 1:38:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 409.6 kB/s eta 1:38:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 409.6 kB/s eta 1:38:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 409.6 kB/s eta 1:38:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 433.6 kB/s eta 1:33:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 440.0 kB/s eta 1:32:05\n",
      "     - -------------------------------------- 0.1/2.5 GB 447.4 kB/s eta 1:30:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 453.7 kB/s eta 1:29:17\n",
      "     - -------------------------------------- 0.1/2.5 GB 459.4 kB/s eta 1:28:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 472.6 kB/s eta 1:25:41\n",
      "     - -------------------------------------- 0.1/2.5 GB 478.3 kB/s eta 1:24:39\n",
      "     - -------------------------------------- 0.1/2.5 GB 478.3 kB/s eta 1:24:39\n",
      "     - -------------------------------------- 0.1/2.5 GB 478.3 kB/s eta 1:24:39\n",
      "     - -------------------------------------- 0.1/2.5 GB 478.3 kB/s eta 1:24:39\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 473.1 kB/s eta 1:25:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 386.5 kB/s eta 1:44:45\n",
      "     - -------------------------------------- 0.1/2.5 GB 384.9 kB/s eta 1:45:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 384.9 kB/s eta 1:45:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 384.9 kB/s eta 1:45:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 384.9 kB/s eta 1:45:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 384.9 kB/s eta 1:45:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.9 kB/s eta 1:58:01\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.8 kB/s eta 1:58:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.6 kB/s eta 1:58:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 342.6 kB/s eta 1:58:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 344.4 kB/s eta 1:57:29\n",
      "     - -------------------------------------- 0.1/2.5 GB 344.4 kB/s eta 1:57:29\n",
      "     - -------------------------------------- 0.1/2.5 GB 344.4 kB/s eta 1:57:29\n",
      "     - -------------------------------------- 0.1/2.5 GB 344.4 kB/s eta 1:57:29\n",
      "     - -------------------------------------- 0.1/2.5 GB 333.4 kB/s eta 2:01:20\n",
      "     - -------------------------------------- 0.1/2.5 GB 386.6 kB/s eta 1:44:38\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 392.0 kB/s eta 1:43:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 370.4 kB/s eta 1:49:12\n",
      "     - -------------------------------------- 0.1/2.5 GB 370.4 kB/s eta 1:49:12\n",
      "     - -------------------------------------- 0.1/2.5 GB 374.4 kB/s eta 1:48:00\n",
      "     - -------------------------------------- 0.1/2.5 GB 374.4 kB/s eta 1:48:00\n",
      "     - -------------------------------------- 0.1/2.5 GB 376.4 kB/s eta 1:47:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 376.4 kB/s eta 1:47:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 376.4 kB/s eta 1:47:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:59\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:59\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:59\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:59\n",
      "     - -------------------------------------- 0.1/2.5 GB 378.7 kB/s eta 1:46:45\n",
      "     - -------------------------------------- 0.1/2.5 GB 378.7 kB/s eta 1:46:45\n",
      "     - -------------------------------------- 0.1/2.5 GB 378.7 kB/s eta 1:46:45\n",
      "     - -------------------------------------- 0.1/2.5 GB 378.7 kB/s eta 1:46:44\n",
      "     - -------------------------------------- 0.1/2.5 GB 378.7 kB/s eta 1:46:44\n",
      "     - -------------------------------------- 0.1/2.5 GB 378.7 kB/s eta 1:46:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 378.7 kB/s eta 1:46:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 377.9 kB/s eta 1:46:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 381.7 kB/s eta 1:45:52\n",
      "     - -------------------------------------- 0.1/2.5 GB 387.6 kB/s eta 1:44:14\n",
      "     - -------------------------------------- 0.1/2.5 GB 393.5 kB/s eta 1:42:40\n",
      "     - -------------------------------------- 0.1/2.5 GB 399.2 kB/s eta 1:41:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 405.8 kB/s eta 1:39:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 405.8 kB/s eta 1:39:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 408.3 kB/s eta 1:38:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 412.8 kB/s eta 1:37:49\n",
      "     - -------------------------------------- 0.1/2.5 GB 427.6 kB/s eta 1:34:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 427.6 kB/s eta 1:34:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 432.7 kB/s eta 1:33:18\n",
      "     - -------------------------------------- 0.1/2.5 GB 438.0 kB/s eta 1:32:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 444.3 kB/s eta 1:30:51\n",
      "     - -------------------------------------- 0.1/2.5 GB 456.0 kB/s eta 1:28:29\n",
      "     - -------------------------------------- 0.1/2.5 GB 478.3 kB/s eta 1:24:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 484.6 kB/s eta 1:23:16\n",
      "     - -------------------------------------- 0.1/2.5 GB 490.8 kB/s eta 1:22:12\n",
      "     - -------------------------------------- 0.1/2.5 GB 496.6 kB/s eta 1:21:14\n",
      "     - -------------------------------------- 0.1/2.5 GB 496.6 kB/s eta 1:21:14\n",
      "     - -------------------------------------- 0.1/2.5 GB 496.8 kB/s eta 1:21:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 502.8 kB/s eta 1:20:13\n",
      "     - -------------------------------------- 0.1/2.5 GB 516.1 kB/s eta 1:18:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 536.8 kB/s eta 1:15:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 542.4 kB/s eta 1:14:20\n",
      "     - -------------------------------------- 0.1/2.5 GB 555.7 kB/s eta 1:12:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 561.9 kB/s eta 1:11:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 573.7 kB/s eta 1:10:14\n",
      "     - -------------------------------------- 0.1/2.5 GB 579.1 kB/s eta 1:09:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 585.5 kB/s eta 1:08:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:04:51\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.0 kB/s eta 1:04:51\n",
      "     - -------------------------------------- 0.1/2.5 GB 623.8 kB/s eta 1:04:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 623.8 kB/s eta 1:04:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 623.8 kB/s eta 1:04:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 623.8 kB/s eta 1:04:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 622.7 kB/s eta 1:04:40\n",
      "     - -------------------------------------- 0.1/2.5 GB 622.7 kB/s eta 1:04:40\n",
      "     - -------------------------------------- 0.1/2.5 GB 622.4 kB/s eta 1:04:41\n",
      "     - -------------------------------------- 0.1/2.5 GB 622.4 kB/s eta 1:04:41\n",
      "     - -------------------------------------- 0.1/2.5 GB 622.4 kB/s eta 1:04:41\n",
      "     - -------------------------------------- 0.1/2.5 GB 626.7 kB/s eta 1:04:14\n",
      "     - -------------------------------------- 0.1/2.5 GB 626.7 kB/s eta 1:04:14\n",
      "     - -------------------------------------- 0.1/2.5 GB 626.7 kB/s eta 1:04:14\n",
      "     - -------------------------------------- 0.1/2.5 GB 623.0 kB/s eta 1:04:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 623.0 kB/s eta 1:04:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 623.0 kB/s eta 1:04:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 623.0 kB/s eta 1:04:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 623.0 kB/s eta 1:04:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 490.1 kB/s eta 1:22:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 490.1 kB/s eta 1:22:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 490.1 kB/s eta 1:22:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.8 kB/s eta 1:16:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.8 kB/s eta 1:16:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.8 kB/s eta 1:16:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.8 kB/s eta 1:16:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 522.0 kB/s eta 1:17:05\n",
      "     - -------------------------------------- 0.1/2.5 GB 524.0 kB/s eta 1:16:46\n",
      "     - -------------------------------------- 0.1/2.5 GB 524.0 kB/s eta 1:16:46\n",
      "     - -------------------------------------- 0.1/2.5 GB 524.0 kB/s eta 1:16:46\n",
      "     - -------------------------------------- 0.1/2.5 GB 524.6 kB/s eta 1:16:41\n",
      "     - -------------------------------------- 0.1/2.5 GB 526.8 kB/s eta 1:16:21\n",
      "     - -------------------------------------- 0.1/2.5 GB 526.8 kB/s eta 1:16:21\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.1 kB/s eta 1:16:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.1 kB/s eta 1:16:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 525.1 kB/s eta 1:16:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 533.8 kB/s eta 1:15:20\n",
      "     - -------------------------------------- 0.1/2.5 GB 533.8 kB/s eta 1:15:20\n",
      "     - -------------------------------------- 0.1/2.5 GB 533.0 kB/s eta 1:15:26\n",
      "     - -------------------------------------- 0.1/2.5 GB 533.0 kB/s eta 1:15:26\n",
      "     - -------------------------------------- 0.1/2.5 GB 533.0 kB/s eta 1:15:26\n",
      "     - -------------------------------------- 0.1/2.5 GB 533.0 kB/s eta 1:15:26\n",
      "     - -------------------------------------- 0.1/2.5 GB 533.0 kB/s eta 1:15:26\n",
      "     - -------------------------------------- 0.1/2.5 GB 533.0 kB/s eta 1:15:26\n",
      "     - -------------------------------------- 0.1/2.5 GB 512.2 kB/s eta 1:18:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 512.2 kB/s eta 1:18:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 512.2 kB/s eta 1:18:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 502.3 kB/s eta 1:20:02\n",
      "     - -------------------------------------- 0.1/2.5 GB 502.3 kB/s eta 1:20:02\n",
      "     - -------------------------------------- 0.1/2.5 GB 502.3 kB/s eta 1:20:02\n",
      "     - -------------------------------------- 0.1/2.5 GB 502.3 kB/s eta 1:20:02\n",
      "     - -------------------------------------- 0.1/2.5 GB 529.2 kB/s eta 1:15:57\n",
      "     - -------------------------------------- 0.1/2.5 GB 531.7 kB/s eta 1:15:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 531.7 kB/s eta 1:15:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 535.3 kB/s eta 1:15:04\n",
      "     - -------------------------------------- 0.1/2.5 GB 538.0 kB/s eta 1:14:41\n",
      "     - -------------------------------------- 0.1/2.5 GB 538.0 kB/s eta 1:14:41\n",
      "     - -------------------------------------- 0.1/2.5 GB 541.2 kB/s eta 1:14:14\n",
      "     - -------------------------------------- 0.1/2.5 GB 547.2 kB/s eta 1:13:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 551.9 kB/s eta 1:12:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 554.3 kB/s eta 1:12:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 567.2 kB/s eta 1:10:48\n",
      "     - -------------------------------------- 0.1/2.5 GB 572.1 kB/s eta 1:10:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 576.7 kB/s eta 1:09:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 584.6 kB/s eta 1:08:40\n",
      "     - -------------------------------------- 0.1/2.5 GB 589.8 kB/s eta 1:08:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 594.5 kB/s eta 1:07:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 610.7 kB/s eta 1:05:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 620.7 kB/s eta 1:04:38\n",
      "     - -------------------------------------- 0.1/2.5 GB 627.3 kB/s eta 1:03:57\n",
      "     - -------------------------------------- 0.1/2.5 GB 632.1 kB/s eta 1:03:27\n",
      "     - -------------------------------------- 0.1/2.5 GB 639.1 kB/s eta 1:02:45\n",
      "     - -------------------------------------- 0.1/2.5 GB 639.1 kB/s eta 1:02:45\n",
      "     - -------------------------------------- 0.1/2.5 GB 639.1 kB/s eta 1:02:45\n",
      "     - -------------------------------------- 0.1/2.5 GB 639.1 kB/s eta 1:02:45\n",
      "     - -------------------------------------- 0.1/2.5 GB 637.8 kB/s eta 1:02:52\n",
      "     - -------------------------------------- 0.1/2.5 GB 643.6 kB/s eta 1:02:18\n",
      "     - -------------------------------------- 0.1/2.5 GB 675.1 kB/s eta 0:59:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 675.1 kB/s eta 0:59:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 676.9 kB/s eta 0:59:13\n",
      "     - -------------------------------------- 0.1/2.5 GB 677.9 kB/s eta 0:59:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 677.9 kB/s eta 0:59:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 680.6 kB/s eta 0:58:53\n",
      "     - -------------------------------------- 0.1/2.5 GB 682.6 kB/s eta 0:58:42\n",
      "     - -------------------------------------- 0.1/2.5 GB 683.4 kB/s eta 0:58:38\n",
      "     - -------------------------------------- 0.1/2.5 GB 682.3 kB/s eta 0:58:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 682.3 kB/s eta 0:58:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 676.4 kB/s eta 0:59:13\n",
      "     - -------------------------------------- 0.1/2.5 GB 680.6 kB/s eta 0:58:51\n",
      "     - -------------------------------------- 0.1/2.5 GB 683.4 kB/s eta 0:58:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 683.4 kB/s eta 0:58:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 683.4 kB/s eta 0:58:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 678.1 kB/s eta 0:59:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 678.1 kB/s eta 0:59:02\n",
      "     - -------------------------------------- 0.1/2.5 GB 678.1 kB/s eta 0:59:02\n",
      "     - -------------------------------------- 0.1/2.5 GB 674.2 kB/s eta 0:59:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 674.2 kB/s eta 0:59:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 674.2 kB/s eta 0:59:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 674.2 kB/s eta 0:59:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 674.2 kB/s eta 0:59:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 629.9 kB/s eta 1:03:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 629.9 kB/s eta 1:03:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 629.9 kB/s eta 1:03:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 629.9 kB/s eta 1:03:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 629.9 kB/s eta 1:03:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 629.9 kB/s eta 1:03:32\n",
      "     - -------------------------------------- 0.1/2.5 GB 587.3 kB/s eta 1:08:09\n",
      "     - -------------------------------------- 0.1/2.5 GB 587.3 kB/s eta 1:08:09\n",
      "     - -------------------------------------- 0.1/2.5 GB 562.2 kB/s eta 1:11:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 562.2 kB/s eta 1:11:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 562.2 kB/s eta 1:11:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 543.5 kB/s eta 1:13:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 543.5 kB/s eta 1:13:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.8 kB/s eta 1:09:07\n",
      "     - -------------------------------------- 0.1/2.5 GB 580.1 kB/s eta 1:08:57\n",
      "     - -------------------------------------- 0.1/2.5 GB 580.1 kB/s eta 1:08:57\n",
      "     - -------------------------------------- 0.1/2.5 GB 580.1 kB/s eta 1:08:57\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 578.5 kB/s eta 1:09:08\n",
      "     - -------------------------------------- 0.1/2.5 GB 531.5 kB/s eta 1:15:15\n",
      "     - -------------------------------------- 0.1/2.5 GB 531.5 kB/s eta 1:15:15\n",
      "     - -------------------------------------- 0.1/2.5 GB 534.0 kB/s eta 1:14:53\n",
      "     - -------------------------------------- 0.1/2.5 GB 534.0 kB/s eta 1:14:53\n",
      "     - -------------------------------------- 0.1/2.5 GB 534.0 kB/s eta 1:14:53\n",
      "     - -------------------------------------- 0.1/2.5 GB 545.3 kB/s eta 1:13:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 545.3 kB/s eta 1:13:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 545.3 kB/s eta 1:13:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 544.4 kB/s eta 1:13:27\n",
      "     - -------------------------------------- 0.1/2.5 GB 544.4 kB/s eta 1:13:27\n",
      "     - -------------------------------------- 0.1/2.5 GB 544.4 kB/s eta 1:13:27\n",
      "     - -------------------------------------- 0.1/2.5 GB 615.4 kB/s eta 1:04:58\n",
      "     - -------------------------------------- 0.1/2.5 GB 615.4 kB/s eta 1:04:58\n",
      "     - -------------------------------------- 0.1/2.5 GB 619.2 kB/s eta 1:04:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 621.7 kB/s eta 1:04:17\n",
      "     - -------------------------------------- 0.1/2.5 GB 625.7 kB/s eta 1:03:52\n",
      "     - -------------------------------------- 0.1/2.5 GB 630.3 kB/s eta 1:03:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 634.9 kB/s eta 1:02:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 639.7 kB/s eta 1:02:27\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.2 kB/s eta 1:02:01\n",
      "     - -------------------------------------- 0.1/2.5 GB 648.9 kB/s eta 1:01:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 648.9 kB/s eta 1:01:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 648.9 kB/s eta 1:01:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 651.6 kB/s eta 1:01:17\n",
      "     - -------------------------------------- 0.1/2.5 GB 656.8 kB/s eta 1:00:47\n",
      "     - -------------------------------------- 0.1/2.5 GB 669.6 kB/s eta 0:59:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 675.4 kB/s eta 0:59:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 689.0 kB/s eta 0:57:55\n",
      "     - -------------------------------------- 0.1/2.5 GB 689.0 kB/s eta 0:57:55\n",
      "     - -------------------------------------- 0.1/2.5 GB 689.0 kB/s eta 0:57:55\n",
      "     - -------------------------------------- 0.1/2.5 GB 689.0 kB/s eta 0:57:55\n",
      "     - -------------------------------------- 0.1/2.5 GB 689.0 kB/s eta 0:57:55\n",
      "     - -------------------------------------- 0.1/2.5 GB 689.0 kB/s eta 0:57:55\n",
      "     - -------------------------------------- 0.1/2.5 GB 689.0 kB/s eta 0:57:55\n",
      "     - -------------------------------------- 0.1/2.5 GB 675.7 kB/s eta 0:59:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 689.1 kB/s eta 0:57:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 701.2 kB/s eta 0:56:53\n",
      "     - -------------------------------------- 0.1/2.5 GB 714.1 kB/s eta 0:55:51\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.8 kB/s eta 0:55:28\n",
      "     - -------------------------------------- 0.1/2.5 GB 734.4 kB/s eta 0:54:17\n",
      "     - -------------------------------------- 0.1/2.5 GB 739.4 kB/s eta 0:53:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 749.0 kB/s eta 0:53:12\n",
      "     - -------------------------------------- 0.1/2.5 GB 753.8 kB/s eta 0:52:51\n",
      "     - -------------------------------------- 0.1/2.5 GB 759.0 kB/s eta 0:52:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 759.0 kB/s eta 0:52:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 759.0 kB/s eta 0:52:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 759.0 kB/s eta 0:52:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 751.9 kB/s eta 0:52:59\n",
      "     - -------------------------------------- 0.1/2.5 GB 759.4 kB/s eta 0:52:27\n",
      "     - -------------------------------------- 0.1/2.5 GB 760.6 kB/s eta 0:52:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 790.2 kB/s eta 0:50:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 790.2 kB/s eta 0:50:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 792.5 kB/s eta 0:50:15\n",
      "     - -------------------------------------- 0.1/2.5 GB 794.6 kB/s eta 0:50:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 794.6 kB/s eta 0:50:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 794.6 kB/s eta 0:50:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 794.6 kB/s eta 0:50:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 794.6 kB/s eta 0:50:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 794.6 kB/s eta 0:50:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 794.6 kB/s eta 0:50:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 794.6 kB/s eta 0:50:06\n",
      "     - -------------------------------------- 0.1/2.5 GB 771.3 kB/s eta 0:51:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 771.3 kB/s eta 0:51:37\n",
      "     - -------------------------------------- 0.1/2.5 GB 779.7 kB/s eta 0:51:03\n",
      "     - -------------------------------------- 0.1/2.5 GB 781.4 kB/s eta 0:50:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 781.4 kB/s eta 0:50:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 781.4 kB/s eta 0:50:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 781.4 kB/s eta 0:50:56\n",
      "     - -------------------------------------- 0.1/2.5 GB 777.7 kB/s eta 0:51:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 777.7 kB/s eta 0:51:10\n",
      "     - -------------------------------------- 0.1/2.5 GB 766.6 kB/s eta 0:51:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 766.6 kB/s eta 0:51:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 766.6 kB/s eta 0:51:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 766.6 kB/s eta 0:51:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 766.6 kB/s eta 0:51:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 766.6 kB/s eta 0:51:54\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.4 kB/s eta 0:55:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.4 kB/s eta 0:55:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.4 kB/s eta 0:55:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.4 kB/s eta 0:55:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.4 kB/s eta 0:55:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.4 kB/s eta 0:55:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.4 kB/s eta 0:55:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.4 kB/s eta 0:55:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 718.4 kB/s eta 0:55:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 658.8 kB/s eta 1:00:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 656.4 kB/s eta 1:00:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 656.4 kB/s eta 1:00:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 648.0 kB/s eta 1:01:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     - -------------------------------------- 0.1/2.5 GB 644.3 kB/s eta 1:01:43\n",
      "     -- ------------------------------------- 0.1/2.5 GB 573.6 kB/s eta 1:09:18\n",
      "     -- ------------------------------------- 0.1/2.5 GB 573.6 kB/s eta 1:09:18\n",
      "     -- ------------------------------------- 0.1/2.5 GB 573.6 kB/s eta 1:09:18\n",
      "     -- ------------------------------------- 0.1/2.5 GB 573.6 kB/s eta 1:09:18\n",
      "     -- ------------------------------------- 0.1/2.5 GB 573.6 kB/s eta 1:09:18\n",
      "     -- ------------------------------------- 0.1/2.5 GB 573.6 kB/s eta 1:09:18\n",
      "     -- ------------------------------------- 0.1/2.5 GB 573.6 kB/s eta 1:09:18\n",
      "     -- ------------------------------------- 0.1/2.5 GB 562.0 kB/s eta 1:10:44\n",
      "     -- ------------------------------------- 0.1/2.5 GB 562.0 kB/s eta 1:10:44\n",
      "     -- ------------------------------------- 0.1/2.5 GB 563.1 kB/s eta 1:10:35\n",
      "     -- ------------------------------------- 0.1/2.5 GB 563.1 kB/s eta 1:10:35\n",
      "     -- ------------------------------------- 0.1/2.5 GB 565.7 kB/s eta 1:10:15\n",
      "     -- ------------------------------------- 0.1/2.5 GB 568.6 kB/s eta 1:09:54\n",
      "     -- ------------------------------------- 0.1/2.5 GB 587.6 kB/s eta 1:07:38\n",
      "     -- ------------------------------------- 0.1/2.5 GB 592.5 kB/s eta 1:07:04\n",
      "     -- ------------------------------------- 0.1/2.5 GB 604.9 kB/s eta 1:05:40\n",
      "     -- ------------------------------------- 0.1/2.5 GB 617.1 kB/s eta 1:04:21\n",
      "     -- ------------------------------------- 0.1/2.5 GB 617.1 kB/s eta 1:04:21\n",
      "     -- ------------------------------------- 0.1/2.5 GB 621.4 kB/s eta 1:03:54\n",
      "     -- ------------------------------------- 0.1/2.5 GB 621.4 kB/s eta 1:03:54\n",
      "     -- ------------------------------------- 0.1/2.5 GB 622.0 kB/s eta 1:03:50\n",
      "     -- ------------------------------------- 0.1/2.5 GB 625.6 kB/s eta 1:03:28\n",
      "     -- ------------------------------------- 0.1/2.5 GB 625.6 kB/s eta 1:03:28\n",
      "     -- ------------------------------------- 0.1/2.5 GB 625.6 kB/s eta 1:03:28\n",
      "     -- ------------------------------------- 0.1/2.5 GB 623.0 kB/s eta 1:03:43\n",
      "     -- ------------------------------------- 0.1/2.5 GB 633.8 kB/s eta 1:02:37\n",
      "     -- ------------------------------------- 0.1/2.5 GB 638.5 kB/s eta 1:02:09\n",
      "     -- ------------------------------------- 0.1/2.5 GB 654.1 kB/s eta 1:00:39\n",
      "     -- ------------------------------------- 0.1/2.5 GB 667.2 kB/s eta 0:59:27\n",
      "     -- ------------------------------------- 0.1/2.5 GB 674.2 kB/s eta 0:58:50\n",
      "     -- ------------------------------------- 0.1/2.5 GB 674.2 kB/s eta 0:58:50\n",
      "     -- ------------------------------------- 0.1/2.5 GB 737.3 kB/s eta 0:53:47\n",
      "     -- ------------------------------------- 0.1/2.5 GB 743.4 kB/s eta 0:53:20\n",
      "     -- ------------------------------------- 0.1/2.5 GB 749.8 kB/s eta 0:52:52\n",
      "     -- ------------------------------------- 0.1/2.5 GB 749.8 kB/s eta 0:52:52\n",
      "     -- ------------------------------------- 0.1/2.5 GB 744.6 kB/s eta 0:53:14\n",
      "     -- ------------------------------------- 0.1/2.5 GB 758.5 kB/s eta 0:52:15\n",
      "     -- ------------------------------------- 0.1/2.5 GB 768.8 kB/s eta 0:51:32\n",
      "     -- ------------------------------------- 0.1/2.5 GB 775.7 kB/s eta 0:51:04\n",
      "     -- ------------------------------------- 0.1/2.5 GB 775.7 kB/s eta 0:51:04\n",
      "     -- ------------------------------------- 0.1/2.5 GB 788.8 kB/s eta 0:50:13\n",
      "     -- ------------------------------------- 0.1/2.5 GB 799.3 kB/s eta 0:49:32\n",
      "     -- ------------------------------------- 0.1/2.5 GB 805.2 kB/s eta 0:49:10\n",
      "     -- ------------------------------------- 0.1/2.5 GB 811.9 kB/s eta 0:48:46\n",
      "     -- ------------------------------------- 0.1/2.5 GB 829.0 kB/s eta 0:47:45\n",
      "     -- ------------------------------------- 0.1/2.5 GB 840.2 kB/s eta 0:47:06\n",
      "     -- ------------------------------------- 0.1/2.5 GB 850.7 kB/s eta 0:46:30\n",
      "     -- ------------------------------------- 0.1/2.5 GB 856.3 kB/s eta 0:46:12\n",
      "     -- ------------------------------------- 0.1/2.5 GB 872.3 kB/s eta 0:45:20\n",
      "     -- ------------------------------------- 0.1/2.5 GB 872.3 kB/s eta 0:45:20\n",
      "     -- ------------------------------------- 0.1/2.5 GB 884.4 kB/s eta 0:44:43\n",
      "     -- ------------------------------------- 0.1/2.5 GB 894.7 kB/s eta 0:44:12\n",
      "     -- ------------------------------------- 0.1/2.5 GB 904.3 kB/s eta 0:43:43\n",
      "     -- ------------------------------------- 0.1/2.5 GB 907.6 kB/s eta 0:43:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 910.2 kB/s eta 0:43:25\n",
      "     -- ------------------------------------- 0.1/2.5 GB 914.5 kB/s eta 0:43:13\n",
      "     -- ------------------------------------- 0.1/2.5 GB 917.5 kB/s eta 0:43:04\n",
      "     -- ------------------------------------- 0.1/2.5 GB 919.4 kB/s eta 0:42:58\n",
      "     -- ------------------------------------- 0.1/2.5 GB 919.4 kB/s eta 0:42:58\n",
      "     -- ------------------------------------- 0.1/2.5 GB 920.4 kB/s eta 0:42:55\n",
      "     -- ------------------------------------- 0.1/2.5 GB 920.4 kB/s eta 0:42:55\n",
      "     -- ------------------------------------- 0.1/2.5 GB 913.0 kB/s eta 0:43:15\n",
      "     -- ------------------------------------- 0.1/2.5 GB 922.2 kB/s eta 0:42:49\n",
      "     -- ------------------------------------- 0.1/2.5 GB 924.7 kB/s eta 0:42:42\n",
      "     -- ------------------------------------- 0.1/2.5 GB 927.2 kB/s eta 0:42:35\n",
      "     -- ------------------------------------- 0.1/2.5 GB 927.2 kB/s eta 0:42:35\n",
      "     -- ------------------------------------- 0.1/2.5 GB 927.2 kB/s eta 0:42:35\n",
      "     -- ------------------------------------- 0.1/2.5 GB 910.2 kB/s eta 0:43:22\n",
      "     -- ------------------------------------- 0.1/2.5 GB 900.5 kB/s eta 0:43:50\n",
      "     -- ------------------------------------- 0.1/2.5 GB 927.5 kB/s eta 0:42:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 927.5 kB/s eta 0:42:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 927.5 kB/s eta 0:42:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 927.5 kB/s eta 0:42:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 927.5 kB/s eta 0:42:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 910.5 kB/s eta 0:43:20\n",
      "     -- ------------------------------------- 0.1/2.5 GB 910.5 kB/s eta 0:43:20\n",
      "     -- ------------------------------------- 0.1/2.5 GB 910.5 kB/s eta 0:43:20\n",
      "     -- ------------------------------------- 0.1/2.5 GB 910.5 kB/s eta 0:43:20\n",
      "     -- ------------------------------------- 0.1/2.5 GB 910.5 kB/s eta 0:43:20\n",
      "     -- ------------------------------------- 0.1/2.5 GB 857.7 kB/s eta 0:46:00\n",
      "     -- ------------------------------------- 0.1/2.5 GB 858.1 kB/s eta 0:45:58\n",
      "     -- ------------------------------------- 0.1/2.5 GB 858.1 kB/s eta 0:45:58\n",
      "     -- ------------------------------------- 0.1/2.5 GB 858.1 kB/s eta 0:45:58\n",
      "     -- ------------------------------------- 0.1/2.5 GB 858.1 kB/s eta 0:45:58\n",
      "     -- ------------------------------------- 0.1/2.5 GB 858.1 kB/s eta 0:45:58\n",
      "     -- ------------------------------------- 0.1/2.5 GB 805.2 kB/s eta 0:48:59\n",
      "     -- ------------------------------------- 0.1/2.5 GB 805.2 kB/s eta 0:48:59\n",
      "     -- ------------------------------------- 0.1/2.5 GB 805.2 kB/s eta 0:48:59\n",
      "     -- ------------------------------------- 0.1/2.5 GB 804.7 kB/s eta 0:49:00\n",
      "     -- ------------------------------------- 0.1/2.5 GB 804.7 kB/s eta 0:49:00\n",
      "     -- ------------------------------------- 0.1/2.5 GB 804.7 kB/s eta 0:49:00\n",
      "     -- ------------------------------------- 0.1/2.5 GB 804.7 kB/s eta 0:49:00\n",
      "     -- ------------------------------------- 0.1/2.5 GB 804.7 kB/s eta 0:49:00\n",
      "     -- ------------------------------------- 0.1/2.5 GB 783.4 kB/s eta 0:50:20\n",
      "     -- ------------------------------------- 0.1/2.5 GB 788.9 kB/s eta 0:49:58\n",
      "     -- ------------------------------------- 0.1/2.5 GB 841.7 kB/s eta 0:46:50\n",
      "     -- ------------------------------------- 0.1/2.5 GB 847.2 kB/s eta 0:46:31\n",
      "     -- ------------------------------------- 0.1/2.5 GB 847.2 kB/s eta 0:46:31\n",
      "     -- ------------------------------------- 0.1/2.5 GB 847.2 kB/s eta 0:46:31\n",
      "     -- ------------------------------------- 0.1/2.5 GB 847.2 kB/s eta 0:46:31\n",
      "     -- ------------------------------------- 0.1/2.5 GB 847.2 kB/s eta 0:46:31\n",
      "     -- ------------------------------------- 0.1/2.5 GB 847.2 kB/s eta 0:46:31\n",
      "     -- ------------------------------------- 0.1/2.5 GB 825.3 kB/s eta 0:47:45\n",
      "     -- ------------------------------------- 0.1/2.5 GB 828.7 kB/s eta 0:47:32\n",
      "     -- ------------------------------------- 0.1/2.5 GB 838.9 kB/s eta 0:46:57\n",
      "     -- ------------------------------------- 0.1/2.5 GB 834.5 kB/s eta 0:47:12\n",
      "     -- ------------------------------------- 0.1/2.5 GB 856.7 kB/s eta 0:45:58\n",
      "     -- ------------------------------------- 0.1/2.5 GB 862.0 kB/s eta 0:45:41\n",
      "     -- ------------------------------------- 0.1/2.5 GB 871.4 kB/s eta 0:45:10\n",
      "     -- ------------------------------------- 0.1/2.5 GB 877.0 kB/s eta 0:44:53\n",
      "     -- ------------------------------------- 0.2/2.5 GB 883.0 kB/s eta 0:44:34\n",
      "     -- ------------------------------------- 0.2/2.5 GB 892.7 kB/s eta 0:44:04\n",
      "     -- ------------------------------------- 0.2/2.5 GB 928.5 kB/s eta 0:42:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 938.1 kB/s eta 0:41:55\n",
      "     -- ------------------------------------- 0.2/2.5 GB 947.5 kB/s eta 0:41:30\n",
      "     -- ------------------------------------- 0.2/2.5 GB 953.3 kB/s eta 0:41:14\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.2 kB/s eta 0:41:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 931.6 kB/s eta 0:42:12\n",
      "     -- ------------------------------------- 0.2/2.5 GB 940.4 kB/s eta 0:41:47\n",
      "     -- ------------------------------------- 0.2/2.5 GB 952.5 kB/s eta 0:41:15\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.0 MB/s eta 0:37:44\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.1 MB/s eta 0:37:17\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.1 MB/s eta 0:36:57\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.1 MB/s eta 0:36:33\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.1 MB/s eta 0:35:55\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.1 MB/s eta 0:35:34\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.1 MB/s eta 0:35:01\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.1 MB/s eta 0:34:27\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.1 MB/s eta 0:34:06\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:44\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:32\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:31:57\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:31:47\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:31:41\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:31:38\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:31:38\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:31:38\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:31:38\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:31:38\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:11\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:11\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:11\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:50\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:50\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:56\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:59\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:59\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:43\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:39\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:31\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:26\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:32:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.2 MB/s eta 0:33:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.1 MB/s eta 0:36:28\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.0 MB/s eta 0:37:15\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.0 MB/s eta 0:37:15\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.0 MB/s eta 0:37:15\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.0 MB/s eta 0:37:15\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.0 MB/s eta 0:38:51\n",
      "     -- ------------------------------------- 0.2/2.5 GB 1.0 MB/s eta 0:38:51\n",
      "     -- ------------------------------------- 0.2/2.5 GB 990.0 kB/s eta 0:39:28\n",
      "     -- ------------------------------------- 0.2/2.5 GB 973.0 kB/s eta 0:40:09\n",
      "     -- ------------------------------------- 0.2/2.5 GB 973.0 kB/s eta 0:40:09\n",
      "     -- ------------------------------------- 0.2/2.5 GB 975.5 kB/s eta 0:40:03\n",
      "     -- ------------------------------------- 0.2/2.5 GB 972.0 kB/s eta 0:40:11\n",
      "     -- ------------------------------------- 0.2/2.5 GB 962.2 kB/s eta 0:40:35\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.9 kB/s eta 0:40:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.4 kB/s eta 0:40:49\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.4 kB/s eta 0:40:49\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.4 kB/s eta 0:40:49\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.4 kB/s eta 0:40:49\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.4 kB/s eta 0:40:49\n",
      "     -- ------------------------------------- 0.2/2.5 GB 917.5 kB/s eta 0:42:33\n",
      "     -- ------------------------------------- 0.2/2.5 GB 919.8 kB/s eta 0:42:26\n",
      "     -- ------------------------------------- 0.2/2.5 GB 921.8 kB/s eta 0:42:20\n",
      "     -- ------------------------------------- 0.2/2.5 GB 922.3 kB/s eta 0:42:19\n",
      "     -- ------------------------------------- 0.2/2.5 GB 920.9 kB/s eta 0:42:23\n",
      "     -- ------------------------------------- 0.2/2.5 GB 921.8 kB/s eta 0:42:20\n",
      "     -- ------------------------------------- 0.2/2.5 GB 930.1 kB/s eta 0:41:57\n",
      "     -- ------------------------------------- 0.2/2.5 GB 930.1 kB/s eta 0:41:57\n",
      "     -- ------------------------------------- 0.2/2.5 GB 930.1 kB/s eta 0:41:57\n",
      "     -- ------------------------------------- 0.2/2.5 GB 922.3 kB/s eta 0:42:18\n",
      "     -- ------------------------------------- 0.2/2.5 GB 922.3 kB/s eta 0:42:18\n",
      "     -- ------------------------------------- 0.2/2.5 GB 922.3 kB/s eta 0:42:18\n",
      "     -- ------------------------------------- 0.2/2.5 GB 930.6 kB/s eta 0:41:55\n",
      "     -- ------------------------------------- 0.2/2.5 GB 930.6 kB/s eta 0:41:55\n",
      "     -- ------------------------------------- 0.2/2.5 GB 926.7 kB/s eta 0:42:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 926.7 kB/s eta 0:42:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 919.4 kB/s eta 0:42:25\n",
      "     -- ------------------------------------- 0.2/2.5 GB 919.4 kB/s eta 0:42:25\n",
      "     -- ------------------------------------- 0.2/2.5 GB 935.5 kB/s eta 0:41:41\n",
      "     -- ------------------------------------- 0.2/2.5 GB 935.5 kB/s eta 0:41:41\n",
      "     -- ------------------------------------- 0.2/2.5 GB 935.5 kB/s eta 0:41:41\n",
      "     -- ------------------------------------- 0.2/2.5 GB 920.4 kB/s eta 0:42:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 944.6 kB/s eta 0:41:16\n",
      "     -- ------------------------------------- 0.2/2.5 GB 944.6 kB/s eta 0:41:16\n",
      "     -- ------------------------------------- 0.2/2.5 GB 944.6 kB/s eta 0:41:16\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.5 kB/s eta 0:41:37\n",
      "     -- ------------------------------------- 0.2/2.5 GB 937.9 kB/s eta 0:41:33\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.9 kB/s eta 0:40:43\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.9 kB/s eta 0:40:43\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.9 kB/s eta 0:40:43\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.9 kB/s eta 0:40:43\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.9 kB/s eta 0:40:43\n",
      "     -- ------------------------------------- 0.2/2.5 GB 956.9 kB/s eta 0:40:43\n",
      "     -- ------------------------------------- 0.2/2.5 GB 940.8 kB/s eta 0:41:25\n",
      "     -- ------------------------------------- 0.2/2.5 GB 940.8 kB/s eta 0:41:25\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.9 kB/s eta 0:41:35\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.9 kB/s eta 0:41:35\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.9 kB/s eta 0:41:35\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.9 kB/s eta 0:41:35\n",
      "     -- ------------------------------------- 0.2/2.5 GB 925.6 kB/s eta 0:42:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 928.1 kB/s eta 0:41:58\n",
      "     -- ------------------------------------- 0.2/2.5 GB 930.6 kB/s eta 0:41:51\n",
      "     -- ------------------------------------- 0.2/2.5 GB 933.1 kB/s eta 0:41:44\n",
      "     -- ------------------------------------- 0.2/2.5 GB 937.9 kB/s eta 0:41:31\n",
      "     -- ------------------------------------- 0.2/2.5 GB 937.4 kB/s eta 0:41:32\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.9 kB/s eta 0:41:33\n",
      "     -- ------------------------------------- 0.2/2.5 GB 935.0 kB/s eta 0:41:38\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.9 kB/s eta 0:41:32\n",
      "     -- ------------------------------------- 0.2/2.5 GB 929.6 kB/s eta 0:41:51\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.0 kB/s eta 0:41:34\n",
      "     -- ------------------------------------- 0.2/2.5 GB 935.4 kB/s eta 0:41:35\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.4 kB/s eta 0:41:32\n",
      "     -- ------------------------------------- 0.2/2.5 GB 936.4 kB/s eta 0:41:32\n",
      "     -- ------------------------------------- 0.2/2.5 GB 919.9 kB/s eta 0:42:16\n",
      "     -- ------------------------------------- 0.2/2.5 GB 917.5 kB/s eta 0:42:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 917.5 kB/s eta 0:42:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 917.5 kB/s eta 0:42:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 917.5 kB/s eta 0:42:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 917.5 kB/s eta 0:42:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 917.5 kB/s eta 0:42:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 917.5 kB/s eta 0:42:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 926.9 kB/s eta 0:41:56\n",
      "     -- ------------------------------------- 0.2/2.5 GB 926.9 kB/s eta 0:41:56\n",
      "     -- ------------------------------------- 0.2/2.5 GB 920.8 kB/s eta 0:42:13\n",
      "     -- ------------------------------------- 0.2/2.5 GB 923.9 kB/s eta 0:42:04\n",
      "     -- ------------------------------------- 0.2/2.5 GB 932.6 kB/s eta 0:41:40\n",
      "     -- ------------------------------------- 0.2/2.5 GB 943.1 kB/s eta 0:41:12\n",
      "     -- ------------------------------------- 0.2/2.5 GB 945.5 kB/s eta 0:41:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 945.5 kB/s eta 0:41:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 945.5 kB/s eta 0:41:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 945.5 kB/s eta 0:41:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 945.5 kB/s eta 0:41:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 945.5 kB/s eta 0:41:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 945.5 kB/s eta 0:41:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 859.0 kB/s eta 0:45:13\n",
      "     -- ------------------------------------- 0.2/2.5 GB 859.0 kB/s eta 0:45:13\n",
      "     -- ------------------------------------- 0.2/2.5 GB 859.0 kB/s eta 0:45:13\n",
      "     -- ------------------------------------- 0.2/2.5 GB 859.0 kB/s eta 0:45:13\n",
      "     -- ------------------------------------- 0.2/2.5 GB 859.0 kB/s eta 0:45:13\n",
      "     -- ------------------------------------- 0.2/2.5 GB 859.0 kB/s eta 0:45:13\n",
      "     -- ------------------------------------- 0.2/2.5 GB 859.0 kB/s eta 0:45:13\n",
      "     -- ------------------------------------- 0.2/2.5 GB 727.2 kB/s eta 0:53:24\n",
      "     -- ------------------------------------- 0.2/2.5 GB 725.3 kB/s eta 0:53:32\n",
      "     -- ------------------------------------- 0.2/2.5 GB 725.3 kB/s eta 0:53:31\n",
      "     -- ------------------------------------- 0.2/2.5 GB 725.3 kB/s eta 0:53:31\n",
      "     -- ------------------------------------- 0.2/2.5 GB 725.3 kB/s eta 0:53:31\n",
      "     -- ------------------------------------- 0.2/2.5 GB 682.6 kB/s eta 0:56:52\n",
      "     -- ------------------------------------- 0.2/2.5 GB 683.4 kB/s eta 0:56:47\n",
      "     -- ------------------------------------- 0.2/2.5 GB 691.4 kB/s eta 0:56:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 713.3 kB/s eta 0:54:23\n",
      "     -- ------------------------------------- 0.2/2.5 GB 724.4 kB/s eta 0:53:33\n",
      "     -- ------------------------------------- 0.2/2.5 GB 736.0 kB/s eta 0:52:41\n",
      "     -- ------------------------------------- 0.2/2.5 GB 739.8 kB/s eta 0:52:25\n",
      "     -- ------------------------------------- 0.2/2.5 GB 739.8 kB/s eta 0:52:25\n",
      "     -- ------------------------------------- 0.2/2.5 GB 751.6 kB/s eta 0:51:35\n",
      "     -- ------------------------------------- 0.2/2.5 GB 754.5 kB/s eta 0:51:23\n",
      "     -- ------------------------------------- 0.2/2.5 GB 754.5 kB/s eta 0:51:23\n",
      "     -- ------------------------------------- 0.2/2.5 GB 748.2 kB/s eta 0:51:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 748.2 kB/s eta 0:51:48\n",
      "     -- ------------------------------------- 0.2/2.5 GB 746.6 kB/s eta 0:51:54\n",
      "     -- ------------------------------------- 0.2/2.5 GB 743.9 kB/s eta 0:52:05\n",
      "     -- ------------------------------------- 0.2/2.5 GB 744.7 kB/s eta 0:52:02\n",
      "     -- ------------------------------------- 0.2/2.5 GB 743.1 kB/s eta 0:52:08\n",
      "     -- ------------------------------------- 0.2/2.5 GB 743.9 kB/s eta 0:52:04\n",
      "     -- ------------------------------------- 0.2/2.5 GB 738.2 kB/s eta 0:52:28\n",
      "     -- ------------------------------------- 0.2/2.5 GB 743.1 kB/s eta 0:52:07\n",
      "     -- ------------------------------------- 0.2/2.5 GB 745.1 kB/s eta 0:51:58\n",
      "     --- ------------------------------------ 0.2/2.5 GB 786.9 kB/s eta 0:49:11\n",
      "     --- ------------------------------------ 0.2/2.5 GB 793.3 kB/s eta 0:48:47\n",
      "     --- ------------------------------------ 0.2/2.5 GB 793.3 kB/s eta 0:48:47\n",
      "     --- ------------------------------------ 0.2/2.5 GB 787.5 kB/s eta 0:49:08\n",
      "     --- ------------------------------------ 0.2/2.5 GB 793.0 kB/s eta 0:48:47\n",
      "     --- ------------------------------------ 0.2/2.5 GB 863.7 kB/s eta 0:44:47\n",
      "     --- ------------------------------------ 0.2/2.5 GB 868.8 kB/s eta 0:44:31\n",
      "     --- ------------------------------------ 0.2/2.5 GB 872.3 kB/s eta 0:44:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 877.2 kB/s eta 0:44:05\n",
      "     --- ------------------------------------ 0.2/2.5 GB 876.8 kB/s eta 0:44:06\n",
      "     --- ------------------------------------ 0.2/2.5 GB 877.3 kB/s eta 0:44:04\n",
      "     --- ------------------------------------ 0.2/2.5 GB 881.6 kB/s eta 0:43:51\n",
      "     --- ------------------------------------ 0.2/2.5 GB 884.4 kB/s eta 0:43:42\n",
      "     --- ------------------------------------ 0.2/2.5 GB 884.9 kB/s eta 0:43:40\n",
      "     --- ------------------------------------ 0.2/2.5 GB 889.5 kB/s eta 0:43:26\n",
      "     --- ------------------------------------ 0.2/2.5 GB 888.1 kB/s eta 0:43:30\n",
      "     --- ------------------------------------ 0.2/2.5 GB 907.6 kB/s eta 0:42:34\n",
      "     --- ------------------------------------ 0.2/2.5 GB 912.2 kB/s eta 0:42:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 916.7 kB/s eta 0:42:08\n",
      "     --- ------------------------------------ 0.2/2.5 GB 924.7 kB/s eta 0:41:46\n",
      "     --- ------------------------------------ 0.2/2.5 GB 927.2 kB/s eta 0:41:39\n",
      "     --- ------------------------------------ 0.2/2.5 GB 934.0 kB/s eta 0:41:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 937.0 kB/s eta 0:41:12\n",
      "     --- ------------------------------------ 0.2/2.5 GB 945.7 kB/s eta 0:40:49\n",
      "     --- ------------------------------------ 0.2/2.5 GB 947.7 kB/s eta 0:40:43\n",
      "     --- ------------------------------------ 0.2/2.5 GB 952.5 kB/s eta 0:40:31\n",
      "     --- ------------------------------------ 0.2/2.5 GB 958.5 kB/s eta 0:40:15\n",
      "     --- ------------------------------------ 0.2/2.5 GB 963.7 kB/s eta 0:40:02\n",
      "     --- ------------------------------------ 0.2/2.5 GB 975.5 kB/s eta 0:39:32\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.0 MB/s eta 0:38:01\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.0 MB/s eta 0:37:35\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.0 MB/s eta 0:37:08\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:36:33\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:35:55\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:35:48\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:35:28\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:35:19\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:35:28\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:35:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:35:19\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:35:10\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:34:42\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:34:33\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:33:43\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.1 MB/s eta 0:33:37\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:33:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:33:13\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:32:40\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:32:32\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:32:09\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:31:46\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:31:32\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:31:03\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:31:02\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:31:00\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:30:55\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.2 MB/s eta 0:30:49\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:30:38\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:30:29\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:30:33\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:30:35\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:30:26\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:29:04\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:29:02\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:28:57\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:28:51\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:28:49\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:28:43\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.3 MB/s eta 0:28:43\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:59\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:51\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:45\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:46\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:33\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:34\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:34\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:28\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:34\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:39\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:48\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:41\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:40\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:41\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:27\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:25\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:15\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.4 MB/s eta 0:27:15\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:59\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:56\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:54\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:54\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:26:01\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:59\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:36\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:34\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:29\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:26\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:26\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:26\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:36\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:34\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:34\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:24:38\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:24:38\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:24:52\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:24:52\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:25:08\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:09\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:09\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:13\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:19\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:19\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:22\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:28\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:24:36\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.5 MB/s eta 0:24:36\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:03\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:03\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:12\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:15\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:16\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:16\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:12\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:24:05\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:23:55\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:23:42\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:23:33\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:23:19\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:23:03\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.6 MB/s eta 0:23:00\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:22:49\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:22:43\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:22:28\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:22:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:22:07\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:22:01\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:21:52\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:21:48\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:21:42\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:21:37\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:21:38\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:21:17\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:21:13\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:21:09\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:21:11\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:21:08\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:21:04\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:59\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:48\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:42\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:41\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:38\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:27\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:25\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.9 MB/s eta 0:20:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.9 MB/s eta 0:20:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.9 MB/s eta 0:20:22\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.9 MB/s eta 0:20:22\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.9 MB/s eta 0:20:22\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:47\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:47\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:52\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:52\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:57\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:57\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:57\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.8 MB/s eta 0:20:57\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     --- ------------------------------------ 0.2/2.5 GB 1.7 MB/s eta 0:22:14\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.7 MB/s eta 0:22:34\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.7 MB/s eta 0:22:34\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.7 MB/s eta 0:22:34\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.7 MB/s eta 0:22:34\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.7 MB/s eta 0:22:34\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.7 MB/s eta 0:22:34\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.6 MB/s eta 0:23:40\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.6 MB/s eta 0:23:40\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.6 MB/s eta 0:23:40\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.6 MB/s eta 0:23:40\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.6 MB/s eta 0:24:17\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.6 MB/s eta 0:24:17\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.5 MB/s eta 0:24:25\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.5 MB/s eta 0:24:25\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.5 MB/s eta 0:24:25\n",
      "     --- ------------------------------------ 0.3/2.5 GB 1.5 MB/s eta 0:24:25\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:25\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:25\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:39\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:45\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:43\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:36\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:36\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:36\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:55\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:53\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:55\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:55\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:03\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:09\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:12\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:08\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:05\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:00\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:00\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:48\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:42\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:41\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:42\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:40\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:47\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:42\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:39\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:43\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:40\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:29\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:23\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:21\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:29\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:29\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:39\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:04\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:08\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:13\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:05\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:52\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:03\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:55\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:59\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:51\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:37\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:14\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:07\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:59\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:37\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:19\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:12\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:24:04\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:57\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:59\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:57\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:52\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:53\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:40\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:32\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:28\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:27\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:25\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:24\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:28\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:27\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:25\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:34\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:36\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:36\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:43\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:52\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:06\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:15\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:26\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:39\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:50\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:03\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:59\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:03\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:03\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:14\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:22\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:28\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:47\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:58\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:10\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:29\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:29\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:49\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:48\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:34\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:29\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:43\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:32\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:24\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:17\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:01\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:48\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:01\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:47\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:38\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:26\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:19\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:22:50\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:22:45\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:22:38\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:22:26\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:29\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:30\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:30\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:35\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:39\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:45\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:45\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:25\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:27\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:29\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:32\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:32\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:32\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:11\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:15\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:22\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:22\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:26\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:26\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.7 MB/s eta 0:21:33\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.6 MB/s eta 0:23:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:37\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:37\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:53\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:53\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:03\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:08\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:16\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:21\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:23\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:24\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:26\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:24\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:25:06\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:59\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:52\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:50\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:48\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:53\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:53\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:53\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:53\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.5 MB/s eta 0:24:53\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:51\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:51\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:51\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:51\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:51\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:25:51\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:27:16\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:27:16\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:27:58\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:27:58\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:28:22\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:28:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:28:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:28:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:28:44\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:50\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:50\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:56\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:32:57\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:32:57\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:33:34\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:33:34\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:05\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:23\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:50\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:51\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:34:54\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:52\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:48\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:51\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:36\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:29\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:29\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:29\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:29\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:58\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:45\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:59\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:45\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:23\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:08\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:34:49\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:37\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 963.2 kB/s eta 0:37:56\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 952.9 kB/s eta 0:38:20\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 952.9 kB/s eta 0:38:20\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 919.4 kB/s eta 0:39:44\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 684.4 kB/s eta 0:53:22\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 675.3 kB/s eta 0:54:05\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 675.3 kB/s eta 0:54:05\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 677.4 kB/s eta 0:53:53\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 677.4 kB/s eta 0:53:53\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 683.4 kB/s eta 0:53:25\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 683.4 kB/s eta 0:53:25\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 685.9 kB/s eta 0:53:13\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 691.8 kB/s eta 0:52:45\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 692.1 kB/s eta 0:52:43\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 690.7 kB/s eta 0:52:49\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 703.1 kB/s eta 0:51:52\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 707.2 kB/s eta 0:51:34\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 717.3 kB/s eta 0:50:50\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 720.3 kB/s eta 0:50:37\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 720.3 kB/s eta 0:50:37\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 716.9 kB/s eta 0:50:51\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 719.5 kB/s eta 0:50:39\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 723.7 kB/s eta 0:50:21\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 727.5 kB/s eta 0:50:05\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 819.1 kB/s eta 0:44:29\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 829.1 kB/s eta 0:43:56\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 833.5 kB/s eta 0:43:42\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 844.6 kB/s eta 0:43:07\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 856.5 kB/s eta 0:42:30\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 869.1 kB/s eta 0:41:53\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 882.0 kB/s eta 0:41:15\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 894.8 kB/s eta 0:40:39\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 914.1 kB/s eta 0:39:47\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 925.9 kB/s eta 0:39:16\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 938.1 kB/s eta 0:38:45\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 949.1 kB/s eta 0:38:17\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 961.0 kB/s eta 0:37:48\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 964.3 kB/s eta 0:37:40\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 964.3 kB/s eta 0:37:40\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 961.5 kB/s eta 0:37:47\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:36:18\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:36:07\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:45\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:28\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:24\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:08\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:35:06\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.0 MB/s eta 0:34:37\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:34:15\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:33:57\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:33:39\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:33:26\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:33:15\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:33:17\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:32:57\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:32:27\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:32:02\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:32:03\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:31:50\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:31:46\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:31:33\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.1 MB/s eta 0:31:26\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:30:56\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:47\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:23\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.2 MB/s eta 0:29:06\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:28:52\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:28:30\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:28:15\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:26:55\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:26:55\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:27:03\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:26:53\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.3 MB/s eta 0:26:42\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 1.4 MB/s eta 0:26:31\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:59\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:51\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:33\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:21\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:12\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:24:33\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:24:24\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:24:18\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:24:11\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:59\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:28\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:22\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:17\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:16\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:13\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:20\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:18\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:24\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:22\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:22\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:17\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:11\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:13\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:13\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:18\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:24\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:24\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:28\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:28\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:28\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:50\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:50\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:27\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:30\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:34\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:36\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:36\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:53\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:53\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:23:00\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:23:00\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:23:00\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:24\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:24\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:39\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:12\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:14\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:17\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:14\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:18\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:18\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:25\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:30\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:35\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:35\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:27\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:28\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:29\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:30\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:30\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:30\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:29\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:31\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:31\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:39\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:44\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:44\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:44\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:44\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:07\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:12\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:12\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:12\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:24\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:24\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:26\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:31\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:31\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:35\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:21:35\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:44\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:46\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:44\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:49\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:49\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:49\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:00\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:57\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:56\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:52\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:48\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:44\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:41\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:44\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:46\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:59\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:59\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:59\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:59\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:52\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:22:52\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:16\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:16\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:39\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:23\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:15\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:12\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:18\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:23\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:33\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:33\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:33\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:45\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:59\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:59\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:24:18\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:24:18\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:43\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:54\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:54\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:14\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:29\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:43\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:58\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:26:00\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:26:09\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:20\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:27\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:32\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:40\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:50\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:51\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:51\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:51\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:51\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:23\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:22\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:21\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:21\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:19\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:21\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:21\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:23\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:33\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:36\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:35\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:49\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:48\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:49\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:49\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:42\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:43\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:32:15\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:32:03\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:48\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:20\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.1 MB/s eta 0:31:14\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:30:37\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:30:35\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:30:28\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:30:05\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:29:56\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:29:47\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:29:31\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:29:31\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:29:03\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:52\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:50\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:42\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:43\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.2 MB/s eta 0:28:22\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:59\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:48\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:42\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:29\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:17\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:05\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:58\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:43\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:25\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:13\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:02\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:47\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:47\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:40\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:34\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:31\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:40\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:43\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:45\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:42\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:35\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:26\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:54\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:50\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:45\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:33\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:32\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:32\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:12\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:24:05\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:55\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:55\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:55\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:58\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:44\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:45\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:45\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:52\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:30\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:55\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:43\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:23\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:27:03\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:50\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:26\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:26:03\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.3 MB/s eta 0:25:53\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:43\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:33\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:21\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:11\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:25:05\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:49\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:40\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:33\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:24\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:18\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.4 MB/s eta 0:24:13\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:24\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:15\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:23:00\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:22:48\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.5 MB/s eta 0:22:39\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:26\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:21\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:17\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:17\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:15\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:10\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:07\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:15\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:17\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:24\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:28\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:34\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:33\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:37\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:35\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:37\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:35\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:35\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:29\n",
      "     ------ --------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:21\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:21\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:20\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:19\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:21:18\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:49\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:49\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.6 MB/s eta 0:20:56\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:52\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:50\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:49\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:45\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:41\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:36\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:31\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:24\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:22\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:16\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:14\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:10\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:20:04\n",
      "     ------- -------------------------------- 0.4/2.5 GB 1.7 MB/s eta 0:19:59\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:20:01\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:20:00\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:55\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:54\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:49\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:47\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:47\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:48\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:49\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:54\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:20:00\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:55\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:54\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:58\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:51\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:50\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:50\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:50\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:45\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:45\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:49\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:41\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:40\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:33\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:33\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:32\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:31\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:34\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:32\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:35\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:37\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:36\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:30\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:19:28\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.7 MB/s eta 0:19:30\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:19:10\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:19:10\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:19:10\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:19:11\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:19:12\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:19:12\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:19:04\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:19:03\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:18:53\n",
      "     ------- -------------------------------- 0.5/2.5 GB 1.8 MB/s eta 0:18:52\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:11\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:13\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:15\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:16\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:15\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:18\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:19\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:21\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:23\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:26\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:29\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:29\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:37\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:40\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:40\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:39\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:40\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:39\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:39\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:40\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:43\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:43\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:45\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:46\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:48\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:54\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:56\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:58\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:02\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:03\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:05\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:06\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:11\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:13\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:18\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:20\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:24\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:25\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:28\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:29\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:33\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:40\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:44\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:45\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:45\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:45\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:43\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:40\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:29\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:29\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:29\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.0 MB/s eta 0:16:26\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:22\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:18\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:12\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:07\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:16:03\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:58\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:54\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:50\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:46\n",
      "     ------- -------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:45\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:40\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.1 MB/s eta 0:15:37\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:34\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:29\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:27\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:23\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:19\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:10\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:06\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:02\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:59\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:58\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:58\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:57\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:57\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:56\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:55\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:53\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:52\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:52\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:54\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:55\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:55\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:00\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:15:00\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:58\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:56\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:56\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:54\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:50\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.2 MB/s eta 0:14:47\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:44\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:38\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:35\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:28\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:28\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:33\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:31\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:32\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:33\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:32\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:24\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:22\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:20\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:17\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:16\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:15\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:16\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:16\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:17\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:13\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:11\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.3 MB/s eta 0:14:05\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:14:02\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:57\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:55\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:52\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:48\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:44\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:41\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:38\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:35\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:31\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:28\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:26\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:25\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:22\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:23\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:24\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.4 MB/s eta 0:13:24\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:22\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:21\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:19\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:18\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:14\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:15\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:15\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:15\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:16\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:17\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:17\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:16\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:16\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:16\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:11\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:13\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:13\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:13\n",
      "     -------- ------------------------------- 0.5/2.5 GB 2.5 MB/s eta 0:13:13\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:14\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:15\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:16\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:17\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:16\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:15\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:15\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:16\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:17\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:17\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:18\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:18\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:19\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:19\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:13:18\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:19\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:19\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:22\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:23\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:25\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:26\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:27\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:27\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:29\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:31\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:33\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:35\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:39\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:42\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:42\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:44\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:44\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:47\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:48\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.3 MB/s eta 0:13:53\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.3 MB/s eta 0:13:56\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.3 MB/s eta 0:13:59\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.3 MB/s eta 0:14:01\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.3 MB/s eta 0:14:04\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.3 MB/s eta 0:14:04\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.3 MB/s eta 0:14:03\n",
      "     -------- ------------------------------- 0.6/2.5 GB 2.3 MB/s eta 0:14:04\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:03\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:04\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:06\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:09\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:11\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:15\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:19\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:20\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:20\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:19\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:20\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:20\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:20\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:20\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:21\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:14:21\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:22\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:26\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:26\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:32\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:37\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:37\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:45\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:46\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:48\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:49\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:50\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:51\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:50\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:50\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:50\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:48\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:41\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:41\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:39\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:39\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:41\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:41\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:41\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:51\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:51\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:50\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:48\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:50\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:49\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:48\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:43\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:42\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:43\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:43\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:45\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:44\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:45\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:47\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:47\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:48\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:43\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:41\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:36\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:36\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:39\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:43\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:49\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:14:57\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:14:59\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:14:59\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:04\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:11\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:14\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:15\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:25\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:29\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.0 MB/s eta 0:15:37\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.0 MB/s eta 0:15:37\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.0 MB/s eta 0:15:38\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.0 MB/s eta 0:15:36\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.0 MB/s eta 0:15:32\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:29\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:29\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:27\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:24\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:24\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:22\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:19\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:16\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:10\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:05\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:15:03\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:14:55\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:14:51\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.1 MB/s eta 0:14:46\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:43\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:35\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:33\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:30\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:29\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:27\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:23\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:15\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:14\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:10\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:09\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:06\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.2 MB/s eta 0:14:01\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:58\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:55\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:51\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:48\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:48\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:42\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:39\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:38\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:38\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:33\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:33\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:32\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:34\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:32\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:30\n",
      "     --------- ------------------------------ 0.6/2.5 GB 2.3 MB/s eta 0:13:27\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.3 MB/s eta 0:13:23\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:20\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:16\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:14\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:17\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:12\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:11\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:08\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:03\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:01\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:12:58\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:12:57\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:12:57\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:12:57\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:00\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:01\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:05\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:04\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:04\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:04\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:04\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:05\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:04\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:02\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:01\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:03\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:06\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:07\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:07\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:06\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:07\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:07\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:06\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:04\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:04\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:04\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:13:01\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:12:58\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:12:54\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:12:49\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.4 MB/s eta 0:12:42\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 2.5 MB/s eta 0:12:40\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:37\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:35\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:33\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:32\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:31\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:31\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:29\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:27\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:26\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:26\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:25\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:25\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:24\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:24\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:18\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:17\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:17\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:15\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:15\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:15\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:15\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:15\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:14\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:14\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:13\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:11\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:12\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:11\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:11\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:10\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:08\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:06\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:04\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:04\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:03\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:03\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.5 MB/s eta 0:12:03\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:59\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:56\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:53\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:53\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:53\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:55\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:55\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:55\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:58\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:58\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:57\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:54\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:54\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:50\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:48\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:45\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:42\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:41\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:40\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:38\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:37\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:37\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:37\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:36\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:36\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:35\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:35\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:35\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:35\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:35\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:34\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:34\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:33\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:33\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:33\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:32\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:29\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:30\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:28\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:28\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:27\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:27\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:27\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:26\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:25\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:24\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:24\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:23\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:24\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:24\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:23\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:26\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:28\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:29\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:30\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:30\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:25\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:25\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:25\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:23\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:23\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:29\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:27\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:27\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:27\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.6 MB/s eta 0:11:22\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:20\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:18\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:17\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:16\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:15\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:16\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:15\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:13\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:10\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:10\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:04\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:01\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:00\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:59\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:58\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:57\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:57\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:59\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:59\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:01\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:11:00\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:59\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:57\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:56\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:55\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:55\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:54\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:54\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:53\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:53\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:52\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:52\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:52\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:52\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:52\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:50\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:50\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:50\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:50\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:49\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:48\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:49\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:49\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:50\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:52\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:50\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:51\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:53\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 2.7 MB/s eta 0:10:57\n",
      "     ----------- ---------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:57\n",
      "     ----------- ---------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:11:00\n",
      "     ----------- ---------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:59\n",
      "     ----------- ---------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:59\n",
      "     ----------- ---------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:59\n",
      "     ----------- ---------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:59\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:11:01\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:11:01\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:11:01\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:11:01\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:57\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:59\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:56\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:57\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:55\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:57\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:57\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:10:58\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.7 MB/s eta 0:11:00\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.6 MB/s eta 0:11:04\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.6 MB/s eta 0:11:04\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.6 MB/s eta 0:11:13\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.6 MB/s eta 0:11:16\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.6 MB/s eta 0:11:17\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.6 MB/s eta 0:11:21\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.6 MB/s eta 0:11:23\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.6 MB/s eta 0:11:24\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.6 MB/s eta 0:11:26\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:27\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:28\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:28\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:28\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:27\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:28\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:28\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:28\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:30\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:30\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:31\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:32\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:32\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:33\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:37\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:39\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:40\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:43\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:45\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:45\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:46\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:47\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:47\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:47\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:48\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:46\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:47\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:46\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:44\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:41\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:39\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:36\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:36\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:33\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:30\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:30\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:25\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:24\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:25\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:25\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:26\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:26\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:28\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:28\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:29\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:30\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:34\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:37\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:39\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:41\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:46\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:46\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:49\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:50\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:50\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:49\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:50\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:50\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:48\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:44\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:41\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:38\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:37\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:36\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:34\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:34\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:33\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:33\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:33\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:34\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:36\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.5 MB/s eta 0:11:36\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:36\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:41\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:41\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:44\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:48\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:50\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:53\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:11:58\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.4 MB/s eta 0:12:01\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:07\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:09\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:14\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:14\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:17\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:18\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:19\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:20\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:24\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:25\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:28\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:29\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.3 MB/s eta 0:12:34\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:35\n",
      "     ------------ --------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:38\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:41\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:42\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:41\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:41\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:44\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:49\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:52\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:55\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:58\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:58\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:04\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:03\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:04\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:07\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:05\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:05\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:04\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:03\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:04\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:05\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:05\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:06\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:58\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:58\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:57\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:56\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:55\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:53\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:53\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:53\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:51\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:52\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:55\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:57\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:57\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:09\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:11\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:11\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:11\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:10\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:10\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:10\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:09\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:07\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:04\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:02\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:13:00\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:57\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:53\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:52\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:49\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:49\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:49\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:49\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:51\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:51\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:53\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:55\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.2 MB/s eta 0:12:57\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:12:59\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:03\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:05\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:09\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:09\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:12\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:15\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:18\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:19\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:20\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:20\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:21\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:21\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:21\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:27\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.1 MB/s eta 0:13:27\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:34\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:36\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:37\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:36\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:36\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:43\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:44\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:43\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:40\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:40\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:52\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:53\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:53\n",
      "     ------------- -------------------------- 0.8/2.5 GB 2.0 MB/s eta 0:13:54\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:53\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:55\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:57\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:59\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:14:03\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:14:09\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:14:11\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:13\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:14\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:21\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:22\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:24\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:25\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:29\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:33\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:31\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:31\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:30\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:31\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:31\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:40\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:38\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:37\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:37\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:34\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:34\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:37\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:37\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:33\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:28\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:25\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:19\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:14\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:15\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:13\n",
      "     ------------- -------------------------- 0.9/2.5 GB 1.9 MB/s eta 0:14:06\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:14:00\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:57\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:55\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:54\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:57\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:57\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:58\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:53\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:48\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:46\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:45\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:40\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:38\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:40\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:41\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:36\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:32\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:29\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.0 MB/s eta 0:13:23\n",
      "     ------------- -------------------------- 0.9/2.5 GB 2.1 MB/s eta 0:13:14\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.1 MB/s eta 0:13:06\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.1 MB/s eta 0:13:01\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.1 MB/s eta 0:12:53\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.1 MB/s eta 0:12:47\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.1 MB/s eta 0:12:45\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:36\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:32\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:27\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:24\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:22\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:26\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:24\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:22\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:18\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:13\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:08\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:09\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:08\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:09\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:12\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:13\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:17\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:16\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:16\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:12\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:10\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:04\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:03\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.2 MB/s eta 0:12:00\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:58\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:56\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:53\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:50\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:45\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:44\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:40\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:40\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:43\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:43\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:45\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:47\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:47\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:45\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:44\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:43\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:41\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:38\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:35\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:31\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.3 MB/s eta 0:11:26\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.4 MB/s eta 0:11:21\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.4 MB/s eta 0:11:13\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.4 MB/s eta 0:11:10\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.4 MB/s eta 0:11:05\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.4 MB/s eta 0:11:01\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.4 MB/s eta 0:10:59\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.4 MB/s eta 0:10:55\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.5 MB/s eta 0:10:51\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.5 MB/s eta 0:10:46\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.5 MB/s eta 0:10:45\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.5 MB/s eta 0:10:41\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.5 MB/s eta 0:10:40\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.5 MB/s eta 0:10:35\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.5 MB/s eta 0:10:31\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.5 MB/s eta 0:10:27\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.6 MB/s eta 0:10:21\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.6 MB/s eta 0:10:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.6 MB/s eta 0:10:10\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.6 MB/s eta 0:10:08\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.6 MB/s eta 0:10:04\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.6 MB/s eta 0:10:00\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.7 MB/s eta 0:09:51\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.7 MB/s eta 0:09:49\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.7 MB/s eta 0:09:45\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.7 MB/s eta 0:09:42\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:31\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:31\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:35\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:34\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:34\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:33\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.7 MB/s eta 0:09:35\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.7 MB/s eta 0:09:36\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.7 MB/s eta 0:09:34\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:29\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:29\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:27\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:26\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:26\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:22\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:19\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:17\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.8 MB/s eta 0:09:13\n",
      "     -------------- ------------------------- 0.9/2.5 GB 2.9 MB/s eta 0:09:10\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:09:07\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:09:06\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:09:05\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:09:04\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:09:02\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:08:59\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:08:58\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:08:59\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:08:59\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:08:58\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:08:57\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:08:58\n",
      "     --------------- ------------------------ 0.9/2.5 GB 2.9 MB/s eta 0:08:56\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:56\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:59\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:58\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:58\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:56\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:54\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:53\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:53\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:52\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:51\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:51\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:50\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:47\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:48\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:53\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:51\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:50\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:50\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:50\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:51\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:51\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:50\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:50\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:48\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:48\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:46\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:46\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:48\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:48\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:47\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:49\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:47\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:47\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:46\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:46\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:46\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:44\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:43\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:40\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:37\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:35\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:33\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:30\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:28\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:27\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:26\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:27\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:28\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:27\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:30\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:31\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:33\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:34\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:35\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:37\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:39\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:41\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:42\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:40\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:38\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:38\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:37\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:35\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:33\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:34\n",
      "     --------------- ------------------------ 1.0/2.5 GB 3.0 MB/s eta 0:08:34\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:37\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:39\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:39\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:39\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:39\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:39\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:38\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:37\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:37\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:36\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:35\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:34\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:33\n",
      "     --------------- ------------------------ 1.0/2.5 GB 2.9 MB/s eta 0:08:32\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:31\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:30\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:29\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:28\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:27\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:27\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:27\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:26\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:26\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:26\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:27\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:27\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:29\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:30\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:31\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:33\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:38\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:36\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:36\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:35\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:34\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:33\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:28\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 2.9 MB/s eta 0:08:26\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:23\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:22\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:21\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:21\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:19\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:16\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:15\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:15\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:15\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:16\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:16\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:17\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:17\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:16\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:15\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:15\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:15\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:13\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:13\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:09\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:08\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:07\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:06\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.0 MB/s eta 0:08:03\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:08:02\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:59\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:55\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:54\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:52\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:51\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:51\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:50\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:49\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:48\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 3.1 MB/s eta 0:07:48\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.1 MB/s eta 0:07:46\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:44\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:43\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:41\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:41\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:42\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:37\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:36\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:35\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:34\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:33\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:31\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:29\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.2 MB/s eta 0:07:27\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:26\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:25\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:24\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:23\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:23\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:22\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:22\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:21\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:21\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:19\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:17\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:15\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:14\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:11\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.3 MB/s eta 0:07:10\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.4 MB/s eta 0:07:07\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.4 MB/s eta 0:07:06\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.4 MB/s eta 0:07:05\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.4 MB/s eta 0:07:02\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.4 MB/s eta 0:06:59\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.4 MB/s eta 0:06:57\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.4 MB/s eta 0:06:56\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:54\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:54\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:54\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:53\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:52\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:52\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:49\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:47\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:45\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:42\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:43\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:43\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:44\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:43\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:42\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:41\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:39\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:37\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:36\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:35\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:34\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:33\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:33\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:33\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:33\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:33\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:31\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:31\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:29\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:29\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:27\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:27\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:27\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:27\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:27\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:27\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:27\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:29\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:30\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:31\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:32\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:34\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:33\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:33\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:30\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:28\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:26\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:25\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:24\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:24\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:24\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:24\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:24\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:24\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:24\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:24\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:22\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:23\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:23\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:22\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:23\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:22\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:21\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:21\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:20\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:20\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:20\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:20\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:20\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:20\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:19\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:19\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:19\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:19\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:20\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:20\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:22\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:23\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.6 MB/s eta 0:06:24\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:25\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:26\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:28\n",
      "     ------------------ --------------------- 1.1/2.5 GB 3.5 MB/s eta 0:06:29\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:34\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:34\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:34\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:34\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:34\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:36\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:37\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:37\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:35\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:33\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:33\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:32\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.5 MB/s eta 0:06:32\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:32\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:32\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:32\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:32\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:32\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:32\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:31\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:31\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:31\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:31\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:29\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:29\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:29\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:30\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:31\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:33\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:35\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:38\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:39\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:40\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:40\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:40\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:40\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:38\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:37\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:37\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:37\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:37\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:38\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:39\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:38\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:37\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:37\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:35\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:33\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:31\n",
      "     ------------------ --------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:29\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:28\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:24\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:23\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:22\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:21\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:19\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:21\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:22\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:30\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:32\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:33\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:33\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:32\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:31\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:30\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:28\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:27\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:24\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:23\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:23\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:22\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:22\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:21\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:19\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:19\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:19\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:20\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:19\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.4 MB/s eta 0:06:21\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:23\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:24\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:28\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:31\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:32\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:34\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:36\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:36\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:37\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:36\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:34\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:35\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:33\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.2 MB/s eta 0:06:31\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:29\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:28\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:29\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:29\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.2/2.5 GB 3.3 MB/s eta 0:06:26\n",
      "     ------------------- -------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:25\n",
      "     ------------------- -------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:23\n",
      "     ------------------- -------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:22\n",
      "     ------------------- -------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:21\n",
      "     ------------------- -------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:21\n",
      "     ------------------- -------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:21\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:20\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:20\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:20\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:20\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:19\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:19\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:19\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:18\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:19\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:18\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:19\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:19\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:20\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:21\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:25\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:25\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:26\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:27\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:26\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:26\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:26\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:25\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:26\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:27\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:27\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:26\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:25\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:23\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:23\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:22\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:23\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:23\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:23\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:23\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:23\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:23\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:23\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:22\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:21\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:20\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:20\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:20\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:19\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:18\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:18\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:18\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:18\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:17\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:17\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:16\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:15\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:15\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:12\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:12\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:15\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:14\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:14\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:14\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:10\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:09\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:09\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:09\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:12\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:13\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:15\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:15\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:11\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.2 MB/s eta 0:06:11\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:09\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:07\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:06\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:06\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:05\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:04\n",
      "     -------------------- ------------------- 1.3/2.5 GB 3.3 MB/s eta 0:06:03\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:02\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:01\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:01\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:01\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:01\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:01\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:00\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:01\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:01\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:01\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:00\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:00\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:06:00\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:59\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:59\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:58\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:58\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:57\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:57\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:56\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:54\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:51\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:50\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:50\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:49\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:48\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:48\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:46\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:47\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:47\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:48\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:46\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:47\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:47\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:47\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:46\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:45\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:46\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:46\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:46\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.4 MB/s eta 0:05:48\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:49\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:48\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:50\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:51\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:52\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:53\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:56\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.3 MB/s eta 0:05:56\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.2 MB/s eta 0:05:59\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.2 MB/s eta 0:06:01\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.2 MB/s eta 0:06:03\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.2 MB/s eta 0:06:03\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.2 MB/s eta 0:06:07\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.1 MB/s eta 0:06:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 3.1 MB/s eta 0:06:11\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.1 MB/s eta 0:06:16\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.1 MB/s eta 0:06:16\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.1 MB/s eta 0:06:21\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:24\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:24\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:28\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:30\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:31\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:32\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:33\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:32\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:31\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:31\n",
      "     --------------------- ------------------ 1.4/2.5 GB 3.0 MB/s eta 0:06:31\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:34\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:34\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:38\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:38\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:39\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:40\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:40\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:41\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:40\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:41\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:41\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:42\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:41\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:43\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.9 MB/s eta 0:06:43\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.8 MB/s eta 0:06:44\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.8 MB/s eta 0:06:46\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.8 MB/s eta 0:06:48\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.8 MB/s eta 0:06:49\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.8 MB/s eta 0:06:52\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.8 MB/s eta 0:06:53\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.8 MB/s eta 0:06:56\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.8 MB/s eta 0:06:57\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.7 MB/s eta 0:06:59\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.7 MB/s eta 0:07:01\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.7 MB/s eta 0:07:04\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.7 MB/s eta 0:07:05\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.7 MB/s eta 0:07:08\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.7 MB/s eta 0:07:12\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.6 MB/s eta 0:07:13\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.6 MB/s eta 0:07:15\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.6 MB/s eta 0:07:17\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.6 MB/s eta 0:07:21\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.6 MB/s eta 0:07:24\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.6 MB/s eta 0:07:27\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.5 MB/s eta 0:07:34\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.5 MB/s eta 0:07:37\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.5 MB/s eta 0:07:40\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.5 MB/s eta 0:07:42\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.5 MB/s eta 0:07:44\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:07:46\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:07:48\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:07:51\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:07:57\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:07:59\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:08:01\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:08:02\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:08:01\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:08:03\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.3 MB/s eta 0:08:06\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.3 MB/s eta 0:08:07\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.3 MB/s eta 0:08:06\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.3 MB/s eta 0:08:05\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.3 MB/s eta 0:08:06\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.3 MB/s eta 0:08:07\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.3 MB/s eta 0:08:08\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.3 MB/s eta 0:08:06\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.3 MB/s eta 0:08:03\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:08:01\n",
      "     --------------------- ------------------ 1.4/2.5 GB 2.4 MB/s eta 0:07:58\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:56\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:57\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:57\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:58\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:08:00\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:59\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:59\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:59\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:59\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:02\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:03\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:05\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:06\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:06\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:07\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:08\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:09\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:11\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:13\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:14\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:16\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:18\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:22\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:25\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:29\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:33\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:36\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:37\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:41\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:45\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:46\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:47\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:49\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:49\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:53\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:51\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:50\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:46\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:44\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:42\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:40\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:40\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:38\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:39\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:39\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:37\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:36\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.1 MB/s eta 0:08:32\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:30\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:29\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:27\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:24\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:23\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:21\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:18\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:17\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:15\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:12\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:09\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.2 MB/s eta 0:08:08\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:08:03\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:07:58\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:07:57\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:07:53\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:07:53\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:07:48\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:07:45\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.3 MB/s eta 0:07:45\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:42\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:42\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:41\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:39\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:38\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:36\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:35\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:35\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:34\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:32\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:31\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:29\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:29\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:30\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:31\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:30\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:30\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:29\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:26\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:24\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:22\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.4 MB/s eta 0:07:21\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:20\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:19\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:17\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:15\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:16\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:15\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:15\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:16\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:14\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:12\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:13\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:13\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:12\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:12\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:11\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:08\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:07\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:06\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:05\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:03\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.5 MB/s eta 0:07:02\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.5 MB/s eta 0:06:59\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.5 MB/s eta 0:06:59\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.6 MB/s eta 0:06:58\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.5 MB/s eta 0:06:59\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.6 MB/s eta 0:06:57\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.6 MB/s eta 0:06:57\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.6 MB/s eta 0:06:56\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.6 MB/s eta 0:06:54\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.6 MB/s eta 0:06:54\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.6 MB/s eta 0:06:55\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.6 MB/s eta 0:06:53\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 2.6 MB/s eta 0:06:53\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:51\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:50\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:50\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:49\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:48\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:47\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:47\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:47\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:45\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:45\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:45\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:45\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:45\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:44\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:45\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:44\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:44\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:43\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:42\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:42\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:44\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:45\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:47\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:47\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:48\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.5 MB/s eta 0:06:49\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.5 MB/s eta 0:06:48\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.5 MB/s eta 0:06:49\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.5 MB/s eta 0:06:49\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.5 MB/s eta 0:06:49\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:47\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:45\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:44\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:42\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:40\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:40\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:38\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:37\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:37\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:35\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:32\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:32\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:31\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:32\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:33\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:35\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:35\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:35\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:35\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:33\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:31\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:30\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:29\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:27\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:26\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:26\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:27\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:29\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:29\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:31\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:31\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:31\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:30\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:29\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:27\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:24\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.6 MB/s eta 0:06:22\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:20\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:19\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:18\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:17\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:16\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:15\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:14\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:13\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:12\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:12\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:08\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:08\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:08\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:10\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:10\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:10\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:11\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:11\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:11\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:10\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:07\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:06\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:06\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:05\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:04\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:04\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:02\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:03\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:02\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:01\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:01\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:00\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:06:00\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:59\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:58\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:57\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:56\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:55\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:54\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:55\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:55\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:54\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:53\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:51\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:49\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:48\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:47\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:47\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:46\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:46\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:46\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:46\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:45\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:45\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:45\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:44\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:44\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:44\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:43\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:43\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:44\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:44\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:44\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:45\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:46\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:48\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:49\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.8 MB/s eta 0:05:51\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:05:52\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:05:52\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:05:53\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:05:53\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:05:53\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:05:52\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:05:52\n",
      "     ------------------------ --------------- 1.5/2.5 GB 2.7 MB/s eta 0:05:51\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:49\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:48\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:46\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:44\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:42\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:41\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:40\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:39\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:38\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:38\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:38\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:38\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:37\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:35\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:34\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:33\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:33\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:32\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:32\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:31\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:30\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:29\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:28\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:26\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:25\n",
      "     ------------------------ --------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:24\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:22\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:20\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:20\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 3.0 MB/s eta 0:05:18\n",
      "     ------------------------- -------------- 1.6/2.5 GB 3.0 MB/s eta 0:05:18\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:20\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:21\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:21\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:20\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:20\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:20\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:25\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:25\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:25\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:24\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:23\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:22\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:21\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:21\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:20\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:20\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:21\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:21\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:23\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.9 MB/s eta 0:05:24\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:25\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:27\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:27\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:27\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:28\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:27\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:27\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:27\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:25\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:25\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:23\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:23\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:23\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:23\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:22\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:22\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:22\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:21\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:22\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:23\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:24\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:24\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:25\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:27\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:27\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:28\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:28\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:28\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:28\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:28\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:34\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:36\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:34\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:32\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:32\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:31\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:31\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:31\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:31\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:31\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:31\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:30\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:30\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:29\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:29\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:29\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:29\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:29\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:30\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:30\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:29\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:29\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:29\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:29\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:28\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:28\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:26\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:24\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:23\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:21\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:18\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:18\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:17\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:18\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:19\n",
      "     ------------------------- -------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:20\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:21\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:21\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:21\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:21\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:22\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:24\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:24\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:23\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:22\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:21\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:19\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:18\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:17\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:18\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:17\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.7 MB/s eta 0:05:16\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:15\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:14\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:13\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:12\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:12\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:11\n",
      "     -------------------------- ------------- 1.6/2.5 GB 2.8 MB/s eta 0:05:11\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:11\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:11\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:11\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:10\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:09\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:08\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:07\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:06\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:05\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:04\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:05:01\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:58\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:57\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:56\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:56\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:56\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:56\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:57\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.8 MB/s eta 0:04:59\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:54\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:54\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:54\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:53\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:51\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:51\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:51\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:52\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:54\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:54\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:53\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:52\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:52\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:50\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:49\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:48\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:46\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:45\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:44\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:45\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:45\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:44\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:43\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:42\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:42\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:41\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:39\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:38\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:37\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:37\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:37\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:38\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:38\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:39\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:39\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:41\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:41\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 2.9 MB/s eta 0:04:39\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:37\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:37\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:35\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:34\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:33\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:33\n",
      "     -------------------------- ------------- 1.7/2.5 GB 3.0 MB/s eta 0:04:32\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:30\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:28\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:27\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:26\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:23\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:22\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:21\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:20\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:20\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:19\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:19\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:19\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:21\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:21\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:21\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:21\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:20\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:20\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:19\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:20\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:19\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:19\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:19\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:19\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:18\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:18\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:17\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:16\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:15\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:14\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:14\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:13\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:13\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:15\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:15\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:15\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:15\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:15\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:15\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:16\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:15\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:15\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:16\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:16\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:16\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:18\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:18\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:18\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:18\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.1 MB/s eta 0:04:18\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:19\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:20\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:20\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:21\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:22\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:20\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:21\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:22\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:23\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:23\n",
      "     --------------------------- ------------ 1.7/2.5 GB 3.0 MB/s eta 0:04:26\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.9 MB/s eta 0:04:28\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.9 MB/s eta 0:04:28\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.9 MB/s eta 0:04:30\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.9 MB/s eta 0:04:32\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.9 MB/s eta 0:04:34\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.8 MB/s eta 0:04:36\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.8 MB/s eta 0:04:37\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.8 MB/s eta 0:04:39\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.8 MB/s eta 0:04:39\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.8 MB/s eta 0:04:40\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.8 MB/s eta 0:04:41\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.8 MB/s eta 0:04:42\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.8 MB/s eta 0:04:43\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.7 MB/s eta 0:04:44\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.7 MB/s eta 0:04:46\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.7 MB/s eta 0:04:47\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.7 MB/s eta 0:04:48\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.7 MB/s eta 0:04:51\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.7 MB/s eta 0:04:52\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:54\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:56\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:58\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:05:00\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:05:01\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:05:03\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:05\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:07\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:08\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:08\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:06\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:06\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:06\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:07\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:06\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:07\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:07\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:06\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.5 MB/s eta 0:05:05\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:05:01\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:59\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:58\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:56\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:56\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:55\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:56\n",
      "     --------------------------- ------------ 1.7/2.5 GB 2.6 MB/s eta 0:04:55\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:54\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:54\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:54\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:54\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:53\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:52\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:51\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:51\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:51\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:52\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:53\n",
      "     --------------------------- ------------ 1.8/2.5 GB 2.6 MB/s eta 0:04:54\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:55\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:55\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:55\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:54\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:53\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:52\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:51\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:48\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:47\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:47\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:47\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:47\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:47\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:48\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:48\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:48\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:48\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:49\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:49\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:49\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:48\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:49\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:52\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:53\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:53\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:54\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:53\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:56\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:57\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:57\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:57\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:56\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:56\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:54\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:53\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:53\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:53\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:54\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:54\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:54\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:53\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:53\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:51\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:50\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:50\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:50\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:49\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:50\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:51\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:51\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:51\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:51\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:52\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:49\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:47\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:46\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:45\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:44\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:44\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:43\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:43\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:42\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:41\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.5 MB/s eta 0:04:41\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:40\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:38\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:37\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:36\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:34\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:33\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:31\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:30\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:30\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:28\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:27\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:27\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:28\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.6 MB/s eta 0:04:27\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:26\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:26\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:24\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:23\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:21\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:19\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:19\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:18\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:17\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:16\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:16\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:16\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:16\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:16\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:16\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:17\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:17\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:16\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.7 MB/s eta 0:04:15\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.8 MB/s eta 0:04:13\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.8 MB/s eta 0:04:12\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.8 MB/s eta 0:04:12\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.8 MB/s eta 0:04:11\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.8 MB/s eta 0:04:10\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.8 MB/s eta 0:04:09\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 2.8 MB/s eta 0:04:08\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.8 MB/s eta 0:04:05\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.8 MB/s eta 0:04:05\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.8 MB/s eta 0:04:03\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:04:02\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:04:00\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:59\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:59\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:58\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:57\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:56\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:55\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:55\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:54\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:54\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:53\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:53\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:52\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:51\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:52\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:51\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:52\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:53\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:54\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:55\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:54\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:54\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:55\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:55\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:54\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:54\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:54\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:53\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:53\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:52\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:50\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:48\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:47\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:47\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:49\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:48\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:48\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:49\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 2.9 MB/s eta 0:03:49\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:49\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:48\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:48\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:48\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:48\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:45\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:45\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:43\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:42\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:42\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:41\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:40\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:38\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:38\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:35\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:33\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:33\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.1 MB/s eta 0:03:32\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:32\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:33\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:33\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:37\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:37\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 3.0 MB/s eta 0:03:37\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:38\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:40\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:38\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:40\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:39\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:38\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:38\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 2.9 MB/s eta 0:03:36\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:35\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:35\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 3.0 MB/s eta 0:03:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.9 MB/s eta 0:03:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.8 MB/s eta 0:03:35\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.8 MB/s eta 0:03:36\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.8 MB/s eta 0:03:36\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.8 MB/s eta 0:03:37\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.8 MB/s eta 0:03:39\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.8 MB/s eta 0:03:39\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.8 MB/s eta 0:03:40\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.8 MB/s eta 0:03:40\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.8 MB/s eta 0:03:41\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:41\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:42\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:42\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:42\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:42\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:44\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:44\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:44\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:46\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:46\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:47\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.7 MB/s eta 0:03:47\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:50\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:51\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:52\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:52\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:53\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:53\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:52\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:53\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:52\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:52\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.6 MB/s eta 0:03:54\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.5 MB/s eta 0:03:55\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.2 MB/s eta 0:04:37\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:38\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.2 MB/s eta 0:04:37\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.2 MB/s eta 0:04:36\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.2 MB/s eta 0:04:35\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.2 MB/s eta 0:04:35\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:36\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:37\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:38\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:38\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:39\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:40\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:41\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:42\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:43\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:44\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:45\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:45\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:46\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:46\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:45\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:44\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:44\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:43\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:41\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:40\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:38\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:37\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:36\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:31\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:30\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:30\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:31\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:35\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.1 MB/s eta 0:04:36\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.0 MB/s eta 0:04:37\n",
      "     ------------------------------ --------- 1.9/2.5 GB 2.0 MB/s eta 0:04:38\n",
      "     ------------------------------- -------- 1.9/2.5 GB 2.0 MB/s eta 0:04:39\n",
      "     ------------------------------- -------- 1.9/2.5 GB 2.0 MB/s eta 0:04:41\n",
      "     ------------------------------- -------- 1.9/2.5 GB 2.0 MB/s eta 0:04:42\n",
      "     ------------------------------- -------- 1.9/2.5 GB 2.0 MB/s eta 0:04:42\n",
      "     ------------------------------- -------- 1.9/2.5 GB 2.0 MB/s eta 0:04:40\n",
      "     ------------------------------- -------- 1.9/2.5 GB 2.0 MB/s eta 0:04:39\n",
      "     ------------------------------- -------- 1.9/2.5 GB 2.0 MB/s eta 0:04:39\n",
      "     ------------------------------- -------- 1.9/2.5 GB 2.0 MB/s eta 0:04:38\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:38\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:38\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:38\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:39\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:39\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:38\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:39\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:39\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:36\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:35\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:35\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:35\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:34\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:33\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:32\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:31\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.0 MB/s eta 0:04:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:29\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:28\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:25\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:24\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:24\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:23\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:22\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:22\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:21\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:20\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:15\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:15\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:18\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:16\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:16\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:17\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:15\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:14\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:14\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:15\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:13\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:12\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:11\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:11\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.2 MB/s eta 0:04:10\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:10\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.1 MB/s eta 0:04:10\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.2 MB/s eta 0:04:07\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.2 MB/s eta 0:04:05\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.2 MB/s eta 0:04:06\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.2 MB/s eta 0:04:03\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.2 MB/s eta 0:04:02\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.2 MB/s eta 0:04:02\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:34\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:34\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:34\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:35\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:35\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:34\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:34\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:33\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:33\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:32\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:32\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:31\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:29\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:29\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:29\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:28\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:28\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:28\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:28\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:28\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:29\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:29\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.4 MB/s eta 0:03:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.4 MB/s eta 0:03:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.4 MB/s eta 0:03:29\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:29\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:27\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:26\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:26\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:24\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:24\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:23\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:22\n",
      "     ------------------------------- -------- 2.0/2.5 GB 2.5 MB/s eta 0:03:23\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:23\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:22\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:21\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:20\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:19\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:19\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:19\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:19\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:19\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:18\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:18\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:18\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:17\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:17\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:16\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:16\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:15\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:15\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:14\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:14\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:16\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:16\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:16\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:15\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:14\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:14\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:13\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:13\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:13\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:13\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:13\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:14\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:15\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:15\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:15\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:15\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:15\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:15\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:14\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:14\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:14\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:13\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:13\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:13\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:12\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:11\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:11\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:11\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:11\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:11\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:10\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:08\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:08\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:07\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:06\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:04\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.5 MB/s eta 0:03:03\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:03:03\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:03:02\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:03:01\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:03:01\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:03:00\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:03:00\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:02:59\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:03:00\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:02:59\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:02:59\n",
      "     -------------------------------- ------- 2.0/2.5 GB 2.6 MB/s eta 0:03:00\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:03:00\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:03:00\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:03:00\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:59\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:59\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:59\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:59\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:58\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:58\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:58\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:58\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:57\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:57\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:57\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:57\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:57\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:56\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:56\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:55\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:54\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:53\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:53\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:52\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:52\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:52\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:52\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:52\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:51\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:51\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:50\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:50\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:49\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:49\n",
      "     -------------------------------- ------- 2.1/2.5 GB 2.6 MB/s eta 0:02:50\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:50\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:50\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:49\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:49\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:48\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:47\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:46\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:45\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:45\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:44\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:44\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:45\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:45\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:46\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:47\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:47\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:46\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:46\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:46\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:45\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:45\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:44\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:43\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:42\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:41\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:41\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:41\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:40\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:40\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:40\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:40\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:39\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:39\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:39\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:38\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:38\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:38\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:37\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:36\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.6 MB/s eta 0:02:34\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:34\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:33\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:33\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:32\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:32\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:32\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:31\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:31\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:30\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:30\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:29\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:28\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:28\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:28\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:28\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:27\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:27\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:27\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:25\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:25\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:25\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:25\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:24\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:24\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:24\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:25\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:25\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:25\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:25\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:24\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:24\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:24\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:24\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:23\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:23\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:23\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:22\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:21\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:20\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:20\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:20\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:20\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:19\n",
      "     --------------------------------- ------ 2.1/2.5 GB 2.7 MB/s eta 0:02:19\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.7 MB/s eta 0:02:19\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.7 MB/s eta 0:02:19\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.7 MB/s eta 0:02:19\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.7 MB/s eta 0:02:20\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.7 MB/s eta 0:02:20\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.7 MB/s eta 0:02:21\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.7 MB/s eta 0:02:21\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.7 MB/s eta 0:02:21\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.6 MB/s eta 0:02:21\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.7 MB/s eta 0:02:21\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.6 MB/s eta 0:02:21\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.6 MB/s eta 0:02:21\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.6 MB/s eta 0:02:21\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.6 MB/s eta 0:02:23\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.6 MB/s eta 0:02:23\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.6 MB/s eta 0:02:24\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.6 MB/s eta 0:02:25\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.6 MB/s eta 0:02:26\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.5 MB/s eta 0:02:27\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.5 MB/s eta 0:02:27\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.5 MB/s eta 0:02:28\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.5 MB/s eta 0:02:28\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.5 MB/s eta 0:02:28\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.5 MB/s eta 0:02:29\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.5 MB/s eta 0:02:29\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.5 MB/s eta 0:02:30\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:31\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:31\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:31\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:32\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:32\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:33\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:33\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:33\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:34\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:34\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:35\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.4 MB/s eta 0:02:35\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.3 MB/s eta 0:02:36\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.3 MB/s eta 0:02:36\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.3 MB/s eta 0:02:37\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.3 MB/s eta 0:02:37\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.3 MB/s eta 0:02:38\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.3 MB/s eta 0:02:38\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.3 MB/s eta 0:02:39\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.3 MB/s eta 0:02:39\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.3 MB/s eta 0:02:41\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:42\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:43\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:43\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:43\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:43\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:43\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:45\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:45\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:45\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:45\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 2.2 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.2 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 2.1 MB/s eta 0:02:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.8 MB/s eta 0:03:18\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.8 MB/s eta 0:03:19\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.8 MB/s eta 0:03:21\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.8 MB/s eta 0:03:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.8 MB/s eta 0:03:23\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.8 MB/s eta 0:03:25\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.7 MB/s eta 0:03:26\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.7 MB/s eta 0:03:28\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.7 MB/s eta 0:03:28\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.7 MB/s eta 0:03:30\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.7 MB/s eta 0:03:33\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.7 MB/s eta 0:03:34\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.7 MB/s eta 0:03:35\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.7 MB/s eta 0:03:36\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.6 MB/s eta 0:03:37\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.6 MB/s eta 0:03:38\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.6 MB/s eta 0:03:38\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.6 MB/s eta 0:03:38\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.6 MB/s eta 0:03:38\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.6 MB/s eta 0:03:38\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:51\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:51\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:59\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:58\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:04:00\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:04:00\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:04:01\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:04:01\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:04:02\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:04:04\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:04:03\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:04:03\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:04:02\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:04:00\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:04:00\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:58\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:57\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.5 MB/s eta 0:03:55\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:56\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:54\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:54\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:55\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:55\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:58\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:58\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:58\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:58\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:58\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:16\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:16\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:16\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:31\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:31\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:31\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:34\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:33\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:30\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:29\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:26\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:25\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:20\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:18\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:16\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:16\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:15\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:15\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:51\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:51\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:50\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:50\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:50\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:50\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:49\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.1 MB/s eta 0:04:48\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:25\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:25\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:23\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:23\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:34\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:34\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:33\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:32\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:31\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:28\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:26\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:24\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:21\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.2 MB/s eta 0:04:18\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:15\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:11\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:08\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:04\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.3 MB/s eta 0:04:01\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:51\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:46\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 1.4 MB/s eta 0:03:44\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.4 MB/s eta 0:03:41\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.4 MB/s eta 0:03:40\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:35\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:33\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:32\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:32\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:31\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:31\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:29\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:27\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:25\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:23\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:20\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:18\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:16\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:13\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:11\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:10\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:09\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:08\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:07\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:06\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:05\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:04\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:04\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:04\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:04\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:04\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:04\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:16\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:14\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:16\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:16\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:14\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.5 MB/s eta 0:03:12\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:05\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:04\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:03:00\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:02:59\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.6 MB/s eta 0:02:56\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.7 MB/s eta 0:02:54\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.7 MB/s eta 0:02:50\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.7 MB/s eta 0:02:49\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.7 MB/s eta 0:02:48\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:43\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:42\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:42\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:41\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:39\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:39\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:39\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:39\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:39\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:39\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:38\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:37\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:36\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:35\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:34\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:33\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:32\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:32\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:32\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:32\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.8 MB/s eta 0:02:35\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.9 MB/s eta 0:02:28\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.9 MB/s eta 0:02:27\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.9 MB/s eta 0:02:26\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.9 MB/s eta 0:02:25\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.9 MB/s eta 0:02:24\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.9 MB/s eta 0:02:21\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 1.9 MB/s eta 0:02:21\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:04\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:02\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:02\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:02\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:01\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:01\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:01\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:00\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:00\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:00\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:00\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:02:00\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:01:59\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:01:59\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:01:59\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:01:58\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 2.2 MB/s eta 0:01:58\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.3 MB/s eta 0:01:54\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.3 MB/s eta 0:01:54\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.3 MB/s eta 0:01:53\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.3 MB/s eta 0:01:52\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.3 MB/s eta 0:01:51\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.3 MB/s eta 0:01:50\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.4 MB/s eta 0:01:45\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.4 MB/s eta 0:01:45\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.4 MB/s eta 0:01:45\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.4 MB/s eta 0:01:45\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.4 MB/s eta 0:01:45\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.4 MB/s eta 0:01:45\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.4 MB/s eta 0:01:45\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.4 MB/s eta 0:01:47\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.4 MB/s eta 0:01:46\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.5 MB/s eta 0:01:40\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 2.5 MB/s eta 0:01:39\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:39\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:38\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:35\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:34\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:33\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.7 MB/s eta 0:01:33\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.7 MB/s eta 0:01:32\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.7 MB/s eta 0:01:31\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.7 MB/s eta 0:01:31\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.7 MB/s eta 0:01:31\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:33\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:33\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:33\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:33\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:33\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:34\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:34\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.6 MB/s eta 0:01:35\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:35\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:40\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:40\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:40\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:40\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:41\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:41\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:41\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:41\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:41\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:41\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:37\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:36\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:35\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:35\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:34\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:34\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:34\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:33\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:33\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:32\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:32\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:31\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:31\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:31\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:30\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:30\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:29\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:28\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:27\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:27\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:28\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:27\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:26\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:26\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:25\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:22\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:22\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:22\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:22\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.5 MB/s eta 0:01:21\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:25\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.4 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:23\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------ --- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:24\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:23\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:20\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:20\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:20\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:20\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:21\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:21\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:21\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:21\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:21\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:21\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:20\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:19\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.2 MB/s eta 0:01:18\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:17\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:17\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:16\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:16\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:15\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:14\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:14\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:13\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:13\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.3 MB/s eta 0:01:12\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:11\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:11\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:11\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:10\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:10\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:10\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:10\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:08\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:08\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:07\n",
      "     ------------------------------------- -- 2.3/2.5 GB 2.4 MB/s eta 0:01:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.4 MB/s eta 0:01:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.4 MB/s eta 0:01:05\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:05\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:05\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:04\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:04\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:03\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:03\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:02\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:02\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:02\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:01\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:00\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:00\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:00\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:00\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:00\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:01\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:00\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:00\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:00\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:01:00\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:59\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:59\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:58\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:58\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:57\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:57\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:57\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:56\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:56\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:56\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:56\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:56\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:56\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:55\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:55\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:55\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:54\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:54\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:54\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:53\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:53\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:52\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:52\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:52\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:52\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.6 MB/s eta 0:00:51\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:51\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.6 MB/s eta 0:00:50\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.5 MB/s eta 0:00:50\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.6 MB/s eta 0:00:49\n",
      "     ------------------------------------- -- 2.4/2.5 GB 2.6 MB/s eta 0:00:49\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.6 MB/s eta 0:00:49\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.6 MB/s eta 0:00:49\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.6 MB/s eta 0:00:49\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.6 MB/s eta 0:00:48\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.7 MB/s eta 0:00:47\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.7 MB/s eta 0:00:47\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.7 MB/s eta 0:00:46\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.7 MB/s eta 0:00:46\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.7 MB/s eta 0:00:45\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.7 MB/s eta 0:00:44\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.7 MB/s eta 0:00:44\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.8 MB/s eta 0:00:43\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.8 MB/s eta 0:00:43\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.8 MB/s eta 0:00:42\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.8 MB/s eta 0:00:42\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.8 MB/s eta 0:00:41\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.8 MB/s eta 0:00:41\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.8 MB/s eta 0:00:40\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.8 MB/s eta 0:00:40\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:39\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:39\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:38\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:38\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:37\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:37\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:37\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:36\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:36\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:36\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:36\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:35\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:35\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:34\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:34\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:34\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:34\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:33\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:33\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:33\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:33\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:33\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:32\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:32\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:32\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:32\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:31\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:31\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:31\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:30\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:30\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:29\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:29\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:29\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:29\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:28\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:28\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:28\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:27\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:27\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:27\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:26\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:26\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:26\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.2 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.1 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:25\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:24\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:23\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:23\n",
      "     -------------------------------------- - 2.4/2.5 GB 2.9 MB/s eta 0:00:23\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:22\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:22\n",
      "     -------------------------------------- - 2.4/2.5 GB 3.0 MB/s eta 0:00:22\n",
      "     ---------------------------------------  2.4/2.5 GB 3.0 MB/s eta 0:00:22\n",
      "     ---------------------------------------  2.4/2.5 GB 3.0 MB/s eta 0:00:21\n",
      "     ---------------------------------------  2.4/2.5 GB 3.0 MB/s eta 0:00:21\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:20\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:20\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:20\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:19\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:19\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:19\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:18\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:18\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:18\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:18\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:17\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:17\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:17\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:16\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:16\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:16\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:16\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:15\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:15\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:15\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:15\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:14\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:13\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:13\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:13\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:13\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:12\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:12\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:12\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:11\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:11\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:11\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:11\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:10\n",
      "     ---------------------------------------  2.5/2.5 GB 3.1 MB/s eta 0:00:10\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:10\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:10\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:10\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:10\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:10\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:09\n",
      "     ---------------------------------------  2.5/2.5 GB 3.0 MB/s eta 0:00:09\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:09\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:09\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:09\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:09\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:09\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:09\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:09\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:08\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:08\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:08\n",
      "     ---------------------------------------  2.5/2.5 GB 2.9 MB/s eta 0:00:08\n",
      "     ---------------------------------------  2.5/2.5 GB 2.8 MB/s eta 0:00:08\n",
      "     ---------------------------------------  2.5/2.5 GB 2.8 MB/s eta 0:00:08\n",
      "     ---------------------------------------  2.5/2.5 GB 2.8 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.8 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.8 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.8 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.8 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.8 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:07\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.7 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.6 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.6 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.6 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.6 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.4 MB/s eta 0:00:06\n",
      "     ---------------------------------------  2.5/2.5 GB 2.4 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.4 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.4 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.4 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.4 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:04\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:04\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:04\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:04\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:04\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:04\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:04\n",
      "     ---------------------------------------  2.5/2.5 GB 2.2 MB/s eta 0:00:04\n",
      "     ---------------------------------------  2.5/2.5 GB 2.2 MB/s eta 0:00:04\n",
      "     ---------------------------------------  2.5/2.5 GB 2.2 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.5/2.5 GB 2.2 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.5/2.5 GB 2.2 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.5/2.5 GB 2.2 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.5/2.5 GB 2.2 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 GB 1.5 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.20.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-win_amd64.whl (6.1 MB)\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/6.1 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/6.1 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/6.1 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     --- ------------------------------------ 0.5/6.1 MB 349.5 kB/s eta 0:00:17\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ----- ---------------------------------- 0.8/6.1 MB 166.1 kB/s eta 0:00:33\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     ------ --------------------------------- 1.0/6.1 MB 133.9 kB/s eta 0:00:39\n",
      "     -------- ------------------------------- 1.3/6.1 MB 133.2 kB/s eta 0:00:37\n",
      "     -------- ------------------------------- 1.3/6.1 MB 133.2 kB/s eta 0:00:37\n",
      "     -------- ------------------------------- 1.3/6.1 MB 133.2 kB/s eta 0:00:37\n",
      "     -------- ------------------------------- 1.3/6.1 MB 133.2 kB/s eta 0:00:37\n",
      "     -------- ------------------------------- 1.3/6.1 MB 133.2 kB/s eta 0:00:37\n",
      "     -------- ------------------------------- 1.3/6.1 MB 133.2 kB/s eta 0:00:37\n",
      "     -------- ------------------------------- 1.3/6.1 MB 133.2 kB/s eta 0:00:37\n",
      "     -------- ------------------------------- 1.3/6.1 MB 133.2 kB/s eta 0:00:37\n",
      "     -------- ------------------------------- 1.3/6.1 MB 133.2 kB/s eta 0:00:37\n",
      "     ---------- ----------------------------- 1.6/6.1 MB 132.5 kB/s eta 0:00:35\n",
      "     ---------- ----------------------------- 1.6/6.1 MB 132.5 kB/s eta 0:00:35\n",
      "     ---------- ----------------------------- 1.6/6.1 MB 132.5 kB/s eta 0:00:35\n",
      "     ---------- ----------------------------- 1.6/6.1 MB 132.5 kB/s eta 0:00:35\n",
      "     ---------- ----------------------------- 1.6/6.1 MB 132.5 kB/s eta 0:00:35\n",
      "     ----------- ---------------------------- 1.8/6.1 MB 145.7 kB/s eta 0:00:30\n",
      "     ----------- ---------------------------- 1.8/6.1 MB 145.7 kB/s eta 0:00:30\n",
      "     ----------- ---------------------------- 1.8/6.1 MB 145.7 kB/s eta 0:00:30\n",
      "     ----------- ---------------------------- 1.8/6.1 MB 145.7 kB/s eta 0:00:30\n",
      "     ----------- ---------------------------- 1.8/6.1 MB 145.7 kB/s eta 0:00:30\n",
      "     ----------- ---------------------------- 1.8/6.1 MB 145.7 kB/s eta 0:00:30\n",
      "     ----------- ---------------------------- 1.8/6.1 MB 145.7 kB/s eta 0:00:30\n",
      "     ----------- ---------------------------- 1.8/6.1 MB 145.7 kB/s eta 0:00:30\n",
      "     ------------- -------------------------- 2.1/6.1 MB 147.2 kB/s eta 0:00:28\n",
      "     ------------- -------------------------- 2.1/6.1 MB 147.2 kB/s eta 0:00:28\n",
      "     ------------- -------------------------- 2.1/6.1 MB 147.2 kB/s eta 0:00:28\n",
      "     ------------- -------------------------- 2.1/6.1 MB 147.2 kB/s eta 0:00:28\n",
      "     --------------- ------------------------ 2.4/6.1 MB 156.8 kB/s eta 0:00:25\n",
      "     --------------- ------------------------ 2.4/6.1 MB 156.8 kB/s eta 0:00:25\n",
      "     --------------- ------------------------ 2.4/6.1 MB 156.8 kB/s eta 0:00:25\n",
      "     ----------------- ---------------------- 2.6/6.1 MB 167.4 kB/s eta 0:00:22\n",
      "     ----------------- ---------------------- 2.6/6.1 MB 167.4 kB/s eta 0:00:22\n",
      "     ----------------- ---------------------- 2.6/6.1 MB 167.4 kB/s eta 0:00:22\n",
      "     ------------------ --------------------- 2.9/6.1 MB 177.9 kB/s eta 0:00:19\n",
      "     ------------------ --------------------- 2.9/6.1 MB 177.9 kB/s eta 0:00:19\n",
      "     ------------------ --------------------- 2.9/6.1 MB 177.9 kB/s eta 0:00:19\n",
      "     ------------------ --------------------- 2.9/6.1 MB 177.9 kB/s eta 0:00:19\n",
      "     -------------------- ------------------- 3.1/6.1 MB 186.4 kB/s eta 0:00:17\n",
      "     -------------------- ------------------- 3.1/6.1 MB 186.4 kB/s eta 0:00:17\n",
      "     ---------------------- ----------------- 3.4/6.1 MB 198.0 kB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 3.4/6.1 MB 198.0 kB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 3.4/6.1 MB 198.0 kB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 3.7/6.1 MB 205.4 kB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 3.7/6.1 MB 205.4 kB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 3.7/6.1 MB 205.4 kB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 3.7/6.1 MB 205.4 kB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 3.7/6.1 MB 205.4 kB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 3.7/6.1 MB 205.4 kB/s eta 0:00:13\n",
      "     ------------------------- -------------- 3.9/6.1 MB 206.8 kB/s eta 0:00:11\n",
      "     ------------------------- -------------- 3.9/6.1 MB 206.8 kB/s eta 0:00:11\n",
      "     ------------------------- -------------- 3.9/6.1 MB 206.8 kB/s eta 0:00:11\n",
      "     --------------------------- ------------ 4.2/6.1 MB 211.8 kB/s eta 0:00:10\n",
      "     --------------------------- ------------ 4.2/6.1 MB 211.8 kB/s eta 0:00:10\n",
      "     --------------------------- ------------ 4.2/6.1 MB 211.8 kB/s eta 0:00:10\n",
      "     ----------------------------- ---------- 4.5/6.1 MB 220.4 kB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 4.5/6.1 MB 220.4 kB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 4.5/6.1 MB 220.4 kB/s eta 0:00:08\n",
      "     ------------------------------ --------- 4.7/6.1 MB 226.2 kB/s eta 0:00:07\n",
      "     ------------------------------ --------- 4.7/6.1 MB 226.2 kB/s eta 0:00:07\n",
      "     -------------------------------- ------- 5.0/6.1 MB 233.6 kB/s eta 0:00:05\n",
      "     -------------------------------- ------- 5.0/6.1 MB 233.6 kB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 5.2/6.1 MB 243.2 kB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 5.5/6.1 MB 252.7 kB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 5.5/6.1 MB 252.7 kB/s eta 0:00:03\n",
      "     ------------------------------------- -- 5.8/6.1 MB 260.2 kB/s eta 0:00:02\n",
      "     ------------------------------------- -- 5.8/6.1 MB 260.2 kB/s eta 0:00:02\n",
      "     ------------------------------------- -- 5.8/6.1 MB 260.2 kB/s eta 0:00:02\n",
      "     ------------------------------------- -- 5.8/6.1 MB 260.2 kB/s eta 0:00:02\n",
      "     ------------------------------------- -- 5.8/6.1 MB 260.2 kB/s eta 0:00:02\n",
      "     ------------------------------------- -- 5.8/6.1 MB 260.2 kB/s eta 0:00:02\n",
      "     ------------------------------------- -- 5.8/6.1 MB 260.2 kB/s eta 0:00:02\n",
      "     ---------------------------------------  6.0/6.1 MB 254.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------  6.0/6.1 MB 254.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------  6.0/6.1 MB 254.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------  6.0/6.1 MB 254.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.1/6.1 MB 248.8 kB/s eta 0:00:00\n",
      "Collecting torchaudio==2.5.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.5/4.1 MB 143.4 kB/s eta 0:00:26\n",
      "     ----- ---------------------------------- 0.5/4.1 MB 143.4 kB/s eta 0:00:26\n",
      "     ----- ---------------------------------- 0.5/4.1 MB 143.4 kB/s eta 0:00:26\n",
      "     ------- -------------------------------- 0.8/4.1 MB 217.9 kB/s eta 0:00:16\n",
      "     ------- -------------------------------- 0.8/4.1 MB 217.9 kB/s eta 0:00:16\n",
      "     ---------- ----------------------------- 1.0/4.1 MB 279.7 kB/s eta 0:00:12\n",
      "     ---------- ----------------------------- 1.0/4.1 MB 279.7 kB/s eta 0:00:12\n",
      "     ------------ --------------------------- 1.3/4.1 MB 324.2 kB/s eta 0:00:09\n",
      "     ------------ --------------------------- 1.3/4.1 MB 324.2 kB/s eta 0:00:09\n",
      "     --------------- ------------------------ 1.6/4.1 MB 351.0 kB/s eta 0:00:08\n",
      "     --------------- ------------------------ 1.6/4.1 MB 351.0 kB/s eta 0:00:08\n",
      "     --------------- ------------------------ 1.6/4.1 MB 351.0 kB/s eta 0:00:08\n",
      "     ----------------- ---------------------- 1.8/4.1 MB 353.2 kB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 1.8/4.1 MB 353.2 kB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 1.8/4.1 MB 353.2 kB/s eta 0:00:07\n",
      "     -------------------- ------------------- 2.1/4.1 MB 364.7 kB/s eta 0:00:06\n",
      "     -------------------- ------------------- 2.1/4.1 MB 364.7 kB/s eta 0:00:06\n",
      "     -------------------- ------------------- 2.1/4.1 MB 364.7 kB/s eta 0:00:06\n",
      "     -------------------- ------------------- 2.1/4.1 MB 364.7 kB/s eta 0:00:06\n",
      "     -------------------- ------------------- 2.1/4.1 MB 364.7 kB/s eta 0:00:06\n",
      "     -------------------- ------------------- 2.1/4.1 MB 364.7 kB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 2.4/4.1 MB 338.1 kB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 2.4/4.1 MB 338.1 kB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 2.4/4.1 MB 338.1 kB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 2.4/4.1 MB 338.1 kB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 2.4/4.1 MB 338.1 kB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 2.4/4.1 MB 338.1 kB/s eta 0:00:06\n",
      "     --------------------------- ------------ 2.9/4.1 MB 343.1 kB/s eta 0:00:04\n",
      "     ------------------------------ --------- 3.1/4.1 MB 368.4 kB/s eta 0:00:03\n",
      "     ------------------------------ --------- 3.1/4.1 MB 368.4 kB/s eta 0:00:03\n",
      "     ------------------------------ --------- 3.1/4.1 MB 368.4 kB/s eta 0:00:03\n",
      "     ------------------------------ --------- 3.1/4.1 MB 368.4 kB/s eta 0:00:03\n",
      "     ------------------------------ --------- 3.1/4.1 MB 368.4 kB/s eta 0:00:03\n",
      "     -------------------------------- ------- 3.4/4.1 MB 360.8 kB/s eta 0:00:03\n",
      "     -------------------------------- ------- 3.4/4.1 MB 360.8 kB/s eta 0:00:03\n",
      "     -------------------------------- ------- 3.4/4.1 MB 360.8 kB/s eta 0:00:03\n",
      "     -------------------------------- ------- 3.4/4.1 MB 360.8 kB/s eta 0:00:03\n",
      "     -------------------------------- ------- 3.4/4.1 MB 360.8 kB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 3.7/4.1 MB 345.7 kB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 3.7/4.1 MB 345.7 kB/s eta 0:00:02\n",
      "     ------------------------------------- -- 3.9/4.1 MB 355.9 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 3.9/4.1 MB 355.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.1/4.1 MB 359.5 kB/s eta 0:00:00\n",
      "Collecting filelock (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting numpy (from torchvision==0.20.1)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.20.1)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "     -----------------------------------  524.3/536.2 kB 882.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 536.2/536.2 kB 878.4 kB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.5.1)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.6 MB 113.3 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 0.5/2.6 MB 113.3 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 0.5/2.6 MB 113.3 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 0.5/2.6 MB 113.3 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 0.5/2.6 MB 113.3 kB/s eta 0:00:19\n",
      "   ------------ --------------------------- 0.8/2.6 MB 159.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 0.8/2.6 MB 159.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 0.8/2.6 MB 159.8 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 0.8/2.6 MB 159.8 kB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 189.2 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 189.2 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 189.2 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 189.2 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 189.2 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 189.2 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 189.2 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 189.2 kB/s eta 0:00:09\n",
      "   -------------------- ------------------- 1.3/2.6 MB 177.5 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 1.3/2.6 MB 177.5 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 1.3/2.6 MB 177.5 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 1.6/2.6 MB 204.1 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 1.6/2.6 MB 204.1 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 1.6/2.6 MB 204.1 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 1.6/2.6 MB 204.1 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 215.5 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 215.5 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 2.1/2.6 MB 233.0 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 2.1/2.6 MB 233.0 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 2.1/2.6 MB 233.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 2.4/2.6 MB 249.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.4/2.6 MB 249.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 262.0 kB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 322.8 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.5/1.7 MB 322.8 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.5/1.7 MB 322.8 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 0.8/1.7 MB 360.8 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 360.8 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 360.8 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 1.0/1.7 MB 354.6 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 430.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 539.2 kB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.9 MB 1.6 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/12.9 MB 1.6 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 1.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.1/12.9 MB 504.0 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 2.4/12.9 MB 526.4 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 2.4/12.9 MB 526.4 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 2.4/12.9 MB 526.4 kB/s eta 0:00:20\n",
      "   -------- ------------------------------- 2.6/12.9 MB 522.4 kB/s eta 0:00:20\n",
      "   -------- ------------------------------- 2.6/12.9 MB 522.4 kB/s eta 0:00:20\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.9 MB 573.2 kB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 411.7 kB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 411.7 kB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 3.7/12.9 MB 430.2 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.9/12.9 MB 446.5 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 4.2/12.9 MB 466.9 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 4.2/12.9 MB 466.9 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 4.2/12.9 MB 466.9 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 4.2/12.9 MB 466.9 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 4.2/12.9 MB 466.9 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 4.2/12.9 MB 466.9 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 4.2/12.9 MB 466.9 kB/s eta 0:00:19\n",
      "   ------------- -------------------------- 4.5/12.9 MB 426.1 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 4.5/12.9 MB 426.1 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 4.5/12.9 MB 426.1 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 4.5/12.9 MB 426.1 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 4.5/12.9 MB 426.1 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 4.7/12.9 MB 410.4 kB/s eta 0:00:20\n",
      "   --------------- ------------------------ 5.0/12.9 MB 427.1 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 5.0/12.9 MB 427.1 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 5.0/12.9 MB 427.1 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 421.7 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 5.5/12.9 MB 377.0 kB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 5.8/12.9 MB 390.2 kB/s eta 0:00:19\n",
      "   ------------------- -------------------- 6.3/12.9 MB 419.0 kB/s eta 0:00:16\n",
      "   --------------------- ------------------ 6.8/12.9 MB 448.1 kB/s eta 0:00:14\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   --------------------- ------------------ 7.1/12.9 MB 462.1 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 416.3 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 383.8 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 7.9/12.9 MB 346.0 kB/s eta 0:00:15\n",
      "   ------------------------- -------------- 8.1/12.9 MB 353.7 kB/s eta 0:00:14\n",
      "   -------------------------- ------------- 8.4/12.9 MB 362.4 kB/s eta 0:00:13\n",
      "   --------------------------- ------------ 8.9/12.9 MB 380.5 kB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 399.5 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 10.0/12.9 MB 418.6 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 10.5/12.9 MB 438.3 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 10.7/12.9 MB 447.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.7/12.9 MB 447.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.7/12.9 MB 447.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.7/12.9 MB 447.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.7/12.9 MB 447.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.7/12.9 MB 447.7 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 11.3/12.9 MB 442.6 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 12.1/12.9 MB 470.1 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 12.9/12.9 MB 497.8 kB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 pillow-11.0.0 sympy-1.13.1 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages for torch-2.5.1+cu124...\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
      "Collecting pyg_lib\n",
      "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/pyg_lib-0.4.0%2Bpt25cu124-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------------ --------------------------- 0.5/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 0.8/1.7 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.0/1.7 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting torch_scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.5/3.5 MB 2.8 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 1.0/3.5 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 1.6/3.5 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.8/3.5 MB 2.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 2.4/3.5 MB 2.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.9/3.5 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.5/3.5 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting torch_sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "     --------------- ------------------------ 0.8/2.1 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.3/2.1 MB 2.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.6/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.8/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting torch_cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_cluster-1.6.3%2Bpt25cu124-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "     ------------------- -------------------- 0.8/1.6 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.3/1.6 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 2.5 MB/s eta 0:00:00\n",
      "Collecting torch_spline_conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt25cu124-cp311-cp311-win_amd64.whl (524 kB)\n",
      "     ---------------------------------------- 0.0/524.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 524.4/524.4 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting scipy (from torch_sparse)\n",
      "  Downloading scipy-1.15.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from scipy->torch_sparse) (2.1.2)\n",
      "Downloading scipy-1.15.2-cp311-cp311-win_amd64.whl (41.2 MB)\n",
      "   ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/41.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/41.2 MB 1.9 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 1.0/41.2 MB 2.1 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 1.8/41.2 MB 2.3 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 2.4/41.2 MB 2.4 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 2.6/41.2 MB 2.4 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.4/41.2 MB 2.5 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 3.9/41.2 MB 2.5 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 4.5/41.2 MB 2.5 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 5.0/41.2 MB 2.5 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 5.5/41.2 MB 2.5 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 6.0/41.2 MB 2.5 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 6.8/41.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 7.3/41.2 MB 2.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 7.9/41.2 MB 2.6 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 8.4/41.2 MB 2.6 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 8.9/41.2 MB 2.6 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 9.2/41.2 MB 2.5 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 9.4/41.2 MB 2.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 9.7/41.2 MB 2.3 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 10.0/41.2 MB 2.3 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 10.5/41.2 MB 2.3 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 11.0/41.2 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 11.5/41.2 MB 2.3 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 11.8/41.2 MB 2.3 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 12.6/41.2 MB 2.3 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 13.1/41.2 MB 2.3 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 13.6/41.2 MB 2.3 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 14.4/41.2 MB 2.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 14.9/41.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 15.5/41.2 MB 2.4 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 16.0/41.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 16.5/41.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 17.3/41.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 17.8/41.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 18.1/41.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 18.6/41.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 19.7/41.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 20.4/41.2 MB 2.5 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 21.2/41.2 MB 2.5 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 22.0/41.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 22.8/41.2 MB 2.6 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 23.3/41.2 MB 2.6 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 23.6/41.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 23.9/41.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 24.4/41.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 24.9/41.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 25.2/41.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 25.7/41.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 26.2/41.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 27.0/41.2 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 27.3/41.2 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 27.5/41.2 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 27.8/41.2 MB 2.4 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 28.6/41.2 MB 2.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 29.4/41.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 30.1/41.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 30.9/41.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 31.5/41.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 31.7/41.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 32.0/41.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 32.5/41.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 33.0/41.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 33.6/41.2 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 34.6/41.2 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 35.4/41.2 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 36.2/41.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 37.0/41.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.5/41.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 38.0/41.2 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 38.3/41.2 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 38.8/41.2 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.3/41.2 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.8/41.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.4/41.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.2/41.2 MB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, scipy, pyg_lib, torch_sparse, torch_cluster\n",
      "Successfully installed pyg_lib-0.4.0+pt25cu124 scipy-1.15.2 torch_cluster-1.6.3+pt25cu124 torch_scatter-2.1.2+pt25cu124 torch_sparse-0.6.18+pt25cu124 torch_spline_conv-1.2.2+pt25cu124\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch_geometricNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Using cached aiohttp-3.11.12-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from torch_geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from torch_geometric) (2.1.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from torch_geometric) (6.1.1)\n",
      "Collecting pyparsing (from torch_geometric)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting requests (from torch_geometric)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from torch_geometric)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch_geometric)\n",
      "  Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric)\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
      "  Using cached propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->torch_geometric)\n",
      "  Using cached charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->torch_geometric)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->torch_geometric)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torch_geometric)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Using cached aiohttp-3.11.12-cp311-cp311-win_amd64.whl (442 kB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Using cached propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "Installing collected packages: urllib3, tqdm, pyparsing, propcache, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, aiosignal, aiohttp, torch_geometric\n",
      "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 attrs-25.1.0 certifi-2025.1.31 charset-normalizer-3.4.1 frozenlist-1.5.0 idna-3.10 multidict-6.1.0 propcache-0.2.1 pyparsing-3.2.1 requests-2.32.3 torch_geometric-2.6.1 tqdm-4.67.1 urllib3-2.3.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def format_pytorch_version(version_str):\n",
    "    # Example input: \"2.0.1+cu118\" -> returns \"2.0.1\"\n",
    "    return version_str.split('+')[0]\n",
    "\n",
    "def format_cuda_version(cuda_str):\n",
    "    # If CUDA is None (CPU-only PyTorch), return \"cpu\"\n",
    "    if cuda_str is None:\n",
    "        return \"cpu\"\n",
    "    # Example: \"11.8\" -> \"cu118\"\n",
    "    return \"cu\" + cuda_str.replace('.', '')\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "print(f\"Installing packages for torch-{TORCH}+{CUDA}...\")\n",
    "\n",
    "%pip install --upgrade --no-cache-dir pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "\n",
    "%pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 2.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/11.1 MB 2.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 2.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 2.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 2.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.8/11.1 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.8/11.1 MB 1.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.1/11.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.1 MB 1.1 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.1 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.1 MB 1.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.6/11.1 MB 938.1 kB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 953.2 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 971.6 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.4/11.1 MB 958.8 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.7/11.1 MB 969.5 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 3.9/11.1 MB 982.9 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 3.9/11.1 MB 982.9 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.2/11.1 MB 991.0 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.2/11.1 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.8/11.1 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.1/11.1 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.6/11.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.1 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.2/11.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.4/11.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.7/11.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.2/11.1 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/124.9 MB 3.3 MB/s eta 0:00:38\n",
      "   ---------------------------------------- 1.0/124.9 MB 3.0 MB/s eta 0:00:42\n",
      "    --------------------------------------- 1.6/124.9 MB 2.6 MB/s eta 0:00:48\n",
      "    --------------------------------------- 2.1/124.9 MB 2.6 MB/s eta 0:00:48\n",
      "    --------------------------------------- 2.6/124.9 MB 2.6 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 3.1/124.9 MB 2.4 MB/s eta 0:00:51\n",
      "   - -------------------------------------- 3.4/124.9 MB 2.4 MB/s eta 0:00:51\n",
      "   - -------------------------------------- 3.7/124.9 MB 2.2 MB/s eta 0:00:55\n",
      "   - -------------------------------------- 3.9/124.9 MB 2.2 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 4.2/124.9 MB 2.0 MB/s eta 0:01:02\n",
      "   - -------------------------------------- 4.2/124.9 MB 2.0 MB/s eta 0:01:02\n",
      "   - -------------------------------------- 4.7/124.9 MB 1.8 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 4.7/124.9 MB 1.8 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 5.0/124.9 MB 1.7 MB/s eta 0:01:13\n",
      "   - -------------------------------------- 5.2/124.9 MB 1.6 MB/s eta 0:01:14\n",
      "   - -------------------------------------- 5.5/124.9 MB 1.6 MB/s eta 0:01:15\n",
      "   - -------------------------------------- 5.5/124.9 MB 1.6 MB/s eta 0:01:15\n",
      "   - -------------------------------------- 5.5/124.9 MB 1.6 MB/s eta 0:01:15\n",
      "   - -------------------------------------- 5.5/124.9 MB 1.6 MB/s eta 0:01:15\n",
      "   - -------------------------------------- 6.0/124.9 MB 1.4 MB/s eta 0:01:25\n",
      "   -- ------------------------------------- 6.6/124.9 MB 1.5 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 7.1/124.9 MB 1.5 MB/s eta 0:01:19\n",
      "   -- ------------------------------------- 7.9/124.9 MB 1.6 MB/s eta 0:01:15\n",
      "   -- ------------------------------------- 8.4/124.9 MB 1.6 MB/s eta 0:01:13\n",
      "   -- ------------------------------------- 8.7/124.9 MB 1.6 MB/s eta 0:01:12\n",
      "   -- ------------------------------------- 9.2/124.9 MB 1.6 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 9.4/124.9 MB 1.6 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 9.7/124.9 MB 1.6 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 10.2/124.9 MB 1.7 MB/s eta 0:01:10\n",
      "   --- ------------------------------------ 10.7/124.9 MB 1.7 MB/s eta 0:01:09\n",
      "   --- ------------------------------------ 11.0/124.9 MB 1.7 MB/s eta 0:01:09\n",
      "   --- ------------------------------------ 11.5/124.9 MB 1.7 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 11.8/124.9 MB 1.7 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 12.1/124.9 MB 1.7 MB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 12.6/124.9 MB 1.7 MB/s eta 0:01:07\n",
      "   ---- ----------------------------------- 12.8/124.9 MB 1.7 MB/s eta 0:01:07\n",
      "   ---- ----------------------------------- 13.4/124.9 MB 1.7 MB/s eta 0:01:07\n",
      "   ---- ----------------------------------- 13.6/124.9 MB 1.7 MB/s eta 0:01:07\n",
      "   ---- ----------------------------------- 14.2/124.9 MB 1.7 MB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 14.4/124.9 MB 1.7 MB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 14.9/124.9 MB 1.7 MB/s eta 0:01:05\n",
      "   ---- ----------------------------------- 15.5/124.9 MB 1.7 MB/s eta 0:01:04\n",
      "   ----- ---------------------------------- 16.0/124.9 MB 1.7 MB/s eta 0:01:03\n",
      "   ----- ---------------------------------- 16.3/124.9 MB 1.7 MB/s eta 0:01:03\n",
      "   ----- ---------------------------------- 16.8/124.9 MB 1.8 MB/s eta 0:01:02\n",
      "   ----- ---------------------------------- 17.3/124.9 MB 1.8 MB/s eta 0:01:01\n",
      "   ----- ---------------------------------- 17.8/124.9 MB 1.8 MB/s eta 0:01:01\n",
      "   ----- ---------------------------------- 18.4/124.9 MB 1.8 MB/s eta 0:01:00\n",
      "   ------ --------------------------------- 18.9/124.9 MB 1.8 MB/s eta 0:00:59\n",
      "   ------ --------------------------------- 19.4/124.9 MB 1.8 MB/s eta 0:00:58\n",
      "   ------ --------------------------------- 20.2/124.9 MB 1.9 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 20.7/124.9 MB 1.9 MB/s eta 0:00:56\n",
      "   ------ --------------------------------- 21.2/124.9 MB 1.9 MB/s eta 0:00:55\n",
      "   ------- -------------------------------- 22.0/124.9 MB 1.9 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 22.5/124.9 MB 1.9 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 23.1/124.9 MB 1.9 MB/s eta 0:00:53\n",
      "   ------- -------------------------------- 23.6/124.9 MB 1.9 MB/s eta 0:00:53\n",
      "   ------- -------------------------------- 24.1/124.9 MB 1.9 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 24.6/124.9 MB 2.0 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 24.9/124.9 MB 2.0 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 25.7/124.9 MB 2.0 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 26.2/124.9 MB 2.0 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 26.7/124.9 MB 2.0 MB/s eta 0:00:49\n",
      "   -------- ------------------------------- 27.0/124.9 MB 2.0 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 27.0/124.9 MB 2.0 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 27.0/124.9 MB 2.0 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 27.3/124.9 MB 1.9 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 27.5/124.9 MB 1.9 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 27.8/124.9 MB 1.9 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 27.8/124.9 MB 1.9 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 28.0/124.9 MB 1.9 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 28.3/124.9 MB 1.9 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 28.6/124.9 MB 1.9 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 28.6/124.9 MB 1.9 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 28.6/124.9 MB 1.9 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 28.8/124.9 MB 1.8 MB/s eta 0:00:54\n",
      "   --------- ------------------------------ 29.1/124.9 MB 1.8 MB/s eta 0:00:54\n",
      "   --------- ------------------------------ 29.6/124.9 MB 1.8 MB/s eta 0:00:54\n",
      "   --------- ------------------------------ 30.4/124.9 MB 1.8 MB/s eta 0:00:53\n",
      "   --------- ------------------------------ 31.2/124.9 MB 1.8 MB/s eta 0:00:52\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 1.8 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 32.5/124.9 MB 1.9 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 33.0/124.9 MB 1.9 MB/s eta 0:00:49\n",
      "   ---------- ----------------------------- 33.6/124.9 MB 1.9 MB/s eta 0:00:49\n",
      "   ---------- ----------------------------- 34.3/124.9 MB 1.9 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 34.6/124.9 MB 1.9 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 35.1/124.9 MB 1.9 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 1.9 MB/s eta 0:00:47\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 1.9 MB/s eta 0:00:47\n",
      "   ----------- ---------------------------- 36.2/124.9 MB 1.9 MB/s eta 0:00:47\n",
      "   ----------- ---------------------------- 36.4/124.9 MB 1.9 MB/s eta 0:00:47\n",
      "   ----------- ---------------------------- 36.7/124.9 MB 1.9 MB/s eta 0:00:47\n",
      "   ----------- ---------------------------- 37.0/124.9 MB 1.9 MB/s eta 0:00:47\n",
      "   ----------- ---------------------------- 37.2/124.9 MB 1.9 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 37.7/124.9 MB 1.9 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 38.3/124.9 MB 1.9 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 39.1/124.9 MB 1.9 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 39.6/124.9 MB 1.9 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 40.4/124.9 MB 1.9 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 40.9/124.9 MB 1.9 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 41.7/124.9 MB 1.9 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 42.2/124.9 MB 1.9 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 42.7/124.9 MB 2.0 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 43.5/124.9 MB 2.0 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 44.0/124.9 MB 2.0 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 44.8/124.9 MB 2.0 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 45.4/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 45.6/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 45.9/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 45.9/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   -------------- ------------------------- 46.4/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 47.2/124.9 MB 2.0 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 47.7/124.9 MB 2.0 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 48.5/124.9 MB 2.0 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 49.3/124.9 MB 2.0 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 49.8/124.9 MB 2.0 MB/s eta 0:00:37\n",
      "   ---------------- ----------------------- 50.6/124.9 MB 2.0 MB/s eta 0:00:37\n",
      "   ---------------- ----------------------- 51.1/124.9 MB 2.0 MB/s eta 0:00:37\n",
      "   ---------------- ----------------------- 51.9/124.9 MB 2.1 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 52.7/124.9 MB 2.1 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 53.2/124.9 MB 2.1 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 54.0/124.9 MB 2.1 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 54.8/124.9 MB 2.1 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 55.3/124.9 MB 2.1 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 56.1/124.9 MB 2.1 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 56.9/124.9 MB 2.1 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 57.7/124.9 MB 2.1 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 58.2/124.9 MB 2.1 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 59.0/124.9 MB 2.2 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 59.8/124.9 MB 2.2 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 60.6/124.9 MB 2.2 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 61.1/124.9 MB 2.2 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 61.9/124.9 MB 2.2 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 62.7/124.9 MB 2.2 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 63.2/124.9 MB 2.2 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 63.4/124.9 MB 2.2 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 63.4/124.9 MB 2.2 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 63.7/124.9 MB 2.2 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 64.2/124.9 MB 2.2 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 64.7/124.9 MB 2.2 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 65.5/124.9 MB 2.2 MB/s eta 0:00:28\n",
      "   --------------------- ------------------ 66.1/124.9 MB 2.2 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 66.6/124.9 MB 2.2 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 67.4/124.9 MB 2.2 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 67.9/124.9 MB 2.2 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 68.7/124.9 MB 2.2 MB/s eta 0:00:26\n",
      "   ---------------------- ----------------- 69.2/124.9 MB 2.2 MB/s eta 0:00:26\n",
      "   ---------------------- ----------------- 69.7/124.9 MB 2.2 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 70.3/124.9 MB 2.2 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 70.8/124.9 MB 2.2 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 71.3/124.9 MB 2.2 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 72.1/124.9 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 72.6/124.9 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 73.4/124.9 MB 2.3 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 74.2/124.9 MB 2.3 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 75.0/124.9 MB 2.3 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 75.8/124.9 MB 2.4 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 76.3/124.9 MB 2.4 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 77.1/124.9 MB 2.4 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 77.9/124.9 MB 2.4 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 78.6/124.9 MB 2.4 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 79.4/124.9 MB 2.4 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 80.2/124.9 MB 2.4 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 81.0/124.9 MB 2.4 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 81.8/124.9 MB 2.5 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 82.6/124.9 MB 2.5 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 83.6/124.9 MB 2.5 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 84.4/124.9 MB 2.5 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 85.2/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 86.0/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 86.8/124.9 MB 2.5 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 87.3/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 87.8/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 88.3/124.9 MB 2.6 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 89.1/124.9 MB 2.6 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 89.9/124.9 MB 2.6 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.0/124.9 MB 2.6 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 91.5/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 92.3/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 2.6 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 94.1/124.9 MB 2.7 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 94.9/124.9 MB 2.7 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 95.7/124.9 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 96.5/124.9 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 97.5/124.9 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 98.3/124.9 MB 2.7 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 99.1/124.9 MB 2.7 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 99.9/124.9 MB 2.7 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 100.7/124.9 MB 2.8 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 101.4/124.9 MB 2.8 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 102.5/124.9 MB 2.8 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 103.3/124.9 MB 2.8 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 104.1/124.9 MB 2.8 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 104.9/124.9 MB 2.8 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 105.9/124.9 MB 2.8 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 106.7/124.9 MB 2.8 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 107.5/124.9 MB 2.8 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 108.3/124.9 MB 2.8 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 108.8/124.9 MB 2.8 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 109.6/124.9 MB 2.8 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 110.4/124.9 MB 2.9 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 111.1/124.9 MB 2.9 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 111.9/124.9 MB 2.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 112.5/124.9 MB 2.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 113.2/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 114.0/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 114.3/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 114.6/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 114.6/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 114.8/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 114.8/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 115.3/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 115.6/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 115.6/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 115.6/124.9 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 116.1/124.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 116.4/124.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 116.7/124.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 116.9/124.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 116.9/124.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 116.9/124.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 116.9/124.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.2/124.9 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.2/124.9 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.4/124.9 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.0/124.9 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 118.5/124.9 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 118.8/124.9 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.3/124.9 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 119.5/124.9 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.1/124.9 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.6/124.9 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.8/124.9 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.4/124.9 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  121.9/124.9 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.2/124.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  122.7/124.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.2/124.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.5/124.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.0/124.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.3/124.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.8/124.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.8/124.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 124.9/124.9 MB 2.7 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, xgboost, scikit-learn, sklearn-compat, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.13.0 joblib-1.4.2 scikit-learn-1.6.1 sklearn-compat-0.1.3 threadpoolctl-3.5.0 xgboost-2.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn imbalanced-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from optuna) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from optuna) (24.2)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.38-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\romai\\desktop\\gnn\\gnn_pu\\.conda\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: PyYAML, Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.9 PyYAML-6.0.2 alembic-1.14.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.2.1 sqlalchemy-2.0.38\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Citeseer\n",
    "#### SCAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 16:39:28,604] A new study created in memory with name: no-name-9ffa1d7c-26c0-45c7-8f28-cda45272791a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.11649134267148638, K=23, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4461186569349865, margin=0.3596784126857589, lpl_weight=0.4917957802880062\n",
      " - ratio=0.41429964058629537, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7758, LPL: 1.3863, Contrastive: 0.1851\n",
      " - Metrics: Accuracy=0.8662, F1=0.7362, Recall=0.8859, Precision=0.6298\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.11649134267148638, K=23, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4461186569349865, margin=0.3596784126857589, lpl_weight=0.4917957802880062\n",
      " - ratio=0.41429964058629537, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7758, LPL: 1.3863, Contrastive: 0.1851\n",
      " - Metrics: Accuracy=0.8623, F1=0.7365, Recall=0.9130, Precision=0.6172\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.11649134267148638, K=23, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4461186569349865, margin=0.3596784126857589, lpl_weight=0.4917957802880062\n",
      " - ratio=0.41429964058629537, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7758, LPL: 1.3863, Contrastive: 0.1851\n",
      " - Metrics: Accuracy=0.8828, F1=0.7665, Recall=0.9130, Precision=0.6605\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.11649134267148638, K=23, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4461186569349865, margin=0.3596784126857589, lpl_weight=0.4917957802880062\n",
      " - ratio=0.41429964058629537, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7758, LPL: 1.3863, Contrastive: 0.1851\n",
      " - Metrics: Accuracy=0.8662, F1=0.7411, Recall=0.9087, Precision=0.6257\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.11649134267148638, K=23, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4461186569349865, margin=0.3596784126857589, lpl_weight=0.4917957802880062\n",
      " - ratio=0.41429964058629537, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7758, LPL: 1.3863, Contrastive: 0.1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 16:40:10,326] Trial 0 finished with value: 0.742725162437942 and parameters: {'alpha': 0.11649134267148638, 'K': 23, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.4461186569349865, 'margin': 0.3596784126857589, 'lpl_weight': 0.4917957802880062, 'ratio': 0.41429964058629537, 'aggregation': 'sum'}. Best is trial 0 with value: 0.742725162437942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8629, F1=0.7333, Recall=0.8944, Precision=0.6214\n",
      "Done. Results written to citeseer_experimentations\\citeseer_scar_2302163928.csv.\n",
      "Average F1 over 5 seeds: 0.7427  0.0121\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6059255158964738, K=19, layers=1, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.3640950535712533, margin=0.5272515879863956, lpl_weight=0.6949631590035429\n",
      " - ratio=0.12104728679579396, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0125, LPL: 1.3863, Contrastive: 0.1608\n",
      "Epoch 50, Loss: 0.9816, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 100, Loss: 0.9812, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 150, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0578\n",
      "Epoch 200, Loss: 0.9810, LPL: 1.3863, Contrastive: 0.0575\n",
      "Epoch 250, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0574\n",
      "Epoch 300, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0573\n",
      " - Metrics: Accuracy=0.9213, F1=0.7930, Recall=0.7161, Precision=0.8885\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6059255158964738, K=19, layers=1, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.3640950535712533, margin=0.5272515879863956, lpl_weight=0.6949631590035429\n",
      " - ratio=0.12104728679579396, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0125, LPL: 1.3863, Contrastive: 0.1608\n",
      "Epoch 50, Loss: 0.9816, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 100, Loss: 0.9812, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 150, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0579\n",
      "Epoch 200, Loss: 0.9810, LPL: 1.3863, Contrastive: 0.0575\n",
      "Epoch 250, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0574\n",
      "Epoch 300, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0573\n",
      " - Metrics: Accuracy=0.9197, F1=0.7909, Recall=0.7204, Precision=0.8767\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6059255158964738, K=19, layers=1, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.3640950535712533, margin=0.5272515879863956, lpl_weight=0.6949631590035429\n",
      " - ratio=0.12104728679579396, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0125, LPL: 1.3863, Contrastive: 0.1608\n",
      "Epoch 50, Loss: 0.9816, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 100, Loss: 0.9812, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 150, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0578\n",
      "Epoch 200, Loss: 0.9810, LPL: 1.3863, Contrastive: 0.0575\n",
      "Epoch 250, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0574\n",
      "Epoch 300, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0573\n",
      " - Metrics: Accuracy=0.9219, F1=0.7981, Recall=0.7332, Precision=0.8756\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6059255158964738, K=19, layers=1, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.3640950535712533, margin=0.5272515879863956, lpl_weight=0.6949631590035429\n",
      " - ratio=0.12104728679579396, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0125, LPL: 1.3863, Contrastive: 0.1608\n",
      "Epoch 50, Loss: 0.9816, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 100, Loss: 0.9812, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 150, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0579\n",
      "Epoch 200, Loss: 0.9810, LPL: 1.3863, Contrastive: 0.0575\n",
      "Epoch 250, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0574\n",
      "Epoch 300, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0573\n",
      " - Metrics: Accuracy=0.9107, F1=0.7714, Recall=0.7147, Precision=0.8378\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6059255158964738, K=19, layers=1, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.3640950535712533, margin=0.5272515879863956, lpl_weight=0.6949631590035429\n",
      " - ratio=0.12104728679579396, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0125, LPL: 1.3863, Contrastive: 0.1608\n",
      "Epoch 50, Loss: 0.9816, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 100, Loss: 0.9812, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 150, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0578\n",
      "Epoch 200, Loss: 0.9810, LPL: 1.3863, Contrastive: 0.0575\n",
      "Epoch 250, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0574\n",
      "Epoch 300, Loss: 0.9809, LPL: 1.3863, Contrastive: 0.0573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 16:42:29,000] Trial 1 finished with value: 0.7882780224345753 and parameters: {'alpha': 0.6059255158964738, 'K': 19, 'layers': 1, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.3640950535712533, 'margin': 0.5272515879863956, 'lpl_weight': 0.6949631590035429, 'ratio': 0.12104728679579396, 'aggregation': 'sum'}. Best is trial 1 with value: 0.7882780224345753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9176, F1=0.7879, Recall=0.7261, Precision=0.8613\n",
      "Done. Results written to citeseer_experimentations\\citeseer_scar_2302164010.csv.\n",
      "Average F1 over 5 seeds: 0.7883  0.0091\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.08414660377308, K=21, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.4300082654309305, margin=0.18332355498619252, lpl_weight=0.26142643342241484\n",
      " - ratio=0.25404025884572035, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5211, LPL: 1.3863, Contrastive: 0.2149\n",
      "Epoch 50, Loss: 0.4905, LPL: 1.3863, Contrastive: 0.1734\n",
      "Epoch 100, Loss: 0.4884, LPL: 1.3863, Contrastive: 0.1706\n",
      " - Metrics: Accuracy=0.9152, F1=0.8115, Recall=0.8659, Precision=0.7635\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.08414660377308, K=21, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.4300082654309305, margin=0.18332355498619252, lpl_weight=0.26142643342241484\n",
      " - ratio=0.25404025884572035, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5211, LPL: 1.3863, Contrastive: 0.2149\n",
      "Epoch 50, Loss: 0.4905, LPL: 1.3863, Contrastive: 0.1734\n",
      "Epoch 100, Loss: 0.4884, LPL: 1.3863, Contrastive: 0.1706\n",
      " - Metrics: Accuracy=0.9294, F1=0.8415, Recall=0.8902, Precision=0.7980\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.08414660377308, K=21, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.4300082654309305, margin=0.18332355498619252, lpl_weight=0.26142643342241484\n",
      " - ratio=0.25404025884572035, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5211, LPL: 1.3863, Contrastive: 0.2149\n",
      "Epoch 50, Loss: 0.4905, LPL: 1.3863, Contrastive: 0.1734\n",
      "Epoch 100, Loss: 0.4884, LPL: 1.3863, Contrastive: 0.1706\n",
      " - Metrics: Accuracy=0.9188, F1=0.8193, Recall=0.8730, Precision=0.7718\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.08414660377308, K=21, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.4300082654309305, margin=0.18332355498619252, lpl_weight=0.26142643342241484\n",
      " - ratio=0.25404025884572035, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5211, LPL: 1.3863, Contrastive: 0.2149\n",
      "Epoch 50, Loss: 0.4905, LPL: 1.3863, Contrastive: 0.1734\n",
      "Epoch 100, Loss: 0.4884, LPL: 1.3863, Contrastive: 0.1706\n",
      " - Metrics: Accuracy=0.9110, F1=0.8047, Recall=0.8702, Precision=0.7485\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.08414660377308, K=21, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.4300082654309305, margin=0.18332355498619252, lpl_weight=0.26142643342241484\n",
      " - ratio=0.25404025884572035, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5211, LPL: 1.3863, Contrastive: 0.2149\n",
      "Epoch 50, Loss: 0.4905, LPL: 1.3863, Contrastive: 0.1734\n",
      "Epoch 100, Loss: 0.4884, LPL: 1.3863, Contrastive: 0.1706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 16:44:18,853] Trial 2 finished with value: 0.816100525732694 and parameters: {'alpha': 0.08414660377308, 'K': 21, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.4300082654309305, 'margin': 0.18332355498619252, 'lpl_weight': 0.26142643342241484, 'ratio': 0.25404025884572035, 'aggregation': 'sum'}. Best is trial 2 with value: 0.816100525732694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9107, F1=0.8034, Recall=0.8659, Precision=0.7494\n",
      "Done. Results written to citeseer_experimentations\\citeseer_scar_2302164229.csv.\n",
      "Average F1 over 5 seeds: 0.8161  0.0139\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5668746728173657, K=19, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1765151743804142, margin=0.9721638666906344, lpl_weight=0.6500496331098355\n",
      " - ratio=0.34447683195700557, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9229, LPL: 1.3863, Contrastive: 0.0622\n",
      " - Metrics: Accuracy=0.9125, F1=0.7932, Recall=0.7960, Precision=0.7904\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5668746728173657, K=19, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1765151743804142, margin=0.9721638666906344, lpl_weight=0.6500496331098355\n",
      " - ratio=0.34447683195700557, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9229, LPL: 1.3863, Contrastive: 0.0622\n"
     ]
    }
   ],
   "source": [
    "from train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"citeseer\",      \n",
    "        \"mechanism\": \"SCAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.05, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 17, 23),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 2),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.05, 0.99),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 0.99),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0, 0.5),\n",
    "        \"pos_weight\": 1,\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\"]),\n",
    "        \"treatment\": \"removal\",#trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"citeseer_scar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Citeseer\n",
    "#### SAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:03:38,552] A new study created in memory with name: no-name-51768b11-9e2d-4414-b07e-f364f0127f2d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.19318242593081886, K=15, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.42110600860832226, margin=0.9239927738665273, lpl_weight=0.9572821553708265\n",
      " - ratio=0.43303873683086513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3362, LPL: 1.3863, Contrastive: 0.2137\n",
      " - Metrics: Accuracy=0.8383, F1=0.6691, Recall=0.7760, Precision=0.5881\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.19318242593081886, K=15, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.42110600860832226, margin=0.9239927738665273, lpl_weight=0.9572821553708265\n",
      " - ratio=0.43303873683086513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3362, LPL: 1.3863, Contrastive: 0.2137\n",
      " - Metrics: Accuracy=0.8644, F1=0.7111, Recall=0.7917, Precision=0.6453\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.19318242593081886, K=15, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.42110600860832226, margin=0.9239927738665273, lpl_weight=0.9572821553708265\n",
      " - ratio=0.43303873683086513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3362, LPL: 1.3863, Contrastive: 0.2137\n",
      " - Metrics: Accuracy=0.8623, F1=0.7094, Recall=0.7974, Precision=0.6389\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.19318242593081886, K=15, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.42110600860832226, margin=0.9239927738665273, lpl_weight=0.9572821553708265\n",
      " - ratio=0.43303873683086513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3362, LPL: 1.3863, Contrastive: 0.2137\n",
      " - Metrics: Accuracy=0.8641, F1=0.7084, Recall=0.7832, Precision=0.6466\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.19318242593081886, K=15, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.42110600860832226, margin=0.9239927738665273, lpl_weight=0.9572821553708265\n",
      " - ratio=0.43303873683086513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3362, LPL: 1.3863, Contrastive: 0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:04:27,032] Trial 0 finished with value: 0.7005643791833988 and parameters: {'alpha': 0.19318242593081886, 'K': 15, 'layers': 3, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.42110600860832226, 'margin': 0.9239927738665273, 'lpl_weight': 0.9572821553708265, 'ratio': 0.43303873683086513, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 0 with value: 0.7005643791833988.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8605, F1=0.7048, Recall=0.7903, Precision=0.6361\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102110338.csv.\n",
      "Average F1 over 5 seeds: 0.7006  0.0159\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8736943955842099, K=22, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1369219263148594, margin=0.5533481495913736, lpl_weight=0.5616376297689698\n",
      " - ratio=0.3416643268199105, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8284, LPL: 1.3863, Contrastive: 0.1137\n",
      "Epoch 50, Loss: 0.8014, LPL: 1.3863, Contrastive: 0.0520\n",
      "Epoch 100, Loss: 0.8010, LPL: 1.3863, Contrastive: 0.0511\n",
      "Epoch 150, Loss: 0.8009, LPL: 1.3863, Contrastive: 0.0510\n",
      " - Metrics: Accuracy=0.7680, F1=0.6267, Recall=0.9244, Precision=0.4740\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8736943955842099, K=22, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1369219263148594, margin=0.5533481495913736, lpl_weight=0.5616376297689698\n",
      " - ratio=0.3416643268199105, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8284, LPL: 1.3863, Contrastive: 0.1137\n",
      "Epoch 50, Loss: 0.8014, LPL: 1.3863, Contrastive: 0.0520\n",
      "Epoch 100, Loss: 0.8010, LPL: 1.3863, Contrastive: 0.0510\n",
      " - Metrics: Accuracy=0.7650, F1=0.6219, Recall=0.9173, Precision=0.4704\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8736943955842099, K=22, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1369219263148594, margin=0.5533481495913736, lpl_weight=0.5616376297689698\n",
      " - ratio=0.3416643268199105, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8284, LPL: 1.3863, Contrastive: 0.1137\n",
      "Epoch 50, Loss: 0.8014, LPL: 1.3863, Contrastive: 0.0520\n",
      "Epoch 100, Loss: 0.8009, LPL: 1.3863, Contrastive: 0.0510\n",
      " - Metrics: Accuracy=0.7638, F1=0.6199, Recall=0.9144, Precision=0.4689\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8736943955842099, K=22, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1369219263148594, margin=0.5533481495913736, lpl_weight=0.5616376297689698\n",
      " - ratio=0.3416643268199105, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8285, LPL: 1.3863, Contrastive: 0.1137\n",
      "Epoch 50, Loss: 0.8014, LPL: 1.3863, Contrastive: 0.0520\n",
      "Epoch 100, Loss: 0.8010, LPL: 1.3863, Contrastive: 0.0511\n",
      "Epoch 150, Loss: 0.8009, LPL: 1.3863, Contrastive: 0.0508\n",
      " - Metrics: Accuracy=0.7625, F1=0.6180, Recall=0.9116, Precision=0.4674\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8736943955842099, K=22, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1369219263148594, margin=0.5533481495913736, lpl_weight=0.5616376297689698\n",
      " - ratio=0.3416643268199105, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8285, LPL: 1.3863, Contrastive: 0.1137\n",
      "Epoch 50, Loss: 0.8014, LPL: 1.3863, Contrastive: 0.0520\n",
      "Epoch 100, Loss: 0.8022, LPL: 1.3863, Contrastive: 0.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:06:36,575] Trial 1 finished with value: 0.62321083172147 and parameters: {'alpha': 0.8736943955842099, 'K': 22, 'layers': 3, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.1369219263148594, 'margin': 0.5533481495913736, 'lpl_weight': 0.5616376297689698, 'ratio': 0.3416643268199105, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.7005643791833988.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7698, F1=0.6296, Recall=0.9287, Precision=0.4762\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102110427.csv.\n",
      "Average F1 over 5 seeds: 0.6232  0.0043\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8507253262439899, K=17, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.2516473119418046, margin=0.5221723585375334, lpl_weight=0.6422800865903974\n",
      " - ratio=0.3972003795706752, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9190, LPL: 1.3863, Contrastive: 0.0799\n",
      "Epoch 50, Loss: 0.9111, LPL: 1.3863, Contrastive: 0.0580\n",
      "Epoch 100, Loss: 0.9110, LPL: 1.3863, Contrastive: 0.0576\n",
      " - Metrics: Accuracy=0.7084, F1=0.5658, Recall=0.9016, Precision=0.4123\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8507253262439899, K=17, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.2516473119418046, margin=0.5221723585375334, lpl_weight=0.6422800865903974\n",
      " - ratio=0.3972003795706752, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9190, LPL: 1.3863, Contrastive: 0.0799\n",
      "Epoch 50, Loss: 0.9111, LPL: 1.3863, Contrastive: 0.0580\n",
      "Epoch 100, Loss: 0.9110, LPL: 1.3863, Contrastive: 0.0576\n",
      " - Metrics: Accuracy=0.7121, F1=0.5712, Recall=0.9101, Precision=0.4162\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8507253262439899, K=17, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.2516473119418046, margin=0.5221723585375334, lpl_weight=0.6422800865903974\n",
      " - ratio=0.3972003795706752, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9190, LPL: 1.3863, Contrastive: 0.0799\n",
      "Epoch 50, Loss: 0.9111, LPL: 1.3863, Contrastive: 0.0580\n",
      "Epoch 100, Loss: 0.9110, LPL: 1.3863, Contrastive: 0.0576\n",
      " - Metrics: Accuracy=0.7133, F1=0.5730, Recall=0.9130, Precision=0.4175\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8507253262439899, K=17, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.2516473119418046, margin=0.5221723585375334, lpl_weight=0.6422800865903974\n",
      " - ratio=0.3972003795706752, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9190, LPL: 1.3863, Contrastive: 0.0799\n",
      "Epoch 50, Loss: 0.9111, LPL: 1.3863, Contrastive: 0.0580\n",
      "Epoch 100, Loss: 0.9110, LPL: 1.3863, Contrastive: 0.0576\n",
      " - Metrics: Accuracy=0.7169, F1=0.5783, Recall=0.9215, Precision=0.4214\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8507253262439899, K=17, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.2516473119418046, margin=0.5221723585375334, lpl_weight=0.6422800865903974\n",
      " - ratio=0.3972003795706752, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9190, LPL: 1.3863, Contrastive: 0.0799\n",
      "Epoch 50, Loss: 0.9111, LPL: 1.3863, Contrastive: 0.0580\n",
      "Epoch 100, Loss: 0.9110, LPL: 1.3863, Contrastive: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:08:34,207] Trial 2 finished with value: 0.5735004476275739 and parameters: {'alpha': 0.8507253262439899, 'K': 17, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': None, 'dropout': 0.2516473119418046, 'margin': 0.5221723585375334, 'lpl_weight': 0.6422800865903974, 'ratio': 0.3972003795706752, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.7005643791833988.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7175, F1=0.5792, Recall=0.9230, Precision=0.4220\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102110636.csv.\n",
      "Average F1 over 5 seeds: 0.5735  0.0049\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4150317098670665, K=15, layers=1, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.4748907133070138, margin=0.5910165725913035, lpl_weight=0.22126671178795787\n",
      " - ratio=0.4306084757905453, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3415, LPL: 1.3863, Contrastive: 0.0447\n",
      "Epoch 50, Loss: 0.3399, LPL: 1.3863, Contrastive: 0.0426\n",
      "Epoch 100, Loss: 0.3399, LPL: 1.3863, Contrastive: 0.0426\n",
      " - Metrics: Accuracy=0.8668, F1=0.7151, Recall=0.7932, Precision=0.6511\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4150317098670665, K=15, layers=1, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.4748907133070138, margin=0.5910165725913035, lpl_weight=0.22126671178795787\n",
      " - ratio=0.4306084757905453, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3415, LPL: 1.3863, Contrastive: 0.0447\n",
      "Epoch 50, Loss: 0.3399, LPL: 1.3863, Contrastive: 0.0426\n",
      "Epoch 100, Loss: 0.3398, LPL: 1.3863, Contrastive: 0.0425\n",
      " - Metrics: Accuracy=0.8677, F1=0.7208, Recall=0.8103, Precision=0.6491\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4150317098670665, K=15, layers=1, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.4748907133070138, margin=0.5910165725913035, lpl_weight=0.22126671178795787\n",
      " - ratio=0.4306084757905453, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3415, LPL: 1.3863, Contrastive: 0.0447\n",
      "Epoch 50, Loss: 0.3399, LPL: 1.3863, Contrastive: 0.0426\n",
      "Epoch 100, Loss: 0.3405, LPL: 1.3863, Contrastive: 0.0434\n",
      " - Metrics: Accuracy=0.8744, F1=0.7314, Recall=0.8117, Precision=0.6655\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4150317098670665, K=15, layers=1, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.4748907133070138, margin=0.5910165725913035, lpl_weight=0.22126671178795787\n",
      " - ratio=0.4306084757905453, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3415, LPL: 1.3863, Contrastive: 0.0447\n",
      "Epoch 50, Loss: 0.3399, LPL: 1.3863, Contrastive: 0.0426\n",
      "Epoch 100, Loss: 0.3398, LPL: 1.3863, Contrastive: 0.0424\n",
      " - Metrics: Accuracy=0.8683, F1=0.7221, Recall=0.8117, Precision=0.6503\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4150317098670665, K=15, layers=1, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.4748907133070138, margin=0.5910165725913035, lpl_weight=0.22126671178795787\n",
      " - ratio=0.4306084757905453, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3415, LPL: 1.3863, Contrastive: 0.0447\n",
      "Epoch 50, Loss: 0.3399, LPL: 1.3863, Contrastive: 0.0426\n",
      "Epoch 100, Loss: 0.3405, LPL: 1.3863, Contrastive: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:09:40,580] Trial 3 finished with value: 0.7218534029809287 and parameters: {'alpha': 0.4150317098670665, 'K': 15, 'layers': 1, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4748907133070138, 'margin': 0.5910165725913035, 'lpl_weight': 0.22126671178795787, 'ratio': 0.4306084757905453, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 3 with value: 0.7218534029809287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8671, F1=0.7199, Recall=0.8103, Precision=0.6477\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102110834.csv.\n",
      "Average F1 over 5 seeds: 0.7219  0.0053\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.14442613591169098, K=15, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.33812263343729343, margin=0.6915173099185175, lpl_weight=0.9504214483484436\n",
      " - ratio=0.2710732649314143, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3254, LPL: 1.3863, Contrastive: 0.1582\n",
      " - Metrics: Accuracy=0.8831, F1=0.7408, Recall=0.7932, Precision=0.6950\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.14442613591169098, K=15, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.33812263343729343, margin=0.6915173099185175, lpl_weight=0.9504214483484436\n",
      " - ratio=0.2710732649314143, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3254, LPL: 1.3863, Contrastive: 0.1581\n",
      " - Metrics: Accuracy=0.8987, F1=0.7700, Recall=0.8046, Precision=0.7382\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.14442613591169098, K=15, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.33812263343729343, margin=0.6915173099185175, lpl_weight=0.9504214483484436\n",
      " - ratio=0.2710732649314143, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3254, LPL: 1.3863, Contrastive: 0.1582\n",
      " - Metrics: Accuracy=0.8765, F1=0.7340, Recall=0.8088, Precision=0.6718\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.14442613591169098, K=15, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.33812263343729343, margin=0.6915173099185175, lpl_weight=0.9504214483484436\n",
      " - ratio=0.2710732649314143, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3254, LPL: 1.3863, Contrastive: 0.1582\n",
      " - Metrics: Accuracy=0.8837, F1=0.7476, Recall=0.8174, Precision=0.6887\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.14442613591169098, K=15, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.33812263343729343, margin=0.6915173099185175, lpl_weight=0.9504214483484436\n",
      " - ratio=0.2710732649314143, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3254, LPL: 1.3863, Contrastive: 0.1581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:10:22,001] Trial 4 finished with value: 0.7448221085169647 and parameters: {'alpha': 0.14442613591169098, 'K': 15, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.33812263343729343, 'margin': 0.6915173099185175, 'lpl_weight': 0.9504214483484436, 'ratio': 0.2710732649314143, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 4 with value: 0.7448221085169647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8762, F1=0.7318, Recall=0.8017, Precision=0.6731\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102110940.csv.\n",
      "Average F1 over 5 seeds: 0.7448  0.0137\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6608890431626081, K=16, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.16894508594600635, margin=0.20585869160008136, lpl_weight=0.5335208758470965\n",
      " - ratio=0.23708654949945004, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8210, LPL: 1.3863, Contrastive: 0.1746\n",
      "Epoch 50, Loss: 0.8155, LPL: 1.3863, Contrastive: 0.1627\n",
      "Epoch 100, Loss: 0.8149, LPL: 1.3863, Contrastive: 0.1615\n",
      " - Metrics: Accuracy=0.8428, F1=0.7023, Recall=0.8802, Precision=0.5843\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6608890431626081, K=16, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.16894508594600635, margin=0.20585869160008136, lpl_weight=0.5335208758470965\n",
      " - ratio=0.23708654949945004, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8210, LPL: 1.3863, Contrastive: 0.1746\n",
      "Epoch 50, Loss: 0.8155, LPL: 1.3863, Contrastive: 0.1627\n",
      "Epoch 100, Loss: 0.8156, LPL: 1.3863, Contrastive: 0.1630\n",
      "Epoch 150, Loss: 0.8162, LPL: 1.3863, Contrastive: 0.1642\n",
      " - Metrics: Accuracy=0.8320, F1=0.6818, Recall=0.8545, Precision=0.5672\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6608890431626081, K=16, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.16894508594600635, margin=0.20585869160008136, lpl_weight=0.5335208758470965\n",
      " - ratio=0.23708654949945004, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8210, LPL: 1.3863, Contrastive: 0.1746\n",
      "Epoch 50, Loss: 0.8155, LPL: 1.3863, Contrastive: 0.1628\n",
      "Epoch 100, Loss: 0.8150, LPL: 1.3863, Contrastive: 0.1616\n",
      " - Metrics: Accuracy=0.8374, F1=0.6921, Recall=0.8673, Precision=0.5758\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6608890431626081, K=16, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.16894508594600635, margin=0.20585869160008136, lpl_weight=0.5335208758470965\n",
      " - ratio=0.23708654949945004, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8210, LPL: 1.3863, Contrastive: 0.1746\n",
      "Epoch 50, Loss: 0.8155, LPL: 1.3863, Contrastive: 0.1627\n",
      "Epoch 100, Loss: 0.8154, LPL: 1.3863, Contrastive: 0.1626\n",
      "Epoch 150, Loss: 0.8146, LPL: 1.3863, Contrastive: 0.1608\n",
      "Epoch 200, Loss: 0.8147, LPL: 1.3863, Contrastive: 0.1610\n",
      "Epoch 250, Loss: 0.8145, LPL: 1.3863, Contrastive: 0.1604\n",
      " - Metrics: Accuracy=0.8494, F1=0.7149, Recall=0.8959, Precision=0.5947\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6608890431626081, K=16, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.16894508594600635, margin=0.20585869160008136, lpl_weight=0.5335208758470965\n",
      " - ratio=0.23708654949945004, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8210, LPL: 1.3863, Contrastive: 0.1746\n",
      "Epoch 50, Loss: 0.8155, LPL: 1.3863, Contrastive: 0.1627\n",
      "Epoch 100, Loss: 0.8179, LPL: 1.3863, Contrastive: 0.1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:11:52,485] Trial 5 finished with value: 0.7007398975526465 and parameters: {'alpha': 0.6608890431626081, 'K': 16, 'layers': 3, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.16894508594600635, 'margin': 0.20585869160008136, 'lpl_weight': 0.5335208758470965, 'ratio': 0.23708654949945004, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 4 with value: 0.7448221085169647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8482, F1=0.7126, Recall=0.8930, Precision=0.5928\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111022.csv.\n",
      "Average F1 over 5 seeds: 0.7007  0.0124\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5597633401375068, K=20, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19715045415317772, margin=0.7830757697621449, lpl_weight=0.6658070516608078\n",
      " - ratio=0.13708306689025596, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9635, LPL: 1.3863, Contrastive: 0.1213\n",
      " - Metrics: Accuracy=0.9059, F1=0.7620, Recall=0.7147, Precision=0.8160\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5597633401375068, K=20, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19715045415317772, margin=0.7830757697621449, lpl_weight=0.6658070516608078\n",
      " - ratio=0.13708306689025596, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9635, LPL: 1.3863, Contrastive: 0.1213\n",
      " - Metrics: Accuracy=0.9098, F1=0.7696, Recall=0.7147, Precision=0.8336\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5597633401375068, K=20, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19715045415317772, margin=0.7830757697621449, lpl_weight=0.6658070516608078\n",
      " - ratio=0.13708306689025596, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9635, LPL: 1.3863, Contrastive: 0.1213\n",
      " - Metrics: Accuracy=0.9035, F1=0.7585, Recall=0.7190, Precision=0.8025\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5597633401375068, K=20, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19715045415317772, margin=0.7830757697621449, lpl_weight=0.6658070516608078\n",
      " - ratio=0.13708306689025596, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9636, LPL: 1.3863, Contrastive: 0.1214\n",
      " - Metrics: Accuracy=0.9044, F1=0.7539, Recall=0.6947, Precision=0.8240\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5597633401375068, K=20, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19715045415317772, margin=0.7830757697621449, lpl_weight=0.6658070516608078\n",
      " - ratio=0.13708306689025596, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9636, LPL: 1.3863, Contrastive: 0.1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:12:39,652] Trial 6 finished with value: 0.7639125638668963 and parameters: {'alpha': 0.5597633401375068, 'K': 20, 'layers': 3, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.19715045415317772, 'margin': 0.7830757697621449, 'lpl_weight': 0.6658070516608078, 'ratio': 0.13708306689025596, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 6 with value: 0.7639125638668963.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9113, F1=0.7757, Recall=0.7275, Precision=0.8306\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111152.csv.\n",
      "Average F1 over 5 seeds: 0.7639  0.0078\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9054313297235015, K=18, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4311382427935435, margin=0.9330678704411725, lpl_weight=0.3762089909947879\n",
      " - ratio=0.4193880421445605, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6643, LPL: 1.3863, Contrastive: 0.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6676, F1=0.5191, Recall=0.8516, Precision=0.3734\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9054313297235015, K=18, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4311382427935435, margin=0.9330678704411725, lpl_weight=0.3762089909947879\n",
      " - ratio=0.4193880421445605, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6643, LPL: 1.3863, Contrastive: 0.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6808, F1=0.5383, Recall=0.8830, Precision=0.3871\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9054313297235015, K=18, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4311382427935435, margin=0.9330678704411725, lpl_weight=0.3762089909947879\n",
      " - ratio=0.4193880421445605, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6643, LPL: 1.3863, Contrastive: 0.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6784, F1=0.5348, Recall=0.8773, Precision=0.3846\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9054313297235015, K=18, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4311382427935435, margin=0.9330678704411725, lpl_weight=0.3762089909947879\n",
      " - ratio=0.4193880421445605, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6643, LPL: 1.3863, Contrastive: 0.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6742, F1=0.5287, Recall=0.8673, Precision=0.3802\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9054313297235015, K=18, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4311382427935435, margin=0.9330678704411725, lpl_weight=0.3762089909947879\n",
      " - ratio=0.4193880421445605, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6643, LPL: 1.3863, Contrastive: 0.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n",
      "[I 2025-02-21 11:13:38,053] Trial 7 finished with value: 0.5292173913043478 and parameters: {'alpha': 0.9054313297235015, 'K': 18, 'layers': 3, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.4311382427935435, 'margin': 0.9330678704411725, 'lpl_weight': 0.3762089909947879, 'ratio': 0.4193880421445605, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 6 with value: 0.7639125638668963.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6718, F1=0.5252, Recall=0.8616, Precision=0.3777\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111239.csv.\n",
      "Average F1 over 5 seeds: 0.5292  0.0068\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4525312312971739, K=22, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.16733129640271685, margin=0.6490270650004096, lpl_weight=0.9239876265670982\n",
      " - ratio=0.22555984792989478, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2895, LPL: 1.3863, Contrastive: 0.1135\n",
      " - Metrics: Accuracy=0.8560, F1=0.7220, Recall=0.8873, Precision=0.6086\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4525312312971739, K=22, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.16733129640271685, margin=0.6490270650004096, lpl_weight=0.9239876265670982\n",
      " - ratio=0.22555984792989478, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2895, LPL: 1.3863, Contrastive: 0.1135\n",
      " - Metrics: Accuracy=0.8554, F1=0.7208, Recall=0.8859, Precision=0.6076\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4525312312971739, K=22, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.16733129640271685, margin=0.6490270650004096, lpl_weight=0.9239876265670982\n",
      " - ratio=0.22555984792989478, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2895, LPL: 1.3863, Contrastive: 0.1135\n",
      " - Metrics: Accuracy=0.8524, F1=0.7150, Recall=0.8787, Precision=0.6027\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4525312312971739, K=22, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.16733129640271685, margin=0.6490270650004096, lpl_weight=0.9239876265670982\n",
      " - ratio=0.22555984792989478, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2895, LPL: 1.3863, Contrastive: 0.1135\n",
      " - Metrics: Accuracy=0.8530, F1=0.7162, Recall=0.8802, Precision=0.6037\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4525312312971739, K=22, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.16733129640271685, margin=0.6490270650004096, lpl_weight=0.9239876265670982\n",
      " - ratio=0.22555984792989478, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2895, LPL: 1.3863, Contrastive: 0.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:14:17,867] Trial 8 finished with value: 0.7180499129425421 and parameters: {'alpha': 0.4525312312971739, 'K': 22, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.16733129640271685, 'margin': 0.6490270650004096, 'lpl_weight': 0.9239876265670982, 'ratio': 0.22555984792989478, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 6 with value: 0.7639125638668963.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8530, F1=0.7162, Recall=0.8802, Precision=0.6037\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111338.csv.\n",
      "Average F1 over 5 seeds: 0.7180  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9158871106345619, K=24, layers=3, hidden=256, out=128\n",
      " - norm=None, dropout=0.3068616418529848, margin=0.3122465354719601, lpl_weight=0.42080850218736066\n",
      " - ratio=0.4552281808909652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6714, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 50, Loss: 0.6543, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 100, Loss: 0.6564, LPL: 1.3863, Contrastive: 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6700, F1=0.5436, Recall=0.9330, Precision=0.3836\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9158871106345619, K=24, layers=3, hidden=256, out=128\n",
      " - norm=None, dropout=0.3068616418529848, margin=0.3122465354719601, lpl_weight=0.42080850218736066\n",
      " - ratio=0.4552281808909652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6714, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 50, Loss: 0.6543, LPL: 1.3863, Contrastive: 0.1225\n",
      " - Metrics: Accuracy=0.6736, F1=0.5486, Recall=0.9415, Precision=0.3871\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9158871106345619, K=24, layers=3, hidden=256, out=128\n",
      " - norm=None, dropout=0.3068616418529848, margin=0.3122465354719601, lpl_weight=0.42080850218736066\n",
      " - ratio=0.4552281808909652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6714, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 50, Loss: 0.6543, LPL: 1.3863, Contrastive: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6778, F1=0.5544, Recall=0.9515, Precision=0.3912\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9158871106345619, K=24, layers=3, hidden=256, out=128\n",
      " - norm=None, dropout=0.3068616418529848, margin=0.3122465354719601, lpl_weight=0.42080850218736066\n",
      " - ratio=0.4552281808909652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6714, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 50, Loss: 0.6543, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 100, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.1223\n",
      "Epoch 150, Loss: 0.6534, LPL: 1.3863, Contrastive: 0.1209\n",
      "Epoch 200, Loss: 0.6530, LPL: 1.3863, Contrastive: 0.1202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6694, F1=0.5428, Recall=0.9315, Precision=0.3830\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9158871106345619, K=24, layers=3, hidden=256, out=128\n",
      " - norm=None, dropout=0.3068616418529848, margin=0.3122465354719601, lpl_weight=0.42080850218736066\n",
      " - ratio=0.4552281808909652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6714, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 50, Loss: 0.6543, LPL: 1.3863, Contrastive: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n",
      "[I 2025-02-21 11:16:09,806] Trial 9 finished with value: 0.5494596841230258 and parameters: {'alpha': 0.9158871106345619, 'K': 24, 'layers': 3, 'hidden_channels': 256, 'out_channels': 128, 'norm': None, 'dropout': 0.3068616418529848, 'margin': 0.3122465354719601, 'lpl_weight': 0.42080850218736066, 'ratio': 0.4552281808909652, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 6 with value: 0.7639125638668963.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6802, F1=0.5578, Recall=0.9572, Precision=0.3935\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111417.csv.\n",
      "Average F1 over 5 seeds: 0.5495  0.0059\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6617341074453986, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23911237962540213, margin=0.7964062145482886, lpl_weight=0.7639809637744821\n",
      " - ratio=0.10258166517012912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0924, LPL: 1.3863, Contrastive: 0.1409\n",
      " - Metrics: Accuracy=0.9146, F1=0.7735, Recall=0.6919, Precision=0.8770\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6617341074453986, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23911237962540213, margin=0.7964062145482886, lpl_weight=0.7639809637744821\n",
      " - ratio=0.10258166517012912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0924, LPL: 1.3863, Contrastive: 0.1409\n",
      " - Metrics: Accuracy=0.9125, F1=0.7663, Recall=0.6805, Precision=0.8768\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6617341074453986, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23911237962540213, margin=0.7964062145482886, lpl_weight=0.7639809637744821\n",
      " - ratio=0.10258166517012912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0924, LPL: 1.3863, Contrastive: 0.1409\n",
      " - Metrics: Accuracy=0.9128, F1=0.7680, Recall=0.6847, Precision=0.8743\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6617341074453986, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23911237962540213, margin=0.7964062145482886, lpl_weight=0.7639809637744821\n",
      " - ratio=0.10258166517012912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0924, LPL: 1.3863, Contrastive: 0.1409\n",
      " - Metrics: Accuracy=0.9119, F1=0.7620, Recall=0.6690, Precision=0.8849\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6617341074453986, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23911237962540213, margin=0.7964062145482886, lpl_weight=0.7639809637744821\n",
      " - ratio=0.10258166517012912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0924, LPL: 1.3863, Contrastive: 0.1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:16:42,568] Trial 10 finished with value: 0.7675088842666762 and parameters: {'alpha': 0.6617341074453986, 'K': 19, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.23911237962540213, 'margin': 0.7964062145482886, 'lpl_weight': 0.7639809637744821, 'ratio': 0.10258166517012912, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 10 with value: 0.7675088842666762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9116, F1=0.7678, Recall=0.6933, Precision=0.8602\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111609.csv.\n",
      "Average F1 over 5 seeds: 0.7675  0.0037\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5898285636680747, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23678538277588718, margin=0.7833145679589952, lpl_weight=0.7329361721463812\n",
      " - ratio=0.10838916697581022, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0536, LPL: 1.3863, Contrastive: 0.1405\n",
      " - Metrics: Accuracy=0.9128, F1=0.7698, Recall=0.6919, Precision=0.8676\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5898285636680747, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23678538277588718, margin=0.7833145679589952, lpl_weight=0.7329361721463812\n",
      " - ratio=0.10838916697581022, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0536, LPL: 1.3863, Contrastive: 0.1405\n",
      " - Metrics: Accuracy=0.9149, F1=0.7752, Recall=0.6961, Precision=0.8746\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5898285636680747, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23678538277588718, margin=0.7833145679589952, lpl_weight=0.7329361721463812\n",
      " - ratio=0.10838916697581022, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0536, LPL: 1.3863, Contrastive: 0.1405\n",
      " - Metrics: Accuracy=0.9131, F1=0.7712, Recall=0.6947, Precision=0.8665\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5898285636680747, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23678538277588718, margin=0.7833145679589952, lpl_weight=0.7329361721463812\n",
      " - ratio=0.10838916697581022, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0536, LPL: 1.3863, Contrastive: 0.1405\n",
      " - Metrics: Accuracy=0.9113, F1=0.7657, Recall=0.6876, Precision=0.8638\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5898285636680747, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.23678538277588718, margin=0.7833145679589952, lpl_weight=0.7329361721463812\n",
      " - ratio=0.10838916697581022, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0536, LPL: 1.3863, Contrastive: 0.1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:17:13,742] Trial 11 finished with value: 0.771081428832898 and parameters: {'alpha': 0.5898285636680747, 'K': 19, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.23678538277588718, 'margin': 0.7833145679589952, 'lpl_weight': 0.7329361721463812, 'ratio': 0.10838916697581022, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 11 with value: 0.771081428832898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9137, F1=0.7735, Recall=0.6990, Precision=0.8657\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111642.csv.\n",
      "Average F1 over 5 seeds: 0.7711  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7046919080070946, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2493286716345877, margin=0.7861280408524915, lpl_weight=0.7936778365067785\n",
      " - ratio=0.1033911404893781, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1296, LPL: 1.3863, Contrastive: 0.1420\n",
      " - Metrics: Accuracy=0.9137, F1=0.7702, Recall=0.6862, Precision=0.8777\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7046919080070946, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2493286716345877, margin=0.7861280408524915, lpl_weight=0.7936778365067785\n",
      " - ratio=0.1033911404893781, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1296, LPL: 1.3863, Contrastive: 0.1420\n",
      " - Metrics: Accuracy=0.9086, F1=0.7572, Recall=0.6762, Precision=0.8603\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7046919080070946, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2493286716345877, margin=0.7861280408524915, lpl_weight=0.7936778365067785\n",
      " - ratio=0.1033911404893781, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1296, LPL: 1.3863, Contrastive: 0.1420\n",
      " - Metrics: Accuracy=0.9146, F1=0.7721, Recall=0.6862, Precision=0.8826\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7046919080070946, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2493286716345877, margin=0.7861280408524915, lpl_weight=0.7936778365067785\n",
      " - ratio=0.1033911404893781, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1296, LPL: 1.3863, Contrastive: 0.1420\n",
      " - Metrics: Accuracy=0.9095, F1=0.7571, Recall=0.6690, Precision=0.8717\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7046919080070946, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2493286716345877, margin=0.7861280408524915, lpl_weight=0.7936778365067785\n",
      " - ratio=0.1033911404893781, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1296, LPL: 1.3863, Contrastive: 0.1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:17:44,538] Trial 12 finished with value: 0.7656879150509851 and parameters: {'alpha': 0.7046919080070946, 'K': 19, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.2493286716345877, 'margin': 0.7861280408524915, 'lpl_weight': 0.7936778365067785, 'ratio': 0.1033911404893781, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 11 with value: 0.771081428832898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9131, F1=0.7719, Recall=0.6976, Precision=0.8640\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111713.csv.\n",
      "Average F1 over 5 seeds: 0.7657  0.0070\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7121356642230035, K=21, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2488557870400587, margin=0.988201108323254, lpl_weight=0.7806023745781782\n",
      " - ratio=0.16636845731065703, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1133, LPL: 1.3863, Contrastive: 0.1419\n",
      "Epoch 50, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 100, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 150, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9059, F1=0.7530, Recall=0.6805, Precision=0.8428\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7121356642230035, K=21, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2488557870400587, margin=0.988201108323254, lpl_weight=0.7806023745781782\n",
      " - ratio=0.16636845731065703, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1133, LPL: 1.3863, Contrastive: 0.1419\n",
      "Epoch 50, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 100, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 150, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9083, F1=0.7600, Recall=0.6890, Precision=0.8474\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7121356642230035, K=21, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2488557870400587, margin=0.988201108323254, lpl_weight=0.7806023745781782\n",
      " - ratio=0.16636845731065703, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1133, LPL: 1.3863, Contrastive: 0.1419\n",
      "Epoch 50, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 100, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 150, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9149, F1=0.7752, Recall=0.6961, Precision=0.8746\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7121356642230035, K=21, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2488557870400587, margin=0.988201108323254, lpl_weight=0.7806023745781782\n",
      " - ratio=0.16636845731065703, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1133, LPL: 1.3863, Contrastive: 0.1419\n",
      "Epoch 50, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 100, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 150, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9074, F1=0.7532, Recall=0.6705, Precision=0.8592\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7121356642230035, K=21, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.2488557870400587, margin=0.988201108323254, lpl_weight=0.7806023745781782\n",
      " - ratio=0.16636845731065703, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1133, LPL: 1.3863, Contrastive: 0.1419\n",
      "Epoch 50, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 100, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0001\n",
      "Epoch 150, Loss: 1.0822, LPL: 1.3863, Contrastive: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:19:01,845] Trial 13 finished with value: 0.7631216645265676 and parameters: {'alpha': 0.7121356642230035, 'K': 21, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.2488557870400587, 'margin': 0.988201108323254, 'lpl_weight': 0.7806023745781782, 'ratio': 0.16636845731065703, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 11 with value: 0.771081428832898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9137, F1=0.7742, Recall=0.7019, Precision=0.8632\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111744.csv.\n",
      "Average F1 over 5 seeds: 0.7631  0.0098\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3398471647125072, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10091140501698381, margin=0.4379426484662008, lpl_weight=0.7895145591510534\n",
      " - ratio=0.1790496837839881, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1223, LPL: 1.3863, Contrastive: 0.1321\n",
      "Epoch 50, Loss: 1.1118, LPL: 1.3863, Contrastive: 0.0824\n",
      "Epoch 100, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0814\n",
      "Epoch 150, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0812\n",
      " - Metrics: Accuracy=0.9161, F1=0.7971, Recall=0.7817, Precision=0.8131\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3398471647125072, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10091140501698381, margin=0.4379426484662008, lpl_weight=0.7895145591510534\n",
      " - ratio=0.1790496837839881, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1223, LPL: 1.3863, Contrastive: 0.1321\n",
      "Epoch 50, Loss: 1.1118, LPL: 1.3863, Contrastive: 0.0824\n",
      "Epoch 100, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0814\n",
      "Epoch 150, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0812\n",
      " - Metrics: Accuracy=0.9209, F1=0.8098, Recall=0.7989, Precision=0.8211\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3398471647125072, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10091140501698381, margin=0.4379426484662008, lpl_weight=0.7895145591510534\n",
      " - ratio=0.1790496837839881, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1223, LPL: 1.3863, Contrastive: 0.1321\n",
      "Epoch 50, Loss: 1.1118, LPL: 1.3863, Contrastive: 0.0824\n",
      "Epoch 100, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0814\n",
      "Epoch 150, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0812\n",
      " - Metrics: Accuracy=0.9101, F1=0.7881, Recall=0.7932, Precision=0.7831\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3398471647125072, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10091140501698381, margin=0.4379426484662008, lpl_weight=0.7895145591510534\n",
      " - ratio=0.1790496837839881, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1223, LPL: 1.3863, Contrastive: 0.1321\n",
      "Epoch 50, Loss: 1.1118, LPL: 1.3863, Contrastive: 0.0824\n",
      "Epoch 100, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0814\n",
      "Epoch 150, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0811\n",
      "Epoch 200, Loss: 1.1115, LPL: 1.3863, Contrastive: 0.0808\n",
      "Epoch 250, Loss: 1.1115, LPL: 1.3863, Contrastive: 0.0807\n",
      "Epoch 300, Loss: 1.1115, LPL: 1.3863, Contrastive: 0.0806\n",
      "Epoch 350, Loss: 1.1114, LPL: 1.3863, Contrastive: 0.0805\n",
      " - Metrics: Accuracy=0.9122, F1=0.7764, Recall=0.7233, Precision=0.8380\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3398471647125072, K=19, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10091140501698381, margin=0.4379426484662008, lpl_weight=0.7895145591510534\n",
      " - ratio=0.1790496837839881, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1223, LPL: 1.3863, Contrastive: 0.1321\n",
      "Epoch 50, Loss: 1.1118, LPL: 1.3863, Contrastive: 0.0824\n",
      "Epoch 100, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0814\n",
      "Epoch 150, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.0811\n",
      "Epoch 200, Loss: 1.1115, LPL: 1.3863, Contrastive: 0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:20:37,815] Trial 14 finished with value: 0.791429795879049 and parameters: {'alpha': 0.3398471647125072, 'K': 19, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.10091140501698381, 'margin': 0.4379426484662008, 'lpl_weight': 0.7895145591510534, 'ratio': 0.1790496837839881, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 14 with value: 0.791429795879049.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9116, F1=0.7857, Recall=0.7689, Precision=0.8033\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102111901.csv.\n",
      "Average F1 over 5 seeds: 0.7914  0.0113\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.29355208961740886, K=25, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10259337436551495, margin=0.4093190911835407, lpl_weight=0.10747758604623542\n",
      " - ratio=0.17371384053195976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1355\n",
      "Epoch 50, Loss: 0.2300, LPL: 1.3863, Contrastive: 0.0907\n",
      "Epoch 100, Loss: 0.2292, LPL: 1.3863, Contrastive: 0.0898\n",
      "Epoch 150, Loss: 0.2289, LPL: 1.3863, Contrastive: 0.0896\n",
      "Epoch 200, Loss: 0.2286, LPL: 1.3863, Contrastive: 0.0892\n",
      "Epoch 250, Loss: 0.2285, LPL: 1.3863, Contrastive: 0.0891\n",
      "Epoch 300, Loss: 0.2284, LPL: 1.3863, Contrastive: 0.0890\n",
      "Epoch 350, Loss: 0.2283, LPL: 1.3863, Contrastive: 0.0889\n",
      " - Metrics: Accuracy=0.9216, F1=0.8039, Recall=0.7632, Precision=0.8492\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.29355208961740886, K=25, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10259337436551495, margin=0.4093190911835407, lpl_weight=0.10747758604623542\n",
      " - ratio=0.17371384053195976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1355\n",
      "Epoch 50, Loss: 0.2300, LPL: 1.3863, Contrastive: 0.0907\n",
      "Epoch 100, Loss: 0.2292, LPL: 1.3863, Contrastive: 0.0898\n",
      "Epoch 150, Loss: 0.2289, LPL: 1.3863, Contrastive: 0.0896\n",
      "Epoch 200, Loss: 0.2286, LPL: 1.3863, Contrastive: 0.0892\n",
      "Epoch 250, Loss: 0.2285, LPL: 1.3863, Contrastive: 0.0891\n",
      "Epoch 300, Loss: 0.2284, LPL: 1.3863, Contrastive: 0.0890\n",
      "Epoch 350, Loss: 0.2283, LPL: 1.3863, Contrastive: 0.0889\n",
      " - Metrics: Accuracy=0.9216, F1=0.7994, Recall=0.7418, Precision=0.8667\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.29355208961740886, K=25, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10259337436551495, margin=0.4093190911835407, lpl_weight=0.10747758604623542\n",
      " - ratio=0.17371384053195976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1355\n",
      "Epoch 50, Loss: 0.2300, LPL: 1.3863, Contrastive: 0.0907\n",
      "Epoch 100, Loss: 0.2292, LPL: 1.3863, Contrastive: 0.0898\n",
      "Epoch 150, Loss: 0.2289, LPL: 1.3863, Contrastive: 0.0896\n",
      "Epoch 200, Loss: 0.2286, LPL: 1.3863, Contrastive: 0.0892\n",
      "Epoch 250, Loss: 0.2285, LPL: 1.3863, Contrastive: 0.0891\n",
      "Epoch 300, Loss: 0.2284, LPL: 1.3863, Contrastive: 0.0890\n",
      "Epoch 350, Loss: 0.2283, LPL: 1.3863, Contrastive: 0.0889\n",
      " - Metrics: Accuracy=0.9155, F1=0.7914, Recall=0.7603, Precision=0.8251\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.29355208961740886, K=25, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10259337436551495, margin=0.4093190911835407, lpl_weight=0.10747758604623542\n",
      " - ratio=0.17371384053195976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1355\n",
      "Epoch 50, Loss: 0.2300, LPL: 1.3863, Contrastive: 0.0907\n",
      "Epoch 100, Loss: 0.2292, LPL: 1.3863, Contrastive: 0.0898\n",
      "Epoch 150, Loss: 0.2289, LPL: 1.3863, Contrastive: 0.0896\n",
      "Epoch 200, Loss: 0.2286, LPL: 1.3863, Contrastive: 0.0892\n",
      "Epoch 250, Loss: 0.2285, LPL: 1.3863, Contrastive: 0.0891\n",
      "Epoch 300, Loss: 0.2284, LPL: 1.3863, Contrastive: 0.0890\n",
      "Epoch 350, Loss: 0.2283, LPL: 1.3863, Contrastive: 0.0889\n",
      " - Metrics: Accuracy=0.9119, F1=0.7775, Recall=0.7304, Precision=0.8312\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.29355208961740886, K=25, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.10259337436551495, margin=0.4093190911835407, lpl_weight=0.10747758604623542\n",
      " - ratio=0.17371384053195976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1355\n",
      "Epoch 50, Loss: 0.2300, LPL: 1.3863, Contrastive: 0.0907\n",
      "Epoch 100, Loss: 0.2292, LPL: 1.3863, Contrastive: 0.0898\n",
      "Epoch 150, Loss: 0.2289, LPL: 1.3863, Contrastive: 0.0895\n",
      "Epoch 200, Loss: 0.2286, LPL: 1.3863, Contrastive: 0.0892\n",
      "Epoch 250, Loss: 0.2285, LPL: 1.3863, Contrastive: 0.0891\n",
      "Epoch 300, Loss: 0.2284, LPL: 1.3863, Contrastive: 0.0890\n",
      "Epoch 350, Loss: 0.2283, LPL: 1.3863, Contrastive: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:23:04,361] Trial 15 finished with value: 0.7912976771964665 and parameters: {'alpha': 0.29355208961740886, 'K': 25, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.10259337436551495, 'margin': 0.4093190911835407, 'lpl_weight': 0.10747758604623542, 'ratio': 0.17371384053195976, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 14 with value: 0.791429795879049.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9158, F1=0.7843, Recall=0.7261, Precision=0.8526\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102112037.csv.\n",
      "Average F1 over 5 seeds: 0.7913  0.0096\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.29309800730632496, K=24, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.10154059731164336, margin=0.37154592683026466, lpl_weight=0.12145917916505133\n",
      " - ratio=0.17882800804193175, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2921, LPL: 1.3863, Contrastive: 0.1408\n",
      "Epoch 50, Loss: 0.2585, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 0.2577, LPL: 1.3863, Contrastive: 0.1016\n",
      "Epoch 150, Loss: 0.2572, LPL: 1.3863, Contrastive: 0.1011\n",
      " - Metrics: Accuracy=0.9219, F1=0.8065, Recall=0.7732, Precision=0.8429\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.29309800730632496, K=24, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.10154059731164336, margin=0.37154592683026466, lpl_weight=0.12145917916505133\n",
      " - ratio=0.17882800804193175, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2921, LPL: 1.3863, Contrastive: 0.1408\n",
      "Epoch 50, Loss: 0.2585, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 0.2577, LPL: 1.3863, Contrastive: 0.1016\n",
      "Epoch 150, Loss: 0.2572, LPL: 1.3863, Contrastive: 0.1012\n",
      " - Metrics: Accuracy=0.9225, F1=0.8111, Recall=0.7903, Precision=0.8331\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.29309800730632496, K=24, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.10154059731164336, margin=0.37154592683026466, lpl_weight=0.12145917916505133\n",
      " - ratio=0.17882800804193175, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2921, LPL: 1.3863, Contrastive: 0.1408\n",
      "Epoch 50, Loss: 0.2585, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 0.2577, LPL: 1.3863, Contrastive: 0.1016\n",
      "Epoch 150, Loss: 0.2572, LPL: 1.3863, Contrastive: 0.1012\n",
      " - Metrics: Accuracy=0.9219, F1=0.8124, Recall=0.8031, Precision=0.8219\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.29309800730632496, K=24, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.10154059731164336, margin=0.37154592683026466, lpl_weight=0.12145917916505133\n",
      " - ratio=0.17882800804193175, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2921, LPL: 1.3863, Contrastive: 0.1408\n",
      "Epoch 50, Loss: 0.2585, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 0.2577, LPL: 1.3863, Contrastive: 0.1016\n",
      "Epoch 150, Loss: 0.2572, LPL: 1.3863, Contrastive: 0.1012\n",
      " - Metrics: Accuracy=0.9113, F1=0.7888, Recall=0.7860, Precision=0.7917\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.29309800730632496, K=24, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.10154059731164336, margin=0.37154592683026466, lpl_weight=0.12145917916505133\n",
      " - ratio=0.17882800804193175, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2921, LPL: 1.3863, Contrastive: 0.1408\n",
      "Epoch 50, Loss: 0.2585, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 0.2577, LPL: 1.3863, Contrastive: 0.1016\n",
      "Epoch 150, Loss: 0.2572, LPL: 1.3863, Contrastive: 0.1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:24:33,440] Trial 16 finished with value: 0.8025091661269185 and parameters: {'alpha': 0.29309800730632496, 'K': 24, 'layers': 1, 'hidden_channels': 64, 'out_channels': 64, 'norm': None, 'dropout': 0.10154059731164336, 'margin': 0.37154592683026466, 'lpl_weight': 0.12145917916505133, 'ratio': 0.17882800804193175, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 16 with value: 0.8025091661269185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9143, F1=0.7936, Recall=0.7817, Precision=0.8059\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102112304.csv.\n",
      "Average F1 over 5 seeds: 0.8025  0.0095\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3043275552295226, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.10112073904708149, margin=0.403565771460964, lpl_weight=0.34345522366802744\n",
      " - ratio=0.3242337541015202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5918, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 0.5369, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 100, Loss: 0.5361, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 150, Loss: 0.5358, LPL: 1.3863, Contrastive: 0.0909\n",
      " - Metrics: Accuracy=0.9092, F1=0.8049, Recall=0.8887, Precision=0.7355\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3043275552295226, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.10112073904708149, margin=0.403565771460964, lpl_weight=0.34345522366802744\n",
      " - ratio=0.3242337541015202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5918, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 0.5369, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 100, Loss: 0.5361, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 150, Loss: 0.5358, LPL: 1.3863, Contrastive: 0.0909\n",
      " - Metrics: Accuracy=0.9053, F1=0.7974, Recall=0.8845, Precision=0.7260\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3043275552295226, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.10112073904708149, margin=0.403565771460964, lpl_weight=0.34345522366802744\n",
      " - ratio=0.3242337541015202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5918, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 0.5369, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 100, Loss: 0.5361, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 150, Loss: 0.5358, LPL: 1.3863, Contrastive: 0.0909\n",
      " - Metrics: Accuracy=0.9053, F1=0.7982, Recall=0.8887, Precision=0.7244\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3043275552295226, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.10112073904708149, margin=0.403565771460964, lpl_weight=0.34345522366802744\n",
      " - ratio=0.3242337541015202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5918, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 0.5369, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 100, Loss: 0.5361, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 150, Loss: 0.5358, LPL: 1.3863, Contrastive: 0.0909\n",
      " - Metrics: Accuracy=0.9032, F1=0.7949, Recall=0.8902, Precision=0.7181\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3043275552295226, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.10112073904708149, margin=0.403565771460964, lpl_weight=0.34345522366802744\n",
      " - ratio=0.3242337541015202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5918, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 0.5369, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 100, Loss: 0.5361, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 150, Loss: 0.5358, LPL: 1.3863, Contrastive: 0.0909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:26:21,859] Trial 17 finished with value: 0.7981226688968601 and parameters: {'alpha': 0.3043275552295226, 'K': 24, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.10112073904708149, 'margin': 0.403565771460964, 'lpl_weight': 0.34345522366802744, 'ratio': 0.3242337541015202, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 16 with value: 0.8025091661269185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9032, F1=0.7952, Recall=0.8916, Precision=0.7176\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102112433.csv.\n",
      "Average F1 over 5 seeds: 0.7981  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3069864315307804, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.36543481767817376, margin=0.17487130238756207, lpl_weight=0.25554917109268604\n",
      " - ratio=0.3241265926695435, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5321, LPL: 1.3863, Contrastive: 0.2389\n",
      "Epoch 50, Loss: 0.4857, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 100, Loss: 0.4843, LPL: 1.3863, Contrastive: 0.1747\n",
      "Epoch 150, Loss: 0.4839, LPL: 1.3863, Contrastive: 0.1741\n",
      " - Metrics: Accuracy=0.9116, F1=0.8056, Recall=0.8688, Precision=0.7509\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3069864315307804, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.36543481767817376, margin=0.17487130238756207, lpl_weight=0.25554917109268604\n",
      " - ratio=0.3241265926695435, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5321, LPL: 1.3863, Contrastive: 0.2389\n",
      "Epoch 50, Loss: 0.4857, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 100, Loss: 0.4843, LPL: 1.3863, Contrastive: 0.1747\n",
      "Epoch 150, Loss: 0.4839, LPL: 1.3863, Contrastive: 0.1741\n",
      " - Metrics: Accuracy=0.9029, F1=0.7899, Recall=0.8659, Precision=0.7261\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3069864315307804, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.36543481767817376, margin=0.17487130238756207, lpl_weight=0.25554917109268604\n",
      " - ratio=0.3241265926695435, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5321, LPL: 1.3863, Contrastive: 0.2389\n",
      "Epoch 50, Loss: 0.4857, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 100, Loss: 0.4843, LPL: 1.3863, Contrastive: 0.1747\n",
      "Epoch 150, Loss: 0.4838, LPL: 1.3863, Contrastive: 0.1740\n",
      "Epoch 200, Loss: 0.4835, LPL: 1.3863, Contrastive: 0.1736\n",
      "Epoch 250, Loss: 0.4834, LPL: 1.3863, Contrastive: 0.1735\n",
      "Epoch 300, Loss: 0.4833, LPL: 1.3863, Contrastive: 0.1733\n",
      " - Metrics: Accuracy=0.9038, F1=0.7911, Recall=0.8645, Precision=0.7292\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3069864315307804, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.36543481767817376, margin=0.17487130238756207, lpl_weight=0.25554917109268604\n",
      " - ratio=0.3241265926695435, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5321, LPL: 1.3863, Contrastive: 0.2389\n",
      "Epoch 50, Loss: 0.4857, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 100, Loss: 0.4843, LPL: 1.3863, Contrastive: 0.1747\n",
      "Epoch 150, Loss: 0.4838, LPL: 1.3863, Contrastive: 0.1740\n",
      "Epoch 200, Loss: 0.4835, LPL: 1.3863, Contrastive: 0.1736\n",
      "Epoch 250, Loss: 0.4834, LPL: 1.3863, Contrastive: 0.1735\n",
      " - Metrics: Accuracy=0.9065, F1=0.7974, Recall=0.8730, Precision=0.7338\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3069864315307804, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.36543481767817376, margin=0.17487130238756207, lpl_weight=0.25554917109268604\n",
      " - ratio=0.3241265926695435, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5321, LPL: 1.3863, Contrastive: 0.2389\n",
      "Epoch 50, Loss: 0.4857, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 100, Loss: 0.4843, LPL: 1.3863, Contrastive: 0.1747\n",
      "Epoch 150, Loss: 0.4838, LPL: 1.3863, Contrastive: 0.1740\n",
      "Epoch 200, Loss: 0.4835, LPL: 1.3863, Contrastive: 0.1736\n",
      "Epoch 250, Loss: 0.4834, LPL: 1.3863, Contrastive: 0.1735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:28:39,673] Trial 18 finished with value: 0.7980874847176954 and parameters: {'alpha': 0.3069864315307804, 'K': 24, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.36543481767817376, 'margin': 0.17487130238756207, 'lpl_weight': 0.25554917109268604, 'ratio': 0.3241265926695435, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 16 with value: 0.8025091661269185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9107, F1=0.8065, Recall=0.8830, Precision=0.7422\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102112621.csv.\n",
      "Average F1 over 5 seeds: 0.7981  0.0070\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2231760400219388, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.1397377658988535, margin=0.30913824977399984, lpl_weight=0.15890274845028324\n",
      " - ratio=0.35469608841276334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3792, LPL: 1.3863, Contrastive: 0.1890\n",
      "Epoch 50, Loss: 0.3245, LPL: 1.3863, Contrastive: 0.1239\n",
      "Epoch 100, Loss: 0.3233, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 150, Loss: 0.3227, LPL: 1.3863, Contrastive: 0.1218\n",
      "Epoch 200, Loss: 0.3225, LPL: 1.3863, Contrastive: 0.1216\n",
      " - Metrics: Accuracy=0.8900, F1=0.7735, Recall=0.8916, Precision=0.6831\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2231760400219388, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.1397377658988535, margin=0.30913824977399984, lpl_weight=0.15890274845028324\n",
      " - ratio=0.35469608841276334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3792, LPL: 1.3863, Contrastive: 0.1890\n",
      "Epoch 50, Loss: 0.3245, LPL: 1.3863, Contrastive: 0.1239\n",
      "Epoch 100, Loss: 0.3233, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 150, Loss: 0.3228, LPL: 1.3863, Contrastive: 0.1218\n",
      "Epoch 200, Loss: 0.3225, LPL: 1.3863, Contrastive: 0.1216\n",
      " - Metrics: Accuracy=0.9017, F1=0.7929, Recall=0.8930, Precision=0.7130\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2231760400219388, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.1397377658988535, margin=0.30913824977399984, lpl_weight=0.15890274845028324\n",
      " - ratio=0.35469608841276334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3792, LPL: 1.3863, Contrastive: 0.1890\n",
      "Epoch 50, Loss: 0.3245, LPL: 1.3863, Contrastive: 0.1239\n",
      "Epoch 100, Loss: 0.3233, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 150, Loss: 0.3227, LPL: 1.3863, Contrastive: 0.1218\n",
      "Epoch 200, Loss: 0.3225, LPL: 1.3863, Contrastive: 0.1216\n",
      " - Metrics: Accuracy=0.8993, F1=0.7876, Recall=0.8859, Precision=0.7089\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2231760400219388, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.1397377658988535, margin=0.30913824977399984, lpl_weight=0.15890274845028324\n",
      " - ratio=0.35469608841276334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3792, LPL: 1.3863, Contrastive: 0.1890\n",
      "Epoch 50, Loss: 0.3245, LPL: 1.3863, Contrastive: 0.1239\n",
      "Epoch 100, Loss: 0.3233, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 150, Loss: 0.3228, LPL: 1.3863, Contrastive: 0.1218\n",
      "Epoch 200, Loss: 0.3225, LPL: 1.3863, Contrastive: 0.1216\n",
      " - Metrics: Accuracy=0.8942, F1=0.7781, Recall=0.8802, Precision=0.6972\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2231760400219388, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.1397377658988535, margin=0.30913824977399984, lpl_weight=0.15890274845028324\n",
      " - ratio=0.35469608841276334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3792, LPL: 1.3863, Contrastive: 0.1890\n",
      "Epoch 50, Loss: 0.3245, LPL: 1.3863, Contrastive: 0.1239\n",
      "Epoch 100, Loss: 0.3233, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 150, Loss: 0.3227, LPL: 1.3863, Contrastive: 0.1218\n",
      "Epoch 200, Loss: 0.3225, LPL: 1.3863, Contrastive: 0.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:30:39,499] Trial 19 finished with value: 0.7827116766457319 and parameters: {'alpha': 0.2231760400219388, 'K': 23, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.1397377658988535, 'margin': 0.30913824977399984, 'lpl_weight': 0.15890274845028324, 'ratio': 0.35469608841276334, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 16 with value: 0.8025091661269185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8963, F1=0.7815, Recall=0.8802, Precision=0.7027\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102112839.csv.\n",
      "Average F1 over 5 seeds: 0.7827  0.0069\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.44596740113599354, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.20877558322416293, margin=0.10649950343063541, lpl_weight=0.3096847396264495\n",
      " - ratio=0.2766534456214162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5943, LPL: 1.3863, Contrastive: 0.2390\n",
      "Epoch 50, Loss: 0.5717, LPL: 1.3863, Contrastive: 0.2063\n",
      "Epoch 100, Loss: 0.5705, LPL: 1.3863, Contrastive: 0.2045\n",
      "Epoch 150, Loss: 0.5699, LPL: 1.3863, Contrastive: 0.2037\n",
      "Epoch 200, Loss: 0.5696, LPL: 1.3863, Contrastive: 0.2032\n",
      " - Metrics: Accuracy=0.9098, F1=0.7959, Recall=0.8345, Precision=0.7607\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.44596740113599354, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.20877558322416293, margin=0.10649950343063541, lpl_weight=0.3096847396264495\n",
      " - ratio=0.2766534456214162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5943, LPL: 1.3863, Contrastive: 0.2390\n",
      "Epoch 50, Loss: 0.5717, LPL: 1.3863, Contrastive: 0.2063\n",
      "Epoch 100, Loss: 0.5705, LPL: 1.3863, Contrastive: 0.2045\n",
      "Epoch 150, Loss: 0.5699, LPL: 1.3863, Contrastive: 0.2037\n",
      "Epoch 200, Loss: 0.5696, LPL: 1.3863, Contrastive: 0.2032\n",
      " - Metrics: Accuracy=0.9050, F1=0.7888, Recall=0.8417, Precision=0.7421\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.44596740113599354, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.20877558322416293, margin=0.10649950343063541, lpl_weight=0.3096847396264495\n",
      " - ratio=0.2766534456214162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5943, LPL: 1.3863, Contrastive: 0.2390\n",
      "Epoch 50, Loss: 0.5717, LPL: 1.3863, Contrastive: 0.2063\n",
      "Epoch 100, Loss: 0.5705, LPL: 1.3863, Contrastive: 0.2045\n",
      "Epoch 150, Loss: 0.5699, LPL: 1.3863, Contrastive: 0.2037\n",
      "Epoch 200, Loss: 0.5695, LPL: 1.3863, Contrastive: 0.2031\n",
      " - Metrics: Accuracy=0.9098, F1=0.7976, Recall=0.8431, Precision=0.7567\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.44596740113599354, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.20877558322416293, margin=0.10649950343063541, lpl_weight=0.3096847396264495\n",
      " - ratio=0.2766534456214162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5943, LPL: 1.3863, Contrastive: 0.2390\n",
      "Epoch 50, Loss: 0.5717, LPL: 1.3863, Contrastive: 0.2063\n",
      "Epoch 100, Loss: 0.5705, LPL: 1.3863, Contrastive: 0.2045\n",
      "Epoch 150, Loss: 0.5699, LPL: 1.3863, Contrastive: 0.2037\n",
      "Epoch 200, Loss: 0.5696, LPL: 1.3863, Contrastive: 0.2032\n",
      " - Metrics: Accuracy=0.9077, F1=0.7924, Recall=0.8359, Precision=0.7532\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.44596740113599354, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.20877558322416293, margin=0.10649950343063541, lpl_weight=0.3096847396264495\n",
      " - ratio=0.2766534456214162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5943, LPL: 1.3863, Contrastive: 0.2390\n",
      "Epoch 50, Loss: 0.5717, LPL: 1.3863, Contrastive: 0.2063\n",
      "Epoch 100, Loss: 0.5705, LPL: 1.3863, Contrastive: 0.2045\n",
      "Epoch 150, Loss: 0.5699, LPL: 1.3863, Contrastive: 0.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:32:52,414] Trial 20 finished with value: 0.7947772106180132 and parameters: {'alpha': 0.44596740113599354, 'K': 25, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.20877558322416293, 'margin': 0.10649950343063541, 'lpl_weight': 0.3096847396264495, 'ratio': 0.2766534456214162, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 16 with value: 0.8025091661269185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9095, F1=0.7992, Recall=0.8545, Precision=0.7506\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102113039.csv.\n",
      "Average F1 over 5 seeds: 0.7948  0.0037\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.31466553959323823, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.37112086777612324, margin=0.3177944906322938, lpl_weight=0.2581756284363828\n",
      " - ratio=0.3246825692534914, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5221, LPL: 1.3863, Contrastive: 0.2214\n",
      "Epoch 50, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.1212\n",
      "Epoch 100, Loss: 0.4466, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 0.4463, LPL: 1.3863, Contrastive: 0.1192\n",
      " - Metrics: Accuracy=0.8945, F1=0.7760, Recall=0.8673, Precision=0.7021\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.31466553959323823, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.37112086777612324, margin=0.3177944906322938, lpl_weight=0.2581756284363828\n",
      " - ratio=0.3246825692534914, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5221, LPL: 1.3863, Contrastive: 0.2214\n",
      "Epoch 50, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.1212\n",
      "Epoch 100, Loss: 0.4466, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 0.4463, LPL: 1.3863, Contrastive: 0.1192\n",
      " - Metrics: Accuracy=0.8972, F1=0.7813, Recall=0.8716, Precision=0.7080\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.31466553959323823, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.37112086777612324, margin=0.3177944906322938, lpl_weight=0.2581756284363828\n",
      " - ratio=0.3246825692534914, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5221, LPL: 1.3863, Contrastive: 0.2214\n",
      "Epoch 50, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.1212\n",
      "Epoch 100, Loss: 0.4466, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 0.4463, LPL: 1.3863, Contrastive: 0.1192\n",
      " - Metrics: Accuracy=0.8999, F1=0.7867, Recall=0.8759, Precision=0.7140\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.31466553959323823, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.37112086777612324, margin=0.3177944906322938, lpl_weight=0.2581756284363828\n",
      " - ratio=0.3246825692534914, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5221, LPL: 1.3863, Contrastive: 0.2214\n",
      "Epoch 50, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.1212\n",
      "Epoch 100, Loss: 0.4466, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 0.4463, LPL: 1.3863, Contrastive: 0.1192\n",
      " - Metrics: Accuracy=0.8978, F1=0.7834, Recall=0.8773, Precision=0.7077\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.31466553959323823, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.37112086777612324, margin=0.3177944906322938, lpl_weight=0.2581756284363828\n",
      " - ratio=0.3246825692534914, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5221, LPL: 1.3863, Contrastive: 0.2214\n",
      "Epoch 50, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.1212\n",
      "Epoch 100, Loss: 0.4466, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 0.4463, LPL: 1.3863, Contrastive: 0.1192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:34:28,067] Trial 21 finished with value: 0.7812713939819816 and parameters: {'alpha': 0.31466553959323823, 'K': 24, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.37112086777612324, 'margin': 0.3177944906322938, 'lpl_weight': 0.2581756284363828, 'ratio': 0.3246825692534914, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 16 with value: 0.8025091661269185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8954, F1=0.7789, Recall=0.8745, Precision=0.7022\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102113252.csv.\n",
      "Average F1 over 5 seeds: 0.7813  0.0037\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2517933027640994, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3774413128479427, margin=0.15074866626861816, lpl_weight=0.3860979046636843\n",
      " - ratio=0.3743917653437712, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6861, LPL: 1.3863, Contrastive: 0.2458\n",
      "Epoch 50, Loss: 0.6503, LPL: 1.3863, Contrastive: 0.1874\n",
      "Epoch 100, Loss: 0.6489, LPL: 1.3863, Contrastive: 0.1851\n",
      "Epoch 150, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.1844\n",
      "Epoch 200, Loss: 0.6482, LPL: 1.3863, Contrastive: 0.1840\n",
      "Epoch 250, Loss: 0.6481, LPL: 1.3863, Contrastive: 0.1839\n",
      " - Metrics: Accuracy=0.8963, F1=0.7784, Recall=0.8645, Precision=0.7079\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2517933027640994, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3774413128479427, margin=0.15074866626861816, lpl_weight=0.3860979046636843\n",
      " - ratio=0.3743917653437712, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6861, LPL: 1.3863, Contrastive: 0.2458\n",
      "Epoch 50, Loss: 0.6503, LPL: 1.3863, Contrastive: 0.1874\n",
      "Epoch 100, Loss: 0.6489, LPL: 1.3863, Contrastive: 0.1851\n",
      "Epoch 150, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.1843\n",
      "Epoch 200, Loss: 0.6481, LPL: 1.3863, Contrastive: 0.1839\n",
      "Epoch 250, Loss: 0.6481, LPL: 1.3863, Contrastive: 0.1838\n",
      " - Metrics: Accuracy=0.8969, F1=0.7811, Recall=0.8730, Precision=0.7067\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2517933027640994, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3774413128479427, margin=0.15074866626861816, lpl_weight=0.3860979046636843\n",
      " - ratio=0.3743917653437712, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6861, LPL: 1.3863, Contrastive: 0.2458\n",
      "Epoch 50, Loss: 0.6503, LPL: 1.3863, Contrastive: 0.1874\n",
      "Epoch 100, Loss: 0.6489, LPL: 1.3863, Contrastive: 0.1851\n",
      "Epoch 150, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.1844\n",
      "Epoch 200, Loss: 0.6482, LPL: 1.3863, Contrastive: 0.1840\n",
      "Epoch 250, Loss: 0.6481, LPL: 1.3863, Contrastive: 0.1839\n",
      " - Metrics: Accuracy=0.9008, F1=0.7898, Recall=0.8845, Precision=0.7135\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2517933027640994, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3774413128479427, margin=0.15074866626861816, lpl_weight=0.3860979046636843\n",
      " - ratio=0.3743917653437712, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6861, LPL: 1.3863, Contrastive: 0.2458\n",
      "Epoch 50, Loss: 0.6503, LPL: 1.3863, Contrastive: 0.1874\n",
      "Epoch 100, Loss: 0.6489, LPL: 1.3863, Contrastive: 0.1851\n",
      "Epoch 150, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.1843\n",
      "Epoch 200, Loss: 0.6481, LPL: 1.3863, Contrastive: 0.1839\n",
      "Epoch 250, Loss: 0.6481, LPL: 1.3863, Contrastive: 0.1838\n",
      " - Metrics: Accuracy=0.8837, F1=0.7592, Recall=0.8702, Precision=0.6733\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2517933027640994, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3774413128479427, margin=0.15074866626861816, lpl_weight=0.3860979046636843\n",
      " - ratio=0.3743917653437712, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6861, LPL: 1.3863, Contrastive: 0.2458\n",
      "Epoch 50, Loss: 0.6503, LPL: 1.3863, Contrastive: 0.1874\n",
      "Epoch 100, Loss: 0.6489, LPL: 1.3863, Contrastive: 0.1851\n",
      "Epoch 150, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.1843\n",
      "Epoch 200, Loss: 0.6482, LPL: 1.3863, Contrastive: 0.1840\n",
      "Epoch 250, Loss: 0.6481, LPL: 1.3863, Contrastive: 0.1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:36:48,754] Trial 22 finished with value: 0.7755689269439512 and parameters: {'alpha': 0.2517933027640994, 'K': 23, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.3774413128479427, 'margin': 0.15074866626861816, 'lpl_weight': 0.3860979046636843, 'ratio': 0.3743917653437712, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 16 with value: 0.8025091661269185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8888, F1=0.7693, Recall=0.8802, Precision=0.6833\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102113428.csv.\n",
      "Average F1 over 5 seeds: 0.7756  0.0105\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.12178203275550273, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.28578977482475043, margin=0.20808673756367518, lpl_weight=0.1932696443440854\n",
      " - ratio=0.2971568698605647, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.2230\n",
      "Epoch 50, Loss: 0.3993, LPL: 1.3863, Contrastive: 0.1628\n",
      "Epoch 100, Loss: 0.3978, LPL: 1.3863, Contrastive: 0.1609\n",
      "Epoch 150, Loss: 0.3971, LPL: 1.3863, Contrastive: 0.1602\n",
      "Epoch 200, Loss: 0.3969, LPL: 1.3863, Contrastive: 0.1599\n",
      " - Metrics: Accuracy=0.9170, F1=0.8145, Recall=0.8645, Precision=0.7700\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.12178203275550273, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.28578977482475043, margin=0.20808673756367518, lpl_weight=0.1932696443440854\n",
      " - ratio=0.2971568698605647, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.2230\n",
      "Epoch 50, Loss: 0.3993, LPL: 1.3863, Contrastive: 0.1628\n",
      "Epoch 100, Loss: 0.3978, LPL: 1.3863, Contrastive: 0.1609\n",
      "Epoch 150, Loss: 0.3971, LPL: 1.3863, Contrastive: 0.1602\n",
      "Epoch 200, Loss: 0.3969, LPL: 1.3863, Contrastive: 0.1599\n",
      " - Metrics: Accuracy=0.9080, F1=0.7976, Recall=0.8602, Precision=0.7435\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.12178203275550273, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.28578977482475043, margin=0.20808673756367518, lpl_weight=0.1932696443440854\n",
      " - ratio=0.2971568698605647, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.2230\n",
      "Epoch 50, Loss: 0.3993, LPL: 1.3863, Contrastive: 0.1628\n",
      "Epoch 100, Loss: 0.3978, LPL: 1.3863, Contrastive: 0.1609\n",
      "Epoch 150, Loss: 0.3971, LPL: 1.3863, Contrastive: 0.1601\n",
      "Epoch 200, Loss: 0.3970, LPL: 1.3863, Contrastive: 0.1599\n",
      "Epoch 250, Loss: 0.3967, LPL: 1.3863, Contrastive: 0.1597\n",
      " - Metrics: Accuracy=0.9122, F1=0.8076, Recall=0.8745, Precision=0.7503\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.12178203275550273, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.28578977482475043, margin=0.20808673756367518, lpl_weight=0.1932696443440854\n",
      " - ratio=0.2971568698605647, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.2230\n",
      "Epoch 50, Loss: 0.3993, LPL: 1.3863, Contrastive: 0.1628\n",
      "Epoch 100, Loss: 0.3978, LPL: 1.3863, Contrastive: 0.1609\n",
      "Epoch 150, Loss: 0.3971, LPL: 1.3863, Contrastive: 0.1602\n",
      "Epoch 200, Loss: 0.3969, LPL: 1.3863, Contrastive: 0.1599\n",
      " - Metrics: Accuracy=0.9131, F1=0.8077, Recall=0.8659, Precision=0.7569\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.12178203275550273, K=24, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.28578977482475043, margin=0.20808673756367518, lpl_weight=0.1932696443440854\n",
      " - ratio=0.2971568698605647, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4478, LPL: 1.3863, Contrastive: 0.2230\n",
      "Epoch 50, Loss: 0.3993, LPL: 1.3863, Contrastive: 0.1628\n",
      "Epoch 100, Loss: 0.3978, LPL: 1.3863, Contrastive: 0.1609\n",
      "Epoch 150, Loss: 0.3971, LPL: 1.3863, Contrastive: 0.1601\n",
      "Epoch 200, Loss: 0.3969, LPL: 1.3863, Contrastive: 0.1599\n",
      "Epoch 250, Loss: 0.3967, LPL: 1.3863, Contrastive: 0.1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:39:08,167] Trial 23 finished with value: 0.8063043107111474 and parameters: {'alpha': 0.12178203275550273, 'K': 24, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.28578977482475043, 'margin': 0.20808673756367518, 'lpl_weight': 0.1932696443440854, 'ratio': 0.2971568698605647, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 23 with value: 0.8063043107111474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9122, F1=0.8040, Recall=0.8545, Precision=0.7592\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102113648.csv.\n",
      "Average F1 over 5 seeds: 0.8063  0.0055\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1384529700262781, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2950230318692544, margin=0.42390801681284346, lpl_weight=0.15316901869193533\n",
      " - ratio=0.49709522205244494, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3845, LPL: 1.3863, Contrastive: 0.2033\n",
      "Epoch 50, Loss: 0.2856, LPL: 1.3863, Contrastive: 0.0865\n",
      "Epoch 100, Loss: 0.2846, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 150, Loss: 0.2843, LPL: 1.3863, Contrastive: 0.0850\n",
      "Epoch 200, Loss: 0.2841, LPL: 1.3863, Contrastive: 0.0848\n",
      " - Metrics: Accuracy=0.8524, F1=0.7249, Recall=0.9230, Precision=0.5969\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1384529700262781, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2950230318692544, margin=0.42390801681284346, lpl_weight=0.15316901869193533\n",
      " - ratio=0.49709522205244494, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3845, LPL: 1.3863, Contrastive: 0.2033\n",
      "Epoch 50, Loss: 0.2856, LPL: 1.3863, Contrastive: 0.0865\n",
      "Epoch 100, Loss: 0.2846, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 150, Loss: 0.2843, LPL: 1.3863, Contrastive: 0.0850\n",
      "Epoch 200, Loss: 0.2841, LPL: 1.3863, Contrastive: 0.0848\n",
      " - Metrics: Accuracy=0.8473, F1=0.7146, Recall=0.9073, Precision=0.5894\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1384529700262781, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2950230318692544, margin=0.42390801681284346, lpl_weight=0.15316901869193533\n",
      " - ratio=0.49709522205244494, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3845, LPL: 1.3863, Contrastive: 0.2033\n",
      "Epoch 50, Loss: 0.2856, LPL: 1.3863, Contrastive: 0.0865\n",
      "Epoch 100, Loss: 0.2846, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 150, Loss: 0.2843, LPL: 1.3863, Contrastive: 0.0850\n",
      "Epoch 200, Loss: 0.2841, LPL: 1.3863, Contrastive: 0.0848\n",
      " - Metrics: Accuracy=0.8593, F1=0.7335, Recall=0.9187, Precision=0.6104\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1384529700262781, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2950230318692544, margin=0.42390801681284346, lpl_weight=0.15316901869193533\n",
      " - ratio=0.49709522205244494, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3845, LPL: 1.3863, Contrastive: 0.2033\n",
      "Epoch 50, Loss: 0.2856, LPL: 1.3863, Contrastive: 0.0865\n",
      "Epoch 100, Loss: 0.2846, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 150, Loss: 0.2843, LPL: 1.3863, Contrastive: 0.0850\n",
      "Epoch 200, Loss: 0.2841, LPL: 1.3863, Contrastive: 0.0847\n",
      " - Metrics: Accuracy=0.8647, F1=0.7393, Recall=0.9101, Precision=0.6224\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1384529700262781, K=23, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2950230318692544, margin=0.42390801681284346, lpl_weight=0.15316901869193533\n",
      " - ratio=0.49709522205244494, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3845, LPL: 1.3863, Contrastive: 0.2033\n",
      "Epoch 50, Loss: 0.2856, LPL: 1.3863, Contrastive: 0.0865\n",
      "Epoch 100, Loss: 0.2846, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 150, Loss: 0.2843, LPL: 1.3863, Contrastive: 0.0850\n",
      "Epoch 200, Loss: 0.2841, LPL: 1.3863, Contrastive: 0.0847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:41:17,904] Trial 24 finished with value: 0.7301101452524452 and parameters: {'alpha': 0.1384529700262781, 'K': 23, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.2950230318692544, 'margin': 0.42390801681284346, 'lpl_weight': 0.15316901869193533, 'ratio': 0.49709522205244494, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 23 with value: 0.8063043107111474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8644, F1=0.7382, Recall=0.9073, Precision=0.6223\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102113908.csv.\n",
      "Average F1 over 5 seeds: 0.7301  0.0093\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.13982967646739755, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14748215708350057, margin=0.2480690826042764, lpl_weight=0.10138746238251836\n",
      " - ratio=0.22787844177769528, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3200, LPL: 1.3863, Contrastive: 0.1997\n",
      "Epoch 50, Loss: 0.2718, LPL: 1.3863, Contrastive: 0.1461\n",
      "Epoch 100, Loss: 0.2707, LPL: 1.3863, Contrastive: 0.1448\n",
      "Epoch 150, Loss: 0.2702, LPL: 1.3863, Contrastive: 0.1442\n",
      "Epoch 200, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 250, Loss: 0.2698, LPL: 1.3863, Contrastive: 0.1438\n",
      " - Metrics: Accuracy=0.9219, F1=0.8192, Recall=0.8402, Precision=0.7992\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.13982967646739755, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14748215708350057, margin=0.2480690826042764, lpl_weight=0.10138746238251836\n",
      " - ratio=0.22787844177769528, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3200, LPL: 1.3863, Contrastive: 0.1997\n",
      "Epoch 50, Loss: 0.2718, LPL: 1.3863, Contrastive: 0.1461\n",
      "Epoch 100, Loss: 0.2707, LPL: 1.3863, Contrastive: 0.1448\n",
      "Epoch 150, Loss: 0.2702, LPL: 1.3863, Contrastive: 0.1442\n",
      "Epoch 200, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 250, Loss: 0.2698, LPL: 1.3863, Contrastive: 0.1438\n",
      " - Metrics: Accuracy=0.9173, F1=0.8105, Recall=0.8388, Precision=0.7840\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.13982967646739755, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14748215708350057, margin=0.2480690826042764, lpl_weight=0.10138746238251836\n",
      " - ratio=0.22787844177769528, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3200, LPL: 1.3863, Contrastive: 0.1997\n",
      "Epoch 50, Loss: 0.2718, LPL: 1.3863, Contrastive: 0.1461\n",
      "Epoch 100, Loss: 0.2707, LPL: 1.3863, Contrastive: 0.1448\n",
      "Epoch 150, Loss: 0.2702, LPL: 1.3863, Contrastive: 0.1443\n",
      "Epoch 200, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1439\n",
      " - Metrics: Accuracy=0.9209, F1=0.8182, Recall=0.8445, Precision=0.7936\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.13982967646739755, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14748215708350057, margin=0.2480690826042764, lpl_weight=0.10138746238251836\n",
      " - ratio=0.22787844177769528, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3200, LPL: 1.3863, Contrastive: 0.1997\n",
      "Epoch 50, Loss: 0.2718, LPL: 1.3863, Contrastive: 0.1461\n",
      "Epoch 100, Loss: 0.2707, LPL: 1.3863, Contrastive: 0.1448\n",
      "Epoch 150, Loss: 0.2702, LPL: 1.3863, Contrastive: 0.1442\n",
      "Epoch 200, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 250, Loss: 0.2698, LPL: 1.3863, Contrastive: 0.1438\n",
      " - Metrics: Accuracy=0.9209, F1=0.8175, Recall=0.8402, Precision=0.7959\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.13982967646739755, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14748215708350057, margin=0.2480690826042764, lpl_weight=0.10138746238251836\n",
      " - ratio=0.22787844177769528, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3200, LPL: 1.3863, Contrastive: 0.1997\n",
      "Epoch 50, Loss: 0.2718, LPL: 1.3863, Contrastive: 0.1461\n",
      "Epoch 100, Loss: 0.2707, LPL: 1.3863, Contrastive: 0.1448\n",
      "Epoch 150, Loss: 0.2702, LPL: 1.3863, Contrastive: 0.1443\n",
      "Epoch 200, Loss: 0.2699, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 250, Loss: 0.2698, LPL: 1.3863, Contrastive: 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:43:40,525] Trial 25 finished with value: 0.8157543662920445 and parameters: {'alpha': 0.13982967646739755, 'K': 25, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.14748215708350057, 'margin': 0.2480690826042764, 'lpl_weight': 0.10138746238251836, 'ratio': 0.22787844177769528, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 25 with value: 0.8157543662920445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9194, F1=0.8134, Recall=0.8331, Precision=0.7946\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102114117.csv.\n",
      "Average F1 over 5 seeds: 0.8158  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.11025431888285023, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14575535998730102, margin=0.2548508783226556, lpl_weight=0.11163681281512958\n",
      " - ratio=0.22412167714856937, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3050, LPL: 1.3863, Contrastive: 0.1691\n",
      "Epoch 50, Loss: 0.2809, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 100, Loss: 0.2807, LPL: 1.3863, Contrastive: 0.1417\n",
      " - Metrics: Accuracy=0.9002, F1=0.7608, Recall=0.7532, Precision=0.7686\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.11025431888285023, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14575535998730102, margin=0.2548508783226556, lpl_weight=0.11163681281512958\n",
      " - ratio=0.22412167714856937, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3050, LPL: 1.3863, Contrastive: 0.1691\n",
      "Epoch 50, Loss: 0.2809, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 100, Loss: 0.2807, LPL: 1.3863, Contrastive: 0.1417\n",
      " - Metrics: Accuracy=0.9059, F1=0.7662, Recall=0.7318, Precision=0.8041\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.11025431888285023, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14575535998730102, margin=0.2548508783226556, lpl_weight=0.11163681281512958\n",
      " - ratio=0.22412167714856937, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3050, LPL: 1.3863, Contrastive: 0.1691\n",
      "Epoch 50, Loss: 0.2809, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 100, Loss: 0.2807, LPL: 1.3863, Contrastive: 0.1417\n",
      " - Metrics: Accuracy=0.9083, F1=0.7746, Recall=0.7475, Precision=0.8037\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.11025431888285023, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14575535998730102, margin=0.2548508783226556, lpl_weight=0.11163681281512958\n",
      " - ratio=0.22412167714856937, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3050, LPL: 1.3863, Contrastive: 0.1691\n",
      "Epoch 50, Loss: 0.2809, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 100, Loss: 0.2807, LPL: 1.3863, Contrastive: 0.1417\n",
      " - Metrics: Accuracy=0.9092, F1=0.7766, Recall=0.7489, Precision=0.8065\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.11025431888285023, K=25, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.14575535998730102, margin=0.2548508783226556, lpl_weight=0.11163681281512958\n",
      " - ratio=0.22412167714856937, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3050, LPL: 1.3863, Contrastive: 0.1691\n",
      "Epoch 50, Loss: 0.2809, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 100, Loss: 0.2807, LPL: 1.3863, Contrastive: 0.1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:45:00,248] Trial 26 finished with value: 0.7687042397899179 and parameters: {'alpha': 0.11025431888285023, 'K': 25, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.14575535998730102, 'margin': 0.2548508783226556, 'lpl_weight': 0.11163681281512958, 'ratio': 0.22412167714856937, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 25 with value: 0.8157543662920445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9041, F1=0.7653, Recall=0.7418, Precision=0.7903\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102114340.csv.\n",
      "Average F1 over 5 seeds: 0.7687  0.0060\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1869991012657347, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.19273854980677826, margin=0.24377763947682315, lpl_weight=0.19693265442467472\n",
      " - ratio=0.2610109692783288, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4382, LPL: 1.3863, Contrastive: 0.2056\n",
      "Epoch 50, Loss: 0.3922, LPL: 1.3863, Contrastive: 0.1484\n",
      "Epoch 100, Loss: 0.3908, LPL: 1.3863, Contrastive: 0.1467\n",
      "Epoch 150, Loss: 0.3902, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 200, Loss: 0.3900, LPL: 1.3863, Contrastive: 0.1456\n",
      " - Metrics: Accuracy=0.9173, F1=0.8113, Recall=0.8431, Precision=0.7817\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1869991012657347, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.19273854980677826, margin=0.24377763947682315, lpl_weight=0.19693265442467472\n",
      " - ratio=0.2610109692783288, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4382, LPL: 1.3863, Contrastive: 0.2056\n",
      "Epoch 50, Loss: 0.3922, LPL: 1.3863, Contrastive: 0.1484\n",
      "Epoch 100, Loss: 0.3908, LPL: 1.3863, Contrastive: 0.1467\n",
      "Epoch 150, Loss: 0.3902, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 200, Loss: 0.3900, LPL: 1.3863, Contrastive: 0.1456\n",
      "Epoch 250, Loss: 0.3898, LPL: 1.3863, Contrastive: 0.1454\n",
      " - Metrics: Accuracy=0.9173, F1=0.8113, Recall=0.8431, Precision=0.7817\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1869991012657347, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.19273854980677826, margin=0.24377763947682315, lpl_weight=0.19693265442467472\n",
      " - ratio=0.2610109692783288, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4382, LPL: 1.3863, Contrastive: 0.2056\n",
      "Epoch 50, Loss: 0.3922, LPL: 1.3863, Contrastive: 0.1484\n",
      "Epoch 100, Loss: 0.3909, LPL: 1.3863, Contrastive: 0.1467\n",
      "Epoch 150, Loss: 0.3902, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 200, Loss: 0.3900, LPL: 1.3863, Contrastive: 0.1456\n",
      " - Metrics: Accuracy=0.9146, F1=0.8094, Recall=0.8602, Precision=0.7643\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1869991012657347, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.19273854980677826, margin=0.24377763947682315, lpl_weight=0.19693265442467472\n",
      " - ratio=0.2610109692783288, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4382, LPL: 1.3863, Contrastive: 0.2056\n",
      "Epoch 50, Loss: 0.3922, LPL: 1.3863, Contrastive: 0.1484\n",
      "Epoch 100, Loss: 0.3908, LPL: 1.3863, Contrastive: 0.1467\n",
      "Epoch 150, Loss: 0.3902, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 200, Loss: 0.3900, LPL: 1.3863, Contrastive: 0.1456\n",
      " - Metrics: Accuracy=0.9143, F1=0.8070, Recall=0.8502, Precision=0.7680\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1869991012657347, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.19273854980677826, margin=0.24377763947682315, lpl_weight=0.19693265442467472\n",
      " - ratio=0.2610109692783288, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4382, LPL: 1.3863, Contrastive: 0.2056\n",
      "Epoch 50, Loss: 0.3922, LPL: 1.3863, Contrastive: 0.1484\n",
      "Epoch 100, Loss: 0.3909, LPL: 1.3863, Contrastive: 0.1468\n",
      "Epoch 150, Loss: 0.3902, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 200, Loss: 0.3900, LPL: 1.3863, Contrastive: 0.1456\n",
      "Epoch 250, Loss: 0.3898, LPL: 1.3863, Contrastive: 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:47:17,471] Trial 27 finished with value: 0.8042999239277193 and parameters: {'alpha': 0.1869991012657347, 'K': 22, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.19273854980677826, 'margin': 0.24377763947682315, 'lpl_weight': 0.19693265442467472, 'ratio': 0.2610109692783288, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 25 with value: 0.8157543662920445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9026, F1=0.7826, Recall=0.8317, Precision=0.7389\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102114500.csv.\n",
      "Average F1 over 5 seeds: 0.8043  0.0110\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.17786956405820498, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2021098210373357, margin=0.2208946883800874, lpl_weight=0.20862859067635178\n",
      " - ratio=0.26662248065203864, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4561, LPL: 1.3863, Contrastive: 0.2109\n",
      "Epoch 50, Loss: 0.4138, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.4124, LPL: 1.3863, Contrastive: 0.1557\n",
      "Epoch 150, Loss: 0.4118, LPL: 1.3863, Contrastive: 0.1549\n",
      "Epoch 200, Loss: 0.4116, LPL: 1.3863, Contrastive: 0.1546\n",
      " - Metrics: Accuracy=0.9149, F1=0.8084, Recall=0.8516, Precision=0.7693\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.17786956405820498, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2021098210373357, margin=0.2208946883800874, lpl_weight=0.20862859067635178\n",
      " - ratio=0.26662248065203864, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4561, LPL: 1.3863, Contrastive: 0.2109\n",
      "Epoch 50, Loss: 0.4138, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.4124, LPL: 1.3863, Contrastive: 0.1557\n",
      "Epoch 150, Loss: 0.4119, LPL: 1.3863, Contrastive: 0.1550\n",
      "Epoch 200, Loss: 0.4116, LPL: 1.3863, Contrastive: 0.1546\n",
      "Epoch 250, Loss: 0.4114, LPL: 1.3863, Contrastive: 0.1544\n",
      " - Metrics: Accuracy=0.9077, F1=0.7913, Recall=0.8302, Precision=0.7558\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.17786956405820498, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2021098210373357, margin=0.2208946883800874, lpl_weight=0.20862859067635178\n",
      " - ratio=0.26662248065203864, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4561, LPL: 1.3863, Contrastive: 0.2109\n",
      "Epoch 50, Loss: 0.4138, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.4124, LPL: 1.3863, Contrastive: 0.1557\n",
      "Epoch 150, Loss: 0.4118, LPL: 1.3863, Contrastive: 0.1549\n",
      "Epoch 200, Loss: 0.4115, LPL: 1.3863, Contrastive: 0.1545\n",
      " - Metrics: Accuracy=0.9110, F1=0.7973, Recall=0.8302, Precision=0.7668\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.17786956405820498, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2021098210373357, margin=0.2208946883800874, lpl_weight=0.20862859067635178\n",
      " - ratio=0.26662248065203864, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4561, LPL: 1.3863, Contrastive: 0.2109\n",
      "Epoch 50, Loss: 0.4138, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.4124, LPL: 1.3863, Contrastive: 0.1557\n",
      "Epoch 150, Loss: 0.4119, LPL: 1.3863, Contrastive: 0.1550\n",
      "Epoch 200, Loss: 0.4116, LPL: 1.3863, Contrastive: 0.1546\n",
      " - Metrics: Accuracy=0.9170, F1=0.8099, Recall=0.8388, Precision=0.7830\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.17786956405820498, K=22, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.2021098210373357, margin=0.2208946883800874, lpl_weight=0.20862859067635178\n",
      " - ratio=0.26662248065203864, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4561, LPL: 1.3863, Contrastive: 0.2109\n",
      "Epoch 50, Loss: 0.4138, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.4124, LPL: 1.3863, Contrastive: 0.1557\n",
      "Epoch 150, Loss: 0.4119, LPL: 1.3863, Contrastive: 0.1550\n",
      "Epoch 200, Loss: 0.4116, LPL: 1.3863, Contrastive: 0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:49:33,570] Trial 28 finished with value: 0.8005282910492074 and parameters: {'alpha': 0.17786956405820498, 'K': 22, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.2021098210373357, 'margin': 0.2208946883800874, 'lpl_weight': 0.20862859067635178, 'ratio': 0.26662248065203864, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 25 with value: 0.8157543662920445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9071, F1=0.7958, Recall=0.8588, Precision=0.7414\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102114717.csv.\n",
      "Average F1 over 5 seeds: 0.8005  0.0073\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.20578918993873907, K=21, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.2845884533345012, margin=0.10087538571990955, lpl_weight=0.42645200299408337\n",
      " - ratio=0.30263441835043237, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7356, LPL: 1.3863, Contrastive: 0.2517\n",
      "Epoch 50, Loss: 0.7092, LPL: 1.3863, Contrastive: 0.2057\n",
      "Epoch 100, Loss: 0.7095, LPL: 1.3863, Contrastive: 0.2063\n",
      " - Metrics: Accuracy=0.9074, F1=0.7919, Recall=0.8359, Precision=0.7522\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.20578918993873907, K=21, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.2845884533345012, margin=0.10087538571990955, lpl_weight=0.42645200299408337\n",
      " - ratio=0.30263441835043237, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7356, LPL: 1.3863, Contrastive: 0.2517\n",
      "Epoch 50, Loss: 0.7092, LPL: 1.3863, Contrastive: 0.2057\n",
      "Epoch 100, Loss: 0.7092, LPL: 1.3863, Contrastive: 0.2057\n",
      " - Metrics: Accuracy=0.9119, F1=0.7989, Recall=0.8302, Precision=0.7698\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.20578918993873907, K=21, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.2845884533345012, margin=0.10087538571990955, lpl_weight=0.42645200299408337\n",
      " - ratio=0.30263441835043237, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7356, LPL: 1.3863, Contrastive: 0.2517\n",
      "Epoch 50, Loss: 0.7092, LPL: 1.3863, Contrastive: 0.2057\n",
      " - Metrics: Accuracy=0.9167, F1=0.8067, Recall=0.8245, Precision=0.7896\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.20578918993873907, K=21, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.2845884533345012, margin=0.10087538571990955, lpl_weight=0.42645200299408337\n",
      " - ratio=0.30263441835043237, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7356, LPL: 1.3863, Contrastive: 0.2517\n",
      "Epoch 50, Loss: 0.7092, LPL: 1.3863, Contrastive: 0.2057\n",
      " - Metrics: Accuracy=0.9200, F1=0.8150, Recall=0.8359, Precision=0.7951\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.20578918993873907, K=21, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.2845884533345012, margin=0.10087538571990955, lpl_weight=0.42645200299408337\n",
      " - ratio=0.30263441835043237, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7356, LPL: 1.3863, Contrastive: 0.2517\n",
      "Epoch 50, Loss: 0.7092, LPL: 1.3863, Contrastive: 0.2057\n",
      "Epoch 100, Loss: 0.7093, LPL: 1.3863, Contrastive: 0.2059\n",
      "Epoch 150, Loss: 0.7084, LPL: 1.3863, Contrastive: 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:50:52,888] Trial 29 finished with value: 0.8011488312224515 and parameters: {'alpha': 0.20578918993873907, 'K': 21, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.2845884533345012, 'margin': 0.10087538571990955, 'lpl_weight': 0.42645200299408337, 'ratio': 0.30263441835043237, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 25 with value: 0.8157543662920445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9155, F1=0.7932, Recall=0.7689, Precision=0.8191\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102114933.csv.\n",
      "Average F1 over 5 seeds: 0.8011  0.0087\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10138777677497936, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17510202854805096, margin=0.269721113708765, lpl_weight=0.3032001431601883\n",
      " - ratio=0.24754831504029137, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5371, LPL: 1.3863, Contrastive: 0.1675\n",
      "Epoch 50, Loss: 0.5156, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 100, Loss: 0.5149, LPL: 1.3863, Contrastive: 0.1357\n",
      "Epoch 150, Loss: 0.5146, LPL: 1.3863, Contrastive: 0.1353\n",
      "Epoch 200, Loss: 0.5144, LPL: 1.3863, Contrastive: 0.1350\n",
      "Epoch 250, Loss: 0.5143, LPL: 1.3863, Contrastive: 0.1349\n",
      " - Metrics: Accuracy=0.9231, F1=0.8192, Recall=0.8274, Precision=0.8112\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10138777677497936, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17510202854805096, margin=0.269721113708765, lpl_weight=0.3032001431601883\n",
      " - ratio=0.24754831504029137, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5371, LPL: 1.3863, Contrastive: 0.1675\n",
      "Epoch 50, Loss: 0.5156, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 100, Loss: 0.5149, LPL: 1.3863, Contrastive: 0.1357\n",
      "Epoch 150, Loss: 0.5146, LPL: 1.3863, Contrastive: 0.1353\n",
      "Epoch 200, Loss: 0.5144, LPL: 1.3863, Contrastive: 0.1350\n",
      "Epoch 250, Loss: 0.5143, LPL: 1.3863, Contrastive: 0.1349\n",
      " - Metrics: Accuracy=0.9128, F1=0.7983, Recall=0.8188, Precision=0.7788\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10138777677497936, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17510202854805096, margin=0.269721113708765, lpl_weight=0.3032001431601883\n",
      " - ratio=0.24754831504029137, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5371, LPL: 1.3863, Contrastive: 0.1675\n",
      "Epoch 50, Loss: 0.5156, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 100, Loss: 0.5149, LPL: 1.3863, Contrastive: 0.1357\n",
      "Epoch 150, Loss: 0.5146, LPL: 1.3863, Contrastive: 0.1353\n",
      "Epoch 200, Loss: 0.5144, LPL: 1.3863, Contrastive: 0.1350\n",
      "Epoch 250, Loss: 0.5143, LPL: 1.3863, Contrastive: 0.1349\n",
      " - Metrics: Accuracy=0.9249, F1=0.8247, Recall=0.8388, Precision=0.8110\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10138777677497936, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17510202854805096, margin=0.269721113708765, lpl_weight=0.3032001431601883\n",
      " - ratio=0.24754831504029137, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5371, LPL: 1.3863, Contrastive: 0.1675\n",
      "Epoch 50, Loss: 0.5156, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 100, Loss: 0.5149, LPL: 1.3863, Contrastive: 0.1357\n",
      "Epoch 150, Loss: 0.5146, LPL: 1.3863, Contrastive: 0.1353\n",
      "Epoch 200, Loss: 0.5144, LPL: 1.3863, Contrastive: 0.1351\n",
      "Epoch 250, Loss: 0.5143, LPL: 1.3863, Contrastive: 0.1349\n",
      " - Metrics: Accuracy=0.9219, F1=0.8174, Recall=0.8302, Precision=0.8050\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10138777677497936, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17510202854805096, margin=0.269721113708765, lpl_weight=0.3032001431601883\n",
      " - ratio=0.24754831504029137, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5371, LPL: 1.3863, Contrastive: 0.1675\n",
      "Epoch 50, Loss: 0.5156, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 100, Loss: 0.5149, LPL: 1.3863, Contrastive: 0.1357\n",
      "Epoch 150, Loss: 0.5146, LPL: 1.3863, Contrastive: 0.1353\n",
      "Epoch 200, Loss: 0.5144, LPL: 1.3863, Contrastive: 0.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:53:18,484] Trial 30 finished with value: 0.8122644134393452 and parameters: {'alpha': 0.10138777677497936, 'K': 21, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.17510202854805096, 'margin': 0.269721113708765, 'lpl_weight': 0.3032001431601883, 'ratio': 0.24754831504029137, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 25 with value: 0.8157543662920445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9149, F1=0.8017, Recall=0.8160, Precision=0.7879\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102115052.csv.\n",
      "Average F1 over 5 seeds: 0.8123  0.0103\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10960262606727297, K=22, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17805937652001128, margin=0.25757195347733575, lpl_weight=0.1930494266010275\n",
      " - ratio=0.24785836079053508, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4052, LPL: 1.3863, Contrastive: 0.1705\n",
      "Epoch 50, Loss: 0.3817, LPL: 1.3863, Contrastive: 0.1413\n",
      "Epoch 100, Loss: 0.3808, LPL: 1.3863, Contrastive: 0.1403\n",
      " - Metrics: Accuracy=0.9185, F1=0.8165, Recall=0.8602, Precision=0.7771\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10960262606727297, K=22, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17805937652001128, margin=0.25757195347733575, lpl_weight=0.1930494266010275\n",
      " - ratio=0.24785836079053508, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4052, LPL: 1.3863, Contrastive: 0.1705\n",
      "Epoch 50, Loss: 0.3817, LPL: 1.3863, Contrastive: 0.1413\n",
      "Epoch 100, Loss: 0.3809, LPL: 1.3863, Contrastive: 0.1403\n",
      " - Metrics: Accuracy=0.9191, F1=0.8112, Recall=0.8245, Precision=0.7983\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10960262606727297, K=22, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17805937652001128, margin=0.25757195347733575, lpl_weight=0.1930494266010275\n",
      " - ratio=0.24785836079053508, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4052, LPL: 1.3863, Contrastive: 0.1705\n",
      "Epoch 50, Loss: 0.3817, LPL: 1.3863, Contrastive: 0.1413\n",
      "Epoch 100, Loss: 0.3809, LPL: 1.3863, Contrastive: 0.1403\n",
      "Epoch 150, Loss: 0.3805, LPL: 1.3863, Contrastive: 0.1399\n",
      "Epoch 200, Loss: 0.3802, LPL: 1.3863, Contrastive: 0.1395\n",
      "Epoch 250, Loss: 0.3801, LPL: 1.3863, Contrastive: 0.1394\n",
      " - Metrics: Accuracy=0.9228, F1=0.8209, Recall=0.8402, Precision=0.8025\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10960262606727297, K=22, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17805937652001128, margin=0.25757195347733575, lpl_weight=0.1930494266010275\n",
      " - ratio=0.24785836079053508, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4052, LPL: 1.3863, Contrastive: 0.1705\n",
      "Epoch 50, Loss: 0.3817, LPL: 1.3863, Contrastive: 0.1413\n",
      "Epoch 100, Loss: 0.3809, LPL: 1.3863, Contrastive: 0.1403\n",
      " - Metrics: Accuracy=0.9240, F1=0.8225, Recall=0.8359, Precision=0.8094\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10960262606727297, K=22, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17805937652001128, margin=0.25757195347733575, lpl_weight=0.1930494266010275\n",
      " - ratio=0.24785836079053508, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4052, LPL: 1.3863, Contrastive: 0.1705\n",
      "Epoch 50, Loss: 0.3817, LPL: 1.3863, Contrastive: 0.1413\n",
      "Epoch 100, Loss: 0.3808, LPL: 1.3863, Contrastive: 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:54:58,074] Trial 31 finished with value: 0.819204720319806 and parameters: {'alpha': 0.10960262606727297, 'K': 22, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.17805937652001128, 'margin': 0.25757195347733575, 'lpl_weight': 0.1930494266010275, 'ratio': 0.24785836079053508, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 31 with value: 0.819204720319806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9240, F1=0.8249, Recall=0.8502, Precision=0.8011\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102115318.csv.\n",
      "Average F1 over 5 seeds: 0.8192  0.0048\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1063579332632898, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1676053813555226, margin=0.2858122618622682, lpl_weight=0.3084457723227903\n",
      " - ratio=0.20602044203882403, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5407, LPL: 1.3863, Contrastive: 0.1636\n",
      "Epoch 50, Loss: 0.5183, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 100, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1298\n",
      "Epoch 150, Loss: 0.5171, LPL: 1.3863, Contrastive: 0.1295\n",
      "Epoch 200, Loss: 0.5169, LPL: 1.3863, Contrastive: 0.1291\n",
      "Epoch 250, Loss: 0.5168, LPL: 1.3863, Contrastive: 0.1290\n",
      " - Metrics: Accuracy=0.9252, F1=0.8192, Recall=0.8046, Precision=0.8343\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1063579332632898, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1676053813555226, margin=0.2858122618622682, lpl_weight=0.3084457723227903\n",
      " - ratio=0.20602044203882403, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5407, LPL: 1.3863, Contrastive: 0.1636\n",
      "Epoch 50, Loss: 0.5183, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 100, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1298\n",
      "Epoch 150, Loss: 0.5171, LPL: 1.3863, Contrastive: 0.1295\n",
      " - Metrics: Accuracy=0.9176, F1=0.8040, Recall=0.8017, Precision=0.8063\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1063579332632898, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1676053813555226, margin=0.2858122618622682, lpl_weight=0.3084457723227903\n",
      " - ratio=0.20602044203882403, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5407, LPL: 1.3863, Contrastive: 0.1636\n",
      "Epoch 50, Loss: 0.5183, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 100, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1298\n",
      "Epoch 150, Loss: 0.5172, LPL: 1.3863, Contrastive: 0.1295\n",
      " - Metrics: Accuracy=0.9252, F1=0.8218, Recall=0.8188, Precision=0.8247\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1063579332632898, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1676053813555226, margin=0.2858122618622682, lpl_weight=0.3084457723227903\n",
      " - ratio=0.20602044203882403, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5407, LPL: 1.3863, Contrastive: 0.1636\n",
      "Epoch 50, Loss: 0.5183, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 100, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1298\n",
      "Epoch 150, Loss: 0.5171, LPL: 1.3863, Contrastive: 0.1294\n",
      "Epoch 200, Loss: 0.5170, LPL: 1.3863, Contrastive: 0.1292\n",
      "Epoch 250, Loss: 0.5168, LPL: 1.3863, Contrastive: 0.1290\n",
      " - Metrics: Accuracy=0.9164, F1=0.7965, Recall=0.7760, Precision=0.8180\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1063579332632898, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1676053813555226, margin=0.2858122618622682, lpl_weight=0.3084457723227903\n",
      " - ratio=0.20602044203882403, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5407, LPL: 1.3863, Contrastive: 0.1636\n",
      "Epoch 50, Loss: 0.5183, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 100, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1298\n",
      "Epoch 150, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:56:56,425] Trial 32 finished with value: 0.8134590979083363 and parameters: {'alpha': 0.1063579332632898, 'K': 21, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.1676053813555226, 'margin': 0.2858122618622682, 'lpl_weight': 0.3084457723227903, 'ratio': 0.20602044203882403, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 31 with value: 0.819204720319806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9264, F1=0.8259, Recall=0.8288, Precision=0.8229\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102115458.csv.\n",
      "Average F1 over 5 seeds: 0.8135  0.0113\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10491361206885755, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17046277099940796, margin=0.4907398957427287, lpl_weight=0.2972991700449277\n",
      " - ratio=0.20293636022215358, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 50, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.0675\n",
      "Epoch 100, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.0663\n",
      "Epoch 150, Loss: 0.4585, LPL: 1.3863, Contrastive: 0.0660\n",
      " - Metrics: Accuracy=0.9303, F1=0.8362, Recall=0.8445, Precision=0.8280\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10491361206885755, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17046277099940796, margin=0.4907398957427287, lpl_weight=0.2972991700449277\n",
      " - ratio=0.20293636022215358, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 50, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.0675\n",
      "Epoch 100, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.0663\n",
      "Epoch 150, Loss: 0.4586, LPL: 1.3863, Contrastive: 0.0661\n",
      " - Metrics: Accuracy=0.9264, F1=0.8278, Recall=0.8402, Precision=0.8158\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10491361206885755, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17046277099940796, margin=0.4907398957427287, lpl_weight=0.2972991700449277\n",
      " - ratio=0.20293636022215358, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 50, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.0675\n",
      "Epoch 100, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.0663\n",
      "Epoch 150, Loss: 0.4586, LPL: 1.3863, Contrastive: 0.0660\n",
      " - Metrics: Accuracy=0.9264, F1=0.8293, Recall=0.8488, Precision=0.8106\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10491361206885755, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17046277099940796, margin=0.4907398957427287, lpl_weight=0.2972991700449277\n",
      " - ratio=0.20293636022215358, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 50, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.0675\n",
      "Epoch 100, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.0663\n",
      "Epoch 150, Loss: 0.4585, LPL: 1.3863, Contrastive: 0.0660\n",
      " - Metrics: Accuracy=0.9300, F1=0.8381, Recall=0.8602, Precision=0.8171\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10491361206885755, K=21, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17046277099940796, margin=0.4907398957427287, lpl_weight=0.2972991700449277\n",
      " - ratio=0.20293636022215358, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1420\n",
      "Epoch 50, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.0675\n",
      "Epoch 100, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.0663\n",
      "Epoch 150, Loss: 0.4585, LPL: 1.3863, Contrastive: 0.0660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 11:58:43,416] Trial 33 finished with value: 0.8307767980590525 and parameters: {'alpha': 0.10491361206885755, 'K': 21, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.17046277099940796, 'margin': 0.4907398957427287, 'lpl_weight': 0.2972991700449277, 'ratio': 0.20293636022215358, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 33 with value: 0.8307767980590525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9234, F1=0.8225, Recall=0.8431, Precision=0.8030\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102115656.csv.\n",
      "Average F1 over 5 seeds: 0.8308  0.0057\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.24193863647157607, K=20, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.136346246533623, margin=0.5270300229439633, lpl_weight=0.48859710261302725\n",
      " - ratio=0.20694753500306112, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7078, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 50, Loss: 0.7065, LPL: 1.3863, Contrastive: 0.0570\n",
      "Epoch 100, Loss: 0.7063, LPL: 1.3863, Contrastive: 0.0567\n",
      " - Metrics: Accuracy=0.8500, F1=0.7007, Recall=0.8331, Precision=0.6046\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.24193863647157607, K=20, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.136346246533623, margin=0.5270300229439633, lpl_weight=0.48859710261302725\n",
      " - ratio=0.20694753500306112, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7078, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 50, Loss: 0.7065, LPL: 1.3863, Contrastive: 0.0570\n",
      "Epoch 100, Loss: 0.7063, LPL: 1.3863, Contrastive: 0.0567\n",
      "Epoch 150, Loss: 0.7063, LPL: 1.3863, Contrastive: 0.0566\n",
      " - Metrics: Accuracy=0.8470, F1=0.6947, Recall=0.8260, Precision=0.5994\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.24193863647157607, K=20, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.136346246533623, margin=0.5270300229439633, lpl_weight=0.48859710261302725\n",
      " - ratio=0.20694753500306112, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7078, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 50, Loss: 0.7065, LPL: 1.3863, Contrastive: 0.0570\n",
      "Epoch 100, Loss: 0.7063, LPL: 1.3863, Contrastive: 0.0567\n",
      " - Metrics: Accuracy=0.8452, F1=0.6911, Recall=0.8217, Precision=0.5963\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.24193863647157607, K=20, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.136346246533623, margin=0.5270300229439633, lpl_weight=0.48859710261302725\n",
      " - ratio=0.20694753500306112, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7078, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 50, Loss: 0.7065, LPL: 1.3863, Contrastive: 0.0570\n",
      "Epoch 100, Loss: 0.7063, LPL: 1.3863, Contrastive: 0.0567\n",
      " - Metrics: Accuracy=0.8512, F1=0.7031, Recall=0.8359, Precision=0.6066\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.24193863647157607, K=20, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.136346246533623, margin=0.5270300229439633, lpl_weight=0.48859710261302725\n",
      " - ratio=0.20694753500306112, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7078, LPL: 1.3863, Contrastive: 0.0596\n",
      "Epoch 50, Loss: 0.7065, LPL: 1.3863, Contrastive: 0.0570\n",
      "Epoch 100, Loss: 0.7063, LPL: 1.3863, Contrastive: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:00:12,310] Trial 34 finished with value: 0.6977804439112177 and parameters: {'alpha': 0.24193863647157607, 'K': 20, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.136346246533623, 'margin': 0.5270300229439633, 'lpl_weight': 0.48859710261302725, 'ratio': 0.20694753500306112, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 33 with value: 0.8307767980590525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8494, F1=0.6995, Recall=0.8317, Precision=0.6035\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102115843.csv.\n",
      "Average F1 over 5 seeds: 0.6978  0.0043\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.387014473395099, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2220978599815331, margin=0.3619588028541399, lpl_weight=0.27607995571965294\n",
      " - ratio=0.19701207001328297, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5106, LPL: 1.3863, Contrastive: 0.1767\n",
      "Epoch 50, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.4577, LPL: 1.3863, Contrastive: 0.1035\n",
      "Epoch 150, Loss: 0.4575, LPL: 1.3863, Contrastive: 0.1032\n",
      "Epoch 200, Loss: 0.4573, LPL: 1.3863, Contrastive: 0.1030\n",
      " - Metrics: Accuracy=0.9252, F1=0.8218, Recall=0.8188, Precision=0.8247\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.387014473395099, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2220978599815331, margin=0.3619588028541399, lpl_weight=0.27607995571965294\n",
      " - ratio=0.19701207001328297, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5106, LPL: 1.3863, Contrastive: 0.1767\n",
      "Epoch 50, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.4577, LPL: 1.3863, Contrastive: 0.1035\n",
      "Epoch 150, Loss: 0.4574, LPL: 1.3863, Contrastive: 0.1032\n",
      " - Metrics: Accuracy=0.9237, F1=0.8219, Recall=0.8359, Precision=0.8083\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.387014473395099, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2220978599815331, margin=0.3619588028541399, lpl_weight=0.27607995571965294\n",
      " - ratio=0.19701207001328297, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5106, LPL: 1.3863, Contrastive: 0.1767\n",
      "Epoch 50, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.4577, LPL: 1.3863, Contrastive: 0.1035\n",
      "Epoch 150, Loss: 0.4574, LPL: 1.3863, Contrastive: 0.1032\n",
      " - Metrics: Accuracy=0.9309, F1=0.8394, Recall=0.8573, Precision=0.8222\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.387014473395099, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2220978599815331, margin=0.3619588028541399, lpl_weight=0.27607995571965294\n",
      " - ratio=0.19701207001328297, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5106, LPL: 1.3863, Contrastive: 0.1767\n",
      "Epoch 50, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.4577, LPL: 1.3863, Contrastive: 0.1035\n",
      "Epoch 150, Loss: 0.4574, LPL: 1.3863, Contrastive: 0.1032\n",
      " - Metrics: Accuracy=0.9288, F1=0.8335, Recall=0.8459, Precision=0.8213\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.387014473395099, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2220978599815331, margin=0.3619588028541399, lpl_weight=0.27607995571965294\n",
      " - ratio=0.19701207001328297, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5106, LPL: 1.3863, Contrastive: 0.1767\n",
      "Epoch 50, Loss: 0.4587, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.4577, LPL: 1.3863, Contrastive: 0.1035\n",
      "Epoch 150, Loss: 0.4575, LPL: 1.3863, Contrastive: 0.1032\n",
      "Epoch 200, Loss: 0.4573, LPL: 1.3863, Contrastive: 0.1030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:02:42,656] Trial 35 finished with value: 0.8290661089565834 and parameters: {'alpha': 0.387014473395099, 'K': 20, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': None, 'dropout': 0.2220978599815331, 'margin': 0.3619588028541399, 'lpl_weight': 0.27607995571965294, 'ratio': 0.19701207001328297, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 33 with value: 0.8307767980590525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9273, F1=0.8289, Recall=0.8359, Precision=0.8219\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102120012.csv.\n",
      "Average F1 over 5 seeds: 0.8291  0.0068\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.39940075425504606, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22529263509404096, margin=0.4764739242394729, lpl_weight=0.2534116361666626\n",
      " - ratio=0.14926972238840927, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4135, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.4035, LPL: 1.3863, Contrastive: 0.0699\n",
      "Epoch 100, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.0694\n",
      " - Metrics: Accuracy=0.9255, F1=0.8063, Recall=0.7361, Precision=0.8912\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.39940075425504606, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22529263509404096, margin=0.4764739242394729, lpl_weight=0.2534116361666626\n",
      " - ratio=0.14926972238840927, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4135, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.4035, LPL: 1.3863, Contrastive: 0.0699\n",
      "Epoch 100, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.0694\n",
      " - Metrics: Accuracy=0.9258, F1=0.8069, Recall=0.7361, Precision=0.8927\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.39940075425504606, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22529263509404096, margin=0.4764739242394729, lpl_weight=0.2534116361666626\n",
      " - ratio=0.14926972238840927, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4135, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.4035, LPL: 1.3863, Contrastive: 0.0699\n",
      "Epoch 100, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.0694\n",
      " - Metrics: Accuracy=0.9261, F1=0.8069, Recall=0.7332, Precision=0.8970\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.39940075425504606, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22529263509404096, margin=0.4764739242394729, lpl_weight=0.2534116361666626\n",
      " - ratio=0.14926972238840927, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4135, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.4035, LPL: 1.3863, Contrastive: 0.0699\n",
      "Epoch 100, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.0694\n",
      " - Metrics: Accuracy=0.9222, F1=0.7962, Recall=0.7218, Precision=0.8877\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.39940075425504606, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22529263509404096, margin=0.4764739242394729, lpl_weight=0.2534116361666626\n",
      " - ratio=0.14926972238840927, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4135, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.4035, LPL: 1.3863, Contrastive: 0.0699\n",
      "Epoch 100, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.0694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:04:31,160] Trial 36 finished with value: 0.8055163908903115 and parameters: {'alpha': 0.39940075425504606, 'K': 18, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.22529263509404096, 'margin': 0.4764739242394729, 'lpl_weight': 0.2534116361666626, 'ratio': 0.14926972238840927, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 33 with value: 0.8307767980590525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9279, F1=0.8113, Recall=0.7361, Precision=0.9037\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102120242.csv.\n",
      "Average F1 over 5 seeds: 0.8055  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8189165283463038, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1302767659963768, margin=0.35552163488673744, lpl_weight=0.482062871239758\n",
      " - ratio=0.2021001013783669, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7542, LPL: 1.3863, Contrastive: 0.1659\n",
      "Epoch 50, Loss: 0.7239, LPL: 1.3863, Contrastive: 0.1074\n",
      "Epoch 100, Loss: 0.7229, LPL: 1.3863, Contrastive: 0.1055\n",
      "Epoch 150, Loss: 0.7232, LPL: 1.3863, Contrastive: 0.1061\n",
      " - Metrics: Accuracy=0.8813, F1=0.7610, Recall=0.8973, Precision=0.6607\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8189165283463038, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1302767659963768, margin=0.35552163488673744, lpl_weight=0.482062871239758\n",
      " - ratio=0.2021001013783669, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7542, LPL: 1.3863, Contrastive: 0.1659\n",
      "Epoch 50, Loss: 0.7239, LPL: 1.3863, Contrastive: 0.1074\n",
      "Epoch 100, Loss: 0.7229, LPL: 1.3863, Contrastive: 0.1055\n",
      "Epoch 150, Loss: 0.7261, LPL: 1.3863, Contrastive: 0.1117\n",
      " - Metrics: Accuracy=0.8777, F1=0.7538, Recall=0.8887, Precision=0.6544\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8189165283463038, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1302767659963768, margin=0.35552163488673744, lpl_weight=0.482062871239758\n",
      " - ratio=0.2021001013783669, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7542, LPL: 1.3863, Contrastive: 0.1659\n",
      "Epoch 50, Loss: 0.7239, LPL: 1.3863, Contrastive: 0.1074\n",
      "Epoch 100, Loss: 0.7229, LPL: 1.3863, Contrastive: 0.1056\n",
      " - Metrics: Accuracy=0.8807, F1=0.7598, Recall=0.8959, Precision=0.6597\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8189165283463038, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1302767659963768, margin=0.35552163488673744, lpl_weight=0.482062871239758\n",
      " - ratio=0.2021001013783669, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7542, LPL: 1.3863, Contrastive: 0.1659\n",
      "Epoch 50, Loss: 0.7239, LPL: 1.3863, Contrastive: 0.1074\n",
      "Epoch 100, Loss: 0.7229, LPL: 1.3863, Contrastive: 0.1056\n",
      " - Metrics: Accuracy=0.8747, F1=0.7477, Recall=0.8816, Precision=0.6492\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8189165283463038, K=20, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1302767659963768, margin=0.35552163488673744, lpl_weight=0.482062871239758\n",
      " - ratio=0.2021001013783669, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7542, LPL: 1.3863, Contrastive: 0.1659\n",
      "Epoch 50, Loss: 0.7239, LPL: 1.3863, Contrastive: 0.1074\n",
      "Epoch 100, Loss: 0.7229, LPL: 1.3863, Contrastive: 0.1055\n",
      "Epoch 150, Loss: 0.7229, LPL: 1.3863, Contrastive: 0.1055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:06:31,466] Trial 37 finished with value: 0.7549909255898367 and parameters: {'alpha': 0.8189165283463038, 'K': 20, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': None, 'dropout': 0.1302767659963768, 'margin': 0.35552163488673744, 'lpl_weight': 0.482062871239758, 'ratio': 0.2021001013783669, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 33 with value: 0.8307767980590525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8771, F1=0.7526, Recall=0.8873, Precision=0.6534\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102120431.csv.\n",
      "Average F1 over 5 seeds: 0.7550  0.0049\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.37723710900430574, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2653392372389523, margin=0.5902726074174123, lpl_weight=0.5979423122947367\n",
      " - ratio=0.13594889546650762, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9006, LPL: 1.3863, Contrastive: 0.1782\n",
      " - Metrics: Accuracy=0.9348, F1=0.8406, Recall=0.8160, Precision=0.8667\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.37723710900430574, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2653392372389523, margin=0.5902726074174123, lpl_weight=0.5979423122947367\n",
      " - ratio=0.13594889546650762, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9006, LPL: 1.3863, Contrastive: 0.1782\n",
      " - Metrics: Accuracy=0.9384, F1=0.8498, Recall=0.8274, Precision=0.8735\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.37723710900430574, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2653392372389523, margin=0.5902726074174123, lpl_weight=0.5979423122947367\n",
      " - ratio=0.13594889546650762, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9006, LPL: 1.3863, Contrastive: 0.1782\n",
      " - Metrics: Accuracy=0.9330, F1=0.8378, Recall=0.8217, Precision=0.8546\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.37723710900430574, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2653392372389523, margin=0.5902726074174123, lpl_weight=0.5979423122947367\n",
      " - ratio=0.13594889546650762, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9006, LPL: 1.3863, Contrastive: 0.1782\n",
      " - Metrics: Accuracy=0.9351, F1=0.8421, Recall=0.8217, Precision=0.8636\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.37723710900430574, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2653392372389523, margin=0.5902726074174123, lpl_weight=0.5979423122947367\n",
      " - ratio=0.13594889546650762, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9006, LPL: 1.3863, Contrastive: 0.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:07:13,670] Trial 38 finished with value: 0.8455717941380525 and parameters: {'alpha': 0.37723710900430574, 'K': 20, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2653392372389523, 'margin': 0.5902726074174123, 'lpl_weight': 0.5979423122947367, 'ratio': 0.13594889546650762, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9414, F1=0.8576, Recall=0.8374, Precision=0.8787\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102120631.csv.\n",
      "Average F1 over 5 seeds: 0.8456  0.0072\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3827488477198658, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2668145888984134, margin=0.5967532564352089, lpl_weight=0.6072319467867382\n",
      " - ratio=0.14803480290196933, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8719, LPL: 1.3863, Contrastive: 0.0768\n",
      "Epoch 50, Loss: 0.8583, LPL: 1.3863, Contrastive: 0.0419\n",
      "Epoch 100, Loss: 0.8580, LPL: 1.3863, Contrastive: 0.0413\n",
      " - Metrics: Accuracy=0.9092, F1=0.7976, Recall=0.8488, Precision=0.7522\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3827488477198658, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2668145888984134, margin=0.5967532564352089, lpl_weight=0.6072319467867382\n",
      " - ratio=0.14803480290196933, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8719, LPL: 1.3863, Contrastive: 0.0768\n",
      "Epoch 50, Loss: 0.8583, LPL: 1.3863, Contrastive: 0.0419\n",
      "Epoch 100, Loss: 0.8580, LPL: 1.3863, Contrastive: 0.0413\n",
      "Epoch 150, Loss: 0.8580, LPL: 1.3863, Contrastive: 0.0412\n",
      "Epoch 200, Loss: 0.8580, LPL: 1.3863, Contrastive: 0.0411\n",
      " - Metrics: Accuracy=0.9062, F1=0.7909, Recall=0.8417, Precision=0.7459\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3827488477198658, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2668145888984134, margin=0.5967532564352089, lpl_weight=0.6072319467867382\n",
      " - ratio=0.14803480290196933, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8719, LPL: 1.3863, Contrastive: 0.0768\n",
      "Epoch 50, Loss: 0.8583, LPL: 1.3863, Contrastive: 0.0419\n",
      "Epoch 100, Loss: 0.8580, LPL: 1.3863, Contrastive: 0.0413\n",
      " - Metrics: Accuracy=0.8996, F1=0.7761, Recall=0.8260, Precision=0.7320\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3827488477198658, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2668145888984134, margin=0.5967532564352089, lpl_weight=0.6072319467867382\n",
      " - ratio=0.14803480290196933, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8719, LPL: 1.3863, Contrastive: 0.0768\n",
      "Epoch 50, Loss: 0.8583, LPL: 1.3863, Contrastive: 0.0419\n",
      "Epoch 100, Loss: 0.8580, LPL: 1.3863, Contrastive: 0.0413\n",
      " - Metrics: Accuracy=0.9026, F1=0.7828, Recall=0.8331, Precision=0.7383\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3827488477198658, K=20, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2668145888984134, margin=0.5967532564352089, lpl_weight=0.6072319467867382\n",
      " - ratio=0.14803480290196933, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8719, LPL: 1.3863, Contrastive: 0.0768\n",
      "Epoch 50, Loss: 0.8583, LPL: 1.3863, Contrastive: 0.0419\n",
      "Epoch 100, Loss: 0.8580, LPL: 1.3863, Contrastive: 0.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:09:13,393] Trial 39 finished with value: 0.7876675603217158 and parameters: {'alpha': 0.3827488477198658, 'K': 20, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2668145888984134, 'margin': 0.5967532564352089, 'lpl_weight': 0.6072319467867382, 'ratio': 0.14803480290196933, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9062, F1=0.7909, Recall=0.8417, Precision=0.7459\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102120713.csv.\n",
      "Average F1 over 5 seeds: 0.7877  0.0074\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.48798505560872657, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22164347556664132, margin=0.4869392966565871, lpl_weight=0.5417565638421659\n",
      " - ratio=0.12787660006223134, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8297, LPL: 1.3863, Contrastive: 0.1716\n",
      "Epoch 50, Loss: 0.7824, LPL: 1.3863, Contrastive: 0.0685\n",
      "Epoch 100, Loss: 0.7818, LPL: 1.3863, Contrastive: 0.0672\n",
      "Epoch 150, Loss: 0.7817, LPL: 1.3863, Contrastive: 0.0669\n",
      "Epoch 200, Loss: 0.7816, LPL: 1.3863, Contrastive: 0.0667\n",
      "Epoch 250, Loss: 0.7816, LPL: 1.3863, Contrastive: 0.0667\n",
      " - Metrics: Accuracy=0.9369, F1=0.8416, Recall=0.7960, Precision=0.8928\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.48798505560872657, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22164347556664132, margin=0.4869392966565871, lpl_weight=0.5417565638421659\n",
      " - ratio=0.12787660006223134, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8297, LPL: 1.3863, Contrastive: 0.1716\n",
      "Epoch 50, Loss: 0.7824, LPL: 1.3863, Contrastive: 0.0685\n",
      "Epoch 100, Loss: 0.7818, LPL: 1.3863, Contrastive: 0.0672\n",
      "Epoch 150, Loss: 0.7817, LPL: 1.3863, Contrastive: 0.0669\n",
      "Epoch 200, Loss: 0.7816, LPL: 1.3863, Contrastive: 0.0667\n",
      " - Metrics: Accuracy=0.9333, F1=0.8351, Recall=0.8017, Precision=0.8713\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.48798505560872657, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22164347556664132, margin=0.4869392966565871, lpl_weight=0.5417565638421659\n",
      " - ratio=0.12787660006223134, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8297, LPL: 1.3863, Contrastive: 0.1716\n",
      "Epoch 50, Loss: 0.7824, LPL: 1.3863, Contrastive: 0.0685\n",
      "Epoch 100, Loss: 0.7818, LPL: 1.3863, Contrastive: 0.0672\n",
      "Epoch 150, Loss: 0.7817, LPL: 1.3863, Contrastive: 0.0669\n",
      "Epoch 200, Loss: 0.7816, LPL: 1.3863, Contrastive: 0.0667\n",
      " - Metrics: Accuracy=0.9345, F1=0.8376, Recall=0.8017, Precision=0.8768\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.48798505560872657, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22164347556664132, margin=0.4869392966565871, lpl_weight=0.5417565638421659\n",
      " - ratio=0.12787660006223134, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8297, LPL: 1.3863, Contrastive: 0.1716\n",
      "Epoch 50, Loss: 0.7824, LPL: 1.3863, Contrastive: 0.0685\n",
      "Epoch 100, Loss: 0.7818, LPL: 1.3863, Contrastive: 0.0672\n",
      "Epoch 150, Loss: 0.7817, LPL: 1.3863, Contrastive: 0.0669\n",
      "Epoch 200, Loss: 0.7816, LPL: 1.3863, Contrastive: 0.0667\n",
      " - Metrics: Accuracy=0.9333, F1=0.8348, Recall=0.8003, Precision=0.8725\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.48798505560872657, K=18, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22164347556664132, margin=0.4869392966565871, lpl_weight=0.5417565638421659\n",
      " - ratio=0.12787660006223134, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8297, LPL: 1.3863, Contrastive: 0.1716\n",
      "Epoch 50, Loss: 0.7824, LPL: 1.3863, Contrastive: 0.0685\n",
      "Epoch 100, Loss: 0.7818, LPL: 1.3863, Contrastive: 0.0672\n",
      "Epoch 150, Loss: 0.7817, LPL: 1.3863, Contrastive: 0.0669\n",
      "Epoch 200, Loss: 0.7816, LPL: 1.3863, Contrastive: 0.0667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:12:04,341] Trial 40 finished with value: 0.8353726470901975 and parameters: {'alpha': 0.48798505560872657, 'K': 18, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.22164347556664132, 'margin': 0.4869392966565871, 'lpl_weight': 0.5417565638421659, 'ratio': 0.12787660006223134, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9300, F1=0.8278, Recall=0.7989, Precision=0.8589\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102120913.csv.\n",
      "Average F1 over 5 seeds: 0.8354  0.0045\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5029548569060279, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2197796869284586, margin=0.4799782917359079, lpl_weight=0.5593035766759308\n",
      " - ratio=0.128396082406431, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8509, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.0703\n",
      "Epoch 100, Loss: 0.8058, LPL: 1.3863, Contrastive: 0.0690\n",
      "Epoch 150, Loss: 0.8056, LPL: 1.3863, Contrastive: 0.0687\n",
      "Epoch 200, Loss: 0.8055, LPL: 1.3863, Contrastive: 0.0685\n",
      " - Metrics: Accuracy=0.9339, F1=0.8333, Recall=0.7846, Precision=0.8885\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5029548569060279, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2197796869284586, margin=0.4799782917359079, lpl_weight=0.5593035766759308\n",
      " - ratio=0.128396082406431, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8509, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.0703\n",
      "Epoch 100, Loss: 0.8058, LPL: 1.3863, Contrastive: 0.0690\n",
      "Epoch 150, Loss: 0.8057, LPL: 1.3863, Contrastive: 0.0688\n",
      " - Metrics: Accuracy=0.9273, F1=0.8205, Recall=0.7889, Precision=0.8547\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5029548569060279, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2197796869284586, margin=0.4799782917359079, lpl_weight=0.5593035766759308\n",
      " - ratio=0.128396082406431, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8509, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.0703\n",
      "Epoch 100, Loss: 0.8058, LPL: 1.3863, Contrastive: 0.0690\n",
      "Epoch 150, Loss: 0.8056, LPL: 1.3863, Contrastive: 0.0687\n",
      "Epoch 200, Loss: 0.8055, LPL: 1.3863, Contrastive: 0.0685\n",
      "Epoch 250, Loss: 0.8055, LPL: 1.3863, Contrastive: 0.0685\n",
      " - Metrics: Accuracy=0.9369, F1=0.8414, Recall=0.7946, Precision=0.8941\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5029548569060279, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2197796869284586, margin=0.4799782917359079, lpl_weight=0.5593035766759308\n",
      " - ratio=0.128396082406431, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8509, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.0703\n",
      "Epoch 100, Loss: 0.8058, LPL: 1.3863, Contrastive: 0.0690\n",
      "Epoch 150, Loss: 0.8056, LPL: 1.3863, Contrastive: 0.0687\n",
      "Epoch 200, Loss: 0.8055, LPL: 1.3863, Contrastive: 0.0685\n",
      " - Metrics: Accuracy=0.9267, F1=0.8176, Recall=0.7803, Precision=0.8587\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5029548569060279, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2197796869284586, margin=0.4799782917359079, lpl_weight=0.5593035766759308\n",
      " - ratio=0.128396082406431, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8509, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.0703\n",
      "Epoch 100, Loss: 0.8058, LPL: 1.3863, Contrastive: 0.0690\n",
      "Epoch 150, Loss: 0.8056, LPL: 1.3863, Contrastive: 0.0687\n",
      "Epoch 200, Loss: 0.8055, LPL: 1.3863, Contrastive: 0.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:14:48,088] Trial 41 finished with value: 0.8283196301813621 and parameters: {'alpha': 0.5029548569060279, 'K': 17, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2197796869284586, 'margin': 0.4799782917359079, 'lpl_weight': 0.5593035766759308, 'ratio': 0.128396082406431, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9306, F1=0.8288, Recall=0.7974, Precision=0.8627\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102121204.csv.\n",
      "Average F1 over 5 seeds: 0.8283  0.0086\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5067279356362676, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2200831409516399, margin=0.4897265627267721, lpl_weight=0.574657957263158\n",
      " - ratio=0.1363495181190189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8695, LPL: 1.3863, Contrastive: 0.1713\n",
      "Epoch 50, Loss: 0.8255, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 0.8249, LPL: 1.3863, Contrastive: 0.0665\n",
      "Epoch 150, Loss: 0.8248, LPL: 1.3863, Contrastive: 0.0662\n",
      "Epoch 200, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0660\n",
      "Epoch 250, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0659\n",
      " - Metrics: Accuracy=0.9333, F1=0.8336, Recall=0.7932, Precision=0.8784\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5067279356362676, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2200831409516399, margin=0.4897265627267721, lpl_weight=0.574657957263158\n",
      " - ratio=0.1363495181190189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8695, LPL: 1.3863, Contrastive: 0.1713\n",
      "Epoch 50, Loss: 0.8255, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 0.8249, LPL: 1.3863, Contrastive: 0.0665\n",
      "Epoch 150, Loss: 0.8248, LPL: 1.3863, Contrastive: 0.0662\n",
      "Epoch 200, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0660\n",
      "Epoch 250, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0659\n",
      "Epoch 300, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0659\n",
      " - Metrics: Accuracy=0.9300, F1=0.8239, Recall=0.7775, Precision=0.8762\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5067279356362676, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2200831409516399, margin=0.4897265627267721, lpl_weight=0.574657957263158\n",
      " - ratio=0.1363495181190189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8695, LPL: 1.3863, Contrastive: 0.1713\n",
      "Epoch 50, Loss: 0.8255, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 0.8249, LPL: 1.3863, Contrastive: 0.0665\n",
      "Epoch 150, Loss: 0.8248, LPL: 1.3863, Contrastive: 0.0662\n",
      "Epoch 200, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0660\n",
      " - Metrics: Accuracy=0.9381, F1=0.8476, Recall=0.8174, Precision=0.8802\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5067279356362676, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2200831409516399, margin=0.4897265627267721, lpl_weight=0.574657957263158\n",
      " - ratio=0.1363495181190189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8695, LPL: 1.3863, Contrastive: 0.1713\n",
      "Epoch 50, Loss: 0.8255, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 0.8249, LPL: 1.3863, Contrastive: 0.0665\n",
      "Epoch 150, Loss: 0.8248, LPL: 1.3863, Contrastive: 0.0662\n",
      "Epoch 200, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0660\n",
      "Epoch 250, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0659\n",
      " - Metrics: Accuracy=0.9282, F1=0.8218, Recall=0.7860, Precision=0.8609\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5067279356362676, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2200831409516399, margin=0.4897265627267721, lpl_weight=0.574657957263158\n",
      " - ratio=0.1363495181190189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8695, LPL: 1.3863, Contrastive: 0.1713\n",
      "Epoch 50, Loss: 0.8255, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 0.8249, LPL: 1.3863, Contrastive: 0.0665\n",
      "Epoch 150, Loss: 0.8248, LPL: 1.3863, Contrastive: 0.0662\n",
      "Epoch 200, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0660\n",
      "Epoch 250, Loss: 0.8247, LPL: 1.3863, Contrastive: 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:18:05,300] Trial 42 finished with value: 0.8301681492120899 and parameters: {'alpha': 0.5067279356362676, 'K': 16, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2200831409516399, 'margin': 0.4897265627267721, 'lpl_weight': 0.574657957263158, 'ratio': 0.1363495181190189, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9285, F1=0.8240, Recall=0.7946, Precision=0.8556\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102121448.csv.\n",
      "Average F1 over 5 seeds: 0.8302  0.0096\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5109462882407825, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658933665674341, margin=0.5899924969247312, lpl_weight=0.6776928401240415\n",
      " - ratio=0.13216073678604884, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9969, LPL: 1.3863, Contrastive: 0.1783\n",
      " - Metrics: Accuracy=0.9339, F1=0.8380, Recall=0.8117, Precision=0.8661\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5109462882407825, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658933665674341, margin=0.5899924969247312, lpl_weight=0.6776928401240415\n",
      " - ratio=0.13216073678604884, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9969, LPL: 1.3863, Contrastive: 0.1783\n",
      " - Metrics: Accuracy=0.9360, F1=0.8442, Recall=0.8231, Precision=0.8664\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5109462882407825, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658933665674341, margin=0.5899924969247312, lpl_weight=0.6776928401240415\n",
      " - ratio=0.13216073678604884, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9969, LPL: 1.3863, Contrastive: 0.1783\n",
      " - Metrics: Accuracy=0.9354, F1=0.8430, Recall=0.8231, Precision=0.8638\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5109462882407825, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658933665674341, margin=0.5899924969247312, lpl_weight=0.6776928401240415\n",
      " - ratio=0.13216073678604884, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9969, LPL: 1.3863, Contrastive: 0.1783\n",
      " - Metrics: Accuracy=0.9336, F1=0.8390, Recall=0.8217, Precision=0.8571\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5109462882407825, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658933665674341, margin=0.5899924969247312, lpl_weight=0.6776928401240415\n",
      " - ratio=0.13216073678604884, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9969, LPL: 1.3863, Contrastive: 0.1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:18:48,681] Trial 43 finished with value: 0.8440106826968641 and parameters: {'alpha': 0.5109462882407825, 'K': 16, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2658933665674341, 'margin': 0.5899924969247312, 'lpl_weight': 0.6776928401240415, 'ratio': 0.13216073678604884, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9411, F1=0.8559, Recall=0.8302, Precision=0.8832\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102121805.csv.\n",
      "Average F1 over 5 seeds: 0.8440  0.0064\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5149316859739179, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3316101005488188, margin=0.5902678302967116, lpl_weight=0.6701538072594729\n",
      " - ratio=0.12398126503636044, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9919, LPL: 1.3863, Contrastive: 0.1907\n",
      " - Metrics: Accuracy=0.9348, F1=0.8379, Recall=0.8003, Precision=0.8793\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5149316859739179, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3316101005488188, margin=0.5902678302967116, lpl_weight=0.6701538072594729\n",
      " - ratio=0.12398126503636044, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9919, LPL: 1.3863, Contrastive: 0.1907\n",
      " - Metrics: Accuracy=0.9315, F1=0.8299, Recall=0.7932, Precision=0.8701\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5149316859739179, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3316101005488188, margin=0.5902678302967116, lpl_weight=0.6701538072594729\n",
      " - ratio=0.12398126503636044, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9919, LPL: 1.3863, Contrastive: 0.1907\n",
      " - Metrics: Accuracy=0.9354, F1=0.8401, Recall=0.8060, Precision=0.8773\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5149316859739179, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3316101005488188, margin=0.5902678302967116, lpl_weight=0.6701538072594729\n",
      " - ratio=0.12398126503636044, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9919, LPL: 1.3863, Contrastive: 0.1907\n",
      " - Metrics: Accuracy=0.9306, F1=0.8272, Recall=0.7889, Precision=0.8695\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5149316859739179, K=16, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3316101005488188, margin=0.5902678302967116, lpl_weight=0.6701538072594729\n",
      " - ratio=0.12398126503636044, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9919, LPL: 1.3863, Contrastive: 0.1907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:19:29,044] Trial 44 finished with value: 0.836539393719864 and parameters: {'alpha': 0.5149316859739179, 'K': 16, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3316101005488188, 'margin': 0.5902678302967116, 'lpl_weight': 0.6701538072594729, 'ratio': 0.12398126503636044, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9387, F1=0.8475, Recall=0.8088, Precision=0.8901\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102121848.csv.\n",
      "Average F1 over 5 seeds: 0.8365  0.0073\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6029969797222501, K=16, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31719138991298146, margin=0.5775156526412035, lpl_weight=0.6703502139952839\n",
      " - ratio=0.11938329273541234, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9778, LPL: 1.3863, Contrastive: 0.1471\n",
      " - Metrics: Accuracy=0.9276, F1=0.8200, Recall=0.7832, Precision=0.8605\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6029969797222501, K=16, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31719138991298146, margin=0.5775156526412035, lpl_weight=0.6703502139952839\n",
      " - ratio=0.11938329273541234, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9778, LPL: 1.3863, Contrastive: 0.1471\n",
      " - Metrics: Accuracy=0.9243, F1=0.8122, Recall=0.7775, Precision=0.8502\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6029969797222501, K=16, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31719138991298146, margin=0.5775156526412035, lpl_weight=0.6703502139952839\n",
      " - ratio=0.11938329273541234, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9778, LPL: 1.3863, Contrastive: 0.1471\n",
      " - Metrics: Accuracy=0.9264, F1=0.8143, Recall=0.7660, Precision=0.8689\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6029969797222501, K=16, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31719138991298146, margin=0.5775156526412035, lpl_weight=0.6703502139952839\n",
      " - ratio=0.11938329273541234, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9778, LPL: 1.3863, Contrastive: 0.1471\n",
      " - Metrics: Accuracy=0.9243, F1=0.8114, Recall=0.7732, Precision=0.8535\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6029969797222501, K=16, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31719138991298146, margin=0.5775156526412035, lpl_weight=0.6703502139952839\n",
      " - ratio=0.11938329273541234, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9778, LPL: 1.3863, Contrastive: 0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:20:18,354] Trial 45 finished with value: 0.8167905854014845 and parameters: {'alpha': 0.6029969797222501, 'K': 16, 'layers': 3, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.31719138991298146, 'margin': 0.5775156526412035, 'lpl_weight': 0.6703502139952839, 'ratio': 0.11938329273541234, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9303, F1=0.8261, Recall=0.7860, Precision=0.8705\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102121929.csv.\n",
      "Average F1 over 5 seeds: 0.8168  0.0055\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5192775222968586, K=15, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3304754344702935, margin=0.7065803012152477, lpl_weight=0.8491590039606494\n",
      " - ratio=0.1592120740169638, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2059, LPL: 1.3863, Contrastive: 0.1904\n",
      " - Metrics: Accuracy=0.8765, F1=0.7305, Recall=0.7946, Precision=0.6760\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5192775222968586, K=15, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3304754344702935, margin=0.7065803012152477, lpl_weight=0.8491590039606494\n",
      " - ratio=0.1592120740169638, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2059, LPL: 1.3863, Contrastive: 0.1904\n",
      " - Metrics: Accuracy=0.8747, F1=0.7266, Recall=0.7903, Precision=0.6723\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5192775222968586, K=15, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3304754344702935, margin=0.7065803012152477, lpl_weight=0.8491590039606494\n",
      " - ratio=0.1592120740169638, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2059, LPL: 1.3863, Contrastive: 0.1904\n",
      " - Metrics: Accuracy=0.8741, F1=0.7252, Recall=0.7889, Precision=0.6711\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5192775222968586, K=15, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3304754344702935, margin=0.7065803012152477, lpl_weight=0.8491590039606494\n",
      " - ratio=0.1592120740169638, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2059, LPL: 1.3863, Contrastive: 0.1904\n",
      " - Metrics: Accuracy=0.8807, F1=0.7397, Recall=0.8046, Precision=0.6845\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5192775222968586, K=15, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3304754344702935, margin=0.7065803012152477, lpl_weight=0.8491590039606494\n",
      " - ratio=0.1592120740169638, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2059, LPL: 1.3863, Contrastive: 0.1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:21:00,685] Trial 46 finished with value: 0.7312786885245902 and parameters: {'alpha': 0.5192775222968586, 'K': 15, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3304754344702935, 'margin': 0.7065803012152477, 'lpl_weight': 0.8491590039606494, 'ratio': 0.1592120740169638, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8783, F1=0.7344, Recall=0.7989, Precision=0.6796\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102122018.csv.\n",
      "Average F1 over 5 seeds: 0.7313  0.0053\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5631477156428435, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26326420000616924, margin=0.6411342151624134, lpl_weight=0.6913714369865498\n",
      " - ratio=0.12429482541560301, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0133, LPL: 1.3863, Contrastive: 0.1778\n",
      " - Metrics: Accuracy=0.9267, F1=0.8168, Recall=0.7760, Precision=0.8621\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5631477156428435, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26326420000616924, margin=0.6411342151624134, lpl_weight=0.6913714369865498\n",
      " - ratio=0.12429482541560301, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0133, LPL: 1.3863, Contrastive: 0.1778\n",
      " - Metrics: Accuracy=0.9333, F1=0.8323, Recall=0.7860, Precision=0.8844\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5631477156428435, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26326420000616924, margin=0.6411342151624134, lpl_weight=0.6913714369865498\n",
      " - ratio=0.12429482541560301, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0133, LPL: 1.3863, Contrastive: 0.1778\n",
      " - Metrics: Accuracy=0.9312, F1=0.8297, Recall=0.7960, Precision=0.8665\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5631477156428435, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26326420000616924, margin=0.6411342151624134, lpl_weight=0.6913714369865498\n",
      " - ratio=0.12429482541560301, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0133, LPL: 1.3863, Contrastive: 0.1778\n",
      " - Metrics: Accuracy=0.9333, F1=0.8351, Recall=0.8017, Precision=0.8713\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5631477156428435, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26326420000616924, margin=0.6411342151624134, lpl_weight=0.6913714369865498\n",
      " - ratio=0.12429482541560301, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0133, LPL: 1.3863, Contrastive: 0.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:21:41,558] Trial 47 finished with value: 0.831370008931151 and parameters: {'alpha': 0.5631477156428435, 'K': 17, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.26326420000616924, 'margin': 0.6411342151624134, 'lpl_weight': 0.6913714369865498, 'ratio': 0.12429482541560301, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9375, F1=0.8429, Recall=0.7960, Precision=0.8957\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102122100.csv.\n",
      "Average F1 over 5 seeds: 0.8314  0.0085\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.46143822782565064, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26755087144223877, margin=0.6422637921530638, lpl_weight=0.6800360078051488\n",
      " - ratio=0.11950420241251236, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9998, LPL: 1.3863, Contrastive: 0.1784\n",
      " - Metrics: Accuracy=0.9261, F1=0.8139, Recall=0.7675, Precision=0.8663\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.46143822782565064, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26755087144223877, margin=0.6422637921530638, lpl_weight=0.6800360078051488\n",
      " - ratio=0.11950420241251236, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9998, LPL: 1.3863, Contrastive: 0.1784\n",
      " - Metrics: Accuracy=0.9291, F1=0.8201, Recall=0.7675, Precision=0.8805\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.46143822782565064, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26755087144223877, margin=0.6422637921530638, lpl_weight=0.6800360078051488\n",
      " - ratio=0.11950420241251236, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9998, LPL: 1.3863, Contrastive: 0.1784\n",
      " - Metrics: Accuracy=0.9315, F1=0.8286, Recall=0.7860, Precision=0.8760\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.46143822782565064, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26755087144223877, margin=0.6422637921530638, lpl_weight=0.6800360078051488\n",
      " - ratio=0.11950420241251236, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9998, LPL: 1.3863, Contrastive: 0.1784\n",
      " - Metrics: Accuracy=0.9291, F1=0.8236, Recall=0.7860, Precision=0.8650\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.46143822782565064, K=17, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.26755087144223877, margin=0.6422637921530638, lpl_weight=0.6800360078051488\n",
      " - ratio=0.11950420241251236, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9998, LPL: 1.3863, Contrastive: 0.1784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:22:22,741] Trial 48 finished with value: 0.8243460344734677 and parameters: {'alpha': 0.46143822782565064, 'K': 17, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.26755087144223877, 'margin': 0.6422637921530638, 'lpl_weight': 0.6800360078051488, 'ratio': 0.11950420241251236, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9354, F1=0.8355, Recall=0.7789, Precision=0.9010\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102122141.csv.\n",
      "Average F1 over 5 seeds: 0.8243  0.0073\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5737913294462824, K=18, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658876115886441, margin=0.7344059696913318, lpl_weight=0.7186557437315787\n",
      " - ratio=0.1466624311788599, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0325, LPL: 1.3863, Contrastive: 0.1288\n",
      " - Metrics: Accuracy=0.9068, F1=0.7693, Recall=0.7375, Precision=0.8040\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5737913294462824, K=18, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658876115886441, margin=0.7344059696913318, lpl_weight=0.7186557437315787\n",
      " - ratio=0.1466624311788599, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0325, LPL: 1.3863, Contrastive: 0.1288\n",
      " - Metrics: Accuracy=0.9092, F1=0.7726, Recall=0.7318, Precision=0.8182\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5737913294462824, K=18, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658876115886441, margin=0.7344059696913318, lpl_weight=0.7186557437315787\n",
      " - ratio=0.1466624311788599, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0325, LPL: 1.3863, Contrastive: 0.1288\n",
      " - Metrics: Accuracy=0.9182, F1=0.7933, Recall=0.7447, Precision=0.8488\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5737913294462824, K=18, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658876115886441, margin=0.7344059696913318, lpl_weight=0.7186557437315787\n",
      " - ratio=0.1466624311788599, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0325, LPL: 1.3863, Contrastive: 0.1288\n",
      " - Metrics: Accuracy=0.9047, F1=0.7611, Recall=0.7204, Precision=0.8067\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5737913294462824, K=18, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2658876115886441, margin=0.7344059696913318, lpl_weight=0.7186557437315787\n",
      " - ratio=0.1466624311788599, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0325, LPL: 1.3863, Contrastive: 0.1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:23:05,622] Trial 49 finished with value: 0.7756226033086795 and parameters: {'alpha': 0.5737913294462824, 'K': 18, 'layers': 3, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2658876115886441, 'margin': 0.7344059696913318, 'lpl_weight': 0.7186557437315787, 'ratio': 0.1466624311788599, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 38 with value: 0.8455717941380525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9137, F1=0.7817, Recall=0.7332, Precision=0.8371\n",
      "Done. Results written to citeseer_experimentations\\citeseer_sar_2102122222.csv.\n",
      "Average F1 over 5 seeds: 0.7756  0.0110\n",
      "Best trial:\n",
      "  Average F1: 0.8455717941380525\n",
      "  Best parameters:\n",
      "    alpha: 0.37723710900430574\n",
      "    K: 20\n",
      "    layers: 2\n",
      "    hidden_channels: 256\n",
      "    out_channels: 128\n",
      "    norm: layernorm\n",
      "    dropout: 0.2653392372389523\n",
      "    margin: 0.5902726074174123\n",
      "    lpl_weight: 0.5979423122947367\n",
      "    ratio: 0.13594889546650762\n",
      "    aggregation: sum\n",
      "    treatment: removal\n"
     ]
    }
   ],
   "source": [
    "from train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"citeseer\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 15, 25),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": 1,#trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"citeseer_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Cora\n",
    "#### SCAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:23:05,650] A new study created in memory with name: no-name-4468d66a-049b-414c-8ec5-8a1409d48901\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.6590275255796161, K=34, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.252224978557246, margin=0.801479736149222, lpl_weight=0.10820398144332889\n",
      " - ratio=0.3781283040605532, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2991, LPL: 1.3863, Contrastive: 0.1672\n",
      " - Metrics: Accuracy=0.7947, F1=0.7347, Recall=0.9413, Precision=0.6025\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6590275255796161, K=34, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.252224978557246, margin=0.801479736149222, lpl_weight=0.10820398144332889\n",
      " - ratio=0.3781283040605532, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2991, LPL: 1.3863, Contrastive: 0.1672\n",
      " - Metrics: Accuracy=0.7969, F1=0.7376, Recall=0.9450, Precision=0.6049\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6590275255796161, K=34, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.252224978557246, margin=0.801479736149222, lpl_weight=0.10820398144332889\n",
      " - ratio=0.3781283040605532, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2991, LPL: 1.3863, Contrastive: 0.1672\n",
      " - Metrics: Accuracy=0.7984, F1=0.7395, Recall=0.9474, Precision=0.6064\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6590275255796161, K=34, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.252224978557246, margin=0.801479736149222, lpl_weight=0.10820398144332889\n",
      " - ratio=0.3781283040605532, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2991, LPL: 1.3863, Contrastive: 0.1672\n",
      " - Metrics: Accuracy=0.7917, F1=0.7309, Recall=0.9364, Precision=0.5994\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6590275255796161, K=34, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.252224978557246, margin=0.801479736149222, lpl_weight=0.10820398144332889\n",
      " - ratio=0.3781283040605532, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2991, LPL: 1.3863, Contrastive: 0.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:23:41,175] Trial 0 finished with value: 0.7356870229007634 and parameters: {'alpha': 0.6590275255796161, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.252224978557246, 'margin': 0.801479736149222, 'lpl_weight': 0.10820398144332889, 'ratio': 0.3781283040605532, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.7356870229007634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7954, F1=0.7357, Recall=0.9425, Precision=0.6033\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102122305.csv.\n",
      "Average F1 over 5 seeds: 0.7357  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9541489676457723, K=33, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4793875130120685, margin=0.3521159342119853, lpl_weight=0.9293264066487583\n",
      " - ratio=0.23356207667182172, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3006, LPL: 1.3863, Contrastive: 0.1732\n",
      "Epoch 50, Loss: 1.2961, LPL: 1.3863, Contrastive: 0.1096\n",
      "Epoch 100, Loss: 1.2960, LPL: 1.3863, Contrastive: 0.1085\n",
      " - Metrics: Accuracy=0.9298, F1=0.8872, Recall=0.9132, Precision=0.8626\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9541489676457723, K=33, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4793875130120685, margin=0.3521159342119853, lpl_weight=0.9293264066487583\n",
      " - ratio=0.23356207667182172, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3006, LPL: 1.3863, Contrastive: 0.1732\n",
      "Epoch 50, Loss: 1.2961, LPL: 1.3863, Contrastive: 0.1097\n",
      "Epoch 100, Loss: 1.2960, LPL: 1.3863, Contrastive: 0.1094\n",
      " - Metrics: Accuracy=0.9114, F1=0.8565, Recall=0.8753, Precision=0.8384\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9541489676457723, K=33, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4793875130120685, margin=0.3521159342119853, lpl_weight=0.9293264066487583\n",
      " - ratio=0.23356207667182172, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3006, LPL: 1.3863, Contrastive: 0.1732\n",
      "Epoch 50, Loss: 1.2961, LPL: 1.3863, Contrastive: 0.1097\n",
      "Epoch 100, Loss: 1.2960, LPL: 1.3863, Contrastive: 0.1093\n",
      " - Metrics: Accuracy=0.9280, F1=0.8832, Recall=0.9010, Precision=0.8660\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9541489676457723, K=33, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4793875130120685, margin=0.3521159342119853, lpl_weight=0.9293264066487583\n",
      " - ratio=0.23356207667182172, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3006, LPL: 1.3863, Contrastive: 0.1731\n",
      "Epoch 50, Loss: 1.2961, LPL: 1.3863, Contrastive: 0.1097\n",
      "Epoch 100, Loss: 1.2961, LPL: 1.3863, Contrastive: 0.1096\n",
      " - Metrics: Accuracy=0.9254, F1=0.8790, Recall=0.8973, Precision=0.8615\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9541489676457723, K=33, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4793875130120685, margin=0.3521159342119853, lpl_weight=0.9293264066487583\n",
      " - ratio=0.23356207667182172, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3006, LPL: 1.3863, Contrastive: 0.1732\n",
      "Epoch 50, Loss: 1.2961, LPL: 1.3863, Contrastive: 0.1096\n",
      "Epoch 100, Loss: 1.2960, LPL: 1.3863, Contrastive: 0.1082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:24:50,664] Trial 1 finished with value: 0.8753877722852119 and parameters: {'alpha': 0.9541489676457723, 'K': 33, 'layers': 3, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.4793875130120685, 'margin': 0.3521159342119853, 'lpl_weight': 0.9293264066487583, 'ratio': 0.23356207667182172, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9191, F1=0.8711, Recall=0.9046, Precision=0.8400\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102122341.csv.\n",
      "Average F1 over 5 seeds: 0.8754  0.0109\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5189123862737155, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3490030071699707, margin=0.9969047461294024, lpl_weight=0.8185093342107809\n",
      " - ratio=0.2700862121313987, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1535, LPL: 1.3863, Contrastive: 0.1037\n",
      "Epoch 50, Loss: 1.1347, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9099, F1=0.8519, Recall=0.8582, Precision=0.8458\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5189123862737155, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3490030071699707, margin=0.9969047461294024, lpl_weight=0.8185093342107809\n",
      " - ratio=0.2700862121313987, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1535, LPL: 1.3863, Contrastive: 0.1037\n",
      "Epoch 50, Loss: 1.1347, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9147, F1=0.8585, Recall=0.8570, Precision=0.8601\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5189123862737155, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3490030071699707, margin=0.9969047461294024, lpl_weight=0.8185093342107809\n",
      " - ratio=0.2700862121313987, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1535, LPL: 1.3863, Contrastive: 0.1037\n",
      "Epoch 50, Loss: 1.1347, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9069, F1=0.8496, Recall=0.8704, Precision=0.8298\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5189123862737155, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3490030071699707, margin=0.9969047461294024, lpl_weight=0.8185093342107809\n",
      " - ratio=0.2700862121313987, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1535, LPL: 1.3863, Contrastive: 0.1037\n",
      "Epoch 50, Loss: 1.1347, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9047, F1=0.8440, Recall=0.8533, Precision=0.8349\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5189123862737155, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3490030071699707, margin=0.9969047461294024, lpl_weight=0.8185093342107809\n",
      " - ratio=0.2700862121313987, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1535, LPL: 1.3863, Contrastive: 0.1037\n",
      "Epoch 50, Loss: 1.1347, LPL: 1.3863, Contrastive: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:25:58,530] Trial 2 finished with value: 0.8573849410228288 and parameters: {'alpha': 0.5189123862737155, 'K': 31, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3490030071699707, 'margin': 0.9969047461294024, 'lpl_weight': 0.8185093342107809, 'ratio': 0.2700862121313987, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9291, F1=0.8828, Recall=0.8839, Precision=0.8817\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102122450.csv.\n",
      "Average F1 over 5 seeds: 0.8574  0.0135\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.46487302325069635, K=26, layers=3, hidden=64, out=128\n",
      " - norm=None, dropout=0.10354277234312154, margin=0.5952950808991776, lpl_weight=0.21691611914398623\n",
      " - ratio=0.27646666659981756, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3606, LPL: 1.3863, Contrastive: 0.0765\n",
      "Epoch 50, Loss: 0.3351, LPL: 1.3863, Contrastive: 0.0439\n",
      "Epoch 100, Loss: 0.3343, LPL: 1.3863, Contrastive: 0.0429\n",
      " - Metrics: Accuracy=0.8637, F1=0.8019, Recall=0.9132, Precision=0.7148\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.46487302325069635, K=26, layers=3, hidden=64, out=128\n",
      " - norm=None, dropout=0.10354277234312154, margin=0.5952950808991776, lpl_weight=0.21691611914398623\n",
      " - ratio=0.27646666659981756, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3606, LPL: 1.3863, Contrastive: 0.0765\n",
      "Epoch 50, Loss: 0.3351, LPL: 1.3863, Contrastive: 0.0439\n",
      "Epoch 100, Loss: 0.3346, LPL: 1.3863, Contrastive: 0.0433\n",
      " - Metrics: Accuracy=0.8741, F1=0.8170, Recall=0.9303, Precision=0.7282\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.46487302325069635, K=26, layers=3, hidden=64, out=128\n",
      " - norm=None, dropout=0.10354277234312154, margin=0.5952950808991776, lpl_weight=0.21691611914398623\n",
      " - ratio=0.27646666659981756, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3606, LPL: 1.3863, Contrastive: 0.0765\n",
      "Epoch 50, Loss: 0.3351, LPL: 1.3863, Contrastive: 0.0439\n",
      "Epoch 100, Loss: 0.3343, LPL: 1.3863, Contrastive: 0.0429\n",
      " - Metrics: Accuracy=0.8682, F1=0.8084, Recall=0.9205, Precision=0.7206\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.46487302325069635, K=26, layers=3, hidden=64, out=128\n",
      " - norm=None, dropout=0.10354277234312154, margin=0.5952950808991776, lpl_weight=0.21691611914398623\n",
      " - ratio=0.27646666659981756, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3606, LPL: 1.3863, Contrastive: 0.0765\n",
      "Epoch 50, Loss: 0.3351, LPL: 1.3863, Contrastive: 0.0439\n",
      "Epoch 100, Loss: 0.3346, LPL: 1.3863, Contrastive: 0.0433\n",
      " - Metrics: Accuracy=0.8763, F1=0.8202, Recall=0.9340, Precision=0.7311\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.46487302325069635, K=26, layers=3, hidden=64, out=128\n",
      " - norm=None, dropout=0.10354277234312154, margin=0.5952950808991776, lpl_weight=0.21691611914398623\n",
      " - ratio=0.27646666659981756, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3606, LPL: 1.3863, Contrastive: 0.0765\n",
      "Epoch 50, Loss: 0.3351, LPL: 1.3863, Contrastive: 0.0439\n",
      "Epoch 100, Loss: 0.3342, LPL: 1.3863, Contrastive: 0.0428\n",
      "Epoch 150, Loss: 0.3342, LPL: 1.3863, Contrastive: 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:26:56,120] Trial 3 finished with value: 0.8146001073537306 and parameters: {'alpha': 0.46487302325069635, 'K': 26, 'layers': 3, 'hidden_channels': 64, 'out_channels': 128, 'norm': None, 'dropout': 0.10354277234312154, 'margin': 0.5952950808991776, 'lpl_weight': 0.21691611914398623, 'ratio': 0.27646666659981756, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8800, F1=0.8256, Recall=0.9401, Precision=0.7359\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102122558.csv.\n",
      "Average F1 over 5 seeds: 0.8146  0.0084\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6821315745667653, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.2078865615110963, margin=0.363817539882329, lpl_weight=0.6059966352994189\n",
      " - ratio=0.14707900755614808, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8827, LPL: 1.3863, Contrastive: 0.1081\n",
      "Epoch 50, Loss: 0.8806, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 100, Loss: 0.8805, LPL: 1.3863, Contrastive: 0.1026\n",
      " - Metrics: Accuracy=0.8940, F1=0.8014, Recall=0.7078, Precision=0.9234\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6821315745667653, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.2078865615110963, margin=0.363817539882329, lpl_weight=0.6059966352994189\n",
      " - ratio=0.14707900755614808, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8827, LPL: 1.3863, Contrastive: 0.1081\n",
      "Epoch 50, Loss: 0.8806, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 100, Loss: 0.8807, LPL: 1.3863, Contrastive: 0.1031\n",
      " - Metrics: Accuracy=0.8914, F1=0.7947, Recall=0.6956, Precision=0.9267\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6821315745667653, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.2078865615110963, margin=0.363817539882329, lpl_weight=0.6059966352994189\n",
      " - ratio=0.14707900755614808, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8827, LPL: 1.3863, Contrastive: 0.1081\n",
      "Epoch 50, Loss: 0.8806, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 100, Loss: 0.8805, LPL: 1.3863, Contrastive: 0.1027\n",
      " - Metrics: Accuracy=0.8973, F1=0.8067, Recall=0.7090, Precision=0.9355\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6821315745667653, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.2078865615110963, margin=0.363817539882329, lpl_weight=0.6059966352994189\n",
      " - ratio=0.14707900755614808, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8827, LPL: 1.3863, Contrastive: 0.1081\n",
      "Epoch 50, Loss: 0.8806, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 100, Loss: 0.8805, LPL: 1.3863, Contrastive: 0.1025\n",
      " - Metrics: Accuracy=0.8881, F1=0.7877, Recall=0.6870, Precision=0.9228\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6821315745667653, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.2078865615110963, margin=0.363817539882329, lpl_weight=0.6059966352994189\n",
      " - ratio=0.14707900755614808, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8827, LPL: 1.3863, Contrastive: 0.1081\n",
      "Epoch 50, Loss: 0.8806, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 100, Loss: 0.8805, LPL: 1.3863, Contrastive: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:27:58,544] Trial 4 finished with value: 0.7946297994738712 and parameters: {'alpha': 0.6821315745667653, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.2078865615110963, 'margin': 0.363817539882329, 'lpl_weight': 0.6059966352994189, 'ratio': 0.14707900755614808, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8848, F1=0.7827, Recall=0.6870, Precision=0.9094\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102122656.csv.\n",
      "Average F1 over 5 seeds: 0.7946  0.0087\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6713478411673588, K=32, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.15134177916227587, margin=0.8264474232783575, lpl_weight=0.9952632784765246\n",
      " - ratio=0.2702967432311131, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0124\n",
      "Epoch 50, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0079\n",
      "Epoch 100, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0077\n",
      " - Metrics: Accuracy=0.8933, F1=0.8188, Recall=0.7983, Precision=0.8404\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6713478411673588, K=32, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.15134177916227587, margin=0.8264474232783575, lpl_weight=0.9952632784765246\n",
      " - ratio=0.2702967432311131, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0124\n",
      "Epoch 50, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0079\n",
      "Epoch 100, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0077\n",
      " - Metrics: Accuracy=0.8944, F1=0.8181, Recall=0.7861, Precision=0.8528\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6713478411673588, K=32, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.15134177916227587, margin=0.8264474232783575, lpl_weight=0.9952632784765246\n",
      " - ratio=0.2702967432311131, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0124\n",
      "Epoch 50, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0079\n",
      "Epoch 100, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0077\n",
      " - Metrics: Accuracy=0.8918, F1=0.8163, Recall=0.7958, Precision=0.8378\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6713478411673588, K=32, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.15134177916227587, margin=0.8264474232783575, lpl_weight=0.9952632784765246\n",
      " - ratio=0.2702967432311131, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0124\n",
      "Epoch 50, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0079\n",
      "Epoch 100, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0077\n",
      " - Metrics: Accuracy=0.8896, F1=0.8087, Recall=0.7726, Precision=0.8483\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6713478411673588, K=32, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.15134177916227587, margin=0.8264474232783575, lpl_weight=0.9952632784765246\n",
      " - ratio=0.2702967432311131, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0124\n",
      "Epoch 50, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0079\n",
      "Epoch 100, Loss: 1.3798, LPL: 1.3863, Contrastive: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:28:54,918] Trial 5 finished with value: 0.8154504024950384 and parameters: {'alpha': 0.6713478411673588, 'K': 32, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.15134177916227587, 'margin': 0.8264474232783575, 'lpl_weight': 0.9952632784765246, 'ratio': 0.2702967432311131, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8918, F1=0.8154, Recall=0.7910, Precision=0.8414\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102122758.csv.\n",
      "Average F1 over 5 seeds: 0.8155  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.749445936859891, K=27, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4647588056398346, margin=0.10632366623181048, lpl_weight=0.8312597283242947\n",
      " - ratio=0.40834795157137105, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1909, LPL: 1.3863, Contrastive: 0.2286\n",
      "Epoch 50, Loss: 1.1874, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 100, Loss: 1.1875, LPL: 1.3863, Contrastive: 0.2084\n",
      " - Metrics: Accuracy=0.8955, F1=0.8444, Recall=0.9389, Precision=0.7672\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.749445936859891, K=27, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4647588056398346, margin=0.10632366623181048, lpl_weight=0.8312597283242947\n",
      " - ratio=0.40834795157137105, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1909, LPL: 1.3863, Contrastive: 0.2286\n",
      "Epoch 50, Loss: 1.1874, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 100, Loss: 1.1875, LPL: 1.3863, Contrastive: 0.2084\n",
      " - Metrics: Accuracy=0.8892, F1=0.8364, Recall=0.9377, Precision=0.7549\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.749445936859891, K=27, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4647588056398346, margin=0.10632366623181048, lpl_weight=0.8312597283242947\n",
      " - ratio=0.40834795157137105, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1909, LPL: 1.3863, Contrastive: 0.2286\n",
      "Epoch 50, Loss: 1.1874, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 100, Loss: 1.1875, LPL: 1.3863, Contrastive: 0.2084\n",
      " - Metrics: Accuracy=0.8973, F1=0.8473, Recall=0.9425, Precision=0.7695\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.749445936859891, K=27, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4647588056398346, margin=0.10632366623181048, lpl_weight=0.8312597283242947\n",
      " - ratio=0.40834795157137105, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1909, LPL: 1.3863, Contrastive: 0.2286\n",
      "Epoch 50, Loss: 1.1874, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 100, Loss: 1.1875, LPL: 1.3863, Contrastive: 0.2084\n",
      " - Metrics: Accuracy=0.8988, F1=0.8478, Recall=0.9328, Precision=0.7770\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.749445936859891, K=27, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4647588056398346, margin=0.10632366623181048, lpl_weight=0.8312597283242947\n",
      " - ratio=0.40834795157137105, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1909, LPL: 1.3863, Contrastive: 0.2286\n",
      "Epoch 50, Loss: 1.1874, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 100, Loss: 1.1875, LPL: 1.3863, Contrastive: 0.2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:29:51,964] Trial 6 finished with value: 0.8425350814711695 and parameters: {'alpha': 0.749445936859891, 'K': 27, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.4647588056398346, 'margin': 0.10632366623181048, 'lpl_weight': 0.8312597283242947, 'ratio': 0.40834795157137105, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8900, F1=0.8368, Recall=0.9340, Precision=0.7579\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102122854.csv.\n",
      "Average F1 over 5 seeds: 0.8425  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7996191771362848, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21733147989226265, margin=0.89260670603617, lpl_weight=0.7124147202851032\n",
      " - ratio=0.4632024393277153, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9979, LPL: 1.3863, Contrastive: 0.0357\n",
      " - Metrics: Accuracy=0.8589, F1=0.7885, Recall=0.8704, Precision=0.7206\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7996191771362848, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21733147989226265, margin=0.89260670603617, lpl_weight=0.7124147202851032\n",
      " - ratio=0.4632024393277153, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9979, LPL: 1.3863, Contrastive: 0.0357\n",
      " - Metrics: Accuracy=0.8490, F1=0.7800, Recall=0.8863, Precision=0.6964\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7996191771362848, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21733147989226265, margin=0.89260670603617, lpl_weight=0.7124147202851032\n",
      " - ratio=0.4632024393277153, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9979, LPL: 1.3863, Contrastive: 0.0357\n",
      " - Metrics: Accuracy=0.8545, F1=0.7889, Recall=0.8998, Precision=0.7023\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7996191771362848, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21733147989226265, margin=0.89260670603617, lpl_weight=0.7124147202851032\n",
      " - ratio=0.4632024393277153, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9979, LPL: 1.3863, Contrastive: 0.0357\n",
      " - Metrics: Accuracy=0.8456, F1=0.7738, Recall=0.8741, Precision=0.6942\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7996191771362848, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21733147989226265, margin=0.89260670603617, lpl_weight=0.7124147202851032\n",
      " - ratio=0.4632024393277153, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9979, LPL: 1.3863, Contrastive: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:30:24,099] Trial 7 finished with value: 0.7818299406954465 and parameters: {'alpha': 0.7996191771362848, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.21733147989226265, 'margin': 0.89260670603617, 'lpl_weight': 0.7124147202851032, 'ratio': 0.4632024393277153, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8464, F1=0.7780, Recall=0.8912, Precision=0.6903\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102122951.csv.\n",
      "Average F1 over 5 seeds: 0.7818  0.0059\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6745378205295919, K=25, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.11088520145954722, margin=0.6964209213968519, lpl_weight=0.6871564619105629\n",
      " - ratio=0.16634398988863036, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9632, LPL: 1.3863, Contrastive: 0.0338\n",
      "Epoch 50, Loss: 0.9601, LPL: 1.3863, Contrastive: 0.0238\n",
      "Epoch 100, Loss: 0.9599, LPL: 1.3863, Contrastive: 0.0235\n",
      " - Metrics: Accuracy=0.8604, F1=0.7652, Recall=0.7531, Precision=0.7778\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6745378205295919, K=25, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.11088520145954722, margin=0.6964209213968519, lpl_weight=0.6871564619105629\n",
      " - ratio=0.16634398988863036, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9632, LPL: 1.3863, Contrastive: 0.0338\n",
      "Epoch 50, Loss: 0.9601, LPL: 1.3863, Contrastive: 0.0238\n",
      "Epoch 100, Loss: 0.9599, LPL: 1.3863, Contrastive: 0.0235\n",
      " - Metrics: Accuracy=0.8848, F1=0.8062, Recall=0.7934, Precision=0.8194\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6745378205295919, K=25, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.11088520145954722, margin=0.6964209213968519, lpl_weight=0.6871564619105629\n",
      " - ratio=0.16634398988863036, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9632, LPL: 1.3863, Contrastive: 0.0338\n",
      "Epoch 50, Loss: 0.9601, LPL: 1.3863, Contrastive: 0.0238\n",
      "Epoch 100, Loss: 0.9599, LPL: 1.3863, Contrastive: 0.0235\n",
      " - Metrics: Accuracy=0.8870, F1=0.8099, Recall=0.7971, Precision=0.8232\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6745378205295919, K=25, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.11088520145954722, margin=0.6964209213968519, lpl_weight=0.6871564619105629\n",
      " - ratio=0.16634398988863036, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9632, LPL: 1.3863, Contrastive: 0.0338\n",
      "Epoch 50, Loss: 0.9601, LPL: 1.3863, Contrastive: 0.0238\n",
      "Epoch 100, Loss: 0.9599, LPL: 1.3863, Contrastive: 0.0235\n",
      " - Metrics: Accuracy=0.8870, F1=0.8099, Recall=0.7971, Precision=0.8232\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6745378205295919, K=25, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.11088520145954722, margin=0.6964209213968519, lpl_weight=0.6871564619105629\n",
      " - ratio=0.16634398988863036, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9632, LPL: 1.3863, Contrastive: 0.0338\n",
      "Epoch 50, Loss: 0.9601, LPL: 1.3863, Contrastive: 0.0238\n",
      "Epoch 100, Loss: 0.9599, LPL: 1.3863, Contrastive: 0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:31:24,478] Trial 8 finished with value: 0.8001005215229551 and parameters: {'alpha': 0.6745378205295919, 'K': 25, 'layers': 3, 'hidden_channels': 64, 'out_channels': 256, 'norm': None, 'dropout': 0.11088520145954722, 'margin': 0.6964209213968519, 'lpl_weight': 0.6871564619105629, 'ratio': 0.16634398988863036, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8866, F1=0.8092, Recall=0.7958, Precision=0.8230\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102123024.csv.\n",
      "Average F1 over 5 seeds: 0.8001  0.0175\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6010569516787998, K=35, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19920680437801142, margin=0.9828210497054504, lpl_weight=0.5465645165821197\n",
      " - ratio=0.3070496902319871, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7890, LPL: 1.3863, Contrastive: 0.0691\n",
      " - Metrics: Accuracy=0.8944, F1=0.8239, Recall=0.8178, Precision=0.8300\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6010569516787998, K=35, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19920680437801142, margin=0.9828210497054504, lpl_weight=0.5465645165821197\n",
      " - ratio=0.3070496902319871, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7890, LPL: 1.3863, Contrastive: 0.0691\n",
      " - Metrics: Accuracy=0.8874, F1=0.8125, Recall=0.8081, Precision=0.8171\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6010569516787998, K=35, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19920680437801142, margin=0.9828210497054504, lpl_weight=0.5465645165821197\n",
      " - ratio=0.3070496902319871, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7890, LPL: 1.3863, Contrastive: 0.0691\n",
      " - Metrics: Accuracy=0.8966, F1=0.8259, Recall=0.8117, Precision=0.8405\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6010569516787998, K=35, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19920680437801142, margin=0.9828210497054504, lpl_weight=0.5465645165821197\n",
      " - ratio=0.3070496902319871, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7890, LPL: 1.3863, Contrastive: 0.0691\n",
      " - Metrics: Accuracy=0.8863, F1=0.8080, Recall=0.7922, Precision=0.8244\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6010569516787998, K=35, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19920680437801142, margin=0.9828210497054504, lpl_weight=0.5465645165821197\n",
      " - ratio=0.3070496902319871, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7890, LPL: 1.3863, Contrastive: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:32:00,534] Trial 9 finished with value: 0.8209090337092825 and parameters: {'alpha': 0.6010569516787998, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.19920680437801142, 'margin': 0.9828210497054504, 'lpl_weight': 0.5465645165821197, 'ratio': 0.3070496902319871, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9014, F1=0.8343, Recall=0.8215, Precision=0.8474\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102123124.csv.\n",
      "Average F1 over 5 seeds: 0.8209  0.0095\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9819470297247279, K=28, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4741727584834736, margin=0.36591494886022125, lpl_weight=0.41871271348787353\n",
      " - ratio=0.10678679574786798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6798, LPL: 1.3863, Contrastive: 0.1709\n",
      "Epoch 50, Loss: 0.6415, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.6408, LPL: 1.3863, Contrastive: 0.1038\n",
      " - Metrics: Accuracy=0.9143, F1=0.8426, Recall=0.7592, Precision=0.9466\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9819470297247279, K=28, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4741727584834736, margin=0.36591494886022125, lpl_weight=0.41871271348787353\n",
      " - ratio=0.10678679574786798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6798, LPL: 1.3863, Contrastive: 0.1709\n",
      "Epoch 50, Loss: 0.6415, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.6407, LPL: 1.3863, Contrastive: 0.1036\n",
      " - Metrics: Accuracy=0.9025, F1=0.8207, Recall=0.7384, Precision=0.9235\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9819470297247279, K=28, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4741727584834736, margin=0.36591494886022125, lpl_weight=0.41871271348787353\n",
      " - ratio=0.10678679574786798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6798, LPL: 1.3863, Contrastive: 0.1708\n",
      "Epoch 50, Loss: 0.6415, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.6406, LPL: 1.3863, Contrastive: 0.1035\n",
      " - Metrics: Accuracy=0.9132, F1=0.8405, Recall=0.7567, Precision=0.9450\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9819470297247279, K=28, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4741727584834736, margin=0.36591494886022125, lpl_weight=0.41871271348787353\n",
      " - ratio=0.10678679574786798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6798, LPL: 1.3863, Contrastive: 0.1709\n",
      "Epoch 50, Loss: 0.6415, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.6410, LPL: 1.3863, Contrastive: 0.1042\n",
      " - Metrics: Accuracy=0.9088, F1=0.8323, Recall=0.7494, Precision=0.9359\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9819470297247279, K=28, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4741727584834736, margin=0.36591494886022125, lpl_weight=0.41871271348787353\n",
      " - ratio=0.10678679574786798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6798, LPL: 1.3863, Contrastive: 0.1709\n",
      "Epoch 50, Loss: 0.6415, LPL: 1.3863, Contrastive: 0.1050\n",
      "Epoch 100, Loss: 0.6406, LPL: 1.3863, Contrastive: 0.1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:33:17,375] Trial 10 finished with value: 0.8329676648154379 and parameters: {'alpha': 0.9819470297247279, 'K': 28, 'layers': 3, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.4741727584834736, 'margin': 0.36591494886022125, 'lpl_weight': 0.41871271348787353, 'ratio': 0.10678679574786798, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 1 with value: 0.8753877722852119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9069, F1=0.8288, Recall=0.7457, Precision=0.9327\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102123200.csv.\n",
      "Average F1 over 5 seeds: 0.8330  0.0080\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.18866494795055833, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3715913352617227, margin=0.39995111049704224, lpl_weight=0.9731791194469844\n",
      " - ratio=0.21371167568099758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3535, LPL: 1.3863, Contrastive: 0.1649\n",
      "Epoch 50, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0934\n",
      "Epoch 100, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0931\n",
      " - Metrics: Accuracy=0.9335, F1=0.8892, Recall=0.8826, Precision=0.8958\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.18866494795055833, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3715913352617227, margin=0.39995111049704224, lpl_weight=0.9731791194469844\n",
      " - ratio=0.21371167568099758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3535, LPL: 1.3863, Contrastive: 0.1649\n",
      "Epoch 50, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0934\n",
      "Epoch 100, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0932\n",
      " - Metrics: Accuracy=0.9269, F1=0.8796, Recall=0.8839, Precision=0.8753\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.18866494795055833, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3715913352617227, margin=0.39995111049704224, lpl_weight=0.9731791194469844\n",
      " - ratio=0.21371167568099758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3535, LPL: 1.3863, Contrastive: 0.1649\n",
      "Epoch 50, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0934\n",
      "Epoch 100, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0932\n",
      " - Metrics: Accuracy=0.9321, F1=0.8878, Recall=0.8900, Precision=0.8856\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.18866494795055833, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3715913352617227, margin=0.39995111049704224, lpl_weight=0.9731791194469844\n",
      " - ratio=0.21371167568099758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3535, LPL: 1.3863, Contrastive: 0.1649\n",
      "Epoch 50, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0934\n",
      "Epoch 100, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0932\n",
      " - Metrics: Accuracy=0.9343, F1=0.8911, Recall=0.8900, Precision=0.8922\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.18866494795055833, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3715913352617227, margin=0.39995111049704224, lpl_weight=0.9731791194469844\n",
      " - ratio=0.21371167568099758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3535, LPL: 1.3863, Contrastive: 0.1649\n",
      "Epoch 50, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0934\n",
      "Epoch 100, Loss: 1.3516, LPL: 1.3863, Contrastive: 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:34:31,544] Trial 11 finished with value: 0.8892361420313708 and parameters: {'alpha': 0.18866494795055833, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3715913352617227, 'margin': 0.39995111049704224, 'lpl_weight': 0.9731791194469844, 'ratio': 0.21371167568099758, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 11 with value: 0.8892361420313708.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9391, F1=0.8986, Recall=0.8936, Precision=0.9036\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102123317.csv.\n",
      "Average F1 over 5 seeds: 0.8892  0.0061\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1566240352709073, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3849488637366818, margin=0.37263962835114545, lpl_weight=0.9952370760595798\n",
      " - ratio=0.20301691042384845, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3805, LPL: 1.3863, Contrastive: 0.1694\n",
      "Epoch 50, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1008\n",
      " - Metrics: Accuracy=0.9306, F1=0.8824, Recall=0.8619, Precision=0.9038\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1566240352709073, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3849488637366818, margin=0.37263962835114545, lpl_weight=0.9952370760595798\n",
      " - ratio=0.20301691042384845, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3805, LPL: 1.3863, Contrastive: 0.1694\n",
      "Epoch 50, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1008\n",
      " - Metrics: Accuracy=0.9309, F1=0.8846, Recall=0.8765, Precision=0.8929\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1566240352709073, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3849488637366818, margin=0.37263962835114545, lpl_weight=0.9952370760595798\n",
      " - ratio=0.20301691042384845, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3805, LPL: 1.3863, Contrastive: 0.1694\n",
      "Epoch 50, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1008\n",
      " - Metrics: Accuracy=0.9380, F1=0.8963, Recall=0.8875, Precision=0.9052\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1566240352709073, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3849488637366818, margin=0.37263962835114545, lpl_weight=0.9952370760595798\n",
      " - ratio=0.20301691042384845, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3805, LPL: 1.3863, Contrastive: 0.1694\n",
      "Epoch 50, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1008\n",
      " - Metrics: Accuracy=0.9357, F1=0.8918, Recall=0.8765, Precision=0.9076\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1566240352709073, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3849488637366818, margin=0.37263962835114545, lpl_weight=0.9952370760595798\n",
      " - ratio=0.20301691042384845, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3805, LPL: 1.3863, Contrastive: 0.1694\n",
      "Epoch 50, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1026\n",
      "Epoch 100, Loss: 1.3802, LPL: 1.3863, Contrastive: 0.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:35:48,492] Trial 12 finished with value: 0.890966373831176 and parameters: {'alpha': 0.1566240352709073, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3849488637366818, 'margin': 0.37263962835114545, 'lpl_weight': 0.9952370760595798, 'ratio': 0.20301691042384845, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 12 with value: 0.890966373831176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9402, F1=0.8998, Recall=0.8888, Precision=0.9110\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102123431.csv.\n",
      "Average F1 over 5 seeds: 0.8910  0.0066\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.13318950807832142, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3609475111929165, margin=0.17816021591482978, lpl_weight=0.8584045277849213\n",
      " - ratio=0.20659836901798856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2184, LPL: 1.3863, Contrastive: 0.2007\n",
      "Epoch 50, Loss: 1.2145, LPL: 1.3863, Contrastive: 0.1729\n",
      " - Metrics: Accuracy=0.9321, F1=0.8854, Recall=0.8692, Precision=0.9023\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.13318950807832142, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3609475111929165, margin=0.17816021591482978, lpl_weight=0.8584045277849213\n",
      " - ratio=0.20659836901798856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2184, LPL: 1.3863, Contrastive: 0.2007\n",
      "Epoch 50, Loss: 1.2145, LPL: 1.3863, Contrastive: 0.1729\n",
      " - Metrics: Accuracy=0.9309, F1=0.8842, Recall=0.8729, Precision=0.8959\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.13318950807832142, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3609475111929165, margin=0.17816021591482978, lpl_weight=0.8584045277849213\n",
      " - ratio=0.20659836901798856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2184, LPL: 1.3863, Contrastive: 0.2007\n",
      "Epoch 50, Loss: 1.2145, LPL: 1.3863, Contrastive: 0.1729\n",
      " - Metrics: Accuracy=0.9387, F1=0.8974, Recall=0.8875, Precision=0.9075\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.13318950807832142, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3609475111929165, margin=0.17816021591482978, lpl_weight=0.8584045277849213\n",
      " - ratio=0.20659836901798856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2184, LPL: 1.3863, Contrastive: 0.2007\n",
      "Epoch 50, Loss: 1.2145, LPL: 1.3863, Contrastive: 0.1729\n",
      " - Metrics: Accuracy=0.9369, F1=0.8940, Recall=0.8814, Precision=0.9069\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.13318950807832142, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3609475111929165, margin=0.17816021591482978, lpl_weight=0.8584045277849213\n",
      " - ratio=0.20659836901798856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2184, LPL: 1.3863, Contrastive: 0.2007\n",
      "Epoch 50, Loss: 1.2145, LPL: 1.3863, Contrastive: 0.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:36:50,892] Trial 13 finished with value: 0.8915593795724146 and parameters: {'alpha': 0.13318950807832142, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3609475111929165, 'margin': 0.17816021591482978, 'lpl_weight': 0.8584045277849213, 'ratio': 0.20659836901798856, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 13 with value: 0.8915593795724146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9387, F1=0.8968, Recall=0.8814, Precision=0.9127\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102123548.csv.\n",
      "Average F1 over 5 seeds: 0.8916  0.0056\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.12381684111544905, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3896632709953618, margin=0.11889866625891071, lpl_weight=0.8192419346866757\n",
      " - ratio=0.19003471945850867, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1757, LPL: 1.3863, Contrastive: 0.2210\n",
      "Epoch 50, Loss: 1.1716, LPL: 1.3863, Contrastive: 0.1986\n",
      " - Metrics: Accuracy=0.9343, F1=0.8873, Recall=0.8570, Precision=0.9199\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.12381684111544905, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3896632709953618, margin=0.11889866625891071, lpl_weight=0.8192419346866757\n",
      " - ratio=0.19003471945850867, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1757, LPL: 1.3863, Contrastive: 0.2210\n",
      "Epoch 50, Loss: 1.1716, LPL: 1.3863, Contrastive: 0.1986\n",
      " - Metrics: Accuracy=0.9202, F1=0.8635, Recall=0.8350, Precision=0.8940\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.12381684111544905, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3896632709953618, margin=0.11889866625891071, lpl_weight=0.8192419346866757\n",
      " - ratio=0.19003471945850867, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1757, LPL: 1.3863, Contrastive: 0.2210\n",
      "Epoch 50, Loss: 1.1716, LPL: 1.3863, Contrastive: 0.1986\n",
      " - Metrics: Accuracy=0.9339, F1=0.8875, Recall=0.8631, Precision=0.9133\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.12381684111544905, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3896632709953618, margin=0.11889866625891071, lpl_weight=0.8192419346866757\n",
      " - ratio=0.19003471945850867, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1757, LPL: 1.3863, Contrastive: 0.2210\n",
      "Epoch 50, Loss: 1.1716, LPL: 1.3863, Contrastive: 0.1986\n",
      " - Metrics: Accuracy=0.9243, F1=0.8708, Recall=0.8447, Precision=0.8986\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.12381684111544905, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3896632709953618, margin=0.11889866625891071, lpl_weight=0.8192419346866757\n",
      " - ratio=0.19003471945850867, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1757, LPL: 1.3863, Contrastive: 0.2210\n",
      "Epoch 50, Loss: 1.1716, LPL: 1.3863, Contrastive: 0.1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:37:52,754] Trial 14 finished with value: 0.8788448704108929 and parameters: {'alpha': 0.12381684111544905, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3896632709953618, 'margin': 0.11889866625891071, 'lpl_weight': 0.8192419346866757, 'ratio': 0.19003471945850867, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 13 with value: 0.8915593795724146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9328, F1=0.8851, Recall=0.8570, Precision=0.9151\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102123650.csv.\n",
      "Average F1 over 5 seeds: 0.8788  0.0099\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.31236944845219183, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31242474275894927, margin=0.24124304327536977, lpl_weight=0.4260800292774936\n",
      " - ratio=0.33328060021430267, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6941, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 50, Loss: 0.6753, LPL: 1.3863, Contrastive: 0.1474\n",
      " - Metrics: Accuracy=0.9180, F1=0.8723, Recall=0.9267, Precision=0.8239\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.31236944845219183, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31242474275894927, margin=0.24124304327536977, lpl_weight=0.4260800292774936\n",
      " - ratio=0.33328060021430267, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6941, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 50, Loss: 0.6753, LPL: 1.3863, Contrastive: 0.1474\n",
      " - Metrics: Accuracy=0.9173, F1=0.8699, Recall=0.9156, Precision=0.8285\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.31236944845219183, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31242474275894927, margin=0.24124304327536977, lpl_weight=0.4260800292774936\n",
      " - ratio=0.33328060021430267, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6941, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 50, Loss: 0.6753, LPL: 1.3863, Contrastive: 0.1474\n",
      " - Metrics: Accuracy=0.9228, F1=0.8788, Recall=0.9267, Precision=0.8357\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.31236944845219183, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31242474275894927, margin=0.24124304327536977, lpl_weight=0.4260800292774936\n",
      " - ratio=0.33328060021430267, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6941, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 50, Loss: 0.6753, LPL: 1.3863, Contrastive: 0.1474\n",
      " - Metrics: Accuracy=0.9225, F1=0.8765, Recall=0.9108, Precision=0.8447\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.31236944845219183, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31242474275894927, margin=0.24124304327536977, lpl_weight=0.4260800292774936\n",
      " - ratio=0.33328060021430267, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6941, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 50, Loss: 0.6753, LPL: 1.3863, Contrastive: 0.1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:38:55,255] Trial 15 finished with value: 0.8723048758783122 and parameters: {'alpha': 0.31236944845219183, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.31242474275894927, 'margin': 0.24124304327536977, 'lpl_weight': 0.4260800292774936, 'ratio': 0.33328060021430267, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 13 with value: 0.8915593795724146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9125, F1=0.8640, Recall=0.9205, Precision=0.8141\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102123752.csv.\n",
      "Average F1 over 5 seeds: 0.8723  0.0052\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.31192917083970995, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4150340942252379, margin=0.24332421288261652, lpl_weight=0.8856697747459107\n",
      " - ratio=0.10811302275438217, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2499, LPL: 1.3863, Contrastive: 0.1932\n",
      "Epoch 50, Loss: 1.2447, LPL: 1.3863, Contrastive: 0.1480\n",
      "Epoch 100, Loss: 1.2447, LPL: 1.3863, Contrastive: 0.1478\n",
      " - Metrics: Accuracy=0.9184, F1=0.8487, Recall=0.7579, Precision=0.9642\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.31192917083970995, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4150340942252379, margin=0.24332421288261652, lpl_weight=0.8856697747459107\n",
      " - ratio=0.10811302275438217, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2499, LPL: 1.3863, Contrastive: 0.1932\n",
      "Epoch 50, Loss: 1.2447, LPL: 1.3863, Contrastive: 0.1480\n",
      "Epoch 100, Loss: 1.2447, LPL: 1.3863, Contrastive: 0.1478\n",
      " - Metrics: Accuracy=0.9121, F1=0.8363, Recall=0.7433, Precision=0.9560\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.31192917083970995, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4150340942252379, margin=0.24332421288261652, lpl_weight=0.8856697747459107\n",
      " - ratio=0.10811302275438217, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2499, LPL: 1.3863, Contrastive: 0.1932\n",
      "Epoch 50, Loss: 1.2447, LPL: 1.3863, Contrastive: 0.1479\n",
      " - Metrics: Accuracy=0.9147, F1=0.8408, Recall=0.7457, Precision=0.9637\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.31192917083970995, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4150340942252379, margin=0.24332421288261652, lpl_weight=0.8856697747459107\n",
      " - ratio=0.10811302275438217, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2499, LPL: 1.3863, Contrastive: 0.1932\n",
      "Epoch 50, Loss: 1.2447, LPL: 1.3863, Contrastive: 0.1480\n",
      " - Metrics: Accuracy=0.9162, F1=0.8444, Recall=0.7531, Precision=0.9610\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.31192917083970995, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4150340942252379, margin=0.24332421288261652, lpl_weight=0.8856697747459107\n",
      " - ratio=0.10811302275438217, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2499, LPL: 1.3863, Contrastive: 0.1932\n",
      "Epoch 50, Loss: 1.2447, LPL: 1.3863, Contrastive: 0.1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:40:03,974] Trial 16 finished with value: 0.8441136759205842 and parameters: {'alpha': 0.31192917083970995, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4150340942252379, 'margin': 0.24332421288261652, 'lpl_weight': 0.8856697747459107, 'ratio': 0.10811302275438217, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 13 with value: 0.8915593795724146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9191, F1=0.8503, Recall=0.7604, Precision=0.9643\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102123855.csv.\n",
      "Average F1 over 5 seeds: 0.8441  0.0051\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.26625526948518147, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30136742497786895, margin=0.5111785498137569, lpl_weight=0.7262936518886128\n",
      " - ratio=0.23112465661992612, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0475, LPL: 1.3863, Contrastive: 0.1486\n",
      "Epoch 50, Loss: 1.0240, LPL: 1.3863, Contrastive: 0.0626\n",
      "Epoch 100, Loss: 1.0238, LPL: 1.3863, Contrastive: 0.0620\n",
      "Epoch 150, Loss: 1.0236, LPL: 1.3863, Contrastive: 0.0611\n",
      "Epoch 200, Loss: 1.0235, LPL: 1.3863, Contrastive: 0.0609\n",
      " - Metrics: Accuracy=0.9424, F1=0.9045, Recall=0.9034, Precision=0.9056\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.26625526948518147, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30136742497786895, margin=0.5111785498137569, lpl_weight=0.7262936518886128\n",
      " - ratio=0.23112465661992612, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0475, LPL: 1.3863, Contrastive: 0.1486\n",
      "Epoch 50, Loss: 1.0240, LPL: 1.3863, Contrastive: 0.0626\n",
      "Epoch 100, Loss: 1.0238, LPL: 1.3863, Contrastive: 0.0620\n",
      "Epoch 150, Loss: 1.0236, LPL: 1.3863, Contrastive: 0.0611\n",
      "Epoch 200, Loss: 1.0235, LPL: 1.3863, Contrastive: 0.0609\n",
      " - Metrics: Accuracy=0.9365, F1=0.8943, Recall=0.8900, Precision=0.8988\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.26625526948518147, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30136742497786895, margin=0.5111785498137569, lpl_weight=0.7262936518886128\n",
      " - ratio=0.23112465661992612, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0475, LPL: 1.3863, Contrastive: 0.1486\n",
      "Epoch 50, Loss: 1.0240, LPL: 1.3863, Contrastive: 0.0626\n",
      "Epoch 100, Loss: 1.0238, LPL: 1.3863, Contrastive: 0.0620\n",
      "Epoch 150, Loss: 1.0236, LPL: 1.3863, Contrastive: 0.0611\n",
      "Epoch 200, Loss: 1.0235, LPL: 1.3863, Contrastive: 0.0609\n",
      " - Metrics: Accuracy=0.9369, F1=0.8959, Recall=0.8998, Precision=0.8921\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.26625526948518147, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30136742497786895, margin=0.5111785498137569, lpl_weight=0.7262936518886128\n",
      " - ratio=0.23112465661992612, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0475, LPL: 1.3863, Contrastive: 0.1486\n",
      "Epoch 50, Loss: 1.0240, LPL: 1.3863, Contrastive: 0.0626\n",
      "Epoch 100, Loss: 1.0238, LPL: 1.3863, Contrastive: 0.0620\n",
      "Epoch 150, Loss: 1.0236, LPL: 1.3863, Contrastive: 0.0611\n",
      "Epoch 200, Loss: 1.0235, LPL: 1.3863, Contrastive: 0.0609\n",
      " - Metrics: Accuracy=0.9391, F1=0.8982, Recall=0.8900, Precision=0.9066\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.26625526948518147, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30136742497786895, margin=0.5111785498137569, lpl_weight=0.7262936518886128\n",
      " - ratio=0.23112465661992612, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0475, LPL: 1.3863, Contrastive: 0.1486\n",
      "Epoch 50, Loss: 1.0240, LPL: 1.3863, Contrastive: 0.0626\n",
      "Epoch 100, Loss: 1.0238, LPL: 1.3863, Contrastive: 0.0620\n",
      "Epoch 150, Loss: 1.0236, LPL: 1.3863, Contrastive: 0.0611\n",
      "Epoch 200, Loss: 1.0235, LPL: 1.3863, Contrastive: 0.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:41:50,943] Trial 17 finished with value: 0.8982590092902513 and parameters: {'alpha': 0.26625526948518147, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.30136742497786895, 'margin': 0.5111785498137569, 'lpl_weight': 0.7262936518886128, 'ratio': 0.23112465661992612, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9387, F1=0.8983, Recall=0.8961, Precision=0.9005\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124004.csv.\n",
      "Average F1 over 5 seeds: 0.8983  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2854399772951729, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30206343105842215, margin=0.5174196267978578, lpl_weight=0.7007423155961452\n",
      " - ratio=0.32708366676627226, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0159, LPL: 1.3863, Contrastive: 0.1485\n",
      "Epoch 50, Loss: 0.9899, LPL: 1.3863, Contrastive: 0.0616\n",
      "Epoch 100, Loss: 0.9895, LPL: 1.3863, Contrastive: 0.0605\n",
      " - Metrics: Accuracy=0.8475, F1=0.7913, Recall=0.9572, Precision=0.6744\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2854399772951729, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30206343105842215, margin=0.5174196267978578, lpl_weight=0.7007423155961452\n",
      " - ratio=0.32708366676627226, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0159, LPL: 1.3863, Contrastive: 0.1485\n",
      "Epoch 50, Loss: 0.9899, LPL: 1.3863, Contrastive: 0.0616\n",
      "Epoch 100, Loss: 0.9895, LPL: 1.3863, Contrastive: 0.0605\n",
      " - Metrics: Accuracy=0.8490, F1=0.7933, Recall=0.9597, Precision=0.6761\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2854399772951729, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30206343105842215, margin=0.5174196267978578, lpl_weight=0.7007423155961452\n",
      " - ratio=0.32708366676627226, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0159, LPL: 1.3863, Contrastive: 0.1485\n",
      "Epoch 50, Loss: 0.9899, LPL: 1.3863, Contrastive: 0.0616\n",
      "Epoch 100, Loss: 0.9895, LPL: 1.3863, Contrastive: 0.0604\n",
      " - Metrics: Accuracy=0.8453, F1=0.7883, Recall=0.9535, Precision=0.6718\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2854399772951729, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30206343105842215, margin=0.5174196267978578, lpl_weight=0.7007423155961452\n",
      " - ratio=0.32708366676627226, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0159, LPL: 1.3863, Contrastive: 0.1485\n",
      "Epoch 50, Loss: 0.9899, LPL: 1.3863, Contrastive: 0.0616\n",
      "Epoch 100, Loss: 0.9895, LPL: 1.3863, Contrastive: 0.0605\n",
      " - Metrics: Accuracy=0.8438, F1=0.7863, Recall=0.9511, Precision=0.6701\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2854399772951729, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30206343105842215, margin=0.5174196267978578, lpl_weight=0.7007423155961452\n",
      " - ratio=0.32708366676627226, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0159, LPL: 1.3863, Contrastive: 0.1485\n",
      "Epoch 50, Loss: 0.9899, LPL: 1.3863, Contrastive: 0.0616\n",
      "Epoch 100, Loss: 0.9895, LPL: 1.3863, Contrastive: 0.0605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:43:06,298] Trial 18 finished with value: 0.7902981303688732 and parameters: {'alpha': 0.2854399772951729, 'K': 31, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.30206343105842215, 'margin': 0.5174196267978578, 'lpl_weight': 0.7007423155961452, 'ratio': 0.32708366676627226, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8482, F1=0.7923, Recall=0.9584, Precision=0.6753\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124151.csv.\n",
      "Average F1 over 5 seeds: 0.7903  0.0026\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.42928798463246615, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2672152824965646, margin=0.5325378361564057, lpl_weight=0.5047449032856341\n",
      " - ratio=0.23648167947721865, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7649, LPL: 1.3863, Contrastive: 0.1315\n",
      " - Metrics: Accuracy=0.9332, F1=0.8913, Recall=0.9071, Precision=0.8760\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.42928798463246615, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2672152824965646, margin=0.5325378361564057, lpl_weight=0.5047449032856341\n",
      " - ratio=0.23648167947721865, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7649, LPL: 1.3863, Contrastive: 0.1315\n",
      " - Metrics: Accuracy=0.9276, F1=0.8842, Recall=0.9144, Precision=0.8558\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.42928798463246615, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2672152824965646, margin=0.5325378361564057, lpl_weight=0.5047449032856341\n",
      " - ratio=0.23648167947721865, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7649, LPL: 1.3863, Contrastive: 0.1315\n",
      " - Metrics: Accuracy=0.9391, F1=0.9008, Recall=0.9156, Precision=0.8864\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.42928798463246615, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2672152824965646, margin=0.5325378361564057, lpl_weight=0.5047449032856341\n",
      " - ratio=0.23648167947721865, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7649, LPL: 1.3863, Contrastive: 0.1315\n",
      " - Metrics: Accuracy=0.9321, F1=0.8889, Recall=0.8998, Precision=0.8783\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.42928798463246615, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2672152824965646, margin=0.5325378361564057, lpl_weight=0.5047449032856341\n",
      " - ratio=0.23648167947721865, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7649, LPL: 1.3863, Contrastive: 0.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:43:36,896] Trial 19 finished with value: 0.8915917308193242 and parameters: {'alpha': 0.42928798463246615, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2672152824965646, 'margin': 0.5325378361564057, 'lpl_weight': 0.5047449032856341, 'ratio': 0.23648167947721865, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9332, F1=0.8928, Recall=0.9218, Precision=0.8657\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124306.csv.\n",
      "Average F1 over 5 seeds: 0.8916  0.0055\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.42483290387373585, K=31, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.2624357642149964, margin=0.5292595967175873, lpl_weight=0.43987560583017976\n",
      " - ratio=0.3668737838738515, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7113, LPL: 1.3863, Contrastive: 0.1813\n",
      "Epoch 50, Loss: 0.6436, LPL: 1.3863, Contrastive: 0.0604\n",
      "Epoch 100, Loss: 0.6423, LPL: 1.3863, Contrastive: 0.0580\n",
      " - Metrics: Accuracy=0.8914, F1=0.8400, Recall=0.9438, Precision=0.7569\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.42483290387373585, K=31, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.2624357642149964, margin=0.5292595967175873, lpl_weight=0.43987560583017976\n",
      " - ratio=0.3668737838738515, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7113, LPL: 1.3863, Contrastive: 0.1812\n",
      "Epoch 50, Loss: 0.6436, LPL: 1.3863, Contrastive: 0.0604\n",
      "Epoch 100, Loss: 0.6423, LPL: 1.3863, Contrastive: 0.0580\n",
      "Epoch 150, Loss: 0.6420, LPL: 1.3863, Contrastive: 0.0576\n",
      "Epoch 200, Loss: 0.6419, LPL: 1.3863, Contrastive: 0.0574\n",
      " - Metrics: Accuracy=0.8966, F1=0.8451, Recall=0.9340, Precision=0.7717\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.42483290387373585, K=31, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.2624357642149964, margin=0.5292595967175873, lpl_weight=0.43987560583017976\n",
      " - ratio=0.3668737838738515, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7113, LPL: 1.3863, Contrastive: 0.1812\n",
      "Epoch 50, Loss: 0.6436, LPL: 1.3863, Contrastive: 0.0604\n",
      "Epoch 100, Loss: 0.6423, LPL: 1.3863, Contrastive: 0.0580\n",
      "Epoch 150, Loss: 0.6420, LPL: 1.3863, Contrastive: 0.0576\n",
      "Epoch 200, Loss: 0.6419, LPL: 1.3863, Contrastive: 0.0574\n",
      " - Metrics: Accuracy=0.8940, F1=0.8424, Recall=0.9377, Precision=0.7647\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.42483290387373585, K=31, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.2624357642149964, margin=0.5292595967175873, lpl_weight=0.43987560583017976\n",
      " - ratio=0.3668737838738515, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7113, LPL: 1.3863, Contrastive: 0.1813\n",
      "Epoch 50, Loss: 0.6436, LPL: 1.3863, Contrastive: 0.0604\n",
      "Epoch 100, Loss: 0.6423, LPL: 1.3863, Contrastive: 0.0580\n",
      " - Metrics: Accuracy=0.9051, F1=0.8578, Recall=0.9474, Precision=0.7836\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.42483290387373585, K=31, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.2624357642149964, margin=0.5292595967175873, lpl_weight=0.43987560583017976\n",
      " - ratio=0.3668737838738515, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7113, LPL: 1.3863, Contrastive: 0.1813\n",
      "Epoch 50, Loss: 0.6436, LPL: 1.3863, Contrastive: 0.0604\n",
      "Epoch 100, Loss: 0.6423, LPL: 1.3863, Contrastive: 0.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:44:45,797] Trial 20 finished with value: 0.8440806068807618 and parameters: {'alpha': 0.42483290387373585, 'K': 31, 'layers': 1, 'hidden_channels': 64, 'out_channels': 128, 'norm': None, 'dropout': 0.2624357642149964, 'margin': 0.5292595967175873, 'lpl_weight': 0.43987560583017976, 'ratio': 0.3668737838738515, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8881, F1=0.8351, Recall=0.9377, Precision=0.7527\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124336.csv.\n",
      "Average F1 over 5 seeds: 0.8441  0.0076\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.38182984202632975, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3357861080839064, margin=0.6828816765826357, lpl_weight=0.5528499856800607\n",
      " - ratio=0.25054363660167606, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8295, LPL: 1.3863, Contrastive: 0.1410\n",
      " - Metrics: Accuracy=0.9210, F1=0.8738, Recall=0.9059, Precision=0.8440\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.38182984202632975, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3357861080839064, margin=0.6828816765826357, lpl_weight=0.5528499856800607\n",
      " - ratio=0.25054363660167606, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8295, LPL: 1.3863, Contrastive: 0.1410\n",
      " - Metrics: Accuracy=0.9247, F1=0.8790, Recall=0.9059, Precision=0.8537\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.38182984202632975, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3357861080839064, margin=0.6828816765826357, lpl_weight=0.5528499856800607\n",
      " - ratio=0.25054363660167606, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8295, LPL: 1.3863, Contrastive: 0.1410\n",
      " - Metrics: Accuracy=0.9162, F1=0.8658, Recall=0.8949, Precision=0.8385\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.38182984202632975, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3357861080839064, margin=0.6828816765826357, lpl_weight=0.5528499856800607\n",
      " - ratio=0.25054363660167606, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8295, LPL: 1.3863, Contrastive: 0.1410\n",
      " - Metrics: Accuracy=0.9143, F1=0.8624, Recall=0.8888, Precision=0.8376\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.38182984202632975, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3357861080839064, margin=0.6828816765826357, lpl_weight=0.5528499856800607\n",
      " - ratio=0.25054363660167606, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8295, LPL: 1.3863, Contrastive: 0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:45:16,097] Trial 21 finished with value: 0.8679540096421438 and parameters: {'alpha': 0.38182984202632975, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3357861080839064, 'margin': 0.6828816765826357, 'lpl_weight': 0.5528499856800607, 'ratio': 0.25054363660167606, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9095, F1=0.8588, Recall=0.9108, Precision=0.8124\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124445.csv.\n",
      "Average F1 over 5 seeds: 0.8680  0.0074\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.22525476728375468, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2643556194206348, margin=0.4810298715327729, lpl_weight=0.3327894187494038\n",
      " - ratio=0.14972341103053008, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5502, LPL: 1.3863, Contrastive: 0.1332\n",
      "Epoch 50, Loss: 0.5084, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 100, Loss: 0.5075, LPL: 1.3863, Contrastive: 0.0692\n",
      " - Metrics: Accuracy=0.9309, F1=0.8779, Recall=0.8215, Precision=0.9425\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.22525476728375468, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2643556194206348, margin=0.4810298715327729, lpl_weight=0.3327894187494038\n",
      " - ratio=0.14972341103053008, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5502, LPL: 1.3863, Contrastive: 0.1332\n",
      "Epoch 50, Loss: 0.5084, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 100, Loss: 0.5075, LPL: 1.3863, Contrastive: 0.0692\n",
      " - Metrics: Accuracy=0.9258, F1=0.8706, Recall=0.8264, Precision=0.9197\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.22525476728375468, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2643556194206348, margin=0.4810298715327729, lpl_weight=0.3327894187494038\n",
      " - ratio=0.14972341103053008, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5502, LPL: 1.3863, Contrastive: 0.1332\n",
      "Epoch 50, Loss: 0.5084, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 100, Loss: 0.5075, LPL: 1.3863, Contrastive: 0.0692\n",
      " - Metrics: Accuracy=0.9354, F1=0.8870, Recall=0.8399, Precision=0.9398\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.22525476728375468, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2643556194206348, margin=0.4810298715327729, lpl_weight=0.3327894187494038\n",
      " - ratio=0.14972341103053008, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5502, LPL: 1.3863, Contrastive: 0.1332\n",
      "Epoch 50, Loss: 0.5084, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 100, Loss: 0.5075, LPL: 1.3863, Contrastive: 0.0692\n",
      " - Metrics: Accuracy=0.9284, F1=0.8752, Recall=0.8313, Precision=0.9239\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.22525476728375468, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2643556194206348, margin=0.4810298715327729, lpl_weight=0.3327894187494038\n",
      " - ratio=0.14972341103053008, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5502, LPL: 1.3863, Contrastive: 0.1332\n",
      "Epoch 50, Loss: 0.5084, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 100, Loss: 0.5075, LPL: 1.3863, Contrastive: 0.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:46:25,300] Trial 22 finished with value: 0.8794693693766854 and parameters: {'alpha': 0.22525476728375468, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2643556194206348, 'margin': 0.4810298715327729, 'lpl_weight': 0.3327894187494038, 'ratio': 0.14972341103053008, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9354, F1=0.8867, Recall=0.8374, Precision=0.9422\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124516.csv.\n",
      "Average F1 over 5 seeds: 0.8795  0.0065\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.28254992119514954, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41987837409257045, margin=0.6034748052687551, lpl_weight=0.7495701999780726\n",
      " - ratio=0.2337708689222279, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0796, LPL: 1.3863, Contrastive: 0.1615\n",
      " - Metrics: Accuracy=0.9269, F1=0.8812, Recall=0.8973, Precision=0.8656\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.28254992119514954, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41987837409257045, margin=0.6034748052687551, lpl_weight=0.7495701999780726\n",
      " - ratio=0.2337708689222279, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0796, LPL: 1.3863, Contrastive: 0.1615\n",
      " - Metrics: Accuracy=0.9210, F1=0.8732, Recall=0.9010, Precision=0.8471\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.28254992119514954, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41987837409257045, margin=0.6034748052687551, lpl_weight=0.7495701999780726\n",
      " - ratio=0.2337708689222279, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0796, LPL: 1.3863, Contrastive: 0.1615\n",
      " - Metrics: Accuracy=0.9258, F1=0.8793, Recall=0.8949, Precision=0.8642\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.28254992119514954, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41987837409257045, margin=0.6034748052687551, lpl_weight=0.7495701999780726\n",
      " - ratio=0.2337708689222279, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0796, LPL: 1.3863, Contrastive: 0.1615\n",
      " - Metrics: Accuracy=0.9210, F1=0.8715, Recall=0.8875, Precision=0.8561\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.28254992119514954, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41987837409257045, margin=0.6034748052687551, lpl_weight=0.7495701999780726\n",
      " - ratio=0.2337708689222279, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0796, LPL: 1.3863, Contrastive: 0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:46:56,856] Trial 23 finished with value: 0.8765987885678383 and parameters: {'alpha': 0.28254992119514954, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.41987837409257045, 'margin': 0.6034748052687551, 'lpl_weight': 0.7495701999780726, 'ratio': 0.2337708689222279, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9232, F1=0.8778, Recall=0.9132, Precision=0.8450\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124625.csv.\n",
      "Average F1 over 5 seeds: 0.8766  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3865516084536964, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.28585854246527576, margin=0.20379334279075662, lpl_weight=0.6191721351694487\n",
      " - ratio=0.1695841059927249, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9298, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 0.9201, LPL: 1.3863, Contrastive: 0.1620\n",
      " - Metrics: Accuracy=0.9295, F1=0.8762, Recall=0.8264, Precision=0.9324\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3865516084536964, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.28585854246527576, margin=0.20379334279075662, lpl_weight=0.6191721351694487\n",
      " - ratio=0.1695841059927249, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9298, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 0.9201, LPL: 1.3863, Contrastive: 0.1620\n",
      " - Metrics: Accuracy=0.9276, F1=0.8729, Recall=0.8227, Precision=0.9296\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3865516084536964, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.28585854246527576, margin=0.20379334279075662, lpl_weight=0.6191721351694487\n",
      " - ratio=0.1695841059927249, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9298, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 0.9201, LPL: 1.3863, Contrastive: 0.1621\n",
      "Epoch 100, Loss: 0.9207, LPL: 1.3863, Contrastive: 0.1636\n",
      " - Metrics: Accuracy=0.9346, F1=0.8862, Recall=0.8423, Precision=0.9349\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3865516084536964, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.28585854246527576, margin=0.20379334279075662, lpl_weight=0.6191721351694487\n",
      " - ratio=0.1695841059927249, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9298, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 0.9201, LPL: 1.3863, Contrastive: 0.1620\n",
      " - Metrics: Accuracy=0.9317, F1=0.8799, Recall=0.8289, Precision=0.9378\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3865516084536964, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.28585854246527576, margin=0.20379334279075662, lpl_weight=0.6191721351694487\n",
      " - ratio=0.1695841059927249, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9298, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 0.9201, LPL: 1.3863, Contrastive: 0.1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:48:02,810] Trial 24 finished with value: 0.8805106351248287 and parameters: {'alpha': 0.3865516084536964, 'K': 27, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.28585854246527576, 'margin': 0.20379334279075662, 'lpl_weight': 0.6191721351694487, 'ratio': 0.1695841059927249, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9350, F1=0.8873, Recall=0.8472, Precision=0.9315\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124656.csv.\n",
      "Average F1 over 5 seeds: 0.8805  0.0056\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1058800381265228, K=32, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3309419023459293, margin=0.44003910671893365, lpl_weight=0.500101587495393\n",
      " - ratio=0.3016835342700688, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7662, LPL: 1.3863, Contrastive: 0.1458\n",
      "Epoch 50, Loss: 0.7344, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.7336, LPL: 1.3863, Contrastive: 0.0807\n",
      " - Metrics: Accuracy=0.9173, F1=0.8716, Recall=0.9291, Precision=0.8207\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1058800381265228, K=32, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3309419023459293, margin=0.44003910671893365, lpl_weight=0.500101587495393\n",
      " - ratio=0.3016835342700688, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7662, LPL: 1.3863, Contrastive: 0.1458\n",
      "Epoch 50, Loss: 0.7344, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.7336, LPL: 1.3863, Contrastive: 0.0807\n",
      " - Metrics: Accuracy=0.9136, F1=0.8660, Recall=0.9242, Precision=0.8147\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1058800381265228, K=32, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3309419023459293, margin=0.44003910671893365, lpl_weight=0.500101587495393\n",
      " - ratio=0.3016835342700688, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7662, LPL: 1.3863, Contrastive: 0.1458\n",
      "Epoch 50, Loss: 0.7344, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.7336, LPL: 1.3863, Contrastive: 0.0807\n",
      " - Metrics: Accuracy=0.9225, F1=0.8797, Recall=0.9389, Precision=0.8276\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1058800381265228, K=32, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3309419023459293, margin=0.44003910671893365, lpl_weight=0.500101587495393\n",
      " - ratio=0.3016835342700688, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7662, LPL: 1.3863, Contrastive: 0.1458\n",
      "Epoch 50, Loss: 0.7344, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.7336, LPL: 1.3863, Contrastive: 0.0807\n",
      " - Metrics: Accuracy=0.9151, F1=0.8671, Recall=0.9169, Precision=0.8224\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1058800381265228, K=32, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3309419023459293, margin=0.44003910671893365, lpl_weight=0.500101587495393\n",
      " - ratio=0.3016835342700688, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7662, LPL: 1.3863, Contrastive: 0.1458\n",
      "Epoch 50, Loss: 0.7344, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.7336, LPL: 1.3863, Contrastive: 0.0807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:49:17,772] Trial 25 finished with value: 0.871304485445558 and parameters: {'alpha': 0.1058800381265228, 'K': 32, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3309419023459293, 'margin': 0.44003910671893365, 'lpl_weight': 0.500101587495393, 'ratio': 0.3016835342700688, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9177, F1=0.8722, Recall=0.9303, Precision=0.8209\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124802.csv.\n",
      "Average F1 over 5 seeds: 0.8713  0.0049\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.24946985491401957, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.22916730491739631, margin=0.7222758879149309, lpl_weight=0.7753842136204387\n",
      " - ratio=0.2150862992653455, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1051, LPL: 1.3863, Contrastive: 0.1344\n",
      " - Metrics: Accuracy=0.9173, F1=0.8699, Recall=0.9156, Precision=0.8285\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.24946985491401957, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.22916730491739631, margin=0.7222758879149309, lpl_weight=0.7753842136204387\n",
      " - ratio=0.2150862992653455, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1051, LPL: 1.3863, Contrastive: 0.1344\n",
      " - Metrics: Accuracy=0.9106, F1=0.8595, Recall=0.9046, Precision=0.8186\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.24946985491401957, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.22916730491739631, margin=0.7222758879149309, lpl_weight=0.7753842136204387\n",
      " - ratio=0.2150862992653455, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1051, LPL: 1.3863, Contrastive: 0.1344\n",
      " - Metrics: Accuracy=0.9084, F1=0.8560, Recall=0.9010, Precision=0.8153\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.24946985491401957, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.22916730491739631, margin=0.7222758879149309, lpl_weight=0.7753842136204387\n",
      " - ratio=0.2150862992653455, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1051, LPL: 1.3863, Contrastive: 0.1344\n",
      " - Metrics: Accuracy=0.9055, F1=0.8513, Recall=0.8961, Precision=0.8108\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.24946985491401957, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.22916730491739631, margin=0.7222758879149309, lpl_weight=0.7753842136204387\n",
      " - ratio=0.2150862992653455, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1051, LPL: 1.3863, Contrastive: 0.1344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:49:56,936] Trial 26 finished with value: 0.859100906274274 and parameters: {'alpha': 0.24946985491401957, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.22916730491739631, 'margin': 0.7222758879149309, 'lpl_weight': 0.7753842136204387, 'ratio': 0.2150862992653455, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9103, F1=0.8588, Recall=0.9034, Precision=0.8184\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124917.csv.\n",
      "Average F1 over 5 seeds: 0.8591  0.0061\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5032244987676511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2861690544767157, margin=0.2965898322438506, lpl_weight=0.6360339926615408\n",
      " - ratio=0.1903498607963967, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9423, LPL: 1.3863, Contrastive: 0.1665\n",
      "Epoch 50, Loss: 0.9279, LPL: 1.3863, Contrastive: 0.1269\n",
      " - Metrics: Accuracy=0.9354, F1=0.8895, Recall=0.8606, Precision=0.9203\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5032244987676511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2861690544767157, margin=0.2965898322438506, lpl_weight=0.6360339926615408\n",
      " - ratio=0.1903498607963967, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9423, LPL: 1.3863, Contrastive: 0.1665\n",
      "Epoch 50, Loss: 0.9279, LPL: 1.3863, Contrastive: 0.1269\n",
      " - Metrics: Accuracy=0.9332, F1=0.8859, Recall=0.8594, Precision=0.9142\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5032244987676511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2861690544767157, margin=0.2965898322438506, lpl_weight=0.6360339926615408\n",
      " - ratio=0.1903498607963967, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9423, LPL: 1.3863, Contrastive: 0.1665\n",
      "Epoch 50, Loss: 0.9279, LPL: 1.3863, Contrastive: 0.1269\n",
      " - Metrics: Accuracy=0.9369, F1=0.8933, Recall=0.8753, Precision=0.9121\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5032244987676511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2861690544767157, margin=0.2965898322438506, lpl_weight=0.6360339926615408\n",
      " - ratio=0.1903498607963967, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9423, LPL: 1.3863, Contrastive: 0.1665\n",
      "Epoch 50, Loss: 0.9279, LPL: 1.3863, Contrastive: 0.1269\n",
      " - Metrics: Accuracy=0.9328, F1=0.8844, Recall=0.8509, Precision=0.9206\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5032244987676511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2861690544767157, margin=0.2965898322438506, lpl_weight=0.6360339926615408\n",
      " - ratio=0.1903498607963967, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9423, LPL: 1.3863, Contrastive: 0.1665\n",
      "Epoch 50, Loss: 0.9279, LPL: 1.3863, Contrastive: 0.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:51:02,475] Trial 27 finished with value: 0.8887893041263861 and parameters: {'alpha': 0.5032244987676511, 'K': 31, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.2861690544767157, 'margin': 0.2965898322438506, 'lpl_weight': 0.6360339926615408, 'ratio': 0.1903498607963967, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9361, F1=0.8909, Recall=0.8631, Precision=0.9205\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102124957.csv.\n",
      "Average F1 over 5 seeds: 0.8888  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3705855231918886, K=27, layers=2, hidden=64, out=64\n",
      " - norm=None, dropout=0.17480439385345464, margin=0.6306737004211993, lpl_weight=0.8918811465469973\n",
      " - ratio=0.2598831583883654, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2495, LPL: 1.3863, Contrastive: 0.1215\n",
      "Epoch 50, Loss: 1.2404, LPL: 1.3863, Contrastive: 0.0373\n",
      "Epoch 100, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0359\n",
      "Epoch 150, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0356\n",
      "Epoch 200, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.0354\n",
      "Epoch 250, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.0352\n",
      " - Metrics: Accuracy=0.9372, F1=0.8984, Recall=0.9193, Precision=0.8785\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3705855231918886, K=27, layers=2, hidden=64, out=64\n",
      " - norm=None, dropout=0.17480439385345464, margin=0.6306737004211993, lpl_weight=0.8918811465469973\n",
      " - ratio=0.2598831583883654, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2495, LPL: 1.3863, Contrastive: 0.1215\n",
      "Epoch 50, Loss: 1.2404, LPL: 1.3863, Contrastive: 0.0373\n",
      "Epoch 100, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0359\n",
      "Epoch 150, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0356\n",
      "Epoch 200, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.0354\n",
      "Epoch 250, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.0352\n",
      " - Metrics: Accuracy=0.9276, F1=0.8837, Recall=0.9108, Precision=0.8583\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3705855231918886, K=27, layers=2, hidden=64, out=64\n",
      " - norm=None, dropout=0.17480439385345464, margin=0.6306737004211993, lpl_weight=0.8918811465469973\n",
      " - ratio=0.2598831583883654, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2495, LPL: 1.3863, Contrastive: 0.1215\n",
      "Epoch 50, Loss: 1.2404, LPL: 1.3863, Contrastive: 0.0373\n",
      "Epoch 100, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0359\n",
      "Epoch 150, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0356\n",
      "Epoch 200, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.0354\n",
      "Epoch 250, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.0352\n",
      " - Metrics: Accuracy=0.9258, F1=0.8814, Recall=0.9132, Precision=0.8518\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3705855231918886, K=27, layers=2, hidden=64, out=64\n",
      " - norm=None, dropout=0.17480439385345464, margin=0.6306737004211993, lpl_weight=0.8918811465469973\n",
      " - ratio=0.2598831583883654, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2495, LPL: 1.3863, Contrastive: 0.1215\n",
      "Epoch 50, Loss: 1.2404, LPL: 1.3863, Contrastive: 0.0373\n",
      "Epoch 100, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0359\n",
      "Epoch 150, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0356\n",
      " - Metrics: Accuracy=0.9313, F1=0.8890, Recall=0.9108, Precision=0.8683\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3705855231918886, K=27, layers=2, hidden=64, out=64\n",
      " - norm=None, dropout=0.17480439385345464, margin=0.6306737004211993, lpl_weight=0.8918811465469973\n",
      " - ratio=0.2598831583883654, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2495, LPL: 1.3863, Contrastive: 0.1215\n",
      "Epoch 50, Loss: 1.2404, LPL: 1.3863, Contrastive: 0.0373\n",
      "Epoch 100, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0359\n",
      "Epoch 150, Loss: 1.2403, LPL: 1.3863, Contrastive: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:52:31,113] Trial 28 finished with value: 0.8853184663972984 and parameters: {'alpha': 0.3705855231918886, 'K': 27, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': None, 'dropout': 0.17480439385345464, 'margin': 0.6306737004211993, 'lpl_weight': 0.8918811465469973, 'ratio': 0.2598831583883654, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9217, F1=0.8740, Recall=0.8985, Precision=0.8507\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102125102.csv.\n",
      "Average F1 over 5 seeds: 0.8853  0.0082\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.19894495924676753, K=30, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.25594888663190996, margin=0.7992749980383231, lpl_weight=0.33123591009907827\n",
      " - ratio=0.3604958744550817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5441, LPL: 1.3863, Contrastive: 0.1270\n",
      " - Metrics: Accuracy=0.8146, F1=0.7558, Recall=0.9499, Precision=0.6276\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.19894495924676753, K=30, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.25594888663190996, margin=0.7992749980383231, lpl_weight=0.33123591009907827\n",
      " - ratio=0.3604958744550817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5441, LPL: 1.3863, Contrastive: 0.1270\n",
      " - Metrics: Accuracy=0.8168, F1=0.7588, Recall=0.9535, Precision=0.6300\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.19894495924676753, K=30, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.25594888663190996, margin=0.7992749980383231, lpl_weight=0.33123591009907827\n",
      " - ratio=0.3604958744550817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5441, LPL: 1.3863, Contrastive: 0.1270\n",
      " - Metrics: Accuracy=0.8146, F1=0.7558, Recall=0.9499, Precision=0.6276\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.19894495924676753, K=30, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.25594888663190996, margin=0.7992749980383231, lpl_weight=0.33123591009907827\n",
      " - ratio=0.3604958744550817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5441, LPL: 1.3863, Contrastive: 0.1270\n",
      " - Metrics: Accuracy=0.8102, F1=0.7500, Recall=0.9425, Precision=0.6228\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.19894495924676753, K=30, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.25594888663190996, margin=0.7992749980383231, lpl_weight=0.33123591009907827\n",
      " - ratio=0.3604958744550817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5441, LPL: 1.3863, Contrastive: 0.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:53:01,938] Trial 29 finished with value: 0.7544747081712062 and parameters: {'alpha': 0.19894495924676753, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.25594888663190996, 'margin': 0.7992749980383231, 'lpl_weight': 0.33123591009907827, 'ratio': 0.3604958744550817, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8117, F1=0.7519, Recall=0.9450, Precision=0.6244\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102125231.csv.\n",
      "Average F1 over 5 seeds: 0.7545  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5887243447688507, K=33, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.3561625453386178, margin=0.760154088333491, lpl_weight=0.11119009774824379\n",
      " - ratio=0.13520962471949444, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.1837\n",
      " - Metrics: Accuracy=0.9088, F1=0.8341, Recall=0.7592, Precision=0.9255\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5887243447688507, K=33, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.3561625453386178, margin=0.760154088333491, lpl_weight=0.11119009774824379\n",
      " - ratio=0.13520962471949444, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.1837\n",
      " - Metrics: Accuracy=0.9147, F1=0.8436, Recall=0.7616, Precision=0.9454\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5887243447688507, K=33, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.3561625453386178, margin=0.760154088333491, lpl_weight=0.11119009774824379\n",
      " - ratio=0.13520962471949444, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.1837\n",
      " - Metrics: Accuracy=0.9092, F1=0.8342, Recall=0.7567, Precision=0.9294\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5887243447688507, K=33, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.3561625453386178, margin=0.760154088333491, lpl_weight=0.11119009774824379\n",
      " - ratio=0.13520962471949444, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.1837\n",
      " - Metrics: Accuracy=0.9106, F1=0.8363, Recall=0.7555, Precision=0.9364\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5887243447688507, K=33, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.3561625453386178, margin=0.760154088333491, lpl_weight=0.11119009774824379\n",
      " - ratio=0.13520962471949444, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:53:30,361] Trial 30 finished with value: 0.8401525397560533 and parameters: {'alpha': 0.5887243447688507, 'K': 33, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.3561625453386178, 'margin': 0.760154088333491, 'lpl_weight': 0.11119009774824379, 'ratio': 0.13520962471949444, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9188, F1=0.8525, Recall=0.7775, Precision=0.9436\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102125302.csv.\n",
      "Average F1 over 5 seeds: 0.8402  0.0071\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1477505644885977, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3927482998839901, margin=0.47652501051606794, lpl_weight=0.8877322656407189\n",
      " - ratio=0.1954867936976763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2493, LPL: 1.3863, Contrastive: 0.1657\n",
      "Epoch 50, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 100, Loss: 1.2386, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 150, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0727\n",
      " - Metrics: Accuracy=0.9424, F1=0.9038, Recall=0.8961, Precision=0.9117\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1477505644885977, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3927482998839901, margin=0.47652501051606794, lpl_weight=0.8877322656407189\n",
      " - ratio=0.1954867936976763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2493, LPL: 1.3863, Contrastive: 0.1657\n",
      "Epoch 50, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 100, Loss: 1.2386, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 150, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0727\n",
      " - Metrics: Accuracy=0.9306, F1=0.8834, Recall=0.8704, Precision=0.8967\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1477505644885977, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3927482998839901, margin=0.47652501051606794, lpl_weight=0.8877322656407189\n",
      " - ratio=0.1954867936976763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2493, LPL: 1.3863, Contrastive: 0.1657\n",
      "Epoch 50, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 100, Loss: 1.2386, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 150, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0727\n",
      " - Metrics: Accuracy=0.9394, F1=0.8986, Recall=0.8888, Precision=0.9087\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1477505644885977, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3927482998839901, margin=0.47652501051606794, lpl_weight=0.8877322656407189\n",
      " - ratio=0.1954867936976763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2493, LPL: 1.3863, Contrastive: 0.1657\n",
      "Epoch 50, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 100, Loss: 1.2386, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 150, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0727\n",
      " - Metrics: Accuracy=0.9361, F1=0.8922, Recall=0.8753, Precision=0.9098\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1477505644885977, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3927482998839901, margin=0.47652501051606794, lpl_weight=0.8877322656407189\n",
      " - ratio=0.1954867936976763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2493, LPL: 1.3863, Contrastive: 0.1657\n",
      "Epoch 50, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 100, Loss: 1.2386, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 150, Loss: 1.2388, LPL: 1.3863, Contrastive: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:55:02,427] Trial 31 finished with value: 0.8938545997858242 and parameters: {'alpha': 0.1477505644885977, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3927482998839901, 'margin': 0.47652501051606794, 'lpl_weight': 0.8877322656407189, 'ratio': 0.1954867936976763, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9350, F1=0.8912, Recall=0.8814, Precision=0.9012\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102125330.csv.\n",
      "Average F1 over 5 seeds: 0.8939  0.0070\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1611019567515363, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4322701975179897, margin=0.44574587659122644, lpl_weight=0.9068302777542994\n",
      " - ratio=0.2324005265050748, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0807\n",
      "Epoch 100, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0799\n",
      " - Metrics: Accuracy=0.9413, F1=0.9038, Recall=0.9132, Precision=0.8946\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1611019567515363, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4322701975179897, margin=0.44574587659122644, lpl_weight=0.9068302777542994\n",
      " - ratio=0.2324005265050748, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0807\n",
      "Epoch 100, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0799\n",
      " - Metrics: Accuracy=0.9317, F1=0.8875, Recall=0.8924, Precision=0.8827\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1611019567515363, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4322701975179897, margin=0.44574587659122644, lpl_weight=0.9068302777542994\n",
      " - ratio=0.2324005265050748, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0807\n",
      "Epoch 100, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0799\n",
      " - Metrics: Accuracy=0.9369, F1=0.8964, Recall=0.9046, Precision=0.8884\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1611019567515363, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4322701975179897, margin=0.44574587659122644, lpl_weight=0.9068302777542994\n",
      " - ratio=0.2324005265050748, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0807\n",
      "Epoch 100, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0799\n",
      " - Metrics: Accuracy=0.9376, F1=0.8975, Recall=0.9046, Precision=0.8905\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1611019567515363, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4322701975179897, margin=0.44574587659122644, lpl_weight=0.9068302777542994\n",
      " - ratio=0.2324005265050748, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0807\n",
      "Epoch 100, Loss: 1.2646, LPL: 1.3863, Contrastive: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:56:13,209] Trial 32 finished with value: 0.8953422029433973 and parameters: {'alpha': 0.1611019567515363, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4322701975179897, 'margin': 0.44574587659122644, 'lpl_weight': 0.9068302777542994, 'ratio': 0.2324005265050748, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9332, F1=0.8914, Recall=0.9083, Precision=0.8751\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102125502.csv.\n",
      "Average F1 over 5 seeds: 0.8953  0.0055\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.17827488489061344, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.43588266482249083, margin=0.4600631145158942, lpl_weight=0.9296042017206501\n",
      " - ratio=0.23659858364990255, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3010, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2941, LPL: 1.3863, Contrastive: 0.0773\n",
      "Epoch 100, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.0752\n",
      " - Metrics: Accuracy=0.9380, F1=0.8974, Recall=0.8985, Precision=0.8963\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.17827488489061344, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.43588266482249083, margin=0.4600631145158942, lpl_weight=0.9296042017206501\n",
      " - ratio=0.23659858364990255, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3010, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2941, LPL: 1.3863, Contrastive: 0.0773\n",
      "Epoch 100, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.0752\n",
      " - Metrics: Accuracy=0.9291, F1=0.8839, Recall=0.8936, Precision=0.8744\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.17827488489061344, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.43588266482249083, margin=0.4600631145158942, lpl_weight=0.9296042017206501\n",
      " - ratio=0.23659858364990255, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3010, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2941, LPL: 1.3863, Contrastive: 0.0773\n",
      "Epoch 100, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.0752\n",
      " - Metrics: Accuracy=0.9417, F1=0.9029, Recall=0.8985, Precision=0.9074\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.17827488489061344, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.43588266482249083, margin=0.4600631145158942, lpl_weight=0.9296042017206501\n",
      " - ratio=0.23659858364990255, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3010, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2941, LPL: 1.3863, Contrastive: 0.0773\n",
      "Epoch 100, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.0752\n",
      " - Metrics: Accuracy=0.9365, F1=0.8960, Recall=0.9059, Precision=0.8864\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.17827488489061344, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.43588266482249083, margin=0.4600631145158942, lpl_weight=0.9296042017206501\n",
      " - ratio=0.23659858364990255, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3010, LPL: 1.3863, Contrastive: 0.1752\n",
      "Epoch 50, Loss: 1.2941, LPL: 1.3863, Contrastive: 0.0773\n",
      "Epoch 100, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:57:30,513] Trial 33 finished with value: 0.8962687857428872 and parameters: {'alpha': 0.17827488489061344, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.43588266482249083, 'margin': 0.4600631145158942, 'lpl_weight': 0.9296042017206501, 'ratio': 0.23659858364990255, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9398, F1=0.9010, Recall=0.9071, Precision=0.8951\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102125613.csv.\n",
      "Average F1 over 5 seeds: 0.8963  0.0067\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.17286040085571475, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4481036667154943, margin=0.44982956730772994, lpl_weight=0.9418635005526856\n",
      " - ratio=0.2916262596838199, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3161, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3104, LPL: 1.3863, Contrastive: 0.0804\n",
      "Epoch 100, Loss: 1.3102, LPL: 1.3863, Contrastive: 0.0782\n",
      " - Metrics: Accuracy=0.9295, F1=0.8890, Recall=0.9352, Precision=0.8472\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.17286040085571475, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4481036667154943, margin=0.44982956730772994, lpl_weight=0.9418635005526856\n",
      " - ratio=0.2916262596838199, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3161, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3104, LPL: 1.3863, Contrastive: 0.0804\n",
      "Epoch 100, Loss: 1.3102, LPL: 1.3863, Contrastive: 0.0782\n",
      " - Metrics: Accuracy=0.9269, F1=0.8842, Recall=0.9242, Precision=0.8475\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.17286040085571475, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4481036667154943, margin=0.44982956730772994, lpl_weight=0.9418635005526856\n",
      " - ratio=0.2916262596838199, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3161, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3104, LPL: 1.3863, Contrastive: 0.0804\n",
      "Epoch 100, Loss: 1.3102, LPL: 1.3863, Contrastive: 0.0782\n",
      " - Metrics: Accuracy=0.9180, F1=0.8723, Recall=0.9267, Precision=0.8239\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.17286040085571475, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4481036667154943, margin=0.44982956730772994, lpl_weight=0.9418635005526856\n",
      " - ratio=0.2916262596838199, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3161, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3104, LPL: 1.3863, Contrastive: 0.0804\n",
      "Epoch 100, Loss: 1.3102, LPL: 1.3863, Contrastive: 0.0782\n",
      " - Metrics: Accuracy=0.9265, F1=0.8825, Recall=0.9132, Precision=0.8537\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.17286040085571475, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4481036667154943, margin=0.44982956730772994, lpl_weight=0.9418635005526856\n",
      " - ratio=0.2916262596838199, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3161, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3104, LPL: 1.3863, Contrastive: 0.0804\n",
      "Epoch 100, Loss: 1.3102, LPL: 1.3863, Contrastive: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 12:58:47,179] Trial 34 finished with value: 0.882116359444528 and parameters: {'alpha': 0.17286040085571475, 'K': 26, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4481036667154943, 'margin': 0.44982956730772994, 'lpl_weight': 0.9418635005526856, 'ratio': 0.2916262596838199, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9261, F1=0.8826, Recall=0.9193, Precision=0.8488\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102125730.csv.\n",
      "Average F1 over 5 seeds: 0.8821  0.0055\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.23418845156130824, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4922468100225803, margin=0.2934080994785821, lpl_weight=0.9222458402201523\n",
      " - ratio=0.23834213596540837, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.1990\n",
      "Epoch 50, Loss: 1.2886, LPL: 1.3863, Contrastive: 0.1303\n",
      "Epoch 100, Loss: 1.2885, LPL: 1.3863, Contrastive: 0.1280\n",
      " - Metrics: Accuracy=0.9317, F1=0.8878, Recall=0.8949, Precision=0.8809\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.23418845156130824, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4922468100225803, margin=0.2934080994785821, lpl_weight=0.9222458402201523\n",
      " - ratio=0.23834213596540837, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.1990\n",
      "Epoch 50, Loss: 1.2886, LPL: 1.3863, Contrastive: 0.1303\n",
      "Epoch 100, Loss: 1.2885, LPL: 1.3863, Contrastive: 0.1280\n",
      " - Metrics: Accuracy=0.9213, F1=0.8731, Recall=0.8961, Precision=0.8513\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.23418845156130824, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4922468100225803, margin=0.2934080994785821, lpl_weight=0.9222458402201523\n",
      " - ratio=0.23834213596540837, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.1990\n",
      "Epoch 50, Loss: 1.2886, LPL: 1.3863, Contrastive: 0.1303\n",
      "Epoch 100, Loss: 1.2885, LPL: 1.3863, Contrastive: 0.1280\n",
      " - Metrics: Accuracy=0.9350, F1=0.8935, Recall=0.9022, Precision=0.8849\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.23418845156130824, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4922468100225803, margin=0.2934080994785821, lpl_weight=0.9222458402201523\n",
      " - ratio=0.23834213596540837, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.1990\n",
      "Epoch 50, Loss: 1.2886, LPL: 1.3863, Contrastive: 0.1303\n",
      "Epoch 100, Loss: 1.2885, LPL: 1.3863, Contrastive: 0.1280\n",
      " - Metrics: Accuracy=0.9324, F1=0.8898, Recall=0.9034, Precision=0.8766\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.23418845156130824, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4922468100225803, margin=0.2934080994785821, lpl_weight=0.9222458402201523\n",
      " - ratio=0.23834213596540837, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2940, LPL: 1.3863, Contrastive: 0.1990\n",
      "Epoch 50, Loss: 1.2886, LPL: 1.3863, Contrastive: 0.1303\n",
      "Epoch 100, Loss: 1.2885, LPL: 1.3863, Contrastive: 0.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:00:01,831] Trial 35 finished with value: 0.8869461650167081 and parameters: {'alpha': 0.23418845156130824, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4922468100225803, 'margin': 0.2934080994785821, 'lpl_weight': 0.9222458402201523, 'ratio': 0.23834213596540837, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9328, F1=0.8905, Recall=0.9046, Precision=0.8768\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102125847.csv.\n",
      "Average F1 over 5 seeds: 0.8869  0.0071\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.34150530211691593, K=26, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.42919042319339296, margin=0.4761943991240059, lpl_weight=0.763091696640072\n",
      " - ratio=0.182611623197284, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0777, LPL: 1.3863, Contrastive: 0.0837\n",
      "Epoch 50, Loss: 1.0744, LPL: 1.3863, Contrastive: 0.0698\n",
      "Epoch 100, Loss: 1.0745, LPL: 1.3863, Contrastive: 0.0701\n",
      " - Metrics: Accuracy=0.9081, F1=0.8339, Recall=0.7641, Precision=0.9178\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.34150530211691593, K=26, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.42919042319339296, margin=0.4761943991240059, lpl_weight=0.763091696640072\n",
      " - ratio=0.182611623197284, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0777, LPL: 1.3863, Contrastive: 0.0837\n",
      "Epoch 50, Loss: 1.0744, LPL: 1.3863, Contrastive: 0.0698\n",
      "Epoch 100, Loss: 1.0745, LPL: 1.3863, Contrastive: 0.0701\n",
      " - Metrics: Accuracy=0.9147, F1=0.8463, Recall=0.7775, Precision=0.9285\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.34150530211691593, K=26, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.42919042319339296, margin=0.4761943991240059, lpl_weight=0.763091696640072\n",
      " - ratio=0.182611623197284, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0777, LPL: 1.3863, Contrastive: 0.0837\n",
      "Epoch 50, Loss: 1.0744, LPL: 1.3863, Contrastive: 0.0698\n",
      " - Metrics: Accuracy=0.9239, F1=0.8639, Recall=0.7995, Precision=0.9397\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.34150530211691593, K=26, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.42919042319339296, margin=0.4761943991240059, lpl_weight=0.763091696640072\n",
      " - ratio=0.182611623197284, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0777, LPL: 1.3863, Contrastive: 0.0837\n",
      "Epoch 50, Loss: 1.0744, LPL: 1.3863, Contrastive: 0.0698\n",
      "Epoch 100, Loss: 1.0745, LPL: 1.3863, Contrastive: 0.0701\n",
      " - Metrics: Accuracy=0.9154, F1=0.8484, Recall=0.7836, Precision=0.9250\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.34150530211691593, K=26, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.42919042319339296, margin=0.4761943991240059, lpl_weight=0.763091696640072\n",
      " - ratio=0.182611623197284, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0777, LPL: 1.3863, Contrastive: 0.0837\n",
      "Epoch 50, Loss: 1.0744, LPL: 1.3863, Contrastive: 0.0698\n",
      "Epoch 100, Loss: 1.0745, LPL: 1.3863, Contrastive: 0.0702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:01:04,893] Trial 36 finished with value: 0.8485818201914375 and parameters: {'alpha': 0.34150530211691593, 'K': 26, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.42919042319339296, 'margin': 0.4761943991240059, 'lpl_weight': 0.763091696640072, 'ratio': 0.182611623197284, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9165, F1=0.8503, Recall=0.7848, Precision=0.9277\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130001.csv.\n",
      "Average F1 over 5 seeds: 0.8486  0.0096\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2501225007936812, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.43984390355077396, margin=0.5868568622433831, lpl_weight=0.9297452754894184\n",
      " - ratio=0.2808353864275919, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3028, LPL: 1.3863, Contrastive: 0.1985\n",
      " - Metrics: Accuracy=0.8833, F1=0.8196, Recall=0.8778, Precision=0.7687\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2501225007936812, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.43984390355077396, margin=0.5868568622433831, lpl_weight=0.9297452754894184\n",
      " - ratio=0.2808353864275919, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3028, LPL: 1.3863, Contrastive: 0.1985\n",
      " - Metrics: Accuracy=0.8859, F1=0.8235, Recall=0.8814, Precision=0.7728\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2501225007936812, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.43984390355077396, margin=0.5868568622433831, lpl_weight=0.9297452754894184\n",
      " - ratio=0.2808353864275919, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3028, LPL: 1.3863, Contrastive: 0.1985\n",
      " - Metrics: Accuracy=0.8844, F1=0.8206, Recall=0.8753, Precision=0.7724\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2501225007936812, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.43984390355077396, margin=0.5868568622433831, lpl_weight=0.9297452754894184\n",
      " - ratio=0.2808353864275919, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3028, LPL: 1.3863, Contrastive: 0.1985\n",
      " - Metrics: Accuracy=0.8730, F1=0.8052, Recall=0.8692, Precision=0.7500\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2501225007936812, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.43984390355077396, margin=0.5868568622433831, lpl_weight=0.9297452754894184\n",
      " - ratio=0.2808353864275919, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3028, LPL: 1.3863, Contrastive: 0.1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:01:38,194] Trial 37 finished with value: 0.8179091522400039 and parameters: {'alpha': 0.2501225007936812, 'K': 27, 'layers': 1, 'hidden_channels': 64, 'out_channels': 256, 'norm': None, 'dropout': 0.43984390355077396, 'margin': 0.5868568622433831, 'lpl_weight': 0.9297452754894184, 'ratio': 0.2808353864275919, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8826, F1=0.8205, Recall=0.8888, Precision=0.7621\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130104.csv.\n",
      "Average F1 over 5 seeds: 0.8179  0.0065\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10587782986941449, K=28, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3990313560266213, margin=0.42422531239418176, lpl_weight=0.7992663997186009\n",
      " - ratio=0.2586721420321911, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1327, LPL: 1.3863, Contrastive: 0.1227\n",
      " - Metrics: Accuracy=0.8833, F1=0.8266, Recall=0.9205, Precision=0.7500\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10587782986941449, K=28, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3990313560266213, margin=0.42422531239418176, lpl_weight=0.7992663997186009\n",
      " - ratio=0.2586721420321911, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1327, LPL: 1.3863, Contrastive: 0.1227\n",
      " - Metrics: Accuracy=0.8840, F1=0.8277, Recall=0.9218, Precision=0.7510\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10587782986941449, K=28, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3990313560266213, margin=0.42422531239418176, lpl_weight=0.7992663997186009\n",
      " - ratio=0.2586721420321911, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1327, LPL: 1.3863, Contrastive: 0.1227\n",
      " - Metrics: Accuracy=0.8737, F1=0.8123, Recall=0.9046, Precision=0.7371\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10587782986941449, K=28, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3990313560266213, margin=0.42422531239418176, lpl_weight=0.7992663997186009\n",
      " - ratio=0.2586721420321911, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1327, LPL: 1.3863, Contrastive: 0.1227\n",
      " - Metrics: Accuracy=0.8700, F1=0.8068, Recall=0.8985, Precision=0.7321\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10587782986941449, K=28, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3990313560266213, margin=0.42422531239418176, lpl_weight=0.7992663997186009\n",
      " - ratio=0.2586721420321911, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1327, LPL: 1.3863, Contrastive: 0.1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:02:15,239] Trial 38 finished with value: 0.8199780461031831 and parameters: {'alpha': 0.10587782986941449, 'K': 28, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.3990313560266213, 'margin': 0.42422531239418176, 'lpl_weight': 0.7992663997186009, 'ratio': 0.2586721420321911, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8833, F1=0.8266, Recall=0.9205, Precision=0.7500\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130138.csv.\n",
      "Average F1 over 5 seeds: 0.8200  0.0087\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9070719778708671, K=29, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.45803932717159185, margin=0.3067631570945515, lpl_weight=0.872675116389929\n",
      " - ratio=0.22497306199256487, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2334, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 1.2258, LPL: 1.3863, Contrastive: 0.1255\n",
      "Epoch 100, Loss: 1.2255, LPL: 1.3863, Contrastive: 0.1236\n",
      " - Metrics: Accuracy=0.9361, F1=0.8942, Recall=0.8936, Precision=0.8947\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9070719778708671, K=29, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.45803932717159185, margin=0.3067631570945515, lpl_weight=0.872675116389929\n",
      " - ratio=0.22497306199256487, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2334, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 1.2258, LPL: 1.3863, Contrastive: 0.1255\n",
      "Epoch 100, Loss: 1.2255, LPL: 1.3863, Contrastive: 0.1236\n",
      " - Metrics: Accuracy=0.9324, F1=0.8882, Recall=0.8888, Precision=0.8877\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9070719778708671, K=29, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.45803932717159185, margin=0.3067631570945515, lpl_weight=0.872675116389929\n",
      " - ratio=0.22497306199256487, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2334, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 1.2258, LPL: 1.3863, Contrastive: 0.1255\n",
      "Epoch 100, Loss: 1.2255, LPL: 1.3863, Contrastive: 0.1236\n",
      " - Metrics: Accuracy=0.9369, F1=0.8964, Recall=0.9046, Precision=0.8884\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9070719778708671, K=29, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.45803932717159185, margin=0.3067631570945515, lpl_weight=0.872675116389929\n",
      " - ratio=0.22497306199256487, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2334, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 1.2258, LPL: 1.3863, Contrastive: 0.1255\n",
      "Epoch 100, Loss: 1.2255, LPL: 1.3863, Contrastive: 0.1236\n",
      " - Metrics: Accuracy=0.9332, F1=0.8890, Recall=0.8863, Precision=0.8918\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9070719778708671, K=29, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.45803932717159185, margin=0.3067631570945515, lpl_weight=0.872675116389929\n",
      " - ratio=0.22497306199256487, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2334, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 1.2258, LPL: 1.3863, Contrastive: 0.1255\n",
      "Epoch 100, Loss: 1.2255, LPL: 1.3863, Contrastive: 0.1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:03:26,319] Trial 39 finished with value: 0.8903712346283783 and parameters: {'alpha': 0.9070719778708671, 'K': 29, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.45803932717159185, 'margin': 0.3067631570945515, 'lpl_weight': 0.872675116389929, 'ratio': 0.22497306199256487, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9298, F1=0.8840, Recall=0.8851, Precision=0.8829\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130215.csv.\n",
      "Average F1 over 5 seeds: 0.8904  0.0044\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.18801375193474684, K=33, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40799894600349557, margin=0.5668723673535981, lpl_weight=0.8376606198246364\n",
      " - ratio=0.43637318816380954, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1804, LPL: 1.3863, Contrastive: 0.1177\n",
      " - Metrics: Accuracy=0.8711, F1=0.8125, Recall=0.9242, Precision=0.7248\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.18801375193474684, K=33, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40799894600349557, margin=0.5668723673535981, lpl_weight=0.8376606198246364\n",
      " - ratio=0.43637318816380954, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1804, LPL: 1.3863, Contrastive: 0.1177\n",
      " - Metrics: Accuracy=0.8678, F1=0.8106, Recall=0.9364, Precision=0.7146\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.18801375193474684, K=33, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40799894600349557, margin=0.5668723673535981, lpl_weight=0.8376606198246364\n",
      " - ratio=0.43637318816380954, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1804, LPL: 1.3863, Contrastive: 0.1177\n",
      " - Metrics: Accuracy=0.8674, F1=0.8061, Recall=0.9120, Precision=0.7222\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.18801375193474684, K=33, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40799894600349557, margin=0.5668723673535981, lpl_weight=0.8376606198246364\n",
      " - ratio=0.43637318816380954, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1804, LPL: 1.3863, Contrastive: 0.1177\n",
      " - Metrics: Accuracy=0.8682, F1=0.8080, Recall=0.9181, Precision=0.7214\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.18801375193474684, K=33, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40799894600349557, margin=0.5668723673535981, lpl_weight=0.8376606198246364\n",
      " - ratio=0.43637318816380954, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1804, LPL: 1.3863, Contrastive: 0.1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:04:02,332] Trial 40 finished with value: 0.8103592394893641 and parameters: {'alpha': 0.18801375193474684, 'K': 33, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.40799894600349557, 'margin': 0.5668723673535981, 'lpl_weight': 0.8376606198246364, 'ratio': 0.43637318816380954, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8719, F1=0.8147, Recall=0.9328, Precision=0.7232\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130326.csv.\n",
      "Average F1 over 5 seeds: 0.8104  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.50462741786112, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.49923307597797684, margin=0.49386231901315814, lpl_weight=0.9560666055670407\n",
      " - ratio=0.2432765788527112, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3333, LPL: 1.3863, Contrastive: 0.1811\n",
      "Epoch 50, Loss: 1.3284, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.0664\n",
      " - Metrics: Accuracy=0.9350, F1=0.8947, Recall=0.9144, Precision=0.8759\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.50462741786112, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.49923307597797684, margin=0.49386231901315814, lpl_weight=0.9560666055670407\n",
      " - ratio=0.2432765788527112, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3333, LPL: 1.3863, Contrastive: 0.1811\n",
      "Epoch 50, Loss: 1.3284, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.0664\n",
      " - Metrics: Accuracy=0.9321, F1=0.8905, Recall=0.9144, Precision=0.8677\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.50462741786112, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.49923307597797684, margin=0.49386231901315814, lpl_weight=0.9560666055670407\n",
      " - ratio=0.2432765788527112, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3333, LPL: 1.3863, Contrastive: 0.1811\n",
      "Epoch 50, Loss: 1.3284, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.0663\n",
      " - Metrics: Accuracy=0.9369, F1=0.8974, Recall=0.9144, Precision=0.8810\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.50462741786112, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.49923307597797684, margin=0.49386231901315814, lpl_weight=0.9560666055670407\n",
      " - ratio=0.2432765788527112, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3333, LPL: 1.3863, Contrastive: 0.1811\n",
      "Epoch 50, Loss: 1.3284, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.0664\n",
      " - Metrics: Accuracy=0.9380, F1=0.8992, Recall=0.9156, Precision=0.8833\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.50462741786112, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.49923307597797684, margin=0.49386231901315814, lpl_weight=0.9560666055670407\n",
      " - ratio=0.2432765788527112, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3333, LPL: 1.3863, Contrastive: 0.1811\n",
      "Epoch 50, Loss: 1.3284, LPL: 1.3863, Contrastive: 0.0678\n",
      "Epoch 100, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:05:20,031] Trial 41 finished with value: 0.8953497403916127 and parameters: {'alpha': 0.50462741786112, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.49923307597797684, 'margin': 0.49386231901315814, 'lpl_weight': 0.9560666055670407, 'ratio': 0.2432765788527112, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9346, F1=0.8950, Recall=0.9218, Precision=0.8697\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130402.csv.\n",
      "Average F1 over 5 seeds: 0.8953  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7680936227333292, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4958929535051545, margin=0.48540601847611264, lpl_weight=0.9455304164114224\n",
      " - ratio=0.24624220327993254, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3211, LPL: 1.3863, Contrastive: 0.1895\n",
      " - Metrics: Accuracy=0.9276, F1=0.8833, Recall=0.9071, Precision=0.8608\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7680936227333292, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4958929535051545, margin=0.48540601847611264, lpl_weight=0.9455304164114224\n",
      " - ratio=0.24624220327993254, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3211, LPL: 1.3863, Contrastive: 0.1895\n",
      " - Metrics: Accuracy=0.9236, F1=0.8792, Recall=0.9205, Precision=0.8413\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7680936227333292, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4958929535051545, margin=0.48540601847611264, lpl_weight=0.9455304164114224\n",
      " - ratio=0.24624220327993254, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3211, LPL: 1.3863, Contrastive: 0.1895\n",
      " - Metrics: Accuracy=0.9309, F1=0.8895, Recall=0.9205, Precision=0.8606\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7680936227333292, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4958929535051545, margin=0.48540601847611264, lpl_weight=0.9455304164114224\n",
      " - ratio=0.24624220327993254, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3211, LPL: 1.3863, Contrastive: 0.1895\n",
      " - Metrics: Accuracy=0.9269, F1=0.8830, Recall=0.9132, Precision=0.8547\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7680936227333292, K=31, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4958929535051545, margin=0.48540601847611264, lpl_weight=0.9455304164114224\n",
      " - ratio=0.24624220327993254, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3211, LPL: 1.3863, Contrastive: 0.1895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:05:58,858] Trial 42 finished with value: 0.8834256098550257 and parameters: {'alpha': 0.7680936227333292, 'K': 31, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4958929535051545, 'margin': 0.48540601847611264, 'lpl_weight': 0.9455304164114224, 'ratio': 0.24624220327993254, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9258, F1=0.8821, Recall=0.9193, Precision=0.8478\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130520.csv.\n",
      "Average F1 over 5 seeds: 0.8834  0.0034\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5327197800334438, K=28, layers=3, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.453970127965044, margin=0.616896081724735, lpl_weight=0.893967634718239\n",
      " - ratio=0.27294006629825185, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2523, LPL: 1.3863, Contrastive: 0.1228\n",
      " - Metrics: Accuracy=0.8970, F1=0.8426, Recall=0.9132, Precision=0.7822\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5327197800334438, K=28, layers=3, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.453970127965044, margin=0.616896081724735, lpl_weight=0.893967634718239\n",
      " - ratio=0.27294006629825185, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2523, LPL: 1.3863, Contrastive: 0.1228\n",
      " - Metrics: Accuracy=0.9007, F1=0.8483, Recall=0.9193, Precision=0.7874\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5327197800334438, K=28, layers=3, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.453970127965044, margin=0.616896081724735, lpl_weight=0.893967634718239\n",
      " - ratio=0.27294006629825185, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2523, LPL: 1.3863, Contrastive: 0.1228\n",
      " - Metrics: Accuracy=0.9088, F1=0.8576, Recall=0.9095, Precision=0.8113\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5327197800334438, K=28, layers=3, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.453970127965044, margin=0.616896081724735, lpl_weight=0.893967634718239\n",
      " - ratio=0.27294006629825185, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2523, LPL: 1.3863, Contrastive: 0.1228\n",
      " - Metrics: Accuracy=0.8966, F1=0.8400, Recall=0.8985, Precision=0.7886\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5327197800334438, K=28, layers=3, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.453970127965044, margin=0.616896081724735, lpl_weight=0.893967634718239\n",
      " - ratio=0.27294006629825185, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2523, LPL: 1.3863, Contrastive: 0.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:06:27,027] Trial 43 finished with value: 0.847972313639303 and parameters: {'alpha': 0.5327197800334438, 'K': 28, 'layers': 3, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.453970127965044, 'margin': 0.616896081724735, 'lpl_weight': 0.893967634718239, 'ratio': 0.27294006629825185, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9032, F1=0.8513, Recall=0.9169, Precision=0.7945\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130558.csv.\n",
      "Average F1 over 5 seeds: 0.8480  0.0063\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1561446544876336, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47546229169818655, margin=0.4009009842442765, lpl_weight=0.9678714844901344\n",
      " - ratio=0.16410718956729367, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3477, LPL: 1.3863, Contrastive: 0.1866\n",
      "Epoch 50, Loss: 1.3448, LPL: 1.3863, Contrastive: 0.0935\n",
      "Epoch 100, Loss: 1.3447, LPL: 1.3863, Contrastive: 0.0924\n",
      " - Metrics: Accuracy=0.9335, F1=0.8840, Recall=0.8386, Precision=0.9346\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1561446544876336, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47546229169818655, margin=0.4009009842442765, lpl_weight=0.9678714844901344\n",
      " - ratio=0.16410718956729367, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3477, LPL: 1.3863, Contrastive: 0.1866\n",
      "Epoch 50, Loss: 1.3448, LPL: 1.3863, Contrastive: 0.0935\n",
      "Epoch 100, Loss: 1.3447, LPL: 1.3863, Contrastive: 0.0924\n",
      " - Metrics: Accuracy=0.9313, F1=0.8809, Recall=0.8411, Precision=0.9247\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1561446544876336, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47546229169818655, margin=0.4009009842442765, lpl_weight=0.9678714844901344\n",
      " - ratio=0.16410718956729367, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3477, LPL: 1.3863, Contrastive: 0.1866\n",
      "Epoch 50, Loss: 1.3448, LPL: 1.3863, Contrastive: 0.0935\n",
      "Epoch 100, Loss: 1.3447, LPL: 1.3863, Contrastive: 0.0925\n",
      " - Metrics: Accuracy=0.9369, F1=0.8907, Recall=0.8521, Precision=0.9331\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1561446544876336, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47546229169818655, margin=0.4009009842442765, lpl_weight=0.9678714844901344\n",
      " - ratio=0.16410718956729367, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3477, LPL: 1.3863, Contrastive: 0.1866\n",
      "Epoch 50, Loss: 1.3448, LPL: 1.3863, Contrastive: 0.0935\n",
      "Epoch 100, Loss: 1.3447, LPL: 1.3863, Contrastive: 0.0925\n",
      " - Metrics: Accuracy=0.9339, F1=0.8853, Recall=0.8447, Precision=0.9300\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1561446544876336, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47546229169818655, margin=0.4009009842442765, lpl_weight=0.9678714844901344\n",
      " - ratio=0.16410718956729367, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3477, LPL: 1.3863, Contrastive: 0.1866\n",
      "Epoch 50, Loss: 1.3448, LPL: 1.3863, Contrastive: 0.0935\n",
      "Epoch 100, Loss: 1.3447, LPL: 1.3863, Contrastive: 0.0924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:07:51,570] Trial 44 finished with value: 0.8857252604366703 and parameters: {'alpha': 0.1561446544876336, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.47546229169818655, 'margin': 0.4009009842442765, 'lpl_weight': 0.9678714844901344, 'ratio': 0.16410718956729367, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9346, F1=0.8876, Recall=0.8545, Precision=0.9234\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130627.csv.\n",
      "Average F1 over 5 seeds: 0.8857  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.21433112149398736, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.43238689885306847, margin=0.500733348521737, lpl_weight=0.998597400376319\n",
      " - ratio=0.2011377318693052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3846, LPL: 1.3863, Contrastive: 0.1552\n",
      "Epoch 50, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0667\n",
      "Epoch 100, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0650\n",
      " - Metrics: Accuracy=0.9328, F1=0.8870, Recall=0.8729, Precision=0.9015\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.21433112149398736, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.43238689885306847, margin=0.500733348521737, lpl_weight=0.998597400376319\n",
      " - ratio=0.2011377318693052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3846, LPL: 1.3863, Contrastive: 0.1552\n",
      "Epoch 50, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0667\n",
      "Epoch 100, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0650\n",
      " - Metrics: Accuracy=0.9254, F1=0.8764, Recall=0.8753, Precision=0.8775\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.21433112149398736, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.43238689885306847, margin=0.500733348521737, lpl_weight=0.998597400376319\n",
      " - ratio=0.2011377318693052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3846, LPL: 1.3863, Contrastive: 0.1552\n",
      "Epoch 50, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0667\n",
      "Epoch 100, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0650\n",
      " - Metrics: Accuracy=0.9346, F1=0.8908, Recall=0.8826, Precision=0.8991\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.21433112149398736, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.43238689885306847, margin=0.500733348521737, lpl_weight=0.998597400376319\n",
      " - ratio=0.2011377318693052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3846, LPL: 1.3863, Contrastive: 0.1552\n",
      "Epoch 50, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0667\n",
      "Epoch 100, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0650\n",
      " - Metrics: Accuracy=0.9280, F1=0.8804, Recall=0.8778, Precision=0.8831\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.21433112149398736, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.43238689885306847, margin=0.500733348521737, lpl_weight=0.998597400376319\n",
      " - ratio=0.2011377318693052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3846, LPL: 1.3863, Contrastive: 0.1552\n",
      "Epoch 50, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0667\n",
      "Epoch 100, Loss: 1.3844, LPL: 1.3863, Contrastive: 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:08:51,887] Trial 45 finished with value: 0.8839056042500875 and parameters: {'alpha': 0.21433112149398736, 'K': 29, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.43238689885306847, 'margin': 0.500733348521737, 'lpl_weight': 0.998597400376319, 'ratio': 0.2011377318693052, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9306, F1=0.8849, Recall=0.8839, Precision=0.8860\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130751.csv.\n",
      "Average F1 over 5 seeds: 0.8839  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8391555180465669, K=32, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.4798246138477228, margin=0.34252100894493975, lpl_weight=0.7194390978415378\n",
      " - ratio=0.1294486941593327, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0577, LPL: 1.3863, Contrastive: 0.2152\n",
      "Epoch 50, Loss: 1.0297, LPL: 1.3863, Contrastive: 0.1153\n",
      "Epoch 100, Loss: 1.0290, LPL: 1.3863, Contrastive: 0.1127\n",
      "Epoch 150, Loss: 1.0288, LPL: 1.3863, Contrastive: 0.1121\n",
      " - Metrics: Accuracy=0.9162, F1=0.8467, Recall=0.7665, Precision=0.9457\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8391555180465669, K=32, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.4798246138477228, margin=0.34252100894493975, lpl_weight=0.7194390978415378\n",
      " - ratio=0.1294486941593327, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0577, LPL: 1.3863, Contrastive: 0.2152\n",
      "Epoch 50, Loss: 1.0297, LPL: 1.3863, Contrastive: 0.1153\n",
      "Epoch 100, Loss: 1.0290, LPL: 1.3863, Contrastive: 0.1127\n",
      "Epoch 150, Loss: 1.0289, LPL: 1.3863, Contrastive: 0.1124\n",
      "Epoch 200, Loss: 1.0285, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 250, Loss: 1.0283, LPL: 1.3863, Contrastive: 0.1104\n",
      " - Metrics: Accuracy=0.9140, F1=0.8427, Recall=0.7628, Precision=0.9412\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8391555180465669, K=32, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.4798246138477228, margin=0.34252100894493975, lpl_weight=0.7194390978415378\n",
      " - ratio=0.1294486941593327, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0577, LPL: 1.3863, Contrastive: 0.2152\n",
      "Epoch 50, Loss: 1.0297, LPL: 1.3863, Contrastive: 0.1153\n",
      "Epoch 100, Loss: 1.0290, LPL: 1.3863, Contrastive: 0.1127\n",
      "Epoch 150, Loss: 1.0289, LPL: 1.3863, Contrastive: 0.1125\n",
      "Epoch 200, Loss: 1.0286, LPL: 1.3863, Contrastive: 0.1112\n",
      "Epoch 250, Loss: 1.0283, LPL: 1.3863, Contrastive: 0.1104\n",
      "Epoch 300, Loss: 1.0283, LPL: 1.3863, Contrastive: 0.1103\n",
      "Epoch 350, Loss: 1.0283, LPL: 1.3863, Contrastive: 0.1101\n",
      " - Metrics: Accuracy=0.9165, F1=0.8475, Recall=0.7677, Precision=0.9458\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8391555180465669, K=32, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.4798246138477228, margin=0.34252100894493975, lpl_weight=0.7194390978415378\n",
      " - ratio=0.1294486941593327, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0577, LPL: 1.3863, Contrastive: 0.2152\n",
      "Epoch 50, Loss: 1.0297, LPL: 1.3863, Contrastive: 0.1153\n",
      "Epoch 100, Loss: 1.0290, LPL: 1.3863, Contrastive: 0.1127\n",
      " - Metrics: Accuracy=0.9236, F1=0.8621, Recall=0.7910, Precision=0.9473\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8391555180465669, K=32, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.4798246138477228, margin=0.34252100894493975, lpl_weight=0.7194390978415378\n",
      " - ratio=0.1294486941593327, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0577, LPL: 1.3863, Contrastive: 0.2152\n",
      "Epoch 50, Loss: 1.0297, LPL: 1.3863, Contrastive: 0.1153\n",
      "Epoch 100, Loss: 1.0290, LPL: 1.3863, Contrastive: 0.1127\n",
      "Epoch 150, Loss: 1.0289, LPL: 1.3863, Contrastive: 0.1124\n",
      "Epoch 200, Loss: 1.0286, LPL: 1.3863, Contrastive: 0.1113\n",
      "Epoch 250, Loss: 1.0283, LPL: 1.3863, Contrastive: 0.1104\n",
      "Epoch 300, Loss: 1.0283, LPL: 1.3863, Contrastive: 0.1103\n",
      "Epoch 350, Loss: 1.0282, LPL: 1.3863, Contrastive: 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:10:35,168] Trial 46 finished with value: 0.8485615509286802 and parameters: {'alpha': 0.8391555180465669, 'K': 32, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': None, 'dropout': 0.4798246138477228, 'margin': 0.34252100894493975, 'lpl_weight': 0.7194390978415378, 'ratio': 0.1294486941593327, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9147, F1=0.8438, Recall=0.7628, Precision=0.9440\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102130851.csv.\n",
      "Average F1 over 5 seeds: 0.8486  0.0070\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6240382296219666, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3791503081870354, margin=0.5573091017530903, lpl_weight=0.7998651742889239\n",
      " - ratio=0.22457757947078277, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1311, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 50, Loss: 1.1189, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 100, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0496\n",
      "Epoch 150, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0495\n",
      "Epoch 200, Loss: 1.1187, LPL: 1.3863, Contrastive: 0.0495\n",
      " - Metrics: Accuracy=0.8962, F1=0.8390, Recall=0.8949, Precision=0.7896\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6240382296219666, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3791503081870354, margin=0.5573091017530903, lpl_weight=0.7998651742889239\n",
      " - ratio=0.22457757947078277, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1311, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 50, Loss: 1.1189, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 100, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0496\n",
      "Epoch 150, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0496\n",
      "Epoch 200, Loss: 1.1187, LPL: 1.3863, Contrastive: 0.0495\n",
      " - Metrics: Accuracy=0.8981, F1=0.8417, Recall=0.8973, Precision=0.7927\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6240382296219666, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3791503081870354, margin=0.5573091017530903, lpl_weight=0.7998651742889239\n",
      " - ratio=0.22457757947078277, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1311, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 50, Loss: 1.1189, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 100, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0496\n",
      "Epoch 150, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0495\n",
      "Epoch 200, Loss: 1.1187, LPL: 1.3863, Contrastive: 0.0495\n",
      " - Metrics: Accuracy=0.9062, F1=0.8544, Recall=0.9108, Precision=0.8045\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6240382296219666, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3791503081870354, margin=0.5573091017530903, lpl_weight=0.7998651742889239\n",
      " - ratio=0.22457757947078277, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1311, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 50, Loss: 1.1189, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 100, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0496\n",
      "Epoch 150, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0495\n",
      "Epoch 200, Loss: 1.1187, LPL: 1.3863, Contrastive: 0.0495\n",
      "Epoch 250, Loss: 1.1187, LPL: 1.3863, Contrastive: 0.0494\n",
      " - Metrics: Accuracy=0.8988, F1=0.8429, Recall=0.8985, Precision=0.7937\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6240382296219666, K=27, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3791503081870354, margin=0.5573091017530903, lpl_weight=0.7998651742889239\n",
      " - ratio=0.22457757947078277, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1311, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 50, Loss: 1.1189, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 100, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0496\n",
      "Epoch 150, Loss: 1.1188, LPL: 1.3863, Contrastive: 0.0495\n",
      "Epoch 200, Loss: 1.1187, LPL: 1.3863, Contrastive: 0.0495\n",
      "Epoch 250, Loss: 1.1187, LPL: 1.3863, Contrastive: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:12:28,399] Trial 47 finished with value: 0.8421056228805762 and parameters: {'alpha': 0.6240382296219666, 'K': 27, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3791503081870354, 'margin': 0.5573091017530903, 'lpl_weight': 0.7998651742889239, 'ratio': 0.22457757947078277, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8922, F1=0.8326, Recall=0.8875, Precision=0.7840\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131035.csv.\n",
      "Average F1 over 5 seeds: 0.8421  0.0071\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.47641314349920794, K=25, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.46197734847239347, margin=0.6503495325307982, lpl_weight=0.6656650804590964\n",
      " - ratio=0.32057911147210116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9926, LPL: 1.3863, Contrastive: 0.2088\n",
      " - Metrics: Accuracy=0.8962, F1=0.8426, Recall=0.9193, Precision=0.7777\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.47641314349920794, K=25, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.46197734847239347, margin=0.6503495325307982, lpl_weight=0.6656650804590964\n",
      " - ratio=0.32057911147210116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9926, LPL: 1.3863, Contrastive: 0.2088\n",
      " - Metrics: Accuracy=0.8892, F1=0.8331, Recall=0.9156, Precision=0.7643\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.47641314349920794, K=25, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.46197734847239347, margin=0.6503495325307982, lpl_weight=0.6656650804590964\n",
      " - ratio=0.32057911147210116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9926, LPL: 1.3863, Contrastive: 0.2088\n",
      " - Metrics: Accuracy=0.9007, F1=0.8485, Recall=0.9205, Precision=0.7868\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.47641314349920794, K=25, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.46197734847239347, margin=0.6503495325307982, lpl_weight=0.6656650804590964\n",
      " - ratio=0.32057911147210116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9926, LPL: 1.3863, Contrastive: 0.2088\n",
      " - Metrics: Accuracy=0.8900, F1=0.8350, Recall=0.9218, Precision=0.7632\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.47641314349920794, K=25, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.46197734847239347, margin=0.6503495325307982, lpl_weight=0.6656650804590964\n",
      " - ratio=0.32057911147210116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9926, LPL: 1.3863, Contrastive: 0.2088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:12:55,729] Trial 48 finished with value: 0.8379542465986489 and parameters: {'alpha': 0.47641314349920794, 'K': 25, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.46197734847239347, 'margin': 0.6503495325307982, 'lpl_weight': 0.6656650804590964, 'ratio': 0.32057911147210116, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8855, F1=0.8306, Recall=0.9291, Precision=0.7510\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131228.csv.\n",
      "Average F1 over 5 seeds: 0.8380  0.0066\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.14890286443998263, K=29, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40449924384359237, margin=0.4034562504800919, lpl_weight=0.8444131029174945\n",
      " - ratio=0.2844936406516838, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1973, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.1851, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.1849, LPL: 1.3863, Contrastive: 0.0916\n",
      " - Metrics: Accuracy=0.9295, F1=0.8880, Recall=0.9254, Precision=0.8534\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.14890286443998263, K=29, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40449924384359237, margin=0.4034562504800919, lpl_weight=0.8444131029174945\n",
      " - ratio=0.2844936406516838, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1973, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.1851, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.1849, LPL: 1.3863, Contrastive: 0.0916\n",
      " - Metrics: Accuracy=0.9210, F1=0.8747, Recall=0.9132, Precision=0.8393\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.14890286443998263, K=29, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40449924384359237, margin=0.4034562504800919, lpl_weight=0.8444131029174945\n",
      " - ratio=0.2844936406516838, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1973, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.1851, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.1849, LPL: 1.3863, Contrastive: 0.0916\n",
      " - Metrics: Accuracy=0.9343, F1=0.8952, Recall=0.9291, Precision=0.8636\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.14890286443998263, K=29, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40449924384359237, margin=0.4034562504800919, lpl_weight=0.8444131029174945\n",
      " - ratio=0.2844936406516838, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1973, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.1851, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.1849, LPL: 1.3863, Contrastive: 0.0916\n",
      " - Metrics: Accuracy=0.9346, F1=0.8953, Recall=0.9254, Precision=0.8671\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.14890286443998263, K=29, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40449924384359237, margin=0.4034562504800919, lpl_weight=0.8444131029174945\n",
      " - ratio=0.2844936406516838, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1973, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.1851, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.1849, LPL: 1.3863, Contrastive: 0.0916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:14:03,595] Trial 49 finished with value: 0.8881541237762459 and parameters: {'alpha': 0.14890286443998263, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.40449924384359237, 'margin': 0.4034562504800919, 'lpl_weight': 0.8444131029174945, 'ratio': 0.2844936406516838, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9291, F1=0.8876, Recall=0.9267, Precision=0.8517\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131255.csv.\n",
      "Average F1 over 5 seeds: 0.8882  0.0075\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2856994509907807, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3406257760327347, margin=0.3274749384434942, lpl_weight=0.9106180140019774\n",
      " - ratio=0.48444391027196365, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2774, LPL: 1.3863, Contrastive: 0.1674\n",
      "Epoch 50, Loss: 1.2728, LPL: 1.3863, Contrastive: 0.1166\n",
      "Epoch 100, Loss: 1.2727, LPL: 1.3863, Contrastive: 0.1155\n",
      " - Metrics: Accuracy=0.8715, F1=0.8157, Recall=0.9413, Precision=0.7196\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2856994509907807, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3406257760327347, margin=0.3274749384434942, lpl_weight=0.9106180140019774\n",
      " - ratio=0.48444391027196365, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2774, LPL: 1.3863, Contrastive: 0.1674\n",
      "Epoch 50, Loss: 1.2728, LPL: 1.3863, Contrastive: 0.1166\n",
      "Epoch 100, Loss: 1.2727, LPL: 1.3863, Contrastive: 0.1155\n",
      " - Metrics: Accuracy=0.8682, F1=0.8130, Recall=0.9487, Precision=0.7113\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2856994509907807, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3406257760327347, margin=0.3274749384434942, lpl_weight=0.9106180140019774\n",
      " - ratio=0.48444391027196365, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2774, LPL: 1.3863, Contrastive: 0.1674\n",
      "Epoch 50, Loss: 1.2728, LPL: 1.3863, Contrastive: 0.1166\n",
      "Epoch 100, Loss: 1.2727, LPL: 1.3863, Contrastive: 0.1155\n",
      " - Metrics: Accuracy=0.8674, F1=0.8125, Recall=0.9511, Precision=0.7092\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2856994509907807, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3406257760327347, margin=0.3274749384434942, lpl_weight=0.9106180140019774\n",
      " - ratio=0.48444391027196365, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2774, LPL: 1.3863, Contrastive: 0.1674\n",
      "Epoch 50, Loss: 1.2728, LPL: 1.3863, Contrastive: 0.1166\n",
      "Epoch 100, Loss: 1.2727, LPL: 1.3863, Contrastive: 0.1158\n",
      " - Metrics: Accuracy=0.8730, F1=0.8178, Recall=0.9438, Precision=0.7215\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2856994509907807, K=26, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3406257760327347, margin=0.3274749384434942, lpl_weight=0.9106180140019774\n",
      " - ratio=0.48444391027196365, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2774, LPL: 1.3863, Contrastive: 0.1674\n",
      "Epoch 50, Loss: 1.2728, LPL: 1.3863, Contrastive: 0.1166\n",
      "Epoch 100, Loss: 1.2727, LPL: 1.3863, Contrastive: 0.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:15:12,795] Trial 50 finished with value: 0.8215901798240299 and parameters: {'alpha': 0.2856994509907807, 'K': 26, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3406257760327347, 'margin': 0.3274749384434942, 'lpl_weight': 0.9106180140019774, 'ratio': 0.48444391027196365, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8988, F1=0.8490, Recall=0.9413, Precision=0.7731\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131403.csv.\n",
      "Average F1 over 5 seeds: 0.8216  0.0138\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.43204675490253264, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22867390062450058, margin=0.5168786653554458, lpl_weight=0.5319031051266927\n",
      " - ratio=0.23800773669920117, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7965, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 0.7659, LPL: 1.3863, Contrastive: 0.0609\n",
      "Epoch 100, Loss: 0.7655, LPL: 1.3863, Contrastive: 0.0600\n",
      " - Metrics: Accuracy=0.9357, F1=0.8948, Recall=0.9046, Precision=0.8852\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.43204675490253264, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22867390062450058, margin=0.5168786653554458, lpl_weight=0.5319031051266927\n",
      " - ratio=0.23800773669920117, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7965, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 0.7659, LPL: 1.3863, Contrastive: 0.0609\n",
      "Epoch 100, Loss: 0.7655, LPL: 1.3863, Contrastive: 0.0600\n",
      " - Metrics: Accuracy=0.9309, F1=0.8877, Recall=0.9034, Precision=0.8725\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.43204675490253264, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22867390062450058, margin=0.5168786653554458, lpl_weight=0.5319031051266927\n",
      " - ratio=0.23800773669920117, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7965, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 0.7659, LPL: 1.3863, Contrastive: 0.0609\n",
      "Epoch 100, Loss: 0.7654, LPL: 1.3863, Contrastive: 0.0600\n",
      " - Metrics: Accuracy=0.9380, F1=0.8995, Recall=0.9193, Precision=0.8806\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.43204675490253264, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22867390062450058, margin=0.5168786653554458, lpl_weight=0.5319031051266927\n",
      " - ratio=0.23800773669920117, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7965, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 0.7659, LPL: 1.3863, Contrastive: 0.0609\n",
      "Epoch 100, Loss: 0.7655, LPL: 1.3863, Contrastive: 0.0600\n",
      " - Metrics: Accuracy=0.9295, F1=0.8839, Recall=0.8888, Precision=0.8791\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.43204675490253264, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.22867390062450058, margin=0.5168786653554458, lpl_weight=0.5319031051266927\n",
      " - ratio=0.23800773669920117, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7965, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 0.7659, LPL: 1.3863, Contrastive: 0.0609\n",
      "Epoch 100, Loss: 0.7654, LPL: 1.3863, Contrastive: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:16:18,375] Trial 51 finished with value: 0.8909578337721182 and parameters: {'alpha': 0.43204675490253264, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.22867390062450058, 'margin': 0.5168786653554458, 'lpl_weight': 0.5319031051266927, 'ratio': 0.23800773669920117, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9317, F1=0.8889, Recall=0.9046, Precision=0.8737\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131512.csv.\n",
      "Average F1 over 5 seeds: 0.8910  0.0055\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5574138864442695, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3171141303257784, margin=0.545627754965984, lpl_weight=0.8585010484677112\n",
      " - ratio=0.21923794453165416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2098, LPL: 1.3863, Contrastive: 0.1392\n",
      " - Metrics: Accuracy=0.9350, F1=0.8931, Recall=0.8985, Precision=0.8877\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5574138864442695, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3171141303257784, margin=0.545627754965984, lpl_weight=0.8585010484677112\n",
      " - ratio=0.21923794453165416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2098, LPL: 1.3863, Contrastive: 0.1392\n",
      " - Metrics: Accuracy=0.9357, F1=0.8943, Recall=0.8998, Precision=0.8889\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5574138864442695, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3171141303257784, margin=0.545627754965984, lpl_weight=0.8585010484677112\n",
      " - ratio=0.21923794453165416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2098, LPL: 1.3863, Contrastive: 0.1392\n",
      " - Metrics: Accuracy=0.9372, F1=0.8972, Recall=0.9071, Precision=0.8876\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5574138864442695, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3171141303257784, margin=0.545627754965984, lpl_weight=0.8585010484677112\n",
      " - ratio=0.21923794453165416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2098, LPL: 1.3863, Contrastive: 0.1392\n",
      " - Metrics: Accuracy=0.9306, F1=0.8855, Recall=0.8888, Precision=0.8823\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5574138864442695, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3171141303257784, margin=0.545627754965984, lpl_weight=0.8585010484677112\n",
      " - ratio=0.21923794453165416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2098, LPL: 1.3863, Contrastive: 0.1392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:16:48,648] Trial 52 finished with value: 0.8930970278007312 and parameters: {'alpha': 0.5574138864442695, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3171141303257784, 'margin': 0.545627754965984, 'lpl_weight': 0.8585010484677112, 'ratio': 0.21923794453165416, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9354, F1=0.8954, Recall=0.9156, Precision=0.8760\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131618.csv.\n",
      "Average F1 over 5 seeds: 0.8931  0.0040\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7209421254283943, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32860592186056087, margin=0.46319348446439795, lpl_weight=0.858558746515675\n",
      " - ratio=0.17851127697186214, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2106, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 1.2009, LPL: 1.3863, Contrastive: 0.0759\n",
      "Epoch 100, Loss: 1.2007, LPL: 1.3863, Contrastive: 0.0741\n",
      " - Metrics: Accuracy=0.9365, F1=0.8921, Recall=0.8692, Precision=0.9162\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7209421254283943, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32860592186056087, margin=0.46319348446439795, lpl_weight=0.858558746515675\n",
      " - ratio=0.17851127697186214, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2106, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 1.2009, LPL: 1.3863, Contrastive: 0.0759\n",
      "Epoch 100, Loss: 1.2007, LPL: 1.3863, Contrastive: 0.0741\n",
      " - Metrics: Accuracy=0.9284, F1=0.8777, Recall=0.8509, Precision=0.9062\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7209421254283943, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32860592186056087, margin=0.46319348446439795, lpl_weight=0.858558746515675\n",
      " - ratio=0.17851127697186214, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2106, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 1.2009, LPL: 1.3863, Contrastive: 0.0759\n",
      "Epoch 100, Loss: 1.2007, LPL: 1.3863, Contrastive: 0.0741\n",
      " - Metrics: Accuracy=0.9339, F1=0.8878, Recall=0.8655, Precision=0.9112\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7209421254283943, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32860592186056087, margin=0.46319348446439795, lpl_weight=0.858558746515675\n",
      " - ratio=0.17851127697186214, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2106, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 1.2009, LPL: 1.3863, Contrastive: 0.0759\n",
      "Epoch 100, Loss: 1.2007, LPL: 1.3863, Contrastive: 0.0741\n",
      " - Metrics: Accuracy=0.9280, F1=0.8782, Recall=0.8594, Precision=0.8978\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7209421254283943, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32860592186056087, margin=0.46319348446439795, lpl_weight=0.858558746515675\n",
      " - ratio=0.17851127697186214, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2106, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 1.2009, LPL: 1.3863, Contrastive: 0.0759\n",
      "Epoch 100, Loss: 1.2007, LPL: 1.3863, Contrastive: 0.0741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:17:50,288] Trial 53 finished with value: 0.8825269792043017 and parameters: {'alpha': 0.7209421254283943, 'K': 31, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.32860592186056087, 'margin': 0.46319348446439795, 'lpl_weight': 0.858558746515675, 'ratio': 0.17851127697186214, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9276, F1=0.8769, Recall=0.8533, Precision=0.9018\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131648.csv.\n",
      "Average F1 over 5 seeds: 0.8825  0.0062\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6335694998617818, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3660328211149583, margin=0.5701236958538184, lpl_weight=0.9636176040177731\n",
      " - ratio=0.20320280152509818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3412, LPL: 1.3863, Contrastive: 0.1481\n",
      "Epoch 50, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0492\n",
      "Epoch 100, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0479\n",
      " - Metrics: Accuracy=0.9361, F1=0.8939, Recall=0.8912, Precision=0.8967\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6335694998617818, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3660328211149583, margin=0.5701236958538184, lpl_weight=0.9636176040177731\n",
      " - ratio=0.20320280152509818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3412, LPL: 1.3863, Contrastive: 0.1481\n",
      "Epoch 50, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0492\n",
      "Epoch 100, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0479\n",
      " - Metrics: Accuracy=0.9339, F1=0.8913, Recall=0.8973, Precision=0.8854\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6335694998617818, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3660328211149583, margin=0.5701236958538184, lpl_weight=0.9636176040177731\n",
      " - ratio=0.20320280152509818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3412, LPL: 1.3863, Contrastive: 0.1481\n",
      "Epoch 50, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0492\n",
      "Epoch 100, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0479\n",
      " - Metrics: Accuracy=0.9398, F1=0.9001, Recall=0.8973, Precision=0.9028\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6335694998617818, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3660328211149583, margin=0.5701236958538184, lpl_weight=0.9636176040177731\n",
      " - ratio=0.20320280152509818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3412, LPL: 1.3863, Contrastive: 0.1481\n",
      "Epoch 50, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0492\n",
      "Epoch 100, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0479\n",
      " - Metrics: Accuracy=0.9309, F1=0.8846, Recall=0.8765, Precision=0.8929\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6335694998617818, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3660328211149583, margin=0.5701236958538184, lpl_weight=0.9636176040177731\n",
      " - ratio=0.20320280152509818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3412, LPL: 1.3863, Contrastive: 0.1481\n",
      "Epoch 50, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0492\n",
      "Epoch 100, Loss: 1.3376, LPL: 1.3863, Contrastive: 0.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:18:55,393] Trial 54 finished with value: 0.8931158285969799 and parameters: {'alpha': 0.6335694998617818, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3660328211149583, 'margin': 0.5701236958538184, 'lpl_weight': 0.9636176040177731, 'ratio': 0.20320280152509818, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9365, F1=0.8956, Recall=0.9022, Precision=0.8892\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131750.csv.\n",
      "Average F1 over 5 seeds: 0.8931  0.0051\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6299485950023005, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3664910708210881, margin=0.4279717193158981, lpl_weight=0.9549256355155208\n",
      " - ratio=0.20692804982830132, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3307, LPL: 1.3863, Contrastive: 0.1532\n",
      "Epoch 50, Loss: 1.3277, LPL: 1.3863, Contrastive: 0.0861\n",
      "Epoch 100, Loss: 1.3276, LPL: 1.3863, Contrastive: 0.0844\n",
      " - Metrics: Accuracy=0.9376, F1=0.8968, Recall=0.8973, Precision=0.8962\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6299485950023005, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3664910708210881, margin=0.4279717193158981, lpl_weight=0.9549256355155208\n",
      " - ratio=0.20692804982830132, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3307, LPL: 1.3863, Contrastive: 0.1532\n",
      "Epoch 50, Loss: 1.3277, LPL: 1.3863, Contrastive: 0.0861\n",
      "Epoch 100, Loss: 1.3276, LPL: 1.3863, Contrastive: 0.0844\n",
      " - Metrics: Accuracy=0.9339, F1=0.8903, Recall=0.8875, Precision=0.8930\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6299485950023005, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3664910708210881, margin=0.4279717193158981, lpl_weight=0.9549256355155208\n",
      " - ratio=0.20692804982830132, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3307, LPL: 1.3863, Contrastive: 0.1532\n",
      "Epoch 50, Loss: 1.3277, LPL: 1.3863, Contrastive: 0.0861\n",
      "Epoch 100, Loss: 1.3276, LPL: 1.3863, Contrastive: 0.0844\n",
      " - Metrics: Accuracy=0.9361, F1=0.8941, Recall=0.8924, Precision=0.8957\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6299485950023005, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3664910708210881, margin=0.4279717193158981, lpl_weight=0.9549256355155208\n",
      " - ratio=0.20692804982830132, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3307, LPL: 1.3863, Contrastive: 0.1532\n",
      "Epoch 50, Loss: 1.3277, LPL: 1.3863, Contrastive: 0.0861\n",
      "Epoch 100, Loss: 1.3276, LPL: 1.3863, Contrastive: 0.0844\n",
      " - Metrics: Accuracy=0.9387, F1=0.8970, Recall=0.8839, Precision=0.9106\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6299485950023005, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3664910708210881, margin=0.4279717193158981, lpl_weight=0.9549256355155208\n",
      " - ratio=0.20692804982830132, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3307, LPL: 1.3863, Contrastive: 0.1532\n",
      "Epoch 50, Loss: 1.3277, LPL: 1.3863, Contrastive: 0.0861\n",
      "Epoch 100, Loss: 1.3276, LPL: 1.3863, Contrastive: 0.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:19:57,155] Trial 55 finished with value: 0.893917615933638 and parameters: {'alpha': 0.6299485950023005, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3664910708210881, 'margin': 0.4279717193158981, 'lpl_weight': 0.9549256355155208, 'ratio': 0.20692804982830132, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9350, F1=0.8915, Recall=0.8839, Precision=0.8993\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131855.csv.\n",
      "Average F1 over 5 seeds: 0.8939  0.0027\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.12927406652748227, K=28, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.39834836408204427, margin=0.3662637789048554, lpl_weight=0.9990254887285128\n",
      " - ratio=0.2608498972002929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3851, LPL: 1.3863, Contrastive: 0.1589\n",
      "Epoch 50, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1054\n",
      "Epoch 100, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1038\n",
      " - Metrics: Accuracy=0.9269, F1=0.8837, Recall=0.9193, Precision=0.8507\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.12927406652748227, K=28, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.39834836408204427, margin=0.3662637789048554, lpl_weight=0.9990254887285128\n",
      " - ratio=0.2608498972002929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3851, LPL: 1.3863, Contrastive: 0.1589\n",
      "Epoch 50, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1054\n",
      "Epoch 100, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1038\n",
      " - Metrics: Accuracy=0.9287, F1=0.8856, Recall=0.9132, Precision=0.8596\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.12927406652748227, K=28, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.39834836408204427, margin=0.3662637789048554, lpl_weight=0.9990254887285128\n",
      " - ratio=0.2608498972002929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3851, LPL: 1.3863, Contrastive: 0.1589\n",
      "Epoch 50, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1054\n",
      "Epoch 100, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1038\n",
      " - Metrics: Accuracy=0.9365, F1=0.8973, Recall=0.9181, Precision=0.8773\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.12927406652748227, K=28, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.39834836408204427, margin=0.3662637789048554, lpl_weight=0.9990254887285128\n",
      " - ratio=0.2608498972002929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3851, LPL: 1.3863, Contrastive: 0.1589\n",
      "Epoch 50, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1054\n",
      "Epoch 100, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1038\n",
      " - Metrics: Accuracy=0.9287, F1=0.8837, Recall=0.8961, Precision=0.8716\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.12927406652748227, K=28, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.39834836408204427, margin=0.3662637789048554, lpl_weight=0.9990254887285128\n",
      " - ratio=0.2608498972002929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3851, LPL: 1.3863, Contrastive: 0.1589\n",
      "Epoch 50, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1054\n",
      "Epoch 100, Loss: 1.3850, LPL: 1.3863, Contrastive: 0.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:20:56,883] Trial 56 finished with value: 0.8879734411177488 and parameters: {'alpha': 0.12927406652748227, 'K': 28, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.39834836408204427, 'margin': 0.3662637789048554, 'lpl_weight': 0.9990254887285128, 'ratio': 0.2608498972002929, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9321, F1=0.8897, Recall=0.9071, Precision=0.8729\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102131957.csv.\n",
      "Average F1 over 5 seeds: 0.8880  0.0051\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.32425954051842437, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4200498243023405, margin=0.427415970562657, lpl_weight=0.9163608564749569\n",
      " - ratio=0.154889205124367, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2792, LPL: 1.3863, Contrastive: 0.1064\n",
      "Epoch 50, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0835\n",
      "Epoch 100, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0831\n",
      " - Metrics: Accuracy=0.9117, F1=0.8369, Recall=0.7494, Precision=0.9474\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.32425954051842437, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4200498243023405, margin=0.427415970562657, lpl_weight=0.9163608564749569\n",
      " - ratio=0.154889205124367, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2792, LPL: 1.3863, Contrastive: 0.1064\n",
      "Epoch 50, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0835\n",
      "Epoch 100, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0831\n",
      "Epoch 150, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0831\n",
      " - Metrics: Accuracy=0.9121, F1=0.8363, Recall=0.7433, Precision=0.9560\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.32425954051842437, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4200498243023405, margin=0.427415970562657, lpl_weight=0.9163608564749569\n",
      " - ratio=0.154889205124367, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2792, LPL: 1.3863, Contrastive: 0.1064\n",
      "Epoch 50, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0835\n",
      "Epoch 100, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0831\n",
      "Epoch 150, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0831\n",
      " - Metrics: Accuracy=0.9162, F1=0.8444, Recall=0.7531, Precision=0.9610\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.32425954051842437, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4200498243023405, margin=0.427415970562657, lpl_weight=0.9163608564749569\n",
      " - ratio=0.154889205124367, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2792, LPL: 1.3863, Contrastive: 0.1064\n",
      "Epoch 50, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0835\n",
      "Epoch 100, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0831\n",
      "Epoch 150, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0831\n",
      " - Metrics: Accuracy=0.9106, F1=0.8319, Recall=0.7323, Precision=0.9630\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.32425954051842437, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4200498243023405, margin=0.427415970562657, lpl_weight=0.9163608564749569\n",
      " - ratio=0.154889205124367, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2792, LPL: 1.3863, Contrastive: 0.1064\n",
      "Epoch 50, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0835\n",
      "Epoch 100, Loss: 1.2773, LPL: 1.3863, Contrastive: 0.0831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:22:08,195] Trial 57 finished with value: 0.8392415649674725 and parameters: {'alpha': 0.32425954051842437, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.4200498243023405, 'margin': 0.427415970562657, 'lpl_weight': 0.9163608564749569, 'ratio': 0.154889205124367, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9165, F1=0.8467, Recall=0.7628, Precision=0.9512\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132056.csv.\n",
      "Average F1 over 5 seeds: 0.8392  0.0055\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6984992184690538, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.3852556493205503, margin=0.49844958900053743, lpl_weight=0.8123526760184827\n",
      " - ratio=0.1947288413024608, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1616, LPL: 1.3863, Contrastive: 0.1888\n",
      " - Metrics: Accuracy=0.9021, F1=0.8418, Recall=0.8619, Precision=0.8226\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6984992184690538, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.3852556493205503, margin=0.49844958900053743, lpl_weight=0.8123526760184827\n",
      " - ratio=0.1947288413024608, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1616, LPL: 1.3863, Contrastive: 0.1888\n",
      " - Metrics: Accuracy=0.9029, F1=0.8430, Recall=0.8631, Precision=0.8238\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6984992184690538, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.3852556493205503, margin=0.49844958900053743, lpl_weight=0.8123526760184827\n",
      " - ratio=0.1947288413024608, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1616, LPL: 1.3863, Contrastive: 0.1888\n",
      " - Metrics: Accuracy=0.9051, F1=0.8466, Recall=0.8667, Precision=0.8273\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6984992184690538, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.3852556493205503, margin=0.49844958900053743, lpl_weight=0.8123526760184827\n",
      " - ratio=0.1947288413024608, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1616, LPL: 1.3863, Contrastive: 0.1888\n",
      " - Metrics: Accuracy=0.9021, F1=0.8418, Recall=0.8619, Precision=0.8226\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6984992184690538, K=27, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.3852556493205503, margin=0.49844958900053743, lpl_weight=0.8123526760184827\n",
      " - ratio=0.1947288413024608, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1616, LPL: 1.3863, Contrastive: 0.1888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:22:43,092] Trial 58 finished with value: 0.8452361846680576 and parameters: {'alpha': 0.6984992184690538, 'K': 27, 'layers': 1, 'hidden_channels': 64, 'out_channels': 256, 'norm': None, 'dropout': 0.3852556493205503, 'margin': 0.49844958900053743, 'lpl_weight': 0.8123526760184827, 'ratio': 0.1947288413024608, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9092, F1=0.8530, Recall=0.8729, Precision=0.8341\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132208.csv.\n",
      "Average F1 over 5 seeds: 0.8452  0.0043\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2613300411417402, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4281806900079101, margin=0.39130703877944817, lpl_weight=0.959319883855713\n",
      " - ratio=0.21173981545906934, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3371, LPL: 1.3863, Contrastive: 0.1773\n",
      "Epoch 50, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0969\n",
      "Epoch 100, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0951\n",
      " - Metrics: Accuracy=0.9383, F1=0.8961, Recall=0.8802, Precision=0.9125\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2613300411417402, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4281806900079101, margin=0.39130703877944817, lpl_weight=0.959319883855713\n",
      " - ratio=0.21173981545906934, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3371, LPL: 1.3863, Contrastive: 0.1773\n",
      "Epoch 50, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0969\n",
      "Epoch 100, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0951\n",
      " - Metrics: Accuracy=0.9265, F1=0.8771, Recall=0.8680, Precision=0.8864\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2613300411417402, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4281806900079101, margin=0.39130703877944817, lpl_weight=0.959319883855713\n",
      " - ratio=0.21173981545906934, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3371, LPL: 1.3863, Contrastive: 0.1773\n",
      "Epoch 50, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0969\n",
      "Epoch 100, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0951\n",
      " - Metrics: Accuracy=0.9383, F1=0.8965, Recall=0.8839, Precision=0.9094\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2613300411417402, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4281806900079101, margin=0.39130703877944817, lpl_weight=0.959319883855713\n",
      " - ratio=0.21173981545906934, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3371, LPL: 1.3863, Contrastive: 0.1773\n",
      "Epoch 50, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0969\n",
      "Epoch 100, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0951\n",
      " - Metrics: Accuracy=0.9394, F1=0.8986, Recall=0.8888, Precision=0.9087\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2613300411417402, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4281806900079101, margin=0.39130703877944817, lpl_weight=0.959319883855713\n",
      " - ratio=0.21173981545906934, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3371, LPL: 1.3863, Contrastive: 0.1773\n",
      "Epoch 50, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0969\n",
      "Epoch 100, Loss: 1.3338, LPL: 1.3863, Contrastive: 0.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:23:51,504] Trial 59 finished with value: 0.8925560684698114 and parameters: {'alpha': 0.2613300411417402, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4281806900079101, 'margin': 0.39130703877944817, 'lpl_weight': 0.959319883855713, 'ratio': 0.21173981545906934, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9369, F1=0.8945, Recall=0.8863, Precision=0.9029\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132243.csv.\n",
      "Average F1 over 5 seeds: 0.8926  0.0078\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5729553706038593, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3707657116341881, margin=0.4564566449583871, lpl_weight=0.7348754175122659\n",
      " - ratio=0.25078627965054584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0591, LPL: 1.3863, Contrastive: 0.1523\n",
      " - Metrics: Accuracy=0.9302, F1=0.8873, Recall=0.9095, Precision=0.8661\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5729553706038593, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3707657116341881, margin=0.4564566449583871, lpl_weight=0.7348754175122659\n",
      " - ratio=0.25078627965054584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0591, LPL: 1.3863, Contrastive: 0.1523\n",
      " - Metrics: Accuracy=0.9269, F1=0.8826, Recall=0.9095, Precision=0.8571\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5729553706038593, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3707657116341881, margin=0.4564566449583871, lpl_weight=0.7348754175122659\n",
      " - ratio=0.25078627965054584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0591, LPL: 1.3863, Contrastive: 0.1523\n",
      " - Metrics: Accuracy=0.9369, F1=0.8979, Recall=0.9193, Precision=0.8775\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5729553706038593, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3707657116341881, margin=0.4564566449583871, lpl_weight=0.7348754175122659\n",
      " - ratio=0.25078627965054584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0591, LPL: 1.3863, Contrastive: 0.1523\n",
      " - Metrics: Accuracy=0.9302, F1=0.8869, Recall=0.9059, Precision=0.8687\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5729553706038593, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3707657116341881, margin=0.4564566449583871, lpl_weight=0.7348754175122659\n",
      " - ratio=0.25078627965054584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0591, LPL: 1.3863, Contrastive: 0.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:24:21,828] Trial 60 finished with value: 0.8890283477970538 and parameters: {'alpha': 0.5729553706038593, 'K': 28, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3707657116341881, 'margin': 0.4564566449583871, 'lpl_weight': 0.7348754175122659, 'ratio': 0.25078627965054584, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9321, F1=0.8905, Recall=0.9144, Precision=0.8677\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132351.csv.\n",
      "Average F1 over 5 seeds: 0.8890  0.0051\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6098304561433878, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35580060845511885, margin=0.538704768510248, lpl_weight=0.9602197431188052\n",
      " - ratio=0.20741693531759717, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3370, LPL: 1.3863, Contrastive: 0.1460\n",
      " - Metrics: Accuracy=0.9439, F1=0.9059, Recall=0.8949, Precision=0.9173\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6098304561433878, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35580060845511885, margin=0.538704768510248, lpl_weight=0.9602197431188052\n",
      " - ratio=0.20741693531759717, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3370, LPL: 1.3863, Contrastive: 0.1460\n",
      " - Metrics: Accuracy=0.9346, F1=0.8913, Recall=0.8875, Precision=0.8952\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6098304561433878, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35580060845511885, margin=0.538704768510248, lpl_weight=0.9602197431188052\n",
      " - ratio=0.20741693531759717, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3370, LPL: 1.3863, Contrastive: 0.1460\n",
      " - Metrics: Accuracy=0.9387, F1=0.8974, Recall=0.8875, Precision=0.9075\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6098304561433878, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35580060845511885, margin=0.538704768510248, lpl_weight=0.9602197431188052\n",
      " - ratio=0.20741693531759717, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3370, LPL: 1.3863, Contrastive: 0.1460\n",
      " - Metrics: Accuracy=0.9313, F1=0.8864, Recall=0.8875, Precision=0.8854\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6098304561433878, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35580060845511885, margin=0.538704768510248, lpl_weight=0.9602197431188052\n",
      " - ratio=0.20741693531759717, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3370, LPL: 1.3863, Contrastive: 0.1460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:24:50,110] Trial 61 finished with value: 0.8968097375284024 and parameters: {'alpha': 0.6098304561433878, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.35580060845511885, 'margin': 0.538704768510248, 'lpl_weight': 0.9602197431188052, 'ratio': 0.20741693531759717, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9409, F1=0.9029, Recall=0.9095, Precision=0.8964\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132421.csv.\n",
      "Average F1 over 5 seeds: 0.8968  0.0072\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6464940412345807, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35226586309075814, margin=0.428101611783232, lpl_weight=0.8964482108365002\n",
      " - ratio=0.17720564513271597, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2583, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.2516, LPL: 1.3863, Contrastive: 0.0859\n",
      "Epoch 100, Loss: 1.2515, LPL: 1.3863, Contrastive: 0.0841\n",
      " - Metrics: Accuracy=0.9298, F1=0.8793, Recall=0.8460, Precision=0.9153\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6464940412345807, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35226586309075814, margin=0.428101611783232, lpl_weight=0.8964482108365002\n",
      " - ratio=0.17720564513271597, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2583, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.2516, LPL: 1.3863, Contrastive: 0.0859\n",
      "Epoch 100, Loss: 1.2515, LPL: 1.3863, Contrastive: 0.0841\n",
      " - Metrics: Accuracy=0.9254, F1=0.8722, Recall=0.8423, Precision=0.9042\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6464940412345807, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35226586309075814, margin=0.428101611783232, lpl_weight=0.8964482108365002\n",
      " - ratio=0.17720564513271597, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2583, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.2516, LPL: 1.3863, Contrastive: 0.0859\n",
      "Epoch 100, Loss: 1.2514, LPL: 1.3863, Contrastive: 0.0841\n",
      " - Metrics: Accuracy=0.9361, F1=0.8902, Recall=0.8570, Precision=0.9260\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6464940412345807, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35226586309075814, margin=0.428101611783232, lpl_weight=0.8964482108365002\n",
      " - ratio=0.17720564513271597, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2583, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.2516, LPL: 1.3863, Contrastive: 0.0859\n",
      "Epoch 100, Loss: 1.2515, LPL: 1.3863, Contrastive: 0.0841\n",
      " - Metrics: Accuracy=0.9295, F1=0.8790, Recall=0.8484, Precision=0.9120\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6464940412345807, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.35226586309075814, margin=0.428101611783232, lpl_weight=0.8964482108365002\n",
      " - ratio=0.17720564513271597, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2583, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.2516, LPL: 1.3863, Contrastive: 0.0859\n",
      "Epoch 100, Loss: 1.2515, LPL: 1.3863, Contrastive: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:25:48,942] Trial 62 finished with value: 0.8823525852135411 and parameters: {'alpha': 0.6464940412345807, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.35226586309075814, 'margin': 0.428101611783232, 'lpl_weight': 0.8964482108365002, 'ratio': 0.17720564513271597, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9361, F1=0.8911, Recall=0.8655, Precision=0.9183\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132450.csv.\n",
      "Average F1 over 5 seeds: 0.8824  0.0072\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6052643702675, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31077415843342276, margin=0.5207699798831901, lpl_weight=0.9775885888952109\n",
      " - ratio=0.22496719399053794, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3583, LPL: 1.3863, Contrastive: 0.1391\n",
      " - Metrics: Accuracy=0.9387, F1=0.8982, Recall=0.8949, Precision=0.9015\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6052643702675, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31077415843342276, margin=0.5207699798831901, lpl_weight=0.9775885888952109\n",
      " - ratio=0.22496719399053794, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3583, LPL: 1.3863, Contrastive: 0.1391\n",
      " - Metrics: Accuracy=0.9324, F1=0.8897, Recall=0.9022, Precision=0.8775\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6052643702675, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31077415843342276, margin=0.5207699798831901, lpl_weight=0.9775885888952109\n",
      " - ratio=0.22496719399053794, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3583, LPL: 1.3863, Contrastive: 0.1391\n",
      " - Metrics: Accuracy=0.9391, F1=0.8993, Recall=0.9010, Precision=0.8977\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6052643702675, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31077415843342276, margin=0.5207699798831901, lpl_weight=0.9775885888952109\n",
      " - ratio=0.22496719399053794, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3583, LPL: 1.3863, Contrastive: 0.1391\n",
      " - Metrics: Accuracy=0.9302, F1=0.8861, Recall=0.8985, Precision=0.8740\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6052643702675, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31077415843342276, margin=0.5207699798831901, lpl_weight=0.9775885888952109\n",
      " - ratio=0.22496719399053794, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3583, LPL: 1.3863, Contrastive: 0.1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:26:19,482] Trial 63 finished with value: 0.8948077246617174 and parameters: {'alpha': 0.6052643702675, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.31077415843342276, 'margin': 0.5207699798831901, 'lpl_weight': 0.9775885888952109, 'ratio': 0.22496719399053794, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9391, F1=0.9008, Recall=0.9156, Precision=0.8864\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132549.csv.\n",
      "Average F1 over 5 seeds: 0.8948  0.0058\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.619063651494773, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.29094883063116656, margin=0.5364083895866801, lpl_weight=0.9628709051693378\n",
      " - ratio=0.22801291140473523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3399, LPL: 1.3863, Contrastive: 0.1355\n",
      " - Metrics: Accuracy=0.9332, F1=0.8908, Recall=0.9022, Precision=0.8796\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.619063651494773, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.29094883063116656, margin=0.5364083895866801, lpl_weight=0.9628709051693378\n",
      " - ratio=0.22801291140473523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3399, LPL: 1.3863, Contrastive: 0.1355\n",
      " - Metrics: Accuracy=0.9313, F1=0.8889, Recall=0.9095, Precision=0.8692\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.619063651494773, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.29094883063116656, margin=0.5364083895866801, lpl_weight=0.9628709051693378\n",
      " - ratio=0.22801291140473523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3399, LPL: 1.3863, Contrastive: 0.1355\n",
      " - Metrics: Accuracy=0.9357, F1=0.8953, Recall=0.9095, Precision=0.8815\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.619063651494773, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.29094883063116656, margin=0.5364083895866801, lpl_weight=0.9628709051693378\n",
      " - ratio=0.22801291140473523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3399, LPL: 1.3863, Contrastive: 0.1355\n",
      " - Metrics: Accuracy=0.9269, F1=0.8812, Recall=0.8973, Precision=0.8656\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.619063651494773, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.29094883063116656, margin=0.5364083895866801, lpl_weight=0.9628709051693378\n",
      " - ratio=0.22801291140473523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3399, LPL: 1.3863, Contrastive: 0.1355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:26:47,827] Trial 64 finished with value: 0.8885010374013321 and parameters: {'alpha': 0.619063651494773, 'K': 27, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.29094883063116656, 'margin': 0.5364083895866801, 'lpl_weight': 0.9628709051693378, 'ratio': 0.22801291140473523, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9291, F1=0.8864, Recall=0.9156, Precision=0.8589\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132619.csv.\n",
      "Average F1 over 5 seeds: 0.8885  0.0047\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6725909572112286, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3090139082189676, margin=0.6488331227820506, lpl_weight=0.9811821234441153\n",
      " - ratio=0.24576664775379164, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3628, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.9243, F1=0.8788, Recall=0.9083, Precision=0.8511\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6725909572112286, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3090139082189676, margin=0.6488331227820506, lpl_weight=0.9811821234441153\n",
      " - ratio=0.24576664775379164, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3628, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.9250, F1=0.8797, Recall=0.9071, Precision=0.8539\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6725909572112286, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3090139082189676, margin=0.6488331227820506, lpl_weight=0.9811821234441153\n",
      " - ratio=0.24576664775379164, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3628, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.9147, F1=0.8639, Recall=0.8961, Precision=0.8339\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6725909572112286, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3090139082189676, margin=0.6488331227820506, lpl_weight=0.9811821234441153\n",
      " - ratio=0.24576664775379164, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3628, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.9136, F1=0.8633, Recall=0.9034, Precision=0.8266\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6725909572112286, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3090139082189676, margin=0.6488331227820506, lpl_weight=0.9811821234441153\n",
      " - ratio=0.24576664775379164, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3628, LPL: 1.3863, Contrastive: 0.1370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:27:16,622] Trial 65 finished with value: 0.8709584149342181 and parameters: {'alpha': 0.6725909572112286, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3090139082189676, 'margin': 0.6488331227820506, 'lpl_weight': 0.9811821234441153, 'ratio': 0.24576664775379164, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9173, F1=0.8692, Recall=0.9095, Precision=0.8322\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132647.csv.\n",
      "Average F1 over 5 seeds: 0.8710  0.0071\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5195520398168825, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32246449049659626, margin=0.9307018469180635, lpl_weight=0.9344274574554052\n",
      " - ratio=0.21441613998530887, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3045, LPL: 1.3863, Contrastive: 0.1384\n",
      " - Metrics: Accuracy=0.9147, F1=0.8589, Recall=0.8594, Precision=0.8584\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5195520398168825, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32246449049659626, margin=0.9307018469180635, lpl_weight=0.9344274574554052\n",
      " - ratio=0.21441613998530887, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3045, LPL: 1.3863, Contrastive: 0.1384\n",
      " - Metrics: Accuracy=0.9151, F1=0.8585, Recall=0.8533, Precision=0.8639\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5195520398168825, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32246449049659626, margin=0.9307018469180635, lpl_weight=0.9344274574554052\n",
      " - ratio=0.21441613998530887, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3045, LPL: 1.3863, Contrastive: 0.1384\n",
      " - Metrics: Accuracy=0.9099, F1=0.8492, Recall=0.8399, Precision=0.8588\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5195520398168825, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32246449049659626, margin=0.9307018469180635, lpl_weight=0.9344274574554052\n",
      " - ratio=0.21441613998530887, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3045, LPL: 1.3863, Contrastive: 0.1384\n",
      " - Metrics: Accuracy=0.9062, F1=0.8436, Recall=0.8374, Precision=0.8499\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5195520398168825, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.32246449049659626, margin=0.9307018469180635, lpl_weight=0.9344274574554052\n",
      " - ratio=0.21441613998530887, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3045, LPL: 1.3863, Contrastive: 0.1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:27:47,464] Trial 66 finished with value: 0.851107998101949 and parameters: {'alpha': 0.5195520398168825, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.32246449049659626, 'margin': 0.9307018469180635, 'lpl_weight': 0.9344274574554052, 'ratio': 0.21441613998530887, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9062, F1=0.8453, Recall=0.8484, Precision=0.8422\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132716.csv.\n",
      "Average F1 over 5 seeds: 0.8511  0.0065\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6035707932028725, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.34441007016238384, margin=0.5162806206996543, lpl_weight=0.5812826850203607\n",
      " - ratio=0.2634635486829964, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8663, LPL: 1.3863, Contrastive: 0.1444\n",
      " - Metrics: Accuracy=0.9258, F1=0.8821, Recall=0.9193, Precision=0.8478\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6035707932028725, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.34441007016238384, margin=0.5162806206996543, lpl_weight=0.5812826850203607\n",
      " - ratio=0.2634635486829964, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8663, LPL: 1.3863, Contrastive: 0.1444\n",
      " - Metrics: Accuracy=0.9250, F1=0.8818, Recall=0.9254, Precision=0.8420\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6035707932028725, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.34441007016238384, margin=0.5162806206996543, lpl_weight=0.5812826850203607\n",
      " - ratio=0.2634635486829964, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8663, LPL: 1.3863, Contrastive: 0.1444\n",
      " - Metrics: Accuracy=0.9332, F1=0.8933, Recall=0.9267, Precision=0.8623\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6035707932028725, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.34441007016238384, margin=0.5162806206996543, lpl_weight=0.5812826850203607\n",
      " - ratio=0.2634635486829964, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8663, LPL: 1.3863, Contrastive: 0.1444\n",
      " - Metrics: Accuracy=0.9287, F1=0.8864, Recall=0.9205, Precision=0.8547\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6035707932028725, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.34441007016238384, margin=0.5162806206996543, lpl_weight=0.5812826850203607\n",
      " - ratio=0.2634635486829964, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8663, LPL: 1.3863, Contrastive: 0.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:28:15,655] Trial 67 finished with value: 0.8851752969669233 and parameters: {'alpha': 0.6035707932028725, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.34441007016238384, 'margin': 0.5162806206996543, 'lpl_weight': 0.5812826850203607, 'ratio': 0.2634635486829964, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9258, F1=0.8822, Recall=0.9205, Precision=0.8470\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132747.csv.\n",
      "Average F1 over 5 seeds: 0.8852  0.0044\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7257028801833406, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2959646370019671, margin=0.6035641823192862, lpl_weight=0.9173987208353208\n",
      " - ratio=0.30732684304758523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2829, LPL: 1.3863, Contrastive: 0.1350\n",
      " - Metrics: Accuracy=0.9154, F1=0.8697, Recall=0.9340, Precision=0.8136\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7257028801833406, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2959646370019671, margin=0.6035641823192862, lpl_weight=0.9173987208353208\n",
      " - ratio=0.30732684304758523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2829, LPL: 1.3863, Contrastive: 0.1350\n",
      " - Metrics: Accuracy=0.9066, F1=0.8579, Recall=0.9340, Precision=0.7934\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7257028801833406, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2959646370019671, margin=0.6035641823192862, lpl_weight=0.9173987208353208\n",
      " - ratio=0.30732684304758523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2829, LPL: 1.3863, Contrastive: 0.1350\n",
      " - Metrics: Accuracy=0.9088, F1=0.8605, Recall=0.9315, Precision=0.7996\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7257028801833406, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2959646370019671, margin=0.6035641823192862, lpl_weight=0.9173987208353208\n",
      " - ratio=0.30732684304758523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2829, LPL: 1.3863, Contrastive: 0.1350\n",
      " - Metrics: Accuracy=0.9095, F1=0.8609, Recall=0.9267, Precision=0.8038\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7257028801833406, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.2959646370019671, margin=0.6035641823192862, lpl_weight=0.9173987208353208\n",
      " - ratio=0.30732684304758523, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2829, LPL: 1.3863, Contrastive: 0.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:28:43,843] Trial 68 finished with value: 0.8633406529893193 and parameters: {'alpha': 0.7257028801833406, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2959646370019671, 'margin': 0.6035641823192862, 'lpl_weight': 0.9173987208353208, 'ratio': 0.30732684304758523, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9140, F1=0.8677, Recall=0.9340, Precision=0.8102\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132815.csv.\n",
      "Average F1 over 5 seeds: 0.8633  0.0045\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5030662419711407, K=27, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2767944288965046, margin=0.5834454890482643, lpl_weight=0.7889303182405714\n",
      " - ratio=0.2711340124430112, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1215, LPL: 1.3863, Contrastive: 0.1319\n",
      " - Metrics: Accuracy=0.8815, F1=0.8266, Recall=0.9352, Precision=0.7406\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5030662419711407, K=27, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2767944288965046, margin=0.5834454890482643, lpl_weight=0.7889303182405714\n",
      " - ratio=0.2711340124430112, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1215, LPL: 1.3863, Contrastive: 0.1319\n",
      " - Metrics: Accuracy=0.8859, F1=0.8331, Recall=0.9425, Precision=0.7464\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5030662419711407, K=27, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2767944288965046, margin=0.5834454890482643, lpl_weight=0.7889303182405714\n",
      " - ratio=0.2711340124430112, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1215, LPL: 1.3863, Contrastive: 0.1319\n",
      " - Metrics: Accuracy=0.8844, F1=0.8309, Recall=0.9401, Precision=0.7444\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5030662419711407, K=27, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2767944288965046, margin=0.5834454890482643, lpl_weight=0.7889303182405714\n",
      " - ratio=0.2711340124430112, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1215, LPL: 1.3863, Contrastive: 0.1319\n",
      " - Metrics: Accuracy=0.8792, F1=0.8233, Recall=0.9315, Precision=0.7377\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5030662419711407, K=27, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2767944288965046, margin=0.5834454890482643, lpl_weight=0.7889303182405714\n",
      " - ratio=0.2711340124430112, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1215, LPL: 1.3863, Contrastive: 0.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:29:13,180] Trial 69 finished with value: 0.8280929227444623 and parameters: {'alpha': 0.5030662419711407, 'K': 27, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.2767944288965046, 'margin': 0.5834454890482643, 'lpl_weight': 0.7889303182405714, 'ratio': 0.2711340124430112, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8815, F1=0.8266, Recall=0.9352, Precision=0.7406\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132843.csv.\n",
      "Average F1 over 5 seeds: 0.8281  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.569945463710813, K=31, layers=3, hidden=64, out=128\n",
      " - norm=layernorm, dropout=0.3033205755088535, margin=0.3789178238965375, lpl_weight=0.8705987058347124\n",
      " - ratio=0.2325033005270093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 1.2201, LPL: 1.3863, Contrastive: 0.1018\n",
      "Epoch 100, Loss: 1.2199, LPL: 1.3863, Contrastive: 0.1005\n",
      " - Metrics: Accuracy=0.9191, F1=0.8713, Recall=0.9059, Precision=0.8392\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.569945463710813, K=31, layers=3, hidden=64, out=128\n",
      " - norm=layernorm, dropout=0.3033205755088535, margin=0.3789178238965375, lpl_weight=0.8705987058347124\n",
      " - ratio=0.2325033005270093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 1.2201, LPL: 1.3863, Contrastive: 0.1018\n",
      "Epoch 100, Loss: 1.2199, LPL: 1.3863, Contrastive: 0.1004\n",
      " - Metrics: Accuracy=0.9184, F1=0.8682, Recall=0.8900, Precision=0.8475\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.569945463710813, K=31, layers=3, hidden=64, out=128\n",
      " - norm=layernorm, dropout=0.3033205755088535, margin=0.3789178238965375, lpl_weight=0.8705987058347124\n",
      " - ratio=0.2325033005270093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 1.2201, LPL: 1.3863, Contrastive: 0.1018\n",
      "Epoch 100, Loss: 1.2199, LPL: 1.3863, Contrastive: 0.1004\n",
      " - Metrics: Accuracy=0.9346, F1=0.8925, Recall=0.8985, Precision=0.8866\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.569945463710813, K=31, layers=3, hidden=64, out=128\n",
      " - norm=layernorm, dropout=0.3033205755088535, margin=0.3789178238965375, lpl_weight=0.8705987058347124\n",
      " - ratio=0.2325033005270093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 1.2201, LPL: 1.3863, Contrastive: 0.1018\n",
      "Epoch 100, Loss: 1.2199, LPL: 1.3863, Contrastive: 0.1004\n",
      "Epoch 150, Loss: 1.2199, LPL: 1.3863, Contrastive: 0.1001\n",
      "Epoch 200, Loss: 1.2198, LPL: 1.3863, Contrastive: 0.0997\n",
      "Epoch 250, Loss: 1.2198, LPL: 1.3863, Contrastive: 0.0995\n",
      " - Metrics: Accuracy=0.9206, F1=0.8698, Recall=0.8778, Precision=0.8619\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.569945463710813, K=31, layers=3, hidden=64, out=128\n",
      " - norm=layernorm, dropout=0.3033205755088535, margin=0.3789178238965375, lpl_weight=0.8705987058347124\n",
      " - ratio=0.2325033005270093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.1264\n",
      "Epoch 50, Loss: 1.2201, LPL: 1.3863, Contrastive: 0.1018\n",
      "Epoch 100, Loss: 1.2199, LPL: 1.3863, Contrastive: 0.1004\n",
      "Epoch 150, Loss: 1.2198, LPL: 1.3863, Contrastive: 0.1000\n",
      "Epoch 200, Loss: 1.2198, LPL: 1.3863, Contrastive: 0.0997\n",
      "Epoch 250, Loss: 1.2198, LPL: 1.3863, Contrastive: 0.0997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:30:17,652] Trial 70 finished with value: 0.8760946935467395 and parameters: {'alpha': 0.569945463710813, 'K': 31, 'layers': 3, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3033205755088535, 'margin': 0.3789178238965375, 'lpl_weight': 0.8705987058347124, 'ratio': 0.2325033005270093, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9258, F1=0.8787, Recall=0.8900, Precision=0.8677\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102132913.csv.\n",
      "Average F1 over 5 seeds: 0.8761  0.0090\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.17537789154732747, K=29, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.39221433628026964, margin=0.469586430126344, lpl_weight=0.9421121519887511\n",
      " - ratio=0.19760634659867052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3172, LPL: 1.3863, Contrastive: 0.1934\n",
      " - Metrics: Accuracy=0.9287, F1=0.8812, Recall=0.8753, Precision=0.8872\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.17537789154732747, K=29, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.39221433628026964, margin=0.469586430126344, lpl_weight=0.9421121519887511\n",
      " - ratio=0.19760634659867052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3172, LPL: 1.3863, Contrastive: 0.1934\n",
      " - Metrics: Accuracy=0.9291, F1=0.8828, Recall=0.8839, Precision=0.8817\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.17537789154732747, K=29, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.39221433628026964, margin=0.469586430126344, lpl_weight=0.9421121519887511\n",
      " - ratio=0.19760634659867052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3172, LPL: 1.3863, Contrastive: 0.1934\n",
      " - Metrics: Accuracy=0.9350, F1=0.8912, Recall=0.8814, Precision=0.9012\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.17537789154732747, K=29, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.39221433628026964, margin=0.469586430126344, lpl_weight=0.9421121519887511\n",
      " - ratio=0.19760634659867052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3172, LPL: 1.3863, Contrastive: 0.1934\n",
      " - Metrics: Accuracy=0.9380, F1=0.8950, Recall=0.8753, Precision=0.9156\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.17537789154732747, K=29, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.39221433628026964, margin=0.469586430126344, lpl_weight=0.9421121519887511\n",
      " - ratio=0.19760634659867052, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3172, LPL: 1.3863, Contrastive: 0.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:30:45,531] Trial 71 finished with value: 0.8884525849791322 and parameters: {'alpha': 0.17537789154732747, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.39221433628026964, 'margin': 0.469586430126344, 'lpl_weight': 0.9421121519887511, 'ratio': 0.19760634659867052, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9350, F1=0.8920, Recall=0.8888, Precision=0.8953\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133017.csv.\n",
      "Average F1 over 5 seeds: 0.8885  0.0054\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.20405508456222662, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.44546933782905024, margin=0.500445751438134, lpl_weight=0.8283815988283176\n",
      " - ratio=0.19128253676857995, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1786, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 1.1596, LPL: 1.3863, Contrastive: 0.0656\n",
      "Epoch 100, Loss: 1.1594, LPL: 1.3863, Contrastive: 0.0643\n",
      " - Metrics: Accuracy=0.9413, F1=0.9004, Recall=0.8790, Precision=0.9230\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.20405508456222662, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.44546933782905024, margin=0.500445751438134, lpl_weight=0.8283815988283176\n",
      " - ratio=0.19128253676857995, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1786, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 1.1596, LPL: 1.3863, Contrastive: 0.0656\n",
      "Epoch 100, Loss: 1.1594, LPL: 1.3863, Contrastive: 0.0643\n",
      " - Metrics: Accuracy=0.9321, F1=0.8851, Recall=0.8667, Precision=0.9043\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.20405508456222662, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.44546933782905024, margin=0.500445751438134, lpl_weight=0.8283815988283176\n",
      " - ratio=0.19128253676857995, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1786, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 1.1596, LPL: 1.3863, Contrastive: 0.0656\n",
      "Epoch 100, Loss: 1.1594, LPL: 1.3863, Contrastive: 0.0643\n",
      " - Metrics: Accuracy=0.9380, F1=0.8941, Recall=0.8667, Precision=0.9232\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.20405508456222662, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.44546933782905024, margin=0.500445751438134, lpl_weight=0.8283815988283176\n",
      " - ratio=0.19128253676857995, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1786, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 1.1596, LPL: 1.3863, Contrastive: 0.0656\n",
      "Epoch 100, Loss: 1.1594, LPL: 1.3863, Contrastive: 0.0643\n",
      " - Metrics: Accuracy=0.9346, F1=0.8883, Recall=0.8606, Precision=0.9179\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.20405508456222662, K=29, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.44546933782905024, margin=0.500445751438134, lpl_weight=0.8283815988283176\n",
      " - ratio=0.19128253676857995, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1786, LPL: 1.3863, Contrastive: 0.1762\n",
      "Epoch 50, Loss: 1.1596, LPL: 1.3863, Contrastive: 0.0656\n",
      "Epoch 100, Loss: 1.1594, LPL: 1.3863, Contrastive: 0.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:31:58,374] Trial 72 finished with value: 0.8907928832972157 and parameters: {'alpha': 0.20405508456222662, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.44546933782905024, 'margin': 0.500445751438134, 'lpl_weight': 0.8283815988283176, 'ratio': 0.19128253676857995, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9324, F1=0.8860, Recall=0.8692, Precision=0.9034\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133045.csv.\n",
      "Average F1 over 5 seeds: 0.8908  0.0057\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.47187661999728553, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3766362768431469, margin=0.44751499687166574, lpl_weight=0.9658404821763844\n",
      " - ratio=0.16646897327794818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3445, LPL: 1.3863, Contrastive: 0.1630\n",
      "Epoch 50, Loss: 1.3417, LPL: 1.3863, Contrastive: 0.0796\n",
      "Epoch 100, Loss: 1.3416, LPL: 1.3863, Contrastive: 0.0784\n",
      " - Metrics: Accuracy=0.9350, F1=0.8880, Recall=0.8533, Precision=0.9257\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.47187661999728553, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3766362768431469, margin=0.44751499687166574, lpl_weight=0.9658404821763844\n",
      " - ratio=0.16646897327794818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3445, LPL: 1.3863, Contrastive: 0.1630\n",
      "Epoch 50, Loss: 1.3417, LPL: 1.3863, Contrastive: 0.0796\n",
      "Epoch 100, Loss: 1.3416, LPL: 1.3863, Contrastive: 0.0784\n",
      " - Metrics: Accuracy=0.9321, F1=0.8832, Recall=0.8509, Precision=0.9182\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.47187661999728553, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3766362768431469, margin=0.44751499687166574, lpl_weight=0.9658404821763844\n",
      " - ratio=0.16646897327794818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3445, LPL: 1.3863, Contrastive: 0.1630\n",
      "Epoch 50, Loss: 1.3417, LPL: 1.3863, Contrastive: 0.0796\n",
      "Epoch 100, Loss: 1.3416, LPL: 1.3863, Contrastive: 0.0785\n",
      " - Metrics: Accuracy=0.9372, F1=0.8923, Recall=0.8606, Precision=0.9263\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.47187661999728553, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3766362768431469, margin=0.44751499687166574, lpl_weight=0.9658404821763844\n",
      " - ratio=0.16646897327794818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3445, LPL: 1.3863, Contrastive: 0.1630\n",
      "Epoch 50, Loss: 1.3417, LPL: 1.3863, Contrastive: 0.0796\n",
      "Epoch 100, Loss: 1.3416, LPL: 1.3863, Contrastive: 0.0785\n",
      " - Metrics: Accuracy=0.9357, F1=0.8879, Recall=0.8423, Precision=0.9387\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.47187661999728553, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3766362768431469, margin=0.44751499687166574, lpl_weight=0.9658404821763844\n",
      " - ratio=0.16646897327794818, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3445, LPL: 1.3863, Contrastive: 0.1630\n",
      "Epoch 50, Loss: 1.3417, LPL: 1.3863, Contrastive: 0.0796\n",
      "Epoch 100, Loss: 1.3416, LPL: 1.3863, Contrastive: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:33:12,801] Trial 73 finished with value: 0.8909011920821328 and parameters: {'alpha': 0.47187661999728553, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3766362768431469, 'margin': 0.44751499687166574, 'lpl_weight': 0.9658404821763844, 'ratio': 0.16646897327794818, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9439, F1=0.9031, Recall=0.8655, Precision=0.9440\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133158.csv.\n",
      "Average F1 over 5 seeds: 0.8909  0.0067\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6528939460347298, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4103931762072415, margin=0.41936570170209975, lpl_weight=0.89530486783585\n",
      " - ratio=0.20746469969414802, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2582, LPL: 1.3863, Contrastive: 0.1630\n",
      " - Metrics: Accuracy=0.9369, F1=0.8950, Recall=0.8912, Precision=0.8989\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6528939460347298, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4103931762072415, margin=0.41936570170209975, lpl_weight=0.89530486783585\n",
      " - ratio=0.20746469969414802, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2582, LPL: 1.3863, Contrastive: 0.1630\n",
      " - Metrics: Accuracy=0.9321, F1=0.8874, Recall=0.8863, Precision=0.8885\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6528939460347298, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4103931762072415, margin=0.41936570170209975, lpl_weight=0.89530486783585\n",
      " - ratio=0.20746469969414802, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2582, LPL: 1.3863, Contrastive: 0.1630\n",
      " - Metrics: Accuracy=0.9391, F1=0.8983, Recall=0.8912, Precision=0.9056\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6528939460347298, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4103931762072415, margin=0.41936570170209975, lpl_weight=0.89530486783585\n",
      " - ratio=0.20746469969414802, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2582, LPL: 1.3863, Contrastive: 0.1630\n",
      " - Metrics: Accuracy=0.9335, F1=0.8892, Recall=0.8826, Precision=0.8958\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6528939460347298, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4103931762072415, margin=0.41936570170209975, lpl_weight=0.89530486783585\n",
      " - ratio=0.20746469969414802, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2582, LPL: 1.3863, Contrastive: 0.1630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:33:41,985] Trial 74 finished with value: 0.8937292003400483 and parameters: {'alpha': 0.6528939460347298, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.4103931762072415, 'margin': 0.41936570170209975, 'lpl_weight': 0.89530486783585, 'ratio': 0.20746469969414802, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9383, F1=0.8987, Recall=0.9059, Precision=0.8917\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133312.csv.\n",
      "Average F1 over 5 seeds: 0.8937  0.0047\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.13681365287603361, K=28, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.3580415818020687, margin=0.5429507751148831, lpl_weight=0.9829252971453326\n",
      " - ratio=0.24363920016915325, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3644, LPL: 1.3863, Contrastive: 0.1069\n",
      "Epoch 50, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0533\n",
      "Epoch 100, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0529\n",
      "Epoch 150, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0528\n",
      "Epoch 200, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0527\n",
      "Epoch 250, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0527\n",
      " - Metrics: Accuracy=0.9121, F1=0.8436, Recall=0.7848, Precision=0.9119\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.13681365287603361, K=28, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.3580415818020687, margin=0.5429507751148831, lpl_weight=0.9829252971453326\n",
      " - ratio=0.24363920016915325, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3644, LPL: 1.3863, Contrastive: 0.1069\n",
      "Epoch 50, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0533\n",
      "Epoch 100, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0529\n",
      "Epoch 150, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0528\n",
      "Epoch 200, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0528\n",
      " - Metrics: Accuracy=0.9147, F1=0.8481, Recall=0.7885, Precision=0.9175\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.13681365287603361, K=28, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.3580415818020687, margin=0.5429507751148831, lpl_weight=0.9829252971453326\n",
      " - ratio=0.24363920016915325, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3644, LPL: 1.3863, Contrastive: 0.1069\n",
      "Epoch 50, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0533\n",
      "Epoch 100, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0529\n",
      "Epoch 150, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0528\n",
      " - Metrics: Accuracy=0.9195, F1=0.8584, Recall=0.8081, Precision=0.9155\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.13681365287603361, K=28, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.3580415818020687, margin=0.5429507751148831, lpl_weight=0.9829252971453326\n",
      " - ratio=0.24363920016915325, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3644, LPL: 1.3863, Contrastive: 0.1069\n",
      "Epoch 50, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0533\n",
      "Epoch 100, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0529\n",
      "Epoch 150, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0528\n",
      " - Metrics: Accuracy=0.9140, F1=0.8472, Recall=0.7897, Precision=0.9137\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.13681365287603361, K=28, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.3580415818020687, margin=0.5429507751148831, lpl_weight=0.9829252971453326\n",
      " - ratio=0.24363920016915325, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3644, LPL: 1.3863, Contrastive: 0.1069\n",
      "Epoch 50, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0533\n",
      "Epoch 100, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0529\n",
      "Epoch 150, Loss: 1.3635, LPL: 1.3863, Contrastive: 0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:35:15,763] Trial 75 finished with value: 0.8524545155270505 and parameters: {'alpha': 0.13681365287603361, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': None, 'dropout': 0.3580415818020687, 'margin': 0.5429507751148831, 'lpl_weight': 0.9829252971453326, 'ratio': 0.24363920016915325, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9225, F1=0.8649, Recall=0.8215, Precision=0.9130\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133342.csv.\n",
      "Average F1 over 5 seeds: 0.8525  0.0079\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.22805216370986903, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.4839441104290726, margin=0.47948628055488735, lpl_weight=0.8800054181052948\n",
      " - ratio=0.1836585764782951, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.1685\n",
      "Epoch 50, Loss: 1.2286, LPL: 1.3863, Contrastive: 0.0721\n",
      "Epoch 100, Loss: 1.2284, LPL: 1.3863, Contrastive: 0.0708\n",
      "Epoch 150, Loss: 1.2285, LPL: 1.3863, Contrastive: 0.0711\n",
      " - Metrics: Accuracy=0.9265, F1=0.8755, Recall=0.8557, Precision=0.8963\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.22805216370986903, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.4839441104290726, margin=0.47948628055488735, lpl_weight=0.8800054181052948\n",
      " - ratio=0.1836585764782951, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.1685\n",
      "Epoch 50, Loss: 1.2286, LPL: 1.3863, Contrastive: 0.0721\n",
      "Epoch 100, Loss: 1.2284, LPL: 1.3863, Contrastive: 0.0708\n",
      "Epoch 150, Loss: 1.2285, LPL: 1.3863, Contrastive: 0.0710\n",
      " - Metrics: Accuracy=0.9276, F1=0.8769, Recall=0.8533, Precision=0.9018\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.22805216370986903, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.4839441104290726, margin=0.47948628055488735, lpl_weight=0.8800054181052948\n",
      " - ratio=0.1836585764782951, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.1685\n",
      "Epoch 50, Loss: 1.2286, LPL: 1.3863, Contrastive: 0.0721\n",
      "Epoch 100, Loss: 1.2284, LPL: 1.3863, Contrastive: 0.0708\n",
      "Epoch 150, Loss: 1.2285, LPL: 1.3863, Contrastive: 0.0710\n",
      " - Metrics: Accuracy=0.9313, F1=0.8829, Recall=0.8570, Precision=0.9104\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.22805216370986903, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.4839441104290726, margin=0.47948628055488735, lpl_weight=0.8800054181052948\n",
      " - ratio=0.1836585764782951, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.1685\n",
      "Epoch 50, Loss: 1.2286, LPL: 1.3863, Contrastive: 0.0721\n",
      "Epoch 100, Loss: 1.2284, LPL: 1.3863, Contrastive: 0.0708\n",
      "Epoch 150, Loss: 1.2285, LPL: 1.3863, Contrastive: 0.0710\n",
      " - Metrics: Accuracy=0.9365, F1=0.8926, Recall=0.8741, Precision=0.9120\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.22805216370986903, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.4839441104290726, margin=0.47948628055488735, lpl_weight=0.8800054181052948\n",
      " - ratio=0.1836585764782951, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2402, LPL: 1.3863, Contrastive: 0.1685\n",
      "Epoch 50, Loss: 1.2286, LPL: 1.3863, Contrastive: 0.0721\n",
      "Epoch 100, Loss: 1.2284, LPL: 1.3863, Contrastive: 0.0708\n",
      "Epoch 150, Loss: 1.2284, LPL: 1.3863, Contrastive: 0.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:36:22,172] Trial 76 finished with value: 0.8844431979702474 and parameters: {'alpha': 0.22805216370986903, 'K': 29, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.4839441104290726, 'margin': 0.47948628055488735, 'lpl_weight': 0.8800054181052948, 'ratio': 0.1836585764782951, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9372, F1=0.8943, Recall=0.8790, Precision=0.9101\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133515.csv.\n",
      "Average F1 over 5 seeds: 0.8844  0.0078\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10942944697786322, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.12365173447003913, margin=0.507882815125442, lpl_weight=0.9359845189511391\n",
      " - ratio=0.2235242000081948, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3055, LPL: 1.3863, Contrastive: 0.1242\n",
      "Epoch 50, Loss: 1.3016, LPL: 1.3863, Contrastive: 0.0628\n",
      "Epoch 100, Loss: 1.3015, LPL: 1.3863, Contrastive: 0.0621\n",
      " - Metrics: Accuracy=0.9332, F1=0.8894, Recall=0.8900, Precision=0.8889\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10942944697786322, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.12365173447003913, margin=0.507882815125442, lpl_weight=0.9359845189511391\n",
      " - ratio=0.2235242000081948, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3055, LPL: 1.3863, Contrastive: 0.1242\n",
      "Epoch 50, Loss: 1.3016, LPL: 1.3863, Contrastive: 0.0628\n",
      "Epoch 100, Loss: 1.3015, LPL: 1.3863, Contrastive: 0.0621\n",
      " - Metrics: Accuracy=0.9261, F1=0.8795, Recall=0.8924, Precision=0.8670\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10942944697786322, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.12365173447003913, margin=0.507882815125442, lpl_weight=0.9359845189511391\n",
      " - ratio=0.2235242000081948, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3055, LPL: 1.3863, Contrastive: 0.1242\n",
      "Epoch 50, Loss: 1.3016, LPL: 1.3863, Contrastive: 0.0628\n",
      "Epoch 100, Loss: 1.3015, LPL: 1.3863, Contrastive: 0.0621\n",
      " - Metrics: Accuracy=0.9372, F1=0.8972, Recall=0.9071, Precision=0.8876\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10942944697786322, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.12365173447003913, margin=0.507882815125442, lpl_weight=0.9359845189511391\n",
      " - ratio=0.2235242000081948, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3055, LPL: 1.3863, Contrastive: 0.1242\n",
      "Epoch 50, Loss: 1.3016, LPL: 1.3863, Contrastive: 0.0628\n",
      "Epoch 100, Loss: 1.3015, LPL: 1.3863, Contrastive: 0.0621\n",
      " - Metrics: Accuracy=0.9313, F1=0.8869, Recall=0.8912, Precision=0.8826\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10942944697786322, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.12365173447003913, margin=0.507882815125442, lpl_weight=0.9359845189511391\n",
      " - ratio=0.2235242000081948, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3055, LPL: 1.3863, Contrastive: 0.1242\n",
      "Epoch 50, Loss: 1.3016, LPL: 1.3863, Contrastive: 0.0628\n",
      "Epoch 100, Loss: 1.3015, LPL: 1.3863, Contrastive: 0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:37:37,842] Trial 77 finished with value: 0.8889192804357651 and parameters: {'alpha': 0.10942944697786322, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.12365173447003913, 'margin': 0.507882815125442, 'lpl_weight': 0.9359845189511391, 'ratio': 0.2235242000081948, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9335, F1=0.8916, Recall=0.9046, Precision=0.8789\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133622.csv.\n",
      "Average F1 over 5 seeds: 0.8889  0.0058\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5402412467659822, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4715777838979951, margin=0.44306661881303616, lpl_weight=0.6737508238684231\n",
      " - ratio=0.2526439168266633, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9941, LPL: 1.3863, Contrastive: 0.1842\n",
      "Epoch 50, Loss: 0.9610, LPL: 1.3863, Contrastive: 0.0828\n",
      "Epoch 100, Loss: 0.9602, LPL: 1.3863, Contrastive: 0.0802\n",
      " - Metrics: Accuracy=0.9295, F1=0.8868, Recall=0.9144, Precision=0.8608\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5402412467659822, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4715777838979951, margin=0.44306661881303616, lpl_weight=0.6737508238684231\n",
      " - ratio=0.2526439168266633, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9941, LPL: 1.3863, Contrastive: 0.1842\n",
      "Epoch 50, Loss: 0.9610, LPL: 1.3863, Contrastive: 0.0828\n",
      "Epoch 100, Loss: 0.9602, LPL: 1.3863, Contrastive: 0.0802\n",
      " - Metrics: Accuracy=0.9188, F1=0.8701, Recall=0.9010, Precision=0.8413\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5402412467659822, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4715777838979951, margin=0.44306661881303616, lpl_weight=0.6737508238684231\n",
      " - ratio=0.2526439168266633, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9941, LPL: 1.3863, Contrastive: 0.1842\n",
      "Epoch 50, Loss: 0.9610, LPL: 1.3863, Contrastive: 0.0828\n",
      "Epoch 100, Loss: 0.9602, LPL: 1.3863, Contrastive: 0.0802\n",
      " - Metrics: Accuracy=0.9339, F1=0.8924, Recall=0.9071, Precision=0.8781\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5402412467659822, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4715777838979951, margin=0.44306661881303616, lpl_weight=0.6737508238684231\n",
      " - ratio=0.2526439168266633, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9941, LPL: 1.3863, Contrastive: 0.1842\n",
      "Epoch 50, Loss: 0.9610, LPL: 1.3863, Contrastive: 0.0828\n",
      "Epoch 100, Loss: 0.9602, LPL: 1.3863, Contrastive: 0.0802\n",
      " - Metrics: Accuracy=0.9291, F1=0.8857, Recall=0.9095, Precision=0.8631\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5402412467659822, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4715777838979951, margin=0.44306661881303616, lpl_weight=0.6737508238684231\n",
      " - ratio=0.2526439168266633, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9941, LPL: 1.3863, Contrastive: 0.1842\n",
      "Epoch 50, Loss: 0.9610, LPL: 1.3863, Contrastive: 0.0828\n",
      "Epoch 100, Loss: 0.9602, LPL: 1.3863, Contrastive: 0.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:38:52,649] Trial 78 finished with value: 0.884565611340005 and parameters: {'alpha': 0.5402412467659822, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4715777838979951, 'margin': 0.44306661881303616, 'lpl_weight': 0.6737508238684231, 'ratio': 0.2526439168266633, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9298, F1=0.8878, Recall=0.9193, Precision=0.8584\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133737.csv.\n",
      "Average F1 over 5 seeds: 0.8846  0.0076\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6882091260854869, K=30, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.2732676011405795, margin=0.5551917324945856, lpl_weight=0.904682128402215\n",
      " - ratio=0.13676092101512663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2705, LPL: 1.3863, Contrastive: 0.1711\n",
      " - Metrics: Accuracy=0.9328, F1=0.8796, Recall=0.8130, Precision=0.9582\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6882091260854869, K=30, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.2732676011405795, margin=0.5551917324945856, lpl_weight=0.904682128402215\n",
      " - ratio=0.13676092101512663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2705, LPL: 1.3863, Contrastive: 0.1711\n",
      " - Metrics: Accuracy=0.9317, F1=0.8779, Recall=0.8130, Precision=0.9541\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6882091260854869, K=30, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.2732676011405795, margin=0.5551917324945856, lpl_weight=0.904682128402215\n",
      " - ratio=0.13676092101512663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2705, LPL: 1.3863, Contrastive: 0.1711\n",
      " - Metrics: Accuracy=0.9295, F1=0.8733, Recall=0.8044, Precision=0.9550\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6882091260854869, K=30, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.2732676011405795, margin=0.5551917324945856, lpl_weight=0.904682128402215\n",
      " - ratio=0.13676092101512663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2705, LPL: 1.3863, Contrastive: 0.1711\n",
      " - Metrics: Accuracy=0.9313, F1=0.8770, Recall=0.8105, Precision=0.9553\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6882091260854869, K=30, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.2732676011405795, margin=0.5551917324945856, lpl_weight=0.904682128402215\n",
      " - ratio=0.13676092101512663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2705, LPL: 1.3863, Contrastive: 0.1711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:39:21,173] Trial 79 finished with value: 0.8778453205486842 and parameters: {'alpha': 0.6882091260854869, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.2732676011405795, 'margin': 0.5551917324945856, 'lpl_weight': 0.904682128402215, 'ratio': 0.13676092101512663, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9332, F1=0.8815, Recall=0.8227, Precision=0.9492\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133852.csv.\n",
      "Average F1 over 5 seeds: 0.8778  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5966408584331182, K=29, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24714751027348314, margin=0.40731391764951214, lpl_weight=0.8444343398872711\n",
      " - ratio=0.21032028331019403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1920, LPL: 1.3863, Contrastive: 0.1371\n",
      "Epoch 50, Loss: 1.1848, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 100, Loss: 1.1846, LPL: 1.3863, Contrastive: 0.0898\n",
      " - Metrics: Accuracy=0.9169, F1=0.8685, Recall=0.9083, Precision=0.8320\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5966408584331182, K=29, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24714751027348314, margin=0.40731391764951214, lpl_weight=0.8444343398872711\n",
      " - ratio=0.21032028331019403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1920, LPL: 1.3863, Contrastive: 0.1371\n",
      "Epoch 50, Loss: 1.1848, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 100, Loss: 1.1846, LPL: 1.3863, Contrastive: 0.0898\n",
      " - Metrics: Accuracy=0.9177, F1=0.8697, Recall=0.9095, Precision=0.8331\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5966408584331182, K=29, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24714751027348314, margin=0.40731391764951214, lpl_weight=0.8444343398872711\n",
      " - ratio=0.21032028331019403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1920, LPL: 1.3863, Contrastive: 0.1371\n",
      "Epoch 50, Loss: 1.1848, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 100, Loss: 1.1846, LPL: 1.3863, Contrastive: 0.0898\n",
      " - Metrics: Accuracy=0.9206, F1=0.8743, Recall=0.9144, Precision=0.8376\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5966408584331182, K=29, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24714751027348314, margin=0.40731391764951214, lpl_weight=0.8444343398872711\n",
      " - ratio=0.21032028331019403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1920, LPL: 1.3863, Contrastive: 0.1371\n",
      "Epoch 50, Loss: 1.1848, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 100, Loss: 1.1846, LPL: 1.3863, Contrastive: 0.0898\n",
      " - Metrics: Accuracy=0.9110, F1=0.8591, Recall=0.8985, Precision=0.8231\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5966408584331182, K=29, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24714751027348314, margin=0.40731391764951214, lpl_weight=0.8444343398872711\n",
      " - ratio=0.21032028331019403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1920, LPL: 1.3863, Contrastive: 0.1371\n",
      "Epoch 50, Loss: 1.1848, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 100, Loss: 1.1846, LPL: 1.3863, Contrastive: 0.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:40:30,170] Trial 80 finished with value: 0.867562828755114 and parameters: {'alpha': 0.5966408584331182, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.24714751027348314, 'margin': 0.40731391764951214, 'lpl_weight': 0.8444343398872711, 'ratio': 0.21032028331019403, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9154, F1=0.8662, Recall=0.9059, Precision=0.8298\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102133921.csv.\n",
      "Average F1 over 5 seeds: 0.8676  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6542624796240574, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4188125370678939, margin=0.4105745199863263, lpl_weight=0.8931405364933357\n",
      " - ratio=0.20489728686124284, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2559, LPL: 1.3863, Contrastive: 0.1662\n",
      " - Metrics: Accuracy=0.9394, F1=0.8985, Recall=0.8875, Precision=0.9098\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6542624796240574, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4188125370678939, margin=0.4105745199863263, lpl_weight=0.8931405364933357\n",
      " - ratio=0.20489728686124284, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2559, LPL: 1.3863, Contrastive: 0.1662\n",
      " - Metrics: Accuracy=0.9361, F1=0.8935, Recall=0.8875, Precision=0.8996\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6542624796240574, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4188125370678939, margin=0.4105745199863263, lpl_weight=0.8931405364933357\n",
      " - ratio=0.20489728686124284, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2559, LPL: 1.3863, Contrastive: 0.1662\n",
      " - Metrics: Accuracy=0.9383, F1=0.8974, Recall=0.8924, Precision=0.9023\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6542624796240574, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4188125370678939, margin=0.4105745199863263, lpl_weight=0.8931405364933357\n",
      " - ratio=0.20489728686124284, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2559, LPL: 1.3863, Contrastive: 0.1662\n",
      " - Metrics: Accuracy=0.9324, F1=0.8868, Recall=0.8765, Precision=0.8974\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6542624796240574, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4188125370678939, margin=0.4105745199863263, lpl_weight=0.8931405364933357\n",
      " - ratio=0.20489728686124284, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2559, LPL: 1.3863, Contrastive: 0.1662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:41:00,636] Trial 81 finished with value: 0.8964899613794758 and parameters: {'alpha': 0.6542624796240574, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.4188125370678939, 'margin': 0.4105745199863263, 'lpl_weight': 0.8931405364933357, 'ratio': 0.20489728686124284, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9431, F1=0.9062, Recall=0.9095, Precision=0.9029\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134030.csv.\n",
      "Average F1 over 5 seeds: 0.8965  0.0063\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7894853672683408, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.43639403414281674, margin=0.34727705147329824, lpl_weight=0.9450906774558485\n",
      " - ratio=0.23193629007193417, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3197, LPL: 1.3863, Contrastive: 0.1742\n",
      "Epoch 50, Loss: 1.3163, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 100, Loss: 1.3162, LPL: 1.3863, Contrastive: 0.1102\n",
      " - Metrics: Accuracy=0.9335, F1=0.8905, Recall=0.8949, Precision=0.8862\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7894853672683408, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.43639403414281674, margin=0.34727705147329824, lpl_weight=0.9450906774558485\n",
      " - ratio=0.23193629007193417, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3197, LPL: 1.3863, Contrastive: 0.1742\n",
      "Epoch 50, Loss: 1.3163, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 100, Loss: 1.3162, LPL: 1.3863, Contrastive: 0.1101\n",
      " - Metrics: Accuracy=0.9239, F1=0.8745, Recall=0.8778, Precision=0.8714\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7894853672683408, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.43639403414281674, margin=0.34727705147329824, lpl_weight=0.9450906774558485\n",
      " - ratio=0.23193629007193417, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3197, LPL: 1.3863, Contrastive: 0.1742\n",
      "Epoch 50, Loss: 1.3163, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 100, Loss: 1.3162, LPL: 1.3863, Contrastive: 0.1102\n",
      " - Metrics: Accuracy=0.9354, F1=0.8940, Recall=0.9022, Precision=0.8860\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7894853672683408, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.43639403414281674, margin=0.34727705147329824, lpl_weight=0.9450906774558485\n",
      " - ratio=0.23193629007193417, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3197, LPL: 1.3863, Contrastive: 0.1742\n",
      "Epoch 50, Loss: 1.3163, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 100, Loss: 1.3162, LPL: 1.3863, Contrastive: 0.1102\n",
      " - Metrics: Accuracy=0.9317, F1=0.8871, Recall=0.8888, Precision=0.8855\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7894853672683408, K=30, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.43639403414281674, margin=0.34727705147329824, lpl_weight=0.9450906774558485\n",
      " - ratio=0.23193629007193417, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3197, LPL: 1.3863, Contrastive: 0.1742\n",
      "Epoch 50, Loss: 1.3163, LPL: 1.3863, Contrastive: 0.1111\n",
      "Epoch 100, Loss: 1.3162, LPL: 1.3863, Contrastive: 0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:42:01,657] Trial 82 finished with value: 0.8872588019299326 and parameters: {'alpha': 0.7894853672683408, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.43639403414281674, 'margin': 0.34727705147329824, 'lpl_weight': 0.9450906774558485, 'ratio': 0.23193629007193417, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9335, F1=0.8901, Recall=0.8912, Precision=0.8890\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134100.csv.\n",
      "Average F1 over 5 seeds: 0.8873  0.0067\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.18401951139957937, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41550900419953873, margin=0.48109084773115807, lpl_weight=0.8771110759073052\n",
      " - ratio=0.2210094688308736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2359, LPL: 1.3863, Contrastive: 0.1626\n",
      " - Metrics: Accuracy=0.9387, F1=0.8984, Recall=0.8973, Precision=0.8995\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.18401951139957937, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41550900419953873, margin=0.48109084773115807, lpl_weight=0.8771110759073052\n",
      " - ratio=0.2210094688308736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2359, LPL: 1.3863, Contrastive: 0.1626\n",
      " - Metrics: Accuracy=0.9365, F1=0.8952, Recall=0.8985, Precision=0.8920\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.18401951139957937, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41550900419953873, margin=0.48109084773115807, lpl_weight=0.8771110759073052\n",
      " - ratio=0.2210094688308736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2359, LPL: 1.3863, Contrastive: 0.1626\n",
      " - Metrics: Accuracy=0.9343, F1=0.8917, Recall=0.8961, Precision=0.8874\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.18401951139957937, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41550900419953873, margin=0.48109084773115807, lpl_weight=0.8771110759073052\n",
      " - ratio=0.2210094688308736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2359, LPL: 1.3863, Contrastive: 0.1626\n",
      " - Metrics: Accuracy=0.9280, F1=0.8817, Recall=0.8888, Precision=0.8748\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.18401951139957937, K=31, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.41550900419953873, margin=0.48109084773115807, lpl_weight=0.8771110759073052\n",
      " - ratio=0.2210094688308736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2359, LPL: 1.3863, Contrastive: 0.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:42:32,576] Trial 83 finished with value: 0.8934985318471803 and parameters: {'alpha': 0.18401951139957937, 'K': 31, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.41550900419953873, 'margin': 0.48109084773115807, 'lpl_weight': 0.8771110759073052, 'ratio': 0.2210094688308736, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9387, F1=0.9004, Recall=0.9169, Precision=0.8844\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134201.csv.\n",
      "Average F1 over 5 seeds: 0.8935  0.0066\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7273354515365295, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3843692176268259, margin=0.5295413521383535, lpl_weight=0.9818942862881315\n",
      " - ratio=0.15873145232231534, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3640, LPL: 1.3863, Contrastive: 0.1525\n",
      " - Metrics: Accuracy=0.9383, F1=0.8926, Recall=0.8484, Precision=0.9417\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7273354515365295, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3843692176268259, margin=0.5295413521383535, lpl_weight=0.9818942862881315\n",
      " - ratio=0.15873145232231534, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3640, LPL: 1.3863, Contrastive: 0.1525\n",
      " - Metrics: Accuracy=0.9343, F1=0.8856, Recall=0.8423, Precision=0.9336\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7273354515365295, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3843692176268259, margin=0.5295413521383535, lpl_weight=0.9818942862881315\n",
      " - ratio=0.15873145232231534, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3640, LPL: 1.3863, Contrastive: 0.1525\n",
      " - Metrics: Accuracy=0.9398, F1=0.8942, Recall=0.8423, Precision=0.9530\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7273354515365295, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3843692176268259, margin=0.5295413521383535, lpl_weight=0.9818942862881315\n",
      " - ratio=0.15873145232231534, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3640, LPL: 1.3863, Contrastive: 0.1525\n",
      " - Metrics: Accuracy=0.9380, F1=0.8918, Recall=0.8460, Precision=0.9428\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7273354515365295, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3843692176268259, margin=0.5295413521383535, lpl_weight=0.9818942862881315\n",
      " - ratio=0.15873145232231534, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3640, LPL: 1.3863, Contrastive: 0.1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:43:02,111] Trial 84 finished with value: 0.8934657523949292 and parameters: {'alpha': 0.7273354515365295, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3843692176268259, 'margin': 0.5295413521383535, 'lpl_weight': 0.9818942862881315, 'ratio': 0.15873145232231534, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9442, F1=0.9031, Recall=0.8606, Precision=0.9501\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134232.csv.\n",
      "Average F1 over 5 seeds: 0.8935  0.0057\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.658022570816809, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.396440413620782, margin=0.3767080754829331, lpl_weight=0.9274391403568683\n",
      " - ratio=0.17528815569175746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2981, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.2930, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 1.2929, LPL: 1.3863, Contrastive: 0.0994\n",
      " - Metrics: Accuracy=0.9357, F1=0.8899, Recall=0.8594, Precision=0.9226\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.658022570816809, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.396440413620782, margin=0.3767080754829331, lpl_weight=0.9274391403568683\n",
      " - ratio=0.17528815569175746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2981, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.2930, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 1.2929, LPL: 1.3863, Contrastive: 0.0994\n",
      " - Metrics: Accuracy=0.9243, F1=0.8695, Recall=0.8350, Precision=0.9070\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.658022570816809, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.396440413620782, margin=0.3767080754829331, lpl_weight=0.9274391403568683\n",
      " - ratio=0.17528815569175746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2981, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.2930, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 1.2929, LPL: 1.3863, Contrastive: 0.0994\n",
      " - Metrics: Accuracy=0.9357, F1=0.8906, Recall=0.8655, Precision=0.9171\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.658022570816809, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.396440413620782, margin=0.3767080754829331, lpl_weight=0.9274391403568683\n",
      " - ratio=0.17528815569175746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2981, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.2930, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 1.2929, LPL: 1.3863, Contrastive: 0.0994\n",
      " - Metrics: Accuracy=0.9258, F1=0.8730, Recall=0.8447, Precision=0.9033\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.658022570816809, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.396440413620782, margin=0.3767080754829331, lpl_weight=0.9274391403568683\n",
      " - ratio=0.17528815569175746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2981, LPL: 1.3863, Contrastive: 0.1714\n",
      "Epoch 50, Loss: 1.2930, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 1.2929, LPL: 1.3863, Contrastive: 0.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:44:09,983] Trial 85 finished with value: 0.8809391304163178 and parameters: {'alpha': 0.658022570816809, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.396440413620782, 'margin': 0.3767080754829331, 'lpl_weight': 0.9274391403568683, 'ratio': 0.17528815569175746, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9309, F1=0.8817, Recall=0.8521, Precision=0.9135\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134302.csv.\n",
      "Average F1 over 5 seeds: 0.8809  0.0086\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.15739925567417457, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.36568637996562414, margin=0.4497783343661528, lpl_weight=0.9992228352484344\n",
      " - ratio=0.18664101958322057, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3853, LPL: 1.3863, Contrastive: 0.1516\n",
      " - Metrics: Accuracy=0.9369, F1=0.8921, Recall=0.8643, Precision=0.9218\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.15739925567417457, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.36568637996562414, margin=0.4497783343661528, lpl_weight=0.9992228352484344\n",
      " - ratio=0.18664101958322057, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3853, LPL: 1.3863, Contrastive: 0.1516\n",
      " - Metrics: Accuracy=0.9335, F1=0.8876, Recall=0.8692, Precision=0.9069\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.15739925567417457, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.36568637996562414, margin=0.4497783343661528, lpl_weight=0.9992228352484344\n",
      " - ratio=0.18664101958322057, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3853, LPL: 1.3863, Contrastive: 0.1516\n",
      " - Metrics: Accuracy=0.9409, F1=0.8995, Recall=0.8753, Precision=0.9251\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.15739925567417457, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.36568637996562414, margin=0.4497783343661528, lpl_weight=0.9992228352484344\n",
      " - ratio=0.18664101958322057, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3853, LPL: 1.3863, Contrastive: 0.1516\n",
      " - Metrics: Accuracy=0.9398, F1=0.8972, Recall=0.8692, Precision=0.9270\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.15739925567417457, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.36568637996562414, margin=0.4497783343661528, lpl_weight=0.9992228352484344\n",
      " - ratio=0.18664101958322057, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3853, LPL: 1.3863, Contrastive: 0.1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:44:40,723] Trial 86 finished with value: 0.8972139411394379 and parameters: {'alpha': 0.15739925567417457, 'K': 27, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.36568637996562414, 'margin': 0.4497783343661528, 'lpl_weight': 0.9992228352484344, 'ratio': 0.18664101958322057, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9465, F1=0.9097, Recall=0.8924, Precision=0.9276\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134410.csv.\n",
      "Average F1 over 5 seeds: 0.8972  0.0075\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7001084607548261, K=26, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3365593766766525, margin=0.274385884451391, lpl_weight=0.9996320766149079\n",
      " - ratio=0.20262757824627073, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 50, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1337\n",
      " - Metrics: Accuracy=0.8996, F1=0.8172, Recall=0.7433, Precision=0.9075\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7001084607548261, K=26, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3365593766766525, margin=0.274385884451391, lpl_weight=0.9996320766149079\n",
      " - ratio=0.20262757824627073, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 50, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1337\n",
      " - Metrics: Accuracy=0.9077, F1=0.8322, Recall=0.7579, Precision=0.9226\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7001084607548261, K=26, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3365593766766525, margin=0.274385884451391, lpl_weight=0.9996320766149079\n",
      " - ratio=0.20262757824627073, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 50, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1337\n",
      " - Metrics: Accuracy=0.9069, F1=0.8302, Recall=0.7531, Precision=0.9249\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7001084607548261, K=26, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3365593766766525, margin=0.274385884451391, lpl_weight=0.9996320766149079\n",
      " - ratio=0.20262757824627073, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 50, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1337\n",
      " - Metrics: Accuracy=0.9066, F1=0.8310, Recall=0.7604, Precision=0.9161\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7001084607548261, K=26, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.3365593766766525, margin=0.274385884451391, lpl_weight=0.9996320766149079\n",
      " - ratio=0.20262757824627073, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1368\n",
      "Epoch 50, Loss: 1.3858, LPL: 1.3863, Contrastive: 0.1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:45:21,265] Trial 87 finished with value: 0.8294620443798291 and parameters: {'alpha': 0.7001084607548261, 'K': 26, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3365593766766525, 'margin': 0.274385884451391, 'lpl_weight': 0.9996320766149079, 'ratio': 0.20262757824627073, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9106, F1=0.8367, Recall=0.7579, Precision=0.9337\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134440.csv.\n",
      "Average F1 over 5 seeds: 0.8295  0.0065\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.581752928874506, K=27, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3479867395995856, margin=0.4637095119530624, lpl_weight=0.9533680204072149\n",
      " - ratio=0.29211154227191566, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.1425\n",
      "Epoch 50, Loss: 1.3252, LPL: 1.3863, Contrastive: 0.0758\n",
      "Epoch 100, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0746\n",
      "Epoch 150, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0739\n",
      "Epoch 200, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0740\n",
      "Epoch 250, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0734\n",
      "Epoch 300, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0731\n",
      "Epoch 350, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0730\n",
      " - Metrics: Accuracy=0.9239, F1=0.8750, Recall=0.8814, Precision=0.8687\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.581752928874506, K=27, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3479867395995856, margin=0.4637095119530624, lpl_weight=0.9533680204072149\n",
      " - ratio=0.29211154227191566, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.1425\n",
      "Epoch 50, Loss: 1.3252, LPL: 1.3863, Contrastive: 0.0758\n",
      "Epoch 100, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0746\n",
      "Epoch 150, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0740\n",
      " - Metrics: Accuracy=0.9247, F1=0.8803, Recall=0.9169, Precision=0.8465\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.581752928874506, K=27, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3479867395995856, margin=0.4637095119530624, lpl_weight=0.9533680204072149\n",
      " - ratio=0.29211154227191566, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.1425\n",
      "Epoch 50, Loss: 1.3252, LPL: 1.3863, Contrastive: 0.0758\n",
      "Epoch 100, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0747\n",
      "Epoch 150, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0739\n",
      " - Metrics: Accuracy=0.9261, F1=0.8821, Recall=0.9144, Precision=0.8519\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.581752928874506, K=27, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3479867395995856, margin=0.4637095119530624, lpl_weight=0.9533680204072149\n",
      " - ratio=0.29211154227191566, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.1425\n",
      "Epoch 50, Loss: 1.3252, LPL: 1.3863, Contrastive: 0.0758\n",
      "Epoch 100, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0746\n",
      "Epoch 150, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0739\n",
      " - Metrics: Accuracy=0.9236, F1=0.8758, Recall=0.8924, Precision=0.8598\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.581752928874506, K=27, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3479867395995856, margin=0.4637095119530624, lpl_weight=0.9533680204072149\n",
      " - ratio=0.29211154227191566, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3283, LPL: 1.3863, Contrastive: 0.1425\n",
      "Epoch 50, Loss: 1.3252, LPL: 1.3863, Contrastive: 0.0758\n",
      "Epoch 100, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0746\n",
      "Epoch 150, Loss: 1.3251, LPL: 1.3863, Contrastive: 0.0739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:46:40,899] Trial 88 finished with value: 0.8784841090709994 and parameters: {'alpha': 0.581752928874506, 'K': 27, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3479867395995856, 'margin': 0.4637095119530624, 'lpl_weight': 0.9533680204072149, 'ratio': 0.29211154227191566, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9250, F1=0.8792, Recall=0.9034, Precision=0.8563\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134521.csv.\n",
      "Average F1 over 5 seeds: 0.8785  0.0027\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2682727884573097, K=27, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.36643927154703804, margin=0.32171475733864496, lpl_weight=0.9121850512759676\n",
      " - ratio=0.18609604928224915, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2828, LPL: 1.3863, Contrastive: 0.2074\n",
      "Epoch 50, Loss: 1.2753, LPL: 1.3863, Contrastive: 0.1219\n",
      "Epoch 100, Loss: 1.2751, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 1.2750, LPL: 1.3863, Contrastive: 0.1193\n",
      "Epoch 200, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1179\n",
      "Epoch 250, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 300, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1171\n",
      "Epoch 350, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1170\n",
      "Epoch 400, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1168\n",
      " - Metrics: Accuracy=0.9110, F1=0.8399, Recall=0.7726, Precision=0.9199\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2682727884573097, K=27, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.36643927154703804, margin=0.32171475733864496, lpl_weight=0.9121850512759676\n",
      " - ratio=0.18609604928224915, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2828, LPL: 1.3863, Contrastive: 0.2074\n",
      "Epoch 50, Loss: 1.2753, LPL: 1.3863, Contrastive: 0.1219\n",
      "Epoch 100, Loss: 1.2751, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 1.2750, LPL: 1.3863, Contrastive: 0.1193\n",
      "Epoch 200, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1179\n",
      "Epoch 250, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 300, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1171\n",
      "Epoch 350, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1170\n",
      "Epoch 400, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1168\n",
      " - Metrics: Accuracy=0.9032, F1=0.8253, Recall=0.7567, Precision=0.9076\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2682727884573097, K=27, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.36643927154703804, margin=0.32171475733864496, lpl_weight=0.9121850512759676\n",
      " - ratio=0.18609604928224915, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2828, LPL: 1.3863, Contrastive: 0.2074\n",
      "Epoch 50, Loss: 1.2753, LPL: 1.3863, Contrastive: 0.1219\n",
      "Epoch 100, Loss: 1.2751, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 1.2750, LPL: 1.3863, Contrastive: 0.1193\n",
      "Epoch 200, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1179\n",
      "Epoch 250, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 300, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1171\n",
      "Epoch 350, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1170\n",
      "Epoch 400, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1168\n",
      " - Metrics: Accuracy=0.9239, F1=0.8657, Recall=0.8117, Precision=0.9274\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2682727884573097, K=27, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.36643927154703804, margin=0.32171475733864496, lpl_weight=0.9121850512759676\n",
      " - ratio=0.18609604928224915, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2828, LPL: 1.3863, Contrastive: 0.2074\n",
      "Epoch 50, Loss: 1.2753, LPL: 1.3863, Contrastive: 0.1219\n",
      "Epoch 100, Loss: 1.2751, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 1.2750, LPL: 1.3863, Contrastive: 0.1193\n",
      "Epoch 200, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1179\n",
      "Epoch 250, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 300, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1171\n",
      "Epoch 350, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1170\n",
      "Epoch 400, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1168\n",
      " - Metrics: Accuracy=0.9073, F1=0.8332, Recall=0.7665, Precision=0.9127\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2682727884573097, K=27, layers=1, hidden=64, out=128\n",
      " - norm=None, dropout=0.36643927154703804, margin=0.32171475733864496, lpl_weight=0.9121850512759676\n",
      " - ratio=0.18609604928224915, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2828, LPL: 1.3863, Contrastive: 0.2074\n",
      "Epoch 50, Loss: 1.2753, LPL: 1.3863, Contrastive: 0.1219\n",
      "Epoch 100, Loss: 1.2751, LPL: 1.3863, Contrastive: 0.1196\n",
      "Epoch 150, Loss: 1.2750, LPL: 1.3863, Contrastive: 0.1193\n",
      "Epoch 200, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1179\n",
      "Epoch 250, Loss: 1.2749, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 300, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1171\n",
      "Epoch 350, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1170\n",
      "Epoch 400, Loss: 1.2748, LPL: 1.3863, Contrastive: 0.1168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:48:38,008] Trial 89 finished with value: 0.8450780278916887 and parameters: {'alpha': 0.2682727884573097, 'K': 27, 'layers': 1, 'hidden_channels': 64, 'out_channels': 128, 'norm': None, 'dropout': 0.36643927154703804, 'margin': 0.32171475733864496, 'lpl_weight': 0.9121850512759676, 'ratio': 0.18609604928224915, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9217, F1=0.8613, Recall=0.8044, Precision=0.9268\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134641.csv.\n",
      "Average F1 over 5 seeds: 0.8451  0.0158\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8388442777066256, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4512801762549088, margin=0.4308979768148032, lpl_weight=0.9730829705639894\n",
      " - ratio=0.391347787026856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3536, LPL: 1.3863, Contrastive: 0.1708\n",
      " - Metrics: Accuracy=0.9040, F1=0.8554, Recall=0.9401, Precision=0.7847\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8388442777066256, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4512801762549088, margin=0.4308979768148032, lpl_weight=0.9730829705639894\n",
      " - ratio=0.391347787026856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3536, LPL: 1.3863, Contrastive: 0.1708\n",
      " - Metrics: Accuracy=0.8977, F1=0.8467, Recall=0.9352, Precision=0.7735\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8388442777066256, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4512801762549088, margin=0.4308979768148032, lpl_weight=0.9730829705639894\n",
      " - ratio=0.391347787026856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3536, LPL: 1.3863, Contrastive: 0.1708\n",
      " - Metrics: Accuracy=0.9029, F1=0.8543, Recall=0.9425, Precision=0.7812\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8388442777066256, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4512801762549088, margin=0.4308979768148032, lpl_weight=0.9730829705639894\n",
      " - ratio=0.391347787026856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3536, LPL: 1.3863, Contrastive: 0.1708\n",
      " - Metrics: Accuracy=0.8929, F1=0.8410, Recall=0.9377, Precision=0.7624\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8388442777066256, K=27, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4512801762549088, margin=0.4308979768148032, lpl_weight=0.9730829705639894\n",
      " - ratio=0.391347787026856, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3536, LPL: 1.3863, Contrastive: 0.1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:49:06,490] Trial 90 finished with value: 0.8507503944559959 and parameters: {'alpha': 0.8388442777066256, 'K': 27, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.4512801762549088, 'margin': 0.4308979768148032, 'lpl_weight': 0.9730829705639894, 'ratio': 0.391347787026856, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9047, F1=0.8563, Recall=0.9401, Precision=0.7863\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134838.csv.\n",
      "Average F1 over 5 seeds: 0.8508  0.0059\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.16285259371847238, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4226581276208759, margin=0.5040865143268517, lpl_weight=0.9481383866343234\n",
      " - ratio=0.21758558865830993, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3229, LPL: 1.3863, Contrastive: 0.1631\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0653\n",
      "Epoch 100, Loss: 1.3177, LPL: 1.3863, Contrastive: 0.0636\n",
      " - Metrics: Accuracy=0.9369, F1=0.8952, Recall=0.8924, Precision=0.8979\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.16285259371847238, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4226581276208759, margin=0.5040865143268517, lpl_weight=0.9481383866343234\n",
      " - ratio=0.21758558865830993, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3229, LPL: 1.3863, Contrastive: 0.1631\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0653\n",
      "Epoch 100, Loss: 1.3177, LPL: 1.3863, Contrastive: 0.0636\n",
      "Epoch 150, Loss: 1.3177, LPL: 1.3863, Contrastive: 0.0636\n",
      "Epoch 200, Loss: 1.3177, LPL: 1.3863, Contrastive: 0.0630\n",
      "Epoch 250, Loss: 1.3177, LPL: 1.3863, Contrastive: 0.0628\n",
      " - Metrics: Accuracy=0.9269, F1=0.8787, Recall=0.8765, Precision=0.8808\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.16285259371847238, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4226581276208759, margin=0.5040865143268517, lpl_weight=0.9481383866343234\n",
      " - ratio=0.21758558865830993, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3229, LPL: 1.3863, Contrastive: 0.1631\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0653\n",
      "Epoch 100, Loss: 1.3177, LPL: 1.3863, Contrastive: 0.0636\n",
      " - Metrics: Accuracy=0.9354, F1=0.8931, Recall=0.8936, Precision=0.8926\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.16285259371847238, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4226581276208759, margin=0.5040865143268517, lpl_weight=0.9481383866343234\n",
      " - ratio=0.21758558865830993, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3229, LPL: 1.3863, Contrastive: 0.1631\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0653\n",
      "Epoch 100, Loss: 1.3177, LPL: 1.3863, Contrastive: 0.0636\n",
      " - Metrics: Accuracy=0.9354, F1=0.8927, Recall=0.8900, Precision=0.8954\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.16285259371847238, K=28, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4226581276208759, margin=0.5040865143268517, lpl_weight=0.9481383866343234\n",
      " - ratio=0.21758558865830993, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3229, LPL: 1.3863, Contrastive: 0.1631\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0653\n",
      "Epoch 100, Loss: 1.3177, LPL: 1.3863, Contrastive: 0.0636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:50:23,301] Trial 91 finished with value: 0.8904031823867895 and parameters: {'alpha': 0.16285259371847238, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.4226581276208759, 'margin': 0.5040865143268517, 'lpl_weight': 0.9481383866343234, 'ratio': 0.21758558865830993, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9343, F1=0.8924, Recall=0.9022, Precision=0.8828\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102134906.csv.\n",
      "Average F1 over 5 seeds: 0.8904  0.0059\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.21918901779138564, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3258675941085952, margin=0.48623425035836226, lpl_weight=0.8588367547573331\n",
      " - ratio=0.1946224341790465, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2121, LPL: 1.3863, Contrastive: 0.1525\n",
      "Epoch 50, Loss: 1.2003, LPL: 1.3863, Contrastive: 0.0688\n",
      "Epoch 100, Loss: 1.2002, LPL: 1.3863, Contrastive: 0.0677\n",
      " - Metrics: Accuracy=0.9343, F1=0.8888, Recall=0.8692, Precision=0.9092\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.21918901779138564, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3258675941085952, margin=0.48623425035836226, lpl_weight=0.8588367547573331\n",
      " - ratio=0.1946224341790465, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2121, LPL: 1.3863, Contrastive: 0.1525\n",
      "Epoch 50, Loss: 1.2003, LPL: 1.3863, Contrastive: 0.0688\n",
      "Epoch 100, Loss: 1.2002, LPL: 1.3863, Contrastive: 0.0677\n",
      " - Metrics: Accuracy=0.9380, F1=0.8951, Recall=0.8765, Precision=0.9145\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.21918901779138564, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3258675941085952, margin=0.48623425035836226, lpl_weight=0.8588367547573331\n",
      " - ratio=0.1946224341790465, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2121, LPL: 1.3863, Contrastive: 0.1525\n",
      "Epoch 50, Loss: 1.2003, LPL: 1.3863, Contrastive: 0.0688\n",
      "Epoch 100, Loss: 1.2002, LPL: 1.3863, Contrastive: 0.0677\n",
      " - Metrics: Accuracy=0.9435, F1=0.9046, Recall=0.8863, Precision=0.9236\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.21918901779138564, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3258675941085952, margin=0.48623425035836226, lpl_weight=0.8588367547573331\n",
      " - ratio=0.1946224341790465, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2121, LPL: 1.3863, Contrastive: 0.1525\n",
      "Epoch 50, Loss: 1.2003, LPL: 1.3863, Contrastive: 0.0688\n",
      "Epoch 100, Loss: 1.2002, LPL: 1.3863, Contrastive: 0.0677\n",
      " - Metrics: Accuracy=0.9350, F1=0.8899, Recall=0.8692, Precision=0.9115\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.21918901779138564, K=30, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3258675941085952, margin=0.48623425035836226, lpl_weight=0.8588367547573331\n",
      " - ratio=0.1946224341790465, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2121, LPL: 1.3863, Contrastive: 0.1525\n",
      "Epoch 50, Loss: 1.2003, LPL: 1.3863, Contrastive: 0.0688\n",
      "Epoch 100, Loss: 1.2002, LPL: 1.3863, Contrastive: 0.0677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:51:35,904] Trial 92 finished with value: 0.8933822473521736 and parameters: {'alpha': 0.21918901779138564, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3258675941085952, 'margin': 0.48623425035836226, 'lpl_weight': 0.8588367547573331, 'ratio': 0.1946224341790465, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9335, F1=0.8886, Recall=0.8778, Precision=0.8997\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102135023.csv.\n",
      "Average F1 over 5 seeds: 0.8934  0.0061\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.14697863298239333, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.40706354635409614, margin=0.3893052096379285, lpl_weight=0.9227355600530669\n",
      " - ratio=0.24028196807057242, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2919, LPL: 1.3863, Contrastive: 0.1643\n",
      "Epoch 50, Loss: 1.2867, LPL: 1.3863, Contrastive: 0.0974\n",
      "Epoch 100, Loss: 1.2866, LPL: 1.3863, Contrastive: 0.0958\n",
      " - Metrics: Accuracy=0.9332, F1=0.8904, Recall=0.8985, Precision=0.8824\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.14697863298239333, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.40706354635409614, margin=0.3893052096379285, lpl_weight=0.9227355600530669\n",
      " - ratio=0.24028196807057242, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2919, LPL: 1.3863, Contrastive: 0.1643\n",
      "Epoch 50, Loss: 1.2867, LPL: 1.3863, Contrastive: 0.0974\n",
      "Epoch 100, Loss: 1.2866, LPL: 1.3863, Contrastive: 0.0958\n",
      " - Metrics: Accuracy=0.9239, F1=0.8759, Recall=0.8888, Precision=0.8634\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.14697863298239333, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.40706354635409614, margin=0.3893052096379285, lpl_weight=0.9227355600530669\n",
      " - ratio=0.24028196807057242, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2919, LPL: 1.3863, Contrastive: 0.1643\n",
      "Epoch 50, Loss: 1.2867, LPL: 1.3863, Contrastive: 0.0974\n",
      "Epoch 100, Loss: 1.2866, LPL: 1.3863, Contrastive: 0.0958\n",
      " - Metrics: Accuracy=0.9339, F1=0.8922, Recall=0.9059, Precision=0.8790\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.14697863298239333, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.40706354635409614, margin=0.3893052096379285, lpl_weight=0.9227355600530669\n",
      " - ratio=0.24028196807057242, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2919, LPL: 1.3863, Contrastive: 0.1643\n",
      "Epoch 50, Loss: 1.2867, LPL: 1.3863, Contrastive: 0.0974\n",
      "Epoch 100, Loss: 1.2866, LPL: 1.3863, Contrastive: 0.0958\n",
      " - Metrics: Accuracy=0.9298, F1=0.8854, Recall=0.8973, Precision=0.8738\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.14697863298239333, K=29, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.40706354635409614, margin=0.3893052096379285, lpl_weight=0.9227355600530669\n",
      " - ratio=0.24028196807057242, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2919, LPL: 1.3863, Contrastive: 0.1643\n",
      "Epoch 50, Loss: 1.2867, LPL: 1.3863, Contrastive: 0.0974\n",
      "Epoch 100, Loss: 1.2866, LPL: 1.3863, Contrastive: 0.0958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:52:40,036] Trial 93 finished with value: 0.8879513318060092 and parameters: {'alpha': 0.14697863298239333, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.40706354635409614, 'margin': 0.3893052096379285, 'lpl_weight': 0.9227355600530669, 'ratio': 0.24028196807057242, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9361, F1=0.8958, Recall=0.9095, Precision=0.8826\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102135135.csv.\n",
      "Average F1 over 5 seeds: 0.8880  0.0069\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6188206904178665, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.372757636381603, margin=0.449341255428348, lpl_weight=0.8913809103416827\n",
      " - ratio=0.14517724510545504, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2533, LPL: 1.3863, Contrastive: 0.1622\n",
      "Epoch 50, Loss: 1.2443, LPL: 1.3863, Contrastive: 0.0791\n",
      "Epoch 100, Loss: 1.2442, LPL: 1.3863, Contrastive: 0.0777\n",
      " - Metrics: Accuracy=0.9328, F1=0.8818, Recall=0.8301, Precision=0.9404\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6188206904178665, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.372757636381603, margin=0.449341255428348, lpl_weight=0.8913809103416827\n",
      " - ratio=0.14517724510545504, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2533, LPL: 1.3863, Contrastive: 0.1622\n",
      "Epoch 50, Loss: 1.2443, LPL: 1.3863, Contrastive: 0.0791\n",
      "Epoch 100, Loss: 1.2442, LPL: 1.3863, Contrastive: 0.0777\n",
      " - Metrics: Accuracy=0.9261, F1=0.8681, Recall=0.8044, Precision=0.9427\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6188206904178665, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.372757636381603, margin=0.449341255428348, lpl_weight=0.8913809103416827\n",
      " - ratio=0.14517724510545504, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2533, LPL: 1.3863, Contrastive: 0.1622\n",
      "Epoch 50, Loss: 1.2443, LPL: 1.3863, Contrastive: 0.0791\n",
      "Epoch 100, Loss: 1.2442, LPL: 1.3863, Contrastive: 0.0777\n",
      " - Metrics: Accuracy=0.9328, F1=0.8812, Recall=0.8252, Precision=0.9454\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6188206904178665, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.372757636381603, margin=0.449341255428348, lpl_weight=0.8913809103416827\n",
      " - ratio=0.14517724510545504, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2533, LPL: 1.3863, Contrastive: 0.1622\n",
      "Epoch 50, Loss: 1.2443, LPL: 1.3863, Contrastive: 0.0791\n",
      "Epoch 100, Loss: 1.2442, LPL: 1.3863, Contrastive: 0.0777\n",
      " - Metrics: Accuracy=0.9298, F1=0.8750, Recall=0.8130, Precision=0.9473\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6188206904178665, K=28, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.372757636381603, margin=0.449341255428348, lpl_weight=0.8913809103416827\n",
      " - ratio=0.14517724510545504, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2533, LPL: 1.3863, Contrastive: 0.1622\n",
      "Epoch 50, Loss: 1.2443, LPL: 1.3863, Contrastive: 0.0791\n",
      "Epoch 100, Loss: 1.2442, LPL: 1.3863, Contrastive: 0.0777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:53:53,034] Trial 94 finished with value: 0.8771457517407502 and parameters: {'alpha': 0.6188206904178665, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.372757636381603, 'margin': 0.449341255428348, 'lpl_weight': 0.8913809103416827, 'ratio': 0.14517724510545504, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9317, F1=0.8796, Recall=0.8264, Precision=0.9402\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102135240.csv.\n",
      "Average F1 over 5 seeds: 0.8771  0.0051\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.19910753880213056, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4654258834059383, margin=0.41216211810842746, lpl_weight=0.9821698449548686\n",
      " - ratio=0.17308823830407594, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3647, LPL: 1.3863, Contrastive: 0.1757\n",
      " - Metrics: Accuracy=0.9387, F1=0.8945, Recall=0.8606, Precision=0.9312\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.19910753880213056, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4654258834059383, margin=0.41216211810842746, lpl_weight=0.9821698449548686\n",
      " - ratio=0.17308823830407594, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3647, LPL: 1.3863, Contrastive: 0.1757\n",
      " - Metrics: Accuracy=0.9365, F1=0.8903, Recall=0.8533, Precision=0.9307\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.19910753880213056, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4654258834059383, margin=0.41216211810842746, lpl_weight=0.9821698449548686\n",
      " - ratio=0.17308823830407594, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3647, LPL: 1.3863, Contrastive: 0.1757\n",
      " - Metrics: Accuracy=0.9417, F1=0.8985, Recall=0.8545, Precision=0.9472\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.19910753880213056, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4654258834059383, margin=0.41216211810842746, lpl_weight=0.9821698449548686\n",
      " - ratio=0.17308823830407594, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3647, LPL: 1.3863, Contrastive: 0.1757\n",
      " - Metrics: Accuracy=0.9391, F1=0.8943, Recall=0.8533, Precision=0.9394\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.19910753880213056, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4654258834059383, margin=0.41216211810842746, lpl_weight=0.9821698449548686\n",
      " - ratio=0.17308823830407594, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3647, LPL: 1.3863, Contrastive: 0.1757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:54:23,552] Trial 95 finished with value: 0.8965140252706011 and parameters: {'alpha': 0.19910753880213056, 'K': 35, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.4654258834059383, 'margin': 0.41216211810842746, 'lpl_weight': 0.9821698449548686, 'ratio': 0.17308823830407594, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9442, F1=0.9050, Recall=0.8790, Precision=0.9326\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102135353.csv.\n",
      "Average F1 over 5 seeds: 0.8965  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.23945679899946876, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46046717489737937, margin=0.4115785791556763, lpl_weight=0.9840261663969937\n",
      " - ratio=0.1220435973078611, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3669, LPL: 1.3863, Contrastive: 0.1746\n",
      " - Metrics: Accuracy=0.9269, F1=0.8673, Recall=0.7910, Precision=0.9599\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.23945679899946876, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46046717489737937, margin=0.4115785791556763, lpl_weight=0.9840261663969937\n",
      " - ratio=0.1220435973078611, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3669, LPL: 1.3863, Contrastive: 0.1746\n",
      " - Metrics: Accuracy=0.9269, F1=0.8673, Recall=0.7910, Precision=0.9599\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.23945679899946876, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46046717489737937, margin=0.4115785791556763, lpl_weight=0.9840261663969937\n",
      " - ratio=0.1220435973078611, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3669, LPL: 1.3863, Contrastive: 0.1746\n",
      " - Metrics: Accuracy=0.9265, F1=0.8658, Recall=0.7848, Precision=0.9654\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.23945679899946876, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46046717489737937, margin=0.4115785791556763, lpl_weight=0.9840261663969937\n",
      " - ratio=0.1220435973078611, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3669, LPL: 1.3863, Contrastive: 0.1746\n",
      " - Metrics: Accuracy=0.9280, F1=0.8689, Recall=0.7897, Precision=0.9656\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.23945679899946876, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46046717489737937, margin=0.4115785791556763, lpl_weight=0.9840261663969937\n",
      " - ratio=0.1220435973078611, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3669, LPL: 1.3863, Contrastive: 0.1746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:54:53,403] Trial 96 finished with value: 0.8679634298887791 and parameters: {'alpha': 0.23945679899946876, 'K': 34, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.46046717489737937, 'margin': 0.4115785791556763, 'lpl_weight': 0.9840261663969937, 'ratio': 0.1220435973078611, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9287, F1=0.8706, Recall=0.7934, Precision=0.9643\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102135423.csv.\n",
      "Average F1 over 5 seeds: 0.8680  0.0016\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.20260670586060933, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4913840709963985, margin=0.5781027697739032, lpl_weight=0.9620071774532265\n",
      " - ratio=0.20554016320038446, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3404, LPL: 1.3863, Contrastive: 0.1781\n",
      " - Metrics: Accuracy=0.9284, F1=0.8810, Recall=0.8778, Precision=0.8842\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.20260670586060933, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4913840709963985, margin=0.5781027697739032, lpl_weight=0.9620071774532265\n",
      " - ratio=0.20554016320038446, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3404, LPL: 1.3863, Contrastive: 0.1781\n",
      " - Metrics: Accuracy=0.9335, F1=0.8881, Recall=0.8729, Precision=0.9038\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.20260670586060933, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4913840709963985, margin=0.5781027697739032, lpl_weight=0.9620071774532265\n",
      " - ratio=0.20554016320038446, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3404, LPL: 1.3863, Contrastive: 0.1781\n",
      " - Metrics: Accuracy=0.9258, F1=0.8762, Recall=0.8692, Precision=0.8832\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.20260670586060933, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4913840709963985, margin=0.5781027697739032, lpl_weight=0.9620071774532265\n",
      " - ratio=0.20554016320038446, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3404, LPL: 1.3863, Contrastive: 0.1781\n",
      " - Metrics: Accuracy=0.9350, F1=0.8910, Recall=0.8790, Precision=0.9033\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.20260670586060933, K=35, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.4913840709963985, margin=0.5781027697739032, lpl_weight=0.9620071774532265\n",
      " - ratio=0.20554016320038446, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3404, LPL: 1.3863, Contrastive: 0.1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:55:23,229] Trial 97 finished with value: 0.8860999220265674 and parameters: {'alpha': 0.20260670586060933, 'K': 35, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.4913840709963985, 'margin': 0.5781027697739032, 'lpl_weight': 0.9620071774532265, 'ratio': 0.20554016320038446, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9365, F1=0.8943, Recall=0.8900, Precision=0.8988\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102135453.csv.\n",
      "Average F1 over 5 seeds: 0.8861  0.0066\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.12365278694092605, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46984909590355645, margin=0.3669963811065297, lpl_weight=0.19629883858215663\n",
      " - ratio=0.16881198834078698, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4163, LPL: 1.3863, Contrastive: 0.1793\n",
      " - Metrics: Accuracy=0.9280, F1=0.8793, Recall=0.8680, Precision=0.8908\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.12365278694092605, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46984909590355645, margin=0.3669963811065297, lpl_weight=0.19629883858215663\n",
      " - ratio=0.16881198834078698, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4163, LPL: 1.3863, Contrastive: 0.1793\n",
      " - Metrics: Accuracy=0.9309, F1=0.8842, Recall=0.8729, Precision=0.8959\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.12365278694092605, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46984909590355645, margin=0.3669963811065297, lpl_weight=0.19629883858215663\n",
      " - ratio=0.16881198834078698, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4163, LPL: 1.3863, Contrastive: 0.1793\n",
      " - Metrics: Accuracy=0.9332, F1=0.8879, Recall=0.8765, Precision=0.8996\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.12365278694092605, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46984909590355645, margin=0.3669963811065297, lpl_weight=0.19629883858215663\n",
      " - ratio=0.16881198834078698, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4163, LPL: 1.3863, Contrastive: 0.1793\n",
      " - Metrics: Accuracy=0.9265, F1=0.8768, Recall=0.8655, Precision=0.8883\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.12365278694092605, K=34, layers=1, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.46984909590355645, margin=0.3669963811065297, lpl_weight=0.19629883858215663\n",
      " - ratio=0.16881198834078698, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4163, LPL: 1.3863, Contrastive: 0.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:55:53,265] Trial 98 finished with value: 0.8850646625310269 and parameters: {'alpha': 0.12365278694092605, 'K': 34, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.46984909590355645, 'margin': 0.3669963811065297, 'lpl_weight': 0.19629883858215663, 'ratio': 0.16881198834078698, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9387, F1=0.8971, Recall=0.8851, Precision=0.9095\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102135523.csv.\n",
      "Average F1 over 5 seeds: 0.8851  0.0072\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6435002303643785, K=32, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.443769204599643, margin=0.46092482861682205, lpl_weight=0.9867928890424483\n",
      " - ratio=0.22919340802586002, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3702, LPL: 1.3863, Contrastive: 0.1677\n",
      " - Metrics: Accuracy=0.9321, F1=0.8882, Recall=0.8936, Precision=0.8829\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6435002303643785, K=32, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.443769204599643, margin=0.46092482861682205, lpl_weight=0.9867928890424483\n",
      " - ratio=0.22919340802586002, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3702, LPL: 1.3863, Contrastive: 0.1677\n",
      " - Metrics: Accuracy=0.9313, F1=0.8880, Recall=0.9010, Precision=0.8753\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6435002303643785, K=32, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.443769204599643, margin=0.46092482861682205, lpl_weight=0.9867928890424483\n",
      " - ratio=0.22919340802586002, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3702, LPL: 1.3863, Contrastive: 0.1677\n",
      " - Metrics: Accuracy=0.9332, F1=0.8905, Recall=0.8998, Precision=0.8814\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6435002303643785, K=32, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.443769204599643, margin=0.46092482861682205, lpl_weight=0.9867928890424483\n",
      " - ratio=0.22919340802586002, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3702, LPL: 1.3863, Contrastive: 0.1677\n",
      " - Metrics: Accuracy=0.9276, F1=0.8821, Recall=0.8961, Precision=0.8685\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6435002303643785, K=32, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.443769204599643, margin=0.46092482861682205, lpl_weight=0.9867928890424483\n",
      " - ratio=0.22919340802586002, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3702, LPL: 1.3863, Contrastive: 0.1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:56:22,488] Trial 99 finished with value: 0.8889667335752852 and parameters: {'alpha': 0.6435002303643785, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.443769204599643, 'margin': 0.46092482861682205, 'lpl_weight': 0.9867928890424483, 'ratio': 0.22919340802586002, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 17 with value: 0.8982590092902513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9361, F1=0.8961, Recall=0.9120, Precision=0.8808\n",
      "Done. Results written to cora_experimentations\\cora_scar_2102135553.csv.\n",
      "Average F1 over 5 seeds: 0.8890  0.0045\n",
      "Best trial:\n",
      "  Average F1: 0.8982590092902513\n",
      "  Best parameters:\n",
      "    alpha: 0.26625526948518147\n",
      "    K: 30\n",
      "    layers: 1\n",
      "    hidden_channels: 256\n",
      "    out_channels: 256\n",
      "    norm: layernorm\n",
      "    dropout: 0.30136742497786895\n",
      "    margin: 0.5111785498137569\n",
      "    lpl_weight: 0.7262936518886128\n",
      "    ratio: 0.23112465661992612\n",
      "    aggregation: sum\n",
      "    treatment: removal\n"
     ]
    }
   ],
   "source": [
    "from train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"cora\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": 1,#trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"cora_scar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Cora\n",
    "#### SAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:56:22,520] A new study created in memory with name: no-name-752611fe-0e4a-499e-ab0b-538cb1576b4a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.4644361873267727, K=29, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21451522129748124, margin=0.5774351883518448, lpl_weight=0.6894272980504211\n",
      " - ratio=0.4082216469176174, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0815\n",
      " - Metrics: Accuracy=0.8852, F1=0.8220, Recall=0.8778, Precision=0.7729\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4644361873267727, K=29, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21451522129748124, margin=0.5774351883518448, lpl_weight=0.6894272980504211\n",
      " - ratio=0.4082216469176174, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0815\n",
      " - Metrics: Accuracy=0.8925, F1=0.8329, Recall=0.8863, Precision=0.7855\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4644361873267727, K=29, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21451522129748124, margin=0.5774351883518448, lpl_weight=0.6894272980504211\n",
      " - ratio=0.4082216469176174, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0815\n",
      " - Metrics: Accuracy=0.8792, F1=0.8141, Recall=0.8753, Precision=0.7609\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4644361873267727, K=29, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21451522129748124, margin=0.5774351883518448, lpl_weight=0.6894272980504211\n",
      " - ratio=0.4082216469176174, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0815\n",
      " - Metrics: Accuracy=0.8804, F1=0.8172, Recall=0.8851, Precision=0.7589\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4644361873267727, K=29, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21451522129748124, margin=0.5774351883518448, lpl_weight=0.6894272980504211\n",
      " - ratio=0.4082216469176174, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.0815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:56:56,438] Trial 0 finished with value: 0.8202565278191223 and parameters: {'alpha': 0.4644361873267727, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.21451522129748124, 'margin': 0.5774351883518448, 'lpl_weight': 0.6894272980504211, 'ratio': 0.4082216469176174, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 0 with value: 0.8202565278191223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8796, F1=0.8152, Recall=0.8790, Precision=0.7600\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102135622.csv.\n",
      "Average F1 over 5 seeds: 0.8203  0.0069\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8012605305582338, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.15720674171130133, margin=0.3105436717700593, lpl_weight=0.5391286318590843\n",
      " - ratio=0.11221640474839122, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8263, LPL: 1.3863, Contrastive: 0.1712\n",
      "Epoch 50, Loss: 0.8043, LPL: 1.3863, Contrastive: 0.1234\n",
      "Epoch 100, Loss: 0.8037, LPL: 1.3863, Contrastive: 0.1221\n",
      " - Metrics: Accuracy=0.9129, F1=0.8386, Recall=0.7494, Precision=0.9519\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8012605305582338, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.15720674171130133, margin=0.3105436717700593, lpl_weight=0.5391286318590843\n",
      " - ratio=0.11221640474839122, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8263, LPL: 1.3863, Contrastive: 0.1712\n",
      "Epoch 50, Loss: 0.8043, LPL: 1.3863, Contrastive: 0.1234\n",
      "Epoch 100, Loss: 0.8036, LPL: 1.3863, Contrastive: 0.1220\n",
      " - Metrics: Accuracy=0.9047, F1=0.8226, Recall=0.7311, Precision=0.9403\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8012605305582338, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.15720674171130133, margin=0.3105436717700593, lpl_weight=0.5391286318590843\n",
      " - ratio=0.11221640474839122, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8263, LPL: 1.3863, Contrastive: 0.1712\n",
      "Epoch 50, Loss: 0.8043, LPL: 1.3863, Contrastive: 0.1234\n",
      "Epoch 100, Loss: 0.8037, LPL: 1.3863, Contrastive: 0.1221\n",
      " - Metrics: Accuracy=0.9173, F1=0.8472, Recall=0.7592, Precision=0.9583\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8012605305582338, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.15720674171130133, margin=0.3105436717700593, lpl_weight=0.5391286318590843\n",
      " - ratio=0.11221640474839122, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8263, LPL: 1.3863, Contrastive: 0.1712\n",
      "Epoch 50, Loss: 0.8043, LPL: 1.3863, Contrastive: 0.1234\n",
      "Epoch 100, Loss: 0.8036, LPL: 1.3863, Contrastive: 0.1220\n",
      " - Metrics: Accuracy=0.9132, F1=0.8389, Recall=0.7482, Precision=0.9548\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8012605305582338, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.15720674171130133, margin=0.3105436717700593, lpl_weight=0.5391286318590843\n",
      " - ratio=0.11221640474839122, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8263, LPL: 1.3863, Contrastive: 0.1712\n",
      "Epoch 50, Loss: 0.8043, LPL: 1.3863, Contrastive: 0.1234\n",
      "Epoch 100, Loss: 0.8036, LPL: 1.3863, Contrastive: 0.1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:57:49,400] Trial 1 finished with value: 0.835938973528496 and parameters: {'alpha': 0.8012605305582338, 'K': 25, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.15720674171130133, 'margin': 0.3105436717700593, 'lpl_weight': 0.5391286318590843, 'ratio': 0.11221640474839122, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 1 with value: 0.835938973528496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9092, F1=0.8324, Recall=0.7469, Precision=0.9400\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102135656.csv.\n",
      "Average F1 over 5 seeds: 0.8359  0.0082\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6899533602602111, K=28, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.2060090019766237, margin=0.8317910506475649, lpl_weight=0.1075118753865437\n",
      " - ratio=0.3654509477125667, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.1596, LPL: 1.3863, Contrastive: 0.0119\n",
      "Epoch 50, Loss: 0.1556, LPL: 1.3863, Contrastive: 0.0074\n",
      "Epoch 100, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 150, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 200, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 250, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n",
      " - Metrics: Accuracy=0.8874, F1=0.8013, Recall=0.7518, Precision=0.8577\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6899533602602111, K=28, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.2060090019766237, margin=0.8317910506475649, lpl_weight=0.1075118753865437\n",
      " - ratio=0.3654509477125667, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.1596, LPL: 1.3863, Contrastive: 0.0119\n",
      "Epoch 50, Loss: 0.1556, LPL: 1.3863, Contrastive: 0.0074\n",
      "Epoch 100, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 150, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 200, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 250, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n",
      " - Metrics: Accuracy=0.8925, F1=0.8114, Recall=0.7653, Precision=0.8634\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6899533602602111, K=28, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.2060090019766237, margin=0.8317910506475649, lpl_weight=0.1075118753865437\n",
      " - ratio=0.3654509477125667, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.1596, LPL: 1.3863, Contrastive: 0.0119\n",
      "Epoch 50, Loss: 0.1556, LPL: 1.3863, Contrastive: 0.0074\n",
      "Epoch 100, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 150, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 200, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 250, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n",
      " - Metrics: Accuracy=0.8944, F1=0.8197, Recall=0.7946, Precision=0.8464\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6899533602602111, K=28, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.2060090019766237, margin=0.8317910506475649, lpl_weight=0.1075118753865437\n",
      " - ratio=0.3654509477125667, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.1596, LPL: 1.3863, Contrastive: 0.0119\n",
      "Epoch 50, Loss: 0.1556, LPL: 1.3863, Contrastive: 0.0074\n",
      "Epoch 100, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 150, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 200, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 250, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n",
      " - Metrics: Accuracy=0.8896, F1=0.8082, Recall=0.7702, Precision=0.8502\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6899533602602111, K=28, layers=2, hidden=64, out=256\n",
      " - norm=None, dropout=0.2060090019766237, margin=0.8317910506475649, lpl_weight=0.1075118753865437\n",
      " - ratio=0.3654509477125667, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.1596, LPL: 1.3863, Contrastive: 0.0119\n",
      "Epoch 50, Loss: 0.1556, LPL: 1.3863, Contrastive: 0.0074\n",
      "Epoch 100, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 150, Loss: 0.1555, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 200, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n",
      "Epoch 250, Loss: 0.1554, LPL: 1.3863, Contrastive: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 13:59:26,386] Trial 2 finished with value: 0.8082721086544664 and parameters: {'alpha': 0.6899533602602111, 'K': 28, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': None, 'dropout': 0.2060090019766237, 'margin': 0.8317910506475649, 'lpl_weight': 0.1075118753865437, 'ratio': 0.3654509477125667, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.835938973528496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8852, F1=0.8008, Recall=0.7641, Precision=0.8412\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102135749.csv.\n",
      "Average F1 over 5 seeds: 0.8083  0.0070\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.22529559668891247, K=26, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.3536127593455982, margin=0.5829910762359827, lpl_weight=0.32744981225588465\n",
      " - ratio=0.12265986541953566, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4929, LPL: 1.3863, Contrastive: 0.0579\n",
      "Epoch 50, Loss: 0.4842, LPL: 1.3863, Contrastive: 0.0450\n",
      "Epoch 100, Loss: 0.4839, LPL: 1.3863, Contrastive: 0.0445\n",
      " - Metrics: Accuracy=0.9121, F1=0.8422, Recall=0.7763, Precision=0.9203\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.22529559668891247, K=26, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.3536127593455982, margin=0.5829910762359827, lpl_weight=0.32744981225588465\n",
      " - ratio=0.12265986541953566, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4929, LPL: 1.3863, Contrastive: 0.0579\n",
      "Epoch 50, Loss: 0.4842, LPL: 1.3863, Contrastive: 0.0450\n",
      "Epoch 100, Loss: 0.4839, LPL: 1.3863, Contrastive: 0.0445\n",
      "Epoch 150, Loss: 0.4838, LPL: 1.3863, Contrastive: 0.0444\n",
      " - Metrics: Accuracy=0.9036, F1=0.8270, Recall=0.7628, Precision=0.9030\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.22529559668891247, K=26, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.3536127593455982, margin=0.5829910762359827, lpl_weight=0.32744981225588465\n",
      " - ratio=0.12265986541953566, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4929, LPL: 1.3863, Contrastive: 0.0579\n",
      "Epoch 50, Loss: 0.4842, LPL: 1.3863, Contrastive: 0.0450\n",
      "Epoch 100, Loss: 0.4839, LPL: 1.3863, Contrastive: 0.0445\n",
      " - Metrics: Accuracy=0.9140, F1=0.8456, Recall=0.7800, Precision=0.9233\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.22529559668891247, K=26, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.3536127593455982, margin=0.5829910762359827, lpl_weight=0.32744981225588465\n",
      " - ratio=0.12265986541953566, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4929, LPL: 1.3863, Contrastive: 0.0579\n",
      "Epoch 50, Loss: 0.4842, LPL: 1.3863, Contrastive: 0.0450\n",
      "Epoch 100, Loss: 0.4839, LPL: 1.3863, Contrastive: 0.0445\n",
      "Epoch 150, Loss: 0.4851, LPL: 1.3863, Contrastive: 0.0463\n",
      " - Metrics: Accuracy=0.8933, F1=0.8085, Recall=0.7457, Precision=0.8828\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.22529559668891247, K=26, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.3536127593455982, margin=0.5829910762359827, lpl_weight=0.32744981225588465\n",
      " - ratio=0.12265986541953566, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4929, LPL: 1.3863, Contrastive: 0.0579\n",
      "Epoch 50, Loss: 0.4842, LPL: 1.3863, Contrastive: 0.0450\n",
      "Epoch 100, Loss: 0.4839, LPL: 1.3863, Contrastive: 0.0445\n",
      "Epoch 150, Loss: 0.4838, LPL: 1.3863, Contrastive: 0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:00:30,033] Trial 3 finished with value: 0.8328274385517137 and parameters: {'alpha': 0.22529559668891247, 'K': 26, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.3536127593455982, 'margin': 0.5829910762359827, 'lpl_weight': 0.32744981225588465, 'ratio': 0.12265986541953566, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 1 with value: 0.835938973528496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9114, F1=0.8408, Recall=0.7751, Precision=0.9188\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102135926.csv.\n",
      "Average F1 over 5 seeds: 0.8328  0.0137\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.23789282345752005, K=27, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.11368754814725951, margin=0.5052097190318511, lpl_weight=0.7981775845032449\n",
      " - ratio=0.20165147491963784, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1220, LPL: 1.3863, Contrastive: 0.0769\n",
      "Epoch 50, Loss: 1.1191, LPL: 1.3863, Contrastive: 0.0623\n",
      "Epoch 100, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0621\n",
      "Epoch 150, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0619\n",
      "Epoch 200, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0619\n",
      " - Metrics: Accuracy=0.8837, F1=0.7768, Recall=0.6699, Precision=0.9241\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.23789282345752005, K=27, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.11368754814725951, margin=0.5052097190318511, lpl_weight=0.7981775845032449\n",
      " - ratio=0.20165147491963784, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1220, LPL: 1.3863, Contrastive: 0.0769\n",
      "Epoch 50, Loss: 1.1191, LPL: 1.3863, Contrastive: 0.0623\n",
      "Epoch 100, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0621\n",
      "Epoch 150, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0619\n",
      "Epoch 200, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0619\n",
      "Epoch 250, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0618\n",
      " - Metrics: Accuracy=0.8863, F1=0.7831, Recall=0.6797, Precision=0.9236\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.23789282345752005, K=27, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.11368754814725951, margin=0.5052097190318511, lpl_weight=0.7981775845032449\n",
      " - ratio=0.20165147491963784, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1220, LPL: 1.3863, Contrastive: 0.0769\n",
      "Epoch 50, Loss: 1.1191, LPL: 1.3863, Contrastive: 0.0623\n",
      "Epoch 100, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0621\n",
      "Epoch 150, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0619\n",
      "Epoch 200, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0619\n",
      " - Metrics: Accuracy=0.8918, F1=0.7955, Recall=0.6968, Precision=0.9268\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.23789282345752005, K=27, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.11368754814725951, margin=0.5052097190318511, lpl_weight=0.7981775845032449\n",
      " - ratio=0.20165147491963784, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1220, LPL: 1.3863, Contrastive: 0.0769\n",
      "Epoch 50, Loss: 1.1191, LPL: 1.3863, Contrastive: 0.0623\n",
      "Epoch 100, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0621\n",
      "Epoch 150, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0620\n",
      "Epoch 200, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0619\n",
      " - Metrics: Accuracy=0.8900, F1=0.7928, Recall=0.6968, Precision=0.9194\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.23789282345752005, K=27, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.11368754814725951, margin=0.5052097190318511, lpl_weight=0.7981775845032449\n",
      " - ratio=0.20165147491963784, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1220, LPL: 1.3863, Contrastive: 0.0769\n",
      "Epoch 50, Loss: 1.1191, LPL: 1.3863, Contrastive: 0.0623\n",
      "Epoch 100, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0621\n",
      "Epoch 150, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0620\n",
      "Epoch 200, Loss: 1.1190, LPL: 1.3863, Contrastive: 0.0619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:02:00,032] Trial 4 finished with value: 0.787459658964081 and parameters: {'alpha': 0.23789282345752005, 'K': 27, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.11368754814725951, 'margin': 0.5052097190318511, 'lpl_weight': 0.7981775845032449, 'ratio': 0.20165147491963784, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.835938973528496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8881, F1=0.7891, Recall=0.6932, Precision=0.9160\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140030.csv.\n",
      "Average F1 over 5 seeds: 0.7875  0.0068\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7164230090799545, K=26, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19601754767043902, margin=0.40048512473586273, lpl_weight=0.4494474884498101\n",
      " - ratio=0.248779709965228, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6883, LPL: 1.3863, Contrastive: 0.1185\n",
      "Epoch 50, Loss: 0.6739, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.6734, LPL: 1.3863, Contrastive: 0.0915\n",
      "Epoch 150, Loss: 0.6736, LPL: 1.3863, Contrastive: 0.0919\n",
      "Epoch 200, Loss: 0.6733, LPL: 1.3863, Contrastive: 0.0912\n",
      "Epoch 250, Loss: 0.6732, LPL: 1.3863, Contrastive: 0.0910\n",
      " - Metrics: Accuracy=0.8667, F1=0.7993, Recall=0.8790, Precision=0.7329\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7164230090799545, K=26, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19601754767043902, margin=0.40048512473586273, lpl_weight=0.4494474884498101\n",
      " - ratio=0.248779709965228, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6883, LPL: 1.3863, Contrastive: 0.1185\n",
      "Epoch 50, Loss: 0.6739, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.6734, LPL: 1.3863, Contrastive: 0.0915\n",
      " - Metrics: Accuracy=0.8586, F1=0.7871, Recall=0.8655, Precision=0.7217\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7164230090799545, K=26, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19601754767043902, margin=0.40048512473586273, lpl_weight=0.4494474884498101\n",
      " - ratio=0.248779709965228, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6883, LPL: 1.3863, Contrastive: 0.1185\n",
      "Epoch 50, Loss: 0.6739, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.6734, LPL: 1.3863, Contrastive: 0.0914\n",
      "Epoch 150, Loss: 0.6734, LPL: 1.3863, Contrastive: 0.0914\n",
      " - Metrics: Accuracy=0.8623, F1=0.7927, Recall=0.8716, Precision=0.7268\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7164230090799545, K=26, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19601754767043902, margin=0.40048512473586273, lpl_weight=0.4494474884498101\n",
      " - ratio=0.248779709965228, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6883, LPL: 1.3863, Contrastive: 0.1185\n",
      "Epoch 50, Loss: 0.6739, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.6734, LPL: 1.3863, Contrastive: 0.0914\n",
      " - Metrics: Accuracy=0.8711, F1=0.8060, Recall=0.8863, Precision=0.7390\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7164230090799545, K=26, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.19601754767043902, margin=0.40048512473586273, lpl_weight=0.4494474884498101\n",
      " - ratio=0.248779709965228, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6883, LPL: 1.3863, Contrastive: 0.1185\n",
      "Epoch 50, Loss: 0.6739, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.6734, LPL: 1.3863, Contrastive: 0.0915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:03:15,506] Trial 5 finished with value: 0.7927491543009001 and parameters: {'alpha': 0.7164230090799545, 'K': 26, 'layers': 3, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.19601754767043902, 'margin': 0.40048512473586273, 'lpl_weight': 0.4494474884498101, 'ratio': 0.248779709965228, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 1 with value: 0.835938973528496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8530, F1=0.7786, Recall=0.8557, Precision=0.7143\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140200.csv.\n",
      "Average F1 over 5 seeds: 0.7927  0.0095\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.17075649000238907, K=26, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.2653883329692066, margin=0.245622910541346, lpl_weight=0.42196169865431254\n",
      " - ratio=0.1968060916990321, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1470\n",
      " - Metrics: Accuracy=0.9084, F1=0.8524, Recall=0.8753, Precision=0.8306\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.17075649000238907, K=26, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.2653883329692066, margin=0.245622910541346, lpl_weight=0.42196169865431254\n",
      " - ratio=0.1968060916990321, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1470\n",
      " - Metrics: Accuracy=0.9129, F1=0.8595, Recall=0.8826, Precision=0.8376\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.17075649000238907, K=26, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.2653883329692066, margin=0.245622910541346, lpl_weight=0.42196169865431254\n",
      " - ratio=0.1968060916990321, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1470\n",
      " - Metrics: Accuracy=0.9136, F1=0.8607, Recall=0.8839, Precision=0.8387\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.17075649000238907, K=26, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.2653883329692066, margin=0.245622910541346, lpl_weight=0.42196169865431254\n",
      " - ratio=0.1968060916990321, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1470\n",
      " - Metrics: Accuracy=0.9055, F1=0.8476, Recall=0.8704, Precision=0.8260\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.17075649000238907, K=26, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.2653883329692066, margin=0.245622910541346, lpl_weight=0.42196169865431254\n",
      " - ratio=0.1968060916990321, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:03:47,113] Trial 6 finished with value: 0.8542857142857143 and parameters: {'alpha': 0.17075649000238907, 'K': 26, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': None, 'dropout': 0.2653883329692066, 'margin': 0.245622910541346, 'lpl_weight': 0.42196169865431254, 'ratio': 0.1968060916990321, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 6 with value: 0.8542857142857143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9077, F1=0.8512, Recall=0.8741, Precision=0.8295\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140315.csv.\n",
      "Average F1 over 5 seeds: 0.8543  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.670477346572328, K=35, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19340089244740155, margin=0.884444811132045, lpl_weight=0.2793231139918416\n",
      " - ratio=0.1313639831317599, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5018, LPL: 1.3863, Contrastive: 0.1589\n",
      " - Metrics: Accuracy=0.8999, F1=0.8228, Recall=0.7689, Precision=0.8847\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.670477346572328, K=35, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19340089244740155, margin=0.884444811132045, lpl_weight=0.2793231139918416\n",
      " - ratio=0.1313639831317599, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5018, LPL: 1.3863, Contrastive: 0.1589\n",
      " - Metrics: Accuracy=0.9073, F1=0.8358, Recall=0.7812, Precision=0.8987\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.670477346572328, K=35, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19340089244740155, margin=0.884444811132045, lpl_weight=0.2793231139918416\n",
      " - ratio=0.1313639831317599, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5018, LPL: 1.3863, Contrastive: 0.1589\n",
      " - Metrics: Accuracy=0.9007, F1=0.8241, Recall=0.7702, Precision=0.8861\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.670477346572328, K=35, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19340089244740155, margin=0.884444811132045, lpl_weight=0.2793231139918416\n",
      " - ratio=0.1313639831317599, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5018, LPL: 1.3863, Contrastive: 0.1589\n",
      " - Metrics: Accuracy=0.9040, F1=0.8301, Recall=0.7763, Precision=0.8919\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.670477346572328, K=35, layers=1, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.19340089244740155, margin=0.884444811132045, lpl_weight=0.2793231139918416\n",
      " - ratio=0.1313639831317599, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5018, LPL: 1.3863, Contrastive: 0.1589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:04:14,809] Trial 7 finished with value: 0.8316567016845969 and parameters: {'alpha': 0.670477346572328, 'K': 35, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.19340089244740155, 'margin': 0.884444811132045, 'lpl_weight': 0.2793231139918416, 'ratio': 0.1313639831317599, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 6 with value: 0.8542857142857143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9129, F1=0.8455, Recall=0.7897, Precision=0.9099\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140347.csv.\n",
      "Average F1 over 5 seeds: 0.8317  0.0084\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8002678821275895, K=32, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.1960687169317621, margin=0.9338012736188961, lpl_weight=0.3416186987320477\n",
      " - ratio=0.14490590310738513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4756, LPL: 1.3863, Contrastive: 0.0031\n",
      "Epoch 50, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0012\n",
      "Epoch 100, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0011\n",
      " - Metrics: Accuracy=0.8999, F1=0.8206, Recall=0.7579, Precision=0.8947\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8002678821275895, K=32, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.1960687169317621, margin=0.9338012736188961, lpl_weight=0.3416186987320477\n",
      " - ratio=0.14490590310738513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4756, LPL: 1.3863, Contrastive: 0.0031\n",
      "Epoch 50, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0012\n",
      "Epoch 100, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0011\n",
      " - Metrics: Accuracy=0.8870, F1=0.7895, Recall=0.7017, Precision=0.9025\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8002678821275895, K=32, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.1960687169317621, margin=0.9338012736188961, lpl_weight=0.3416186987320477\n",
      " - ratio=0.14490590310738513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4756, LPL: 1.3863, Contrastive: 0.0031\n",
      "Epoch 50, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0012\n",
      "Epoch 100, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0011\n",
      " - Metrics: Accuracy=0.8885, F1=0.7984, Recall=0.7311, Precision=0.8794\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8002678821275895, K=32, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.1960687169317621, margin=0.9338012736188961, lpl_weight=0.3416186987320477\n",
      " - ratio=0.14490590310738513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4756, LPL: 1.3863, Contrastive: 0.0031\n",
      "Epoch 50, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0012\n",
      "Epoch 100, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0011\n",
      " - Metrics: Accuracy=0.8992, F1=0.8181, Recall=0.7506, Precision=0.8990\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8002678821275895, K=32, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.1960687169317621, margin=0.9338012736188961, lpl_weight=0.3416186987320477\n",
      " - ratio=0.14490590310738513, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4756, LPL: 1.3863, Contrastive: 0.0031\n",
      "Epoch 50, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0012\n",
      "Epoch 100, Loss: 0.4743, LPL: 1.3863, Contrastive: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:05:21,720] Trial 8 finished with value: 0.8059305969909563 and parameters: {'alpha': 0.8002678821275895, 'K': 32, 'layers': 3, 'hidden_channels': 64, 'out_channels': 256, 'norm': None, 'dropout': 0.1960687169317621, 'margin': 0.9338012736188961, 'lpl_weight': 0.3416186987320477, 'ratio': 0.14490590310738513, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 6 with value: 0.8542857142857143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8911, F1=0.8029, Recall=0.7347, Precision=0.8851\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140414.csv.\n",
      "Average F1 over 5 seeds: 0.8059  0.0118\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9311503683267849, K=31, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.13362295930406579, margin=0.7992861523318017, lpl_weight=0.8993026418128638\n",
      " - ratio=0.3947585858461182, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2479, LPL: 1.3863, Contrastive: 0.0122\n",
      "Epoch 50, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0103\n",
      "Epoch 100, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0102\n",
      " - Metrics: Accuracy=0.8877, F1=0.8284, Recall=0.8973, Precision=0.7694\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9311503683267849, K=31, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.13362295930406579, margin=0.7992861523318017, lpl_weight=0.8993026418128638\n",
      " - ratio=0.3947585858461182, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2479, LPL: 1.3863, Contrastive: 0.0122\n",
      "Epoch 50, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0103\n",
      "Epoch 100, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0102\n",
      " - Metrics: Accuracy=0.8711, F1=0.7801, Recall=0.7567, Precision=0.8049\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9311503683267849, K=31, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.13362295930406579, margin=0.7992861523318017, lpl_weight=0.8993026418128638\n",
      " - ratio=0.3947585858461182, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2479, LPL: 1.3863, Contrastive: 0.0122\n",
      "Epoch 50, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0103\n",
      "Epoch 100, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0102\n",
      " - Metrics: Accuracy=0.8822, F1=0.7977, Recall=0.7689, Precision=0.8287\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9311503683267849, K=31, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.13362295930406579, margin=0.7992861523318017, lpl_weight=0.8993026418128638\n",
      " - ratio=0.3947585858461182, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2479, LPL: 1.3863, Contrastive: 0.0122\n",
      "Epoch 50, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0103\n",
      "Epoch 100, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0102\n",
      " - Metrics: Accuracy=0.8852, F1=0.8252, Recall=0.8973, Precision=0.7638\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9311503683267849, K=31, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.13362295930406579, margin=0.7992861523318017, lpl_weight=0.8993026418128638\n",
      " - ratio=0.3947585858461182, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2479, LPL: 1.3863, Contrastive: 0.0122\n",
      "Epoch 50, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0103\n",
      "Epoch 100, Loss: 1.2477, LPL: 1.3863, Contrastive: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:06:24,492] Trial 9 finished with value: 0.818242250635534 and parameters: {'alpha': 0.9311503683267849, 'K': 31, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.13362295930406579, 'margin': 0.7992861523318017, 'lpl_weight': 0.8993026418128638, 'ratio': 0.3947585858461182, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 6 with value: 0.8542857142857143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9103, F1=0.8598, Recall=0.9108, Precision=0.8142\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140521.csv.\n",
      "Average F1 over 5 seeds: 0.8182  0.0274\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1064626715878716, K=34, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.45951902013491286, margin=0.10535668320429054, lpl_weight=0.6485835794345401\n",
      " - ratio=0.4918034716592289, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9795, LPL: 1.3863, Contrastive: 0.2287\n",
      "Epoch 50, Loss: 0.9717, LPL: 1.3863, Contrastive: 0.2065\n",
      "Epoch 100, Loss: 0.9712, LPL: 1.3863, Contrastive: 0.2051\n",
      " - Metrics: Accuracy=0.7164, F1=0.6743, Recall=0.9719, Precision=0.5162\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1064626715878716, K=34, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.45951902013491286, margin=0.10535668320429054, lpl_weight=0.6485835794345401\n",
      " - ratio=0.4918034716592289, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9795, LPL: 1.3863, Contrastive: 0.2287\n",
      "Epoch 50, Loss: 0.9717, LPL: 1.3863, Contrastive: 0.2065\n",
      "Epoch 100, Loss: 0.9714, LPL: 1.3863, Contrastive: 0.2056\n",
      " - Metrics: Accuracy=0.7208, F1=0.6794, Recall=0.9792, Precision=0.5201\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1064626715878716, K=34, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.45951902013491286, margin=0.10535668320429054, lpl_weight=0.6485835794345401\n",
      " - ratio=0.4918034716592289, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9795, LPL: 1.3863, Contrastive: 0.2287\n",
      "Epoch 50, Loss: 0.9717, LPL: 1.3863, Contrastive: 0.2065\n",
      "Epoch 100, Loss: 0.9712, LPL: 1.3863, Contrastive: 0.2051\n",
      " - Metrics: Accuracy=0.7179, F1=0.6760, Recall=0.9743, Precision=0.5175\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1064626715878716, K=34, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.45951902013491286, margin=0.10535668320429054, lpl_weight=0.6485835794345401\n",
      " - ratio=0.4918034716592289, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9795, LPL: 1.3863, Contrastive: 0.2287\n",
      "Epoch 50, Loss: 0.9717, LPL: 1.3863, Contrastive: 0.2066\n",
      "Epoch 100, Loss: 0.9718, LPL: 1.3863, Contrastive: 0.2069\n",
      " - Metrics: Accuracy=0.7194, F1=0.6777, Recall=0.9768, Precision=0.5188\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1064626715878716, K=34, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.45951902013491286, margin=0.10535668320429054, lpl_weight=0.6485835794345401\n",
      " - ratio=0.4918034716592289, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9795, LPL: 1.3863, Contrastive: 0.2287\n",
      "Epoch 50, Loss: 0.9717, LPL: 1.3863, Contrastive: 0.2065\n",
      "Epoch 100, Loss: 0.9714, LPL: 1.3863, Contrastive: 0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:07:29,694] Trial 10 finished with value: 0.6765055131467345 and parameters: {'alpha': 0.1064626715878716, 'K': 34, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': None, 'dropout': 0.45951902013491286, 'margin': 0.10535668320429054, 'lpl_weight': 0.6485835794345401, 'ratio': 0.4918034716592289, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 6 with value: 0.8542857142857143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7171, F1=0.6751, Recall=0.9731, Precision=0.5169\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140624.csv.\n",
      "Average F1 over 5 seeds: 0.6765  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.45630581269083736, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.311408815517086, margin=0.19249629013837757, lpl_weight=0.5295431475268001\n",
      " - ratio=0.20479492222090537, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8220, LPL: 1.3863, Contrastive: 0.1868\n",
      "Epoch 50, Loss: 0.8133, LPL: 1.3863, Contrastive: 0.1683\n",
      "Epoch 100, Loss: 0.8131, LPL: 1.3863, Contrastive: 0.1680\n",
      " - Metrics: Accuracy=0.9114, F1=0.8587, Recall=0.8912, Precision=0.8284\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.45630581269083736, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.311408815517086, margin=0.19249629013837757, lpl_weight=0.5295431475268001\n",
      " - ratio=0.20479492222090537, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8220, LPL: 1.3863, Contrastive: 0.1868\n",
      "Epoch 50, Loss: 0.8133, LPL: 1.3863, Contrastive: 0.1683\n",
      "Epoch 100, Loss: 0.8131, LPL: 1.3863, Contrastive: 0.1679\n",
      " - Metrics: Accuracy=0.9069, F1=0.8516, Recall=0.8839, Precision=0.8216\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.45630581269083736, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.311408815517086, margin=0.19249629013837757, lpl_weight=0.5295431475268001\n",
      " - ratio=0.20479492222090537, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8220, LPL: 1.3863, Contrastive: 0.1868\n",
      "Epoch 50, Loss: 0.8133, LPL: 1.3863, Contrastive: 0.1683\n",
      "Epoch 100, Loss: 0.8128, LPL: 1.3863, Contrastive: 0.1673\n",
      " - Metrics: Accuracy=0.9106, F1=0.8575, Recall=0.8900, Precision=0.8273\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.45630581269083736, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.311408815517086, margin=0.19249629013837757, lpl_weight=0.5295431475268001\n",
      " - ratio=0.20479492222090537, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8220, LPL: 1.3863, Contrastive: 0.1868\n",
      "Epoch 50, Loss: 0.8133, LPL: 1.3863, Contrastive: 0.1683\n",
      "Epoch 100, Loss: 0.8133, LPL: 1.3863, Contrastive: 0.1683\n",
      " - Metrics: Accuracy=0.9003, F1=0.8410, Recall=0.8729, Precision=0.8114\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.45630581269083736, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.311408815517086, margin=0.19249629013837757, lpl_weight=0.5295431475268001\n",
      " - ratio=0.20479492222090537, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8220, LPL: 1.3863, Contrastive: 0.1868\n",
      "Epoch 50, Loss: 0.8133, LPL: 1.3863, Contrastive: 0.1683\n",
      "Epoch 100, Loss: 0.8131, LPL: 1.3863, Contrastive: 0.1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:08:21,627] Trial 11 finished with value: 0.8558303886925795 and parameters: {'alpha': 0.45630581269083736, 'K': 25, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.311408815517086, 'margin': 0.19249629013837757, 'lpl_weight': 0.5295431475268001, 'ratio': 0.20479492222090537, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 11 with value: 0.8558303886925795.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9188, F1=0.8704, Recall=0.9034, Precision=0.8398\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140729.csv.\n",
      "Average F1 over 5 seeds: 0.8558  0.0096\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3977386320133111, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3081808170101416, margin=0.12253694893341868, lpl_weight=0.4713921410248216\n",
      " - ratio=0.25753956698048547, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2110\n",
      "Epoch 50, Loss: 0.7580, LPL: 1.3863, Contrastive: 0.1978\n",
      " - Metrics: Accuracy=0.8866, F1=0.8312, Recall=0.9242, Precision=0.7552\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3977386320133111, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3081808170101416, margin=0.12253694893341868, lpl_weight=0.4713921410248216\n",
      " - ratio=0.25753956698048547, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2110\n",
      "Epoch 50, Loss: 0.7580, LPL: 1.3863, Contrastive: 0.1978\n",
      " - Metrics: Accuracy=0.8748, F1=0.8136, Recall=0.9046, Precision=0.7393\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3977386320133111, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3081808170101416, margin=0.12253694893341868, lpl_weight=0.4713921410248216\n",
      " - ratio=0.25753956698048547, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2110\n",
      "Epoch 50, Loss: 0.7580, LPL: 1.3863, Contrastive: 0.1978\n",
      " - Metrics: Accuracy=0.8866, F1=0.8312, Recall=0.9242, Precision=0.7552\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3977386320133111, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3081808170101416, margin=0.12253694893341868, lpl_weight=0.4713921410248216\n",
      " - ratio=0.25753956698048547, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2110\n",
      "Epoch 50, Loss: 0.7580, LPL: 1.3863, Contrastive: 0.1978\n",
      " - Metrics: Accuracy=0.8792, F1=0.8202, Recall=0.9120, Precision=0.7453\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3977386320133111, K=25, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3081808170101416, margin=0.12253694893341868, lpl_weight=0.4713921410248216\n",
      " - ratio=0.25753956698048547, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2110\n",
      "Epoch 50, Loss: 0.7580, LPL: 1.3863, Contrastive: 0.1978\n",
      "Epoch 100, Loss: 0.7581, LPL: 1.3863, Contrastive: 0.1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:09:08,649] Trial 12 finished with value: 0.8233095107201759 and parameters: {'alpha': 0.3977386320133111, 'K': 25, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3081808170101416, 'margin': 0.12253694893341868, 'lpl_weight': 0.4713921410248216, 'ratio': 0.25753956698048547, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 11 with value: 0.8558303886925795.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8792, F1=0.8202, Recall=0.9120, Precision=0.7453\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140821.csv.\n",
      "Average F1 over 5 seeds: 0.8233  0.0069\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3448124628314849, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.3809995198621438, margin=0.27117082945752713, lpl_weight=0.6238945139606231\n",
      " - ratio=0.1875357207992241, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9297, LPL: 1.3863, Contrastive: 0.1724\n",
      "Epoch 50, Loss: 0.9169, LPL: 1.3863, Contrastive: 0.1381\n",
      " - Metrics: Accuracy=0.9232, F1=0.8745, Recall=0.8863, Precision=0.8631\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3448124628314849, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.3809995198621438, margin=0.27117082945752713, lpl_weight=0.6238945139606231\n",
      " - ratio=0.1875357207992241, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9297, LPL: 1.3863, Contrastive: 0.1724\n",
      "Epoch 50, Loss: 0.9169, LPL: 1.3863, Contrastive: 0.1381\n",
      " - Metrics: Accuracy=0.9188, F1=0.8673, Recall=0.8790, Precision=0.8560\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3448124628314849, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.3809995198621438, margin=0.27117082945752713, lpl_weight=0.6238945139606231\n",
      " - ratio=0.1875357207992241, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9297, LPL: 1.3863, Contrastive: 0.1724\n",
      "Epoch 50, Loss: 0.9169, LPL: 1.3863, Contrastive: 0.1381\n",
      " - Metrics: Accuracy=0.9195, F1=0.8685, Recall=0.8802, Precision=0.8571\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3448124628314849, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.3809995198621438, margin=0.27117082945752713, lpl_weight=0.6238945139606231\n",
      " - ratio=0.1875357207992241, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9297, LPL: 1.3863, Contrastive: 0.1724\n",
      "Epoch 50, Loss: 0.9169, LPL: 1.3863, Contrastive: 0.1381\n",
      " - Metrics: Accuracy=0.9151, F1=0.8613, Recall=0.8729, Precision=0.8500\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3448124628314849, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.3809995198621438, margin=0.27117082945752713, lpl_weight=0.6238945139606231\n",
      " - ratio=0.1875357207992241, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9297, LPL: 1.3863, Contrastive: 0.1724\n",
      "Epoch 50, Loss: 0.9169, LPL: 1.3863, Contrastive: 0.1381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:09:59,406] Trial 13 finished with value: 0.8670687575392038 and parameters: {'alpha': 0.3448124628314849, 'K': 28, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.3809995198621438, 'margin': 0.27117082945752713, 'lpl_weight': 0.6238945139606231, 'ratio': 0.1875357207992241, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 13 with value: 0.8670687575392038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9165, F1=0.8637, Recall=0.8753, Precision=0.8524\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140908.csv.\n",
      "Average F1 over 5 seeds: 0.8671  0.0045\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.36537720409766855, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.41426853221190946, margin=0.26291805366873056, lpl_weight=0.9945709642322698\n",
      " - ratio=0.303515117158293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3797, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1414\n",
      "Epoch 100, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1397\n",
      " - Metrics: Accuracy=0.8608, F1=0.8042, Recall=0.9462, Precision=0.6992\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.36537720409766855, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.41426853221190946, margin=0.26291805366873056, lpl_weight=0.9945709642322698\n",
      " - ratio=0.303515117158293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3797, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1414\n",
      "Epoch 100, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1398\n",
      " - Metrics: Accuracy=0.8564, F1=0.7979, Recall=0.9389, Precision=0.6938\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.36537720409766855, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.41426853221190946, margin=0.26291805366873056, lpl_weight=0.9945709642322698\n",
      " - ratio=0.303515117158293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3797, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1414\n",
      "Epoch 100, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1397\n",
      " - Metrics: Accuracy=0.8645, F1=0.8094, Recall=0.9523, Precision=0.7037\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.36537720409766855, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.41426853221190946, margin=0.26291805366873056, lpl_weight=0.9945709642322698\n",
      " - ratio=0.303515117158293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3797, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1414\n",
      "Epoch 100, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1399\n",
      " - Metrics: Accuracy=0.8527, F1=0.7927, Recall=0.9328, Precision=0.6893\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.36537720409766855, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.41426853221190946, margin=0.26291805366873056, lpl_weight=0.9945709642322698\n",
      " - ratio=0.303515117158293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3797, LPL: 1.3863, Contrastive: 0.1782\n",
      "Epoch 50, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1414\n",
      "Epoch 100, Loss: 1.3795, LPL: 1.3863, Contrastive: 0.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:10:56,509] Trial 14 finished with value: 0.8010389610389609 and parameters: {'alpha': 0.36537720409766855, 'K': 29, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.41426853221190946, 'margin': 0.26291805366873056, 'lpl_weight': 0.9945709642322698, 'ratio': 0.303515117158293, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 13 with value: 0.8670687575392038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8586, F1=0.8010, Recall=0.9425, Precision=0.6965\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102140959.csv.\n",
      "Average F1 over 5 seeds: 0.8010  0.0056\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5444880582315171, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.36631003645760407, margin=0.41232739291292997, lpl_weight=0.6671354196429609\n",
      " - ratio=0.1918448263178567, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9745, LPL: 1.3863, Contrastive: 0.1492\n",
      "Epoch 50, Loss: 0.9552, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 100, Loss: 0.9545, LPL: 1.3863, Contrastive: 0.0891\n",
      " - Metrics: Accuracy=0.9136, F1=0.8597, Recall=0.8765, Precision=0.8435\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5444880582315171, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.36631003645760407, margin=0.41232739291292997, lpl_weight=0.6671354196429609\n",
      " - ratio=0.1918448263178567, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9745, LPL: 1.3863, Contrastive: 0.1492\n",
      "Epoch 50, Loss: 0.9552, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 100, Loss: 0.9545, LPL: 1.3863, Contrastive: 0.0891\n",
      " - Metrics: Accuracy=0.9092, F1=0.8525, Recall=0.8692, Precision=0.8365\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5444880582315171, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.36631003645760407, margin=0.41232739291292997, lpl_weight=0.6671354196429609\n",
      " - ratio=0.1918448263178567, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9745, LPL: 1.3863, Contrastive: 0.1492\n",
      "Epoch 50, Loss: 0.9552, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 100, Loss: 0.9545, LPL: 1.3863, Contrastive: 0.0891\n",
      " - Metrics: Accuracy=0.9173, F1=0.8657, Recall=0.8826, Precision=0.8494\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5444880582315171, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.36631003645760407, margin=0.41232739291292997, lpl_weight=0.6671354196429609\n",
      " - ratio=0.1918448263178567, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9745, LPL: 1.3863, Contrastive: 0.1492\n",
      "Epoch 50, Loss: 0.9552, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 100, Loss: 0.9545, LPL: 1.3863, Contrastive: 0.0891\n",
      " - Metrics: Accuracy=0.9129, F1=0.8585, Recall=0.8753, Precision=0.8424\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5444880582315171, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.36631003645760407, margin=0.41232739291292997, lpl_weight=0.6671354196429609\n",
      " - ratio=0.1918448263178567, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9745, LPL: 1.3863, Contrastive: 0.1492\n",
      "Epoch 50, Loss: 0.9552, LPL: 1.3863, Contrastive: 0.0913\n",
      "Epoch 100, Loss: 0.9545, LPL: 1.3863, Contrastive: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:11:59,555] Trial 15 finished with value: 0.8594724220623501 and parameters: {'alpha': 0.5444880582315171, 'K': 28, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.36631003645760407, 'margin': 0.41232739291292997, 'lpl_weight': 0.6671354196429609, 'ratio': 0.1918448263178567, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 13 with value: 0.8670687575392038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9143, F1=0.8609, Recall=0.8778, Precision=0.8447\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141056.csv.\n",
      "Average F1 over 5 seeds: 0.8595  0.0042\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5954310372692561, K=31, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.38518917914038214, margin=0.4278883432206471, lpl_weight=0.6664508089145591\n",
      " - ratio=0.3000251160446582, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9741, LPL: 1.3863, Contrastive: 0.1505\n",
      "Epoch 50, Loss: 0.9528, LPL: 1.3863, Contrastive: 0.0867\n",
      "Epoch 100, Loss: 0.9521, LPL: 1.3863, Contrastive: 0.0845\n",
      " - Metrics: Accuracy=0.8637, F1=0.8075, Recall=0.9462, Precision=0.7043\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5954310372692561, K=31, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.38518917914038214, margin=0.4278883432206471, lpl_weight=0.6664508089145591\n",
      " - ratio=0.3000251160446582, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9741, LPL: 1.3863, Contrastive: 0.1505\n",
      "Epoch 50, Loss: 0.9528, LPL: 1.3863, Contrastive: 0.0867\n",
      "Epoch 100, Loss: 0.9521, LPL: 1.3863, Contrastive: 0.0845\n",
      " - Metrics: Accuracy=0.8571, F1=0.7981, Recall=0.9352, Precision=0.6961\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5954310372692561, K=31, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.38518917914038214, margin=0.4278883432206471, lpl_weight=0.6664508089145591\n",
      " - ratio=0.3000251160446582, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9741, LPL: 1.3863, Contrastive: 0.1505\n",
      "Epoch 50, Loss: 0.9528, LPL: 1.3863, Contrastive: 0.0867\n",
      "Epoch 100, Loss: 0.9521, LPL: 1.3863, Contrastive: 0.0845\n",
      " - Metrics: Accuracy=0.8541, F1=0.7939, Recall=0.9303, Precision=0.6924\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5954310372692561, K=31, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.38518917914038214, margin=0.4278883432206471, lpl_weight=0.6664508089145591\n",
      " - ratio=0.3000251160446582, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9741, LPL: 1.3863, Contrastive: 0.1505\n",
      "Epoch 50, Loss: 0.9528, LPL: 1.3863, Contrastive: 0.0867\n",
      "Epoch 100, Loss: 0.9521, LPL: 1.3863, Contrastive: 0.0845\n",
      " - Metrics: Accuracy=0.8623, F1=0.8054, Recall=0.9438, Precision=0.7025\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5954310372692561, K=31, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.38518917914038214, margin=0.4278883432206471, lpl_weight=0.6664508089145591\n",
      " - ratio=0.3000251160446582, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9741, LPL: 1.3863, Contrastive: 0.1505\n",
      "Epoch 50, Loss: 0.9528, LPL: 1.3863, Contrastive: 0.0867\n",
      "Epoch 100, Loss: 0.9521, LPL: 1.3863, Contrastive: 0.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:13:03,292] Trial 16 finished with value: 0.8016692749087115 and parameters: {'alpha': 0.5954310372692561, 'K': 31, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.38518917914038214, 'margin': 0.4278883432206471, 'lpl_weight': 0.6664508089145591, 'ratio': 0.3000251160446582, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 13 with value: 0.8670687575392038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8608, F1=0.8033, Recall=0.9413, Precision=0.7006\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141159.csv.\n",
      "Average F1 over 5 seeds: 0.8017  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5383032102563455, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.49844668439410195, margin=0.7049687655710255, lpl_weight=0.7770120904940662\n",
      " - ratio=0.17054299419659033, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1698\n",
      " - Metrics: Accuracy=0.8999, F1=0.8326, Recall=0.8240, Precision=0.8414\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5383032102563455, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.49844668439410195, margin=0.7049687655710255, lpl_weight=0.7770120904940662\n",
      " - ratio=0.17054299419659033, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1698\n",
      " - Metrics: Accuracy=0.8999, F1=0.8326, Recall=0.8240, Precision=0.8414\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5383032102563455, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.49844668439410195, margin=0.7049687655710255, lpl_weight=0.7770120904940662\n",
      " - ratio=0.17054299419659033, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1698\n",
      " - Metrics: Accuracy=0.8903, F1=0.8166, Recall=0.8081, Precision=0.8252\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5383032102563455, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.49844668439410195, margin=0.7049687655710255, lpl_weight=0.7770120904940662\n",
      " - ratio=0.17054299419659033, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1698\n",
      " - Metrics: Accuracy=0.8918, F1=0.8190, Recall=0.8105, Precision=0.8277\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5383032102563455, K=28, layers=1, hidden=128, out=128\n",
      " - norm=None, dropout=0.49844668439410195, margin=0.7049687655710255, lpl_weight=0.7770120904940662\n",
      " - ratio=0.17054299419659033, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:13:36,855] Trial 17 finished with value: 0.8265388377052172 and parameters: {'alpha': 0.5383032102563455, 'K': 28, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.49844668439410195, 'margin': 0.7049687655710255, 'lpl_weight': 0.7770120904940662, 'ratio': 0.17054299419659033, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 13 with value: 0.8670687575392038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8996, F1=0.8319, Recall=0.8227, Precision=0.8413\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141303.csv.\n",
      "Average F1 over 5 seeds: 0.8265  0.0072\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3281223239559194, K=30, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3593138802971175, margin=0.36180182931632177, lpl_weight=0.779169884804215\n",
      " - ratio=0.2563031474872138, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1085, LPL: 1.3863, Contrastive: 0.1282\n",
      "Epoch 50, Loss: 1.1039, LPL: 1.3863, Contrastive: 0.1073\n",
      " - Metrics: Accuracy=0.8907, F1=0.8370, Recall=0.9291, Precision=0.7615\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3281223239559194, K=30, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3593138802971175, margin=0.36180182931632177, lpl_weight=0.779169884804215\n",
      " - ratio=0.2563031474872138, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1085, LPL: 1.3863, Contrastive: 0.1282\n",
      "Epoch 50, Loss: 1.1039, LPL: 1.3863, Contrastive: 0.1073\n",
      " - Metrics: Accuracy=0.8855, F1=0.8293, Recall=0.9205, Precision=0.7545\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3281223239559194, K=30, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3593138802971175, margin=0.36180182931632177, lpl_weight=0.779169884804215\n",
      " - ratio=0.2563031474872138, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1085, LPL: 1.3863, Contrastive: 0.1282\n",
      "Epoch 50, Loss: 1.1039, LPL: 1.3863, Contrastive: 0.1073\n",
      " - Metrics: Accuracy=0.8951, F1=0.8436, Recall=0.9364, Precision=0.7675\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3281223239559194, K=30, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3593138802971175, margin=0.36180182931632177, lpl_weight=0.779169884804215\n",
      " - ratio=0.2563031474872138, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1085, LPL: 1.3863, Contrastive: 0.1282\n",
      "Epoch 50, Loss: 1.1039, LPL: 1.3863, Contrastive: 0.1073\n",
      " - Metrics: Accuracy=0.8936, F1=0.8414, Recall=0.9340, Precision=0.7655\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3281223239559194, K=30, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3593138802971175, margin=0.36180182931632177, lpl_weight=0.779169884804215\n",
      " - ratio=0.2563031474872138, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1085, LPL: 1.3863, Contrastive: 0.1282\n",
      "Epoch 50, Loss: 1.1039, LPL: 1.3863, Contrastive: 0.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:14:23,283] Trial 18 finished with value: 0.8381057268722467 and parameters: {'alpha': 0.3281223239559194, 'K': 30, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.3593138802971175, 'margin': 0.36180182931632177, 'lpl_weight': 0.779169884804215, 'ratio': 0.2563031474872138, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 13 with value: 0.8670687575392038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8922, F1=0.8392, Recall=0.9315, Precision=0.7635\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141336.csv.\n",
      "Average F1 over 5 seeds: 0.8381  0.0049\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5506397524433885, K=28, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.42460362561299425, margin=0.476979095090568, lpl_weight=0.60343202609337\n",
      " - ratio=0.34814776480267645, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8964, LPL: 1.3863, Contrastive: 0.1510\n",
      "Epoch 50, Loss: 0.8656, LPL: 1.3863, Contrastive: 0.0733\n",
      "Epoch 100, Loss: 0.8649, LPL: 1.3863, Contrastive: 0.0716\n",
      "Epoch 150, Loss: 0.8648, LPL: 1.3863, Contrastive: 0.0712\n",
      " - Metrics: Accuracy=0.8316, F1=0.7751, Recall=0.9609, Precision=0.6496\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5506397524433885, K=28, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.42460362561299425, margin=0.476979095090568, lpl_weight=0.60343202609337\n",
      " - ratio=0.34814776480267645, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8964, LPL: 1.3863, Contrastive: 0.1510\n",
      "Epoch 50, Loss: 0.8656, LPL: 1.3863, Contrastive: 0.0733\n",
      "Epoch 100, Loss: 0.8649, LPL: 1.3863, Contrastive: 0.0715\n",
      " - Metrics: Accuracy=0.8287, F1=0.7712, Recall=0.9560, Precision=0.6463\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5506397524433885, K=28, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.42460362561299425, margin=0.476979095090568, lpl_weight=0.60343202609337\n",
      " - ratio=0.34814776480267645, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8964, LPL: 1.3863, Contrastive: 0.1510\n",
      "Epoch 50, Loss: 0.8656, LPL: 1.3863, Contrastive: 0.0733\n",
      "Epoch 100, Loss: 0.8649, LPL: 1.3863, Contrastive: 0.0715\n",
      " - Metrics: Accuracy=0.8279, F1=0.7702, Recall=0.9548, Precision=0.6455\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5506397524433885, K=28, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.42460362561299425, margin=0.476979095090568, lpl_weight=0.60343202609337\n",
      " - ratio=0.34814776480267645, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8964, LPL: 1.3863, Contrastive: 0.1510\n",
      "Epoch 50, Loss: 0.8656, LPL: 1.3863, Contrastive: 0.0733\n",
      "Epoch 100, Loss: 0.8649, LPL: 1.3863, Contrastive: 0.0716\n",
      " - Metrics: Accuracy=0.8279, F1=0.7702, Recall=0.9548, Precision=0.6455\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5506397524433885, K=28, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.42460362561299425, margin=0.476979095090568, lpl_weight=0.60343202609337\n",
      " - ratio=0.34814776480267645, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8964, LPL: 1.3863, Contrastive: 0.1510\n",
      "Epoch 50, Loss: 0.8656, LPL: 1.3863, Contrastive: 0.0733\n",
      "Epoch 100, Loss: 0.8649, LPL: 1.3863, Contrastive: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:15:27,731] Trial 19 finished with value: 0.7702169625246549 and parameters: {'alpha': 0.5506397524433885, 'K': 28, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.42460362561299425, 'margin': 0.476979095090568, 'lpl_weight': 0.60343202609337, 'ratio': 0.34814776480267645, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 13 with value: 0.8670687575392038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8235, F1=0.7643, Recall=0.9474, Precision=0.6405\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141423.csv.\n",
      "Average F1 over 5 seeds: 0.7702  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2885769705409146, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.34276187909966827, margin=0.6708463820470021, lpl_weight=0.8758872917551468\n",
      " - ratio=0.1727968779888676, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2311, LPL: 1.3863, Contrastive: 0.1361\n",
      " - Metrics: Accuracy=0.9225, F1=0.8708, Recall=0.8655, Precision=0.8762\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2885769705409146, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.34276187909966827, margin=0.6708463820470021, lpl_weight=0.8758872917551468\n",
      " - ratio=0.1727968779888676, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2311, LPL: 1.3863, Contrastive: 0.1361\n",
      " - Metrics: Accuracy=0.9184, F1=0.8640, Recall=0.8582, Precision=0.8699\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2885769705409146, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.34276187909966827, margin=0.6708463820470021, lpl_weight=0.8758872917551468\n",
      " - ratio=0.1727968779888676, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2311, LPL: 1.3863, Contrastive: 0.1361\n",
      " - Metrics: Accuracy=0.9154, F1=0.8591, Recall=0.8533, Precision=0.8649\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2885769705409146, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.34276187909966827, margin=0.6708463820470021, lpl_weight=0.8758872917551468\n",
      " - ratio=0.1727968779888676, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2311, LPL: 1.3863, Contrastive: 0.1361\n",
      " - Metrics: Accuracy=0.9191, F1=0.8652, Recall=0.8594, Precision=0.8711\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2885769705409146, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.34276187909966827, margin=0.6708463820470021, lpl_weight=0.8758872917551468\n",
      " - ratio=0.1727968779888676, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2311, LPL: 1.3863, Contrastive: 0.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:15:57,988] Trial 20 finished with value: 0.8647376840998421 and parameters: {'alpha': 0.2885769705409146, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.34276187909966827, 'margin': 0.6708463820470021, 'lpl_weight': 0.8758872917551468, 'ratio': 0.1727968779888676, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 13 with value: 0.8670687575392038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9188, F1=0.8645, Recall=0.8582, Precision=0.8710\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141527.csv.\n",
      "Average F1 over 5 seeds: 0.8647  0.0037\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2947209253880016, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.3464622926245935, margin=0.6675065653689388, lpl_weight=0.8815093050468522\n",
      " - ratio=0.17519405087187895, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2382, LPL: 1.3863, Contrastive: 0.1367\n",
      " - Metrics: Accuracy=0.9184, F1=0.8645, Recall=0.8619, Precision=0.8672\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2947209253880016, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.3464622926245935, margin=0.6675065653689388, lpl_weight=0.8815093050468522\n",
      " - ratio=0.17519405087187895, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2382, LPL: 1.3863, Contrastive: 0.1367\n",
      " - Metrics: Accuracy=0.9143, F1=0.8577, Recall=0.8545, Precision=0.8608\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2947209253880016, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.3464622926245935, margin=0.6675065653689388, lpl_weight=0.8815093050468522\n",
      " - ratio=0.17519405087187895, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2382, LPL: 1.3863, Contrastive: 0.1367\n",
      " - Metrics: Accuracy=0.9180, F1=0.8638, Recall=0.8606, Precision=0.8670\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2947209253880016, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.3464622926245935, margin=0.6675065653689388, lpl_weight=0.8815093050468522\n",
      " - ratio=0.17519405087187895, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2382, LPL: 1.3863, Contrastive: 0.1367\n",
      " - Metrics: Accuracy=0.9195, F1=0.8663, Recall=0.8631, Precision=0.8695\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2947209253880016, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.3464622926245935, margin=0.6675065653689388, lpl_weight=0.8815093050468522\n",
      " - ratio=0.17519405087187895, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2382, LPL: 1.3863, Contrastive: 0.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:16:27,293] Trial 21 finished with value: 0.862821764189752 and parameters: {'alpha': 0.2947209253880016, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.3464622926245935, 'margin': 0.6675065653689388, 'lpl_weight': 0.8815093050468522, 'ratio': 0.17519405087187895, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 13 with value: 0.8670687575392038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9169, F1=0.8619, Recall=0.8582, Precision=0.8656\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141558.csv.\n",
      "Average F1 over 5 seeds: 0.8628  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2910483051681488, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2607453687294975, margin=0.6680909645576116, lpl_weight=0.9063521227550063\n",
      " - ratio=0.16408662469403257, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2638, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 50, Loss: 1.2593, LPL: 1.3863, Contrastive: 0.0304\n",
      "Epoch 100, Loss: 1.2592, LPL: 1.3863, Contrastive: 0.0293\n",
      " - Metrics: Accuracy=0.9169, F1=0.8598, Recall=0.8435, Precision=0.8767\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2910483051681488, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2607453687294975, margin=0.6680909645576116, lpl_weight=0.9063521227550063\n",
      " - ratio=0.16408662469403257, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2638, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 50, Loss: 1.2593, LPL: 1.3863, Contrastive: 0.0304\n",
      "Epoch 100, Loss: 1.2592, LPL: 1.3863, Contrastive: 0.0293\n",
      " - Metrics: Accuracy=0.9169, F1=0.8598, Recall=0.8435, Precision=0.8767\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2910483051681488, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2607453687294975, margin=0.6680909645576116, lpl_weight=0.9063521227550063\n",
      " - ratio=0.16408662469403257, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2638, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 50, Loss: 1.2593, LPL: 1.3863, Contrastive: 0.0304\n",
      "Epoch 100, Loss: 1.2592, LPL: 1.3863, Contrastive: 0.0293\n",
      " - Metrics: Accuracy=0.9258, F1=0.8748, Recall=0.8582, Precision=0.8920\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2910483051681488, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2607453687294975, margin=0.6680909645576116, lpl_weight=0.9063521227550063\n",
      " - ratio=0.16408662469403257, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2638, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 50, Loss: 1.2593, LPL: 1.3863, Contrastive: 0.0304\n",
      "Epoch 100, Loss: 1.2592, LPL: 1.3863, Contrastive: 0.0293\n",
      " - Metrics: Accuracy=0.9221, F1=0.8685, Recall=0.8521, Precision=0.8856\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2910483051681488, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2607453687294975, margin=0.6680909645576116, lpl_weight=0.9063521227550063\n",
      " - ratio=0.16408662469403257, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2638, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 50, Loss: 1.2593, LPL: 1.3863, Contrastive: 0.0304\n",
      "Epoch 100, Loss: 1.2592, LPL: 1.3863, Contrastive: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:17:35,073] Trial 22 finished with value: 0.8675389408099689 and parameters: {'alpha': 0.2910483051681488, 'K': 33, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.2607453687294975, 'margin': 0.6680909645576116, 'lpl_weight': 0.9063521227550063, 'ratio': 0.16408662469403257, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8675389408099689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9258, F1=0.8748, Recall=0.8582, Precision=0.8920\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141627.csv.\n",
      "Average F1 over 5 seeds: 0.8675  0.0067\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2742555773431236, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2608333355581629, margin=0.6640062733768757, lpl_weight=0.9964119023649477\n",
      " - ratio=0.2326917727772408, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3816, LPL: 1.3863, Contrastive: 0.0788\n",
      "Epoch 50, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0312\n",
      "Epoch 100, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0301\n",
      " - Metrics: Accuracy=0.8951, F1=0.8388, Recall=0.9034, Precision=0.7828\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2742555773431236, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2608333355581629, margin=0.6640062733768757, lpl_weight=0.9964119023649477\n",
      " - ratio=0.2326917727772408, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3816, LPL: 1.3863, Contrastive: 0.0788\n",
      "Epoch 50, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0312\n",
      "Epoch 100, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0301\n",
      " - Metrics: Accuracy=0.8996, F1=0.8456, Recall=0.9108, Precision=0.7892\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2742555773431236, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2608333355581629, margin=0.6640062733768757, lpl_weight=0.9964119023649477\n",
      " - ratio=0.2326917727772408, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3816, LPL: 1.3863, Contrastive: 0.0788\n",
      "Epoch 50, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0312\n",
      "Epoch 100, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0301\n",
      " - Metrics: Accuracy=0.8988, F1=0.8445, Recall=0.9095, Precision=0.7881\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2742555773431236, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2608333355581629, margin=0.6640062733768757, lpl_weight=0.9964119023649477\n",
      " - ratio=0.2326917727772408, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3816, LPL: 1.3863, Contrastive: 0.0788\n",
      "Epoch 50, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0312\n",
      "Epoch 100, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0303\n",
      " - Metrics: Accuracy=0.8996, F1=0.8456, Recall=0.9108, Precision=0.7892\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2742555773431236, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2608333355581629, margin=0.6640062733768757, lpl_weight=0.9964119023649477\n",
      " - ratio=0.2326917727772408, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3816, LPL: 1.3863, Contrastive: 0.0788\n",
      "Epoch 50, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0312\n",
      "Epoch 100, Loss: 1.3814, LPL: 1.3863, Contrastive: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:18:42,752] Trial 23 finished with value: 0.8463110102156639 and parameters: {'alpha': 0.2742555773431236, 'K': 33, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.2608333355581629, 'margin': 0.6640062733768757, 'lpl_weight': 0.9964119023649477, 'ratio': 0.2326917727772408, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8675389408099689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9069, F1=0.8570, Recall=0.9230, Precision=0.7998\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141735.csv.\n",
      "Average F1 over 5 seeds: 0.8463  0.0059\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.17643378103294696, K=35, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2712559308160032, margin=0.7596091345805168, lpl_weight=0.87463101911725\n",
      " - ratio=0.14769407863515555, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2225, LPL: 1.3863, Contrastive: 0.0799\n",
      " - Metrics: Accuracy=0.8900, F1=0.8099, Recall=0.7763, Precision=0.8467\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.17643378103294696, K=35, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2712559308160032, margin=0.7596091345805168, lpl_weight=0.87463101911725\n",
      " - ratio=0.14769407863515555, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2225, LPL: 1.3863, Contrastive: 0.0799\n",
      " - Metrics: Accuracy=0.8833, F1=0.7982, Recall=0.7641, Precision=0.8356\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.17643378103294696, K=35, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2712559308160032, margin=0.7596091345805168, lpl_weight=0.87463101911725\n",
      " - ratio=0.14769407863515555, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2225, LPL: 1.3863, Contrastive: 0.0799\n",
      " - Metrics: Accuracy=0.8748, F1=0.7837, Recall=0.7506, Precision=0.8198\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.17643378103294696, K=35, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2712559308160032, margin=0.7596091345805168, lpl_weight=0.87463101911725\n",
      " - ratio=0.14769407863515555, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2225, LPL: 1.3863, Contrastive: 0.0799\n",
      " - Metrics: Accuracy=0.8874, F1=0.8054, Recall=0.7714, Precision=0.8425\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.17643378103294696, K=35, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.2712559308160032, margin=0.7596091345805168, lpl_weight=0.87463101911725\n",
      " - ratio=0.14769407863515555, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2225, LPL: 1.3863, Contrastive: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:19:12,965] Trial 24 finished with value: 0.7993347482029143 and parameters: {'alpha': 0.17643378103294696, 'K': 35, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.2712559308160032, 'margin': 0.7596091345805168, 'lpl_weight': 0.87463101911725, 'ratio': 0.14769407863515555, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8675389408099689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8840, F1=0.7995, Recall=0.7653, Precision=0.8369\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141842.csv.\n",
      "Average F1 over 5 seeds: 0.7993  0.0089\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.39661498906175524, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3230304537456621, margin=0.621074709249795, lpl_weight=0.9163520140510406\n",
      " - ratio=0.10005787718176562, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2779, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 50, Loss: 1.2736, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 100, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.0378\n",
      " - Metrics: Accuracy=0.9117, F1=0.8360, Recall=0.7445, Precision=0.9531\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.39661498906175524, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3230304537456621, margin=0.621074709249795, lpl_weight=0.9163520140510406\n",
      " - ratio=0.10005787718176562, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2779, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 50, Loss: 1.2736, LPL: 1.3863, Contrastive: 0.0391\n",
      "Epoch 100, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.0378\n",
      " - Metrics: Accuracy=0.9051, F1=0.8236, Recall=0.7335, Precision=0.9390\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.39661498906175524, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3230304537456621, margin=0.621074709249795, lpl_weight=0.9163520140510406\n",
      " - ratio=0.10005787718176562, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2779, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 50, Loss: 1.2736, LPL: 1.3863, Contrastive: 0.0391\n",
      "Epoch 100, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.0378\n",
      " - Metrics: Accuracy=0.9103, F1=0.8332, Recall=0.7421, Precision=0.9499\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.39661498906175524, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3230304537456621, margin=0.621074709249795, lpl_weight=0.9163520140510406\n",
      " - ratio=0.10005787718176562, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2779, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 50, Loss: 1.2736, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 100, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.0378\n",
      " - Metrics: Accuracy=0.9066, F1=0.8264, Recall=0.7359, Precision=0.9421\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.39661498906175524, K=33, layers=3, hidden=128, out=128\n",
      " - norm=None, dropout=0.3230304537456621, margin=0.621074709249795, lpl_weight=0.9163520140510406\n",
      " - ratio=0.10005787718176562, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2779, LPL: 1.3863, Contrastive: 0.0909\n",
      "Epoch 50, Loss: 1.2736, LPL: 1.3863, Contrastive: 0.0391\n",
      "Epoch 100, Loss: 1.2735, LPL: 1.3863, Contrastive: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:20:12,033] Trial 25 finished with value: 0.8286649520692073 and parameters: {'alpha': 0.39661498906175524, 'K': 33, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.3230304537456621, 'margin': 0.621074709249795, 'lpl_weight': 0.9163520140510406, 'ratio': 0.10005787718176562, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8675389408099689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9055, F1=0.8242, Recall=0.7335, Precision=0.9404\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102141913.csv.\n",
      "Average F1 over 5 seeds: 0.8287  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10134962372930018, K=32, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.4039440112665329, margin=0.5213436605653284, lpl_weight=0.738885859181731\n",
      " - ratio=0.22843021022204707, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0539, LPL: 1.3863, Contrastive: 0.1132\n",
      "Epoch 50, Loss: 1.0405, LPL: 1.3863, Contrastive: 0.0622\n",
      "Epoch 100, Loss: 1.0403, LPL: 1.3863, Contrastive: 0.0611\n",
      " - Metrics: Accuracy=0.8936, F1=0.8356, Recall=0.8949, Precision=0.7837\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10134962372930018, K=32, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.4039440112665329, margin=0.5213436605653284, lpl_weight=0.738885859181731\n",
      " - ratio=0.22843021022204707, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0539, LPL: 1.3863, Contrastive: 0.1132\n",
      "Epoch 50, Loss: 1.0405, LPL: 1.3863, Contrastive: 0.0622\n",
      "Epoch 100, Loss: 1.0402, LPL: 1.3863, Contrastive: 0.0609\n",
      "Epoch 150, Loss: 1.0402, LPL: 1.3863, Contrastive: 0.0607\n",
      " - Metrics: Accuracy=0.9018, F1=0.8482, Recall=0.9083, Precision=0.7955\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10134962372930018, K=32, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.4039440112665329, margin=0.5213436605653284, lpl_weight=0.738885859181731\n",
      " - ratio=0.22843021022204707, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0539, LPL: 1.3863, Contrastive: 0.1132\n",
      "Epoch 50, Loss: 1.0405, LPL: 1.3863, Contrastive: 0.0622\n",
      "Epoch 100, Loss: 1.0402, LPL: 1.3863, Contrastive: 0.0610\n",
      " - Metrics: Accuracy=0.9003, F1=0.8459, Recall=0.9059, Precision=0.7934\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10134962372930018, K=32, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.4039440112665329, margin=0.5213436605653284, lpl_weight=0.738885859181731\n",
      " - ratio=0.22843021022204707, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0539, LPL: 1.3863, Contrastive: 0.1132\n",
      "Epoch 50, Loss: 1.0405, LPL: 1.3863, Contrastive: 0.0622\n",
      "Epoch 100, Loss: 1.0402, LPL: 1.3863, Contrastive: 0.0609\n",
      "Epoch 150, Loss: 1.0404, LPL: 1.3863, Contrastive: 0.0616\n",
      " - Metrics: Accuracy=0.8988, F1=0.8436, Recall=0.9034, Precision=0.7912\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10134962372930018, K=32, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.4039440112665329, margin=0.5213436605653284, lpl_weight=0.738885859181731\n",
      " - ratio=0.22843021022204707, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0539, LPL: 1.3863, Contrastive: 0.1132\n",
      "Epoch 50, Loss: 1.0405, LPL: 1.3863, Contrastive: 0.0622\n",
      "Epoch 100, Loss: 1.0403, LPL: 1.3863, Contrastive: 0.0611\n",
      "Epoch 150, Loss: 1.0402, LPL: 1.3863, Contrastive: 0.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:21:17,835] Trial 26 finished with value: 0.8445205479452055 and parameters: {'alpha': 0.10134962372930018, 'K': 32, 'layers': 3, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.4039440112665329, 'margin': 0.5213436605653284, 'lpl_weight': 0.738885859181731, 'ratio': 0.22843021022204707, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8675389408099689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9025, F1=0.8493, Recall=0.9095, Precision=0.7966\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142012.csv.\n",
      "Average F1 over 5 seeds: 0.8445  0.0049\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4520492550518159, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.450210919886853, margin=0.7543305249565393, lpl_weight=0.841470673136221\n",
      " - ratio=0.27808256533211584, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1916, LPL: 1.3863, Contrastive: 0.1584\n",
      " - Metrics: Accuracy=0.8593, F1=0.7959, Recall=0.9083, Precision=0.7083\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4520492550518159, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.450210919886853, margin=0.7543305249565393, lpl_weight=0.841470673136221\n",
      " - ratio=0.27808256533211584, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1916, LPL: 1.3863, Contrastive: 0.1584\n",
      " - Metrics: Accuracy=0.8549, F1=0.7895, Recall=0.9010, Precision=0.7026\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4520492550518159, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.450210919886853, margin=0.7543305249565393, lpl_weight=0.841470673136221\n",
      " - ratio=0.27808256533211584, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1916, LPL: 1.3863, Contrastive: 0.1584\n",
      " - Metrics: Accuracy=0.8497, F1=0.7820, Recall=0.8924, Precision=0.6959\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4520492550518159, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.450210919886853, margin=0.7543305249565393, lpl_weight=0.841470673136221\n",
      " - ratio=0.27808256533211584, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1916, LPL: 1.3863, Contrastive: 0.1584\n",
      " - Metrics: Accuracy=0.8541, F1=0.7884, Recall=0.8998, Precision=0.7016\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4520492550518159, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.450210919886853, margin=0.7543305249565393, lpl_weight=0.841470673136221\n",
      " - ratio=0.27808256533211584, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1916, LPL: 1.3863, Contrastive: 0.1584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:21:48,871] Trial 27 finished with value: 0.7903588644884841 and parameters: {'alpha': 0.4520492550518159, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.450210919886853, 'margin': 0.7543305249565393, 'lpl_weight': 0.841470673136221, 'ratio': 0.27808256533211584, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8675389408099689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8593, F1=0.7959, Recall=0.9083, Precision=0.7083\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142117.csv.\n",
      "Average F1 over 5 seeds: 0.7904  0.0052\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.32626575553335363, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.28547411547169055, margin=0.993518582555353, lpl_weight=0.9505611177171108\n",
      " - ratio=0.17837449811262052, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3240, LPL: 1.3863, Contrastive: 0.1267\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9136, F1=0.8571, Recall=0.8582, Precision=0.8561\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.32626575553335363, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.28547411547169055, margin=0.993518582555353, lpl_weight=0.9505611177171108\n",
      " - ratio=0.17837449811262052, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3240, LPL: 1.3863, Contrastive: 0.1267\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9177, F1=0.8638, Recall=0.8643, Precision=0.8632\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.32626575553335363, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.28547411547169055, margin=0.993518582555353, lpl_weight=0.9505611177171108\n",
      " - ratio=0.17837449811262052, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3240, LPL: 1.3863, Contrastive: 0.1267\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9162, F1=0.8613, Recall=0.8619, Precision=0.8608\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.32626575553335363, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.28547411547169055, margin=0.993518582555353, lpl_weight=0.9505611177171108\n",
      " - ratio=0.17837449811262052, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3240, LPL: 1.3863, Contrastive: 0.1267\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.9117, F1=0.8540, Recall=0.8545, Precision=0.8535\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.32626575553335363, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.28547411547169055, margin=0.993518582555353, lpl_weight=0.9505611177171108\n",
      " - ratio=0.17837449811262052, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3240, LPL: 1.3863, Contrastive: 0.1267\n",
      "Epoch 50, Loss: 1.3178, LPL: 1.3863, Contrastive: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:22:37,995] Trial 28 finished with value: 0.8610888271590582 and parameters: {'alpha': 0.32626575553335363, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.28547411547169055, 'margin': 0.993518582555353, 'lpl_weight': 0.9505611177171108, 'ratio': 0.17837449811262052, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8675389408099689.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9210, F1=0.8692, Recall=0.8692, Precision=0.8692\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142148.csv.\n",
      "Average F1 over 5 seeds: 0.8611  0.0053\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.16107195481833164, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2359693325559022, margin=0.5723905535808865, lpl_weight=0.7222590327396654\n",
      " - ratio=0.15526305838265766, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0361, LPL: 1.3863, Contrastive: 0.1256\n",
      " - Metrics: Accuracy=0.9380, F1=0.8916, Recall=0.8447, Precision=0.9440\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.16107195481833164, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2359693325559022, margin=0.5723905535808865, lpl_weight=0.7222590327396654\n",
      " - ratio=0.15526305838265766, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0361, LPL: 1.3863, Contrastive: 0.1256\n",
      " - Metrics: Accuracy=0.9361, F1=0.8890, Recall=0.8472, Precision=0.9352\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.16107195481833164, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2359693325559022, margin=0.5723905535808865, lpl_weight=0.7222590327396654\n",
      " - ratio=0.15526305838265766, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0361, LPL: 1.3863, Contrastive: 0.1256\n",
      " - Metrics: Accuracy=0.9350, F1=0.8862, Recall=0.8374, Precision=0.9409\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.16107195481833164, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2359693325559022, margin=0.5723905535808865, lpl_weight=0.7222590327396654\n",
      " - ratio=0.15526305838265766, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0361, LPL: 1.3863, Contrastive: 0.1256\n",
      " - Metrics: Accuracy=0.9383, F1=0.8919, Recall=0.8423, Precision=0.9477\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.16107195481833164, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2359693325559022, margin=0.5723905535808865, lpl_weight=0.7222590327396654\n",
      " - ratio=0.15526305838265766, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0361, LPL: 1.3863, Contrastive: 0.1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:23:09,297] Trial 29 finished with value: 0.8897204159684101 and parameters: {'alpha': 0.16107195481833164, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.2359693325559022, 'margin': 0.5723905535808865, 'lpl_weight': 0.7222590327396654, 'ratio': 0.15526305838265766, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 29 with value: 0.8897204159684101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9369, F1=0.8899, Recall=0.8447, Precision=0.9401\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142238.csv.\n",
      "Average F1 over 5 seeds: 0.8897  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.19973313425177092, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2361342326662837, margin=0.5862449610067738, lpl_weight=0.7180443205641128\n",
      " - ratio=0.14215367589389186, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0418, LPL: 1.3863, Contrastive: 0.1646\n",
      " - Metrics: Accuracy=0.9332, F1=0.8818, Recall=0.8252, Precision=0.9467\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.19973313425177092, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2361342326662837, margin=0.5862449610067738, lpl_weight=0.7180443205641128\n",
      " - ratio=0.14215367589389186, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0418, LPL: 1.3863, Contrastive: 0.1646\n",
      " - Metrics: Accuracy=0.9354, F1=0.8857, Recall=0.8289, Precision=0.9509\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.19973313425177092, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2361342326662837, margin=0.5862449610067738, lpl_weight=0.7180443205641128\n",
      " - ratio=0.14215367589389186, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0418, LPL: 1.3863, Contrastive: 0.1646\n",
      " - Metrics: Accuracy=0.9346, F1=0.8838, Recall=0.8227, Precision=0.9546\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.19973313425177092, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2361342326662837, margin=0.5862449610067738, lpl_weight=0.7180443205641128\n",
      " - ratio=0.14215367589389186, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0418, LPL: 1.3863, Contrastive: 0.1646\n",
      " - Metrics: Accuracy=0.9328, F1=0.8801, Recall=0.8166, Precision=0.9543\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.19973313425177092, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2361342326662837, margin=0.5862449610067738, lpl_weight=0.7180443205641128\n",
      " - ratio=0.14215367589389186, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0418, LPL: 1.3863, Contrastive: 0.1646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:23:36,047] Trial 30 finished with value: 0.883070374869002 and parameters: {'alpha': 0.19973313425177092, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.2361342326662837, 'margin': 0.5862449610067738, 'lpl_weight': 0.7180443205641128, 'ratio': 0.14215367589389186, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 29 with value: 0.8897204159684101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9339, F1=0.8840, Recall=0.8337, Precision=0.9407\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142309.csv.\n",
      "Average F1 over 5 seeds: 0.8831  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.14995936043376173, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.23524599777750838, margin=0.5913502188678587, lpl_weight=0.7182898620987102\n",
      " - ratio=0.14231166015577384, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0421, LPL: 1.3863, Contrastive: 0.1643\n",
      " - Metrics: Accuracy=0.9313, F1=0.8789, Recall=0.8252, Precision=0.9401\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.14995936043376173, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.23524599777750838, margin=0.5913502188678587, lpl_weight=0.7182898620987102\n",
      " - ratio=0.14231166015577384, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0421, LPL: 1.3863, Contrastive: 0.1643\n",
      " - Metrics: Accuracy=0.9309, F1=0.8782, Recall=0.8240, Precision=0.9400\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.14995936043376173, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.23524599777750838, margin=0.5913502188678587, lpl_weight=0.7182898620987102\n",
      " - ratio=0.14231166015577384, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0421, LPL: 1.3863, Contrastive: 0.1643\n",
      " - Metrics: Accuracy=0.9332, F1=0.8808, Recall=0.8178, Precision=0.9544\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.14995936043376173, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.23524599777750838, margin=0.5913502188678587, lpl_weight=0.7182898620987102\n",
      " - ratio=0.14231166015577384, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0421, LPL: 1.3863, Contrastive: 0.1643\n",
      " - Metrics: Accuracy=0.9328, F1=0.8804, Recall=0.8191, Precision=0.9517\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.14995936043376173, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.23524599777750838, margin=0.5913502188678587, lpl_weight=0.7182898620987102\n",
      " - ratio=0.14231166015577384, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0421, LPL: 1.3863, Contrastive: 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:24:02,924] Trial 31 finished with value: 0.8804072026010112 and parameters: {'alpha': 0.14995936043376173, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.23524599777750838, 'margin': 0.5913502188678587, 'lpl_weight': 0.7182898620987102, 'ratio': 0.14231166015577384, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 29 with value: 0.8897204159684101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9339, F1=0.8837, Recall=0.8313, Precision=0.9431\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142336.csv.\n",
      "Average F1 over 5 seeds: 0.8804  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.17337917402450628, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2314012594702975, margin=0.6003642586510636, lpl_weight=0.7173409622138935\n",
      " - ratio=0.15018040750911552, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0408, LPL: 1.3863, Contrastive: 0.1639\n",
      " - Metrics: Accuracy=0.9321, F1=0.8805, Recall=0.8289, Precision=0.9391\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.17337917402450628, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2314012594702975, margin=0.6003642586510636, lpl_weight=0.7173409622138935\n",
      " - ratio=0.15018040750911552, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0408, LPL: 1.3863, Contrastive: 0.1639\n",
      " - Metrics: Accuracy=0.9369, F1=0.8896, Recall=0.8423, Precision=0.9425\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.17337917402450628, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2314012594702975, margin=0.6003642586510636, lpl_weight=0.7173409622138935\n",
      " - ratio=0.15018040750911552, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0408, LPL: 1.3863, Contrastive: 0.1639\n",
      " - Metrics: Accuracy=0.9350, F1=0.8853, Recall=0.8301, Precision=0.9483\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.17337917402450628, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2314012594702975, margin=0.6003642586510636, lpl_weight=0.7173409622138935\n",
      " - ratio=0.15018040750911552, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0408, LPL: 1.3863, Contrastive: 0.1639\n",
      " - Metrics: Accuracy=0.9332, F1=0.8824, Recall=0.8301, Precision=0.9417\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.17337917402450628, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2314012594702975, margin=0.6003642586510636, lpl_weight=0.7173409622138935\n",
      " - ratio=0.15018040750911552, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0408, LPL: 1.3863, Contrastive: 0.1639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:24:29,802] Trial 32 finished with value: 0.8837226263602055 and parameters: {'alpha': 0.17337917402450628, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.2314012594702975, 'margin': 0.6003642586510636, 'lpl_weight': 0.7173409622138935, 'ratio': 0.15018040750911552, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 29 with value: 0.8897204159684101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9321, F1=0.8808, Recall=0.8313, Precision=0.9366\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142402.csv.\n",
      "Average F1 over 5 seeds: 0.8837  0.0034\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.180782462577263, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.22890363303744432, margin=0.5879862967849245, lpl_weight=0.7177817890871232\n",
      " - ratio=0.12088118664133138, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0412, LPL: 1.3863, Contrastive: 0.1635\n",
      " - Metrics: Accuracy=0.9258, F1=0.8650, Recall=0.7873, Precision=0.9598\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.180782462577263, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.22890363303744432, margin=0.5879862967849245, lpl_weight=0.7177817890871232\n",
      " - ratio=0.12088118664133138, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0412, LPL: 1.3863, Contrastive: 0.1635\n",
      " - Metrics: Accuracy=0.9269, F1=0.8673, Recall=0.7910, Precision=0.9599\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.180782462577263, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.22890363303744432, margin=0.5879862967849245, lpl_weight=0.7177817890871232\n",
      " - ratio=0.12088118664133138, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0412, LPL: 1.3863, Contrastive: 0.1635\n",
      " - Metrics: Accuracy=0.9287, F1=0.8706, Recall=0.7934, Precision=0.9643\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.180782462577263, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.22890363303744432, margin=0.5879862967849245, lpl_weight=0.7177817890871232\n",
      " - ratio=0.12088118664133138, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0412, LPL: 1.3863, Contrastive: 0.1635\n",
      " - Metrics: Accuracy=0.9258, F1=0.8650, Recall=0.7873, Precision=0.9598\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.180782462577263, K=30, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.22890363303744432, margin=0.5879862967849245, lpl_weight=0.7177817890871232\n",
      " - ratio=0.12088118664133138, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0412, LPL: 1.3863, Contrastive: 0.1635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:24:57,183] Trial 33 finished with value: 0.8679396303597562 and parameters: {'alpha': 0.180782462577263, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.22890363303744432, 'margin': 0.5879862967849245, 'lpl_weight': 0.7177817890871232, 'ratio': 0.12088118664133138, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 29 with value: 0.8897204159684101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9291, F1=0.8718, Recall=0.7983, Precision=0.9603\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142429.csv.\n",
      "Average F1 over 5 seeds: 0.8679  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.15383915051257807, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16265810979839168, margin=0.5662957039051271, lpl_weight=0.5735317681671238\n",
      " - ratio=0.1385688750871457, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8614, LPL: 1.3863, Contrastive: 0.1556\n",
      " - Metrics: Accuracy=0.9369, F1=0.8885, Recall=0.8325, Precision=0.9524\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.15383915051257807, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16265810979839168, margin=0.5662957039051271, lpl_weight=0.5735317681671238\n",
      " - ratio=0.1385688750871457, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8614, LPL: 1.3863, Contrastive: 0.1556\n",
      " - Metrics: Accuracy=0.9321, F1=0.8801, Recall=0.8252, Precision=0.9427\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.15383915051257807, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16265810979839168, margin=0.5662957039051271, lpl_weight=0.5735317681671238\n",
      " - ratio=0.1385688750871457, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8614, LPL: 1.3863, Contrastive: 0.1556\n",
      " - Metrics: Accuracy=0.9369, F1=0.8882, Recall=0.8301, Precision=0.9550\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.15383915051257807, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16265810979839168, margin=0.5662957039051271, lpl_weight=0.5735317681671238\n",
      " - ratio=0.1385688750871457, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8614, LPL: 1.3863, Contrastive: 0.1556\n",
      " - Metrics: Accuracy=0.9376, F1=0.8892, Recall=0.8289, Precision=0.9590\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.15383915051257807, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16265810979839168, margin=0.5662957039051271, lpl_weight=0.5735317681671238\n",
      " - ratio=0.1385688750871457, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8614, LPL: 1.3863, Contrastive: 0.1556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:25:24,409] Trial 34 finished with value: 0.8858776101516236 and parameters: {'alpha': 0.15383915051257807, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.16265810979839168, 'margin': 0.5662957039051271, 'lpl_weight': 0.5735317681671238, 'ratio': 0.1385688750871457, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 29 with value: 0.8897204159684101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9339, F1=0.8835, Recall=0.8301, Precision=0.9444\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142457.csv.\n",
      "Average F1 over 5 seeds: 0.8859  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.21940311645206306, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1672703673883987, margin=0.5381962955907098, lpl_weight=0.5649018244930006\n",
      " - ratio=0.10706575704933416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8513, LPL: 1.3863, Contrastive: 0.1567\n",
      " - Metrics: Accuracy=0.9213, F1=0.8546, Recall=0.7653, Precision=0.9675\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.21940311645206306, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1672703673883987, margin=0.5381962955907098, lpl_weight=0.5649018244930006\n",
      " - ratio=0.10706575704933416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8513, LPL: 1.3863, Contrastive: 0.1567\n",
      " - Metrics: Accuracy=0.9188, F1=0.8491, Recall=0.7567, Precision=0.9672\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.21940311645206306, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1672703673883987, margin=0.5381962955907098, lpl_weight=0.5649018244930006\n",
      " - ratio=0.10706575704933416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8513, LPL: 1.3863, Contrastive: 0.1567\n",
      " - Metrics: Accuracy=0.9254, F1=0.8620, Recall=0.7714, Precision=0.9768\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.21940311645206306, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1672703673883987, margin=0.5381962955907098, lpl_weight=0.5649018244930006\n",
      " - ratio=0.10706575704933416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8513, LPL: 1.3863, Contrastive: 0.1567\n",
      " - Metrics: Accuracy=0.9213, F1=0.8546, Recall=0.7653, Precision=0.9675\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.21940311645206306, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1672703673883987, margin=0.5381962955907098, lpl_weight=0.5649018244930006\n",
      " - ratio=0.10706575704933416, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8513, LPL: 1.3863, Contrastive: 0.1567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:25:51,638] Trial 35 finished with value: 0.8553028590206602 and parameters: {'alpha': 0.21940311645206306, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.1672703673883987, 'margin': 0.5381962955907098, 'lpl_weight': 0.5649018244930006, 'ratio': 0.10706575704933416, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 29 with value: 0.8897204159684101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9221, F1=0.8562, Recall=0.7677, Precision=0.9676\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142524.csv.\n",
      "Average F1 over 5 seeds: 0.8553  0.0041\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.22902678456162948, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16587207213667154, margin=0.46309513959356946, lpl_weight=0.5771946043097365\n",
      " - ratio=0.21605128942845014, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8676, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 0.8326, LPL: 1.3863, Contrastive: 0.0767\n",
      "Epoch 100, Loss: 0.8317, LPL: 1.3863, Contrastive: 0.0745\n",
      "Epoch 150, Loss: 0.8315, LPL: 1.3863, Contrastive: 0.0742\n",
      " - Metrics: Accuracy=0.9365, F1=0.8950, Recall=0.8961, Precision=0.8939\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.22902678456162948, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16587207213667154, margin=0.46309513959356946, lpl_weight=0.5771946043097365\n",
      " - ratio=0.21605128942845014, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8676, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 0.8326, LPL: 1.3863, Contrastive: 0.0767\n",
      "Epoch 100, Loss: 0.8317, LPL: 1.3863, Contrastive: 0.0745\n",
      "Epoch 150, Loss: 0.8315, LPL: 1.3863, Contrastive: 0.0742\n",
      " - Metrics: Accuracy=0.9280, F1=0.8817, Recall=0.8888, Precision=0.8748\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.22902678456162948, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16587207213667154, margin=0.46309513959356946, lpl_weight=0.5771946043097365\n",
      " - ratio=0.21605128942845014, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8676, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 0.8326, LPL: 1.3863, Contrastive: 0.0767\n",
      "Epoch 100, Loss: 0.8317, LPL: 1.3863, Contrastive: 0.0745\n",
      "Epoch 150, Loss: 0.8315, LPL: 1.3863, Contrastive: 0.0742\n",
      " - Metrics: Accuracy=0.9417, F1=0.9038, Recall=0.9071, Precision=0.9005\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.22902678456162948, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16587207213667154, margin=0.46309513959356946, lpl_weight=0.5771946043097365\n",
      " - ratio=0.21605128942845014, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8676, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 0.8326, LPL: 1.3863, Contrastive: 0.0767\n",
      "Epoch 100, Loss: 0.8317, LPL: 1.3863, Contrastive: 0.0745\n",
      "Epoch 150, Loss: 0.8315, LPL: 1.3863, Contrastive: 0.0742\n",
      " - Metrics: Accuracy=0.9365, F1=0.8942, Recall=0.8888, Precision=0.8998\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.22902678456162948, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16587207213667154, margin=0.46309513959356946, lpl_weight=0.5771946043097365\n",
      " - ratio=0.21605128942845014, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8676, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 0.8326, LPL: 1.3863, Contrastive: 0.0767\n",
      "Epoch 100, Loss: 0.8317, LPL: 1.3863, Contrastive: 0.0745\n",
      "Epoch 150, Loss: 0.8316, LPL: 1.3863, Contrastive: 0.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:26:58,214] Trial 36 finished with value: 0.8939391535191493 and parameters: {'alpha': 0.22902678456162948, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.16587207213667154, 'margin': 0.46309513959356946, 'lpl_weight': 0.5771946043097365, 'ratio': 0.21605128942845014, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 36 with value: 0.8939391535191493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9361, F1=0.8950, Recall=0.9010, Precision=0.8890\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142551.csv.\n",
      "Average F1 over 5 seeds: 0.8939  0.0070\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.24849362424773241, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16650019165151517, margin=0.47306459320093475, lpl_weight=0.5137043056082752\n",
      " - ratio=0.216382827325318, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7527, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.7466, LPL: 1.3863, Contrastive: 0.0710\n",
      "Epoch 100, Loss: 0.7465, LPL: 1.3863, Contrastive: 0.0707\n",
      " - Metrics: Accuracy=0.9121, F1=0.8409, Recall=0.7689, Precision=0.9277\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.24849362424773241, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16650019165151517, margin=0.47306459320093475, lpl_weight=0.5137043056082752\n",
      " - ratio=0.216382827325318, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7527, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.7466, LPL: 1.3863, Contrastive: 0.0710\n",
      "Epoch 100, Loss: 0.7465, LPL: 1.3863, Contrastive: 0.0707\n",
      " - Metrics: Accuracy=0.9143, F1=0.8476, Recall=0.7885, Precision=0.9162\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.24849362424773241, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16650019165151517, margin=0.47306459320093475, lpl_weight=0.5137043056082752\n",
      " - ratio=0.216382827325318, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7527, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.7466, LPL: 1.3863, Contrastive: 0.0710\n",
      "Epoch 100, Loss: 0.7465, LPL: 1.3863, Contrastive: 0.0707\n",
      " - Metrics: Accuracy=0.9140, F1=0.8441, Recall=0.7714, Precision=0.9321\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.24849362424773241, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16650019165151517, margin=0.47306459320093475, lpl_weight=0.5137043056082752\n",
      " - ratio=0.216382827325318, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7527, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.7466, LPL: 1.3863, Contrastive: 0.0710\n",
      "Epoch 100, Loss: 0.7465, LPL: 1.3863, Contrastive: 0.0707\n",
      " - Metrics: Accuracy=0.9125, F1=0.8421, Recall=0.7726, Precision=0.9253\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.24849362424773241, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.16650019165151517, margin=0.47306459320093475, lpl_weight=0.5137043056082752\n",
      " - ratio=0.216382827325318, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7527, LPL: 1.3863, Contrastive: 0.0834\n",
      "Epoch 50, Loss: 0.7466, LPL: 1.3863, Contrastive: 0.0710\n",
      "Epoch 100, Loss: 0.7465, LPL: 1.3863, Contrastive: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:27:57,717] Trial 37 finished with value: 0.8417239517874829 and parameters: {'alpha': 0.24849362424773241, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.16650019165151517, 'margin': 0.47306459320093475, 'lpl_weight': 0.5137043056082752, 'ratio': 0.216382827325318, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 36 with value: 0.8939391535191493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9081, F1=0.8339, Recall=0.7641, Precision=0.9178\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142658.csv.\n",
      "Average F1 over 5 seeds: 0.8417  0.0045\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.14206121779048367, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.12899515763840286, margin=0.337768261953467, lpl_weight=0.5782840375884917\n",
      " - ratio=0.4866777098488266, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8724, LPL: 1.3863, Contrastive: 0.1678\n",
      "Epoch 50, Loss: 0.8504, LPL: 1.3863, Contrastive: 0.1156\n",
      "Epoch 100, Loss: 0.8492, LPL: 1.3863, Contrastive: 0.1127\n",
      "Epoch 150, Loss: 0.8489, LPL: 1.3863, Contrastive: 0.1121\n",
      "Epoch 200, Loss: 0.8487, LPL: 1.3863, Contrastive: 0.1116\n",
      " - Metrics: Accuracy=0.8955, F1=0.8476, Recall=0.9621, Precision=0.7575\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.14206121779048367, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.12899515763840286, margin=0.337768261953467, lpl_weight=0.5782840375884917\n",
      " - ratio=0.4866777098488266, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8724, LPL: 1.3863, Contrastive: 0.1678\n",
      "Epoch 50, Loss: 0.8504, LPL: 1.3863, Contrastive: 0.1156\n",
      "Epoch 100, Loss: 0.8492, LPL: 1.3863, Contrastive: 0.1127\n",
      "Epoch 150, Loss: 0.8489, LPL: 1.3863, Contrastive: 0.1120\n",
      "Epoch 200, Loss: 0.8487, LPL: 1.3863, Contrastive: 0.1116\n",
      " - Metrics: Accuracy=0.8840, F1=0.8312, Recall=0.9450, Precision=0.7418\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.14206121779048367, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.12899515763840286, margin=0.337768261953467, lpl_weight=0.5782840375884917\n",
      " - ratio=0.4866777098488266, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8724, LPL: 1.3863, Contrastive: 0.1678\n",
      "Epoch 50, Loss: 0.8504, LPL: 1.3863, Contrastive: 0.1156\n",
      "Epoch 100, Loss: 0.8492, LPL: 1.3863, Contrastive: 0.1127\n",
      "Epoch 150, Loss: 0.8489, LPL: 1.3863, Contrastive: 0.1120\n",
      "Epoch 200, Loss: 0.8487, LPL: 1.3863, Contrastive: 0.1116\n",
      " - Metrics: Accuracy=0.8840, F1=0.8323, Recall=0.9523, Precision=0.7391\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.14206121779048367, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.12899515763840286, margin=0.337768261953467, lpl_weight=0.5782840375884917\n",
      " - ratio=0.4866777098488266, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8724, LPL: 1.3863, Contrastive: 0.1678\n",
      "Epoch 50, Loss: 0.8504, LPL: 1.3863, Contrastive: 0.1156\n",
      "Epoch 100, Loss: 0.8492, LPL: 1.3863, Contrastive: 0.1127\n",
      "Epoch 150, Loss: 0.8489, LPL: 1.3863, Contrastive: 0.1121\n",
      "Epoch 200, Loss: 0.8487, LPL: 1.3863, Contrastive: 0.1116\n",
      " - Metrics: Accuracy=0.8903, F1=0.8385, Recall=0.9425, Precision=0.7551\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.14206121779048367, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.12899515763840286, margin=0.337768261953467, lpl_weight=0.5782840375884917\n",
      " - ratio=0.4866777098488266, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8724, LPL: 1.3863, Contrastive: 0.1678\n",
      "Epoch 50, Loss: 0.8504, LPL: 1.3863, Contrastive: 0.1156\n",
      "Epoch 100, Loss: 0.8492, LPL: 1.3863, Contrastive: 0.1127\n",
      "Epoch 150, Loss: 0.8489, LPL: 1.3863, Contrastive: 0.1120\n",
      "Epoch 200, Loss: 0.8488, LPL: 1.3863, Contrastive: 0.1116\n",
      "Epoch 250, Loss: 0.8487, LPL: 1.3863, Contrastive: 0.1116\n",
      "Epoch 300, Loss: 0.8487, LPL: 1.3863, Contrastive: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:29:33,436] Trial 38 finished with value: 0.8373721588702205 and parameters: {'alpha': 0.14206121779048367, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.12899515763840286, 'margin': 0.337768261953467, 'lpl_weight': 0.5782840375884917, 'ratio': 0.4866777098488266, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 36 with value: 0.8939391535191493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8892, F1=0.8373, Recall=0.9438, Precision=0.7524\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142757.csv.\n",
      "Average F1 over 5 seeds: 0.8374  0.0058\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.22921108605652063, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.10571490859700755, margin=0.4589752835477431, lpl_weight=0.3786424871048111\n",
      " - ratio=0.12902200457495167, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5762, LPL: 1.3863, Contrastive: 0.0826\n",
      "Epoch 50, Loss: 0.5713, LPL: 1.3863, Contrastive: 0.0747\n",
      "Epoch 100, Loss: 0.5712, LPL: 1.3863, Contrastive: 0.0745\n",
      " - Metrics: Accuracy=0.8977, F1=0.8026, Recall=0.6883, Precision=0.9624\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.22921108605652063, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.10571490859700755, margin=0.4589752835477431, lpl_weight=0.3786424871048111\n",
      " - ratio=0.12902200457495167, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5762, LPL: 1.3863, Contrastive: 0.0826\n",
      "Epoch 50, Loss: 0.5713, LPL: 1.3863, Contrastive: 0.0747\n",
      "Epoch 100, Loss: 0.5712, LPL: 1.3863, Contrastive: 0.0745\n",
      " - Metrics: Accuracy=0.8918, F1=0.7906, Recall=0.6760, Precision=0.9518\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.22921108605652063, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.10571490859700755, margin=0.4589752835477431, lpl_weight=0.3786424871048111\n",
      " - ratio=0.12902200457495167, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5762, LPL: 1.3863, Contrastive: 0.0826\n",
      "Epoch 50, Loss: 0.5713, LPL: 1.3863, Contrastive: 0.0747\n",
      "Epoch 100, Loss: 0.5712, LPL: 1.3863, Contrastive: 0.0745\n",
      " - Metrics: Accuracy=0.9069, F1=0.8230, Recall=0.7164, Precision=0.9670\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.22921108605652063, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.10571490859700755, margin=0.4589752835477431, lpl_weight=0.3786424871048111\n",
      " - ratio=0.12902200457495167, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5762, LPL: 1.3863, Contrastive: 0.0826\n",
      "Epoch 50, Loss: 0.5713, LPL: 1.3863, Contrastive: 0.0747\n",
      "Epoch 100, Loss: 0.5712, LPL: 1.3863, Contrastive: 0.0745\n",
      " - Metrics: Accuracy=0.9058, F1=0.8205, Recall=0.7127, Precision=0.9668\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.22921108605652063, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.10571490859700755, margin=0.4589752835477431, lpl_weight=0.3786424871048111\n",
      " - ratio=0.12902200457495167, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5762, LPL: 1.3863, Contrastive: 0.0826\n",
      "Epoch 50, Loss: 0.5713, LPL: 1.3863, Contrastive: 0.0747\n",
      "Epoch 100, Loss: 0.5712, LPL: 1.3863, Contrastive: 0.0745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:30:29,149] Trial 39 finished with value: 0.809086669762981 and parameters: {'alpha': 0.22921108605652063, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.10571490859700755, 'margin': 0.4589752835477431, 'lpl_weight': 0.3786424871048111, 'ratio': 0.12902200457495167, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 36 with value: 0.8939391535191493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8996, F1=0.8087, Recall=0.7029, Precision=0.9520\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102142933.csv.\n",
      "Average F1 over 5 seeds: 0.8091  0.0119\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.14073557935340858, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.18101528090131078, margin=0.5397136531929095, lpl_weight=0.11661795480413872\n",
      " - ratio=0.21480595303749334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3030, LPL: 1.3863, Contrastive: 0.1600\n",
      "Epoch 50, Loss: 0.2112, LPL: 1.3863, Contrastive: 0.0561\n",
      "Epoch 100, Loss: 0.2102, LPL: 1.3863, Contrastive: 0.0550\n",
      "Epoch 150, Loss: 0.2098, LPL: 1.3863, Contrastive: 0.0545\n",
      "Epoch 200, Loss: 0.2095, LPL: 1.3863, Contrastive: 0.0542\n",
      " - Metrics: Accuracy=0.9387, F1=0.8978, Recall=0.8912, Precision=0.9045\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.14073557935340858, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.18101528090131078, margin=0.5397136531929095, lpl_weight=0.11661795480413872\n",
      " - ratio=0.21480595303749334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3030, LPL: 1.3863, Contrastive: 0.1600\n",
      "Epoch 50, Loss: 0.2112, LPL: 1.3863, Contrastive: 0.0561\n",
      "Epoch 100, Loss: 0.2102, LPL: 1.3863, Contrastive: 0.0550\n",
      "Epoch 150, Loss: 0.2098, LPL: 1.3863, Contrastive: 0.0545\n",
      "Epoch 200, Loss: 0.2095, LPL: 1.3863, Contrastive: 0.0542\n",
      " - Metrics: Accuracy=0.9332, F1=0.8885, Recall=0.8814, Precision=0.8957\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.14073557935340858, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.18101528090131078, margin=0.5397136531929095, lpl_weight=0.11661795480413872\n",
      " - ratio=0.21480595303749334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3030, LPL: 1.3863, Contrastive: 0.1600\n",
      "Epoch 50, Loss: 0.2112, LPL: 1.3863, Contrastive: 0.0561\n",
      "Epoch 100, Loss: 0.2102, LPL: 1.3863, Contrastive: 0.0550\n",
      "Epoch 150, Loss: 0.2098, LPL: 1.3863, Contrastive: 0.0545\n",
      "Epoch 200, Loss: 0.2095, LPL: 1.3863, Contrastive: 0.0542\n",
      "Epoch 250, Loss: 0.2094, LPL: 1.3863, Contrastive: 0.0541\n",
      "Epoch 300, Loss: 0.2093, LPL: 1.3863, Contrastive: 0.0539\n",
      " - Metrics: Accuracy=0.9383, F1=0.8957, Recall=0.8765, Precision=0.9157\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.14073557935340858, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.18101528090131078, margin=0.5397136531929095, lpl_weight=0.11661795480413872\n",
      " - ratio=0.21480595303749334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3030, LPL: 1.3863, Contrastive: 0.1600\n",
      "Epoch 50, Loss: 0.2112, LPL: 1.3863, Contrastive: 0.0561\n",
      "Epoch 100, Loss: 0.2102, LPL: 1.3863, Contrastive: 0.0550\n",
      "Epoch 150, Loss: 0.2098, LPL: 1.3863, Contrastive: 0.0545\n",
      "Epoch 200, Loss: 0.2095, LPL: 1.3863, Contrastive: 0.0542\n",
      "Epoch 250, Loss: 0.2094, LPL: 1.3863, Contrastive: 0.0541\n",
      "Epoch 300, Loss: 0.2093, LPL: 1.3863, Contrastive: 0.0539\n",
      " - Metrics: Accuracy=0.9324, F1=0.8854, Recall=0.8643, Precision=0.9076\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.14073557935340858, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.18101528090131078, margin=0.5397136531929095, lpl_weight=0.11661795480413872\n",
      " - ratio=0.21480595303749334, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3030, LPL: 1.3863, Contrastive: 0.1600\n",
      "Epoch 50, Loss: 0.2112, LPL: 1.3863, Contrastive: 0.0561\n",
      "Epoch 100, Loss: 0.2102, LPL: 1.3863, Contrastive: 0.0550\n",
      "Epoch 150, Loss: 0.2098, LPL: 1.3863, Contrastive: 0.0545\n",
      "Epoch 200, Loss: 0.2095, LPL: 1.3863, Contrastive: 0.0542\n",
      "Epoch 250, Loss: 0.2094, LPL: 1.3863, Contrastive: 0.0541\n",
      "Epoch 300, Loss: 0.2093, LPL: 1.3863, Contrastive: 0.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:32:16,557] Trial 40 finished with value: 0.8919454345254039 and parameters: {'alpha': 0.14073557935340858, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.18101528090131078, 'margin': 0.5397136531929095, 'lpl_weight': 0.11661795480413872, 'ratio': 0.21480595303749334, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 36 with value: 0.8939391535191493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9365, F1=0.8924, Recall=0.8716, Precision=0.9141\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102143029.csv.\n",
      "Average F1 over 5 seeds: 0.8919  0.0045\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.13364487896695113, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1787045424312352, margin=0.5484785412639752, lpl_weight=0.15352705172949654\n",
      " - ratio=0.15381602424743546, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3479, LPL: 1.3863, Contrastive: 0.1596\n",
      "Epoch 50, Loss: 0.2588, LPL: 1.3863, Contrastive: 0.0543\n",
      "Epoch 100, Loss: 0.2575, LPL: 1.3863, Contrastive: 0.0528\n",
      " - Metrics: Accuracy=0.9328, F1=0.8812, Recall=0.8252, Precision=0.9454\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.13364487896695113, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1787045424312352, margin=0.5484785412639752, lpl_weight=0.15352705172949654\n",
      " - ratio=0.15381602424743546, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3479, LPL: 1.3863, Contrastive: 0.1596\n",
      "Epoch 50, Loss: 0.2588, LPL: 1.3863, Contrastive: 0.0543\n",
      "Epoch 100, Loss: 0.2575, LPL: 1.3863, Contrastive: 0.0528\n",
      " - Metrics: Accuracy=0.9309, F1=0.8794, Recall=0.8337, Precision=0.9304\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.13364487896695113, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1787045424312352, margin=0.5484785412639752, lpl_weight=0.15352705172949654\n",
      " - ratio=0.15381602424743546, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3479, LPL: 1.3863, Contrastive: 0.1596\n",
      "Epoch 50, Loss: 0.2588, LPL: 1.3863, Contrastive: 0.0543\n",
      "Epoch 100, Loss: 0.2575, LPL: 1.3863, Contrastive: 0.0528\n",
      " - Metrics: Accuracy=0.9354, F1=0.8873, Recall=0.8423, Precision=0.9374\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.13364487896695113, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1787045424312352, margin=0.5484785412639752, lpl_weight=0.15352705172949654\n",
      " - ratio=0.15381602424743546, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3479, LPL: 1.3863, Contrastive: 0.1596\n",
      "Epoch 50, Loss: 0.2588, LPL: 1.3863, Contrastive: 0.0543\n",
      "Epoch 100, Loss: 0.2575, LPL: 1.3863, Contrastive: 0.0528\n",
      " - Metrics: Accuracy=0.9313, F1=0.8794, Recall=0.8289, Precision=0.9365\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.13364487896695113, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1787045424312352, margin=0.5484785412639752, lpl_weight=0.15352705172949654\n",
      " - ratio=0.15381602424743546, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3479, LPL: 1.3863, Contrastive: 0.1596\n",
      "Epoch 50, Loss: 0.2588, LPL: 1.3863, Contrastive: 0.0543\n",
      "Epoch 100, Loss: 0.2575, LPL: 1.3863, Contrastive: 0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:33:22,686] Trial 41 finished with value: 0.8824380280863406 and parameters: {'alpha': 0.13364487896695113, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.1787045424312352, 'margin': 0.5484785412639752, 'lpl_weight': 0.15352705172949654, 'ratio': 0.15381602424743546, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 36 with value: 0.8939391535191493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9343, F1=0.8849, Recall=0.8362, Precision=0.9396\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102143216.csv.\n",
      "Average F1 over 5 seeds: 0.8824  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1039587928487396, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1432370677420261, margin=0.5058032106703939, lpl_weight=0.27119056302724337\n",
      " - ratio=0.3256170337151093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4887, LPL: 1.3863, Contrastive: 0.1547\n",
      "Epoch 50, Loss: 0.4233, LPL: 1.3863, Contrastive: 0.0650\n",
      "Epoch 100, Loss: 0.4220, LPL: 1.3863, Contrastive: 0.0631\n",
      "Epoch 150, Loss: 0.4217, LPL: 1.3863, Contrastive: 0.0627\n",
      "Epoch 200, Loss: 0.4215, LPL: 1.3863, Contrastive: 0.0624\n",
      " - Metrics: Accuracy=0.9254, F1=0.8830, Recall=0.9315, Precision=0.8392\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1039587928487396, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1432370677420261, margin=0.5058032106703939, lpl_weight=0.27119056302724337\n",
      " - ratio=0.3256170337151093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4887, LPL: 1.3863, Contrastive: 0.1547\n",
      "Epoch 50, Loss: 0.4233, LPL: 1.3863, Contrastive: 0.0650\n",
      "Epoch 100, Loss: 0.4220, LPL: 1.3863, Contrastive: 0.0631\n",
      "Epoch 150, Loss: 0.4217, LPL: 1.3863, Contrastive: 0.0627\n",
      "Epoch 200, Loss: 0.4215, LPL: 1.3863, Contrastive: 0.0624\n",
      " - Metrics: Accuracy=0.9195, F1=0.8738, Recall=0.9230, Precision=0.8297\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1039587928487396, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1432370677420261, margin=0.5058032106703939, lpl_weight=0.27119056302724337\n",
      " - ratio=0.3256170337151093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4887, LPL: 1.3863, Contrastive: 0.1547\n",
      "Epoch 50, Loss: 0.4233, LPL: 1.3863, Contrastive: 0.0650\n",
      "Epoch 100, Loss: 0.4220, LPL: 1.3863, Contrastive: 0.0631\n",
      "Epoch 150, Loss: 0.4217, LPL: 1.3863, Contrastive: 0.0627\n",
      "Epoch 200, Loss: 0.4215, LPL: 1.3863, Contrastive: 0.0624\n",
      " - Metrics: Accuracy=0.9273, F1=0.8850, Recall=0.9267, Precision=0.8469\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1039587928487396, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1432370677420261, margin=0.5058032106703939, lpl_weight=0.27119056302724337\n",
      " - ratio=0.3256170337151093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4887, LPL: 1.3863, Contrastive: 0.1547\n",
      "Epoch 50, Loss: 0.4233, LPL: 1.3863, Contrastive: 0.0650\n",
      "Epoch 100, Loss: 0.4220, LPL: 1.3863, Contrastive: 0.0631\n",
      "Epoch 150, Loss: 0.4217, LPL: 1.3863, Contrastive: 0.0627\n",
      "Epoch 200, Loss: 0.4215, LPL: 1.3863, Contrastive: 0.0624\n",
      " - Metrics: Accuracy=0.9202, F1=0.8735, Recall=0.9120, Precision=0.8382\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1039587928487396, K=29, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1432370677420261, margin=0.5058032106703939, lpl_weight=0.27119056302724337\n",
      " - ratio=0.3256170337151093, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4887, LPL: 1.3863, Contrastive: 0.1547\n",
      "Epoch 50, Loss: 0.4233, LPL: 1.3863, Contrastive: 0.0650\n",
      "Epoch 100, Loss: 0.4220, LPL: 1.3863, Contrastive: 0.0631\n",
      "Epoch 150, Loss: 0.4217, LPL: 1.3863, Contrastive: 0.0627\n",
      "Epoch 200, Loss: 0.4215, LPL: 1.3863, Contrastive: 0.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:34:56,830] Trial 42 finished with value: 0.8790406155723842 and parameters: {'alpha': 0.1039587928487396, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.1432370677420261, 'margin': 0.5058032106703939, 'lpl_weight': 0.27119056302724337, 'ratio': 0.3256170337151093, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 36 with value: 0.8939391535191493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9236, F1=0.8799, Recall=0.9267, Precision=0.8376\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102143322.csv.\n",
      "Average F1 over 5 seeds: 0.8790  0.0047\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2146219476451828, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.21231901855494123, margin=0.6222239698542831, lpl_weight=0.47421368022054794\n",
      " - ratio=0.21696373511313638, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7424, LPL: 1.3863, Contrastive: 0.1618\n",
      " - Metrics: Accuracy=0.9424, F1=0.9037, Recall=0.8949, Precision=0.9127\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2146219476451828, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.21231901855494123, margin=0.6222239698542831, lpl_weight=0.47421368022054794\n",
      " - ratio=0.21696373511313638, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7424, LPL: 1.3863, Contrastive: 0.1618\n",
      " - Metrics: Accuracy=0.9387, F1=0.8996, Recall=0.9095, Precision=0.8900\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2146219476451828, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.21231901855494123, margin=0.6222239698542831, lpl_weight=0.47421368022054794\n",
      " - ratio=0.21696373511313638, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7424, LPL: 1.3863, Contrastive: 0.1618\n",
      " - Metrics: Accuracy=0.9350, F1=0.8927, Recall=0.8949, Precision=0.8905\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2146219476451828, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.21231901855494123, margin=0.6222239698542831, lpl_weight=0.47421368022054794\n",
      " - ratio=0.21696373511313638, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7424, LPL: 1.3863, Contrastive: 0.1618\n",
      " - Metrics: Accuracy=0.9335, F1=0.8904, Recall=0.8936, Precision=0.8871\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2146219476451828, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.21231901855494123, margin=0.6222239698542831, lpl_weight=0.47421368022054794\n",
      " - ratio=0.21696373511313638, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7424, LPL: 1.3863, Contrastive: 0.1618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:35:25,535] Trial 43 finished with value: 0.8958646843919336 and parameters: {'alpha': 0.2146219476451828, 'K': 31, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.21231901855494123, 'margin': 0.6222239698542831, 'lpl_weight': 0.47421368022054794, 'ratio': 0.21696373511313638, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9346, F1=0.8929, Recall=0.9022, Precision=0.8838\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102143456.csv.\n",
      "Average F1 over 5 seeds: 0.8959  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2468404454117925, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2106481325879097, margin=0.6351528526869368, lpl_weight=0.20945152439935427\n",
      " - ratio=0.23890377920570088, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3474, LPL: 1.3863, Contrastive: 0.0721\n",
      " - Metrics: Accuracy=0.9195, F1=0.8638, Recall=0.8447, Precision=0.8836\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2468404454117925, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2106481325879097, margin=0.6351528526869368, lpl_weight=0.20945152439935427\n",
      " - ratio=0.23890377920570088, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3474, LPL: 1.3863, Contrastive: 0.0721\n",
      " - Metrics: Accuracy=0.9317, F1=0.8852, Recall=0.8716, Precision=0.8991\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2468404454117925, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2106481325879097, margin=0.6351528526869368, lpl_weight=0.20945152439935427\n",
      " - ratio=0.23890377920570088, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3474, LPL: 1.3863, Contrastive: 0.0721\n",
      " - Metrics: Accuracy=0.9265, F1=0.8769, Recall=0.8667, Precision=0.8874\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2468404454117925, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2106481325879097, margin=0.6351528526869368, lpl_weight=0.20945152439935427\n",
      " - ratio=0.23890377920570088, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3474, LPL: 1.3863, Contrastive: 0.0721\n",
      " - Metrics: Accuracy=0.9213, F1=0.8679, Recall=0.8557, Precision=0.8805\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2468404454117925, K=31, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2106481325879097, margin=0.6351528526869368, lpl_weight=0.20945152439935427\n",
      " - ratio=0.23890377920570088, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.3474, LPL: 1.3863, Contrastive: 0.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:35:51,995] Trial 44 finished with value: 0.8756397356341461 and parameters: {'alpha': 0.2468404454117925, 'K': 31, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.2106481325879097, 'margin': 0.6351528526869368, 'lpl_weight': 0.20945152439935427, 'ratio': 0.23890377920570088, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9302, F1=0.8844, Recall=0.8839, Precision=0.8849\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102143525.csv.\n",
      "Average F1 over 5 seeds: 0.8756  0.0086\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9700664292735902, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.18685534985398222, margin=0.3790177176874142, lpl_weight=0.4942034301949364\n",
      " - ratio=0.21462653639425705, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7573, LPL: 1.3863, Contrastive: 0.1426\n",
      "Epoch 50, Loss: 0.7353, LPL: 1.3863, Contrastive: 0.0993\n",
      "Epoch 100, Loss: 0.7348, LPL: 1.3863, Contrastive: 0.0983\n",
      " - Metrics: Accuracy=0.9380, F1=0.8947, Recall=0.8729, Precision=0.9177\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9700664292735902, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.18685534985398222, margin=0.3790177176874142, lpl_weight=0.4942034301949364\n",
      " - ratio=0.21462653639425705, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7573, LPL: 1.3863, Contrastive: 0.1426\n",
      "Epoch 50, Loss: 0.7353, LPL: 1.3863, Contrastive: 0.0993\n",
      "Epoch 100, Loss: 0.7349, LPL: 1.3863, Contrastive: 0.0985\n",
      " - Metrics: Accuracy=0.9284, F1=0.8786, Recall=0.8582, Precision=0.9000\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9700664292735902, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.18685534985398222, margin=0.3790177176874142, lpl_weight=0.4942034301949364\n",
      " - ratio=0.21462653639425705, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7573, LPL: 1.3863, Contrastive: 0.1426\n",
      "Epoch 50, Loss: 0.7353, LPL: 1.3863, Contrastive: 0.0993\n",
      "Epoch 100, Loss: 0.7349, LPL: 1.3863, Contrastive: 0.0984\n",
      "Epoch 150, Loss: 0.7350, LPL: 1.3863, Contrastive: 0.0987\n",
      " - Metrics: Accuracy=0.9335, F1=0.8885, Recall=0.8765, Precision=0.9008\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9700664292735902, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.18685534985398222, margin=0.3790177176874142, lpl_weight=0.4942034301949364\n",
      " - ratio=0.21462653639425705, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7573, LPL: 1.3863, Contrastive: 0.1426\n",
      "Epoch 50, Loss: 0.7353, LPL: 1.3863, Contrastive: 0.0993\n",
      "Epoch 100, Loss: 0.7348, LPL: 1.3863, Contrastive: 0.0983\n",
      " - Metrics: Accuracy=0.9328, F1=0.8870, Recall=0.8729, Precision=0.9015\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9700664292735902, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.18685534985398222, margin=0.3790177176874142, lpl_weight=0.4942034301949364\n",
      " - ratio=0.21462653639425705, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7573, LPL: 1.3863, Contrastive: 0.1426\n",
      "Epoch 50, Loss: 0.7354, LPL: 1.3863, Contrastive: 0.0994\n",
      "Epoch 100, Loss: 0.7349, LPL: 1.3863, Contrastive: 0.0983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:37:02,142] Trial 45 finished with value: 0.8885451049068422 and parameters: {'alpha': 0.9700664292735902, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.18685534985398222, 'margin': 0.3790177176874142, 'lpl_weight': 0.4942034301949364, 'ratio': 0.21462653639425705, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9365, F1=0.8940, Recall=0.8863, Precision=0.9017\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102143552.csv.\n",
      "Average F1 over 5 seeds: 0.8885  0.0058\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6755979439603289, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19520439080523658, margin=0.4358183773219809, lpl_weight=0.4090462883764668\n",
      " - ratio=0.21312241980788663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6482, LPL: 1.3863, Contrastive: 0.1373\n",
      "Epoch 50, Loss: 0.6156, LPL: 1.3863, Contrastive: 0.0821\n",
      "Epoch 100, Loss: 0.6151, LPL: 1.3863, Contrastive: 0.0812\n",
      " - Metrics: Accuracy=0.9431, F1=0.9042, Recall=0.8888, Precision=0.9203\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6755979439603289, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19520439080523658, margin=0.4358183773219809, lpl_weight=0.4090462883764668\n",
      " - ratio=0.21312241980788663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6482, LPL: 1.3863, Contrastive: 0.1373\n",
      "Epoch 50, Loss: 0.6156, LPL: 1.3863, Contrastive: 0.0821\n",
      "Epoch 100, Loss: 0.6151, LPL: 1.3863, Contrastive: 0.0812\n",
      " - Metrics: Accuracy=0.9287, F1=0.8800, Recall=0.8655, Precision=0.8951\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6755979439603289, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19520439080523658, margin=0.4358183773219809, lpl_weight=0.4090462883764668\n",
      " - ratio=0.21312241980788663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6482, LPL: 1.3863, Contrastive: 0.1373\n",
      "Epoch 50, Loss: 0.6156, LPL: 1.3863, Contrastive: 0.0821\n",
      "Epoch 100, Loss: 0.6151, LPL: 1.3863, Contrastive: 0.0812\n",
      " - Metrics: Accuracy=0.9398, F1=0.8991, Recall=0.8875, Precision=0.9109\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6755979439603289, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19520439080523658, margin=0.4358183773219809, lpl_weight=0.4090462883764668\n",
      " - ratio=0.21312241980788663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6482, LPL: 1.3863, Contrastive: 0.1373\n",
      "Epoch 50, Loss: 0.6156, LPL: 1.3863, Contrastive: 0.0821\n",
      "Epoch 100, Loss: 0.6150, LPL: 1.3863, Contrastive: 0.0812\n",
      " - Metrics: Accuracy=0.9402, F1=0.9000, Recall=0.8912, Precision=0.9090\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6755979439603289, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19520439080523658, margin=0.4358183773219809, lpl_weight=0.4090462883764668\n",
      " - ratio=0.21312241980788663, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6482, LPL: 1.3863, Contrastive: 0.1373\n",
      "Epoch 50, Loss: 0.6156, LPL: 1.3863, Contrastive: 0.0821\n",
      "Epoch 100, Loss: 0.6150, LPL: 1.3863, Contrastive: 0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:38:12,662] Trial 46 finished with value: 0.8952769218691126 and parameters: {'alpha': 0.6755979439603289, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.19520439080523658, 'margin': 0.4358183773219809, 'lpl_weight': 0.4090462883764668, 'ratio': 0.21312241980788663, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9365, F1=0.8930, Recall=0.8778, Precision=0.9089\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102143702.csv.\n",
      "Average F1 over 5 seeds: 0.8953  0.0084\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7800772100607215, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2075424527592377, margin=0.43759884955052136, lpl_weight=0.4158199542048388\n",
      " - ratio=0.26812683127424397, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6347, LPL: 1.3863, Contrastive: 0.0997\n",
      "Epoch 50, Loss: 0.6237, LPL: 1.3863, Contrastive: 0.0809\n",
      "Epoch 100, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0803\n",
      "Epoch 150, Loss: 0.6232, LPL: 1.3863, Contrastive: 0.0801\n",
      " - Metrics: Accuracy=0.8870, F1=0.7930, Recall=0.7164, Precision=0.8879\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7800772100607215, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2075424527592377, margin=0.43759884955052136, lpl_weight=0.4158199542048388\n",
      " - ratio=0.26812683127424397, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6347, LPL: 1.3863, Contrastive: 0.0997\n",
      "Epoch 50, Loss: 0.6237, LPL: 1.3863, Contrastive: 0.0809\n",
      "Epoch 100, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0803\n",
      "Epoch 150, Loss: 0.6232, LPL: 1.3863, Contrastive: 0.0801\n",
      "Epoch 200, Loss: 0.6232, LPL: 1.3863, Contrastive: 0.0800\n",
      " - Metrics: Accuracy=0.8829, F1=0.7821, Recall=0.6956, Precision=0.8932\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7800772100607215, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2075424527592377, margin=0.43759884955052136, lpl_weight=0.4158199542048388\n",
      " - ratio=0.26812683127424397, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6347, LPL: 1.3863, Contrastive: 0.0997\n",
      "Epoch 50, Loss: 0.6237, LPL: 1.3863, Contrastive: 0.0809\n",
      "Epoch 100, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0803\n",
      "Epoch 150, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0801\n",
      "Epoch 200, Loss: 0.6232, LPL: 1.3863, Contrastive: 0.0800\n",
      "Epoch 250, Loss: 0.6231, LPL: 1.3863, Contrastive: 0.0799\n",
      " - Metrics: Accuracy=0.8925, F1=0.8043, Recall=0.7311, Precision=0.8939\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7800772100607215, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2075424527592377, margin=0.43759884955052136, lpl_weight=0.4158199542048388\n",
      " - ratio=0.26812683127424397, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6347, LPL: 1.3863, Contrastive: 0.0997\n",
      "Epoch 50, Loss: 0.6237, LPL: 1.3863, Contrastive: 0.0809\n",
      "Epoch 100, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0803\n",
      "Epoch 150, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0802\n",
      " - Metrics: Accuracy=0.8929, F1=0.8077, Recall=0.7445, Precision=0.8826\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7800772100607215, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2075424527592377, margin=0.43759884955052136, lpl_weight=0.4158199542048388\n",
      " - ratio=0.26812683127424397, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6347, LPL: 1.3863, Contrastive: 0.0997\n",
      "Epoch 50, Loss: 0.6237, LPL: 1.3863, Contrastive: 0.0809\n",
      "Epoch 100, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0803\n",
      "Epoch 150, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0802\n",
      "Epoch 200, Loss: 0.6232, LPL: 1.3863, Contrastive: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:39:32,527] Trial 47 finished with value: 0.7987083873297893 and parameters: {'alpha': 0.7800772100607215, 'K': 26, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2075424527592377, 'margin': 0.43759884955052136, 'lpl_weight': 0.4158199542048388, 'ratio': 0.26812683127424397, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8936, F1=0.8065, Recall=0.7335, Precision=0.8955\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102143812.csv.\n",
      "Average F1 over 5 seeds: 0.7987  0.0098\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7404914155732412, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14650882186235054, margin=0.30413779658039103, lpl_weight=0.10076282664480675\n",
      " - ratio=0.28527370443315375, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2767, LPL: 1.3863, Contrastive: 0.1523\n",
      "Epoch 50, Loss: 0.2510, LPL: 1.3863, Contrastive: 0.1238\n",
      " - Metrics: Accuracy=0.9213, F1=0.8730, Recall=0.8949, Precision=0.8522\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7404914155732412, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14650882186235054, margin=0.30413779658039103, lpl_weight=0.10076282664480675\n",
      " - ratio=0.28527370443315375, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2767, LPL: 1.3863, Contrastive: 0.1523\n",
      "Epoch 50, Loss: 0.2510, LPL: 1.3863, Contrastive: 0.1238\n",
      " - Metrics: Accuracy=0.9221, F1=0.8724, Recall=0.8814, Precision=0.8635\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7404914155732412, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14650882186235054, margin=0.30413779658039103, lpl_weight=0.10076282664480675\n",
      " - ratio=0.28527370443315375, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2767, LPL: 1.3863, Contrastive: 0.1523\n",
      "Epoch 50, Loss: 0.2510, LPL: 1.3863, Contrastive: 0.1238\n",
      " - Metrics: Accuracy=0.9346, F1=0.8928, Recall=0.9010, Precision=0.8848\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7404914155732412, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14650882186235054, margin=0.30413779658039103, lpl_weight=0.10076282664480675\n",
      " - ratio=0.28527370443315375, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2767, LPL: 1.3863, Contrastive: 0.1523\n",
      "Epoch 50, Loss: 0.2510, LPL: 1.3863, Contrastive: 0.1238\n",
      " - Metrics: Accuracy=0.9213, F1=0.8722, Recall=0.8888, Precision=0.8563\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7404914155732412, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14650882186235054, margin=0.30413779658039103, lpl_weight=0.10076282664480675\n",
      " - ratio=0.28527370443315375, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.2767, LPL: 1.3863, Contrastive: 0.1523\n",
      "Epoch 50, Loss: 0.2510, LPL: 1.3863, Contrastive: 0.1238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:40:33,501] Trial 48 finished with value: 0.8797959778297365 and parameters: {'alpha': 0.7404914155732412, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.14650882186235054, 'margin': 0.30413779658039103, 'lpl_weight': 0.10076282664480675, 'ratio': 0.28527370443315375, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9317, F1=0.8886, Recall=0.9022, Precision=0.8754\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102143932.csv.\n",
      "Average F1 over 5 seeds: 0.8798  0.0090\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6911235271073068, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1251097207781557, margin=0.7366908516842672, lpl_weight=0.30201245459881965\n",
      " - ratio=0.20294070118470345, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5024, LPL: 1.3863, Contrastive: 0.1199\n",
      " - Metrics: Accuracy=0.9428, F1=0.9043, Recall=0.8949, Precision=0.9139\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6911235271073068, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1251097207781557, margin=0.7366908516842672, lpl_weight=0.30201245459881965\n",
      " - ratio=0.20294070118470345, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5024, LPL: 1.3863, Contrastive: 0.1199\n",
      " - Metrics: Accuracy=0.9376, F1=0.8960, Recall=0.8900, Precision=0.9021\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6911235271073068, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1251097207781557, margin=0.7366908516842672, lpl_weight=0.30201245459881965\n",
      " - ratio=0.20294070118470345, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5024, LPL: 1.3863, Contrastive: 0.1199\n",
      " - Metrics: Accuracy=0.9380, F1=0.8962, Recall=0.8863, Precision=0.9062\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6911235271073068, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1251097207781557, margin=0.7366908516842672, lpl_weight=0.30201245459881965\n",
      " - ratio=0.20294070118470345, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5024, LPL: 1.3863, Contrastive: 0.1199\n",
      " - Metrics: Accuracy=0.9361, F1=0.8929, Recall=0.8814, Precision=0.9046\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6911235271073068, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1251097207781557, margin=0.7366908516842672, lpl_weight=0.30201245459881965\n",
      " - ratio=0.20294070118470345, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5024, LPL: 1.3863, Contrastive: 0.1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:41:08,725] Trial 49 finished with value: 0.8956668787499955 and parameters: {'alpha': 0.6911235271073068, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1251097207781557, 'margin': 0.7366908516842672, 'lpl_weight': 0.30201245459881965, 'ratio': 0.20294070118470345, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9332, F1=0.8890, Recall=0.8863, Precision=0.8918\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144033.csv.\n",
      "Average F1 over 5 seeds: 0.8957  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8643308915669604, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12702637105023057, margin=0.8714076490594547, lpl_weight=0.29812238457617646\n",
      " - ratio=0.2044153843493509, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4977, LPL: 1.3863, Contrastive: 0.1202\n",
      " - Metrics: Accuracy=0.9350, F1=0.8911, Recall=0.8802, Precision=0.9023\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8643308915669604, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12702637105023057, margin=0.8714076490594547, lpl_weight=0.29812238457617646\n",
      " - ratio=0.2044153843493509, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4977, LPL: 1.3863, Contrastive: 0.1202\n",
      " - Metrics: Accuracy=0.9387, F1=0.8977, Recall=0.8900, Precision=0.9055\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8643308915669604, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12702637105023057, margin=0.8714076490594547, lpl_weight=0.29812238457617646\n",
      " - ratio=0.2044153843493509, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4977, LPL: 1.3863, Contrastive: 0.1202\n",
      " - Metrics: Accuracy=0.9346, F1=0.8903, Recall=0.8778, Precision=0.9031\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8643308915669604, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12702637105023057, margin=0.8714076490594547, lpl_weight=0.29812238457617646\n",
      " - ratio=0.2044153843493509, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4977, LPL: 1.3863, Contrastive: 0.1202\n",
      " - Metrics: Accuracy=0.9321, F1=0.8864, Recall=0.8778, Precision=0.8953\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8643308915669604, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12702637105023057, margin=0.8714076490594547, lpl_weight=0.29812238457617646\n",
      " - ratio=0.2044153843493509, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4977, LPL: 1.3863, Contrastive: 0.1202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:41:43,480] Trial 50 finished with value: 0.8911126026273335 and parameters: {'alpha': 0.8643308915669604, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.12702637105023057, 'margin': 0.8714076490594547, 'lpl_weight': 0.29812238457617646, 'ratio': 0.2044153843493509, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9346, F1=0.8901, Recall=0.8765, Precision=0.9042\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144108.csv.\n",
      "Average F1 over 5 seeds: 0.8911  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8495505940347614, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12077927931846857, margin=0.8856821935953558, lpl_weight=0.31734934211409005\n",
      " - ratio=0.20264570388834033, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5214, LPL: 1.3863, Contrastive: 0.1194\n",
      " - Metrics: Accuracy=0.9346, F1=0.8897, Recall=0.8729, Precision=0.9072\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8495505940347614, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12077927931846857, margin=0.8856821935953558, lpl_weight=0.31734934211409005\n",
      " - ratio=0.20264570388834033, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5214, LPL: 1.3863, Contrastive: 0.1194\n",
      " - Metrics: Accuracy=0.9339, F1=0.8889, Recall=0.8753, Precision=0.9029\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8495505940347614, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12077927931846857, margin=0.8856821935953558, lpl_weight=0.31734934211409005\n",
      " - ratio=0.20264570388834033, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5214, LPL: 1.3863, Contrastive: 0.1194\n",
      " - Metrics: Accuracy=0.9339, F1=0.8892, Recall=0.8778, Precision=0.9009\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8495505940347614, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12077927931846857, margin=0.8856821935953558, lpl_weight=0.31734934211409005\n",
      " - ratio=0.20264570388834033, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5214, LPL: 1.3863, Contrastive: 0.1194\n",
      " - Metrics: Accuracy=0.9306, F1=0.8826, Recall=0.8643, Precision=0.9018\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8495505940347614, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12077927931846857, margin=0.8856821935953558, lpl_weight=0.31734934211409005\n",
      " - ratio=0.20264570388834033, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5214, LPL: 1.3863, Contrastive: 0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:42:18,449] Trial 51 finished with value: 0.8867587966412357 and parameters: {'alpha': 0.8495505940347614, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.12077927931846857, 'margin': 0.8856821935953558, 'lpl_weight': 0.31734934211409005, 'ratio': 0.20264570388834033, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9306, F1=0.8834, Recall=0.8704, Precision=0.8967\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144143.csv.\n",
      "Average F1 over 5 seeds: 0.8868  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6562535619803644, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10251072926548856, margin=0.8351844263990302, lpl_weight=0.23672134075521542\n",
      " - ratio=0.22025819732859833, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4174, LPL: 1.3863, Contrastive: 0.1169\n",
      " - Metrics: Accuracy=0.9372, F1=0.8965, Recall=0.8998, Precision=0.8932\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6562535619803644, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10251072926548856, margin=0.8351844263990302, lpl_weight=0.23672134075521542\n",
      " - ratio=0.22025819732859833, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4174, LPL: 1.3863, Contrastive: 0.1169\n",
      " - Metrics: Accuracy=0.9332, F1=0.8897, Recall=0.8924, Precision=0.8870\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6562535619803644, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10251072926548856, margin=0.8351844263990302, lpl_weight=0.23672134075521542\n",
      " - ratio=0.22025819732859833, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4174, LPL: 1.3863, Contrastive: 0.1169\n",
      " - Metrics: Accuracy=0.9321, F1=0.8883, Recall=0.8949, Precision=0.8819\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6562535619803644, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10251072926548856, margin=0.8351844263990302, lpl_weight=0.23672134075521542\n",
      " - ratio=0.22025819732859833, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4174, LPL: 1.3863, Contrastive: 0.1169\n",
      " - Metrics: Accuracy=0.9295, F1=0.8832, Recall=0.8826, Precision=0.8837\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6562535619803644, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10251072926548856, margin=0.8351844263990302, lpl_weight=0.23672134075521542\n",
      " - ratio=0.22025819732859833, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4174, LPL: 1.3863, Contrastive: 0.1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:42:52,633] Trial 52 finished with value: 0.8891553850905465 and parameters: {'alpha': 0.6562535619803644, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.10251072926548856, 'margin': 0.8351844263990302, 'lpl_weight': 0.23672134075521542, 'ratio': 0.22025819732859833, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9321, F1=0.8881, Recall=0.8924, Precision=0.8838\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144218.csv.\n",
      "Average F1 over 5 seeds: 0.8892  0.0043\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8959485279887577, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1448617724926487, margin=0.7178764737912701, lpl_weight=0.4116129312441613\n",
      " - ratio=0.24584022690954924, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6427, LPL: 1.3863, Contrastive: 0.1226\n",
      " - Metrics: Accuracy=0.9346, F1=0.8950, Recall=0.9218, Precision=0.8697\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8959485279887577, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1448617724926487, margin=0.7178764737912701, lpl_weight=0.4116129312441613\n",
      " - ratio=0.24584022690954924, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6427, LPL: 1.3863, Contrastive: 0.1226\n",
      " - Metrics: Accuracy=0.9339, F1=0.8943, Recall=0.9254, Precision=0.8651\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8959485279887577, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1448617724926487, margin=0.7178764737912701, lpl_weight=0.4116129312441613\n",
      " - ratio=0.24584022690954924, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6427, LPL: 1.3863, Contrastive: 0.1226\n",
      " - Metrics: Accuracy=0.9295, F1=0.8866, Recall=0.9132, Precision=0.8616\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8959485279887577, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1448617724926487, margin=0.7178764737912701, lpl_weight=0.4116129312441613\n",
      " - ratio=0.24584022690954924, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6427, LPL: 1.3863, Contrastive: 0.1226\n",
      " - Metrics: Accuracy=0.9254, F1=0.8799, Recall=0.9046, Precision=0.8565\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8959485279887577, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1448617724926487, margin=0.7178764737912701, lpl_weight=0.4116129312441613\n",
      " - ratio=0.24584022690954924, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6427, LPL: 1.3863, Contrastive: 0.1226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:43:26,028] Trial 53 finished with value: 0.8890914980064796 and parameters: {'alpha': 0.8959485279887577, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1448617724926487, 'margin': 0.7178764737912701, 'lpl_weight': 0.4116129312441613, 'ratio': 0.24584022690954924, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9313, F1=0.8897, Recall=0.9169, Precision=0.8641\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144252.csv.\n",
      "Average F1 over 5 seeds: 0.8891  0.0055\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6387974533418157, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.17974756746388984, margin=0.8770439071589337, lpl_weight=0.3576024382241292\n",
      " - ratio=0.19512137341299424, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5944, LPL: 1.3863, Contrastive: 0.1536\n",
      " - Metrics: Accuracy=0.9180, F1=0.8597, Recall=0.8313, Precision=0.8901\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6387974533418157, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.17974756746388984, margin=0.8770439071589337, lpl_weight=0.3576024382241292\n",
      " - ratio=0.19512137341299424, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5944, LPL: 1.3863, Contrastive: 0.1536\n",
      " - Metrics: Accuracy=0.9143, F1=0.8528, Recall=0.8215, Precision=0.8865\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6387974533418157, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.17974756746388984, margin=0.8770439071589337, lpl_weight=0.3576024382241292\n",
      " - ratio=0.19512137341299424, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5944, LPL: 1.3863, Contrastive: 0.1536\n",
      " - Metrics: Accuracy=0.9040, F1=0.8379, Recall=0.8215, Precision=0.8550\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6387974533418157, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.17974756746388984, margin=0.8770439071589337, lpl_weight=0.3576024382241292\n",
      " - ratio=0.19512137341299424, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5944, LPL: 1.3863, Contrastive: 0.1536\n",
      " - Metrics: Accuracy=0.9077, F1=0.8430, Recall=0.8203, Precision=0.8669\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6387974533418157, K=25, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.17974756746388984, margin=0.8770439071589337, lpl_weight=0.3576024382241292\n",
      " - ratio=0.19512137341299424, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5944, LPL: 1.3863, Contrastive: 0.1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:44:01,697] Trial 54 finished with value: 0.8485089195633956 and parameters: {'alpha': 0.6387974533418157, 'K': 25, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.17974756746388984, 'margin': 0.8770439071589337, 'lpl_weight': 0.3576024382241292, 'ratio': 0.19512137341299424, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9117, F1=0.8492, Recall=0.8227, Precision=0.8774\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144326.csv.\n",
      "Average F1 over 5 seeds: 0.8485  0.0076\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7209028326324027, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1234240147003168, margin=0.803861120010251, lpl_weight=0.15693794524870763\n",
      " - ratio=0.20736690580666692, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3184, LPL: 1.3863, Contrastive: 0.1197\n",
      " - Metrics: Accuracy=0.9431, F1=0.9047, Recall=0.8936, Precision=0.9160\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7209028326324027, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1234240147003168, margin=0.803861120010251, lpl_weight=0.15693794524870763\n",
      " - ratio=0.20736690580666692, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3184, LPL: 1.3863, Contrastive: 0.1197\n",
      " - Metrics: Accuracy=0.9354, F1=0.8916, Recall=0.8802, Precision=0.9034\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7209028326324027, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1234240147003168, margin=0.803861120010251, lpl_weight=0.15693794524870763\n",
      " - ratio=0.20736690580666692, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3184, LPL: 1.3863, Contrastive: 0.1197\n",
      " - Metrics: Accuracy=0.9376, F1=0.8954, Recall=0.8839, Precision=0.9072\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7209028326324027, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1234240147003168, margin=0.803861120010251, lpl_weight=0.15693794524870763\n",
      " - ratio=0.20736690580666692, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3184, LPL: 1.3863, Contrastive: 0.1197\n",
      " - Metrics: Accuracy=0.9287, F1=0.8811, Recall=0.8741, Precision=0.8882\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7209028326324027, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1234240147003168, margin=0.803861120010251, lpl_weight=0.15693794524870763\n",
      " - ratio=0.20736690580666692, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3184, LPL: 1.3863, Contrastive: 0.1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:44:36,237] Trial 55 finished with value: 0.8924989397442117 and parameters: {'alpha': 0.7209028326324027, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1234240147003168, 'margin': 0.803861120010251, 'lpl_weight': 0.15693794524870763, 'ratio': 0.20736690580666692, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9339, F1=0.8897, Recall=0.8826, Precision=0.8969\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144401.csv.\n",
      "Average F1 over 5 seeds: 0.8925  0.0077\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7076626093534019, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14840883343722364, margin=0.7904127156152826, lpl_weight=0.17336358410169683\n",
      " - ratio=0.25788652792111955, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3419, LPL: 1.3863, Contrastive: 0.1228\n",
      " - Metrics: Accuracy=0.9365, F1=0.8975, Recall=0.9205, Precision=0.8756\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7076626093534019, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14840883343722364, margin=0.7904127156152826, lpl_weight=0.17336358410169683\n",
      " - ratio=0.25788652792111955, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3419, LPL: 1.3863, Contrastive: 0.1228\n",
      " - Metrics: Accuracy=0.9317, F1=0.8902, Recall=0.9169, Precision=0.8651\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7076626093534019, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14840883343722364, margin=0.7904127156152826, lpl_weight=0.17336358410169683\n",
      " - ratio=0.25788652792111955, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3419, LPL: 1.3863, Contrastive: 0.1228\n",
      " - Metrics: Accuracy=0.9243, F1=0.8789, Recall=0.9095, Precision=0.8503\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7076626093534019, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14840883343722364, margin=0.7904127156152826, lpl_weight=0.17336358410169683\n",
      " - ratio=0.25788652792111955, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3419, LPL: 1.3863, Contrastive: 0.1228\n",
      " - Metrics: Accuracy=0.9217, F1=0.8737, Recall=0.8961, Precision=0.8523\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7076626093534019, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.14840883343722364, margin=0.7904127156152826, lpl_weight=0.17336358410169683\n",
      " - ratio=0.25788652792111955, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3419, LPL: 1.3863, Contrastive: 0.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:45:11,041] Trial 56 finished with value: 0.8844982790248943 and parameters: {'alpha': 0.7076626093534019, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.14840883343722364, 'margin': 0.7904127156152826, 'lpl_weight': 0.17336358410169683, 'ratio': 0.25788652792111955, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9261, F1=0.8822, Recall=0.9156, Precision=0.8511\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144436.csv.\n",
      "Average F1 over 5 seeds: 0.8845  0.0084\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7462581015852703, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1978825449414338, margin=0.7147792938204103, lpl_weight=0.44899561948638234\n",
      " - ratio=0.190339510328351, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6940, LPL: 1.3863, Contrastive: 0.1298\n",
      " - Metrics: Accuracy=0.9387, F1=0.8957, Recall=0.8716, Precision=0.9212\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7462581015852703, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1978825449414338, margin=0.7147792938204103, lpl_weight=0.44899561948638234\n",
      " - ratio=0.190339510328351, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6940, LPL: 1.3863, Contrastive: 0.1298\n",
      " - Metrics: Accuracy=0.9372, F1=0.8934, Recall=0.8704, Precision=0.9175\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7462581015852703, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1978825449414338, margin=0.7147792938204103, lpl_weight=0.44899561948638234\n",
      " - ratio=0.190339510328351, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6940, LPL: 1.3863, Contrastive: 0.1298\n",
      " - Metrics: Accuracy=0.9335, F1=0.8871, Recall=0.8643, Precision=0.9111\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7462581015852703, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1978825449414338, margin=0.7147792938204103, lpl_weight=0.44899561948638234\n",
      " - ratio=0.190339510328351, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6940, LPL: 1.3863, Contrastive: 0.1298\n",
      " - Metrics: Accuracy=0.9335, F1=0.8865, Recall=0.8594, Precision=0.9154\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7462581015852703, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1978825449414338, margin=0.7147792938204103, lpl_weight=0.44899561948638234\n",
      " - ratio=0.190339510328351, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6940, LPL: 1.3863, Contrastive: 0.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:45:46,661] Trial 57 finished with value: 0.8903655615088117 and parameters: {'alpha': 0.7462581015852703, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1978825449414338, 'margin': 0.7147792938204103, 'lpl_weight': 0.44899561948638234, 'ratio': 0.190339510328351, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9343, F1=0.8892, Recall=0.8729, Precision=0.9061\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144511.csv.\n",
      "Average F1 over 5 seeds: 0.8904  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6168848726640391, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11544674900684986, margin=0.7498088828919933, lpl_weight=0.1506776191651134\n",
      " - ratio=0.23123938528582866, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.2646, LPL: 1.3863, Contrastive: 0.0655\n",
      " - Metrics: Accuracy=0.9221, F1=0.8734, Recall=0.8900, Precision=0.8575\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6168848726640391, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11544674900684986, margin=0.7498088828919933, lpl_weight=0.1506776191651134\n",
      " - ratio=0.23123938528582866, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.2646, LPL: 1.3863, Contrastive: 0.0655\n",
      " - Metrics: Accuracy=0.9265, F1=0.8813, Recall=0.9034, Precision=0.8603\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6168848726640391, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11544674900684986, margin=0.7498088828919933, lpl_weight=0.1506776191651134\n",
      " - ratio=0.23123938528582866, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.2646, LPL: 1.3863, Contrastive: 0.0655\n",
      " - Metrics: Accuracy=0.9269, F1=0.8804, Recall=0.8912, Precision=0.8699\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6168848726640391, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11544674900684986, margin=0.7498088828919933, lpl_weight=0.1506776191651134\n",
      " - ratio=0.23123938528582866, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.2646, LPL: 1.3863, Contrastive: 0.0655\n",
      " - Metrics: Accuracy=0.9210, F1=0.8722, Recall=0.8924, Precision=0.8528\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6168848726640391, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11544674900684986, margin=0.7498088828919933, lpl_weight=0.1506776191651134\n",
      " - ratio=0.23123938528582866, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.2646, LPL: 1.3863, Contrastive: 0.0655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:46:21,126] Trial 58 finished with value: 0.878798629205035 and parameters: {'alpha': 0.6168848726640391, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.11544674900684986, 'margin': 0.7498088828919933, 'lpl_weight': 0.1506776191651134, 'ratio': 0.23123938528582866, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9298, F1=0.8866, Recall=0.9083, Precision=0.8660\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144546.csv.\n",
      "Average F1 over 5 seeds: 0.8788  0.0054\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5929148559889617, K=28, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.17247143869806214, margin=0.7939176993749983, lpl_weight=0.20734366314026711\n",
      " - ratio=0.21413009687086043, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4091, LPL: 1.3863, Contrastive: 0.1535\n",
      " - Metrics: Accuracy=0.9140, F1=0.8566, Recall=0.8509, Precision=0.8625\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5929148559889617, K=28, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.17247143869806214, margin=0.7939176993749983, lpl_weight=0.20734366314026711\n",
      " - ratio=0.21413009687086043, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4091, LPL: 1.3863, Contrastive: 0.1535\n",
      " - Metrics: Accuracy=0.9106, F1=0.8508, Recall=0.8435, Precision=0.8582\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5929148559889617, K=28, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.17247143869806214, margin=0.7939176993749983, lpl_weight=0.20734366314026711\n",
      " - ratio=0.21413009687086043, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4091, LPL: 1.3863, Contrastive: 0.1535\n",
      " - Metrics: Accuracy=0.9117, F1=0.8515, Recall=0.8374, Precision=0.8660\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5929148559889617, K=28, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.17247143869806214, margin=0.7939176993749983, lpl_weight=0.20734366314026711\n",
      " - ratio=0.21413009687086043, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4091, LPL: 1.3863, Contrastive: 0.1535\n",
      " - Metrics: Accuracy=0.9040, F1=0.8395, Recall=0.8313, Precision=0.8479\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5929148559889617, K=28, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.17247143869806214, margin=0.7939176993749983, lpl_weight=0.20734366314026711\n",
      " - ratio=0.21413009687086043, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4091, LPL: 1.3863, Contrastive: 0.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:46:54,436] Trial 59 finished with value: 0.8506168852607934 and parameters: {'alpha': 0.5929148559889617, 'K': 28, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.17247143869806214, 'margin': 0.7939176993749983, 'lpl_weight': 0.20734366314026711, 'ratio': 0.21413009687086043, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9121, F1=0.8547, Recall=0.8557, Precision=0.8537\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144621.csv.\n",
      "Average F1 over 5 seeds: 0.8506  0.0059\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6717597835079572, K=32, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1347316194740292, margin=0.3925474932064803, lpl_weight=0.3713110930193824\n",
      " - ratio=0.24585450549969584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6002, LPL: 1.3863, Contrastive: 0.1360\n",
      "Epoch 50, Loss: 0.5744, LPL: 1.3863, Contrastive: 0.0948\n",
      "Epoch 100, Loss: 0.5745, LPL: 1.3863, Contrastive: 0.0951\n",
      " - Metrics: Accuracy=0.9343, F1=0.8913, Recall=0.8924, Precision=0.8902\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6717597835079572, K=32, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1347316194740292, margin=0.3925474932064803, lpl_weight=0.3713110930193824\n",
      " - ratio=0.24585450549969584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6002, LPL: 1.3863, Contrastive: 0.1360\n",
      "Epoch 50, Loss: 0.5744, LPL: 1.3863, Contrastive: 0.0948\n",
      "Epoch 100, Loss: 0.5744, LPL: 1.3863, Contrastive: 0.0949\n",
      " - Metrics: Accuracy=0.9280, F1=0.8812, Recall=0.8839, Precision=0.8785\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6717597835079572, K=32, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1347316194740292, margin=0.3925474932064803, lpl_weight=0.3713110930193824\n",
      " - ratio=0.24585450549969584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6002, LPL: 1.3863, Contrastive: 0.1360\n",
      "Epoch 50, Loss: 0.5744, LPL: 1.3863, Contrastive: 0.0948\n",
      "Epoch 100, Loss: 0.5747, LPL: 1.3863, Contrastive: 0.0954\n",
      " - Metrics: Accuracy=0.9350, F1=0.8932, Recall=0.8998, Precision=0.8867\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6717597835079572, K=32, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1347316194740292, margin=0.3925474932064803, lpl_weight=0.3713110930193824\n",
      " - ratio=0.24585450549969584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6002, LPL: 1.3863, Contrastive: 0.1360\n",
      "Epoch 50, Loss: 0.5744, LPL: 1.3863, Contrastive: 0.0948\n",
      "Epoch 100, Loss: 0.5743, LPL: 1.3863, Contrastive: 0.0947\n",
      " - Metrics: Accuracy=0.9273, F1=0.8782, Recall=0.8680, Precision=0.8886\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6717597835079572, K=32, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1347316194740292, margin=0.3925474932064803, lpl_weight=0.3713110930193824\n",
      " - ratio=0.24585450549969584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6002, LPL: 1.3863, Contrastive: 0.1360\n",
      "Epoch 50, Loss: 0.5744, LPL: 1.3863, Contrastive: 0.0948\n",
      "Epoch 100, Loss: 0.5744, LPL: 1.3863, Contrastive: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:48:05,581] Trial 60 finished with value: 0.8874299996823897 and parameters: {'alpha': 0.6717597835079572, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1347316194740292, 'margin': 0.3925474932064803, 'lpl_weight': 0.3713110930193824, 'ratio': 0.24585450549969584, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9361, F1=0.8933, Recall=0.8851, Precision=0.9016\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144654.csv.\n",
      "Average F1 over 5 seeds: 0.8874  0.0064\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8339750699095407, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12291595876364828, margin=0.8275904523599568, lpl_weight=0.28734220963785234\n",
      " - ratio=0.20600577252570218, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4836, LPL: 1.3863, Contrastive: 0.1196\n",
      " - Metrics: Accuracy=0.9409, F1=0.9002, Recall=0.8826, Precision=0.9186\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8339750699095407, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12291595876364828, margin=0.8275904523599568, lpl_weight=0.28734220963785234\n",
      " - ratio=0.20600577252570218, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4836, LPL: 1.3863, Contrastive: 0.1196\n",
      " - Metrics: Accuracy=0.9306, F1=0.8845, Recall=0.8802, Precision=0.8889\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8339750699095407, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12291595876364828, margin=0.8275904523599568, lpl_weight=0.28734220963785234\n",
      " - ratio=0.20600577252570218, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4836, LPL: 1.3863, Contrastive: 0.1196\n",
      " - Metrics: Accuracy=0.9369, F1=0.8939, Recall=0.8802, Precision=0.9079\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8339750699095407, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12291595876364828, margin=0.8275904523599568, lpl_weight=0.28734220963785234\n",
      " - ratio=0.20600577252570218, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4836, LPL: 1.3863, Contrastive: 0.1196\n",
      " - Metrics: Accuracy=0.9328, F1=0.8870, Recall=0.8729, Precision=0.9015\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8339750699095407, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12291595876364828, margin=0.8275904523599568, lpl_weight=0.28734220963785234\n",
      " - ratio=0.20600577252570218, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4836, LPL: 1.3863, Contrastive: 0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:48:41,732] Trial 61 finished with value: 0.8923499280396474 and parameters: {'alpha': 0.8339750699095407, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.12291595876364828, 'margin': 0.8275904523599568, 'lpl_weight': 0.28734220963785234, 'ratio': 0.20600577252570218, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9380, F1=0.8962, Recall=0.8863, Precision=0.9062\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144805.csv.\n",
      "Average F1 over 5 seeds: 0.8923  0.0058\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8226459090750204, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.15706682326079674, margin=0.8254132448563155, lpl_weight=0.2661203822923572\n",
      " - ratio=0.183761395352823, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4598, LPL: 1.3863, Contrastive: 0.1239\n",
      " - Metrics: Accuracy=0.9357, F1=0.8903, Recall=0.8631, Precision=0.9193\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8226459090750204, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.15706682326079674, margin=0.8254132448563155, lpl_weight=0.2661203822923572\n",
      " - ratio=0.183761395352823, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4598, LPL: 1.3863, Contrastive: 0.1239\n",
      " - Metrics: Accuracy=0.9335, F1=0.8859, Recall=0.8545, Precision=0.9197\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8226459090750204, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.15706682326079674, margin=0.8254132448563155, lpl_weight=0.2661203822923572\n",
      " - ratio=0.183761395352823, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4598, LPL: 1.3863, Contrastive: 0.1239\n",
      " - Metrics: Accuracy=0.9324, F1=0.8835, Recall=0.8484, Precision=0.9216\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8226459090750204, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.15706682326079674, margin=0.8254132448563155, lpl_weight=0.2661203822923572\n",
      " - ratio=0.183761395352823, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4598, LPL: 1.3863, Contrastive: 0.1239\n",
      " - Metrics: Accuracy=0.9302, F1=0.8805, Recall=0.8509, Precision=0.9122\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8226459090750204, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.15706682326079674, margin=0.8254132448563155, lpl_weight=0.2661203822923572\n",
      " - ratio=0.183761395352823, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4598, LPL: 1.3863, Contrastive: 0.1239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:49:16,415] Trial 62 finished with value: 0.8851990213380823 and parameters: {'alpha': 0.8226459090750204, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.15706682326079674, 'margin': 0.8254132448563155, 'lpl_weight': 0.2661203822923572, 'ratio': 0.183761395352823, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9332, F1=0.8858, Recall=0.8582, Precision=0.9153\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144841.csv.\n",
      "Average F1 over 5 seeds: 0.8852  0.0032\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7689006983705337, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21979235487063623, margin=0.932778184187955, lpl_weight=0.14344253221534892\n",
      " - ratio=0.20620549180271072, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3128, LPL: 1.3863, Contrastive: 0.1330\n",
      " - Metrics: Accuracy=0.9309, F1=0.8842, Recall=0.8729, Precision=0.8959\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7689006983705337, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21979235487063623, margin=0.932778184187955, lpl_weight=0.14344253221534892\n",
      " - ratio=0.20620549180271072, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3128, LPL: 1.3863, Contrastive: 0.1330\n",
      " - Metrics: Accuracy=0.9332, F1=0.8879, Recall=0.8765, Precision=0.8996\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7689006983705337, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21979235487063623, margin=0.932778184187955, lpl_weight=0.14344253221534892\n",
      " - ratio=0.20620549180271072, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3128, LPL: 1.3863, Contrastive: 0.1330\n",
      " - Metrics: Accuracy=0.9313, F1=0.8843, Recall=0.8692, Precision=0.9000\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7689006983705337, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21979235487063623, margin=0.932778184187955, lpl_weight=0.14344253221534892\n",
      " - ratio=0.20620549180271072, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3128, LPL: 1.3863, Contrastive: 0.1330\n",
      " - Metrics: Accuracy=0.9273, F1=0.8777, Recall=0.8643, Precision=0.8916\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7689006983705337, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.21979235487063623, margin=0.932778184187955, lpl_weight=0.14344253221534892\n",
      " - ratio=0.20620549180271072, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3128, LPL: 1.3863, Contrastive: 0.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:49:52,185] Trial 63 finished with value: 0.8828757840078195 and parameters: {'alpha': 0.7689006983705337, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.21979235487063623, 'margin': 0.932778184187955, 'lpl_weight': 0.14344253221534892, 'ratio': 0.20620549180271072, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 43 with value: 0.8958646843919336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9287, F1=0.8802, Recall=0.8667, Precision=0.8941\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144916.csv.\n",
      "Average F1 over 5 seeds: 0.8829  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5225556218682548, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19148721756379133, margin=0.6348520731231905, lpl_weight=0.45644165733336167\n",
      " - ratio=0.22301166205654735, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7031, LPL: 1.3863, Contrastive: 0.1294\n",
      " - Metrics: Accuracy=0.9335, F1=0.8922, Recall=0.9108, Precision=0.8744\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5225556218682548, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19148721756379133, margin=0.6348520731231905, lpl_weight=0.45644165733336167\n",
      " - ratio=0.22301166205654735, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7031, LPL: 1.3863, Contrastive: 0.1294\n",
      " - Metrics: Accuracy=0.9369, F1=0.8973, Recall=0.9132, Precision=0.8819\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5225556218682548, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19148721756379133, margin=0.6348520731231905, lpl_weight=0.45644165733336167\n",
      " - ratio=0.22301166205654735, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7031, LPL: 1.3863, Contrastive: 0.1294\n",
      " - Metrics: Accuracy=0.9409, F1=0.9028, Recall=0.9083, Precision=0.8973\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5225556218682548, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19148721756379133, margin=0.6348520731231905, lpl_weight=0.45644165733336167\n",
      " - ratio=0.22301166205654735, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7031, LPL: 1.3863, Contrastive: 0.1294\n",
      " - Metrics: Accuracy=0.9394, F1=0.9000, Recall=0.9022, Precision=0.8978\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5225556218682548, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19148721756379133, margin=0.6348520731231905, lpl_weight=0.45644165733336167\n",
      " - ratio=0.22301166205654735, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7031, LPL: 1.3863, Contrastive: 0.1294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:50:26,442] Trial 64 finished with value: 0.8976055666614717 and parameters: {'alpha': 0.5225556218682548, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.19148721756379133, 'margin': 0.6348520731231905, 'lpl_weight': 0.45644165733336167, 'ratio': 0.22301166205654735, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9361, F1=0.8957, Recall=0.9083, Precision=0.8835\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102144952.csv.\n",
      "Average F1 over 5 seeds: 0.8976  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5001088969432945, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1553674902732396, margin=0.6992787137238081, lpl_weight=0.45919014930850127\n",
      " - ratio=0.16732374263961783, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7036, LPL: 1.3863, Contrastive: 0.1240\n",
      " - Metrics: Accuracy=0.9391, F1=0.8948, Recall=0.8582, Precision=0.9348\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5001088969432945, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1553674902732396, margin=0.6992787137238081, lpl_weight=0.45919014930850127\n",
      " - ratio=0.16732374263961783, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7036, LPL: 1.3863, Contrastive: 0.1240\n",
      " - Metrics: Accuracy=0.9350, F1=0.8875, Recall=0.8484, Precision=0.9303\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5001088969432945, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1553674902732396, margin=0.6992787137238081, lpl_weight=0.45919014930850127\n",
      " - ratio=0.16732374263961783, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7036, LPL: 1.3863, Contrastive: 0.1240\n",
      " - Metrics: Accuracy=0.9376, F1=0.8922, Recall=0.8545, Precision=0.9332\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5001088969432945, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1553674902732396, margin=0.6992787137238081, lpl_weight=0.45919014930850127\n",
      " - ratio=0.16732374263961783, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7036, LPL: 1.3863, Contrastive: 0.1240\n",
      " - Metrics: Accuracy=0.9335, F1=0.8842, Recall=0.8399, Precision=0.9334\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5001088969432945, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1553674902732396, margin=0.6992787137238081, lpl_weight=0.45919014930850127\n",
      " - ratio=0.16732374263961783, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7036, LPL: 1.3863, Contrastive: 0.1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:51:01,479] Trial 65 finished with value: 0.8904324237773679 and parameters: {'alpha': 0.5001088969432945, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1553674902732396, 'margin': 0.6992787137238081, 'lpl_weight': 0.45919014930850127, 'ratio': 0.16732374263961783, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9380, F1=0.8935, Recall=0.8619, Precision=0.9276\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145026.csv.\n",
      "Average F1 over 5 seeds: 0.8904  0.0040\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7040451043893605, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.197532601484417, margin=0.6268451227871268, lpl_weight=0.33620969296213166\n",
      " - ratio=0.28138455532576895, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5526, LPL: 1.3863, Contrastive: 0.1303\n",
      " - Metrics: Accuracy=0.9221, F1=0.8784, Recall=0.9315, Precision=0.8310\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7040451043893605, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.197532601484417, margin=0.6268451227871268, lpl_weight=0.33620969296213166\n",
      " - ratio=0.28138455532576895, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5526, LPL: 1.3863, Contrastive: 0.1303\n",
      " - Metrics: Accuracy=0.9225, F1=0.8800, Recall=0.9413, Precision=0.8262\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7040451043893605, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.197532601484417, margin=0.6268451227871268, lpl_weight=0.33620969296213166\n",
      " - ratio=0.28138455532576895, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5526, LPL: 1.3863, Contrastive: 0.1303\n",
      " - Metrics: Accuracy=0.9165, F1=0.8691, Recall=0.9169, Precision=0.8260\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7040451043893605, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.197532601484417, margin=0.6268451227871268, lpl_weight=0.33620969296213166\n",
      " - ratio=0.28138455532576895, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5526, LPL: 1.3863, Contrastive: 0.1303\n",
      " - Metrics: Accuracy=0.9243, F1=0.8806, Recall=0.9242, Precision=0.8409\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7040451043893605, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.197532601484417, margin=0.6268451227871268, lpl_weight=0.33620969296213166\n",
      " - ratio=0.28138455532576895, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5526, LPL: 1.3863, Contrastive: 0.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:51:34,890] Trial 66 finished with value: 0.873848618029902 and parameters: {'alpha': 0.7040451043893605, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.197532601484417, 'margin': 0.6268451227871268, 'lpl_weight': 0.33620969296213166, 'ratio': 0.28138455532576895, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9095, F1=0.8612, Recall=0.9291, Precision=0.8025\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145101.csv.\n",
      "Average F1 over 5 seeds: 0.8738  0.0076\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7392792131061914, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.24952648605510835, margin=0.763359194602862, lpl_weight=0.5308619135872426\n",
      " - ratio=0.2661209909357206, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1376\n",
      " - Metrics: Accuracy=0.9317, F1=0.8907, Recall=0.9218, Precision=0.8617\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7392792131061914, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.24952648605510835, margin=0.763359194602862, lpl_weight=0.5308619135872426\n",
      " - ratio=0.2661209909357206, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1376\n",
      " - Metrics: Accuracy=0.9328, F1=0.8922, Recall=0.9205, Precision=0.8655\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7392792131061914, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.24952648605510835, margin=0.763359194602862, lpl_weight=0.5308619135872426\n",
      " - ratio=0.2661209909357206, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1376\n",
      " - Metrics: Accuracy=0.9221, F1=0.8761, Recall=0.9120, Precision=0.8429\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7392792131061914, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.24952648605510835, margin=0.763359194602862, lpl_weight=0.5308619135872426\n",
      " - ratio=0.2661209909357206, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1376\n",
      " - Metrics: Accuracy=0.9184, F1=0.8687, Recall=0.8936, Precision=0.8451\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7392792131061914, K=26, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.24952648605510835, margin=0.763359194602862, lpl_weight=0.5308619135872426\n",
      " - ratio=0.2661209909357206, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:52:08,659] Trial 67 finished with value: 0.8812114111560222 and parameters: {'alpha': 0.7392792131061914, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.24952648605510835, 'margin': 0.763359194602862, 'lpl_weight': 0.5308619135872426, 'ratio': 0.2661209909357206, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9232, F1=0.8784, Recall=0.9181, Precision=0.8419\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145134.csv.\n",
      "Average F1 over 5 seeds: 0.8812  0.0090\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5829512810685288, K=25, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1149566489781832, margin=0.8371333781705237, lpl_weight=0.49663781153322906\n",
      " - ratio=0.22701113855612978, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7481, LPL: 1.3863, Contrastive: 0.1184\n",
      " - Metrics: Accuracy=0.9369, F1=0.8969, Recall=0.9095, Precision=0.8847\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5829512810685288, K=25, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1149566489781832, margin=0.8371333781705237, lpl_weight=0.49663781153322906\n",
      " - ratio=0.22701113855612978, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7481, LPL: 1.3863, Contrastive: 0.1184\n",
      " - Metrics: Accuracy=0.9302, F1=0.8861, Recall=0.8985, Precision=0.8740\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5829512810685288, K=25, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1149566489781832, margin=0.8371333781705237, lpl_weight=0.49663781153322906\n",
      " - ratio=0.22701113855612978, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7481, LPL: 1.3863, Contrastive: 0.1184\n",
      " - Metrics: Accuracy=0.9280, F1=0.8823, Recall=0.8936, Precision=0.8713\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5829512810685288, K=25, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1149566489781832, margin=0.8371333781705237, lpl_weight=0.49663781153322906\n",
      " - ratio=0.22701113855612978, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7481, LPL: 1.3863, Contrastive: 0.1184\n",
      " - Metrics: Accuracy=0.9258, F1=0.8785, Recall=0.8888, Precision=0.8686\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5829512810685288, K=25, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1149566489781832, margin=0.8371333781705237, lpl_weight=0.49663781153322906\n",
      " - ratio=0.22701113855612978, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7481, LPL: 1.3863, Contrastive: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:52:42,702] Trial 68 finished with value: 0.887089991700876 and parameters: {'alpha': 0.5829512810685288, 'K': 25, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1149566489781832, 'margin': 0.8371333781705237, 'lpl_weight': 0.49663781153322906, 'ratio': 0.22701113855612978, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9339, F1=0.8916, Recall=0.8998, Precision=0.8836\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145208.csv.\n",
      "Average F1 over 5 seeds: 0.8871  0.0065\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8053031256267417, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.1378146705572058, margin=0.9159941332126126, lpl_weight=0.39726055629952006\n",
      " - ratio=0.183231182134363, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6402, LPL: 1.3863, Contrastive: 0.1485\n",
      " - Metrics: Accuracy=0.9103, F1=0.8467, Recall=0.8203, Precision=0.8748\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8053031256267417, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.1378146705572058, margin=0.9159941332126126, lpl_weight=0.39726055629952006\n",
      " - ratio=0.183231182134363, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6402, LPL: 1.3863, Contrastive: 0.1485\n",
      " - Metrics: Accuracy=0.9088, F1=0.8436, Recall=0.8142, Precision=0.8752\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8053031256267417, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.1378146705572058, margin=0.9159941332126126, lpl_weight=0.39726055629952006\n",
      " - ratio=0.183231182134363, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6402, LPL: 1.3863, Contrastive: 0.1485\n",
      " - Metrics: Accuracy=0.9014, F1=0.8307, Recall=0.8007, Precision=0.8630\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8053031256267417, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.1378146705572058, margin=0.9159941332126126, lpl_weight=0.39726055629952006\n",
      " - ratio=0.183231182134363, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6402, LPL: 1.3863, Contrastive: 0.1485\n",
      " - Metrics: Accuracy=0.8988, F1=0.8248, Recall=0.7885, Precision=0.8646\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8053031256267417, K=26, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.1378146705572058, margin=0.9159941332126126, lpl_weight=0.39726055629952006\n",
      " - ratio=0.183231182134363, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6402, LPL: 1.3863, Contrastive: 0.1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:53:19,171] Trial 69 finished with value: 0.8378264884026253 and parameters: {'alpha': 0.8053031256267417, 'K': 26, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1378146705572058, 'margin': 0.9159941332126126, 'lpl_weight': 0.39726055629952006, 'ratio': 0.183231182134363, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9088, F1=0.8434, Recall=0.8130, Precision=0.8762\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145242.csv.\n",
      "Average F1 over 5 seeds: 0.8378  0.0085\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4921755550701528, K=32, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2174145694453343, margin=0.6441499052936286, lpl_weight=0.43860622604422383\n",
      " - ratio=0.3152843301098665, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6572, LPL: 1.3863, Contrastive: 0.0876\n",
      " - Metrics: Accuracy=0.9021, F1=0.8517, Recall=0.9303, Precision=0.7853\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4921755550701528, K=32, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2174145694453343, margin=0.6441499052936286, lpl_weight=0.43860622604422383\n",
      " - ratio=0.3152843301098665, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6572, LPL: 1.3863, Contrastive: 0.0876\n",
      " - Metrics: Accuracy=0.8925, F1=0.8404, Recall=0.9364, Precision=0.7622\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4921755550701528, K=32, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2174145694453343, margin=0.6441499052936286, lpl_weight=0.43860622604422383\n",
      " - ratio=0.3152843301098665, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6572, LPL: 1.3863, Contrastive: 0.0876\n",
      " - Metrics: Accuracy=0.8951, F1=0.8424, Recall=0.9279, Precision=0.7713\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4921755550701528, K=32, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2174145694453343, margin=0.6441499052936286, lpl_weight=0.43860622604422383\n",
      " - ratio=0.3152843301098665, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6572, LPL: 1.3863, Contrastive: 0.0876\n",
      " - Metrics: Accuracy=0.8981, F1=0.8460, Recall=0.9267, Precision=0.7782\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4921755550701528, K=32, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2174145694453343, margin=0.6441499052936286, lpl_weight=0.43860622604422383\n",
      " - ratio=0.3152843301098665, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6572, LPL: 1.3863, Contrastive: 0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:53:54,989] Trial 70 finished with value: 0.8474562543802191 and parameters: {'alpha': 0.4921755550701528, 'K': 32, 'layers': 3, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2174145694453343, 'margin': 0.6441499052936286, 'lpl_weight': 0.43860622604422383, 'ratio': 0.3152843301098665, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9058, F1=0.8568, Recall=0.9328, Precision=0.7923\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145319.csv.\n",
      "Average F1 over 5 seeds: 0.8475  0.0061\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6718165121115716, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.17440604406946655, margin=0.4952247332312566, lpl_weight=0.6191019260840178\n",
      " - ratio=0.23962112601470265, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9193, LPL: 1.3863, Contrastive: 0.1602\n",
      " - Metrics: Accuracy=0.9298, F1=0.8872, Recall=0.9132, Precision=0.8626\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6718165121115716, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.17440604406946655, margin=0.4952247332312566, lpl_weight=0.6191019260840178\n",
      " - ratio=0.23962112601470265, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9193, LPL: 1.3863, Contrastive: 0.1602\n",
      " - Metrics: Accuracy=0.9298, F1=0.8865, Recall=0.9071, Precision=0.8668\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6718165121115716, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.17440604406946655, margin=0.4952247332312566, lpl_weight=0.6191019260840178\n",
      " - ratio=0.23962112601470265, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9193, LPL: 1.3863, Contrastive: 0.1602\n",
      " - Metrics: Accuracy=0.9328, F1=0.8917, Recall=0.9156, Precision=0.8689\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6718165121115716, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.17440604406946655, margin=0.4952247332312566, lpl_weight=0.6191019260840178\n",
      " - ratio=0.23962112601470265, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9193, LPL: 1.3863, Contrastive: 0.1602\n",
      " - Metrics: Accuracy=0.9321, F1=0.8907, Recall=0.9169, Precision=0.8661\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6718165121115716, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.17440604406946655, margin=0.4952247332312566, lpl_weight=0.6191019260840178\n",
      " - ratio=0.23962112601470265, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9193, LPL: 1.3863, Contrastive: 0.1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:54:21,548] Trial 71 finished with value: 0.888624978279011 and parameters: {'alpha': 0.6718165121115716, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.17440604406946655, 'margin': 0.4952247332312566, 'lpl_weight': 0.6191019260840178, 'ratio': 0.23962112601470265, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9295, F1=0.8870, Recall=0.9169, Precision=0.8591\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145355.csv.\n",
      "Average F1 over 5 seeds: 0.8886  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.41652661954544234, K=28, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.19008928192023014, margin=0.4403949667129807, lpl_weight=0.1207577727400938\n",
      " - ratio=0.22377988825188425, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3123, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 50, Loss: 0.2397, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.2385, LPL: 1.3863, Contrastive: 0.0808\n",
      "Epoch 150, Loss: 0.2380, LPL: 1.3863, Contrastive: 0.0803\n",
      " - Metrics: Accuracy=0.9339, F1=0.8892, Recall=0.8778, Precision=0.9009\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.41652661954544234, K=28, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.19008928192023014, margin=0.4403949667129807, lpl_weight=0.1207577727400938\n",
      " - ratio=0.22377988825188425, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3123, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 50, Loss: 0.2397, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.2385, LPL: 1.3863, Contrastive: 0.0808\n",
      "Epoch 150, Loss: 0.2380, LPL: 1.3863, Contrastive: 0.0803\n",
      " - Metrics: Accuracy=0.9376, F1=0.8968, Recall=0.8973, Precision=0.8962\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.41652661954544234, K=28, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.19008928192023014, margin=0.4403949667129807, lpl_weight=0.1207577727400938\n",
      " - ratio=0.22377988825188425, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3123, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 50, Loss: 0.2397, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.2385, LPL: 1.3863, Contrastive: 0.0808\n",
      " - Metrics: Accuracy=0.9402, F1=0.9006, Recall=0.8973, Precision=0.9039\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.41652661954544234, K=28, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.19008928192023014, margin=0.4403949667129807, lpl_weight=0.1207577727400938\n",
      " - ratio=0.22377988825188425, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3123, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 50, Loss: 0.2397, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.2385, LPL: 1.3863, Contrastive: 0.0808\n",
      "Epoch 150, Loss: 0.2380, LPL: 1.3863, Contrastive: 0.0803\n",
      " - Metrics: Accuracy=0.9265, F1=0.8783, Recall=0.8778, Precision=0.8788\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.41652661954544234, K=28, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.19008928192023014, margin=0.4403949667129807, lpl_weight=0.1207577727400938\n",
      " - ratio=0.22377988825188425, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3123, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 50, Loss: 0.2397, LPL: 1.3863, Contrastive: 0.0822\n",
      "Epoch 100, Loss: 0.2385, LPL: 1.3863, Contrastive: 0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:55:28,812] Trial 72 finished with value: 0.8917046672945762 and parameters: {'alpha': 0.41652661954544234, 'K': 28, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.19008928192023014, 'margin': 0.4403949667129807, 'lpl_weight': 0.1207577727400938, 'ratio': 0.22377988825188425, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9365, F1=0.8937, Recall=0.8839, Precision=0.9038\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145421.csv.\n",
      "Average F1 over 5 seeds: 0.8917  0.0077\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9336188947752536, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1599581003058116, margin=0.5313042002462283, lpl_weight=0.18911155390438722\n",
      " - ratio=0.19780855063623773, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3886, LPL: 1.3863, Contrastive: 0.1560\n",
      "Epoch 50, Loss: 0.3095, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 100, Loss: 0.3083, LPL: 1.3863, Contrastive: 0.0568\n",
      "Epoch 150, Loss: 0.3081, LPL: 1.3863, Contrastive: 0.0567\n",
      " - Metrics: Accuracy=0.9324, F1=0.8861, Recall=0.8704, Precision=0.9024\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9336188947752536, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1599581003058116, margin=0.5313042002462283, lpl_weight=0.18911155390438722\n",
      " - ratio=0.19780855063623773, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3886, LPL: 1.3863, Contrastive: 0.1560\n",
      "Epoch 50, Loss: 0.3095, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 100, Loss: 0.3083, LPL: 1.3863, Contrastive: 0.0568\n",
      "Epoch 150, Loss: 0.3082, LPL: 1.3863, Contrastive: 0.0567\n",
      " - Metrics: Accuracy=0.9273, F1=0.8786, Recall=0.8716, Precision=0.8857\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9336188947752536, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1599581003058116, margin=0.5313042002462283, lpl_weight=0.18911155390438722\n",
      " - ratio=0.19780855063623773, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3886, LPL: 1.3863, Contrastive: 0.1560\n",
      "Epoch 50, Loss: 0.3095, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 100, Loss: 0.3083, LPL: 1.3863, Contrastive: 0.0568\n",
      "Epoch 150, Loss: 0.3083, LPL: 1.3863, Contrastive: 0.0569\n",
      " - Metrics: Accuracy=0.9428, F1=0.9045, Recall=0.8973, Precision=0.9118\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9336188947752536, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1599581003058116, margin=0.5313042002462283, lpl_weight=0.18911155390438722\n",
      " - ratio=0.19780855063623773, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3886, LPL: 1.3863, Contrastive: 0.1560\n",
      "Epoch 50, Loss: 0.3095, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 100, Loss: 0.3082, LPL: 1.3863, Contrastive: 0.0568\n",
      "Epoch 150, Loss: 0.3081, LPL: 1.3863, Contrastive: 0.0566\n",
      " - Metrics: Accuracy=0.9357, F1=0.8919, Recall=0.8778, Precision=0.9066\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9336188947752536, K=27, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.1599581003058116, margin=0.5313042002462283, lpl_weight=0.18911155390438722\n",
      " - ratio=0.19780855063623773, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3886, LPL: 1.3863, Contrastive: 0.1560\n",
      "Epoch 50, Loss: 0.3095, LPL: 1.3863, Contrastive: 0.0584\n",
      "Epoch 100, Loss: 0.3083, LPL: 1.3863, Contrastive: 0.0568\n",
      "Epoch 150, Loss: 0.3082, LPL: 1.3863, Contrastive: 0.0568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:56:36,510] Trial 73 finished with value: 0.8902579633766488 and parameters: {'alpha': 0.9336188947752536, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.1599581003058116, 'margin': 0.5313042002462283, 'lpl_weight': 0.18911155390438722, 'ratio': 0.19780855063623773, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 64 with value: 0.8976055666614717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9343, F1=0.8901, Recall=0.8814, Precision=0.8990\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145528.csv.\n",
      "Average F1 over 5 seeds: 0.8903  0.0085\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2055729875410836, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1104135618773921, margin=0.6939001069897156, lpl_weight=0.30356566632812654\n",
      " - ratio=0.21127741537653247, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5031, LPL: 1.3863, Contrastive: 0.1181\n",
      " - Metrics: Accuracy=0.9413, F1=0.9031, Recall=0.9059, Precision=0.9004\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2055729875410836, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1104135618773921, margin=0.6939001069897156, lpl_weight=0.30356566632812654\n",
      " - ratio=0.21127741537653247, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5031, LPL: 1.3863, Contrastive: 0.1181\n",
      " - Metrics: Accuracy=0.9387, F1=0.8995, Recall=0.9083, Precision=0.8909\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2055729875410836, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1104135618773921, margin=0.6939001069897156, lpl_weight=0.30356566632812654\n",
      " - ratio=0.21127741537653247, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5031, LPL: 1.3863, Contrastive: 0.1181\n",
      " - Metrics: Accuracy=0.9398, F1=0.9008, Recall=0.9046, Precision=0.8970\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2055729875410836, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1104135618773921, margin=0.6939001069897156, lpl_weight=0.30356566632812654\n",
      " - ratio=0.21127741537653247, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5031, LPL: 1.3863, Contrastive: 0.1181\n",
      " - Metrics: Accuracy=0.9387, F1=0.8979, Recall=0.8924, Precision=0.9035\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2055729875410836, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1104135618773921, margin=0.6939001069897156, lpl_weight=0.30356566632812654\n",
      " - ratio=0.21127741537653247, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5031, LPL: 1.3863, Contrastive: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:57:12,223] Trial 74 finished with value: 0.8986365732883037 and parameters: {'alpha': 0.2055729875410836, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1104135618773921, 'margin': 0.6939001069897156, 'lpl_weight': 0.30356566632812654, 'ratio': 0.21127741537653247, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 74 with value: 0.8986365732883037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9343, F1=0.8919, Recall=0.8973, Precision=0.8865\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145636.csv.\n",
      "Average F1 over 5 seeds: 0.8986  0.0038\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.20186945339894213, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12973130843034775, margin=0.7349927890482515, lpl_weight=0.24192674662059163\n",
      " - ratio=0.16130757633749013, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4269, LPL: 1.3863, Contrastive: 0.1207\n",
      " - Metrics: Accuracy=0.9376, F1=0.8912, Recall=0.8460, Precision=0.9415\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.20186945339894213, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12973130843034775, margin=0.7349927890482515, lpl_weight=0.24192674662059163\n",
      " - ratio=0.16130757633749013, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4269, LPL: 1.3863, Contrastive: 0.1207\n",
      " - Metrics: Accuracy=0.9317, F1=0.8807, Recall=0.8350, Precision=0.9318\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.20186945339894213, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12973130843034775, margin=0.7349927890482515, lpl_weight=0.24192674662059163\n",
      " - ratio=0.16130757633749013, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4269, LPL: 1.3863, Contrastive: 0.1207\n",
      " - Metrics: Accuracy=0.9354, F1=0.8870, Recall=0.8399, Precision=0.9398\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.20186945339894213, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12973130843034775, margin=0.7349927890482515, lpl_weight=0.24192674662059163\n",
      " - ratio=0.16130757633749013, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4269, LPL: 1.3863, Contrastive: 0.1207\n",
      " - Metrics: Accuracy=0.9357, F1=0.8882, Recall=0.8447, Precision=0.9363\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.20186945339894213, K=26, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.12973130843034775, margin=0.7349927890482515, lpl_weight=0.24192674662059163\n",
      " - ratio=0.16130757633749013, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4269, LPL: 1.3863, Contrastive: 0.1207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:57:47,125] Trial 75 finished with value: 0.8881377832773112 and parameters: {'alpha': 0.20186945339894213, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.12973130843034775, 'margin': 0.7349927890482515, 'lpl_weight': 0.24192674662059163, 'ratio': 0.16130757633749013, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 74 with value: 0.8986365732883037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9387, F1=0.8936, Recall=0.8521, Precision=0.9394\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145712.csv.\n",
      "Average F1 over 5 seeds: 0.8881  0.0044\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.31474918991770395, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10649094456999313, margin=0.6751312124025475, lpl_weight=0.31996810436640166\n",
      " - ratio=0.4175813141206929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5238, LPL: 1.3863, Contrastive: 0.1179\n",
      " - Metrics: Accuracy=0.8970, F1=0.8480, Recall=0.9511, Precision=0.7650\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.31474918991770395, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10649094456999313, margin=0.6751312124025475, lpl_weight=0.31996810436640166\n",
      " - ratio=0.4175813141206929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5238, LPL: 1.3863, Contrastive: 0.1179\n",
      " - Metrics: Accuracy=0.8888, F1=0.8393, Recall=0.9609, Precision=0.7450\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.31474918991770395, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10649094456999313, margin=0.6751312124025475, lpl_weight=0.31996810436640166\n",
      " - ratio=0.4175813141206929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5238, LPL: 1.3863, Contrastive: 0.1179\n",
      " - Metrics: Accuracy=0.8977, F1=0.8482, Recall=0.9462, Precision=0.7686\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.31474918991770395, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10649094456999313, margin=0.6751312124025475, lpl_weight=0.31996810436640166\n",
      " - ratio=0.4175813141206929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5238, LPL: 1.3863, Contrastive: 0.1179\n",
      " - Metrics: Accuracy=0.9032, F1=0.8557, Recall=0.9499, Precision=0.7786\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.31474918991770395, K=25, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10649094456999313, margin=0.6751312124025475, lpl_weight=0.31996810436640166\n",
      " - ratio=0.4175813141206929, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5238, LPL: 1.3863, Contrastive: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:58:19,284] Trial 76 finished with value: 0.8482013098975415 and parameters: {'alpha': 0.31474918991770395, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.10649094456999313, 'margin': 0.6751312124025475, 'lpl_weight': 0.31996810436640166, 'ratio': 0.4175813141206929, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 74 with value: 0.8986365732883037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8984, F1=0.8498, Recall=0.9511, Precision=0.7680\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145747.csv.\n",
      "Average F1 over 5 seeds: 0.8482  0.0053\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5544340824678612, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10186564304023132, margin=0.6936062659717405, lpl_weight=0.481052316622947\n",
      " - ratio=0.1757278355522852, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7277, LPL: 1.3863, Contrastive: 0.1171\n",
      " - Metrics: Accuracy=0.9439, F1=0.9042, Recall=0.8765, Precision=0.9336\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5544340824678612, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10186564304023132, margin=0.6936062659717405, lpl_weight=0.481052316622947\n",
      " - ratio=0.1757278355522852, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7277, LPL: 1.3863, Contrastive: 0.1171\n",
      " - Metrics: Accuracy=0.9376, F1=0.8928, Recall=0.8606, Precision=0.9275\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5544340824678612, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10186564304023132, margin=0.6936062659717405, lpl_weight=0.481052316622947\n",
      " - ratio=0.1757278355522852, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7277, LPL: 1.3863, Contrastive: 0.1171\n",
      " - Metrics: Accuracy=0.9413, F1=0.8999, Recall=0.8741, Precision=0.9274\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5544340824678612, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10186564304023132, margin=0.6936062659717405, lpl_weight=0.481052316622947\n",
      " - ratio=0.1757278355522852, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7277, LPL: 1.3863, Contrastive: 0.1171\n",
      " - Metrics: Accuracy=0.9372, F1=0.8921, Recall=0.8594, Precision=0.9274\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5544340824678612, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10186564304023132, margin=0.6936062659717405, lpl_weight=0.481052316622947\n",
      " - ratio=0.1757278355522852, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7277, LPL: 1.3863, Contrastive: 0.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 14:58:54,470] Trial 77 finished with value: 0.8975486738733359 and parameters: {'alpha': 0.5544340824678612, 'K': 31, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.10186564304023132, 'margin': 0.6936062659717405, 'lpl_weight': 0.481052316622947, 'ratio': 0.1757278355522852, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 74 with value: 0.8986365732883037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9405, F1=0.8987, Recall=0.8729, Precision=0.9261\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145819.csv.\n",
      "Average F1 over 5 seeds: 0.8975  0.0045\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.36400282152275054, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10090654865322382, margin=0.6860130417556554, lpl_weight=0.48035705798599093\n",
      " - ratio=0.17124235148992456, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6991, LPL: 1.3863, Contrastive: 0.0639\n",
      "Epoch 50, Loss: 0.6790, LPL: 1.3863, Contrastive: 0.0252\n",
      "Epoch 100, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 150, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 200, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0248\n",
      " - Metrics: Accuracy=0.9007, F1=0.8133, Recall=0.7164, Precision=0.9406\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.36400282152275054, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10090654865322382, margin=0.6860130417556554, lpl_weight=0.48035705798599093\n",
      " - ratio=0.17124235148992456, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6991, LPL: 1.3863, Contrastive: 0.0639\n",
      "Epoch 50, Loss: 0.6790, LPL: 1.3863, Contrastive: 0.0252\n",
      "Epoch 100, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 150, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 200, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0248\n",
      " - Metrics: Accuracy=0.8992, F1=0.8121, Recall=0.7213, Precision=0.9291\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.36400282152275054, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10090654865322382, margin=0.6860130417556554, lpl_weight=0.48035705798599093\n",
      " - ratio=0.17124235148992456, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6991, LPL: 1.3863, Contrastive: 0.0639\n",
      "Epoch 50, Loss: 0.6790, LPL: 1.3863, Contrastive: 0.0252\n",
      "Epoch 100, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 150, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 200, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0248\n",
      " - Metrics: Accuracy=0.9081, F1=0.8296, Recall=0.7408, Precision=0.9425\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.36400282152275054, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10090654865322382, margin=0.6860130417556554, lpl_weight=0.48035705798599093\n",
      " - ratio=0.17124235148992456, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6991, LPL: 1.3863, Contrastive: 0.0639\n",
      "Epoch 50, Loss: 0.6790, LPL: 1.3863, Contrastive: 0.0252\n",
      "Epoch 100, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 150, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 200, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0248\n",
      " - Metrics: Accuracy=0.9084, F1=0.8285, Recall=0.7323, Precision=0.9538\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.36400282152275054, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10090654865322382, margin=0.6860130417556554, lpl_weight=0.48035705798599093\n",
      " - ratio=0.17124235148992456, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6991, LPL: 1.3863, Contrastive: 0.0639\n",
      "Epoch 50, Loss: 0.6790, LPL: 1.3863, Contrastive: 0.0252\n",
      "Epoch 100, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 150, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0249\n",
      "Epoch 200, Loss: 0.6788, LPL: 1.3863, Contrastive: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:00:40,308] Trial 78 finished with value: 0.8208233376867502 and parameters: {'alpha': 0.36400282152275054, 'K': 31, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.10090654865322382, 'margin': 0.6860130417556554, 'lpl_weight': 0.48035705798599093, 'ratio': 0.17124235148992456, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 74 with value: 0.8986365732883037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9036, F1=0.8206, Recall=0.7298, Precision=0.9372\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102145854.csv.\n",
      "Average F1 over 5 seeds: 0.8208  0.0073\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2722668210023009, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11714003785041255, margin=0.6430338086522838, lpl_weight=0.5130495703035074\n",
      " - ratio=0.18957881741444985, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7694, LPL: 1.3863, Contrastive: 0.1195\n",
      " - Metrics: Accuracy=0.9494, F1=0.9145, Recall=0.8961, Precision=0.9338\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2722668210023009, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11714003785041255, margin=0.6430338086522838, lpl_weight=0.5130495703035074\n",
      " - ratio=0.18957881741444985, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7694, LPL: 1.3863, Contrastive: 0.1195\n",
      " - Metrics: Accuracy=0.9435, F1=0.9051, Recall=0.8924, Precision=0.9182\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2722668210023009, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11714003785041255, margin=0.6430338086522838, lpl_weight=0.5130495703035074\n",
      " - ratio=0.18957881741444985, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7694, LPL: 1.3863, Contrastive: 0.1195\n",
      " - Metrics: Accuracy=0.9398, F1=0.8998, Recall=0.8949, Precision=0.9048\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2722668210023009, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11714003785041255, margin=0.6430338086522838, lpl_weight=0.5130495703035074\n",
      " - ratio=0.18957881741444985, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7694, LPL: 1.3863, Contrastive: 0.1195\n",
      " - Metrics: Accuracy=0.9413, F1=0.9014, Recall=0.8888, Precision=0.9145\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2722668210023009, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11714003785041255, margin=0.6430338086522838, lpl_weight=0.5130495703035074\n",
      " - ratio=0.18957881741444985, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7694, LPL: 1.3863, Contrastive: 0.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:01:16,657] Trial 79 finished with value: 0.9032227171486319 and parameters: {'alpha': 0.2722668210023009, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.11714003785041255, 'margin': 0.6430338086522838, 'lpl_weight': 0.5130495703035074, 'ratio': 0.18957881741444985, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 79 with value: 0.9032227171486319.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9372, F1=0.8952, Recall=0.8875, Precision=0.9030\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150040.csv.\n",
      "Average F1 over 5 seeds: 0.9032  0.0065\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2650976280068105, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11370601749478691, margin=0.6385816127843098, lpl_weight=0.5377508234531202\n",
      " - ratio=0.18363712575909763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1191\n",
      " - Metrics: Accuracy=0.9446, F1=0.9065, Recall=0.8888, Precision=0.9249\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2650976280068105, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11370601749478691, margin=0.6385816127843098, lpl_weight=0.5377508234531202\n",
      " - ratio=0.18363712575909763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1191\n",
      " - Metrics: Accuracy=0.9472, F1=0.9113, Recall=0.8985, Precision=0.9245\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2650976280068105, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11370601749478691, margin=0.6385816127843098, lpl_weight=0.5377508234531202\n",
      " - ratio=0.18363712575909763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1191\n",
      " - Metrics: Accuracy=0.9428, F1=0.9037, Recall=0.8888, Precision=0.9191\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2650976280068105, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11370601749478691, margin=0.6385816127843098, lpl_weight=0.5377508234531202\n",
      " - ratio=0.18363712575909763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1191\n",
      " - Metrics: Accuracy=0.9435, F1=0.9038, Recall=0.8790, Precision=0.9301\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2650976280068105, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11370601749478691, margin=0.6385816127843098, lpl_weight=0.5377508234531202\n",
      " - ratio=0.18363712575909763, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8005, LPL: 1.3863, Contrastive: 0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:01:51,116] Trial 80 finished with value: 0.9053897958560334 and parameters: {'alpha': 0.2650976280068105, 'K': 31, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.11370601749478691, 'margin': 0.6385816127843098, 'lpl_weight': 0.5377508234531202, 'ratio': 0.18363712575909763, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 80 with value: 0.9053897958560334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9417, F1=0.9016, Recall=0.8851, Precision=0.9188\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150116.csv.\n",
      "Average F1 over 5 seeds: 0.9054  0.0034\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2735784265995187, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1122751507049513, margin=0.654959850383843, lpl_weight=0.5512072098850233\n",
      " - ratio=0.1887892826882448, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8173, LPL: 1.3863, Contrastive: 0.1186\n",
      " - Metrics: Accuracy=0.9483, F1=0.9127, Recall=0.8949, Precision=0.9313\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2735784265995187, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1122751507049513, margin=0.654959850383843, lpl_weight=0.5512072098850233\n",
      " - ratio=0.1887892826882448, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8173, LPL: 1.3863, Contrastive: 0.1186\n",
      " - Metrics: Accuracy=0.9424, F1=0.9038, Recall=0.8961, Precision=0.9117\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2735784265995187, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1122751507049513, margin=0.654959850383843, lpl_weight=0.5512072098850233\n",
      " - ratio=0.1887892826882448, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8173, LPL: 1.3863, Contrastive: 0.1186\n",
      " - Metrics: Accuracy=0.9413, F1=0.9017, Recall=0.8912, Precision=0.9124\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2735784265995187, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1122751507049513, margin=0.654959850383843, lpl_weight=0.5512072098850233\n",
      " - ratio=0.1887892826882448, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8173, LPL: 1.3863, Contrastive: 0.1186\n",
      " - Metrics: Accuracy=0.9413, F1=0.9006, Recall=0.8802, Precision=0.9219\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2735784265995187, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1122751507049513, margin=0.654959850383843, lpl_weight=0.5512072098850233\n",
      " - ratio=0.1887892826882448, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8173, LPL: 1.3863, Contrastive: 0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:02:26,527] Trial 81 finished with value: 0.9011779641862537 and parameters: {'alpha': 0.2735784265995187, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.1122751507049513, 'margin': 0.654959850383843, 'lpl_weight': 0.5512072098850233, 'ratio': 0.1887892826882448, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 80 with value: 0.9053897958560334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9321, F1=0.8871, Recall=0.8839, Precision=0.8904\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150151.csv.\n",
      "Average F1 over 5 seeds: 0.9012  0.0082\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.262894913184948, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11220397633789674, margin=0.6104435795059576, lpl_weight=0.5115255490403701\n",
      " - ratio=0.18409075643378162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7673, LPL: 1.3863, Contrastive: 0.1192\n",
      " - Metrics: Accuracy=0.9457, F1=0.9082, Recall=0.8888, Precision=0.9285\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.262894913184948, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11220397633789674, margin=0.6104435795059576, lpl_weight=0.5115255490403701\n",
      " - ratio=0.18409075643378162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7673, LPL: 1.3863, Contrastive: 0.1192\n",
      " - Metrics: Accuracy=0.9442, F1=0.9059, Recall=0.8888, Precision=0.9238\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.262894913184948, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11220397633789674, margin=0.6104435795059576, lpl_weight=0.5115255490403701\n",
      " - ratio=0.18409075643378162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7673, LPL: 1.3863, Contrastive: 0.1192\n",
      " - Metrics: Accuracy=0.9439, F1=0.9057, Recall=0.8924, Precision=0.9194\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.262894913184948, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11220397633789674, margin=0.6104435795059576, lpl_weight=0.5115255490403701\n",
      " - ratio=0.18409075643378162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7673, LPL: 1.3863, Contrastive: 0.1192\n",
      " - Metrics: Accuracy=0.9402, F1=0.8990, Recall=0.8814, Precision=0.9173\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.262894913184948, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11220397633789674, margin=0.6104435795059576, lpl_weight=0.5115255490403701\n",
      " - ratio=0.18409075643378162, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7673, LPL: 1.3863, Contrastive: 0.1192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:03:02,228] Trial 82 finished with value: 0.9051978593482308 and parameters: {'alpha': 0.262894913184948, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.11220397633789674, 'margin': 0.6104435795059576, 'lpl_weight': 0.5115255490403701, 'ratio': 0.18409075643378162, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 80 with value: 0.9053897958560334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9446, F1=0.9072, Recall=0.8961, Precision=0.9185\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150226.csv.\n",
      "Average F1 over 5 seeds: 0.9052  0.0032\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2808223375748188, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10784504904639507, margin=0.6508496989225496, lpl_weight=0.5426013747760599\n",
      " - ratio=0.18080522098428806, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.1183\n",
      " - Metrics: Accuracy=0.9431, F1=0.9035, Recall=0.8814, Precision=0.9267\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2808223375748188, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10784504904639507, margin=0.6508496989225496, lpl_weight=0.5426013747760599\n",
      " - ratio=0.18080522098428806, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.1183\n",
      " - Metrics: Accuracy=0.9453, F1=0.9075, Recall=0.8875, Precision=0.9284\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2808223375748188, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10784504904639507, margin=0.6508496989225496, lpl_weight=0.5426013747760599\n",
      " - ratio=0.18080522098428806, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.1183\n",
      " - Metrics: Accuracy=0.9413, F1=0.9008, Recall=0.8826, Precision=0.9197\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2808223375748188, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10784504904639507, margin=0.6508496989225496, lpl_weight=0.5426013747760599\n",
      " - ratio=0.18080522098428806, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.1183\n",
      " - Metrics: Accuracy=0.9431, F1=0.9036, Recall=0.8826, Precision=0.9256\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2808223375748188, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10784504904639507, margin=0.6508496989225496, lpl_weight=0.5426013747760599\n",
      " - ratio=0.18080522098428806, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8063, LPL: 1.3863, Contrastive: 0.1183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:03:37,929] Trial 83 finished with value: 0.9018608073735855 and parameters: {'alpha': 0.2808223375748188, 'K': 31, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.10784504904639507, 'margin': 0.6508496989225496, 'lpl_weight': 0.5426013747760599, 'ratio': 0.18080522098428806, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 80 with value: 0.9053897958560334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9369, F1=0.8939, Recall=0.8802, Precision=0.9079\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150302.csv.\n",
      "Average F1 over 5 seeds: 0.9019  0.0045\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2659792473805755, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11028543468502834, margin=0.6138220210749461, lpl_weight=0.5464560605010937\n",
      " - ratio=0.18460256771562278, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8115, LPL: 1.3863, Contrastive: 0.1189\n",
      " - Metrics: Accuracy=0.9494, F1=0.9147, Recall=0.8985, Precision=0.9316\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2659792473805755, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11028543468502834, margin=0.6138220210749461, lpl_weight=0.5464560605010937\n",
      " - ratio=0.18460256771562278, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8115, LPL: 1.3863, Contrastive: 0.1189\n",
      " - Metrics: Accuracy=0.9465, F1=0.9103, Recall=0.8998, Precision=0.9212\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2659792473805755, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11028543468502834, margin=0.6138220210749461, lpl_weight=0.5464560605010937\n",
      " - ratio=0.18460256771562278, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8115, LPL: 1.3863, Contrastive: 0.1189\n",
      " - Metrics: Accuracy=0.9439, F1=0.9056, Recall=0.8912, Precision=0.9205\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2659792473805755, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11028543468502834, margin=0.6138220210749461, lpl_weight=0.5464560605010937\n",
      " - ratio=0.18460256771562278, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8115, LPL: 1.3863, Contrastive: 0.1189\n",
      " - Metrics: Accuracy=0.9413, F1=0.9013, Recall=0.8875, Precision=0.9155\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2659792473805755, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11028543468502834, margin=0.6138220210749461, lpl_weight=0.5464560605010937\n",
      " - ratio=0.18460256771562278, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8115, LPL: 1.3863, Contrastive: 0.1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:04:12,608] Trial 84 finished with value: 0.9069667208768248 and parameters: {'alpha': 0.2659792473805755, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.11028543468502834, 'margin': 0.6138220210749461, 'lpl_weight': 0.5464560605010937, 'ratio': 0.18460256771562278, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 84 with value: 0.9069667208768248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9424, F1=0.9029, Recall=0.8863, Precision=0.9201\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150338.csv.\n",
      "Average F1 over 5 seeds: 0.9070  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2728548877982621, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10983782384421052, margin=0.6086949937206158, lpl_weight=0.5447089790416493\n",
      " - ratio=0.1587807806610388, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8093, LPL: 1.3863, Contrastive: 0.1190\n",
      " - Metrics: Accuracy=0.9435, F1=0.9024, Recall=0.8643, Precision=0.9439\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2728548877982621, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10983782384421052, margin=0.6086949937206158, lpl_weight=0.5447089790416493\n",
      " - ratio=0.1587807806610388, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8093, LPL: 1.3863, Contrastive: 0.1190\n",
      " - Metrics: Accuracy=0.9424, F1=0.9005, Recall=0.8631, Precision=0.9413\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2728548877982621, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10983782384421052, margin=0.6086949937206158, lpl_weight=0.5447089790416493\n",
      " - ratio=0.1587807806610388, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8093, LPL: 1.3863, Contrastive: 0.1190\n",
      " - Metrics: Accuracy=0.9420, F1=0.8998, Recall=0.8619, Precision=0.9413\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2728548877982621, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10983782384421052, margin=0.6086949937206158, lpl_weight=0.5447089790416493\n",
      " - ratio=0.1587807806610388, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8093, LPL: 1.3863, Contrastive: 0.1190\n",
      " - Metrics: Accuracy=0.9457, F1=0.9061, Recall=0.8667, Precision=0.9491\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2728548877982621, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10983782384421052, margin=0.6086949937206158, lpl_weight=0.5447089790416493\n",
      " - ratio=0.1587807806610388, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8093, LPL: 1.3863, Contrastive: 0.1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:04:48,298] Trial 85 finished with value: 0.902738641703564 and parameters: {'alpha': 0.2728548877982621, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.10983782384421052, 'margin': 0.6086949937206158, 'lpl_weight': 0.5447089790416493, 'ratio': 0.1587807806610388, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 84 with value: 0.9069667208768248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9446, F1=0.9049, Recall=0.8729, Precision=0.9395\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150412.csv.\n",
      "Average F1 over 5 seeds: 0.9027  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2593051041714778, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11009982690407315, margin=0.6505797490365179, lpl_weight=0.5396957722235918\n",
      " - ratio=0.16125248062037706, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8027, LPL: 1.3863, Contrastive: 0.1184\n",
      " - Metrics: Accuracy=0.9450, F1=0.9053, Recall=0.8704, Precision=0.9430\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2593051041714778, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11009982690407315, margin=0.6505797490365179, lpl_weight=0.5396957722235918\n",
      " - ratio=0.16125248062037706, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8027, LPL: 1.3863, Contrastive: 0.1184\n",
      " - Metrics: Accuracy=0.9405, F1=0.8979, Recall=0.8655, Precision=0.9328\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2593051041714778, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11009982690407315, margin=0.6505797490365179, lpl_weight=0.5396957722235918\n",
      " - ratio=0.16125248062037706, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8027, LPL: 1.3863, Contrastive: 0.1184\n",
      " - Metrics: Accuracy=0.9398, F1=0.8969, Recall=0.8667, Precision=0.9292\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2593051041714778, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11009982690407315, margin=0.6505797490365179, lpl_weight=0.5396957722235918\n",
      " - ratio=0.16125248062037706, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8027, LPL: 1.3863, Contrastive: 0.1184\n",
      " - Metrics: Accuracy=0.9402, F1=0.8966, Recall=0.8582, Precision=0.9385\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2593051041714778, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11009982690407315, margin=0.6505797490365179, lpl_weight=0.5396957722235918\n",
      " - ratio=0.16125248062037706, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8027, LPL: 1.3863, Contrastive: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:05:25,320] Trial 86 finished with value: 0.8995303218233932 and parameters: {'alpha': 0.2593051041714778, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.11009982690407315, 'margin': 0.6505797490365179, 'lpl_weight': 0.5396957722235918, 'ratio': 0.16125248062037706, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 84 with value: 0.9069667208768248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9424, F1=0.9010, Recall=0.8680, Precision=0.9367\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150448.csv.\n",
      "Average F1 over 5 seeds: 0.8995  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.27947278993190977, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11541550286611998, margin=0.6080148402524234, lpl_weight=0.6010082821641163\n",
      " - ratio=0.12180772246438189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8809, LPL: 1.3863, Contrastive: 0.1197\n",
      " - Metrics: Accuracy=0.9302, F1=0.8739, Recall=0.8007, Precision=0.9618\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.27947278993190977, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11541550286611998, margin=0.6080148402524234, lpl_weight=0.6010082821641163\n",
      " - ratio=0.12180772246438189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8809, LPL: 1.3863, Contrastive: 0.1197\n",
      " - Metrics: Accuracy=0.9273, F1=0.8684, Recall=0.7946, Precision=0.9573\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.27947278993190977, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11541550286611998, margin=0.6080148402524234, lpl_weight=0.6010082821641163\n",
      " - ratio=0.12180772246438189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8809, LPL: 1.3863, Contrastive: 0.1197\n",
      " - Metrics: Accuracy=0.9273, F1=0.8677, Recall=0.7897, Precision=0.9627\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.27947278993190977, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11541550286611998, margin=0.6080148402524234, lpl_weight=0.6010082821641163\n",
      " - ratio=0.12180772246438189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8809, LPL: 1.3863, Contrastive: 0.1197\n",
      " - Metrics: Accuracy=0.9313, F1=0.8760, Recall=0.8032, Precision=0.9633\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.27947278993190977, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11541550286611998, margin=0.6080148402524234, lpl_weight=0.6010082821641163\n",
      " - ratio=0.12180772246438189, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8809, LPL: 1.3863, Contrastive: 0.1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:06:01,685] Trial 87 finished with value: 0.8722198716949349 and parameters: {'alpha': 0.27947278993190977, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.11541550286611998, 'margin': 0.6080148402524234, 'lpl_weight': 0.6010082821641163, 'ratio': 0.12180772246438189, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 84 with value: 0.9069667208768248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9309, F1=0.8751, Recall=0.8007, Precision=0.9647\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150525.csv.\n",
      "Average F1 over 5 seeds: 0.8722  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2624500758148273, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11128839117371542, margin=0.6509354750951071, lpl_weight=0.5482438493524614\n",
      " - ratio=0.15838213525883893, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8136, LPL: 1.3863, Contrastive: 0.1185\n",
      " - Metrics: Accuracy=0.9417, F1=0.8991, Recall=0.8606, Precision=0.9412\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2624500758148273, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11128839117371542, margin=0.6509354750951071, lpl_weight=0.5482438493524614\n",
      " - ratio=0.15838213525883893, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8136, LPL: 1.3863, Contrastive: 0.1185\n",
      " - Metrics: Accuracy=0.9372, F1=0.8917, Recall=0.8557, Precision=0.9309\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2624500758148273, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11128839117371542, margin=0.6509354750951071, lpl_weight=0.5482438493524614\n",
      " - ratio=0.15838213525883893, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8136, LPL: 1.3863, Contrastive: 0.1185\n",
      " - Metrics: Accuracy=0.9391, F1=0.8952, Recall=0.8619, Precision=0.9313\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2624500758148273, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11128839117371542, margin=0.6509354750951071, lpl_weight=0.5482438493524614\n",
      " - ratio=0.15838213525883893, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8136, LPL: 1.3863, Contrastive: 0.1185\n",
      " - Metrics: Accuracy=0.9391, F1=0.8942, Recall=0.8521, Precision=0.9406\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2624500758148273, K=32, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11128839117371542, margin=0.6509354750951071, lpl_weight=0.5482438493524614\n",
      " - ratio=0.15838213525883893, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8136, LPL: 1.3863, Contrastive: 0.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:06:37,790] Trial 88 finished with value: 0.896985633136006 and parameters: {'alpha': 0.2624500758148273, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.11128839117371542, 'margin': 0.6509354750951071, 'lpl_weight': 0.5482438493524614, 'ratio': 0.15838213525883893, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 84 with value: 0.9069667208768248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9446, F1=0.9047, Recall=0.8704, Precision=0.9418\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150601.csv.\n",
      "Average F1 over 5 seeds: 0.8970  0.0045\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.30999330537243497, K=33, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.1364208696927905, margin=0.5566859447872137, lpl_weight=0.5089852981650325\n",
      " - ratio=0.13677289937637996, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7792, LPL: 1.3863, Contrastive: 0.1498\n",
      "Epoch 50, Loss: 0.7314, LPL: 1.3863, Contrastive: 0.0526\n",
      "Epoch 100, Loss: 0.7307, LPL: 1.3863, Contrastive: 0.0511\n",
      "Epoch 150, Loss: 0.7306, LPL: 1.3863, Contrastive: 0.0509\n",
      "Epoch 200, Loss: 0.7304, LPL: 1.3863, Contrastive: 0.0506\n",
      "Epoch 250, Loss: 0.7303, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 300, Loss: 0.7302, LPL: 1.3863, Contrastive: 0.0501\n",
      " - Metrics: Accuracy=0.9151, F1=0.8467, Recall=0.7763, Precision=0.9311\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.30999330537243497, K=33, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.1364208696927905, margin=0.5566859447872137, lpl_weight=0.5089852981650325\n",
      " - ratio=0.13677289937637996, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7792, LPL: 1.3863, Contrastive: 0.1498\n",
      "Epoch 50, Loss: 0.7314, LPL: 1.3863, Contrastive: 0.0526\n",
      "Epoch 100, Loss: 0.7307, LPL: 1.3863, Contrastive: 0.0511\n",
      "Epoch 150, Loss: 0.7306, LPL: 1.3863, Contrastive: 0.0509\n",
      "Epoch 200, Loss: 0.7304, LPL: 1.3863, Contrastive: 0.0506\n",
      "Epoch 250, Loss: 0.7303, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 300, Loss: 0.7302, LPL: 1.3863, Contrastive: 0.0501\n",
      " - Metrics: Accuracy=0.9151, F1=0.8463, Recall=0.7738, Precision=0.9336\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.30999330537243497, K=33, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.1364208696927905, margin=0.5566859447872137, lpl_weight=0.5089852981650325\n",
      " - ratio=0.13677289937637996, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7792, LPL: 1.3863, Contrastive: 0.1498\n",
      "Epoch 50, Loss: 0.7314, LPL: 1.3863, Contrastive: 0.0526\n",
      "Epoch 100, Loss: 0.7307, LPL: 1.3863, Contrastive: 0.0511\n",
      "Epoch 150, Loss: 0.7306, LPL: 1.3863, Contrastive: 0.0509\n",
      "Epoch 200, Loss: 0.7304, LPL: 1.3863, Contrastive: 0.0506\n",
      "Epoch 250, Loss: 0.7303, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 300, Loss: 0.7302, LPL: 1.3863, Contrastive: 0.0501\n",
      " - Metrics: Accuracy=0.9191, F1=0.8541, Recall=0.7836, Precision=0.9385\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.30999330537243497, K=33, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.1364208696927905, margin=0.5566859447872137, lpl_weight=0.5089852981650325\n",
      " - ratio=0.13677289937637996, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7792, LPL: 1.3863, Contrastive: 0.1498\n",
      "Epoch 50, Loss: 0.7314, LPL: 1.3863, Contrastive: 0.0526\n",
      "Epoch 100, Loss: 0.7307, LPL: 1.3863, Contrastive: 0.0511\n",
      "Epoch 150, Loss: 0.7306, LPL: 1.3863, Contrastive: 0.0509\n",
      "Epoch 200, Loss: 0.7304, LPL: 1.3863, Contrastive: 0.0506\n",
      "Epoch 250, Loss: 0.7303, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 300, Loss: 0.7302, LPL: 1.3863, Contrastive: 0.0501\n",
      " - Metrics: Accuracy=0.9221, F1=0.8591, Recall=0.7861, Precision=0.9470\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.30999330537243497, K=33, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.1364208696927905, margin=0.5566859447872137, lpl_weight=0.5089852981650325\n",
      " - ratio=0.13677289937637996, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7792, LPL: 1.3863, Contrastive: 0.1498\n",
      "Epoch 50, Loss: 0.7314, LPL: 1.3863, Contrastive: 0.0526\n",
      "Epoch 100, Loss: 0.7307, LPL: 1.3863, Contrastive: 0.0511\n",
      "Epoch 150, Loss: 0.7306, LPL: 1.3863, Contrastive: 0.0509\n",
      "Epoch 200, Loss: 0.7304, LPL: 1.3863, Contrastive: 0.0506\n",
      "Epoch 250, Loss: 0.7303, LPL: 1.3863, Contrastive: 0.0503\n",
      "Epoch 300, Loss: 0.7302, LPL: 1.3863, Contrastive: 0.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:08:38,253] Trial 89 finished with value: 0.8507825174827053 and parameters: {'alpha': 0.30999330537243497, 'K': 33, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.1364208696927905, 'margin': 0.5566859447872137, 'lpl_weight': 0.5089852981650325, 'ratio': 0.13677289937637996, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 84 with value: 0.9069667208768248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9154, F1=0.8478, Recall=0.7800, Precision=0.9287\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150637.csv.\n",
      "Average F1 over 5 seeds: 0.8508  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.35769555280645726, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11323527664114902, margin=0.5779114468133074, lpl_weight=0.6508135130248496\n",
      " - ratio=0.1876169343882858, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9442, LPL: 1.3863, Contrastive: 0.1201\n",
      " - Metrics: Accuracy=0.9457, F1=0.9083, Recall=0.8900, Precision=0.9274\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.35769555280645726, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11323527664114902, margin=0.5779114468133074, lpl_weight=0.6508135130248496\n",
      " - ratio=0.1876169343882858, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9442, LPL: 1.3863, Contrastive: 0.1201\n",
      " - Metrics: Accuracy=0.9420, F1=0.9022, Recall=0.8851, Precision=0.9199\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.35769555280645726, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11323527664114902, margin=0.5779114468133074, lpl_weight=0.6508135130248496\n",
      " - ratio=0.1876169343882858, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9442, LPL: 1.3863, Contrastive: 0.1201\n",
      " - Metrics: Accuracy=0.9450, F1=0.9073, Recall=0.8912, Precision=0.9240\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.35769555280645726, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11323527664114902, margin=0.5779114468133074, lpl_weight=0.6508135130248496\n",
      " - ratio=0.1876169343882858, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9442, LPL: 1.3863, Contrastive: 0.1201\n",
      " - Metrics: Accuracy=0.9417, F1=0.9020, Recall=0.8888, Precision=0.9156\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.35769555280645726, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.11323527664114902, margin=0.5779114468133074, lpl_weight=0.6508135130248496\n",
      " - ratio=0.1876169343882858, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9442, LPL: 1.3863, Contrastive: 0.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:09:24,740] Trial 90 finished with value: 0.9042582750073928 and parameters: {'alpha': 0.35769555280645726, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.11323527664114902, 'margin': 0.5779114468133074, 'lpl_weight': 0.6508135130248496, 'ratio': 0.1876169343882858, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 84 with value: 0.9069667208768248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9413, F1=0.9015, Recall=0.8900, Precision=0.9134\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150838.csv.\n",
      "Average F1 over 5 seeds: 0.9043  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3373822370861275, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1097238817127695, margin=0.6030206027429083, lpl_weight=0.6481747596336911\n",
      " - ratio=0.1810073136528454, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9405, LPL: 1.3863, Contrastive: 0.1191\n",
      " - Metrics: Accuracy=0.9417, F1=0.9012, Recall=0.8814, Precision=0.9220\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3373822370861275, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1097238817127695, margin=0.6030206027429083, lpl_weight=0.6481747596336911\n",
      " - ratio=0.1810073136528454, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9405, LPL: 1.3863, Contrastive: 0.1191\n",
      " - Metrics: Accuracy=0.9442, F1=0.9058, Recall=0.8875, Precision=0.9248\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3373822370861275, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1097238817127695, margin=0.6030206027429083, lpl_weight=0.6481747596336911\n",
      " - ratio=0.1810073136528454, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9405, LPL: 1.3863, Contrastive: 0.1191\n",
      " - Metrics: Accuracy=0.9435, F1=0.9047, Recall=0.8875, Precision=0.9225\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3373822370861275, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1097238817127695, margin=0.6030206027429083, lpl_weight=0.6481747596336911\n",
      " - ratio=0.1810073136528454, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9405, LPL: 1.3863, Contrastive: 0.1191\n",
      " - Metrics: Accuracy=0.9446, F1=0.9060, Recall=0.8839, Precision=0.9293\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3373822370861275, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1097238817127695, margin=0.6030206027429083, lpl_weight=0.6481747596336911\n",
      " - ratio=0.1810073136528454, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9405, LPL: 1.3863, Contrastive: 0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:10:07,014] Trial 91 finished with value: 0.9048446694545529 and parameters: {'alpha': 0.3373822370861275, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.1097238817127695, 'margin': 0.6030206027429083, 'lpl_weight': 0.6481747596336911, 'ratio': 0.1810073136528454, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 84 with value: 0.9069667208768248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9446, F1=0.9065, Recall=0.8888, Precision=0.9249\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102150924.csv.\n",
      "Average F1 over 5 seeds: 0.9048  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3363418036378095, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10027806837130233, margin=0.6122135674174606, lpl_weight=0.6855152573652302\n",
      " - ratio=0.14947223345844662, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9874, LPL: 1.3863, Contrastive: 0.1178\n",
      " - Metrics: Accuracy=0.9405, F1=0.8962, Recall=0.8496, Precision=0.9482\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3363418036378095, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10027806837130233, margin=0.6122135674174606, lpl_weight=0.6855152573652302\n",
      " - ratio=0.14947223345844662, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9874, LPL: 1.3863, Contrastive: 0.1178\n",
      " - Metrics: Accuracy=0.9365, F1=0.8889, Recall=0.8411, Precision=0.9425\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3363418036378095, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10027806837130233, margin=0.6122135674174606, lpl_weight=0.6855152573652302\n",
      " - ratio=0.14947223345844662, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9874, LPL: 1.3863, Contrastive: 0.1178\n",
      " - Metrics: Accuracy=0.9405, F1=0.8961, Recall=0.8484, Precision=0.9494\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3363418036378095, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10027806837130233, margin=0.6122135674174606, lpl_weight=0.6855152573652302\n",
      " - ratio=0.14947223345844662, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9874, LPL: 1.3863, Contrastive: 0.1178\n",
      " - Metrics: Accuracy=0.9394, F1=0.8942, Recall=0.8472, Precision=0.9467\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3363418036378095, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.10027806837130233, margin=0.6122135674174606, lpl_weight=0.6855152573652302\n",
      " - ratio=0.14947223345844662, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9874, LPL: 1.3863, Contrastive: 0.1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:10:52,805] Trial 92 finished with value: 0.8948116728081918 and parameters: {'alpha': 0.3363418036378095, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.10027806837130233, 'margin': 0.6122135674174606, 'lpl_weight': 0.6855152573652302, 'ratio': 0.14947223345844662, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 84 with value: 0.9069667208768248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9417, F1=0.8987, Recall=0.8570, Precision=0.9447\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102151007.csv.\n",
      "Average F1 over 5 seeds: 0.8948  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3646851286915938, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1160176450126895, margin=0.5797681958669664, lpl_weight=0.6566368540932288\n",
      " - ratio=0.18077581608302912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9516, LPL: 1.3863, Contrastive: 0.1203\n",
      " - Metrics: Accuracy=0.9487, F1=0.9131, Recall=0.8924, Precision=0.9347\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3646851286915938, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1160176450126895, margin=0.5797681958669664, lpl_weight=0.6566368540932288\n",
      " - ratio=0.18077581608302912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9516, LPL: 1.3863, Contrastive: 0.1203\n",
      " - Metrics: Accuracy=0.9439, F1=0.9051, Recall=0.8863, Precision=0.9247\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3646851286915938, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1160176450126895, margin=0.5797681958669664, lpl_weight=0.6566368540932288\n",
      " - ratio=0.18077581608302912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9516, LPL: 1.3863, Contrastive: 0.1203\n",
      " - Metrics: Accuracy=0.9446, F1=0.9065, Recall=0.8888, Precision=0.9249\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3646851286915938, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1160176450126895, margin=0.5797681958669664, lpl_weight=0.6566368540932288\n",
      " - ratio=0.18077581608302912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9516, LPL: 1.3863, Contrastive: 0.1203\n",
      " - Metrics: Accuracy=0.9446, F1=0.9062, Recall=0.8863, Precision=0.9271\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3646851286915938, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1160176450126895, margin=0.5797681958669664, lpl_weight=0.6566368540932288\n",
      " - ratio=0.18077581608302912, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9516, LPL: 1.3863, Contrastive: 0.1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:11:34,386] Trial 93 finished with value: 0.9070065300961664 and parameters: {'alpha': 0.3646851286915938, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.1160176450126895, 'margin': 0.5797681958669664, 'lpl_weight': 0.6566368540932288, 'ratio': 0.18077581608302912, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 93 with value: 0.9070065300961664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9431, F1=0.9041, Recall=0.8875, Precision=0.9213\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102151052.csv.\n",
      "Average F1 over 5 seeds: 0.9070  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.40048904442770317, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13407661439070012, margin=0.5921051393926662, lpl_weight=0.630670085282741\n",
      " - ratio=0.18875987461050295, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9195, LPL: 1.3863, Contrastive: 0.1225\n",
      " - Metrics: Accuracy=0.9435, F1=0.9050, Recall=0.8912, Precision=0.9193\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.40048904442770317, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13407661439070012, margin=0.5921051393926662, lpl_weight=0.630670085282741\n",
      " - ratio=0.18875987461050295, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9195, LPL: 1.3863, Contrastive: 0.1225\n",
      " - Metrics: Accuracy=0.9439, F1=0.9057, Recall=0.8924, Precision=0.9194\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.40048904442770317, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13407661439070012, margin=0.5921051393926662, lpl_weight=0.630670085282741\n",
      " - ratio=0.18875987461050295, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9195, LPL: 1.3863, Contrastive: 0.1225\n",
      " - Metrics: Accuracy=0.9453, F1=0.9086, Recall=0.8998, Precision=0.9177\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.40048904442770317, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13407661439070012, margin=0.5921051393926662, lpl_weight=0.630670085282741\n",
      " - ratio=0.18875987461050295, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9195, LPL: 1.3863, Contrastive: 0.1225\n",
      " - Metrics: Accuracy=0.9483, F1=0.9133, Recall=0.9010, Precision=0.9259\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.40048904442770317, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13407661439070012, margin=0.5921051393926662, lpl_weight=0.630670085282741\n",
      " - ratio=0.18875987461050295, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9195, LPL: 1.3863, Contrastive: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:12:10,984] Trial 94 finished with value: 0.9072679583787939 and parameters: {'alpha': 0.40048904442770317, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.13407661439070012, 'margin': 0.5921051393926662, 'lpl_weight': 0.630670085282741, 'ratio': 0.18875987461050295, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 94 with value: 0.9072679583787939.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9424, F1=0.9037, Recall=0.8949, Precision=0.9127\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102151134.csv.\n",
      "Average F1 over 5 seeds: 0.9073  0.0034\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.38196916547322013, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13934316546292372, margin=0.5955009838655241, lpl_weight=0.6462643617516511\n",
      " - ratio=0.18432724985852963, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9394, LPL: 1.3863, Contrastive: 0.1230\n",
      " - Metrics: Accuracy=0.9420, F1=0.9022, Recall=0.8851, Precision=0.9199\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.38196916547322013, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13934316546292372, margin=0.5955009838655241, lpl_weight=0.6462643617516511\n",
      " - ratio=0.18432724985852963, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9394, LPL: 1.3863, Contrastive: 0.1230\n",
      " - Metrics: Accuracy=0.9442, F1=0.9063, Recall=0.8924, Precision=0.9206\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.38196916547322013, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13934316546292372, margin=0.5955009838655241, lpl_weight=0.6462643617516511\n",
      " - ratio=0.18432724985852963, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9394, LPL: 1.3863, Contrastive: 0.1230\n",
      " - Metrics: Accuracy=0.9442, F1=0.9062, Recall=0.8912, Precision=0.9216\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.38196916547322013, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13934316546292372, margin=0.5955009838655241, lpl_weight=0.6462643617516511\n",
      " - ratio=0.18432724985852963, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9394, LPL: 1.3863, Contrastive: 0.1230\n",
      " - Metrics: Accuracy=0.9424, F1=0.9031, Recall=0.8888, Precision=0.9179\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.38196916547322013, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13934316546292372, margin=0.5955009838655241, lpl_weight=0.6462643617516511\n",
      " - ratio=0.18432724985852963, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9394, LPL: 1.3863, Contrastive: 0.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:12:51,006] Trial 95 finished with value: 0.9051125228029712 and parameters: {'alpha': 0.38196916547322013, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.13934316546292372, 'margin': 0.5955009838655241, 'lpl_weight': 0.6462643617516511, 'ratio': 0.18432724985852963, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 94 with value: 0.9072679583787939.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9450, F1=0.9079, Recall=0.8973, Precision=0.9186\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102151211.csv.\n",
      "Average F1 over 5 seeds: 0.9051  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.40581498048569375, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1501907305266969, margin=0.5851959373803942, lpl_weight=0.6569206713536416\n",
      " - ratio=0.16936794659610174, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9534, LPL: 1.3863, Contrastive: 0.1245\n",
      " - Metrics: Accuracy=0.9457, F1=0.9070, Recall=0.8765, Precision=0.9397\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.40581498048569375, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1501907305266969, margin=0.5851959373803942, lpl_weight=0.6569206713536416\n",
      " - ratio=0.16936794659610174, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9534, LPL: 1.3863, Contrastive: 0.1245\n",
      " - Metrics: Accuracy=0.9420, F1=0.9012, Recall=0.8753, Precision=0.9287\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.40581498048569375, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1501907305266969, margin=0.5851959373803942, lpl_weight=0.6569206713536416\n",
      " - ratio=0.16936794659610174, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9534, LPL: 1.3863, Contrastive: 0.1245\n",
      " - Metrics: Accuracy=0.9483, F1=0.9119, Recall=0.8863, Precision=0.9391\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.40581498048569375, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1501907305266969, margin=0.5851959373803942, lpl_weight=0.6569206713536416\n",
      " - ratio=0.16936794659610174, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9534, LPL: 1.3863, Contrastive: 0.1245\n",
      " - Metrics: Accuracy=0.9446, F1=0.9053, Recall=0.8765, Precision=0.9360\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.40581498048569375, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1501907305266969, margin=0.5851959373803942, lpl_weight=0.6569206713536416\n",
      " - ratio=0.16936794659610174, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9534, LPL: 1.3863, Contrastive: 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:13:28,822] Trial 96 finished with value: 0.9057878681655238 and parameters: {'alpha': 0.40581498048569375, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.1501907305266969, 'margin': 0.5851959373803942, 'lpl_weight': 0.6569206713536416, 'ratio': 0.16936794659610174, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 94 with value: 0.9072679583787939.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9435, F1=0.9035, Recall=0.8753, Precision=0.9335\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102151251.csv.\n",
      "Average F1 over 5 seeds: 0.9058  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3908942201707772, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14826482759821835, margin=0.5792792625375316, lpl_weight=0.6411689232682336\n",
      " - ratio=0.17045331175016531, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9335, LPL: 1.3863, Contrastive: 0.1244\n",
      " - Metrics: Accuracy=0.9442, F1=0.9040, Recall=0.8692, Precision=0.9417\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3908942201707772, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14826482759821835, margin=0.5792792625375316, lpl_weight=0.6411689232682336\n",
      " - ratio=0.17045331175016531, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9335, LPL: 1.3863, Contrastive: 0.1244\n",
      " - Metrics: Accuracy=0.9439, F1=0.9046, Recall=0.8814, Precision=0.9291\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3908942201707772, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14826482759821835, margin=0.5792792625375316, lpl_weight=0.6411689232682336\n",
      " - ratio=0.17045331175016531, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9335, LPL: 1.3863, Contrastive: 0.1244\n",
      " - Metrics: Accuracy=0.9453, F1=0.9072, Recall=0.8839, Precision=0.9317\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3908942201707772, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14826482759821835, margin=0.5792792625375316, lpl_weight=0.6411689232682336\n",
      " - ratio=0.17045331175016531, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9335, LPL: 1.3863, Contrastive: 0.1244\n",
      " - Metrics: Accuracy=0.9442, F1=0.9050, Recall=0.8790, Precision=0.9326\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3908942201707772, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14826482759821835, margin=0.5792792625375316, lpl_weight=0.6411689232682336\n",
      " - ratio=0.17045331175016531, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9335, LPL: 1.3863, Contrastive: 0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:14:04,158] Trial 97 finished with value: 0.9065441360032545 and parameters: {'alpha': 0.3908942201707772, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.14826482759821835, 'margin': 0.5792792625375316, 'lpl_weight': 0.6411689232682336, 'ratio': 0.17045331175016531, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 94 with value: 0.9072679583787939.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9483, F1=0.9119, Recall=0.8863, Precision=0.9391\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102151328.csv.\n",
      "Average F1 over 5 seeds: 0.9065  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.41442746593917906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13630902369716563, margin=0.5665472555924278, lpl_weight=0.6528629823821546\n",
      " - ratio=0.17130083242022817, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9302, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 50, Loss: 0.9216, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.9215, LPL: 1.3863, Contrastive: 0.0474\n",
      " - Metrics: Accuracy=0.8977, F1=0.8051, Recall=0.6993, Precision=0.9486\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.41442746593917906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13630902369716563, margin=0.5665472555924278, lpl_weight=0.6528629823821546\n",
      " - ratio=0.17130083242022817, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9302, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 50, Loss: 0.9216, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.9215, LPL: 1.3863, Contrastive: 0.0474\n",
      " - Metrics: Accuracy=0.8996, F1=0.8071, Recall=0.6956, Precision=0.9611\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.41442746593917906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13630902369716563, margin=0.5665472555924278, lpl_weight=0.6528629823821546\n",
      " - ratio=0.17130083242022817, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9302, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 50, Loss: 0.9216, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.9215, LPL: 1.3863, Contrastive: 0.0474\n",
      " - Metrics: Accuracy=0.9044, F1=0.8200, Recall=0.7213, Precision=0.9501\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.41442746593917906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13630902369716563, margin=0.5665472555924278, lpl_weight=0.6528629823821546\n",
      " - ratio=0.17130083242022817, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9302, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 50, Loss: 0.9216, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.9215, LPL: 1.3863, Contrastive: 0.0474\n",
      " - Metrics: Accuracy=0.8907, F1=0.7880, Recall=0.6724, Precision=0.9516\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.41442746593917906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.13630902369716563, margin=0.5665472555924278, lpl_weight=0.6528629823821546\n",
      " - ratio=0.17130083242022817, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9302, LPL: 1.3863, Contrastive: 0.0724\n",
      "Epoch 50, Loss: 0.9216, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.9215, LPL: 1.3863, Contrastive: 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:15:22,163] Trial 98 finished with value: 0.8046443918453802 and parameters: {'alpha': 0.41442746593917906, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.13630902369716563, 'margin': 0.5665472555924278, 'lpl_weight': 0.6528629823821546, 'ratio': 0.17130083242022817, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 94 with value: 0.9072679583787939.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8962, F1=0.8031, Recall=0.7005, Precision=0.9409\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102151404.csv.\n",
      "Average F1 over 5 seeds: 0.8046  0.0102\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3615782966051645, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14697434142383314, margin=0.5821097014494977, lpl_weight=0.6433825926494596\n",
      " - ratio=0.19625485495073602, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9362, LPL: 1.3863, Contrastive: 0.1243\n",
      " - Metrics: Accuracy=0.9472, F1=0.9113, Recall=0.8985, Precision=0.9245\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3615782966051645, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14697434142383314, margin=0.5821097014494977, lpl_weight=0.6433825926494596\n",
      " - ratio=0.19625485495073602, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9362, LPL: 1.3863, Contrastive: 0.1243\n",
      " - Metrics: Accuracy=0.9435, F1=0.9063, Recall=0.9046, Precision=0.9080\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3615782966051645, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14697434142383314, margin=0.5821097014494977, lpl_weight=0.6433825926494596\n",
      " - ratio=0.19625485495073602, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9362, LPL: 1.3863, Contrastive: 0.1243\n",
      " - Metrics: Accuracy=0.9465, F1=0.9108, Recall=0.9046, Precision=0.9170\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3615782966051645, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14697434142383314, margin=0.5821097014494977, lpl_weight=0.6433825926494596\n",
      " - ratio=0.19625485495073602, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9362, LPL: 1.3863, Contrastive: 0.1243\n",
      " - Metrics: Accuracy=0.9442, F1=0.9072, Recall=0.9022, Precision=0.9122\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3615782966051645, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.14697434142383314, margin=0.5821097014494977, lpl_weight=0.6433825926494596\n",
      " - ratio=0.19625485495073602, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9362, LPL: 1.3863, Contrastive: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:15:57,888] Trial 99 finished with value: 0.9093667648493238 and parameters: {'alpha': 0.3615782966051645, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.14697434142383314, 'margin': 0.5821097014494977, 'lpl_weight': 0.6433825926494596, 'ratio': 0.19625485495073602, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 99 with value: 0.9093667648493238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9468, F1=0.9112, Recall=0.9034, Precision=0.9192\n",
      "Done. Results written to cora_experimentations\\cora_sar_2102151522.csv.\n",
      "Average F1 over 5 seeds: 0.9094  0.0022\n",
      "Best trial:\n",
      "  Average F1: 0.9093667648493238\n",
      "  Best parameters:\n",
      "    alpha: 0.3615782966051645\n",
      "    K: 35\n",
      "    layers: 2\n",
      "    hidden_channels: 256\n",
      "    out_channels: 256\n",
      "    norm: layernorm\n",
      "    dropout: 0.14697434142383314\n",
      "    margin: 0.5821097014494977\n",
      "    lpl_weight: 0.6433825926494596\n",
      "    ratio: 0.19625485495073602\n",
      "    aggregation: sum\n",
      "    treatment: removal\n"
     ]
    }
   ],
   "source": [
    "from train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"cora\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": 1,#trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"cora_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Pubmed\n",
    "#### SCAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:15:57,917] A new study created in memory with name: no-name-1280e0bc-d9bb-485b-b582-15d7ebb729d4\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.7796640274059625, K=29, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.1797844387097658, margin=0.14898368999957545, lpl_weight=0.4557055139425369\n",
      " - ratio=0.30658989044761664, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7410, LPL: 1.3863, Contrastive: 0.2008\n",
      "Epoch 50, Loss: 0.7326, LPL: 1.3863, Contrastive: 0.1852\n",
      " - Metrics: Accuracy=0.8933, F1=0.8719, Recall=0.9084, Precision=0.8381\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7796640274059625, K=29, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.1797844387097658, margin=0.14898368999957545, lpl_weight=0.4557055139425369\n",
      " - ratio=0.30658989044761664, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7410, LPL: 1.3863, Contrastive: 0.2008\n",
      "Epoch 50, Loss: 0.7326, LPL: 1.3863, Contrastive: 0.1852\n",
      " - Metrics: Accuracy=0.8937, F1=0.8719, Recall=0.9055, Precision=0.8406\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7796640274059625, K=29, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.1797844387097658, margin=0.14898368999957545, lpl_weight=0.4557055139425369\n",
      " - ratio=0.30658989044761664, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7410, LPL: 1.3863, Contrastive: 0.2008\n",
      "Epoch 50, Loss: 0.7325, LPL: 1.3863, Contrastive: 0.1852\n",
      " - Metrics: Accuracy=0.8908, F1=0.8683, Recall=0.9018, Precision=0.8372\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7796640274059625, K=29, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.1797844387097658, margin=0.14898368999957545, lpl_weight=0.4557055139425369\n",
      " - ratio=0.30658989044761664, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7410, LPL: 1.3863, Contrastive: 0.2008\n",
      "Epoch 50, Loss: 0.7326, LPL: 1.3863, Contrastive: 0.1852\n",
      " - Metrics: Accuracy=0.8909, F1=0.8685, Recall=0.9018, Precision=0.8375\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7796640274059625, K=29, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.1797844387097658, margin=0.14898368999957545, lpl_weight=0.4557055139425369\n",
      " - ratio=0.30658989044761664, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7410, LPL: 1.3863, Contrastive: 0.2008\n",
      "Epoch 50, Loss: 0.7325, LPL: 1.3863, Contrastive: 0.1852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:18:30,793] Trial 0 finished with value: 0.8702607610910984 and parameters: {'alpha': 0.7796640274059625, 'K': 29, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.1797844387097658, 'margin': 0.14898368999957545, 'lpl_weight': 0.4557055139425369, 'ratio': 0.30658989044761664, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8926, F1=0.8708, Recall=0.9058, Precision=0.8384\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102151557.csv.\n",
      "Average F1 over 5 seeds: 0.8703  0.0016\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.47509853891433396, K=30, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.33926257429148177, margin=0.11017042593138295, lpl_weight=0.2910897648260409\n",
      " - ratio=0.4156138078404573, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6434, LPL: 1.3863, Contrastive: 0.3384\n",
      " - Metrics: Accuracy=0.8760, F1=0.8543, Recall=0.9101, Precision=0.8050\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.47509853891433396, K=30, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.33926257429148177, margin=0.11017042593138295, lpl_weight=0.2910897648260409\n",
      " - ratio=0.4156138078404573, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6434, LPL: 1.3863, Contrastive: 0.3384\n",
      " - Metrics: Accuracy=0.8747, F1=0.8537, Recall=0.9149, Precision=0.8001\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.47509853891433396, K=30, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.33926257429148177, margin=0.11017042593138295, lpl_weight=0.2910897648260409\n",
      " - ratio=0.4156138078404573, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6434, LPL: 1.3863, Contrastive: 0.3384\n",
      " - Metrics: Accuracy=0.8740, F1=0.8522, Recall=0.9095, Precision=0.8017\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.47509853891433396, K=30, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.33926257429148177, margin=0.11017042593138295, lpl_weight=0.2910897648260409\n",
      " - ratio=0.4156138078404573, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6434, LPL: 1.3863, Contrastive: 0.3384\n",
      " - Metrics: Accuracy=0.8730, F1=0.8511, Recall=0.9091, Precision=0.8001\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.47509853891433396, K=30, layers=1, hidden=256, out=128\n",
      " - norm=None, dropout=0.33926257429148177, margin=0.11017042593138295, lpl_weight=0.2910897648260409\n",
      " - ratio=0.4156138078404573, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6434, LPL: 1.3863, Contrastive: 0.3384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:20:31,377] Trial 1 finished with value: 0.8519884062003111 and parameters: {'alpha': 0.47509853891433396, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': None, 'dropout': 0.33926257429148177, 'margin': 0.11017042593138295, 'lpl_weight': 0.2910897648260409, 'ratio': 0.4156138078404573, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8715, F1=0.8486, Recall=0.9020, Precision=0.8012\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102151830.csv.\n",
      "Average F1 over 5 seeds: 0.8520  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10346960092653379, K=27, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.4306177713733429, margin=0.9869860759312589, lpl_weight=0.899395815824247\n",
      " - ratio=0.3883896625068245, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2473, LPL: 1.3863, Contrastive: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7618, F1=0.7337, Recall=0.8216, Precision=0.6628\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10346960092653379, K=27, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.4306177713733429, margin=0.9869860759312589, lpl_weight=0.899395815824247\n",
      " - ratio=0.3883896625068245, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2473, LPL: 1.3863, Contrastive: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7598, F1=0.7309, Recall=0.8169, Precision=0.6613\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10346960092653379, K=27, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.4306177713733429, margin=0.9869860759312589, lpl_weight=0.899395815824247\n",
      " - ratio=0.3883896625068245, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2473, LPL: 1.3863, Contrastive: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7579, F1=0.7287, Recall=0.8140, Precision=0.6596\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10346960092653379, K=27, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.4306177713733429, margin=0.9869860759312589, lpl_weight=0.899395815824247\n",
      " - ratio=0.3883896625068245, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2473, LPL: 1.3863, Contrastive: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7654, F1=0.7377, Recall=0.8259, Precision=0.6665\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10346960092653379, K=27, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.4306177713733429, margin=0.9869860759312589, lpl_weight=0.899395815824247\n",
      " - ratio=0.3883896625068245, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2473, LPL: 1.3863, Contrastive: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n",
      "[I 2025-02-21 15:22:38,803] Trial 2 finished with value: 0.7314338029495178 and parameters: {'alpha': 0.10346960092653379, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': None, 'dropout': 0.4306177713733429, 'margin': 0.9869860759312589, 'lpl_weight': 0.899395815824247, 'ratio': 0.3883896625068245, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7552, F1=0.7261, Recall=0.8124, Precision=0.6564\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102152031.csv.\n",
      "Average F1 over 5 seeds: 0.7314  0.0040\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8921878184933132, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.32314032851519997, margin=0.755943753717363, lpl_weight=0.1776884559234978\n",
      " - ratio=0.14352966558067834, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.0864\n",
      " - Metrics: Accuracy=0.8840, F1=0.8442, Recall=0.7869, Precision=0.9104\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8921878184933132, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.32314032851519997, margin=0.755943753717363, lpl_weight=0.1776884559234978\n",
      " - ratio=0.14352966558067834, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.0864\n",
      " - Metrics: Accuracy=0.8856, F1=0.8459, Recall=0.7862, Precision=0.9154\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8921878184933132, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.32314032851519997, margin=0.755943753717363, lpl_weight=0.1776884559234978\n",
      " - ratio=0.14352966558067834, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.0864\n",
      " - Metrics: Accuracy=0.8806, F1=0.8386, Recall=0.7768, Precision=0.9111\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8921878184933132, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.32314032851519997, margin=0.755943753717363, lpl_weight=0.1776884559234978\n",
      " - ratio=0.14352966558067834, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.0864\n",
      " - Metrics: Accuracy=0.8821, F1=0.8411, Recall=0.7812, Precision=0.9110\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8921878184933132, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.32314032851519997, margin=0.755943753717363, lpl_weight=0.1776884559234978\n",
      " - ratio=0.14352966558067834, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3174, LPL: 1.3863, Contrastive: 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:24:26,362] Trial 3 finished with value: 0.8425594127430752 and parameters: {'alpha': 0.8921878184933132, 'K': 35, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.32314032851519997, 'margin': 0.755943753717363, 'lpl_weight': 0.1776884559234978, 'ratio': 0.14352966558067834, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8838, F1=0.8430, Recall=0.7813, Precision=0.9154\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102152238.csv.\n",
      "Average F1 over 5 seeds: 0.8426  0.0025\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7126235643021253, K=32, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4136782397886004, margin=0.43295693056805107, lpl_weight=0.5061610128162187\n",
      " - ratio=0.40254738296862524, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7734, LPL: 1.3863, Contrastive: 0.1451\n",
      "Epoch 50, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.0844\n",
      "Epoch 100, Loss: 0.7426, LPL: 1.3863, Contrastive: 0.0828\n",
      " - Metrics: Accuracy=0.8611, F1=0.8388, Recall=0.9048, Precision=0.7819\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7126235643021253, K=32, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4136782397886004, margin=0.43295693056805107, lpl_weight=0.5061610128162187\n",
      " - ratio=0.40254738296862524, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7734, LPL: 1.3863, Contrastive: 0.1451\n",
      "Epoch 50, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.0844\n",
      "Epoch 100, Loss: 0.7426, LPL: 1.3863, Contrastive: 0.0828\n",
      " - Metrics: Accuracy=0.8606, F1=0.8376, Recall=0.9003, Precision=0.7831\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7126235643021253, K=32, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4136782397886004, margin=0.43295693056805107, lpl_weight=0.5061610128162187\n",
      " - ratio=0.40254738296862524, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7734, LPL: 1.3863, Contrastive: 0.1451\n",
      "Epoch 50, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.0844\n",
      "Epoch 100, Loss: 0.7426, LPL: 1.3863, Contrastive: 0.0828\n",
      " - Metrics: Accuracy=0.8661, F1=0.8429, Recall=0.8994, Precision=0.7931\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7126235643021253, K=32, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4136782397886004, margin=0.43295693056805107, lpl_weight=0.5061610128162187\n",
      " - ratio=0.40254738296862524, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7734, LPL: 1.3863, Contrastive: 0.1451\n",
      "Epoch 50, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.0844\n",
      "Epoch 100, Loss: 0.7426, LPL: 1.3863, Contrastive: 0.0828\n",
      " - Metrics: Accuracy=0.8597, F1=0.8362, Recall=0.8965, Precision=0.7835\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7126235643021253, K=32, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4136782397886004, margin=0.43295693056805107, lpl_weight=0.5061610128162187\n",
      " - ratio=0.40254738296862524, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7734, LPL: 1.3863, Contrastive: 0.1451\n",
      "Epoch 50, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.0844\n",
      "Epoch 100, Loss: 0.7426, LPL: 1.3863, Contrastive: 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:26:40,537] Trial 4 finished with value: 0.8379746344729373 and parameters: {'alpha': 0.7126235643021253, 'K': 32, 'layers': 1, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.4136782397886004, 'margin': 0.43295693056805107, 'lpl_weight': 0.5061610128162187, 'ratio': 0.40254738296862524, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8582, F1=0.8343, Recall=0.8940, Precision=0.7821\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102152426.csv.\n",
      "Average F1 over 5 seeds: 0.8380  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4240168592029787, K=34, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.33349846190148635, margin=0.7336185493781447, lpl_weight=0.4066260143453142\n",
      " - ratio=0.37361436289518457, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6161, LPL: 1.3863, Contrastive: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8112, F1=0.7892, Recall=0.8848, Precision=0.7123\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4240168592029787, K=34, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.33349846190148635, margin=0.7336185493781447, lpl_weight=0.4066260143453142\n",
      " - ratio=0.37361436289518457, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6161, LPL: 1.3863, Contrastive: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8162, F1=0.7950, Recall=0.8918, Precision=0.7171\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4240168592029787, K=34, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.33349846190148635, margin=0.7336185493781447, lpl_weight=0.4066260143453142\n",
      " - ratio=0.37361436289518457, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6161, LPL: 1.3863, Contrastive: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8132, F1=0.7913, Recall=0.8869, Precision=0.7144\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4240168592029787, K=34, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.33349846190148635, margin=0.7336185493781447, lpl_weight=0.4066260143453142\n",
      " - ratio=0.37361436289518457, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6161, LPL: 1.3863, Contrastive: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8078, F1=0.7853, Recall=0.8801, Precision=0.7089\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4240168592029787, K=34, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.33349846190148635, margin=0.7336185493781447, lpl_weight=0.4066260143453142\n",
      " - ratio=0.37361436289518457, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6161, LPL: 1.3863, Contrastive: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n",
      "[I 2025-02-21 15:29:27,565] Trial 5 finished with value: 0.7906807443800659 and parameters: {'alpha': 0.4240168592029787, 'K': 34, 'layers': 3, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.33349846190148635, 'margin': 0.7336185493781447, 'lpl_weight': 0.4066260143453142, 'ratio': 0.37361436289518457, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8141, F1=0.7926, Recall=0.8893, Precision=0.7149\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102152640.csv.\n",
      "Average F1 over 5 seeds: 0.7907  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2254115290106971, K=26, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4278872709080612, margin=0.905171112337524, lpl_weight=0.8822453258332387\n",
      " - ratio=0.1605943479903152, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2234, LPL: 1.3863, Contrastive: 0.0026\n",
      "Epoch 50, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.0023\n",
      " - Metrics: Accuracy=0.8849, F1=0.8438, Recall=0.7783, Precision=0.9214\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2254115290106971, K=26, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4278872709080612, margin=0.905171112337524, lpl_weight=0.8822453258332387\n",
      " - ratio=0.1605943479903152, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2234, LPL: 1.3863, Contrastive: 0.0026\n",
      "Epoch 50, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.0023\n",
      " - Metrics: Accuracy=0.8847, F1=0.8430, Recall=0.7747, Precision=0.9244\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2254115290106971, K=26, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4278872709080612, margin=0.905171112337524, lpl_weight=0.8822453258332387\n",
      " - ratio=0.1605943479903152, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2234, LPL: 1.3863, Contrastive: 0.0026\n",
      "Epoch 50, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.0023\n",
      " - Metrics: Accuracy=0.8883, F1=0.8472, Recall=0.7750, Precision=0.9342\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2254115290106971, K=26, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4278872709080612, margin=0.905171112337524, lpl_weight=0.8822453258332387\n",
      " - ratio=0.1605943479903152, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2234, LPL: 1.3863, Contrastive: 0.0026\n",
      "Epoch 50, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.0023\n",
      " - Metrics: Accuracy=0.8878, F1=0.8476, Recall=0.7813, Precision=0.9261\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2254115290106971, K=26, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.4278872709080612, margin=0.905171112337524, lpl_weight=0.8822453258332387\n",
      " - ratio=0.1605943479903152, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2234, LPL: 1.3863, Contrastive: 0.0026\n",
      "Epoch 50, Loss: 1.2233, LPL: 1.3863, Contrastive: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:31:27,805] Trial 6 finished with value: 0.8454273257890161 and parameters: {'alpha': 0.2254115290106971, 'K': 26, 'layers': 1, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.4278872709080612, 'margin': 0.905171112337524, 'lpl_weight': 0.8822453258332387, 'ratio': 0.1605943479903152, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8869, F1=0.8456, Recall=0.7755, Precision=0.9297\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102152927.csv.\n",
      "Average F1 over 5 seeds: 0.8454  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8551305529820448, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4860959729383255, margin=0.15625677975174831, lpl_weight=0.6348287595108622\n",
      " - ratio=0.21069022916242652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9557, LPL: 1.3863, Contrastive: 0.2071\n",
      "Epoch 50, Loss: 0.9464, LPL: 1.3863, Contrastive: 0.1817\n",
      " - Metrics: Accuracy=0.9025, F1=0.8736, Recall=0.8442, Precision=0.9052\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8551305529820448, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4860959729383255, margin=0.15625677975174831, lpl_weight=0.6348287595108622\n",
      " - ratio=0.21069022916242652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9557, LPL: 1.3863, Contrastive: 0.2071\n",
      "Epoch 50, Loss: 0.9464, LPL: 1.3863, Contrastive: 0.1817\n",
      " - Metrics: Accuracy=0.9021, F1=0.8731, Recall=0.8434, Precision=0.9050\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8551305529820448, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4860959729383255, margin=0.15625677975174831, lpl_weight=0.6348287595108622\n",
      " - ratio=0.21069022916242652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9557, LPL: 1.3863, Contrastive: 0.2071\n",
      "Epoch 50, Loss: 0.9464, LPL: 1.3863, Contrastive: 0.1817\n",
      " - Metrics: Accuracy=0.8971, F1=0.8663, Recall=0.8343, Precision=0.9009\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8551305529820448, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4860959729383255, margin=0.15625677975174831, lpl_weight=0.6348287595108622\n",
      " - ratio=0.21069022916242652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9557, LPL: 1.3863, Contrastive: 0.2071\n",
      "Epoch 50, Loss: 0.9464, LPL: 1.3863, Contrastive: 0.1817\n",
      " - Metrics: Accuracy=0.8953, F1=0.8639, Recall=0.8325, Precision=0.8978\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8551305529820448, K=31, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4860959729383255, margin=0.15625677975174831, lpl_weight=0.6348287595108622\n",
      " - ratio=0.21069022916242652, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9557, LPL: 1.3863, Contrastive: 0.2071\n",
      "Epoch 50, Loss: 0.9464, LPL: 1.3863, Contrastive: 0.1817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:35:07,446] Trial 7 finished with value: 0.8684006339789517 and parameters: {'alpha': 0.8551305529820448, 'K': 31, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4860959729383255, 'margin': 0.15625677975174831, 'lpl_weight': 0.6348287595108622, 'ratio': 0.21069022916242652, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8961, F1=0.8650, Recall=0.8330, Precision=0.8995\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102153127.csv.\n",
      "Average F1 over 5 seeds: 0.8684  0.0041\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3954026898891221, K=25, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4834465050427259, margin=0.45805624024710057, lpl_weight=0.10746460261313094\n",
      " - ratio=0.20902011335038373, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2916, LPL: 1.3863, Contrastive: 0.1598\n",
      " - Metrics: Accuracy=0.8963, F1=0.8653, Recall=0.8338, Precision=0.8992\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3954026898891221, K=25, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4834465050427259, margin=0.45805624024710057, lpl_weight=0.10746460261313094\n",
      " - ratio=0.20902011335038373, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2916, LPL: 1.3863, Contrastive: 0.1598\n",
      " - Metrics: Accuracy=0.8951, F1=0.8638, Recall=0.8331, Precision=0.8968\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3954026898891221, K=25, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4834465050427259, margin=0.45805624024710057, lpl_weight=0.10746460261313094\n",
      " - ratio=0.20902011335038373, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2916, LPL: 1.3863, Contrastive: 0.1598\n",
      " - Metrics: Accuracy=0.8940, F1=0.8623, Recall=0.8307, Precision=0.8963\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3954026898891221, K=25, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4834465050427259, margin=0.45805624024710057, lpl_weight=0.10746460261313094\n",
      " - ratio=0.20902011335038373, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2916, LPL: 1.3863, Contrastive: 0.1598\n",
      " - Metrics: Accuracy=0.8912, F1=0.8586, Recall=0.8272, Precision=0.8925\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3954026898891221, K=25, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4834465050427259, margin=0.45805624024710057, lpl_weight=0.10746460261313094\n",
      " - ratio=0.20902011335038373, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2916, LPL: 1.3863, Contrastive: 0.1598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:37:44,303] Trial 8 finished with value: 0.8621637284976875 and parameters: {'alpha': 0.3954026898891221, 'K': 25, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4834465050427259, 'margin': 0.45805624024710057, 'lpl_weight': 0.10746460261313094, 'ratio': 0.20902011335038373, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8928, F1=0.8609, Recall=0.8305, Precision=0.8937\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102153507.csv.\n",
      "Average F1 over 5 seeds: 0.8622  0.0023\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.767792738068351, K=27, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.4793378332132423, margin=0.7019634323110872, lpl_weight=0.27406705735134607\n",
      " - ratio=0.3743745137911185, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4613, LPL: 1.3863, Contrastive: 0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8178, F1=0.7953, Recall=0.8863, Precision=0.7212\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.767792738068351, K=27, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.4793378332132423, margin=0.7019634323110872, lpl_weight=0.27406705735134607\n",
      " - ratio=0.3743745137911185, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4613, LPL: 1.3863, Contrastive: 0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8193, F1=0.7967, Recall=0.8865, Precision=0.7235\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.767792738068351, K=27, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.4793378332132423, margin=0.7019634323110872, lpl_weight=0.27406705735134607\n",
      " - ratio=0.3743745137911185, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4613, LPL: 1.3863, Contrastive: 0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8200, F1=0.7981, Recall=0.8909, Precision=0.7229\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.767792738068351, K=27, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.4793378332132423, margin=0.7019634323110872, lpl_weight=0.27406705735134607\n",
      " - ratio=0.3743745137911185, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4613, LPL: 1.3863, Contrastive: 0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8205, F1=0.7984, Recall=0.8897, Precision=0.7241\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.767792738068351, K=27, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.4793378332132423, margin=0.7019634323110872, lpl_weight=0.27406705735134607\n",
      " - ratio=0.3743745137911185, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4613, LPL: 1.3863, Contrastive: 0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n",
      "[I 2025-02-21 15:39:31,725] Trial 9 finished with value: 0.7956664561858848 and parameters: {'alpha': 0.767792738068351, 'K': 27, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.4793378332132423, 'margin': 0.7019634323110872, 'lpl_weight': 0.27406705735134607, 'ratio': 0.3743745137911185, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8128, F1=0.7898, Recall=0.8808, Precision=0.7159\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102153744.csv.\n",
      "Average F1 over 5 seeds: 0.7957  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9909540233934103, K=29, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.11477989918693686, margin=0.3045363383264393, lpl_weight=0.6965997405442765\n",
      " - ratio=0.295722927229415, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0103, LPL: 1.3863, Contrastive: 0.1469\n",
      "Epoch 50, Loss: 1.0057, LPL: 1.3863, Contrastive: 0.1320\n",
      " - Metrics: Accuracy=0.8783, F1=0.8538, Recall=0.8898, Precision=0.8206\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9909540233934103, K=29, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.11477989918693686, margin=0.3045363383264393, lpl_weight=0.6965997405442765\n",
      " - ratio=0.295722927229415, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0103, LPL: 1.3863, Contrastive: 0.1469\n",
      "Epoch 50, Loss: 1.0075, LPL: 1.3863, Contrastive: 0.1377\n",
      " - Metrics: Accuracy=0.8778, F1=0.8529, Recall=0.8870, Precision=0.8214\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9909540233934103, K=29, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.11477989918693686, margin=0.3045363383264393, lpl_weight=0.6965997405442765\n",
      " - ratio=0.295722927229415, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0103, LPL: 1.3863, Contrastive: 0.1470\n",
      "Epoch 50, Loss: 1.0061, LPL: 1.3863, Contrastive: 0.1331\n",
      " - Metrics: Accuracy=0.8776, F1=0.8528, Recall=0.8881, Precision=0.8202\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9909540233934103, K=29, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.11477989918693686, margin=0.3045363383264393, lpl_weight=0.6965997405442765\n",
      " - ratio=0.295722927229415, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0103, LPL: 1.3863, Contrastive: 0.1469\n",
      "Epoch 50, Loss: 1.0052, LPL: 1.3863, Contrastive: 0.1302\n",
      " - Metrics: Accuracy=0.8785, F1=0.8525, Recall=0.8791, Precision=0.8275\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9909540233934103, K=29, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.11477989918693686, margin=0.3045363383264393, lpl_weight=0.6965997405442765\n",
      " - ratio=0.295722927229415, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0103, LPL: 1.3863, Contrastive: 0.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:41:51,530] Trial 10 finished with value: 0.8534106106916468 and parameters: {'alpha': 0.9909540233934103, 'K': 29, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.11477989918693686, 'margin': 0.3045363383264393, 'lpl_weight': 0.6965997405442765, 'ratio': 0.295722927229415, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 0 with value: 0.8702607610910984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8798, F1=0.8550, Recall=0.8869, Precision=0.8253\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102153931.csv.\n",
      "Average F1 over 5 seeds: 0.8534  0.0009\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6718817918500981, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1737423005844193, margin=0.10039868740251393, lpl_weight=0.6622375185257193\n",
      " - ratio=0.2639450757295954, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9951, LPL: 1.3863, Contrastive: 0.2280\n",
      "Epoch 50, Loss: 0.9880, LPL: 1.3863, Contrastive: 0.2072\n",
      " - Metrics: Accuracy=0.9018, F1=0.8786, Recall=0.8897, Precision=0.8677\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6718817918500981, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1737423005844193, margin=0.10039868740251393, lpl_weight=0.6622375185257193\n",
      " - ratio=0.2639450757295954, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9951, LPL: 1.3863, Contrastive: 0.2280\n",
      "Epoch 50, Loss: 0.9880, LPL: 1.3863, Contrastive: 0.2072\n",
      " - Metrics: Accuracy=0.8984, F1=0.8742, Recall=0.8836, Precision=0.8650\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6718817918500981, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1737423005844193, margin=0.10039868740251393, lpl_weight=0.6622375185257193\n",
      " - ratio=0.2639450757295954, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9951, LPL: 1.3863, Contrastive: 0.2280\n",
      "Epoch 50, Loss: 0.9880, LPL: 1.3863, Contrastive: 0.2072\n",
      " - Metrics: Accuracy=0.8951, F1=0.8706, Recall=0.8836, Precision=0.8581\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6718817918500981, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1737423005844193, margin=0.10039868740251393, lpl_weight=0.6622375185257193\n",
      " - ratio=0.2639450757295954, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9951, LPL: 1.3863, Contrastive: 0.2280\n",
      "Epoch 50, Loss: 0.9880, LPL: 1.3863, Contrastive: 0.2072\n",
      " - Metrics: Accuracy=0.9014, F1=0.8776, Recall=0.8851, Precision=0.8702\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6718817918500981, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1737423005844193, margin=0.10039868740251393, lpl_weight=0.6622375185257193\n",
      " - ratio=0.2639450757295954, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9951, LPL: 1.3863, Contrastive: 0.2280\n",
      "Epoch 50, Loss: 0.9880, LPL: 1.3863, Contrastive: 0.2072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:44:54,569] Trial 11 finished with value: 0.8756768545164686 and parameters: {'alpha': 0.6718817918500981, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1737423005844193, 'margin': 0.10039868740251393, 'lpl_weight': 0.6622375185257193, 'ratio': 0.2639450757295954, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 11 with value: 0.8756768545164686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9014, F1=0.8775, Recall=0.8844, Precision=0.8706\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102154151.csv.\n",
      "Average F1 over 5 seeds: 0.8757  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6257914195010679, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15168822354036768, margin=0.255338947711509, lpl_weight=0.7481957221832095\n",
      " - ratio=0.4957895081419159, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0761, LPL: 1.3863, Contrastive: 0.1543\n",
      "Epoch 50, Loss: 1.0729, LPL: 1.3863, Contrastive: 0.1415\n",
      " - Metrics: Accuracy=0.8372, F1=0.8233, Recall=0.9495, Precision=0.7267\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6257914195010679, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15168822354036768, margin=0.255338947711509, lpl_weight=0.7481957221832095\n",
      " - ratio=0.4957895081419159, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0761, LPL: 1.3863, Contrastive: 0.1543\n",
      "Epoch 50, Loss: 1.0729, LPL: 1.3863, Contrastive: 0.1415\n",
      " - Metrics: Accuracy=0.8297, F1=0.8164, Recall=0.9481, Precision=0.7169\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6257914195010679, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15168822354036768, margin=0.255338947711509, lpl_weight=0.7481957221832095\n",
      " - ratio=0.4957895081419159, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0761, LPL: 1.3863, Contrastive: 0.1543\n",
      "Epoch 50, Loss: 1.0729, LPL: 1.3863, Contrastive: 0.1415\n",
      " - Metrics: Accuracy=0.8422, F1=0.8273, Recall=0.9467, Precision=0.7347\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6257914195010679, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15168822354036768, margin=0.255338947711509, lpl_weight=0.7481957221832095\n",
      " - ratio=0.4957895081419159, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0761, LPL: 1.3863, Contrastive: 0.1543\n",
      "Epoch 50, Loss: 1.0729, LPL: 1.3863, Contrastive: 0.1415\n",
      " - Metrics: Accuracy=0.8290, F1=0.8142, Recall=0.9380, Precision=0.7192\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6257914195010679, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15168822354036768, margin=0.255338947711509, lpl_weight=0.7481957221832095\n",
      " - ratio=0.4957895081419159, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0761, LPL: 1.3863, Contrastive: 0.1543\n",
      "Epoch 50, Loss: 1.0729, LPL: 1.3863, Contrastive: 0.1415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:47:52,902] Trial 12 finished with value: 0.8198993233490712 and parameters: {'alpha': 0.6257914195010679, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.15168822354036768, 'margin': 0.255338947711509, 'lpl_weight': 0.7481957221832095, 'ratio': 0.4957895081419159, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 11 with value: 0.8756768545164686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8322, F1=0.8183, Recall=0.9460, Precision=0.7209\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102154454.csv.\n",
      "Average F1 over 5 seeds: 0.8199  0.0048\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.614945971328193, K=29, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2083407930890927, margin=0.29453569864049717, lpl_weight=0.5103671886646531\n",
      " - ratio=0.29734115455304583, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7779, LPL: 1.3863, Contrastive: 0.1437\n",
      "Epoch 50, Loss: 0.7704, LPL: 1.3863, Contrastive: 0.1284\n",
      "Epoch 100, Loss: 0.7765, LPL: 1.3863, Contrastive: 0.1409\n",
      " - Metrics: Accuracy=0.8926, F1=0.8706, Recall=0.9044, Precision=0.8392\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.614945971328193, K=29, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2083407930890927, margin=0.29453569864049717, lpl_weight=0.5103671886646531\n",
      " - ratio=0.29734115455304583, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7779, LPL: 1.3863, Contrastive: 0.1437\n",
      "Epoch 50, Loss: 0.7704, LPL: 1.3863, Contrastive: 0.1284\n",
      "Epoch 100, Loss: 0.7755, LPL: 1.3863, Contrastive: 0.1388\n",
      " - Metrics: Accuracy=0.8945, F1=0.8725, Recall=0.9034, Precision=0.8436\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.614945971328193, K=29, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2083407930890927, margin=0.29453569864049717, lpl_weight=0.5103671886646531\n",
      " - ratio=0.29734115455304583, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7779, LPL: 1.3863, Contrastive: 0.1437\n",
      "Epoch 50, Loss: 0.7704, LPL: 1.3863, Contrastive: 0.1284\n",
      "Epoch 100, Loss: 0.7790, LPL: 1.3863, Contrastive: 0.1460\n",
      " - Metrics: Accuracy=0.8919, F1=0.8697, Recall=0.9029, Precision=0.8388\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.614945971328193, K=29, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2083407930890927, margin=0.29453569864049717, lpl_weight=0.5103671886646531\n",
      " - ratio=0.29734115455304583, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7779, LPL: 1.3863, Contrastive: 0.1437\n",
      "Epoch 50, Loss: 0.7704, LPL: 1.3863, Contrastive: 0.1284\n",
      "Epoch 100, Loss: 0.7757, LPL: 1.3863, Contrastive: 0.1392\n",
      " - Metrics: Accuracy=0.8934, F1=0.8714, Recall=0.9043, Precision=0.8408\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.614945971328193, K=29, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2083407930890927, margin=0.29453569864049717, lpl_weight=0.5103671886646531\n",
      " - ratio=0.29734115455304583, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7779, LPL: 1.3863, Contrastive: 0.1437\n",
      "Epoch 50, Loss: 0.7704, LPL: 1.3863, Contrastive: 0.1284\n",
      "Epoch 100, Loss: 0.7731, LPL: 1.3863, Contrastive: 0.1339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:50:27,985] Trial 13 finished with value: 0.8709942063641106 and parameters: {'alpha': 0.614945971328193, 'K': 29, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.2083407930890927, 'margin': 0.29453569864049717, 'lpl_weight': 0.5103671886646531, 'ratio': 0.29734115455304583, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 11 with value: 0.8756768545164686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8934, F1=0.8709, Recall=0.9003, Precision=0.8433\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102154752.csv.\n",
      "Average F1 over 5 seeds: 0.8710  0.0009\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6151373746804762, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2242311994290817, margin=0.2819664095322346, lpl_weight=0.5761878193110654\n",
      " - ratio=0.2998670983377616, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8594, LPL: 1.3863, Contrastive: 0.1431\n",
      "Epoch 50, Loss: 0.8546, LPL: 1.3863, Contrastive: 0.1317\n",
      " - Metrics: Accuracy=0.8955, F1=0.8737, Recall=0.9051, Precision=0.8443\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6151373746804762, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2242311994290817, margin=0.2819664095322346, lpl_weight=0.5761878193110654\n",
      " - ratio=0.2998670983377616, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8594, LPL: 1.3863, Contrastive: 0.1431\n",
      "Epoch 50, Loss: 0.8546, LPL: 1.3863, Contrastive: 0.1317\n",
      " - Metrics: Accuracy=0.8938, F1=0.8723, Recall=0.9079, Precision=0.8394\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6151373746804762, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2242311994290817, margin=0.2819664095322346, lpl_weight=0.5761878193110654\n",
      " - ratio=0.2998670983377616, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8594, LPL: 1.3863, Contrastive: 0.1431\n",
      "Epoch 50, Loss: 0.8546, LPL: 1.3863, Contrastive: 0.1317\n",
      " - Metrics: Accuracy=0.8929, F1=0.8704, Recall=0.9004, Precision=0.8423\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6151373746804762, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2242311994290817, margin=0.2819664095322346, lpl_weight=0.5761878193110654\n",
      " - ratio=0.2998670983377616, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8594, LPL: 1.3863, Contrastive: 0.1431\n",
      "Epoch 50, Loss: 0.8546, LPL: 1.3863, Contrastive: 0.1317\n",
      " - Metrics: Accuracy=0.8960, F1=0.8744, Recall=0.9063, Precision=0.8446\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6151373746804762, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2242311994290817, margin=0.2819664095322346, lpl_weight=0.5761878193110654\n",
      " - ratio=0.2998670983377616, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8594, LPL: 1.3863, Contrastive: 0.1431\n",
      "Epoch 50, Loss: 0.8546, LPL: 1.3863, Contrastive: 0.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:53:31,245] Trial 14 finished with value: 0.8726231620610918 and parameters: {'alpha': 0.6151373746804762, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2242311994290817, 'margin': 0.2819664095322346, 'lpl_weight': 0.5761878193110654, 'ratio': 0.2998670983377616, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 11 with value: 0.8756768545164686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8941, F1=0.8724, Recall=0.9060, Precision=0.8411\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102155028.csv.\n",
      "Average F1 over 5 seeds: 0.8726  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5311031346531587, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24538111087672715, margin=0.41638371321098333, lpl_weight=0.7621846841147637\n",
      " - ratio=0.23594715913885006, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0814, LPL: 1.3863, Contrastive: 0.1041\n",
      "Epoch 50, Loss: 1.0774, LPL: 1.3863, Contrastive: 0.0876\n",
      "Epoch 100, Loss: 1.0784, LPL: 1.3863, Contrastive: 0.0915\n",
      " - Metrics: Accuracy=0.9077, F1=0.8830, Recall=0.8720, Precision=0.8943\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5311031346531587, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24538111087672715, margin=0.41638371321098333, lpl_weight=0.7621846841147637\n",
      " - ratio=0.23594715913885006, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0814, LPL: 1.3863, Contrastive: 0.1041\n",
      "Epoch 50, Loss: 1.0774, LPL: 1.3863, Contrastive: 0.0876\n",
      "Epoch 100, Loss: 1.0799, LPL: 1.3863, Contrastive: 0.0981\n",
      " - Metrics: Accuracy=0.9076, F1=0.8829, Recall=0.8719, Precision=0.8941\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5311031346531587, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24538111087672715, margin=0.41638371321098333, lpl_weight=0.7621846841147637\n",
      " - ratio=0.23594715913885006, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0814, LPL: 1.3863, Contrastive: 0.1041\n",
      "Epoch 50, Loss: 1.0774, LPL: 1.3863, Contrastive: 0.0876\n",
      "Epoch 100, Loss: 1.0805, LPL: 1.3863, Contrastive: 0.1003\n",
      " - Metrics: Accuracy=0.9060, F1=0.8806, Recall=0.8678, Precision=0.8938\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5311031346531587, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24538111087672715, margin=0.41638371321098333, lpl_weight=0.7621846841147637\n",
      " - ratio=0.23594715913885006, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0814, LPL: 1.3863, Contrastive: 0.1041\n",
      "Epoch 50, Loss: 1.0774, LPL: 1.3863, Contrastive: 0.0876\n",
      "Epoch 100, Loss: 1.0790, LPL: 1.3863, Contrastive: 0.0943\n",
      " - Metrics: Accuracy=0.9044, F1=0.8791, Recall=0.8701, Precision=0.8884\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5311031346531587, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24538111087672715, margin=0.41638371321098333, lpl_weight=0.7621846841147637\n",
      " - ratio=0.23594715913885006, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0814, LPL: 1.3863, Contrastive: 0.1041\n",
      "Epoch 50, Loss: 1.0774, LPL: 1.3863, Contrastive: 0.0876\n",
      "Epoch 100, Loss: 1.0810, LPL: 1.3863, Contrastive: 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 15:56:45,264] Trial 15 finished with value: 0.8809428866883211 and parameters: {'alpha': 0.5311031346531587, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.24538111087672715, 'margin': 0.41638371321098333, 'lpl_weight': 0.7621846841147637, 'ratio': 0.23594715913885006, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9041, F1=0.8791, Recall=0.8731, Precision=0.8852\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102155331.csv.\n",
      "Average F1 over 5 seeds: 0.8809  0.0017\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.262395252359631, K=35, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2666145697309293, margin=0.5176228205070696, lpl_weight=0.9897726470770152\n",
      " - ratio=0.22357495672647482, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3728, LPL: 1.3863, Contrastive: 0.0706\n",
      "Epoch 50, Loss: 1.3727, LPL: 1.3863, Contrastive: 0.0605\n",
      " - Metrics: Accuracy=0.8854, F1=0.8558, Recall=0.8516, Precision=0.8602\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.262395252359631, K=35, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2666145697309293, margin=0.5176228205070696, lpl_weight=0.9897726470770152\n",
      " - ratio=0.22357495672647482, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3728, LPL: 1.3863, Contrastive: 0.0706\n",
      "Epoch 50, Loss: 1.3727, LPL: 1.3863, Contrastive: 0.0611\n",
      " - Metrics: Accuracy=0.8774, F1=0.8461, Recall=0.8443, Precision=0.8480\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.262395252359631, K=35, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2666145697309293, margin=0.5176228205070696, lpl_weight=0.9897726470770152\n",
      " - ratio=0.22357495672647482, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3728, LPL: 1.3863, Contrastive: 0.0706\n",
      "Epoch 50, Loss: 1.3727, LPL: 1.3863, Contrastive: 0.0607\n",
      " - Metrics: Accuracy=0.8891, F1=0.8594, Recall=0.8490, Precision=0.8701\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.262395252359631, K=35, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2666145697309293, margin=0.5176228205070696, lpl_weight=0.9897726470770152\n",
      " - ratio=0.22357495672647482, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3728, LPL: 1.3863, Contrastive: 0.0706\n",
      "Epoch 50, Loss: 1.3727, LPL: 1.3863, Contrastive: 0.0606\n",
      " - Metrics: Accuracy=0.8873, F1=0.8567, Recall=0.8437, Precision=0.8702\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.262395252359631, K=35, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2666145697309293, margin=0.5176228205070696, lpl_weight=0.9897726470770152\n",
      " - ratio=0.22357495672647482, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3728, LPL: 1.3863, Contrastive: 0.0706\n",
      "Epoch 50, Loss: 1.3727, LPL: 1.3863, Contrastive: 0.0607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:00:00,516] Trial 16 finished with value: 0.8555443416213953 and parameters: {'alpha': 0.262395252359631, 'K': 35, 'layers': 3, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2666145697309293, 'margin': 0.5176228205070696, 'lpl_weight': 0.9897726470770152, 'ratio': 0.22357495672647482, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8877, F1=0.8596, Recall=0.8603, Precision=0.8588\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102155645.csv.\n",
      "Average F1 over 5 seeds: 0.8555  0.0049\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5142620226310091, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2647254292181002, margin=0.6081045112652863, lpl_weight=0.8059225995781744\n",
      " - ratio=0.25935636552406505, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1352, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 50, Loss: 1.1254, LPL: 1.3863, Contrastive: 0.0420\n",
      "Epoch 100, Loss: 1.1251, LPL: 1.3863, Contrastive: 0.0404\n",
      "Epoch 150, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0397\n",
      "Epoch 200, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0394\n",
      "Epoch 250, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0393\n",
      "Epoch 300, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 350, Loss: 1.1248, LPL: 1.3863, Contrastive: 0.0392\n",
      " - Metrics: Accuracy=0.9018, F1=0.8744, Recall=0.8565, Precision=0.8931\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5142620226310091, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2647254292181002, margin=0.6081045112652863, lpl_weight=0.8059225995781744\n",
      " - ratio=0.25935636552406505, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1352, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 50, Loss: 1.1254, LPL: 1.3863, Contrastive: 0.0420\n",
      "Epoch 100, Loss: 1.1251, LPL: 1.3863, Contrastive: 0.0404\n",
      "Epoch 150, Loss: 1.1250, LPL: 1.3863, Contrastive: 0.0397\n",
      "Epoch 200, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0394\n",
      "Epoch 250, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0393\n",
      "Epoch 300, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 350, Loss: 1.1248, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 400, Loss: 1.1248, LPL: 1.3863, Contrastive: 0.0391\n",
      "Epoch 450, Loss: 1.1248, LPL: 1.3863, Contrastive: 0.0391\n",
      " - Metrics: Accuracy=0.8973, F1=0.8688, Recall=0.8512, Precision=0.8872\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5142620226310091, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2647254292181002, margin=0.6081045112652863, lpl_weight=0.8059225995781744\n",
      " - ratio=0.25935636552406505, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1352, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 50, Loss: 1.1254, LPL: 1.3863, Contrastive: 0.0420\n",
      "Epoch 100, Loss: 1.1251, LPL: 1.3863, Contrastive: 0.0404\n",
      "Epoch 150, Loss: 1.1250, LPL: 1.3863, Contrastive: 0.0397\n",
      "Epoch 200, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0394\n",
      "Epoch 250, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0393\n",
      "Epoch 300, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 350, Loss: 1.1248, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 400, Loss: 1.1248, LPL: 1.3863, Contrastive: 0.0391\n",
      " - Metrics: Accuracy=0.9021, F1=0.8748, Recall=0.8569, Precision=0.8935\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5142620226310091, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2647254292181002, margin=0.6081045112652863, lpl_weight=0.8059225995781744\n",
      " - ratio=0.25935636552406505, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1352, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 50, Loss: 1.1254, LPL: 1.3863, Contrastive: 0.0420\n",
      "Epoch 100, Loss: 1.1251, LPL: 1.3863, Contrastive: 0.0404\n",
      "Epoch 150, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0397\n",
      "Epoch 200, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0394\n",
      "Epoch 250, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0393\n",
      "Epoch 300, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 350, Loss: 1.1248, LPL: 1.3863, Contrastive: 0.0392\n",
      " - Metrics: Accuracy=0.8985, F1=0.8706, Recall=0.8550, Precision=0.8869\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5142620226310091, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.2647254292181002, margin=0.6081045112652863, lpl_weight=0.8059225995781744\n",
      " - ratio=0.25935636552406505, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1352, LPL: 1.3863, Contrastive: 0.0926\n",
      "Epoch 50, Loss: 1.1254, LPL: 1.3863, Contrastive: 0.0420\n",
      "Epoch 100, Loss: 1.1251, LPL: 1.3863, Contrastive: 0.0404\n",
      "Epoch 150, Loss: 1.1250, LPL: 1.3863, Contrastive: 0.0397\n",
      "Epoch 200, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0394\n",
      "Epoch 250, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0393\n",
      "Epoch 300, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 350, Loss: 1.1249, LPL: 1.3863, Contrastive: 0.0392\n",
      "Epoch 400, Loss: 1.1248, LPL: 1.3863, Contrastive: 0.0392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:05:37,342] Trial 17 finished with value: 0.8720954570707533 and parameters: {'alpha': 0.5142620226310091, 'K': 33, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2647254292181002, 'margin': 0.6081045112652863, 'lpl_weight': 0.8059225995781744, 'ratio': 0.25935636552406505, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8994, F1=0.8718, Recall=0.8563, Precision=0.8878\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102160000.csv.\n",
      "Average F1 over 5 seeds: 0.8721  0.0023\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.30959598647007625, K=31, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.10516726176573762, margin=0.37686890253396654, lpl_weight=0.6470194782195787\n",
      " - ratio=0.11167944501615584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9382, LPL: 1.3863, Contrastive: 0.1168\n",
      "Epoch 50, Loss: 0.9378, LPL: 1.3863, Contrastive: 0.1157\n",
      " - Metrics: Accuracy=0.8815, F1=0.8396, Recall=0.7766, Precision=0.9138\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.30959598647007625, K=31, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.10516726176573762, margin=0.37686890253396654, lpl_weight=0.6470194782195787\n",
      " - ratio=0.11167944501615584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9382, LPL: 1.3863, Contrastive: 0.1167\n",
      "Epoch 50, Loss: 0.9351, LPL: 1.3863, Contrastive: 0.1081\n",
      " - Metrics: Accuracy=0.8780, F1=0.8345, Recall=0.7704, Precision=0.9103\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.30959598647007625, K=31, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.10516726176573762, margin=0.37686890253396654, lpl_weight=0.6470194782195787\n",
      " - ratio=0.11167944501615584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9382, LPL: 1.3863, Contrastive: 0.1167\n",
      " - Metrics: Accuracy=0.8810, F1=0.8386, Recall=0.7745, Precision=0.9144\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.30959598647007625, K=31, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.10516726176573762, margin=0.37686890253396654, lpl_weight=0.6470194782195787\n",
      " - ratio=0.11167944501615584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9382, LPL: 1.3863, Contrastive: 0.1167\n",
      "Epoch 50, Loss: 0.9360, LPL: 1.3863, Contrastive: 0.1106\n",
      " - Metrics: Accuracy=0.8816, F1=0.8393, Recall=0.7741, Precision=0.9166\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.30959598647007625, K=31, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.10516726176573762, margin=0.37686890253396654, lpl_weight=0.6470194782195787\n",
      " - ratio=0.11167944501615584, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9382, LPL: 1.3863, Contrastive: 0.1167\n",
      "Epoch 50, Loss: 0.9350, LPL: 1.3863, Contrastive: 0.1077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:08:32,532] Trial 18 finished with value: 0.8387082123071737 and parameters: {'alpha': 0.30959598647007625, 'K': 31, 'layers': 3, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.10516726176573762, 'margin': 0.37686890253396654, 'lpl_weight': 0.6470194782195787, 'ratio': 0.11167944501615584, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8826, F1=0.8414, Recall=0.7798, Precision=0.9136\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102160537.csv.\n",
      "Average F1 over 5 seeds: 0.8387  0.0023\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6853222550059309, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.26077304726499934, margin=0.6158157531198359, lpl_weight=0.7897270300400397\n",
      " - ratio=0.25175754281808493, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1114, LPL: 1.3863, Contrastive: 0.0788\n",
      " - Metrics: Accuracy=0.8956, F1=0.8681, Recall=0.8604, Precision=0.8759\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6853222550059309, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.26077304726499934, margin=0.6158157531198359, lpl_weight=0.7897270300400397\n",
      " - ratio=0.25175754281808493, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1114, LPL: 1.3863, Contrastive: 0.0788\n",
      " - Metrics: Accuracy=0.8934, F1=0.8653, Recall=0.8566, Precision=0.8741\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6853222550059309, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.26077304726499934, margin=0.6158157531198359, lpl_weight=0.7897270300400397\n",
      " - ratio=0.25175754281808493, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1114, LPL: 1.3863, Contrastive: 0.0788\n",
      " - Metrics: Accuracy=0.8935, F1=0.8651, Recall=0.8551, Precision=0.8753\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6853222550059309, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.26077304726499934, margin=0.6158157531198359, lpl_weight=0.7897270300400397\n",
      " - ratio=0.25175754281808493, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1114, LPL: 1.3863, Contrastive: 0.0788\n",
      " - Metrics: Accuracy=0.8942, F1=0.8657, Recall=0.8545, Precision=0.8773\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6853222550059309, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.26077304726499934, margin=0.6158157531198359, lpl_weight=0.7897270300400397\n",
      " - ratio=0.25175754281808493, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1114, LPL: 1.3863, Contrastive: 0.0788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:10:59,727] Trial 19 finished with value: 0.8653216871045677 and parameters: {'alpha': 0.6853222550059309, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.26077304726499934, 'margin': 0.6158157531198359, 'lpl_weight': 0.7897270300400397, 'ratio': 0.25175754281808493, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8913, F1=0.8624, Recall=0.8527, Precision=0.8723\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102160832.csv.\n",
      "Average F1 over 5 seeds: 0.8653  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3623822756778873, K=34, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.18026749791395602, margin=0.21492989794881626, lpl_weight=0.9826857158258201\n",
      " - ratio=0.3391339125463683, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3654, LPL: 1.3863, Contrastive: 0.1780\n",
      "Epoch 50, Loss: 1.3651, LPL: 1.3863, Contrastive: 0.1618\n",
      " - Metrics: Accuracy=0.8647, F1=0.8424, Recall=0.9049, Precision=0.7879\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3623822756778873, K=34, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.18026749791395602, margin=0.21492989794881626, lpl_weight=0.9826857158258201\n",
      " - ratio=0.3391339125463683, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3654, LPL: 1.3863, Contrastive: 0.1780\n",
      "Epoch 50, Loss: 1.3651, LPL: 1.3863, Contrastive: 0.1620\n",
      " - Metrics: Accuracy=0.8599, F1=0.8368, Recall=0.8990, Precision=0.7826\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3623822756778873, K=34, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.18026749791395602, margin=0.21492989794881626, lpl_weight=0.9826857158258201\n",
      " - ratio=0.3391339125463683, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3654, LPL: 1.3863, Contrastive: 0.1780\n",
      "Epoch 50, Loss: 1.3651, LPL: 1.3863, Contrastive: 0.1623\n",
      " - Metrics: Accuracy=0.8600, F1=0.8372, Recall=0.9012, Precision=0.7816\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3623822756778873, K=34, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.18026749791395602, margin=0.21492989794881626, lpl_weight=0.9826857158258201\n",
      " - ratio=0.3391339125463683, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3654, LPL: 1.3863, Contrastive: 0.1780\n",
      "Epoch 50, Loss: 1.3651, LPL: 1.3863, Contrastive: 0.1638\n",
      " - Metrics: Accuracy=0.8648, F1=0.8417, Recall=0.9003, Precision=0.7903\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3623822756778873, K=34, layers=3, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.18026749791395602, margin=0.21492989794881626, lpl_weight=0.9826857158258201\n",
      " - ratio=0.3391339125463683, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.3654, LPL: 1.3863, Contrastive: 0.1780\n",
      "Epoch 50, Loss: 1.3651, LPL: 1.3863, Contrastive: 0.1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:13:56,266] Trial 20 finished with value: 0.8377727086210747 and parameters: {'alpha': 0.3623822756778873, 'K': 34, 'layers': 3, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.18026749791395602, 'margin': 0.21492989794881626, 'lpl_weight': 0.9826857158258201, 'ratio': 0.3391339125463683, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8545, F1=0.8308, Recall=0.8942, Precision=0.7758\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102161059.csv.\n",
      "Average F1 over 5 seeds: 0.8378  0.0042\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6015275300866615, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22151314134661396, margin=0.3616215014102796, lpl_weight=0.5963584067786716\n",
      " - ratio=0.26705658580257746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8741, LPL: 1.3863, Contrastive: 0.1174\n",
      "Epoch 50, Loss: 0.8689, LPL: 1.3863, Contrastive: 0.1045\n",
      " - Metrics: Accuracy=0.9028, F1=0.8779, Recall=0.8745, Precision=0.8813\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6015275300866615, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22151314134661396, margin=0.3616215014102796, lpl_weight=0.5963584067786716\n",
      " - ratio=0.26705658580257746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8741, LPL: 1.3863, Contrastive: 0.1174\n",
      "Epoch 50, Loss: 0.8689, LPL: 1.3863, Contrastive: 0.1044\n",
      " - Metrics: Accuracy=0.9004, F1=0.8755, Recall=0.8763, Precision=0.8747\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6015275300866615, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22151314134661396, margin=0.3616215014102796, lpl_weight=0.5963584067786716\n",
      " - ratio=0.26705658580257746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8741, LPL: 1.3863, Contrastive: 0.1174\n",
      "Epoch 50, Loss: 0.8689, LPL: 1.3863, Contrastive: 0.1045\n",
      " - Metrics: Accuracy=0.9028, F1=0.8781, Recall=0.8763, Precision=0.8799\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6015275300866615, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22151314134661396, margin=0.3616215014102796, lpl_weight=0.5963584067786716\n",
      " - ratio=0.26705658580257746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8741, LPL: 1.3863, Contrastive: 0.1174\n",
      "Epoch 50, Loss: 0.8689, LPL: 1.3863, Contrastive: 0.1044\n",
      " - Metrics: Accuracy=0.9012, F1=0.8757, Recall=0.8714, Precision=0.8801\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6015275300866615, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22151314134661396, margin=0.3616215014102796, lpl_weight=0.5963584067786716\n",
      " - ratio=0.26705658580257746, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8741, LPL: 1.3863, Contrastive: 0.1174\n",
      "Epoch 50, Loss: 0.8689, LPL: 1.3863, Contrastive: 0.1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:16:58,868] Trial 21 finished with value: 0.8772739963552952 and parameters: {'alpha': 0.6015275300866615, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.22151314134661396, 'margin': 0.3616215014102796, 'lpl_weight': 0.5963584067786716, 'ratio': 0.26705658580257746, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9033, F1=0.8792, Recall=0.8808, Precision=0.8776\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102161356.csv.\n",
      "Average F1 over 5 seeds: 0.8773  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5544041325547282, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22296837578230372, margin=0.38384715930490954, lpl_weight=0.5949436256437635\n",
      " - ratio=0.17393088840785953, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8699, LPL: 1.3863, Contrastive: 0.1114\n",
      "Epoch 50, Loss: 0.8642, LPL: 1.3863, Contrastive: 0.0974\n",
      " - Metrics: Accuracy=0.9057, F1=0.8755, Recall=0.8300, Precision=0.9263\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5544041325547282, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22296837578230372, margin=0.38384715930490954, lpl_weight=0.5949436256437635\n",
      " - ratio=0.17393088840785953, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8699, LPL: 1.3863, Contrastive: 0.1114\n",
      "Epoch 50, Loss: 0.8642, LPL: 1.3863, Contrastive: 0.0973\n",
      "Epoch 100, Loss: 0.8670, LPL: 1.3863, Contrastive: 0.1042\n",
      " - Metrics: Accuracy=0.9037, F1=0.8716, Recall=0.8183, Precision=0.9324\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5544041325547282, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22296837578230372, margin=0.38384715930490954, lpl_weight=0.5949436256437635\n",
      " - ratio=0.17393088840785953, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8699, LPL: 1.3863, Contrastive: 0.1114\n",
      "Epoch 50, Loss: 0.8642, LPL: 1.3863, Contrastive: 0.0973\n",
      " - Metrics: Accuracy=0.9047, F1=0.8740, Recall=0.8279, Precision=0.9255\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5544041325547282, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22296837578230372, margin=0.38384715930490954, lpl_weight=0.5949436256437635\n",
      " - ratio=0.17393088840785953, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8699, LPL: 1.3863, Contrastive: 0.1114\n",
      "Epoch 50, Loss: 0.8642, LPL: 1.3863, Contrastive: 0.0973\n",
      " - Metrics: Accuracy=0.9010, F1=0.8685, Recall=0.8183, Precision=0.9252\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5544041325547282, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.22296837578230372, margin=0.38384715930490954, lpl_weight=0.5949436256437635\n",
      " - ratio=0.17393088840785953, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8699, LPL: 1.3863, Contrastive: 0.1114\n",
      "Epoch 50, Loss: 0.8642, LPL: 1.3863, Contrastive: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:20:10,028] Trial 22 finished with value: 0.8725273275471371 and parameters: {'alpha': 0.5544041325547282, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.22296837578230372, 'margin': 0.38384715930490954, 'lpl_weight': 0.5949436256437635, 'ratio': 0.17393088840785953, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9047, F1=0.8730, Recall=0.8204, Precision=0.9329\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102161658.csv.\n",
      "Average F1 over 5 seeds: 0.8725  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5543339029839905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1534680438562687, margin=0.36311868931650143, lpl_weight=0.6927294817432244\n",
      " - ratio=0.25154630530190736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9961, LPL: 1.3863, Contrastive: 0.1163\n",
      "Epoch 50, Loss: 0.9922, LPL: 1.3863, Contrastive: 0.1039\n",
      " - Metrics: Accuracy=0.8999, F1=0.8756, Recall=0.8818, Precision=0.8694\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5543339029839905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1534680438562687, margin=0.36311868931650143, lpl_weight=0.6927294817432244\n",
      " - ratio=0.25154630530190736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9961, LPL: 1.3863, Contrastive: 0.1163\n",
      "Epoch 50, Loss: 0.9922, LPL: 1.3863, Contrastive: 0.1039\n",
      " - Metrics: Accuracy=0.9051, F1=0.8817, Recall=0.8857, Precision=0.8777\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5543339029839905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1534680438562687, margin=0.36311868931650143, lpl_weight=0.6927294817432244\n",
      " - ratio=0.25154630530190736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9961, LPL: 1.3863, Contrastive: 0.1163\n",
      "Epoch 50, Loss: 0.9922, LPL: 1.3863, Contrastive: 0.1039\n",
      " - Metrics: Accuracy=0.8981, F1=0.8725, Recall=0.8726, Precision=0.8723\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5543339029839905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1534680438562687, margin=0.36311868931650143, lpl_weight=0.6927294817432244\n",
      " - ratio=0.25154630530190736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9961, LPL: 1.3863, Contrastive: 0.1163\n",
      "Epoch 50, Loss: 0.9922, LPL: 1.3863, Contrastive: 0.1039\n",
      " - Metrics: Accuracy=0.9062, F1=0.8825, Recall=0.8825, Precision=0.8825\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5543339029839905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1534680438562687, margin=0.36311868931650143, lpl_weight=0.6927294817432244\n",
      " - ratio=0.25154630530190736, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.9961, LPL: 1.3863, Contrastive: 0.1163\n",
      "Epoch 50, Loss: 0.9922, LPL: 1.3863, Contrastive: 0.1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:23:18,979] Trial 23 finished with value: 0.87847715236593 and parameters: {'alpha': 0.5543339029839905, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1534680438562687, 'margin': 0.36311868931650143, 'lpl_weight': 0.6927294817432244, 'ratio': 0.25154630530190736, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9041, F1=0.8801, Recall=0.8817, Precision=0.8786\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102162010.csv.\n",
      "Average F1 over 5 seeds: 0.8785  0.0039\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5425074999800612, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.13279125387882001, margin=0.5126882068883725, lpl_weight=0.723074031721497\n",
      " - ratio=0.18795588936965157, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0250, LPL: 1.3863, Contrastive: 0.0816\n",
      "Epoch 50, Loss: 1.0194, LPL: 1.3863, Contrastive: 0.0614\n",
      "Epoch 100, Loss: 1.0193, LPL: 1.3863, Contrastive: 0.0611\n",
      " - Metrics: Accuracy=0.9047, F1=0.8723, Recall=0.8152, Precision=0.9379\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5425074999800612, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.13279125387882001, margin=0.5126882068883725, lpl_weight=0.723074031721497\n",
      " - ratio=0.18795588936965157, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0250, LPL: 1.3863, Contrastive: 0.0816\n",
      "Epoch 50, Loss: 1.0194, LPL: 1.3863, Contrastive: 0.0614\n",
      " - Metrics: Accuracy=0.9044, F1=0.8726, Recall=0.8201, Precision=0.9324\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5425074999800612, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.13279125387882001, margin=0.5126882068883725, lpl_weight=0.723074031721497\n",
      " - ratio=0.18795588936965157, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0250, LPL: 1.3863, Contrastive: 0.0816\n",
      "Epoch 50, Loss: 1.0194, LPL: 1.3863, Contrastive: 0.0614\n",
      " - Metrics: Accuracy=0.9051, F1=0.8738, Recall=0.8227, Precision=0.9316\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5425074999800612, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.13279125387882001, margin=0.5126882068883725, lpl_weight=0.723074031721497\n",
      " - ratio=0.18795588936965157, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0250, LPL: 1.3863, Contrastive: 0.0816\n",
      "Epoch 50, Loss: 1.0194, LPL: 1.3863, Contrastive: 0.0614\n",
      " - Metrics: Accuracy=0.9044, F1=0.8726, Recall=0.8194, Precision=0.9331\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5425074999800612, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.13279125387882001, margin=0.5126882068883725, lpl_weight=0.723074031721497\n",
      " - ratio=0.18795588936965157, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0250, LPL: 1.3863, Contrastive: 0.0816\n",
      "Epoch 50, Loss: 1.0194, LPL: 1.3863, Contrastive: 0.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:26:28,987] Trial 24 finished with value: 0.8737058328151651 and parameters: {'alpha': 0.5425074999800612, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.13279125387882001, 'margin': 0.5126882068883725, 'lpl_weight': 0.723074031721497, 'ratio': 0.18795588936965157, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9077, F1=0.8773, Recall=0.8260, Precision=0.9353\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102162319.csv.\n",
      "Average F1 over 5 seeds: 0.8737  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.47433539478800557, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.29737915330081643, margin=0.36908381241619637, lpl_weight=0.3598489846472871\n",
      " - ratio=0.23995553348031293, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5739, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 50, Loss: 0.5644, LPL: 1.3863, Contrastive: 0.1023\n",
      "Epoch 100, Loss: 0.5735, LPL: 1.3863, Contrastive: 0.1166\n",
      " - Metrics: Accuracy=0.9051, F1=0.8803, Recall=0.8733, Precision=0.8874\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.47433539478800557, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.29737915330081643, margin=0.36908381241619637, lpl_weight=0.3598489846472871\n",
      " - ratio=0.23995553348031293, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5739, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 50, Loss: 0.5644, LPL: 1.3863, Contrastive: 0.1023\n",
      "Epoch 100, Loss: 0.5956, LPL: 1.3863, Contrastive: 0.1512\n",
      " - Metrics: Accuracy=0.9020, F1=0.8769, Recall=0.8743, Precision=0.8795\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.47433539478800557, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.29737915330081643, margin=0.36908381241619637, lpl_weight=0.3598489846472871\n",
      " - ratio=0.23995553348031293, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5739, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 50, Loss: 0.5644, LPL: 1.3863, Contrastive: 0.1023\n",
      " - Metrics: Accuracy=0.9080, F1=0.8824, Recall=0.8639, Precision=0.9017\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.47433539478800557, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.29737915330081643, margin=0.36908381241619637, lpl_weight=0.3598489846472871\n",
      " - ratio=0.23995553348031293, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5739, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 50, Loss: 0.5644, LPL: 1.3863, Contrastive: 0.1023\n",
      "Epoch 100, Loss: 0.5793, LPL: 1.3863, Contrastive: 0.1256\n",
      " - Metrics: Accuracy=0.9012, F1=0.8755, Recall=0.8700, Precision=0.8812\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.47433539478800557, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.29737915330081643, margin=0.36908381241619637, lpl_weight=0.3598489846472871\n",
      " - ratio=0.23995553348031293, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5739, LPL: 1.3863, Contrastive: 0.1173\n",
      "Epoch 50, Loss: 0.5644, LPL: 1.3863, Contrastive: 0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:29:40,440] Trial 25 finished with value: 0.8783286156793674 and parameters: {'alpha': 0.47433539478800557, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.29737915330081643, 'margin': 0.36908381241619637, 'lpl_weight': 0.3598489846472871, 'ratio': 0.23995553348031293, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9035, F1=0.8766, Recall=0.8583, Precision=0.8957\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102162629.csv.\n",
      "Average F1 over 5 seeds: 0.8783  0.0026\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4609782342917345, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.30199418467544475, margin=0.44953295505360424, lpl_weight=0.39868972600282016\n",
      " - ratio=0.33454933623403627, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6322, LPL: 1.3863, Contrastive: 0.1322\n",
      "Epoch 50, Loss: 0.6000, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 100, Loss: 0.6291, LPL: 1.3863, Contrastive: 0.1270\n",
      " - Metrics: Accuracy=0.8447, F1=0.8143, Recall=0.8530, Precision=0.7791\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4609782342917345, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.30199418467544475, margin=0.44953295505360424, lpl_weight=0.39868972600282016\n",
      " - ratio=0.33454933623403627, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6322, LPL: 1.3863, Contrastive: 0.1322\n",
      "Epoch 50, Loss: 0.6000, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 100, Loss: 0.6250, LPL: 1.3863, Contrastive: 0.1202\n",
      " - Metrics: Accuracy=0.8478, F1=0.8183, Recall=0.8579, Precision=0.7822\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4609782342917345, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.30199418467544475, margin=0.44953295505360424, lpl_weight=0.39868972600282016\n",
      " - ratio=0.33454933623403627, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6322, LPL: 1.3863, Contrastive: 0.1322\n",
      "Epoch 50, Loss: 0.6000, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 100, Loss: 0.6336, LPL: 1.3863, Contrastive: 0.1345\n",
      " - Metrics: Accuracy=0.8840, F1=0.8618, Recall=0.9059, Precision=0.8218\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4609782342917345, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.30199418467544475, margin=0.44953295505360424, lpl_weight=0.39868972600282016\n",
      " - ratio=0.33454933623403627, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6322, LPL: 1.3863, Contrastive: 0.1322\n",
      "Epoch 50, Loss: 0.6000, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 100, Loss: 0.6143, LPL: 1.3863, Contrastive: 0.1024\n",
      " - Metrics: Accuracy=0.8688, F1=0.8431, Recall=0.8823, Precision=0.8072\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4609782342917345, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.30199418467544475, margin=0.44953295505360424, lpl_weight=0.39868972600282016\n",
      " - ratio=0.33454933623403627, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6322, LPL: 1.3863, Contrastive: 0.1322\n",
      "Epoch 50, Loss: 0.6000, LPL: 1.3863, Contrastive: 0.0787\n",
      "Epoch 100, Loss: 0.6083, LPL: 1.3863, Contrastive: 0.0924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:32:53,314] Trial 26 finished with value: 0.8395686899854061 and parameters: {'alpha': 0.4609782342917345, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.30199418467544475, 'margin': 0.44953295505360424, 'lpl_weight': 0.39868972600282016, 'ratio': 0.33454933623403627, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8844, F1=0.8603, Recall=0.8914, Precision=0.8314\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102162940.csv.\n",
      "Average F1 over 5 seeds: 0.8396  0.0201\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.34995160192197905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2969003971277524, margin=0.604602454556695, lpl_weight=0.3115150525923283\n",
      " - ratio=0.21875349649264325, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4886, LPL: 1.3863, Contrastive: 0.0824\n",
      " - Metrics: Accuracy=0.8950, F1=0.8642, Recall=0.8362, Precision=0.8941\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.34995160192197905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2969003971277524, margin=0.604602454556695, lpl_weight=0.3115150525923283\n",
      " - ratio=0.21875349649264325, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4886, LPL: 1.3863, Contrastive: 0.0824\n",
      " - Metrics: Accuracy=0.8959, F1=0.8654, Recall=0.8380, Precision=0.8948\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.34995160192197905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2969003971277524, margin=0.604602454556695, lpl_weight=0.3115150525923283\n",
      " - ratio=0.21875349649264325, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4886, LPL: 1.3863, Contrastive: 0.0824\n",
      " - Metrics: Accuracy=0.8937, F1=0.8621, Recall=0.8323, Precision=0.8943\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.34995160192197905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2969003971277524, margin=0.604602454556695, lpl_weight=0.3115150525923283\n",
      " - ratio=0.21875349649264325, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4886, LPL: 1.3863, Contrastive: 0.0824\n",
      " - Metrics: Accuracy=0.8932, F1=0.8613, Recall=0.8298, Precision=0.8952\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.34995160192197905, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2969003971277524, margin=0.604602454556695, lpl_weight=0.3115150525923283\n",
      " - ratio=0.21875349649264325, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4886, LPL: 1.3863, Contrastive: 0.0824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:35:22,424] Trial 27 finished with value: 0.8627308060113483 and parameters: {'alpha': 0.34995160192197905, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2969003971277524, 'margin': 0.604602454556695, 'lpl_weight': 0.3115150525923283, 'ratio': 0.21875349649264325, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8923, F1=0.8606, Recall=0.8326, Precision=0.8905\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102163253.csv.\n",
      "Average F1 over 5 seeds: 0.8627  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.48901501388935387, K=35, layers=3, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.37209476062574304, margin=0.20977536730622223, lpl_weight=0.843173236393377\n",
      " - ratio=0.23516322718423313, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1964, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 1.1942, LPL: 1.3863, Contrastive: 0.1617\n",
      "Epoch 100, Loss: 1.1957, LPL: 1.3863, Contrastive: 0.1712\n",
      " - Metrics: Accuracy=0.8863, F1=0.8576, Recall=0.8570, Precision=0.8582\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.48901501388935387, K=35, layers=3, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.37209476062574304, margin=0.20977536730622223, lpl_weight=0.843173236393377\n",
      " - ratio=0.23516322718423313, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1964, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 1.1942, LPL: 1.3863, Contrastive: 0.1617\n",
      " - Metrics: Accuracy=0.8981, F1=0.8714, Recall=0.8640, Precision=0.8788\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.48901501388935387, K=35, layers=3, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.37209476062574304, margin=0.20977536730622223, lpl_weight=0.843173236393377\n",
      " - ratio=0.23516322718423313, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1964, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 1.1942, LPL: 1.3863, Contrastive: 0.1617\n",
      "Epoch 100, Loss: 1.1945, LPL: 1.3863, Contrastive: 0.1630\n",
      " - Metrics: Accuracy=0.8985, F1=0.8712, Recall=0.8596, Precision=0.8832\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.48901501388935387, K=35, layers=3, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.37209476062574304, margin=0.20977536730622223, lpl_weight=0.843173236393377\n",
      " - ratio=0.23516322718423313, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1964, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 1.1942, LPL: 1.3863, Contrastive: 0.1617\n",
      " - Metrics: Accuracy=0.8990, F1=0.8715, Recall=0.8580, Precision=0.8855\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.48901501388935387, K=35, layers=3, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.37209476062574304, margin=0.20977536730622223, lpl_weight=0.843173236393377\n",
      " - ratio=0.23516322718423313, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1964, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 1.1942, LPL: 1.3863, Contrastive: 0.1617\n",
      "Epoch 100, Loss: 1.1952, LPL: 1.3863, Contrastive: 0.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:38:21,564] Trial 28 finished with value: 0.8682227864101277 and parameters: {'alpha': 0.48901501388935387, 'K': 35, 'layers': 3, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.37209476062574304, 'margin': 0.20977536730622223, 'lpl_weight': 0.843173236393377, 'ratio': 0.23516322718423313, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8973, F1=0.8694, Recall=0.8557, Precision=0.8835\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102163522.csv.\n",
      "Average F1 over 5 seeds: 0.8682  0.0054\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1985204937928408, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18830818023353735, margin=0.3578038057780001, lpl_weight=0.4460353365553147\n",
      " - ratio=0.13661865573433563, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6862, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 50, Loss: 0.6776, LPL: 1.3863, Contrastive: 0.1070\n",
      "Epoch 100, Loss: 0.6768, LPL: 1.3863, Contrastive: 0.1056\n",
      " - Metrics: Accuracy=0.8803, F1=0.8421, Recall=0.7996, Precision=0.8894\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1985204937928408, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18830818023353735, margin=0.3578038057780001, lpl_weight=0.4460353365553147\n",
      " - ratio=0.13661865573433563, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6862, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 50, Loss: 0.6776, LPL: 1.3863, Contrastive: 0.1069\n",
      "Epoch 100, Loss: 0.6769, LPL: 1.3863, Contrastive: 0.1057\n",
      " - Metrics: Accuracy=0.9010, F1=0.8692, Recall=0.8231, Precision=0.9207\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1985204937928408, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18830818023353735, margin=0.3578038057780001, lpl_weight=0.4460353365553147\n",
      " - ratio=0.13661865573433563, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6862, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 50, Loss: 0.6776, LPL: 1.3863, Contrastive: 0.1070\n",
      "Epoch 100, Loss: 0.6769, LPL: 1.3863, Contrastive: 0.1058\n",
      " - Metrics: Accuracy=0.8937, F1=0.8600, Recall=0.8173, Precision=0.9074\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1985204937928408, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18830818023353735, margin=0.3578038057780001, lpl_weight=0.4460353365553147\n",
      " - ratio=0.13661865573433563, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6862, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 50, Loss: 0.6776, LPL: 1.3863, Contrastive: 0.1069\n",
      "Epoch 100, Loss: 0.6772, LPL: 1.3863, Contrastive: 0.1063\n",
      " - Metrics: Accuracy=0.8946, F1=0.8588, Recall=0.8030, Precision=0.9229\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1985204937928408, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18830818023353735, margin=0.3578038057780001, lpl_weight=0.4460353365553147\n",
      " - ratio=0.13661865573433563, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.6862, LPL: 1.3863, Contrastive: 0.1225\n",
      "Epoch 50, Loss: 0.6776, LPL: 1.3863, Contrastive: 0.1069\n",
      "Epoch 100, Loss: 0.6781, LPL: 1.3863, Contrastive: 0.1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:40:51,767] Trial 29 finished with value: 0.8593088145270358 and parameters: {'alpha': 0.1985204937928408, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.18830818023353735, 'margin': 0.3578038057780001, 'lpl_weight': 0.4460353365553147, 'ratio': 0.13661865573433563, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8983, F1=0.8664, Recall=0.8262, Precision=0.9108\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102163821.csv.\n",
      "Average F1 over 5 seeds: 0.8593  0.0094\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.556927859857202, K=31, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3673434272311998, margin=0.5430540452020294, lpl_weight=0.3788829359555108\n",
      " - ratio=0.33066346540108693, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5948, LPL: 1.3863, Contrastive: 0.1119\n",
      " - Metrics: Accuracy=0.8893, F1=0.8668, Recall=0.9018, Precision=0.8344\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.556927859857202, K=31, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3673434272311998, margin=0.5430540452020294, lpl_weight=0.3788829359555108\n",
      " - ratio=0.33066346540108693, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5948, LPL: 1.3863, Contrastive: 0.1119\n",
      " - Metrics: Accuracy=0.8871, F1=0.8646, Recall=0.9026, Precision=0.8297\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.556927859857202, K=31, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3673434272311998, margin=0.5430540452020294, lpl_weight=0.3788829359555108\n",
      " - ratio=0.33066346540108693, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5948, LPL: 1.3863, Contrastive: 0.1119\n",
      " - Metrics: Accuracy=0.8879, F1=0.8656, Recall=0.9037, Precision=0.8305\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.556927859857202, K=31, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3673434272311998, margin=0.5430540452020294, lpl_weight=0.3788829359555108\n",
      " - ratio=0.33066346540108693, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5948, LPL: 1.3863, Contrastive: 0.1119\n",
      " - Metrics: Accuracy=0.8871, F1=0.8642, Recall=0.8998, Precision=0.8313\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.556927859857202, K=31, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3673434272311998, margin=0.5430540452020294, lpl_weight=0.3788829359555108\n",
      " - ratio=0.33066346540108693, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5948, LPL: 1.3863, Contrastive: 0.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:42:49,303] Trial 30 finished with value: 0.8645502534521821 and parameters: {'alpha': 0.556927859857202, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3673434272311998, 'margin': 0.5430540452020294, 'lpl_weight': 0.3788829359555108, 'ratio': 0.33066346540108693, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8848, F1=0.8615, Recall=0.8977, Precision=0.8282\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102164051.csv.\n",
      "Average F1 over 5 seeds: 0.8646  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5814311903481804, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24447329071887708, margin=0.34477657633235353, lpl_weight=0.5366157343354567\n",
      " - ratio=0.2669722016113219, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8007, LPL: 1.3863, Contrastive: 0.1226\n",
      "Epoch 50, Loss: 0.7948, LPL: 1.3863, Contrastive: 0.1098\n",
      " - Metrics: Accuracy=0.9027, F1=0.8784, Recall=0.8794, Precision=0.8774\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5814311903481804, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24447329071887708, margin=0.34477657633235353, lpl_weight=0.5366157343354567\n",
      " - ratio=0.2669722016113219, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8007, LPL: 1.3863, Contrastive: 0.1226\n",
      "Epoch 50, Loss: 0.7948, LPL: 1.3863, Contrastive: 0.1098\n",
      " - Metrics: Accuracy=0.9041, F1=0.8798, Recall=0.8783, Precision=0.8813\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5814311903481804, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24447329071887708, margin=0.34477657633235353, lpl_weight=0.5366157343354567\n",
      " - ratio=0.2669722016113219, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8007, LPL: 1.3863, Contrastive: 0.1226\n",
      "Epoch 50, Loss: 0.7948, LPL: 1.3863, Contrastive: 0.1098\n",
      " - Metrics: Accuracy=0.9064, F1=0.8824, Recall=0.8791, Precision=0.8857\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5814311903481804, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24447329071887708, margin=0.34477657633235353, lpl_weight=0.5366157343354567\n",
      " - ratio=0.2669722016113219, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8007, LPL: 1.3863, Contrastive: 0.1226\n",
      "Epoch 50, Loss: 0.7948, LPL: 1.3863, Contrastive: 0.1098\n",
      " - Metrics: Accuracy=0.9039, F1=0.8793, Recall=0.8758, Precision=0.8828\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5814311903481804, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.24447329071887708, margin=0.34477657633235353, lpl_weight=0.5366157343354567\n",
      " - ratio=0.2669722016113219, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8007, LPL: 1.3863, Contrastive: 0.1226\n",
      "Epoch 50, Loss: 0.7948, LPL: 1.3863, Contrastive: 0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:45:55,974] Trial 31 finished with value: 0.8794421114518393 and parameters: {'alpha': 0.5814311903481804, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.24447329071887708, 'margin': 0.34477657633235353, 'lpl_weight': 0.5366157343354567, 'ratio': 0.2669722016113219, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9022, F1=0.8774, Recall=0.8762, Precision=0.8785\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102164249.csv.\n",
      "Average F1 over 5 seeds: 0.8794  0.0017\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.44219209992254893, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.25096764819953404, margin=0.44258350841503546, lpl_weight=0.4796305966046237\n",
      " - ratio=0.1908686472298634, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7164, LPL: 1.3863, Contrastive: 0.0990\n",
      "Epoch 50, Loss: 0.7066, LPL: 1.3863, Contrastive: 0.0802\n",
      "Epoch 100, Loss: 0.7075, LPL: 1.3863, Contrastive: 0.0819\n",
      " - Metrics: Accuracy=0.9033, F1=0.8719, Recall=0.8237, Precision=0.9261\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.44219209992254893, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.25096764819953404, margin=0.44258350841503546, lpl_weight=0.4796305966046237\n",
      " - ratio=0.1908686472298634, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7164, LPL: 1.3863, Contrastive: 0.0990\n",
      "Epoch 50, Loss: 0.7066, LPL: 1.3863, Contrastive: 0.0802\n",
      "Epoch 100, Loss: 0.7064, LPL: 1.3863, Contrastive: 0.0797\n",
      " - Metrics: Accuracy=0.9056, F1=0.8760, Recall=0.8349, Precision=0.9213\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.44219209992254893, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.25096764819953404, margin=0.44258350841503546, lpl_weight=0.4796305966046237\n",
      " - ratio=0.1908686472298634, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7164, LPL: 1.3863, Contrastive: 0.0990\n",
      "Epoch 50, Loss: 0.7066, LPL: 1.3863, Contrastive: 0.0802\n",
      "Epoch 100, Loss: 0.7069, LPL: 1.3863, Contrastive: 0.0807\n",
      " - Metrics: Accuracy=0.9059, F1=0.8751, Recall=0.8255, Precision=0.9310\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.44219209992254893, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.25096764819953404, margin=0.44258350841503546, lpl_weight=0.4796305966046237\n",
      " - ratio=0.1908686472298634, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7164, LPL: 1.3863, Contrastive: 0.0990\n",
      "Epoch 50, Loss: 0.7066, LPL: 1.3863, Contrastive: 0.0802\n",
      "Epoch 100, Loss: 0.7202, LPL: 1.3863, Contrastive: 0.1062\n",
      " - Metrics: Accuracy=0.9035, F1=0.8745, Recall=0.8415, Precision=0.9102\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.44219209992254893, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.25096764819953404, margin=0.44258350841503546, lpl_weight=0.4796305966046237\n",
      " - ratio=0.1908686472298634, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7164, LPL: 1.3863, Contrastive: 0.0990\n",
      "Epoch 50, Loss: 0.7066, LPL: 1.3863, Contrastive: 0.0802\n",
      "Epoch 100, Loss: 0.7076, LPL: 1.3863, Contrastive: 0.0820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:49:11,643] Trial 32 finished with value: 0.8741866320191065 and parameters: {'alpha': 0.44219209992254893, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.25096764819953404, 'margin': 0.44258350841503546, 'lpl_weight': 0.4796305966046237, 'ratio': 0.1908686472298634, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9041, F1=0.8735, Recall=0.8288, Precision=0.9232\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102164556.csv.\n",
      "Average F1 over 5 seeds: 0.8742  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.49476494298557483, K=30, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2862240989290399, margin=0.400191479823435, lpl_weight=0.5439411766318217\n",
      " - ratio=0.27841869985653966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8040, LPL: 1.3863, Contrastive: 0.1094\n",
      "Epoch 50, Loss: 0.7963, LPL: 1.3863, Contrastive: 0.0927\n",
      " - Metrics: Accuracy=0.9040, F1=0.8803, Recall=0.8832, Precision=0.8774\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.49476494298557483, K=30, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2862240989290399, margin=0.400191479823435, lpl_weight=0.5439411766318217\n",
      " - ratio=0.27841869985653966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8040, LPL: 1.3863, Contrastive: 0.1094\n",
      "Epoch 50, Loss: 0.7963, LPL: 1.3863, Contrastive: 0.0927\n",
      " - Metrics: Accuracy=0.9065, F1=0.8833, Recall=0.8862, Precision=0.8804\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.49476494298557483, K=30, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2862240989290399, margin=0.400191479823435, lpl_weight=0.5439411766318217\n",
      " - ratio=0.27841869985653966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8040, LPL: 1.3863, Contrastive: 0.1094\n",
      "Epoch 50, Loss: 0.7963, LPL: 1.3863, Contrastive: 0.0927\n",
      " - Metrics: Accuracy=0.9041, F1=0.8806, Recall=0.8857, Precision=0.8756\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.49476494298557483, K=30, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2862240989290399, margin=0.400191479823435, lpl_weight=0.5439411766318217\n",
      " - ratio=0.27841869985653966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8040, LPL: 1.3863, Contrastive: 0.1094\n",
      "Epoch 50, Loss: 0.7963, LPL: 1.3863, Contrastive: 0.0927\n",
      " - Metrics: Accuracy=0.9021, F1=0.8776, Recall=0.8789, Precision=0.8764\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.49476494298557483, K=30, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2862240989290399, margin=0.400191479823435, lpl_weight=0.5439411766318217\n",
      " - ratio=0.27841869985653966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8040, LPL: 1.3863, Contrastive: 0.1094\n",
      "Epoch 50, Loss: 0.7963, LPL: 1.3863, Contrastive: 0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:52:19,516] Trial 33 finished with value: 0.8800627977237028 and parameters: {'alpha': 0.49476494298557483, 'K': 30, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2862240989290399, 'margin': 0.400191479823435, 'lpl_weight': 0.5439411766318217, 'ratio': 0.27841869985653966, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9022, F1=0.8785, Recall=0.8850, Precision=0.8721\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102164911.csv.\n",
      "Average F1 over 5 seeds: 0.8801  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7923496067971116, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.23852648806415946, margin=0.32051736219507077, lpl_weight=0.5423432026163805\n",
      " - ratio=0.2729665309924771, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8484, LPL: 1.3863, Contrastive: 0.2110\n",
      " - Metrics: Accuracy=0.8970, F1=0.8695, Recall=0.8589, Precision=0.8804\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7923496067971116, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.23852648806415946, margin=0.32051736219507077, lpl_weight=0.5423432026163805\n",
      " - ratio=0.2729665309924771, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8484, LPL: 1.3863, Contrastive: 0.2110\n",
      " - Metrics: Accuracy=0.8972, F1=0.8698, Recall=0.8597, Precision=0.8802\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7923496067971116, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.23852648806415946, margin=0.32051736219507077, lpl_weight=0.5423432026163805\n",
      " - ratio=0.2729665309924771, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8484, LPL: 1.3863, Contrastive: 0.2110\n",
      " - Metrics: Accuracy=0.8946, F1=0.8665, Recall=0.8565, Precision=0.8768\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7923496067971116, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.23852648806415946, margin=0.32051736219507077, lpl_weight=0.5423432026163805\n",
      " - ratio=0.2729665309924771, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8484, LPL: 1.3863, Contrastive: 0.2110\n",
      " - Metrics: Accuracy=0.8987, F1=0.8720, Recall=0.8641, Precision=0.8800\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7923496067971116, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.23852648806415946, margin=0.32051736219507077, lpl_weight=0.5423432026163805\n",
      " - ratio=0.2729665309924771, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8484, LPL: 1.3863, Contrastive: 0.2110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:54:48,455] Trial 34 finished with value: 0.8693107859281834 and parameters: {'alpha': 0.7923496067971116, 'K': 30, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.23852648806415946, 'margin': 0.32051736219507077, 'lpl_weight': 0.5423432026163805, 'ratio': 0.2729665309924771, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8961, F1=0.8687, Recall=0.8606, Precision=0.8769\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102165219.csv.\n",
      "Average F1 over 5 seeds: 0.8693  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7331842687072542, K=30, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2852328796995867, margin=0.4775795555070292, lpl_weight=0.6778335673798646\n",
      " - ratio=0.28528047938776585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9779, LPL: 1.3863, Contrastive: 0.1186\n",
      " - Metrics: Accuracy=0.8832, F1=0.8589, Recall=0.8902, Precision=0.8298\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7331842687072542, K=30, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2852328796995867, margin=0.4775795555070292, lpl_weight=0.6778335673798646\n",
      " - ratio=0.28528047938776585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9779, LPL: 1.3863, Contrastive: 0.1186\n",
      " - Metrics: Accuracy=0.8838, F1=0.8596, Recall=0.8910, Precision=0.8303\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7331842687072542, K=30, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2852328796995867, margin=0.4775795555070292, lpl_weight=0.6778335673798646\n",
      " - ratio=0.28528047938776585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9779, LPL: 1.3863, Contrastive: 0.1186\n",
      " - Metrics: Accuracy=0.8824, F1=0.8580, Recall=0.8898, Precision=0.8284\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7331842687072542, K=30, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2852328796995867, margin=0.4775795555070292, lpl_weight=0.6778335673798646\n",
      " - ratio=0.28528047938776585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9779, LPL: 1.3863, Contrastive: 0.1186\n",
      " - Metrics: Accuracy=0.8822, F1=0.8577, Recall=0.8893, Precision=0.8284\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7331842687072542, K=30, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2852328796995867, margin=0.4775795555070292, lpl_weight=0.6778335673798646\n",
      " - ratio=0.28528047938776585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9779, LPL: 1.3863, Contrastive: 0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:56:54,702] Trial 35 finished with value: 0.8576186777420032 and parameters: {'alpha': 0.7331842687072542, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.2852328796995867, 'margin': 0.4775795555070292, 'lpl_weight': 0.6778335673798646, 'ratio': 0.28528047938776585, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8790, F1=0.8538, Recall=0.8848, Precision=0.8249\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102165448.csv.\n",
      "Average F1 over 5 seeds: 0.8576  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5673839981081966, K=28, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15671381766494846, margin=0.23529112140820568, lpl_weight=0.5447513222330209\n",
      " - ratio=0.320216845733015, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8805, LPL: 1.3863, Contrastive: 0.2753\n",
      "Epoch 50, Loss: 0.8238, LPL: 1.3863, Contrastive: 0.1507\n",
      " - Metrics: Accuracy=0.8933, F1=0.8716, Recall=0.9062, Precision=0.8395\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5673839981081966, K=28, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15671381766494846, margin=0.23529112140820568, lpl_weight=0.5447513222330209\n",
      " - ratio=0.320216845733015, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8805, LPL: 1.3863, Contrastive: 0.2753\n",
      "Epoch 50, Loss: 0.8238, LPL: 1.3863, Contrastive: 0.1508\n",
      " - Metrics: Accuracy=0.8941, F1=0.8725, Recall=0.9072, Precision=0.8404\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5673839981081966, K=28, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15671381766494846, margin=0.23529112140820568, lpl_weight=0.5447513222330209\n",
      " - ratio=0.320216845733015, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8805, LPL: 1.3863, Contrastive: 0.2753\n",
      "Epoch 50, Loss: 0.8238, LPL: 1.3863, Contrastive: 0.1507\n",
      " - Metrics: Accuracy=0.8946, F1=0.8732, Recall=0.9091, Precision=0.8401\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5673839981081966, K=28, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15671381766494846, margin=0.23529112140820568, lpl_weight=0.5447513222330209\n",
      " - ratio=0.320216845733015, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8805, LPL: 1.3863, Contrastive: 0.2753\n",
      "Epoch 50, Loss: 0.8238, LPL: 1.3863, Contrastive: 0.1507\n",
      " - Metrics: Accuracy=0.8939, F1=0.8721, Recall=0.9055, Precision=0.8411\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5673839981081966, K=28, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.15671381766494846, margin=0.23529112140820568, lpl_weight=0.5447513222330209\n",
      " - ratio=0.320216845733015, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8805, LPL: 1.3863, Contrastive: 0.2753\n",
      "Epoch 50, Loss: 0.8238, LPL: 1.3863, Contrastive: 0.1507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 16:59:52,675] Trial 36 finished with value: 0.8714477832160025 and parameters: {'alpha': 0.5673839981081966, 'K': 28, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.15671381766494846, 'margin': 0.23529112140820568, 'lpl_weight': 0.5447513222330209, 'ratio': 0.320216845733015, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8899, F1=0.8678, Recall=0.9046, Precision=0.8339\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102165654.csv.\n",
      "Average F1 over 5 seeds: 0.8714  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6655228484531205, K=29, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.36206290264321217, margin=0.40691729433329754, lpl_weight=0.7604296043857955\n",
      " - ratio=0.2448850731317965, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0857, LPL: 1.3863, Contrastive: 0.1315\n",
      "Epoch 50, Loss: 1.0764, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.0759, LPL: 1.3863, Contrastive: 0.0907\n",
      " - Metrics: Accuracy=0.9045, F1=0.8792, Recall=0.8701, Precision=0.8885\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6655228484531205, K=29, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.36206290264321217, margin=0.40691729433329754, lpl_weight=0.7604296043857955\n",
      " - ratio=0.2448850731317965, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0857, LPL: 1.3863, Contrastive: 0.1315\n",
      "Epoch 50, Loss: 1.0764, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.0760, LPL: 1.3863, Contrastive: 0.0910\n",
      " - Metrics: Accuracy=0.9008, F1=0.8765, Recall=0.8809, Precision=0.8721\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6655228484531205, K=29, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.36206290264321217, margin=0.40691729433329754, lpl_weight=0.7604296043857955\n",
      " - ratio=0.2448850731317965, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0857, LPL: 1.3863, Contrastive: 0.1315\n",
      "Epoch 50, Loss: 1.0764, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.0760, LPL: 1.3863, Contrastive: 0.0910\n",
      " - Metrics: Accuracy=0.8990, F1=0.8743, Recall=0.8795, Precision=0.8691\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6655228484531205, K=29, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.36206290264321217, margin=0.40691729433329754, lpl_weight=0.7604296043857955\n",
      " - ratio=0.2448850731317965, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0857, LPL: 1.3863, Contrastive: 0.1316\n",
      "Epoch 50, Loss: 1.0764, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.0760, LPL: 1.3863, Contrastive: 0.0910\n",
      " - Metrics: Accuracy=0.8951, F1=0.8692, Recall=0.8725, Precision=0.8659\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6655228484531205, K=29, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.36206290264321217, margin=0.40691729433329754, lpl_weight=0.7604296043857955\n",
      " - ratio=0.2448850731317965, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0857, LPL: 1.3863, Contrastive: 0.1315\n",
      "Epoch 50, Loss: 1.0764, LPL: 1.3863, Contrastive: 0.0929\n",
      "Epoch 100, Loss: 1.0760, LPL: 1.3863, Contrastive: 0.0910\n",
      "Epoch 150, Loss: 1.0790, LPL: 1.3863, Contrastive: 0.1036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:03:02,311] Trial 37 finished with value: 0.8750976118786618 and parameters: {'alpha': 0.6655228484531205, 'K': 29, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': None, 'dropout': 0.36206290264321217, 'margin': 0.40691729433329754, 'lpl_weight': 0.7604296043857955, 'ratio': 0.2448850731317965, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9010, F1=0.8763, Recall=0.8782, Precision=0.8744\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102165952.csv.\n",
      "Average F1 over 5 seeds: 0.8751  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4049881321172128, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.32761319096161223, margin=0.32749722239061246, lpl_weight=0.9275431447512693\n",
      " - ratio=0.34779208258921374, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3004, LPL: 1.3863, Contrastive: 0.2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8424, F1=0.8202, Recall=0.9001, Precision=0.7534\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4049881321172128, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.32761319096161223, margin=0.32749722239061246, lpl_weight=0.9275431447512693\n",
      " - ratio=0.34779208258921374, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3004, LPL: 1.3863, Contrastive: 0.2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8404, F1=0.8178, Recall=0.8968, Precision=0.7517\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4049881321172128, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.32761319096161223, margin=0.32749722239061246, lpl_weight=0.9275431447512693\n",
      " - ratio=0.34779208258921374, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3004, LPL: 1.3863, Contrastive: 0.2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8375, F1=0.8146, Recall=0.8937, Precision=0.7483\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4049881321172128, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.32761319096161223, margin=0.32749722239061246, lpl_weight=0.9275431447512693\n",
      " - ratio=0.34779208258921374, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3004, LPL: 1.3863, Contrastive: 0.2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8452, F1=0.8234, Recall=0.9032, Precision=0.7565\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4049881321172128, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.32761319096161223, margin=0.32749722239061246, lpl_weight=0.9275431447512693\n",
      " - ratio=0.34779208258921374, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3004, LPL: 1.3863, Contrastive: 0.2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n",
      "[I 2025-02-21 17:05:33,680] Trial 38 finished with value: 0.817529545550526 and parameters: {'alpha': 0.4049881321172128, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.32761319096161223, 'margin': 0.32749722239061246, 'lpl_weight': 0.9275431447512693, 'ratio': 0.34779208258921374, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8349, F1=0.8116, Recall=0.8905, Precision=0.7456\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102170302.csv.\n",
      "Average F1 over 5 seeds: 0.8175  0.0041\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5101696845423532, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.19626215419722937, margin=0.834422471443534, lpl_weight=0.623671017438298\n",
      " - ratio=0.4434909495082765, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8979, LPL: 1.3863, Contrastive: 0.0886\n",
      " - Metrics: Accuracy=0.8365, F1=0.8150, Recall=0.9017, Precision=0.7436\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5101696845423532, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.19626215419722937, margin=0.834422471443534, lpl_weight=0.623671017438298\n",
      " - ratio=0.4434909495082765, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8979, LPL: 1.3863, Contrastive: 0.0886\n",
      " - Metrics: Accuracy=0.8359, F1=0.8150, Recall=0.9051, Precision=0.7412\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5101696845423532, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.19626215419722937, margin=0.834422471443534, lpl_weight=0.623671017438298\n",
      " - ratio=0.4434909495082765, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8979, LPL: 1.3863, Contrastive: 0.0886\n",
      " - Metrics: Accuracy=0.8410, F1=0.8197, Recall=0.9048, Precision=0.7492\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5101696845423532, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.19626215419722937, margin=0.834422471443534, lpl_weight=0.623671017438298\n",
      " - ratio=0.4434909495082765, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8979, LPL: 1.3863, Contrastive: 0.0886\n",
      " - Metrics: Accuracy=0.8413, F1=0.8198, Recall=0.9037, Precision=0.7501\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5101696845423532, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.19626215419722937, margin=0.834422471443534, lpl_weight=0.623671017438298\n",
      " - ratio=0.4434909495082765, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8979, LPL: 1.3863, Contrastive: 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:07:30,310] Trial 39 finished with value: 0.8162813597919476 and parameters: {'alpha': 0.5101696845423532, 'K': 32, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.19626215419722937, 'margin': 0.834422471443534, 'lpl_weight': 0.623671017438298, 'ratio': 0.4434909495082765, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8337, F1=0.8119, Recall=0.8987, Precision=0.7404\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102170533.csv.\n",
      "Average F1 over 5 seeds: 0.8163  0.0030\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5877389226289772, K=28, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.28306884136452776, margin=0.49799159505375806, lpl_weight=0.44733791303641024\n",
      " - ratio=0.1983476314648701, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6816, LPL: 1.3863, Contrastive: 0.1112\n",
      " - Metrics: Accuracy=0.8980, F1=0.8679, Recall=0.8386, Precision=0.8992\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5877389226289772, K=28, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.28306884136452776, margin=0.49799159505375806, lpl_weight=0.44733791303641024\n",
      " - ratio=0.1983476314648701, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6816, LPL: 1.3863, Contrastive: 0.1112\n",
      " - Metrics: Accuracy=0.9000, F1=0.8706, Recall=0.8420, Precision=0.9012\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5877389226289772, K=28, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.28306884136452776, margin=0.49799159505375806, lpl_weight=0.44733791303641024\n",
      " - ratio=0.1983476314648701, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6816, LPL: 1.3863, Contrastive: 0.1112\n",
      " - Metrics: Accuracy=0.8990, F1=0.8693, Recall=0.8414, Precision=0.8992\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5877389226289772, K=28, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.28306884136452776, margin=0.49799159505375806, lpl_weight=0.44733791303641024\n",
      " - ratio=0.1983476314648701, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6816, LPL: 1.3863, Contrastive: 0.1112\n",
      " - Metrics: Accuracy=0.8955, F1=0.8647, Recall=0.8356, Precision=0.8958\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5877389226289772, K=28, layers=1, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.28306884136452776, margin=0.49799159505375806, lpl_weight=0.44733791303641024\n",
      " - ratio=0.1983476314648701, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6816, LPL: 1.3863, Contrastive: 0.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:09:19,857] Trial 40 finished with value: 0.8681662498582188 and parameters: {'alpha': 0.5877389226289772, 'K': 28, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.28306884136452776, 'margin': 0.49799159505375806, 'lpl_weight': 0.44733791303641024, 'ratio': 0.1983476314648701, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8980, F1=0.8684, Recall=0.8424, Precision=0.8960\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102170730.csv.\n",
      "Average F1 over 5 seeds: 0.8682  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4723708256969979, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.32163978231959806, margin=0.4332083991320791, lpl_weight=0.33568011016363847\n",
      " - ratio=0.23439899077092125, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1043\n",
      "Epoch 50, Loss: 0.5205, LPL: 1.3863, Contrastive: 0.0831\n",
      "Epoch 100, Loss: 0.5315, LPL: 1.3863, Contrastive: 0.0995\n",
      " - Metrics: Accuracy=0.9008, F1=0.8742, Recall=0.8627, Precision=0.8860\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4723708256969979, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.32163978231959806, margin=0.4332083991320791, lpl_weight=0.33568011016363847\n",
      " - ratio=0.23439899077092125, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1043\n",
      "Epoch 50, Loss: 0.5205, LPL: 1.3863, Contrastive: 0.0831\n",
      "Epoch 100, Loss: 0.5205, LPL: 1.3863, Contrastive: 0.0831\n",
      " - Metrics: Accuracy=0.9061, F1=0.8790, Recall=0.8540, Precision=0.9056\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4723708256969979, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.32163978231959806, margin=0.4332083991320791, lpl_weight=0.33568011016363847\n",
      " - ratio=0.23439899077092125, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1043\n",
      "Epoch 50, Loss: 0.5205, LPL: 1.3863, Contrastive: 0.0831\n",
      "Epoch 100, Loss: 0.5203, LPL: 1.3863, Contrastive: 0.0827\n",
      " - Metrics: Accuracy=0.9069, F1=0.8805, Recall=0.8582, Precision=0.9040\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4723708256969979, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.32163978231959806, margin=0.4332083991320791, lpl_weight=0.33568011016363847\n",
      " - ratio=0.23439899077092125, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1043\n",
      "Epoch 50, Loss: 0.5205, LPL: 1.3863, Contrastive: 0.0831\n",
      "Epoch 100, Loss: 0.5235, LPL: 1.3863, Contrastive: 0.0875\n",
      " - Metrics: Accuracy=0.9036, F1=0.8763, Recall=0.8546, Precision=0.8991\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4723708256969979, K=35, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.32163978231959806, margin=0.4332083991320791, lpl_weight=0.33568011016363847\n",
      " - ratio=0.23439899077092125, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1043\n",
      "Epoch 50, Loss: 0.5205, LPL: 1.3863, Contrastive: 0.0831\n",
      "Epoch 100, Loss: 0.5203, LPL: 1.3863, Contrastive: 0.0827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:12:35,323] Trial 41 finished with value: 0.8776143240682922 and parameters: {'alpha': 0.4723708256969979, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.32163978231959806, 'margin': 0.4332083991320791, 'lpl_weight': 0.33568011016363847, 'ratio': 0.23439899077092125, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9050, F1=0.8781, Recall=0.8568, Precision=0.9004\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102170919.csv.\n",
      "Average F1 over 5 seeds: 0.8776  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.512910028062082, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.31013564681370875, margin=0.15902762490545258, lpl_weight=0.20464532490788626\n",
      " - ratio=0.280169559235086, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4366, LPL: 1.3863, Contrastive: 0.1923\n",
      "Epoch 50, Loss: 0.4268, LPL: 1.3863, Contrastive: 0.1800\n",
      " - Metrics: Accuracy=0.8952, F1=0.8710, Recall=0.8865, Precision=0.8561\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.512910028062082, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.31013564681370875, margin=0.15902762490545258, lpl_weight=0.20464532490788626\n",
      " - ratio=0.280169559235086, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4366, LPL: 1.3863, Contrastive: 0.1923\n",
      "Epoch 50, Loss: 0.4269, LPL: 1.3863, Contrastive: 0.1801\n",
      " - Metrics: Accuracy=0.8992, F1=0.8762, Recall=0.8931, Precision=0.8600\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.512910028062082, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.31013564681370875, margin=0.15902762490545258, lpl_weight=0.20464532490788626\n",
      " - ratio=0.280169559235086, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4366, LPL: 1.3863, Contrastive: 0.1923\n",
      "Epoch 50, Loss: 0.4269, LPL: 1.3863, Contrastive: 0.1801\n",
      " - Metrics: Accuracy=0.9012, F1=0.8771, Recall=0.8823, Precision=0.8719\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.512910028062082, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.31013564681370875, margin=0.15902762490545258, lpl_weight=0.20464532490788626\n",
      " - ratio=0.280169559235086, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4366, LPL: 1.3863, Contrastive: 0.1923\n",
      "Epoch 50, Loss: 0.4269, LPL: 1.3863, Contrastive: 0.1801\n",
      " - Metrics: Accuracy=0.8958, F1=0.8719, Recall=0.8879, Precision=0.8565\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.512910028062082, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.31013564681370875, margin=0.15902762490545258, lpl_weight=0.20464532490788626\n",
      " - ratio=0.280169559235086, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4366, LPL: 1.3863, Contrastive: 0.1923\n",
      "Epoch 50, Loss: 0.4269, LPL: 1.3863, Contrastive: 0.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:15:37,360] Trial 42 finished with value: 0.8740556239669285 and parameters: {'alpha': 0.512910028062082, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.31013564681370875, 'margin': 0.15902762490545258, 'lpl_weight': 0.20464532490788626, 'ratio': 0.280169559235086, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8972, F1=0.8740, Recall=0.8930, Precision=0.8559\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102171235.csv.\n",
      "Average F1 over 5 seeds: 0.8741  0.0023\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.408552228787214, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.3418264479162957, margin=0.40935099027421745, lpl_weight=0.5021933708380426\n",
      " - ratio=0.314540544535976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7511, LPL: 1.3863, Contrastive: 0.1103\n",
      "Epoch 50, Loss: 0.7411, LPL: 1.3863, Contrastive: 0.0902\n",
      " - Metrics: Accuracy=0.8938, F1=0.8718, Recall=0.9035, Precision=0.8422\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.408552228787214, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.3418264479162957, margin=0.40935099027421745, lpl_weight=0.5021933708380426\n",
      " - ratio=0.314540544535976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7511, LPL: 1.3863, Contrastive: 0.1103\n",
      "Epoch 50, Loss: 0.7411, LPL: 1.3863, Contrastive: 0.0902\n",
      " - Metrics: Accuracy=0.8942, F1=0.8724, Recall=0.9060, Precision=0.8412\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.408552228787214, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.3418264479162957, margin=0.40935099027421745, lpl_weight=0.5021933708380426\n",
      " - ratio=0.314540544535976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7511, LPL: 1.3863, Contrastive: 0.1103\n",
      "Epoch 50, Loss: 0.7411, LPL: 1.3863, Contrastive: 0.0902\n",
      " - Metrics: Accuracy=0.8972, F1=0.8747, Recall=0.8982, Precision=0.8524\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.408552228787214, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.3418264479162957, margin=0.40935099027421745, lpl_weight=0.5021933708380426\n",
      " - ratio=0.314540544535976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7511, LPL: 1.3863, Contrastive: 0.1103\n",
      "Epoch 50, Loss: 0.7411, LPL: 1.3863, Contrastive: 0.0902\n",
      " - Metrics: Accuracy=0.8944, F1=0.8721, Recall=0.9016, Precision=0.8444\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.408552228787214, K=34, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.3418264479162957, margin=0.40935099027421745, lpl_weight=0.5021933708380426\n",
      " - ratio=0.314540544535976, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7511, LPL: 1.3863, Contrastive: 0.1103\n",
      "Epoch 50, Loss: 0.7411, LPL: 1.3863, Contrastive: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:19:36,897] Trial 43 finished with value: 0.8726712395034777 and parameters: {'alpha': 0.408552228787214, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.3418264479162957, 'margin': 0.40935099027421745, 'lpl_weight': 0.5021933708380426, 'ratio': 0.314540544535976, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8947, F1=0.8724, Recall=0.9018, Precision=0.8449\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102171537.csv.\n",
      "Average F1 over 5 seeds: 0.8727  0.0010\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6545436992108568, K=35, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.39752419895128793, margin=0.3347720221261771, lpl_weight=0.2274849045052056\n",
      " - ratio=0.24576247349670202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4166, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 50, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.1135\n",
      " - Metrics: Accuracy=0.9044, F1=0.8782, Recall=0.8626, Precision=0.8943\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6545436992108568, K=35, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.39752419895128793, margin=0.3347720221261771, lpl_weight=0.2274849045052056\n",
      " - ratio=0.24576247349670202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4166, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 50, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.1135\n",
      " - Metrics: Accuracy=0.9039, F1=0.8782, Recall=0.8670, Precision=0.8896\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6545436992108568, K=35, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.39752419895128793, margin=0.3347720221261771, lpl_weight=0.2274849045052056\n",
      " - ratio=0.24576247349670202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4166, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 50, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.1135\n",
      "Epoch 100, Loss: 0.4157, LPL: 1.3863, Contrastive: 0.1299\n",
      " - Metrics: Accuracy=0.8988, F1=0.8719, Recall=0.8623, Precision=0.8816\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6545436992108568, K=35, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.39752419895128793, margin=0.3347720221261771, lpl_weight=0.2274849045052056\n",
      " - ratio=0.24576247349670202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4166, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 50, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.1135\n",
      " - Metrics: Accuracy=0.9037, F1=0.8774, Recall=0.8626, Precision=0.8928\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6545436992108568, K=35, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.39752419895128793, margin=0.3347720221261771, lpl_weight=0.2274849045052056\n",
      " - ratio=0.24576247349670202, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4166, LPL: 1.3863, Contrastive: 0.1311\n",
      "Epoch 50, Loss: 0.4031, LPL: 1.3863, Contrastive: 0.1135\n",
      "Epoch 100, Loss: 0.4043, LPL: 1.3863, Contrastive: 0.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:22:49,739] Trial 44 finished with value: 0.8761609611954013 and parameters: {'alpha': 0.6545436992108568, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.39752419895128793, 'margin': 0.3347720221261771, 'lpl_weight': 0.2274849045052056, 'ratio': 0.24576247349670202, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9023, F1=0.8752, Recall=0.8577, Precision=0.8934\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102171936.csv.\n",
      "Average F1 over 5 seeds: 0.8762  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.44964850470536666, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.28058048350452125, margin=0.2661385506129005, lpl_weight=0.7212815518121439\n",
      " - ratio=0.16611405577091679, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0414, LPL: 1.3863, Contrastive: 0.1487\n",
      "Epoch 50, Loss: 1.0383, LPL: 1.3863, Contrastive: 0.1378\n",
      " - Metrics: Accuracy=0.9011, F1=0.8665, Recall=0.8034, Precision=0.9403\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.44964850470536666, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.28058048350452125, margin=0.2661385506129005, lpl_weight=0.7212815518121439\n",
      " - ratio=0.16611405577091679, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0414, LPL: 1.3863, Contrastive: 0.1487\n",
      "Epoch 50, Loss: 1.0383, LPL: 1.3863, Contrastive: 0.1378\n",
      " - Metrics: Accuracy=0.9025, F1=0.8684, Recall=0.8050, Precision=0.9426\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.44964850470536666, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.28058048350452125, margin=0.2661385506129005, lpl_weight=0.7212815518121439\n",
      " - ratio=0.16611405577091679, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0414, LPL: 1.3863, Contrastive: 0.1487\n",
      "Epoch 50, Loss: 1.0383, LPL: 1.3863, Contrastive: 0.1378\n",
      " - Metrics: Accuracy=0.9016, F1=0.8685, Recall=0.8140, Precision=0.9309\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.44964850470536666, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.28058048350452125, margin=0.2661385506129005, lpl_weight=0.7212815518121439\n",
      " - ratio=0.16611405577091679, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0414, LPL: 1.3863, Contrastive: 0.1487\n",
      "Epoch 50, Loss: 1.0383, LPL: 1.3863, Contrastive: 0.1378\n",
      " - Metrics: Accuracy=0.9021, F1=0.8703, Recall=0.8221, Precision=0.9245\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.44964850470536666, K=33, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.28058048350452125, margin=0.2661385506129005, lpl_weight=0.7212815518121439\n",
      " - ratio=0.16611405577091679, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0414, LPL: 1.3863, Contrastive: 0.1487\n",
      "Epoch 50, Loss: 1.0383, LPL: 1.3863, Contrastive: 0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:25:55,272] Trial 45 finished with value: 0.8684377551455806 and parameters: {'alpha': 0.44964850470536666, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.28058048350452125, 'margin': 0.2661385506129005, 'lpl_weight': 0.7212815518121439, 'ratio': 0.16611405577091679, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9029, F1=0.8686, Recall=0.8036, Precision=0.9450\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102172249.csv.\n",
      "Average F1 over 5 seeds: 0.8684  0.0012\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3571290528253637, K=25, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.2431616660961697, margin=0.5803667756428628, lpl_weight=0.832968510499603\n",
      " - ratio=0.3631319123340288, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1674, LPL: 1.3863, Contrastive: 0.0760\n",
      "Epoch 50, Loss: 1.1623, LPL: 1.3863, Contrastive: 0.0454\n",
      "Epoch 100, Loss: 1.1639, LPL: 1.3863, Contrastive: 0.0551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8192, F1=0.7966, Recall=0.8860, Precision=0.7235\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3571290528253637, K=25, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.2431616660961697, margin=0.5803667756428628, lpl_weight=0.832968510499603\n",
      " - ratio=0.3631319123340288, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1674, LPL: 1.3863, Contrastive: 0.0760\n",
      "Epoch 50, Loss: 1.1623, LPL: 1.3863, Contrastive: 0.0454\n",
      "Epoch 100, Loss: 1.1634, LPL: 1.3863, Contrastive: 0.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8305, F1=0.8092, Recall=0.8998, Precision=0.7351\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3571290528253637, K=25, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.2431616660961697, margin=0.5803667756428628, lpl_weight=0.832968510499603\n",
      " - ratio=0.3631319123340288, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1674, LPL: 1.3863, Contrastive: 0.0760\n",
      "Epoch 50, Loss: 1.1623, LPL: 1.3863, Contrastive: 0.0454\n",
      "Epoch 100, Loss: 1.1639, LPL: 1.3863, Contrastive: 0.0548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8205, F1=0.7978, Recall=0.8866, Precision=0.7252\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3571290528253637, K=25, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.2431616660961697, margin=0.5803667756428628, lpl_weight=0.832968510499603\n",
      " - ratio=0.3631319123340288, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1674, LPL: 1.3863, Contrastive: 0.0760\n",
      "Epoch 50, Loss: 1.1623, LPL: 1.3863, Contrastive: 0.0454\n",
      "Epoch 100, Loss: 1.1632, LPL: 1.3863, Contrastive: 0.0509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8331, F1=0.8122, Recall=0.9036, Precision=0.7376\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3571290528253637, K=25, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.2431616660961697, margin=0.5803667756428628, lpl_weight=0.832968510499603\n",
      " - ratio=0.3631319123340288, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1674, LPL: 1.3863, Contrastive: 0.0760\n",
      "Epoch 50, Loss: 1.1623, LPL: 1.3863, Contrastive: 0.0454\n",
      "Epoch 100, Loss: 1.1631, LPL: 1.3863, Contrastive: 0.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n",
      "[I 2025-02-21 17:29:06,542] Trial 46 finished with value: 0.8064470070792584 and parameters: {'alpha': 0.3571290528253637, 'K': 25, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.2431616660961697, 'margin': 0.5803667756428628, 'lpl_weight': 0.832968510499603, 'ratio': 0.3631319123340288, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8369, F1=0.8165, Recall=0.9083, Precision=0.7416\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102172555.csv.\n",
      "Average F1 over 5 seeds: 0.8064  0.0079\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5167739980764894, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.20563330203610497, margin=0.40128068148393525, lpl_weight=0.3559919333991449\n",
      " - ratio=0.22484785339828892, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5621, LPL: 1.3863, Contrastive: 0.1065\n",
      "Epoch 50, Loss: 0.5530, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.5548, LPL: 1.3863, Contrastive: 0.0952\n",
      " - Metrics: Accuracy=0.9060, F1=0.8796, Recall=0.8593, Precision=0.9008\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5167739980764894, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.20563330203610497, margin=0.40128068148393525, lpl_weight=0.3559919333991449\n",
      " - ratio=0.22484785339828892, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5621, LPL: 1.3863, Contrastive: 0.1065\n",
      "Epoch 50, Loss: 0.5530, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.5605, LPL: 1.3863, Contrastive: 0.1041\n",
      " - Metrics: Accuracy=0.9023, F1=0.8758, Recall=0.8622, Precision=0.8898\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5167739980764894, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.20563330203610497, margin=0.40128068148393525, lpl_weight=0.3559919333991449\n",
      " - ratio=0.22484785339828892, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5621, LPL: 1.3863, Contrastive: 0.1065\n",
      "Epoch 50, Loss: 0.5530, LPL: 1.3863, Contrastive: 0.0923\n",
      " - Metrics: Accuracy=0.9049, F1=0.8787, Recall=0.8627, Precision=0.8954\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5167739980764894, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.20563330203610497, margin=0.40128068148393525, lpl_weight=0.3559919333991449\n",
      " - ratio=0.22484785339828892, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5621, LPL: 1.3863, Contrastive: 0.1065\n",
      "Epoch 50, Loss: 0.5530, LPL: 1.3863, Contrastive: 0.0923\n",
      " - Metrics: Accuracy=0.9017, F1=0.8746, Recall=0.8587, Precision=0.8911\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5167739980764894, K=32, layers=2, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.20563330203610497, margin=0.40128068148393525, lpl_weight=0.3559919333991449\n",
      " - ratio=0.22484785339828892, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.5621, LPL: 1.3863, Contrastive: 0.1065\n",
      "Epoch 50, Loss: 0.5530, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.5595, LPL: 1.3863, Contrastive: 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:32:17,570] Trial 47 finished with value: 0.8763338211728229 and parameters: {'alpha': 0.5167739980764894, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.20563330203610497, 'margin': 0.40128068148393525, 'lpl_weight': 0.3559919333991449, 'ratio': 0.22484785339828892, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8998, F1=0.8730, Recall=0.8621, Precision=0.8841\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102172906.csv.\n",
      "Average F1 over 5 seeds: 0.8763  0.0025\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7307245006173277, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.12842990465701737, margin=0.1927018969362656, lpl_weight=0.5574407572876022\n",
      " - ratio=0.21052269115132116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8549, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 0.8470, LPL: 1.3863, Contrastive: 0.1678\n",
      " - Metrics: Accuracy=0.9039, F1=0.8774, Recall=0.8608, Precision=0.8946\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7307245006173277, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.12842990465701737, margin=0.1927018969362656, lpl_weight=0.5574407572876022\n",
      " - ratio=0.21052269115132116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8549, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 0.8470, LPL: 1.3863, Contrastive: 0.1678\n",
      " - Metrics: Accuracy=0.9069, F1=0.8813, Recall=0.8658, Precision=0.8975\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7307245006173277, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.12842990465701737, margin=0.1927018969362656, lpl_weight=0.5574407572876022\n",
      " - ratio=0.21052269115132116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8549, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 0.8470, LPL: 1.3863, Contrastive: 0.1678\n",
      " - Metrics: Accuracy=0.9060, F1=0.8790, Recall=0.8547, Precision=0.9046\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7307245006173277, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.12842990465701737, margin=0.1927018969362656, lpl_weight=0.5574407572876022\n",
      " - ratio=0.21052269115132116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8549, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 0.8470, LPL: 1.3863, Contrastive: 0.1678\n",
      " - Metrics: Accuracy=0.8991, F1=0.8703, Recall=0.8476, Precision=0.8943\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7307245006173277, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.12842990465701737, margin=0.1927018969362656, lpl_weight=0.5574407572876022\n",
      " - ratio=0.21052269115132116, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8549, LPL: 1.3863, Contrastive: 0.1857\n",
      "Epoch 50, Loss: 0.8470, LPL: 1.3863, Contrastive: 0.1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:34:29,992] Trial 48 finished with value: 0.877568912846364 and parameters: {'alpha': 0.7307245006173277, 'K': 33, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.12842990465701737, 'margin': 0.1927018969362656, 'lpl_weight': 0.5574407572876022, 'ratio': 0.21052269115132116, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9061, F1=0.8799, Recall=0.8607, Precision=0.8999\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102173217.csv.\n",
      "Average F1 over 5 seeds: 0.8776  0.0038\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6447601667251329, K=35, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.16513074229307365, margin=0.988214927936796, lpl_weight=0.25926532200483754\n",
      " - ratio=0.28564594150034084, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3950, LPL: 1.3863, Contrastive: 0.0481\n",
      "Epoch 50, Loss: 0.3595, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.8493, F1=0.8158, Recall=0.8357, Precision=0.7969\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6447601667251329, K=35, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.16513074229307365, margin=0.988214927936796, lpl_weight=0.25926532200483754\n",
      " - ratio=0.28564594150034084, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3950, LPL: 1.3863, Contrastive: 0.0481\n",
      "Epoch 50, Loss: 0.3595, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.8497, F1=0.8166, Recall=0.8378, Precision=0.7965\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6447601667251329, K=35, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.16513074229307365, margin=0.988214927936796, lpl_weight=0.25926532200483754\n",
      " - ratio=0.28564594150034084, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3950, LPL: 1.3863, Contrastive: 0.0481\n",
      "Epoch 50, Loss: 0.3595, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.8501, F1=0.8168, Recall=0.8367, Precision=0.7979\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6447601667251329, K=35, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.16513074229307365, margin=0.988214927936796, lpl_weight=0.25926532200483754\n",
      " - ratio=0.28564594150034084, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3950, LPL: 1.3863, Contrastive: 0.0481\n",
      "Epoch 50, Loss: 0.3595, LPL: 1.3863, Contrastive: 0.0000\n",
      " - Metrics: Accuracy=0.8544, F1=0.8226, Recall=0.8448, Precision=0.8015\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6447601667251329, K=35, layers=3, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.16513074229307365, margin=0.988214927936796, lpl_weight=0.25926532200483754\n",
      " - ratio=0.28564594150034084, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3950, LPL: 1.3863, Contrastive: 0.0481\n",
      "Epoch 50, Loss: 0.3595, LPL: 1.3863, Contrastive: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:37:40,373] Trial 49 finished with value: 0.8178557728124629 and parameters: {'alpha': 0.6447601667251329, 'K': 35, 'layers': 3, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.16513074229307365, 'margin': 0.988214927936796, 'lpl_weight': 0.25926532200483754, 'ratio': 0.28564594150034084, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 15 with value: 0.8809428866883211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8502, F1=0.8174, Recall=0.8392, Precision=0.7966\n",
      "Done. Results written to pubmed_experimentations\\pubmed_scar_2102173430.csv.\n",
      "Average F1 over 5 seeds: 0.8179  0.0024\n",
      "Best trial:\n",
      "  Average F1: 0.8809428866883211\n",
      "  Best parameters:\n",
      "    alpha: 0.5311031346531587\n",
      "    K: 33\n",
      "    layers: 2\n",
      "    hidden_channels: 128\n",
      "    out_channels: 256\n",
      "    norm: graphnorm\n",
      "    dropout: 0.24538111087672715\n",
      "    margin: 0.41638371321098333\n",
      "    lpl_weight: 0.7621846841147637\n",
      "    ratio: 0.23594715913885006\n",
      "    aggregation: sum\n",
      "    treatment: removal\n"
     ]
    }
   ],
   "source": [
    "from train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"pubmed\",      \n",
    "        \"mechanism\": \"SCAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": 1,#trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"pubmed_scar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization Pubmed\n",
    "#### SAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:37:40,402] A new study created in memory with name: no-name-844003c5-4ac3-4390-9eab-9c8130d0dffc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.8470687016196532, K=30, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.47531813740286366, margin=0.5703046345692171, lpl_weight=0.35007282250426\n",
      " - ratio=0.447658056484299, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5204, LPL: 1.3863, Contrastive: 0.0540\n",
      "Epoch 50, Loss: 0.5163, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.5257, LPL: 1.3863, Contrastive: 0.0621\n",
      " - Metrics: Accuracy=0.8560, F1=0.8375, Recall=0.9290, Precision=0.7624\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8470687016196532, K=30, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.47531813740286366, margin=0.5703046345692171, lpl_weight=0.35007282250426\n",
      " - ratio=0.447658056484299, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5204, LPL: 1.3863, Contrastive: 0.0540\n",
      "Epoch 50, Loss: 0.5163, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.5237, LPL: 1.3863, Contrastive: 0.0590\n",
      " - Metrics: Accuracy=0.8414, F1=0.8219, Recall=0.9167, Precision=0.7449\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8470687016196532, K=30, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.47531813740286366, margin=0.5703046345692171, lpl_weight=0.35007282250426\n",
      " - ratio=0.447658056484299, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5204, LPL: 1.3863, Contrastive: 0.0540\n",
      "Epoch 50, Loss: 0.5163, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.5283, LPL: 1.3863, Contrastive: 0.0662\n",
      " - Metrics: Accuracy=0.8458, F1=0.8254, Recall=0.9125, Precision=0.7534\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8470687016196532, K=30, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.47531813740286366, margin=0.5703046345692171, lpl_weight=0.35007282250426\n",
      " - ratio=0.447658056484299, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5204, LPL: 1.3863, Contrastive: 0.0540\n",
      "Epoch 50, Loss: 0.5163, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.5346, LPL: 1.3863, Contrastive: 0.0759\n",
      " - Metrics: Accuracy=0.8457, F1=0.8226, Recall=0.8956, Precision=0.7606\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8470687016196532, K=30, layers=2, hidden=256, out=64\n",
      " - norm=layernorm, dropout=0.47531813740286366, margin=0.5703046345692171, lpl_weight=0.35007282250426\n",
      " - ratio=0.447658056484299, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5204, LPL: 1.3863, Contrastive: 0.0540\n",
      "Epoch 50, Loss: 0.5163, LPL: 1.3863, Contrastive: 0.0476\n",
      "Epoch 100, Loss: 0.5190, LPL: 1.3863, Contrastive: 0.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:40:27,164] Trial 0 finished with value: 0.8274415087727414 and parameters: {'alpha': 0.8470687016196532, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.47531813740286366, 'margin': 0.5703046345692171, 'lpl_weight': 0.35007282250426, 'ratio': 0.447658056484299, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 0 with value: 0.8274415087727414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8508, F1=0.8298, Recall=0.9105, Precision=0.7623\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102173740.csv.\n",
      "Average F1 over 5 seeds: 0.8274  0.0057\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8952800923037607, K=34, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.40674542189187124, margin=0.7714836601982721, lpl_weight=0.9608682616897146\n",
      " - ratio=0.42813270752793064, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3327, LPL: 1.3863, Contrastive: 0.0171\n",
      "Epoch 50, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0136\n",
      "Epoch 100, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0137\n",
      " - Metrics: Accuracy=0.7789, F1=0.7625, Recall=0.8886, Precision=0.6677\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8952800923037607, K=34, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.40674542189187124, margin=0.7714836601982721, lpl_weight=0.9608682616897146\n",
      " - ratio=0.42813270752793064, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3327, LPL: 1.3863, Contrastive: 0.0171\n",
      "Epoch 50, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0136\n",
      "Epoch 100, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0135\n",
      " - Metrics: Accuracy=0.8041, F1=0.7912, Recall=0.9294, Precision=0.6888\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8952800923037607, K=34, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.40674542189187124, margin=0.7714836601982721, lpl_weight=0.9608682616897146\n",
      " - ratio=0.42813270752793064, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3327, LPL: 1.3863, Contrastive: 0.0171\n",
      "Epoch 50, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0136\n",
      "Epoch 100, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0135\n",
      " - Metrics: Accuracy=0.8020, F1=0.7890, Recall=0.9269, Precision=0.6869\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8952800923037607, K=34, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.40674542189187124, margin=0.7714836601982721, lpl_weight=0.9608682616897146\n",
      " - ratio=0.42813270752793064, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3327, LPL: 1.3863, Contrastive: 0.0171\n",
      "Epoch 50, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0136\n",
      "Epoch 100, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0134\n",
      "Epoch 150, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0145\n",
      " - Metrics: Accuracy=0.7978, F1=0.7842, Recall=0.9197, Precision=0.6835\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8952800923037607, K=34, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.40674542189187124, margin=0.7714836601982721, lpl_weight=0.9608682616897146\n",
      " - ratio=0.42813270752793064, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3327, LPL: 1.3863, Contrastive: 0.0171\n",
      "Epoch 50, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0136\n",
      "Epoch 100, Loss: 1.3326, LPL: 1.3863, Contrastive: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:43:05,208] Trial 1 finished with value: 0.7832610605194236 and parameters: {'alpha': 0.8952800923037607, 'K': 34, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.40674542189187124, 'margin': 0.7714836601982721, 'lpl_weight': 0.9608682616897146, 'ratio': 0.42813270752793064, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.8274415087727414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8025, F1=0.7893, Recall=0.9266, Precision=0.6875\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102174027.csv.\n",
      "Average F1 over 5 seeds: 0.7833  0.0106\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.19954502423179923, K=27, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.40531402409446426, margin=0.7030668093507084, lpl_weight=0.19627010065388384\n",
      " - ratio=0.1464256440035655, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2915, LPL: 1.3863, Contrastive: 0.0241\n",
      "Epoch 50, Loss: 0.2905, LPL: 1.3863, Contrastive: 0.0229\n",
      "Epoch 100, Loss: 0.2942, LPL: 1.3863, Contrastive: 0.0275\n",
      " - Metrics: Accuracy=0.8471, F1=0.7938, Recall=0.7368, Precision=0.8604\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.19954502423179923, K=27, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.40531402409446426, margin=0.7030668093507084, lpl_weight=0.19627010065388384\n",
      " - ratio=0.1464256440035655, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2915, LPL: 1.3863, Contrastive: 0.0241\n",
      "Epoch 50, Loss: 0.2905, LPL: 1.3863, Contrastive: 0.0229\n",
      "Epoch 100, Loss: 0.3053, LPL: 1.3863, Contrastive: 0.0413\n",
      " - Metrics: Accuracy=0.8483, F1=0.7949, Recall=0.7360, Precision=0.8640\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.19954502423179923, K=27, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.40531402409446426, margin=0.7030668093507084, lpl_weight=0.19627010065388384\n",
      " - ratio=0.1464256440035655, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2915, LPL: 1.3863, Contrastive: 0.0241\n",
      "Epoch 50, Loss: 0.2905, LPL: 1.3863, Contrastive: 0.0229\n",
      " - Metrics: Accuracy=0.8557, F1=0.8046, Recall=0.7441, Precision=0.8758\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.19954502423179923, K=27, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.40531402409446426, margin=0.7030668093507084, lpl_weight=0.19627010065388384\n",
      " - ratio=0.1464256440035655, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2915, LPL: 1.3863, Contrastive: 0.0241\n",
      "Epoch 50, Loss: 0.2905, LPL: 1.3863, Contrastive: 0.0229\n",
      "Epoch 100, Loss: 0.3045, LPL: 1.3863, Contrastive: 0.0403\n",
      " - Metrics: Accuracy=0.8434, F1=0.7893, Recall=0.7343, Precision=0.8532\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.19954502423179923, K=27, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.40531402409446426, margin=0.7030668093507084, lpl_weight=0.19627010065388384\n",
      " - ratio=0.1464256440035655, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2915, LPL: 1.3863, Contrastive: 0.0241\n",
      "Epoch 50, Loss: 0.2905, LPL: 1.3863, Contrastive: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:46:12,276] Trial 2 finished with value: 0.7985129000285547 and parameters: {'alpha': 0.19954502423179923, 'K': 27, 'layers': 3, 'hidden_channels': 256, 'out_channels': 64, 'norm': None, 'dropout': 0.40531402409446426, 'margin': 0.7030668093507084, 'lpl_weight': 0.19627010065388384, 'ratio': 0.1464256440035655, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 0 with value: 0.8274415087727414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8588, F1=0.8099, Recall=0.7534, Precision=0.8756\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102174305.csv.\n",
      "Average F1 over 5 seeds: 0.7985  0.0076\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7574600593518743, K=30, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.14432450149467857, margin=0.7817051441171219, lpl_weight=0.2437438616272556\n",
      " - ratio=0.3883359024527966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4027, LPL: 1.3863, Contrastive: 0.0857\n",
      " - Metrics: Accuracy=0.8558, F1=0.8322, Recall=0.8950, Precision=0.7776\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7574600593518743, K=30, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.14432450149467857, margin=0.7817051441171219, lpl_weight=0.2437438616272556\n",
      " - ratio=0.3883359024527966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4027, LPL: 1.3863, Contrastive: 0.0857\n",
      " - Metrics: Accuracy=0.8490, F1=0.8253, Recall=0.8932, Precision=0.7671\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7574600593518743, K=30, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.14432450149467857, margin=0.7817051441171219, lpl_weight=0.2437438616272556\n",
      " - ratio=0.3883359024527966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4027, LPL: 1.3863, Contrastive: 0.0857\n",
      " - Metrics: Accuracy=0.8515, F1=0.8276, Recall=0.8924, Precision=0.7715\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7574600593518743, K=30, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.14432450149467857, margin=0.7817051441171219, lpl_weight=0.2437438616272556\n",
      " - ratio=0.3883359024527966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4027, LPL: 1.3863, Contrastive: 0.0857\n",
      " - Metrics: Accuracy=0.8530, F1=0.8286, Recall=0.8894, Precision=0.7756\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7574600593518743, K=30, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.14432450149467857, margin=0.7817051441171219, lpl_weight=0.2437438616272556\n",
      " - ratio=0.3883359024527966, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4027, LPL: 1.3863, Contrastive: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:48:06,609] Trial 3 finished with value: 0.8289529277984874 and parameters: {'alpha': 0.7574600593518743, 'K': 30, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': None, 'dropout': 0.14432450149467857, 'margin': 0.7817051441171219, 'lpl_weight': 0.2437438616272556, 'ratio': 0.3883359024527966, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 3 with value: 0.8289529277984874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8553, F1=0.8311, Recall=0.8912, Precision=0.7786\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102174612.csv.\n",
      "Average F1 over 5 seeds: 0.8290  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9366386632061651, K=25, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.1477349024392278, margin=0.22547654747484694, lpl_weight=0.35381112013633886\n",
      " - ratio=0.10459766744839896, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.2917\n",
      "Epoch 50, Loss: 0.5922, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.5923, LPL: 1.3863, Contrastive: 0.1575\n",
      " - Metrics: Accuracy=0.8764, F1=0.8223, Recall=0.7161, Precision=0.9654\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9366386632061651, K=25, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.1477349024392278, margin=0.22547654747484694, lpl_weight=0.35381112013633886\n",
      " - ratio=0.10459766744839896, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.2917\n",
      "Epoch 50, Loss: 0.5922, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.5902, LPL: 1.3863, Contrastive: 0.1542\n",
      "Epoch 150, Loss: 0.5896, LPL: 1.3863, Contrastive: 0.1533\n",
      " - Metrics: Accuracy=0.8760, F1=0.8222, Recall=0.7177, Precision=0.9624\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9366386632061651, K=25, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.1477349024392278, margin=0.22547654747484694, lpl_weight=0.35381112013633886\n",
      " - ratio=0.10459766744839896, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.2917\n",
      "Epoch 50, Loss: 0.5922, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.5906, LPL: 1.3863, Contrastive: 0.1550\n",
      "Epoch 150, Loss: 0.5899, LPL: 1.3863, Contrastive: 0.1538\n",
      "Epoch 200, Loss: 0.5891, LPL: 1.3863, Contrastive: 0.1526\n",
      "Epoch 250, Loss: 0.5889, LPL: 1.3863, Contrastive: 0.1523\n",
      "Epoch 300, Loss: 0.5888, LPL: 1.3863, Contrastive: 0.1521\n",
      "Epoch 350, Loss: 0.5887, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 400, Loss: 0.5886, LPL: 1.3863, Contrastive: 0.1519\n",
      " - Metrics: Accuracy=0.8714, F1=0.8128, Recall=0.6988, Precision=0.9712\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9366386632061651, K=25, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.1477349024392278, margin=0.22547654747484694, lpl_weight=0.35381112013633886\n",
      " - ratio=0.10459766744839896, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.2917\n",
      "Epoch 50, Loss: 0.5922, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.5908, LPL: 1.3863, Contrastive: 0.1552\n",
      " - Metrics: Accuracy=0.8730, F1=0.8161, Recall=0.7059, Precision=0.9671\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9366386632061651, K=25, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.1477349024392278, margin=0.22547654747484694, lpl_weight=0.35381112013633886\n",
      " - ratio=0.10459766744839896, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6789, LPL: 1.3863, Contrastive: 0.2917\n",
      "Epoch 50, Loss: 0.5922, LPL: 1.3863, Contrastive: 0.1574\n",
      "Epoch 100, Loss: 0.5923, LPL: 1.3863, Contrastive: 0.1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:51:46,164] Trial 4 finished with value: 0.8187380066671782 and parameters: {'alpha': 0.9366386632061651, 'K': 25, 'layers': 1, 'hidden_channels': 64, 'out_channels': 256, 'norm': None, 'dropout': 0.1477349024392278, 'margin': 0.22547654747484694, 'lpl_weight': 0.35381112013633886, 'ratio': 0.10459766744839896, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 3 with value: 0.8289529277984874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8752, F1=0.8203, Recall=0.7133, Precision=0.9651\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102174806.csv.\n",
      "Average F1 over 5 seeds: 0.8187  0.0037\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.87559731479295, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4570971180926924, margin=0.3496937042002922, lpl_weight=0.2169550690726315\n",
      " - ratio=0.14208033049705834, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4092, LPL: 1.3863, Contrastive: 0.1385\n",
      "Epoch 50, Loss: 0.3873, LPL: 1.3863, Contrastive: 0.1106\n",
      "Epoch 100, Loss: 0.3860, LPL: 1.3863, Contrastive: 0.1088\n",
      " - Metrics: Accuracy=0.8919, F1=0.8515, Recall=0.7764, Precision=0.9428\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.87559731479295, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4570971180926924, margin=0.3496937042002922, lpl_weight=0.2169550690726315\n",
      " - ratio=0.14208033049705834, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4092, LPL: 1.3863, Contrastive: 0.1385\n",
      "Epoch 50, Loss: 0.3873, LPL: 1.3863, Contrastive: 0.1105\n",
      "Epoch 100, Loss: 0.3858, LPL: 1.3863, Contrastive: 0.1086\n",
      " - Metrics: Accuracy=0.8920, F1=0.8539, Recall=0.7901, Precision=0.9289\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.87559731479295, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4570971180926924, margin=0.3496937042002922, lpl_weight=0.2169550690726315\n",
      " - ratio=0.14208033049705834, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4092, LPL: 1.3863, Contrastive: 0.1385\n",
      "Epoch 50, Loss: 0.3873, LPL: 1.3863, Contrastive: 0.1106\n",
      "Epoch 100, Loss: 0.3863, LPL: 1.3863, Contrastive: 0.1092\n",
      " - Metrics: Accuracy=0.8968, F1=0.8585, Recall=0.7840, Precision=0.9487\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.87559731479295, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4570971180926924, margin=0.3496937042002922, lpl_weight=0.2169550690726315\n",
      " - ratio=0.14208033049705834, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4092, LPL: 1.3863, Contrastive: 0.1385\n",
      "Epoch 50, Loss: 0.3873, LPL: 1.3863, Contrastive: 0.1105\n",
      "Epoch 100, Loss: 0.3878, LPL: 1.3863, Contrastive: 0.1112\n",
      " - Metrics: Accuracy=0.8926, F1=0.8526, Recall=0.7773, Precision=0.9440\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.87559731479295, K=33, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.4570971180926924, margin=0.3496937042002922, lpl_weight=0.2169550690726315\n",
      " - ratio=0.14208033049705834, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4092, LPL: 1.3863, Contrastive: 0.1385\n",
      "Epoch 50, Loss: 0.3873, LPL: 1.3863, Contrastive: 0.1106\n",
      "Epoch 100, Loss: 0.3862, LPL: 1.3863, Contrastive: 0.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:54:21,302] Trial 5 finished with value: 0.8552826854227338 and parameters: {'alpha': 0.87559731479295, 'K': 33, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.4570971180926924, 'margin': 0.3496937042002922, 'lpl_weight': 0.2169550690726315, 'ratio': 0.14208033049705834, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 5 with value: 0.8552826854227338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8945, F1=0.8599, Recall=0.8109, Precision=0.9152\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102175146.csv.\n",
      "Average F1 over 5 seeds: 0.8553  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5007282640922686, K=27, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.12769963557769654, margin=0.9687488607436933, lpl_weight=0.8337655344005355\n",
      " - ratio=0.15679776258100758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1698, LPL: 1.3863, Contrastive: 0.0837\n",
      " - Metrics: Accuracy=0.8808, F1=0.8389, Recall=0.7770, Precision=0.9114\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5007282640922686, K=27, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.12769963557769654, margin=0.9687488607436933, lpl_weight=0.8337655344005355\n",
      " - ratio=0.15679776258100758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1698, LPL: 1.3863, Contrastive: 0.0837\n",
      " - Metrics: Accuracy=0.8791, F1=0.8373, Recall=0.7790, Precision=0.9050\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5007282640922686, K=27, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.12769963557769654, margin=0.9687488607436933, lpl_weight=0.8337655344005355\n",
      " - ratio=0.15679776258100758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1698, LPL: 1.3863, Contrastive: 0.0837\n",
      " - Metrics: Accuracy=0.8836, F1=0.8431, Recall=0.7827, Precision=0.9135\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5007282640922686, K=27, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.12769963557769654, margin=0.9687488607436933, lpl_weight=0.8337655344005355\n",
      " - ratio=0.15679776258100758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1698, LPL: 1.3863, Contrastive: 0.0837\n",
      " - Metrics: Accuracy=0.8811, F1=0.8397, Recall=0.7797, Precision=0.9098\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5007282640922686, K=27, layers=1, hidden=256, out=64\n",
      " - norm=None, dropout=0.12769963557769654, margin=0.9687488607436933, lpl_weight=0.8337655344005355\n",
      " - ratio=0.15679776258100758, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.1698, LPL: 1.3863, Contrastive: 0.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:56:20,669] Trial 6 finished with value: 0.8401581357574809 and parameters: {'alpha': 0.5007282640922686, 'K': 27, 'layers': 1, 'hidden_channels': 256, 'out_channels': 64, 'norm': None, 'dropout': 0.12769963557769654, 'margin': 0.9687488607436933, 'lpl_weight': 0.8337655344005355, 'ratio': 0.15679776258100758, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 5 with value: 0.8552826854227338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8822, F1=0.8419, Recall=0.7851, Precision=0.9074\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102175421.csv.\n",
      "Average F1 over 5 seeds: 0.8402  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6558743890697725, K=26, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.49493346266201865, margin=0.7879506711940136, lpl_weight=0.571966214093025\n",
      " - ratio=0.4701792443679851, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7992, LPL: 1.3863, Contrastive: 0.0147\n",
      "Epoch 50, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0117\n",
      "Epoch 100, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 150, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 200, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0116\n",
      " - Metrics: Accuracy=0.7165, F1=0.7009, Recall=0.8319, Precision=0.6056\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6558743890697725, K=26, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.49493346266201865, margin=0.7879506711940136, lpl_weight=0.571966214093025\n",
      " - ratio=0.4701792443679851, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7992, LPL: 1.3863, Contrastive: 0.0147\n",
      "Epoch 50, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0117\n",
      "Epoch 100, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 150, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 200, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0116\n",
      " - Metrics: Accuracy=0.7126, F1=0.6973, Recall=0.8286, Precision=0.6019\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6558743890697725, K=26, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.49493346266201865, margin=0.7879506711940136, lpl_weight=0.571966214093025\n",
      " - ratio=0.4701792443679851, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7992, LPL: 1.3863, Contrastive: 0.0147\n",
      "Epoch 50, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0117\n",
      "Epoch 100, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 150, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 200, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0116\n",
      " - Metrics: Accuracy=0.7152, F1=0.6994, Recall=0.8296, Precision=0.6045\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6558743890697725, K=26, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.49493346266201865, margin=0.7879506711940136, lpl_weight=0.571966214093025\n",
      " - ratio=0.4701792443679851, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7992, LPL: 1.3863, Contrastive: 0.0147\n",
      "Epoch 50, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0117\n",
      "Epoch 100, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 150, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 200, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0116\n",
      " - Metrics: Accuracy=0.7107, F1=0.6945, Recall=0.8234, Precision=0.6005\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6558743890697725, K=26, layers=3, hidden=128, out=64\n",
      " - norm=None, dropout=0.49493346266201865, margin=0.7879506711940136, lpl_weight=0.571966214093025\n",
      " - ratio=0.4701792443679851, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7992, LPL: 1.3863, Contrastive: 0.0147\n",
      "Epoch 50, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0117\n",
      "Epoch 100, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 150, Loss: 0.7978, LPL: 1.3863, Contrastive: 0.0115\n",
      "Epoch 200, Loss: 0.7979, LPL: 1.3863, Contrastive: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:59:38,501] Trial 7 finished with value: 0.6971071667633806 and parameters: {'alpha': 0.6558743890697725, 'K': 26, 'layers': 3, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.49493346266201865, 'margin': 0.7879506711940136, 'lpl_weight': 0.571966214093025, 'ratio': 0.4701792443679851, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 5 with value: 0.8552826854227338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7087, F1=0.6935, Recall=0.8249, Precision=0.5982\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102175620.csv.\n",
      "Average F1 over 5 seeds: 0.6971  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.42958266916370313, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.23893848245637336, margin=0.21675166614099806, lpl_weight=0.6405215402940378\n",
      " - ratio=0.1363737339532742, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9830, LPL: 1.3863, Contrastive: 0.2645\n",
      "Epoch 50, Loss: 0.9443, LPL: 1.3863, Contrastive: 0.1568\n",
      " - Metrics: Accuracy=0.8936, F1=0.8554, Recall=0.7878, Precision=0.9356\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.42958266916370313, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.23893848245637336, margin=0.21675166614099806, lpl_weight=0.6405215402940378\n",
      " - ratio=0.1363737339532742, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9830, LPL: 1.3863, Contrastive: 0.2645\n",
      "Epoch 50, Loss: 0.9443, LPL: 1.3863, Contrastive: 0.1568\n",
      " - Metrics: Accuracy=0.8781, F1=0.8334, Recall=0.7637, Precision=0.9172\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.42958266916370313, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.23893848245637336, margin=0.21675166614099806, lpl_weight=0.6405215402940378\n",
      " - ratio=0.1363737339532742, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9830, LPL: 1.3863, Contrastive: 0.2645\n",
      "Epoch 50, Loss: 0.9443, LPL: 1.3863, Contrastive: 0.1568\n",
      " - Metrics: Accuracy=0.8895, F1=0.8449, Recall=0.7534, Precision=0.9617\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.42958266916370313, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.23893848245637336, margin=0.21675166614099806, lpl_weight=0.6405215402940378\n",
      " - ratio=0.1363737339532742, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9830, LPL: 1.3863, Contrastive: 0.2645\n",
      "Epoch 50, Loss: 0.9443, LPL: 1.3863, Contrastive: 0.1568\n",
      " - Metrics: Accuracy=0.8922, F1=0.8527, Recall=0.7813, Precision=0.9385\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.42958266916370313, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.23893848245637336, margin=0.21675166614099806, lpl_weight=0.6405215402940378\n",
      " - ratio=0.1363737339532742, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9830, LPL: 1.3863, Contrastive: 0.2645\n",
      "Epoch 50, Loss: 0.9443, LPL: 1.3863, Contrastive: 0.1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:03:18,104] Trial 8 finished with value: 0.8475700945412241 and parameters: {'alpha': 0.42958266916370313, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.23893848245637336, 'margin': 0.21675166614099806, 'lpl_weight': 0.6405215402940378, 'ratio': 0.1363737339532742, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 5 with value: 0.8552826854227338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8922, F1=0.8514, Recall=0.7733, Precision=0.9470\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102175938.csv.\n",
      "Average F1 over 5 seeds: 0.8476  0.0079\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4560963794804682, K=25, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.44685626645719156, margin=0.6645098616770617, lpl_weight=0.5858880736478316\n",
      " - ratio=0.19519496865172792, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8681, LPL: 1.3863, Contrastive: 0.1349\n",
      " - Metrics: Accuracy=0.8791, F1=0.8432, Recall=0.8137, Precision=0.8749\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4560963794804682, K=25, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.44685626645719156, margin=0.6645098616770617, lpl_weight=0.5858880736478316\n",
      " - ratio=0.19519496865172792, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8681, LPL: 1.3863, Contrastive: 0.1349\n",
      " - Metrics: Accuracy=0.8760, F1=0.8387, Recall=0.8071, Precision=0.8730\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4560963794804682, K=25, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.44685626645719156, margin=0.6645098616770617, lpl_weight=0.5858880736478316\n",
      " - ratio=0.19519496865172792, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8681, LPL: 1.3863, Contrastive: 0.1349\n",
      " - Metrics: Accuracy=0.8823, F1=0.8466, Recall=0.8128, Precision=0.8833\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4560963794804682, K=25, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.44685626645719156, margin=0.6645098616770617, lpl_weight=0.5858880736478316\n",
      " - ratio=0.19519496865172792, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8681, LPL: 1.3863, Contrastive: 0.1349\n",
      " - Metrics: Accuracy=0.8815, F1=0.8454, Recall=0.8113, Precision=0.8825\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4560963794804682, K=25, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.44685626645719156, margin=0.6645098616770617, lpl_weight=0.5858880736478316\n",
      " - ratio=0.19519496865172792, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8681, LPL: 1.3863, Contrastive: 0.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:05:10,733] Trial 9 finished with value: 0.8425957976216472 and parameters: {'alpha': 0.4560963794804682, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.44685626645719156, 'margin': 0.6645098616770617, 'lpl_weight': 0.5858880736478316, 'ratio': 0.19519496865172792, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 5 with value: 0.8552826854227338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8766, F1=0.8391, Recall=0.8053, Precision=0.8757\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102180318.csv.\n",
      "Average F1 over 5 seeds: 0.8426  0.0032\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1798466142798537, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32517724002924336, margin=0.3767986050139098, lpl_weight=0.11446735460434086\n",
      " - ratio=0.26671006894317684, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2723, LPL: 1.3863, Contrastive: 0.1283\n",
      "Epoch 50, Loss: 0.2479, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 0.2553, LPL: 1.3863, Contrastive: 0.1091\n",
      " - Metrics: Accuracy=0.8861, F1=0.8600, Recall=0.8762, Precision=0.8444\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1798466142798537, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32517724002924336, margin=0.3767986050139098, lpl_weight=0.11446735460434086\n",
      " - ratio=0.26671006894317684, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2723, LPL: 1.3863, Contrastive: 0.1283\n",
      "Epoch 50, Loss: 0.2479, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 0.2634, LPL: 1.3863, Contrastive: 0.1182\n",
      " - Metrics: Accuracy=0.8855, F1=0.8594, Recall=0.8766, Precision=0.8430\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1798466142798537, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32517724002924336, margin=0.3767986050139098, lpl_weight=0.11446735460434086\n",
      " - ratio=0.26671006894317684, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2723, LPL: 1.3863, Contrastive: 0.1283\n",
      "Epoch 50, Loss: 0.2479, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 0.2479, LPL: 1.3863, Contrastive: 0.1007\n",
      " - Metrics: Accuracy=0.8922, F1=0.8675, Recall=0.8838, Precision=0.8518\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1798466142798537, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32517724002924336, margin=0.3767986050139098, lpl_weight=0.11446735460434086\n",
      " - ratio=0.26671006894317684, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2723, LPL: 1.3863, Contrastive: 0.1283\n",
      "Epoch 50, Loss: 0.2479, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 0.2495, LPL: 1.3863, Contrastive: 0.1025\n",
      " - Metrics: Accuracy=0.8909, F1=0.8659, Recall=0.8820, Precision=0.8503\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1798466142798537, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32517724002924336, margin=0.3767986050139098, lpl_weight=0.11446735460434086\n",
      " - ratio=0.26671006894317684, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2723, LPL: 1.3863, Contrastive: 0.1283\n",
      "Epoch 50, Loss: 0.2479, LPL: 1.3863, Contrastive: 0.1008\n",
      "Epoch 100, Loss: 0.2474, LPL: 1.3863, Contrastive: 0.1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:07:55,445] Trial 10 finished with value: 0.8641283123900146 and parameters: {'alpha': 0.1798466142798537, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.32517724002924336, 'margin': 0.3767986050139098, 'lpl_weight': 0.11446735460434086, 'ratio': 0.26671006894317684, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 10 with value: 0.8641283123900146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8925, F1=0.8678, Recall=0.8832, Precision=0.8530\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102180510.csv.\n",
      "Average F1 over 5 seeds: 0.8641  0.0037\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.17246309762498208, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3211494978820338, margin=0.4054071304376709, lpl_weight=0.10949887051053304\n",
      " - ratio=0.2615399744325343, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2611, LPL: 1.3863, Contrastive: 0.1227\n",
      "Epoch 50, Loss: 0.2340, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.2324, LPL: 1.3863, Contrastive: 0.0905\n",
      "Epoch 150, Loss: 0.2323, LPL: 1.3863, Contrastive: 0.0904\n",
      " - Metrics: Accuracy=0.8932, F1=0.8681, Recall=0.8797, Precision=0.8567\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.17246309762498208, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3211494978820338, margin=0.4054071304376709, lpl_weight=0.10949887051053304\n",
      " - ratio=0.2615399744325343, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2611, LPL: 1.3863, Contrastive: 0.1227\n",
      "Epoch 50, Loss: 0.2340, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.2327, LPL: 1.3863, Contrastive: 0.0909\n",
      " - Metrics: Accuracy=0.8926, F1=0.8673, Recall=0.8792, Precision=0.8558\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.17246309762498208, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3211494978820338, margin=0.4054071304376709, lpl_weight=0.10949887051053304\n",
      " - ratio=0.2615399744325343, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2611, LPL: 1.3863, Contrastive: 0.1227\n",
      "Epoch 50, Loss: 0.2340, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.2325, LPL: 1.3863, Contrastive: 0.0906\n",
      " - Metrics: Accuracy=0.8949, F1=0.8701, Recall=0.8815, Precision=0.8591\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.17246309762498208, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3211494978820338, margin=0.4054071304376709, lpl_weight=0.10949887051053304\n",
      " - ratio=0.2615399744325343, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2611, LPL: 1.3863, Contrastive: 0.1227\n",
      "Epoch 50, Loss: 0.2340, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.2330, LPL: 1.3863, Contrastive: 0.0912\n",
      " - Metrics: Accuracy=0.8909, F1=0.8652, Recall=0.8767, Precision=0.8539\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.17246309762498208, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3211494978820338, margin=0.4054071304376709, lpl_weight=0.10949887051053304\n",
      " - ratio=0.2615399744325343, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2611, LPL: 1.3863, Contrastive: 0.1227\n",
      "Epoch 50, Loss: 0.2340, LPL: 1.3863, Contrastive: 0.0923\n",
      "Epoch 100, Loss: 0.2324, LPL: 1.3863, Contrastive: 0.0905\n",
      "Epoch 150, Loss: 0.2323, LPL: 1.3863, Contrastive: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:10:51,711] Trial 11 finished with value: 0.8673441917812577 and parameters: {'alpha': 0.17246309762498208, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3211494978820338, 'margin': 0.4054071304376709, 'lpl_weight': 0.10949887051053304, 'ratio': 0.2615399744325343, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 11 with value: 0.8673441917812577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8916, F1=0.8660, Recall=0.8770, Precision=0.8553\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102180755.csv.\n",
      "Average F1 over 5 seeds: 0.8673  0.0017\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.11950927946688132, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3116236621723191, margin=0.3788192866731203, lpl_weight=0.10885689330934062\n",
      " - ratio=0.28507418132784657, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2641, LPL: 1.3863, Contrastive: 0.1270\n",
      "Epoch 50, Loss: 0.2403, LPL: 1.3863, Contrastive: 0.1003\n",
      "Epoch 100, Loss: 0.2524, LPL: 1.3863, Contrastive: 0.1138\n",
      " - Metrics: Accuracy=0.8817, F1=0.8572, Recall=0.8888, Precision=0.8278\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.11950927946688132, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3116236621723191, margin=0.3788192866731203, lpl_weight=0.10885689330934062\n",
      " - ratio=0.28507418132784657, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2641, LPL: 1.3863, Contrastive: 0.1270\n",
      "Epoch 50, Loss: 0.2403, LPL: 1.3863, Contrastive: 0.1003\n",
      "Epoch 100, Loss: 0.2397, LPL: 1.3863, Contrastive: 0.0996\n",
      " - Metrics: Accuracy=0.8832, F1=0.8590, Recall=0.8902, Precision=0.8299\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.11950927946688132, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3116236621723191, margin=0.3788192866731203, lpl_weight=0.10885689330934062\n",
      " - ratio=0.28507418132784657, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2641, LPL: 1.3863, Contrastive: 0.1270\n",
      "Epoch 50, Loss: 0.2403, LPL: 1.3863, Contrastive: 0.1003\n",
      "Epoch 100, Loss: 0.2524, LPL: 1.3863, Contrastive: 0.1138\n",
      " - Metrics: Accuracy=0.8837, F1=0.8596, Recall=0.8916, Precision=0.8298\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.11950927946688132, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3116236621723191, margin=0.3788192866731203, lpl_weight=0.10885689330934062\n",
      " - ratio=0.28507418132784657, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2641, LPL: 1.3863, Contrastive: 0.1270\n",
      "Epoch 50, Loss: 0.2403, LPL: 1.3863, Contrastive: 0.1003\n",
      "Epoch 100, Loss: 0.2394, LPL: 1.3863, Contrastive: 0.0993\n",
      " - Metrics: Accuracy=0.8846, F1=0.8605, Recall=0.8916, Precision=0.8316\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.11950927946688132, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3116236621723191, margin=0.3788192866731203, lpl_weight=0.10885689330934062\n",
      " - ratio=0.28507418132784657, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2641, LPL: 1.3863, Contrastive: 0.1270\n",
      "Epoch 50, Loss: 0.2403, LPL: 1.3863, Contrastive: 0.1003\n",
      "Epoch 100, Loss: 0.2397, LPL: 1.3863, Contrastive: 0.0996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:13:38,863] Trial 12 finished with value: 0.859485096010004 and parameters: {'alpha': 0.11950927946688132, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3116236621723191, 'margin': 0.3788192866731203, 'lpl_weight': 0.10885689330934062, 'ratio': 0.28507418132784657, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 11 with value: 0.8673441917812577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8851, F1=0.8612, Recall=0.8921, Precision=0.8323\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102181051.csv.\n",
      "Average F1 over 5 seeds: 0.8595  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2926111333185004, K=32, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.30399512951482127, margin=0.41558056084583733, lpl_weight=0.4077299750901358\n",
      " - ratio=0.2662015073568274, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0981\n",
      "Epoch 50, Loss: 0.6189, LPL: 1.3863, Contrastive: 0.0906\n",
      " - Metrics: Accuracy=0.8699, F1=0.8407, Recall=0.8596, Precision=0.8227\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2926111333185004, K=32, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.30399512951482127, margin=0.41558056084583733, lpl_weight=0.4077299750901358\n",
      " - ratio=0.2662015073568274, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0981\n",
      "Epoch 50, Loss: 0.6180, LPL: 1.3863, Contrastive: 0.0892\n",
      " - Metrics: Accuracy=0.8631, F1=0.8326, Recall=0.8522, Precision=0.8138\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2926111333185004, K=32, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.30399512951482127, margin=0.41558056084583733, lpl_weight=0.4077299750901358\n",
      " - ratio=0.2662015073568274, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0981\n",
      "Epoch 50, Loss: 0.6189, LPL: 1.3863, Contrastive: 0.0906\n",
      "Epoch 100, Loss: 0.6284, LPL: 1.3863, Contrastive: 0.1066\n",
      " - Metrics: Accuracy=0.8435, F1=0.8092, Recall=0.8305, Precision=0.7889\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2926111333185004, K=32, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.30399512951482127, margin=0.41558056084583733, lpl_weight=0.4077299750901358\n",
      " - ratio=0.2662015073568274, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0981\n",
      "Epoch 50, Loss: 0.6186, LPL: 1.3863, Contrastive: 0.0901\n",
      " - Metrics: Accuracy=0.8612, F1=0.8303, Recall=0.8497, Precision=0.8117\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2926111333185004, K=32, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.30399512951482127, margin=0.41558056084583733, lpl_weight=0.4077299750901358\n",
      " - ratio=0.2662015073568274, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6233, LPL: 1.3863, Contrastive: 0.0981\n",
      "Epoch 50, Loss: 0.6180, LPL: 1.3863, Contrastive: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:16:24,987] Trial 13 finished with value: 0.8280331518572247 and parameters: {'alpha': 0.2926111333185004, 'K': 32, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.30399512951482127, 'margin': 0.41558056084583733, 'lpl_weight': 0.4077299750901358, 'ratio': 0.2662015073568274, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 11 with value: 0.8673441917812577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8585, F1=0.8275, Recall=0.8493, Precision=0.8068\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102181338.csv.\n",
      "Average F1 over 5 seeds: 0.8280  0.0104\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.304561806554624, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.25489107065691036, margin=0.47323658013393094, lpl_weight=0.12395024199466864\n",
      " - ratio=0.3508920785968854, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2729, LPL: 1.3863, Contrastive: 0.1154\n",
      "Epoch 50, Loss: 0.2367, LPL: 1.3863, Contrastive: 0.0740\n",
      "Epoch 100, Loss: 0.2349, LPL: 1.3863, Contrastive: 0.0720\n",
      " - Metrics: Accuracy=0.8613, F1=0.8423, Recall=0.9275, Precision=0.7715\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.304561806554624, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.25489107065691036, margin=0.47323658013393094, lpl_weight=0.12395024199466864\n",
      " - ratio=0.3508920785968854, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2729, LPL: 1.3863, Contrastive: 0.1154\n",
      "Epoch 50, Loss: 0.2367, LPL: 1.3863, Contrastive: 0.0740\n",
      "Epoch 100, Loss: 0.2349, LPL: 1.3863, Contrastive: 0.0720\n",
      "Epoch 150, Loss: 0.2343, LPL: 1.3863, Contrastive: 0.0713\n",
      "Epoch 200, Loss: 0.2340, LPL: 1.3863, Contrastive: 0.0709\n",
      "Epoch 250, Loss: 0.2338, LPL: 1.3863, Contrastive: 0.0707\n",
      "Epoch 300, Loss: 0.2336, LPL: 1.3863, Contrastive: 0.0706\n",
      "Epoch 350, Loss: 0.2336, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 400, Loss: 0.2336, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 450, Loss: 0.2336, LPL: 1.3863, Contrastive: 0.0705\n",
      " - Metrics: Accuracy=0.8569, F1=0.8373, Recall=0.9222, Precision=0.7668\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.304561806554624, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.25489107065691036, margin=0.47323658013393094, lpl_weight=0.12395024199466864\n",
      " - ratio=0.3508920785968854, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2729, LPL: 1.3863, Contrastive: 0.1154\n",
      "Epoch 50, Loss: 0.2367, LPL: 1.3863, Contrastive: 0.0740\n",
      "Epoch 100, Loss: 0.2349, LPL: 1.3863, Contrastive: 0.0720\n",
      "Epoch 150, Loss: 0.2342, LPL: 1.3863, Contrastive: 0.0712\n",
      "Epoch 200, Loss: 0.2339, LPL: 1.3863, Contrastive: 0.0709\n",
      "Epoch 250, Loss: 0.2337, LPL: 1.3863, Contrastive: 0.0706\n",
      "Epoch 300, Loss: 0.2336, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 350, Loss: 0.2336, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 400, Loss: 0.2335, LPL: 1.3863, Contrastive: 0.0705\n",
      "Epoch 450, Loss: 0.2335, LPL: 1.3863, Contrastive: 0.0704\n",
      " - Metrics: Accuracy=0.8617, F1=0.8428, Recall=0.9280, Precision=0.7719\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.304561806554624, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.25489107065691036, margin=0.47323658013393094, lpl_weight=0.12395024199466864\n",
      " - ratio=0.3508920785968854, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2729, LPL: 1.3863, Contrastive: 0.1153\n",
      "Epoch 50, Loss: 0.2367, LPL: 1.3863, Contrastive: 0.0740\n",
      "Epoch 100, Loss: 0.2349, LPL: 1.3863, Contrastive: 0.0720\n",
      "Epoch 150, Loss: 0.2342, LPL: 1.3863, Contrastive: 0.0712\n",
      " - Metrics: Accuracy=0.8586, F1=0.8393, Recall=0.9243, Precision=0.7686\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.304561806554624, K=32, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.25489107065691036, margin=0.47323658013393094, lpl_weight=0.12395024199466864\n",
      " - ratio=0.3508920785968854, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.2729, LPL: 1.3863, Contrastive: 0.1154\n",
      "Epoch 50, Loss: 0.2367, LPL: 1.3863, Contrastive: 0.0740\n",
      "Epoch 100, Loss: 0.2349, LPL: 1.3863, Contrastive: 0.0720\n",
      "Epoch 150, Loss: 0.2342, LPL: 1.3863, Contrastive: 0.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:19:56,194] Trial 14 finished with value: 0.8403756653999193 and parameters: {'alpha': 0.304561806554624, 'K': 32, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.25489107065691036, 'margin': 0.47323658013393094, 'lpl_weight': 0.12395024199466864, 'ratio': 0.3508920785968854, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 11 with value: 0.8673441917812577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8594, F1=0.8401, Recall=0.9250, Precision=0.7696\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102181625.csv.\n",
      "Average F1 over 5 seeds: 0.8404  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10554564344335746, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3547205417835157, margin=0.13886971130331593, lpl_weight=0.4311663688778529\n",
      " - ratio=0.23287798991068293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7131, LPL: 1.3863, Contrastive: 0.2029\n",
      "Epoch 50, Loss: 0.7058, LPL: 1.3863, Contrastive: 0.1899\n",
      " - Metrics: Accuracy=0.8991, F1=0.8722, Recall=0.8625, Precision=0.8822\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10554564344335746, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3547205417835157, margin=0.13886971130331593, lpl_weight=0.4311663688778529\n",
      " - ratio=0.23287798991068293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7131, LPL: 1.3863, Contrastive: 0.2029\n",
      "Epoch 50, Loss: 0.7058, LPL: 1.3863, Contrastive: 0.1899\n",
      " - Metrics: Accuracy=0.8959, F1=0.8682, Recall=0.8584, Precision=0.8782\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10554564344335746, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3547205417835157, margin=0.13886971130331593, lpl_weight=0.4311663688778529\n",
      " - ratio=0.23287798991068293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7131, LPL: 1.3863, Contrastive: 0.2029\n",
      "Epoch 50, Loss: 0.7058, LPL: 1.3863, Contrastive: 0.1899\n",
      " - Metrics: Accuracy=0.8960, F1=0.8685, Recall=0.8601, Precision=0.8771\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10554564344335746, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3547205417835157, margin=0.13886971130331593, lpl_weight=0.4311663688778529\n",
      " - ratio=0.23287798991068293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7131, LPL: 1.3863, Contrastive: 0.2029\n",
      "Epoch 50, Loss: 0.7058, LPL: 1.3863, Contrastive: 0.1899\n",
      " - Metrics: Accuracy=0.8936, F1=0.8652, Recall=0.8543, Precision=0.8763\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10554564344335746, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3547205417835157, margin=0.13886971130331593, lpl_weight=0.4311663688778529\n",
      " - ratio=0.23287798991068293, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7131, LPL: 1.3863, Contrastive: 0.2029\n",
      "Epoch 50, Loss: 0.7058, LPL: 1.3863, Contrastive: 0.1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:22:29,570] Trial 15 finished with value: 0.8680551662620349 and parameters: {'alpha': 0.10554564344335746, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3547205417835157, 'margin': 0.13886971130331593, 'lpl_weight': 0.4311663688778529, 'ratio': 0.23287798991068293, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8680551662620349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8944, F1=0.8662, Recall=0.8559, Precision=0.8768\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102181956.csv.\n",
      "Average F1 over 5 seeds: 0.8681  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3422769484868912, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3683745725874933, margin=0.10045671883568541, lpl_weight=0.7304251683242684\n",
      " - ratio=0.2312042128044065, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0718, LPL: 1.3863, Contrastive: 0.2197\n",
      "Epoch 50, Loss: 1.0685, LPL: 1.3863, Contrastive: 0.2073\n",
      " - Metrics: Accuracy=0.8944, F1=0.8659, Recall=0.8535, Precision=0.8787\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3422769484868912, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3683745725874933, margin=0.10045671883568541, lpl_weight=0.7304251683242684\n",
      " - ratio=0.2312042128044065, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0718, LPL: 1.3863, Contrastive: 0.2197\n",
      "Epoch 50, Loss: 1.0685, LPL: 1.3863, Contrastive: 0.2072\n",
      " - Metrics: Accuracy=0.8895, F1=0.8595, Recall=0.8462, Precision=0.8733\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3422769484868912, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3683745725874933, margin=0.10045671883568541, lpl_weight=0.7304251683242684\n",
      " - ratio=0.2312042128044065, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0718, LPL: 1.3863, Contrastive: 0.2197\n",
      "Epoch 50, Loss: 1.0685, LPL: 1.3863, Contrastive: 0.2072\n",
      " - Metrics: Accuracy=0.8958, F1=0.8676, Recall=0.8543, Precision=0.8812\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3422769484868912, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3683745725874933, margin=0.10045671883568541, lpl_weight=0.7304251683242684\n",
      " - ratio=0.2312042128044065, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0718, LPL: 1.3863, Contrastive: 0.2197\n",
      "Epoch 50, Loss: 1.0685, LPL: 1.3863, Contrastive: 0.2073\n",
      " - Metrics: Accuracy=0.8955, F1=0.8672, Recall=0.8547, Precision=0.8801\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3422769484868912, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3683745725874933, margin=0.10045671883568541, lpl_weight=0.7304251683242684\n",
      " - ratio=0.2312042128044065, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0718, LPL: 1.3863, Contrastive: 0.2197\n",
      "Epoch 50, Loss: 1.0685, LPL: 1.3863, Contrastive: 0.2072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:25:05,765] Trial 16 finished with value: 0.864848914025895 and parameters: {'alpha': 0.3422769484868912, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3683745725874933, 'margin': 0.10045671883568541, 'lpl_weight': 0.7304251683242684, 'ratio': 0.2312042128044065, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8680551662620349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8929, F1=0.8640, Recall=0.8521, Precision=0.8763\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102182229.csv.\n",
      "Average F1 over 5 seeds: 0.8648  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5989480224006816, K=32, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.2293728939705018, margin=0.10477949385640212, lpl_weight=0.44416839783301654\n",
      " - ratio=0.34267401826376903, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.2296\n",
      "Epoch 50, Loss: 0.7305, LPL: 1.3863, Contrastive: 0.2065\n",
      " - Metrics: Accuracy=0.8470, F1=0.8243, Recall=0.8985, Precision=0.7614\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5989480224006816, K=32, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.2293728939705018, margin=0.10477949385640212, lpl_weight=0.44416839783301654\n",
      " - ratio=0.34267401826376903, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.2296\n",
      "Epoch 50, Loss: 0.7305, LPL: 1.3863, Contrastive: 0.2065\n",
      " - Metrics: Accuracy=0.8457, F1=0.8227, Recall=0.8963, Precision=0.7603\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5989480224006816, K=32, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.2293728939705018, margin=0.10477949385640212, lpl_weight=0.44416839783301654\n",
      " - ratio=0.34267401826376903, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.2296\n",
      "Epoch 50, Loss: 0.7305, LPL: 1.3863, Contrastive: 0.2065\n",
      " - Metrics: Accuracy=0.8287, F1=0.8029, Recall=0.8737, Precision=0.7428\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5989480224006816, K=32, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.2293728939705018, margin=0.10477949385640212, lpl_weight=0.44416839783301654\n",
      " - ratio=0.34267401826376903, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.2296\n",
      "Epoch 50, Loss: 0.7305, LPL: 1.3863, Contrastive: 0.2065\n",
      " - Metrics: Accuracy=0.8374, F1=0.8133, Recall=0.8870, Precision=0.7510\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5989480224006816, K=32, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.2293728939705018, margin=0.10477949385640212, lpl_weight=0.44416839783301654\n",
      " - ratio=0.34267401826376903, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7434, LPL: 1.3863, Contrastive: 0.2296\n",
      "Epoch 50, Loss: 0.7305, LPL: 1.3863, Contrastive: 0.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:27:48,542] Trial 17 finished with value: 0.8047900769909445 and parameters: {'alpha': 0.5989480224006816, 'K': 32, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.2293728939705018, 'margin': 0.10477949385640212, 'lpl_weight': 0.44416839783301654, 'ratio': 0.34267401826376903, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8680551662620349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7929, F1=0.7607, Recall=0.8240, Precision=0.7064\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102182505.csv.\n",
      "Average F1 over 5 seeds: 0.8048  0.0233\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10932159289139023, K=33, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3535748872523228, margin=0.24829582129675215, lpl_weight=0.293155651675563\n",
      " - ratio=0.20134944996985263, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5168, LPL: 1.3863, Contrastive: 0.1562\n",
      "Epoch 50, Loss: 0.5105, LPL: 1.3863, Contrastive: 0.1473\n",
      " - Metrics: Accuracy=0.8688, F1=0.8318, Recall=0.8118, Precision=0.8527\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10932159289139023, K=33, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3535748872523228, margin=0.24829582129675215, lpl_weight=0.293155651675563\n",
      " - ratio=0.20134944996985263, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5168, LPL: 1.3863, Contrastive: 0.1562\n",
      "Epoch 50, Loss: 0.5111, LPL: 1.3863, Contrastive: 0.1482\n",
      " - Metrics: Accuracy=0.8833, F1=0.8510, Recall=0.8344, Precision=0.8683\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10932159289139023, K=33, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3535748872523228, margin=0.24829582129675215, lpl_weight=0.293155651675563\n",
      " - ratio=0.20134944996985263, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5168, LPL: 1.3863, Contrastive: 0.1562\n",
      "Epoch 50, Loss: 0.5111, LPL: 1.3863, Contrastive: 0.1481\n",
      " - Metrics: Accuracy=0.8686, F1=0.8322, Recall=0.8156, Precision=0.8495\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10932159289139023, K=33, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3535748872523228, margin=0.24829582129675215, lpl_weight=0.293155651675563\n",
      " - ratio=0.20134944996985263, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5168, LPL: 1.3863, Contrastive: 0.1562\n",
      "Epoch 50, Loss: 0.5106, LPL: 1.3863, Contrastive: 0.1474\n",
      " - Metrics: Accuracy=0.8839, F1=0.8521, Recall=0.8376, Precision=0.8671\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10932159289139023, K=33, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3535748872523228, margin=0.24829582129675215, lpl_weight=0.293155651675563\n",
      " - ratio=0.20134944996985263, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5168, LPL: 1.3863, Contrastive: 0.1562\n",
      "Epoch 50, Loss: 0.5103, LPL: 1.3863, Contrastive: 0.1470\n",
      "Epoch 100, Loss: 0.5093, LPL: 1.3863, Contrastive: 0.1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:30:25,518] Trial 18 finished with value: 0.8436856919057005 and parameters: {'alpha': 0.10932159289139023, 'K': 33, 'layers': 3, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3535748872523228, 'margin': 0.24829582129675215, 'lpl_weight': 0.293155651675563, 'ratio': 0.20134944996985263, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8680551662620349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8838, F1=0.8514, Recall=0.8331, Precision=0.8704\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102182748.csv.\n",
      "Average F1 over 5 seeds: 0.8437  0.0096\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2051401924171139, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.20510392321899867, margin=0.5563340050887937, lpl_weight=0.4628189589395539\n",
      " - ratio=0.31462574202703125, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6916, LPL: 1.3863, Contrastive: 0.0930\n",
      "Epoch 50, Loss: 0.6696, LPL: 1.3863, Contrastive: 0.0521\n",
      "Epoch 100, Loss: 0.6689, LPL: 1.3863, Contrastive: 0.0508\n",
      " - Metrics: Accuracy=0.8765, F1=0.8548, Recall=0.9106, Precision=0.8055\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2051401924171139, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.20510392321899867, margin=0.5563340050887937, lpl_weight=0.4628189589395539\n",
      " - ratio=0.31462574202703125, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6916, LPL: 1.3863, Contrastive: 0.0930\n",
      "Epoch 50, Loss: 0.6696, LPL: 1.3863, Contrastive: 0.0521\n",
      "Epoch 100, Loss: 0.6689, LPL: 1.3863, Contrastive: 0.0508\n",
      " - Metrics: Accuracy=0.8521, F1=0.8262, Recall=0.8800, Precision=0.7786\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2051401924171139, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.20510392321899867, margin=0.5563340050887937, lpl_weight=0.4628189589395539\n",
      " - ratio=0.31462574202703125, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6916, LPL: 1.3863, Contrastive: 0.0930\n",
      "Epoch 50, Loss: 0.6696, LPL: 1.3863, Contrastive: 0.0521\n",
      "Epoch 100, Loss: 0.6689, LPL: 1.3863, Contrastive: 0.0508\n",
      " - Metrics: Accuracy=0.8771, F1=0.8555, Recall=0.9115, Precision=0.8061\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2051401924171139, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.20510392321899867, margin=0.5563340050887937, lpl_weight=0.4628189589395539\n",
      " - ratio=0.31462574202703125, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6916, LPL: 1.3863, Contrastive: 0.0930\n",
      "Epoch 50, Loss: 0.6696, LPL: 1.3863, Contrastive: 0.0521\n",
      "Epoch 100, Loss: 0.6689, LPL: 1.3863, Contrastive: 0.0508\n",
      " - Metrics: Accuracy=0.8768, F1=0.8553, Recall=0.9112, Precision=0.8057\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2051401924171139, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.20510392321899867, margin=0.5563340050887937, lpl_weight=0.4628189589395539\n",
      " - ratio=0.31462574202703125, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6916, LPL: 1.3863, Contrastive: 0.0930\n",
      "Epoch 50, Loss: 0.6696, LPL: 1.3863, Contrastive: 0.0521\n",
      "Epoch 100, Loss: 0.6689, LPL: 1.3863, Contrastive: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:33:30,447] Trial 19 finished with value: 0.8493974813325533 and parameters: {'alpha': 0.2051401924171139, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.20510392321899867, 'margin': 0.5563340050887937, 'lpl_weight': 0.4628189589395539, 'ratio': 0.31462574202703125, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8680551662620349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8768, F1=0.8552, Recall=0.9112, Precision=0.8057\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102183025.csv.\n",
      "Average F1 over 5 seeds: 0.8494  0.0116\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3353431354774189, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.3945076296978654, margin=0.26782742543940774, lpl_weight=0.7177440818011648\n",
      " - ratio=0.2271538074180319, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0374, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.0337, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.8944, F1=0.8651, Recall=0.8484, Precision=0.8826\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3353431354774189, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.3945076296978654, margin=0.26782742543940774, lpl_weight=0.7177440818011648\n",
      " - ratio=0.2271538074180319, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0374, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.0337, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.8900, F1=0.8593, Recall=0.8408, Precision=0.8786\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3353431354774189, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.3945076296978654, margin=0.26782742543940774, lpl_weight=0.7177440818011648\n",
      " - ratio=0.2271538074180319, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0374, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.0337, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.8937, F1=0.8640, Recall=0.8453, Precision=0.8836\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3353431354774189, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.3945076296978654, margin=0.26782742543940774, lpl_weight=0.7177440818011648\n",
      " - ratio=0.2271538074180319, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0374, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.0337, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.8938, F1=0.8642, Recall=0.8460, Precision=0.8833\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3353431354774189, K=31, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.3945076296978654, margin=0.26782742543940774, lpl_weight=0.7177440818011648\n",
      " - ratio=0.2271538074180319, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0374, LPL: 1.3863, Contrastive: 0.1501\n",
      "Epoch 50, Loss: 1.0337, LPL: 1.3863, Contrastive: 0.1371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:36:42,004] Trial 20 finished with value: 0.8636691134235616 and parameters: {'alpha': 0.3353431354774189, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3945076296978654, 'margin': 0.26782742543940774, 'lpl_weight': 0.7177440818011648, 'ratio': 0.2271538074180319, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 15 with value: 0.8680551662620349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8948, F1=0.8657, Recall=0.8486, Precision=0.8834\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102183330.csv.\n",
      "Average F1 over 5 seeds: 0.8637  0.0023\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3905733017461206, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.35843415909387344, margin=0.13388491644078554, lpl_weight=0.6903515815427492\n",
      " - ratio=0.23504858097636067, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0205, LPL: 1.3863, Contrastive: 0.2050\n",
      "Epoch 50, Loss: 1.0165, LPL: 1.3863, Contrastive: 0.1921\n",
      " - Metrics: Accuracy=0.8985, F1=0.8714, Recall=0.8607, Precision=0.8823\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3905733017461206, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.35843415909387344, margin=0.13388491644078554, lpl_weight=0.6903515815427492\n",
      " - ratio=0.23504858097636067, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0205, LPL: 1.3863, Contrastive: 0.2050\n",
      "Epoch 50, Loss: 1.0165, LPL: 1.3863, Contrastive: 0.1921\n",
      " - Metrics: Accuracy=0.8940, F1=0.8656, Recall=0.8545, Precision=0.8770\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3905733017461206, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.35843415909387344, margin=0.13388491644078554, lpl_weight=0.6903515815427492\n",
      " - ratio=0.23504858097636067, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0205, LPL: 1.3863, Contrastive: 0.2050\n",
      "Epoch 50, Loss: 1.0165, LPL: 1.3863, Contrastive: 0.1921\n",
      " - Metrics: Accuracy=0.8999, F1=0.8733, Recall=0.8637, Precision=0.8831\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3905733017461206, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.35843415909387344, margin=0.13388491644078554, lpl_weight=0.6903515815427492\n",
      " - ratio=0.23504858097636067, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0205, LPL: 1.3863, Contrastive: 0.2050\n",
      "Epoch 50, Loss: 1.0165, LPL: 1.3863, Contrastive: 0.1921\n",
      " - Metrics: Accuracy=0.8965, F1=0.8689, Recall=0.8583, Precision=0.8797\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3905733017461206, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.35843415909387344, margin=0.13388491644078554, lpl_weight=0.6903515815427492\n",
      " - ratio=0.23504858097636067, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0205, LPL: 1.3863, Contrastive: 0.2050\n",
      "Epoch 50, Loss: 1.0165, LPL: 1.3863, Contrastive: 0.1921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:39:15,730] Trial 21 finished with value: 0.869313187772647 and parameters: {'alpha': 0.3905733017461206, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.35843415909387344, 'margin': 0.13388491644078554, 'lpl_weight': 0.6903515815427492, 'ratio': 0.23504858097636067, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 21 with value: 0.869313187772647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8954, F1=0.8674, Recall=0.8564, Precision=0.8787\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102183642.csv.\n",
      "Average F1 over 5 seeds: 0.8693  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.25503455062799246, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.34674827917164924, margin=0.16177445978937793, lpl_weight=0.8360928606739102\n",
      " - ratio=0.21468635530396302, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1908, LPL: 1.3863, Contrastive: 0.1935\n",
      "Epoch 50, Loss: 1.1886, LPL: 1.3863, Contrastive: 0.1802\n",
      " - Metrics: Accuracy=0.9039, F1=0.8772, Recall=0.8587, Precision=0.8965\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.25503455062799246, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.34674827917164924, margin=0.16177445978937793, lpl_weight=0.8360928606739102\n",
      " - ratio=0.21468635530396302, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1908, LPL: 1.3863, Contrastive: 0.1935\n",
      "Epoch 50, Loss: 1.1886, LPL: 1.3863, Contrastive: 0.1802\n",
      " - Metrics: Accuracy=0.8998, F1=0.8711, Recall=0.8480, Precision=0.8955\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.25503455062799246, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.34674827917164924, margin=0.16177445978937793, lpl_weight=0.8360928606739102\n",
      " - ratio=0.21468635530396302, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1908, LPL: 1.3863, Contrastive: 0.1935\n",
      "Epoch 50, Loss: 1.1886, LPL: 1.3863, Contrastive: 0.1802\n",
      " - Metrics: Accuracy=0.9042, F1=0.8774, Recall=0.8583, Precision=0.8974\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.25503455062799246, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.34674827917164924, margin=0.16177445978937793, lpl_weight=0.8360928606739102\n",
      " - ratio=0.21468635530396302, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1908, LPL: 1.3863, Contrastive: 0.1935\n",
      "Epoch 50, Loss: 1.1886, LPL: 1.3863, Contrastive: 0.1802\n",
      " - Metrics: Accuracy=0.9042, F1=0.8768, Recall=0.8538, Precision=0.9011\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.25503455062799246, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.34674827917164924, margin=0.16177445978937793, lpl_weight=0.8360928606739102\n",
      " - ratio=0.21468635530396302, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1908, LPL: 1.3863, Contrastive: 0.1935\n",
      "Epoch 50, Loss: 1.1886, LPL: 1.3863, Contrastive: 0.1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:41:56,314] Trial 22 finished with value: 0.8749015333712882 and parameters: {'alpha': 0.25503455062799246, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.34674827917164924, 'margin': 0.16177445978937793, 'lpl_weight': 0.8360928606739102, 'ratio': 0.21468635530396302, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9000, F1=0.8720, Recall=0.8526, Precision=0.8923\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102183915.csv.\n",
      "Average F1 over 5 seeds: 0.8749  0.0027\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3977074078076561, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3594289370829786, margin=0.16793366893962902, lpl_weight=0.9038169459855228\n",
      " - ratio=0.19007249751794403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2713, LPL: 1.3863, Contrastive: 0.1911\n",
      "Epoch 50, Loss: 1.2700, LPL: 1.3863, Contrastive: 0.1774\n",
      " - Metrics: Accuracy=0.8978, F1=0.8659, Recall=0.8268, Precision=0.9090\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3977074078076561, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3594289370829786, margin=0.16793366893962902, lpl_weight=0.9038169459855228\n",
      " - ratio=0.19007249751794403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2713, LPL: 1.3863, Contrastive: 0.1911\n",
      "Epoch 50, Loss: 1.2700, LPL: 1.3863, Contrastive: 0.1774\n",
      " - Metrics: Accuracy=0.8980, F1=0.8665, Recall=0.8291, Precision=0.9074\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3977074078076561, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3594289370829786, margin=0.16793366893962902, lpl_weight=0.9038169459855228\n",
      " - ratio=0.19007249751794403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2713, LPL: 1.3863, Contrastive: 0.1911\n",
      "Epoch 50, Loss: 1.2700, LPL: 1.3863, Contrastive: 0.1774\n",
      " - Metrics: Accuracy=0.8986, F1=0.8666, Recall=0.8251, Precision=0.9125\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3977074078076561, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3594289370829786, margin=0.16793366893962902, lpl_weight=0.9038169459855228\n",
      " - ratio=0.19007249751794403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2713, LPL: 1.3863, Contrastive: 0.1911\n",
      "Epoch 50, Loss: 1.2700, LPL: 1.3863, Contrastive: 0.1774\n",
      " - Metrics: Accuracy=0.9007, F1=0.8695, Recall=0.8282, Precision=0.9151\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3977074078076561, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3594289370829786, margin=0.16793366893962902, lpl_weight=0.9038169459855228\n",
      " - ratio=0.19007249751794403, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2713, LPL: 1.3863, Contrastive: 0.1911\n",
      "Epoch 50, Loss: 1.2700, LPL: 1.3863, Contrastive: 0.1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:44:36,101] Trial 23 finished with value: 0.8652903118419839 and parameters: {'alpha': 0.3977074078076561, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3594289370829786, 'margin': 0.16793366893962902, 'lpl_weight': 0.9038169459855228, 'ratio': 0.19007249751794403, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8922, F1=0.8579, Recall=0.8146, Precision=0.9061\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102184156.csv.\n",
      "Average F1 over 5 seeds: 0.8653  0.0039\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.269140184449361, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.28130219053692274, margin=0.29466760282285964, lpl_weight=0.8116593992620579\n",
      " - ratio=0.23294636266246233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1527, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 50, Loss: 1.1493, LPL: 1.3863, Contrastive: 0.1281\n",
      "Epoch 100, Loss: 1.1491, LPL: 1.3863, Contrastive: 0.1268\n",
      " - Metrics: Accuracy=0.8914, F1=0.8623, Recall=0.8517, Precision=0.8732\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.269140184449361, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.28130219053692274, margin=0.29466760282285964, lpl_weight=0.8116593992620579\n",
      " - ratio=0.23294636266246233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1527, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 50, Loss: 1.1493, LPL: 1.3863, Contrastive: 0.1281\n",
      "Epoch 100, Loss: 1.1494, LPL: 1.3863, Contrastive: 0.1283\n",
      " - Metrics: Accuracy=0.8933, F1=0.8650, Recall=0.8555, Precision=0.8747\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.269140184449361, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.28130219053692274, margin=0.29466760282285964, lpl_weight=0.8116593992620579\n",
      " - ratio=0.23294636266246233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1527, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 50, Loss: 1.1493, LPL: 1.3863, Contrastive: 0.1281\n",
      "Epoch 100, Loss: 1.1491, LPL: 1.3863, Contrastive: 0.1268\n",
      " - Metrics: Accuracy=0.8920, F1=0.8634, Recall=0.8550, Precision=0.8720\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.269140184449361, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.28130219053692274, margin=0.29466760282285964, lpl_weight=0.8116593992620579\n",
      " - ratio=0.23294636266246233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1527, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 50, Loss: 1.1493, LPL: 1.3863, Contrastive: 0.1281\n",
      "Epoch 100, Loss: 1.1494, LPL: 1.3863, Contrastive: 0.1283\n",
      " - Metrics: Accuracy=0.8941, F1=0.8658, Recall=0.8556, Precision=0.8762\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.269140184449361, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.28130219053692274, margin=0.29466760282285964, lpl_weight=0.8116593992620579\n",
      " - ratio=0.23294636266246233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1527, LPL: 1.3863, Contrastive: 0.1460\n",
      "Epoch 50, Loss: 1.1493, LPL: 1.3863, Contrastive: 0.1281\n",
      "Epoch 100, Loss: 1.1491, LPL: 1.3863, Contrastive: 0.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:47:26,893] Trial 24 finished with value: 0.864221276094708 and parameters: {'alpha': 0.269140184449361, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.28130219053692274, 'margin': 0.29466760282285964, 'lpl_weight': 0.8116593992620579, 'ratio': 0.23294636266246233, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8931, F1=0.8646, Recall=0.8546, Precision=0.8748\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102184436.csv.\n",
      "Average F1 over 5 seeds: 0.8642  0.0012\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.23539935998962025, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.4290598461848151, margin=0.14028753419258863, lpl_weight=0.7097324612734129\n",
      " - ratio=0.3201848913406368, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0467, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 1.0394, LPL: 1.3863, Contrastive: 0.1912\n",
      "Epoch 100, Loss: 1.0389, LPL: 1.3863, Contrastive: 0.1893\n",
      " - Metrics: Accuracy=0.8623, F1=0.8389, Recall=0.8978, Precision=0.7873\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.23539935998962025, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.4290598461848151, margin=0.14028753419258863, lpl_weight=0.7097324612734129\n",
      " - ratio=0.3201848913406368, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0467, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 1.0394, LPL: 1.3863, Contrastive: 0.1912\n",
      "Epoch 100, Loss: 1.0390, LPL: 1.3863, Contrastive: 0.1899\n",
      " - Metrics: Accuracy=0.8601, F1=0.8364, Recall=0.8955, Precision=0.7846\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.23539935998962025, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.4290598461848151, margin=0.14028753419258863, lpl_weight=0.7097324612734129\n",
      " - ratio=0.3201848913406368, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0467, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 1.0394, LPL: 1.3863, Contrastive: 0.1912\n",
      "Epoch 100, Loss: 1.0390, LPL: 1.3863, Contrastive: 0.1897\n",
      " - Metrics: Accuracy=0.8653, F1=0.8424, Recall=0.9012, Precision=0.7908\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.23539935998962025, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.4290598461848151, margin=0.14028753419258863, lpl_weight=0.7097324612734129\n",
      " - ratio=0.3201848913406368, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0467, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 1.0394, LPL: 1.3863, Contrastive: 0.1912\n",
      "Epoch 100, Loss: 1.0390, LPL: 1.3863, Contrastive: 0.1899\n",
      " - Metrics: Accuracy=0.8618, F1=0.8385, Recall=0.8977, Precision=0.7866\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.23539935998962025, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.4290598461848151, margin=0.14028753419258863, lpl_weight=0.7097324612734129\n",
      " - ratio=0.3201848913406368, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0467, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 1.0394, LPL: 1.3863, Contrastive: 0.1912\n",
      "Epoch 100, Loss: 1.0399, LPL: 1.3863, Contrastive: 0.1931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:50:02,822] Trial 25 finished with value: 0.8387852251459474 and parameters: {'alpha': 0.23539935998962025, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.4290598461848151, 'margin': 0.14028753419258863, 'lpl_weight': 0.7097324612734129, 'ratio': 0.3201848913406368, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8613, F1=0.8378, Recall=0.8969, Precision=0.7860\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102184726.csv.\n",
      "Average F1 over 5 seeds: 0.8388  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5491663344358408, K=35, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3524233233859751, margin=0.18991297040549862, lpl_weight=0.839714526326319\n",
      " - ratio=0.17337794705000048, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1934, LPL: 1.3863, Contrastive: 0.1826\n",
      "Epoch 50, Loss: 1.1911, LPL: 1.3863, Contrastive: 0.1685\n",
      " - Metrics: Accuracy=0.9021, F1=0.8695, Recall=0.8168, Precision=0.9296\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5491663344358408, K=35, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3524233233859751, margin=0.18991297040549862, lpl_weight=0.839714526326319\n",
      " - ratio=0.17337794705000048, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1934, LPL: 1.3863, Contrastive: 0.1826\n",
      "Epoch 50, Loss: 1.1911, LPL: 1.3863, Contrastive: 0.1685\n",
      " - Metrics: Accuracy=0.8980, F1=0.8641, Recall=0.8119, Precision=0.9235\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5491663344358408, K=35, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3524233233859751, margin=0.18991297040549862, lpl_weight=0.839714526326319\n",
      " - ratio=0.17337794705000048, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1934, LPL: 1.3863, Contrastive: 0.1826\n",
      "Epoch 50, Loss: 1.1911, LPL: 1.3863, Contrastive: 0.1685\n",
      " - Metrics: Accuracy=0.9045, F1=0.8734, Recall=0.8241, Precision=0.9289\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5491663344358408, K=35, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3524233233859751, margin=0.18991297040549862, lpl_weight=0.839714526326319\n",
      " - ratio=0.17337794705000048, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1934, LPL: 1.3863, Contrastive: 0.1826\n",
      "Epoch 50, Loss: 1.1911, LPL: 1.3863, Contrastive: 0.1685\n",
      " - Metrics: Accuracy=0.8993, F1=0.8657, Recall=0.8130, Precision=0.9258\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5491663344358408, K=35, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3524233233859751, margin=0.18991297040549862, lpl_weight=0.839714526326319\n",
      " - ratio=0.17337794705000048, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1934, LPL: 1.3863, Contrastive: 0.1826\n",
      "Epoch 50, Loss: 1.1911, LPL: 1.3863, Contrastive: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:52:39,313] Trial 26 finished with value: 0.8695000828727062 and parameters: {'alpha': 0.5491663344358408, 'K': 35, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3524233233859751, 'margin': 0.18991297040549862, 'lpl_weight': 0.839714526326319, 'ratio': 0.17337794705000048, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9049, F1=0.8748, Recall=0.8315, Precision=0.9228\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102185002.csv.\n",
      "Average F1 over 5 seeds: 0.8695  0.0041\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5635563197070631, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2760748922264591, margin=0.3016683564666989, lpl_weight=0.832304563830307\n",
      " - ratio=0.17755729650695967, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1767, LPL: 1.3863, Contrastive: 0.1365\n",
      "Epoch 50, Loss: 1.1747, LPL: 1.3863, Contrastive: 0.1248\n",
      " - Metrics: Accuracy=0.9009, F1=0.8689, Recall=0.8225, Precision=0.9209\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5635563197070631, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2760748922264591, margin=0.3016683564666989, lpl_weight=0.832304563830307\n",
      " - ratio=0.17755729650695967, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1767, LPL: 1.3863, Contrastive: 0.1365\n",
      "Epoch 50, Loss: 1.1747, LPL: 1.3863, Contrastive: 0.1248\n",
      " - Metrics: Accuracy=0.8987, F1=0.8659, Recall=0.8188, Precision=0.9186\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5635563197070631, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2760748922264591, margin=0.3016683564666989, lpl_weight=0.832304563830307\n",
      " - ratio=0.17755729650695967, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1767, LPL: 1.3863, Contrastive: 0.1365\n",
      "Epoch 50, Loss: 1.1747, LPL: 1.3863, Contrastive: 0.1248\n",
      " - Metrics: Accuracy=0.9043, F1=0.8734, Recall=0.8264, Precision=0.9261\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5635563197070631, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2760748922264591, margin=0.3016683564666989, lpl_weight=0.832304563830307\n",
      " - ratio=0.17755729650695967, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1767, LPL: 1.3863, Contrastive: 0.1365\n",
      "Epoch 50, Loss: 1.1747, LPL: 1.3863, Contrastive: 0.1248\n",
      " - Metrics: Accuracy=0.9031, F1=0.8713, Recall=0.8213, Precision=0.9277\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5635563197070631, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2760748922264591, margin=0.3016683564666989, lpl_weight=0.832304563830307\n",
      " - ratio=0.17755729650695967, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1767, LPL: 1.3863, Contrastive: 0.1365\n",
      "Epoch 50, Loss: 1.1747, LPL: 1.3863, Contrastive: 0.1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:55:52,332] Trial 27 finished with value: 0.869141020112948 and parameters: {'alpha': 0.5635563197070631, 'K': 33, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2760748922264591, 'margin': 0.3016683564666989, 'lpl_weight': 0.832304563830307, 'ratio': 0.17755729650695967, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8989, F1=0.8662, Recall=0.8192, Precision=0.9189\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102185239.csv.\n",
      "Average F1 over 5 seeds: 0.8691  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6714409539147308, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3765696979026366, margin=0.1892543483346289, lpl_weight=0.9954120650637245\n",
      " - ratio=0.10992942711632907, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3808, LPL: 1.3863, Contrastive: 0.1834\n",
      "Epoch 50, Loss: 1.3807, LPL: 1.3863, Contrastive: 0.1686\n",
      " - Metrics: Accuracy=0.8856, F1=0.8388, Recall=0.7449, Precision=0.9598\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6714409539147308, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3765696979026366, margin=0.1892543483346289, lpl_weight=0.9954120650637245\n",
      " - ratio=0.10992942711632907, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3808, LPL: 1.3863, Contrastive: 0.1834\n",
      "Epoch 50, Loss: 1.3807, LPL: 1.3863, Contrastive: 0.1686\n",
      " - Metrics: Accuracy=0.8827, F1=0.8339, Recall=0.7375, Precision=0.9594\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6714409539147308, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3765696979026366, margin=0.1892543483346289, lpl_weight=0.9954120650637245\n",
      " - ratio=0.10992942711632907, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3808, LPL: 1.3863, Contrastive: 0.1834\n",
      "Epoch 50, Loss: 1.3807, LPL: 1.3863, Contrastive: 0.1686\n",
      " - Metrics: Accuracy=0.8834, F1=0.8354, Recall=0.7407, Precision=0.9578\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6714409539147308, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3765696979026366, margin=0.1892543483346289, lpl_weight=0.9954120650637245\n",
      " - ratio=0.10992942711632907, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3808, LPL: 1.3863, Contrastive: 0.1834\n",
      "Epoch 50, Loss: 1.3807, LPL: 1.3863, Contrastive: 0.1686\n",
      " - Metrics: Accuracy=0.8821, F1=0.8324, Recall=0.7330, Precision=0.9630\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6714409539147308, K=29, layers=1, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.3765696979026366, margin=0.1892543483346289, lpl_weight=0.9954120650637245\n",
      " - ratio=0.10992942711632907, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3808, LPL: 1.3863, Contrastive: 0.1834\n",
      "Epoch 50, Loss: 1.3807, LPL: 1.3863, Contrastive: 0.1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:58:24,302] Trial 28 finished with value: 0.8351980790532156 and parameters: {'alpha': 0.6714409539147308, 'K': 29, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.3765696979026366, 'margin': 0.1892543483346289, 'lpl_weight': 0.9954120650637245, 'ratio': 0.10992942711632907, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8838, F1=0.8355, Recall=0.7393, Precision=0.9606\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102185552.csv.\n",
      "Average F1 over 5 seeds: 0.8352  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5043240174874326, K=31, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3306970021806641, margin=0.476182982116369, lpl_weight=0.9001680173959276\n",
      " - ratio=0.1746591310369954, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2607, LPL: 1.3863, Contrastive: 0.1281\n",
      " - Metrics: Accuracy=0.8602, F1=0.8121, Recall=0.7567, Precision=0.8763\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5043240174874326, K=31, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3306970021806641, margin=0.476182982116369, lpl_weight=0.9001680173959276\n",
      " - ratio=0.1746591310369954, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2607, LPL: 1.3863, Contrastive: 0.1281\n",
      " - Metrics: Accuracy=0.8565, F1=0.8069, Recall=0.7506, Precision=0.8722\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5043240174874326, K=31, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3306970021806641, margin=0.476182982116369, lpl_weight=0.9001680173959276\n",
      " - ratio=0.1746591310369954, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2607, LPL: 1.3863, Contrastive: 0.1281\n",
      " - Metrics: Accuracy=0.8637, F1=0.8173, Recall=0.7637, Precision=0.8791\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5043240174874326, K=31, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3306970021806641, margin=0.476182982116369, lpl_weight=0.9001680173959276\n",
      " - ratio=0.1746591310369954, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2607, LPL: 1.3863, Contrastive: 0.1281\n",
      " - Metrics: Accuracy=0.8612, F1=0.8135, Recall=0.7580, Precision=0.8778\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5043240174874326, K=31, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.3306970021806641, margin=0.476182982116369, lpl_weight=0.9001680173959276\n",
      " - ratio=0.1746591310369954, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2607, LPL: 1.3863, Contrastive: 0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:00:22,482] Trial 29 finished with value: 0.8118983333214324 and parameters: {'alpha': 0.5043240174874326, 'K': 31, 'layers': 1, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3306970021806641, 'margin': 0.476182982116369, 'lpl_weight': 0.9001680173959276, 'ratio': 0.1746591310369954, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8579, F1=0.8097, Recall=0.7566, Precision=0.8708\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102185824.csv.\n",
      "Average F1 over 5 seeds: 0.8119  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.38226049291745984, K=34, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.18183161480283322, margin=0.29886696427768605, lpl_weight=0.7844676610622193\n",
      " - ratio=0.20746565770303896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1169, LPL: 1.3863, Contrastive: 0.1363\n",
      "Epoch 50, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1277\n",
      " - Metrics: Accuracy=0.8973, F1=0.8678, Recall=0.8438, Precision=0.8931\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.38226049291745984, K=34, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.18183161480283322, margin=0.29886696427768605, lpl_weight=0.7844676610622193\n",
      " - ratio=0.20746565770303896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1169, LPL: 1.3863, Contrastive: 0.1363\n",
      "Epoch 50, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1277\n",
      " - Metrics: Accuracy=0.8769, F1=0.8417, Recall=0.8194, Precision=0.8651\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.38226049291745984, K=34, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.18183161480283322, margin=0.29886696427768605, lpl_weight=0.7844676610622193\n",
      " - ratio=0.20746565770303896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1169, LPL: 1.3863, Contrastive: 0.1363\n",
      "Epoch 50, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1277\n",
      " - Metrics: Accuracy=0.8791, F1=0.8453, Recall=0.8270, Precision=0.8644\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.38226049291745984, K=34, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.18183161480283322, margin=0.29886696427768605, lpl_weight=0.7844676610622193\n",
      " - ratio=0.20746565770303896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1169, LPL: 1.3863, Contrastive: 0.1363\n",
      "Epoch 50, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1277\n",
      " - Metrics: Accuracy=0.8921, F1=0.8614, Recall=0.8400, Precision=0.8840\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.38226049291745984, K=34, layers=3, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.18183161480283322, margin=0.29886696427768605, lpl_weight=0.7844676610622193\n",
      " - ratio=0.20746565770303896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1169, LPL: 1.3863, Contrastive: 0.1363\n",
      "Epoch 50, Loss: 1.1150, LPL: 1.3863, Contrastive: 0.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:03:05,626] Trial 30 finished with value: 0.8555163750289111 and parameters: {'alpha': 0.38226049291745984, 'K': 34, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.18183161480283322, 'margin': 0.29886696427768605, 'lpl_weight': 0.7844676610622193, 'ratio': 0.20746565770303896, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8918, F1=0.8614, Recall=0.8422, Precision=0.8816\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102190022.csv.\n",
      "Average F1 over 5 seeds: 0.8555  0.0102\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5749303729840348, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.27596124838002956, margin=0.3146451993141089, lpl_weight=0.8791440376520168\n",
      " - ratio=0.1707685339927943, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2347, LPL: 1.3863, Contrastive: 0.1323\n",
      "Epoch 50, Loss: 1.2333, LPL: 1.3863, Contrastive: 0.1201\n",
      " - Metrics: Accuracy=0.8935, F1=0.8563, Recall=0.7943, Precision=0.9287\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5749303729840348, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.27596124838002956, margin=0.3146451993141089, lpl_weight=0.8791440376520168\n",
      " - ratio=0.1707685339927943, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2347, LPL: 1.3863, Contrastive: 0.1323\n",
      "Epoch 50, Loss: 1.2333, LPL: 1.3863, Contrastive: 0.1201\n",
      " - Metrics: Accuracy=0.8954, F1=0.8589, Recall=0.7973, Precision=0.9308\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5749303729840348, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.27596124838002956, margin=0.3146451993141089, lpl_weight=0.8791440376520168\n",
      " - ratio=0.1707685339927943, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2347, LPL: 1.3863, Contrastive: 0.1323\n",
      "Epoch 50, Loss: 1.2333, LPL: 1.3863, Contrastive: 0.1201\n",
      " - Metrics: Accuracy=0.8976, F1=0.8621, Recall=0.8015, Precision=0.9326\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5749303729840348, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.27596124838002956, margin=0.3146451993141089, lpl_weight=0.8791440376520168\n",
      " - ratio=0.1707685339927943, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2347, LPL: 1.3863, Contrastive: 0.1323\n",
      "Epoch 50, Loss: 1.2333, LPL: 1.3863, Contrastive: 0.1201\n",
      " - Metrics: Accuracy=0.8965, F1=0.8605, Recall=0.7989, Precision=0.9324\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5749303729840348, K=33, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.27596124838002956, margin=0.3146451993141089, lpl_weight=0.8791440376520168\n",
      " - ratio=0.1707685339927943, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2347, LPL: 1.3863, Contrastive: 0.1323\n",
      "Epoch 50, Loss: 1.2333, LPL: 1.3863, Contrastive: 0.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:06:16,833] Trial 31 finished with value: 0.8587375458227255 and parameters: {'alpha': 0.5749303729840348, 'K': 33, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.27596124838002956, 'margin': 0.3146451993141089, 'lpl_weight': 0.8791440376520168, 'ratio': 0.1707685339927943, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8924, F1=0.8559, Recall=0.8004, Precision=0.9197\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102190305.csv.\n",
      "Average F1 over 5 seeds: 0.8587  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.78415350364219, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2802510030369309, margin=0.18177722805652197, lpl_weight=0.6622687789709016\n",
      " - ratio=0.24819544071639155, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9798, LPL: 1.3863, Contrastive: 0.1827\n",
      "Epoch 50, Loss: 0.9757, LPL: 1.3863, Contrastive: 0.1705\n",
      " - Metrics: Accuracy=0.8924, F1=0.8652, Recall=0.8649, Precision=0.8655\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.78415350364219, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2802510030369309, margin=0.18177722805652197, lpl_weight=0.6622687789709016\n",
      " - ratio=0.24819544071639155, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9798, LPL: 1.3863, Contrastive: 0.1827\n",
      "Epoch 50, Loss: 0.9757, LPL: 1.3863, Contrastive: 0.1704\n",
      " - Metrics: Accuracy=0.8909, F1=0.8633, Recall=0.8626, Precision=0.8639\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.78415350364219, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2802510030369309, margin=0.18177722805652197, lpl_weight=0.6622687789709016\n",
      " - ratio=0.24819544071639155, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9798, LPL: 1.3863, Contrastive: 0.1827\n",
      "Epoch 50, Loss: 0.9757, LPL: 1.3863, Contrastive: 0.1705\n",
      " - Metrics: Accuracy=0.8948, F1=0.8682, Recall=0.8676, Precision=0.8689\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.78415350364219, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2802510030369309, margin=0.18177722805652197, lpl_weight=0.6622687789709016\n",
      " - ratio=0.24819544071639155, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9798, LPL: 1.3863, Contrastive: 0.1827\n",
      "Epoch 50, Loss: 0.9757, LPL: 1.3863, Contrastive: 0.1705\n",
      " - Metrics: Accuracy=0.8936, F1=0.8668, Recall=0.8665, Precision=0.8671\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.78415350364219, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.2802510030369309, margin=0.18177722805652197, lpl_weight=0.6622687789709016\n",
      " - ratio=0.24819544071639155, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9798, LPL: 1.3863, Contrastive: 0.1827\n",
      "Epoch 50, Loss: 0.9757, LPL: 1.3863, Contrastive: 0.1705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:09:23,172] Trial 32 finished with value: 0.8665004456312266 and parameters: {'alpha': 0.78415350364219, 'K': 34, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2802510030369309, 'margin': 0.18177722805652197, 'lpl_weight': 0.6622687789709016, 'ratio': 0.24819544071639155, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8954, F1=0.8690, Recall=0.8688, Precision=0.8692\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102190616.csv.\n",
      "Average F1 over 5 seeds: 0.8665  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5066762680203554, K=35, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4232157725819188, margin=0.24278138079602457, lpl_weight=0.7783737621669264\n",
      " - ratio=0.20942859706844028, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1144, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.1466\n",
      " - Metrics: Accuracy=0.8976, F1=0.8669, Recall=0.8354, Precision=0.9009\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5066762680203554, K=35, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4232157725819188, margin=0.24278138079602457, lpl_weight=0.7783737621669264\n",
      " - ratio=0.20942859706844028, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1144, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.1466\n",
      " - Metrics: Accuracy=0.8984, F1=0.8678, Recall=0.8356, Precision=0.9027\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5066762680203554, K=35, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4232157725819188, margin=0.24278138079602457, lpl_weight=0.7783737621669264\n",
      " - ratio=0.20942859706844028, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1144, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.1466\n",
      " - Metrics: Accuracy=0.8951, F1=0.8636, Recall=0.8316, Precision=0.8982\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5066762680203554, K=35, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4232157725819188, margin=0.24278138079602457, lpl_weight=0.7783737621669264\n",
      " - ratio=0.20942859706844028, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1144, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.1466\n",
      " - Metrics: Accuracy=0.8975, F1=0.8666, Recall=0.8339, Precision=0.9021\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5066762680203554, K=35, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.4232157725819188, margin=0.24278138079602457, lpl_weight=0.7783737621669264\n",
      " - ratio=0.20942859706844028, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1144, LPL: 1.3863, Contrastive: 0.1594\n",
      "Epoch 50, Loss: 1.1116, LPL: 1.3863, Contrastive: 0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:12:33,643] Trial 33 finished with value: 0.8640834015529156 and parameters: {'alpha': 0.5066762680203554, 'K': 35, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.4232157725819188, 'margin': 0.24278138079602457, 'lpl_weight': 0.7783737621669264, 'ratio': 0.20942859706844028, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8887, F1=0.8554, Recall=0.8239, Precision=0.8894\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102190923.csv.\n",
      "Average F1 over 5 seeds: 0.8641  0.0046\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6366641182683436, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.340602047970045, margin=0.16595292096281447, lpl_weight=0.8325951237994345\n",
      " - ratio=0.12808196638636263, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2068, LPL: 1.3863, Contrastive: 0.3141\n",
      " - Metrics: Accuracy=0.8673, F1=0.8121, Recall=0.7180, Precision=0.9347\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6366641182683436, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.340602047970045, margin=0.16595292096281447, lpl_weight=0.8325951237994345\n",
      " - ratio=0.12808196638636263, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2068, LPL: 1.3863, Contrastive: 0.3141\n",
      " - Metrics: Accuracy=0.8679, F1=0.8130, Recall=0.7189, Precision=0.9355\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6366641182683436, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.340602047970045, margin=0.16595292096281447, lpl_weight=0.8325951237994345\n",
      " - ratio=0.12808196638636263, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2068, LPL: 1.3863, Contrastive: 0.3141\n",
      " - Metrics: Accuracy=0.8703, F1=0.8163, Recall=0.7217, Precision=0.9395\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6366641182683436, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.340602047970045, margin=0.16595292096281447, lpl_weight=0.8325951237994345\n",
      " - ratio=0.12808196638636263, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2068, LPL: 1.3863, Contrastive: 0.3141\n",
      " - Metrics: Accuracy=0.8704, F1=0.8168, Recall=0.7230, Precision=0.9384\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6366641182683436, K=34, layers=1, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.340602047970045, margin=0.16595292096281447, lpl_weight=0.8325951237994345\n",
      " - ratio=0.12808196638636263, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2068, LPL: 1.3863, Contrastive: 0.3141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:15:08,958] Trial 34 finished with value: 0.8144140438269087 and parameters: {'alpha': 0.6366641182683436, 'K': 34, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.340602047970045, 'margin': 0.16595292096281447, 'lpl_weight': 0.8325951237994345, 'ratio': 0.12808196638636263, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8687, F1=0.8139, Recall=0.7186, Precision=0.9383\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102191233.csv.\n",
      "Average F1 over 5 seeds: 0.8144  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.746329292694749, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.406556504995012, margin=0.21656876248724516, lpl_weight=0.9561437231218413\n",
      " - ratio=0.17088253778790924, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3329, LPL: 1.3863, Contrastive: 0.1680\n",
      "Epoch 50, Loss: 1.3324, LPL: 1.3863, Contrastive: 0.1567\n",
      " - Metrics: Accuracy=0.8960, F1=0.8598, Recall=0.7981, Precision=0.9318\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.746329292694749, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.406556504995012, margin=0.21656876248724516, lpl_weight=0.9561437231218413\n",
      " - ratio=0.17088253778790924, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3329, LPL: 1.3863, Contrastive: 0.1680\n",
      "Epoch 50, Loss: 1.3324, LPL: 1.3863, Contrastive: 0.1567\n",
      " - Metrics: Accuracy=0.8894, F1=0.8506, Recall=0.7878, Precision=0.9242\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.746329292694749, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.406556504995012, margin=0.21656876248724516, lpl_weight=0.9561437231218413\n",
      " - ratio=0.17088253778790924, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3329, LPL: 1.3863, Contrastive: 0.1680\n",
      "Epoch 50, Loss: 1.3324, LPL: 1.3863, Contrastive: 0.1567\n",
      " - Metrics: Accuracy=0.8954, F1=0.8583, Recall=0.7937, Precision=0.9345\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.746329292694749, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.406556504995012, margin=0.21656876248724516, lpl_weight=0.9561437231218413\n",
      " - ratio=0.17088253778790924, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3329, LPL: 1.3863, Contrastive: 0.1680\n",
      "Epoch 50, Loss: 1.3324, LPL: 1.3863, Contrastive: 0.1567\n",
      " - Metrics: Accuracy=0.8984, F1=0.8639, Recall=0.8077, Precision=0.9285\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.746329292694749, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.406556504995012, margin=0.21656876248724516, lpl_weight=0.9561437231218413\n",
      " - ratio=0.17088253778790924, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3329, LPL: 1.3863, Contrastive: 0.1680\n",
      "Epoch 50, Loss: 1.3324, LPL: 1.3863, Contrastive: 0.1567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:18:16,322] Trial 35 finished with value: 0.8572544562793201 and parameters: {'alpha': 0.746329292694749, 'K': 33, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.406556504995012, 'margin': 0.21656876248724516, 'lpl_weight': 0.9561437231218413, 'ratio': 0.17088253778790924, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8918, F1=0.8537, Recall=0.7905, Precision=0.9279\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102191509.csv.\n",
      "Average F1 over 5 seeds: 0.8573  0.0047\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5506288289423511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3805881374488351, margin=0.340652008646307, lpl_weight=0.6367863939626273\n",
      " - ratio=0.2981281359377391, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9431, LPL: 1.3863, Contrastive: 0.1660\n",
      " - Metrics: Accuracy=0.8523, F1=0.8237, Recall=0.8643, Precision=0.7868\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5506288289423511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3805881374488351, margin=0.340652008646307, lpl_weight=0.6367863939626273\n",
      " - ratio=0.2981281359377391, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9431, LPL: 1.3863, Contrastive: 0.1660\n",
      " - Metrics: Accuracy=0.8457, F1=0.8158, Recall=0.8554, Precision=0.7797\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5506288289423511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3805881374488351, margin=0.340652008646307, lpl_weight=0.6367863939626273\n",
      " - ratio=0.2981281359377391, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9431, LPL: 1.3863, Contrastive: 0.1660\n",
      " - Metrics: Accuracy=0.8533, F1=0.8249, Recall=0.8650, Precision=0.7883\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5506288289423511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3805881374488351, margin=0.340652008646307, lpl_weight=0.6367863939626273\n",
      " - ratio=0.2981281359377391, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9431, LPL: 1.3863, Contrastive: 0.1660\n",
      " - Metrics: Accuracy=0.8544, F1=0.8262, Recall=0.8663, Precision=0.7897\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5506288289423511, K=31, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3805881374488351, margin=0.340652008646307, lpl_weight=0.6367863939626273\n",
      " - ratio=0.2981281359377391, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9431, LPL: 1.3863, Contrastive: 0.1660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:21:01,574] Trial 36 finished with value: 0.822196032239785 and parameters: {'alpha': 0.5506288289423511, 'K': 31, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.3805881374488351, 'margin': 0.340652008646307, 'lpl_weight': 0.6367863939626273, 'ratio': 0.2981281359377391, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8495, F1=0.8204, Recall=0.8606, Precision=0.7837\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102191816.csv.\n",
      "Average F1 over 5 seeds: 0.8222  0.0037\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7126504455145188, K=32, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.29644095099800105, margin=0.10622571333218211, lpl_weight=0.5084690110248015\n",
      " - ratio=0.4072437229096146, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8121, LPL: 1.3863, Contrastive: 0.2182\n",
      "Epoch 50, Loss: 0.8054, LPL: 1.3863, Contrastive: 0.2045\n",
      " - Metrics: Accuracy=0.8591, F1=0.8404, Recall=0.9293, Precision=0.7671\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7126504455145188, K=32, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.29644095099800105, margin=0.10622571333218211, lpl_weight=0.5084690110248015\n",
      " - ratio=0.4072437229096146, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8121, LPL: 1.3863, Contrastive: 0.2182\n",
      "Epoch 50, Loss: 0.8054, LPL: 1.3863, Contrastive: 0.2045\n",
      " - Metrics: Accuracy=0.8562, F1=0.8372, Recall=0.9262, Precision=0.7638\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7126504455145188, K=32, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.29644095099800105, margin=0.10622571333218211, lpl_weight=0.5084690110248015\n",
      " - ratio=0.4072437229096146, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8121, LPL: 1.3863, Contrastive: 0.2182\n",
      "Epoch 50, Loss: 0.8054, LPL: 1.3863, Contrastive: 0.2045\n",
      " - Metrics: Accuracy=0.8603, F1=0.8417, Recall=0.9298, Precision=0.7688\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7126504455145188, K=32, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.29644095099800105, margin=0.10622571333218211, lpl_weight=0.5084690110248015\n",
      " - ratio=0.4072437229096146, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8121, LPL: 1.3863, Contrastive: 0.2182\n",
      "Epoch 50, Loss: 0.8054, LPL: 1.3863, Contrastive: 0.2045\n",
      " - Metrics: Accuracy=0.8618, F1=0.8433, Recall=0.9310, Precision=0.7707\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7126504455145188, K=32, layers=1, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.29644095099800105, margin=0.10622571333218211, lpl_weight=0.5084690110248015\n",
      " - ratio=0.4072437229096146, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8121, LPL: 1.3863, Contrastive: 0.2182\n",
      "Epoch 50, Loss: 0.8054, LPL: 1.3863, Contrastive: 0.2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:23:33,194] Trial 37 finished with value: 0.8405951118638813 and parameters: {'alpha': 0.7126504455145188, 'K': 32, 'layers': 1, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.29644095099800105, 'margin': 0.10622571333218211, 'lpl_weight': 0.5084690110248015, 'ratio': 0.4072437229096146, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8589, F1=0.8403, Recall=0.9295, Precision=0.7667\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102192101.csv.\n",
      "Average F1 over 5 seeds: 0.8406  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4588033603752675, K=33, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.25490414171750325, margin=0.6184030786444874, lpl_weight=0.7381743901223683\n",
      " - ratio=0.15598843665096057, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0450, LPL: 1.3863, Contrastive: 0.0828\n",
      " - Metrics: Accuracy=0.8952, F1=0.8599, Recall=0.8048, Precision=0.9230\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4588033603752675, K=33, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.25490414171750325, margin=0.6184030786444874, lpl_weight=0.7381743901223683\n",
      " - ratio=0.15598843665096057, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0450, LPL: 1.3863, Contrastive: 0.0828\n",
      " - Metrics: Accuracy=0.8955, F1=0.8607, Recall=0.8079, Precision=0.9208\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4588033603752675, K=33, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.25490414171750325, margin=0.6184030786444874, lpl_weight=0.7381743901223683\n",
      " - ratio=0.15598843665096057, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0450, LPL: 1.3863, Contrastive: 0.0828\n",
      " - Metrics: Accuracy=0.8973, F1=0.8634, Recall=0.8123, Precision=0.9214\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4588033603752675, K=33, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.25490414171750325, margin=0.6184030786444874, lpl_weight=0.7381743901223683\n",
      " - ratio=0.15598843665096057, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0450, LPL: 1.3863, Contrastive: 0.0828\n",
      " - Metrics: Accuracy=0.8966, F1=0.8617, Recall=0.8060, Precision=0.9256\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4588033603752675, K=33, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.25490414171750325, margin=0.6184030786444874, lpl_weight=0.7381743901223683\n",
      " - ratio=0.15598843665096057, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0450, LPL: 1.3863, Contrastive: 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:25:22,056] Trial 38 finished with value: 0.8607706009664486 and parameters: {'alpha': 0.4588033603752675, 'K': 33, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.25490414171750325, 'margin': 0.6184030786444874, 'lpl_weight': 0.7381743901223683, 'ratio': 0.15598843665096057, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8939, F1=0.8583, Recall=0.8043, Precision=0.9200\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102192333.csv.\n",
      "Average F1 over 5 seeds: 0.8608  0.0017\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8204719171245478, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3939395480858558, margin=0.8584070416827787, lpl_weight=0.8637785475445218\n",
      " - ratio=0.12279453318420006, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1983, LPL: 1.3863, Contrastive: 0.0059\n",
      "Epoch 50, Loss: 1.1982, LPL: 1.3863, Contrastive: 0.0051\n",
      "Epoch 100, Loss: 1.1981, LPL: 1.3863, Contrastive: 0.0051\n",
      " - Metrics: Accuracy=0.8642, F1=0.8039, Recall=0.6969, Precision=0.9496\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8204719171245478, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3939395480858558, margin=0.8584070416827787, lpl_weight=0.8637785475445218\n",
      " - ratio=0.12279453318420006, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1983, LPL: 1.3863, Contrastive: 0.0059\n",
      "Epoch 50, Loss: 1.1982, LPL: 1.3863, Contrastive: 0.0051\n",
      "Epoch 100, Loss: 1.1981, LPL: 1.3863, Contrastive: 0.0051\n",
      " - Metrics: Accuracy=0.8626, F1=0.8018, Recall=0.6960, Precision=0.9455\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8204719171245478, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3939395480858558, margin=0.8584070416827787, lpl_weight=0.8637785475445218\n",
      " - ratio=0.12279453318420006, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1983, LPL: 1.3863, Contrastive: 0.0059\n",
      "Epoch 50, Loss: 1.1982, LPL: 1.3863, Contrastive: 0.0051\n",
      "Epoch 100, Loss: 1.1981, LPL: 1.3863, Contrastive: 0.0051\n",
      " - Metrics: Accuracy=0.8642, F1=0.8035, Recall=0.6954, Precision=0.9515\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8204719171245478, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3939395480858558, margin=0.8584070416827787, lpl_weight=0.8637785475445218\n",
      " - ratio=0.12279453318420006, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1983, LPL: 1.3863, Contrastive: 0.0059\n",
      "Epoch 50, Loss: 1.1982, LPL: 1.3863, Contrastive: 0.0051\n",
      "Epoch 100, Loss: 1.1981, LPL: 1.3863, Contrastive: 0.0051\n",
      " - Metrics: Accuracy=0.8666, F1=0.8077, Recall=0.7012, Precision=0.9522\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8204719171245478, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3939395480858558, margin=0.8584070416827787, lpl_weight=0.8637785475445218\n",
      " - ratio=0.12279453318420006, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1983, LPL: 1.3863, Contrastive: 0.0059\n",
      "Epoch 50, Loss: 1.1982, LPL: 1.3863, Contrastive: 0.0051\n",
      "Epoch 100, Loss: 1.1981, LPL: 1.3863, Contrastive: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:29:16,007] Trial 39 finished with value: 0.8045291293185477 and parameters: {'alpha': 0.8204719171245478, 'K': 34, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.3939395480858558, 'margin': 0.8584070416827787, 'lpl_weight': 0.8637785475445218, 'ratio': 0.12279453318420006, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8657, F1=0.8058, Recall=0.6977, Precision=0.9537\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102192522.csv.\n",
      "Average F1 over 5 seeds: 0.8045  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.39016985945306515, K=35, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.33934939857632657, margin=0.2803978732059837, lpl_weight=0.9175736717610383\n",
      " - ratio=0.49012793516805014, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2855, LPL: 1.3863, Contrastive: 0.1640\n",
      "Epoch 50, Loss: 1.2831, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 1.2831, LPL: 1.3863, Contrastive: 0.1342\n",
      " - Metrics: Accuracy=0.7685, F1=0.7659, Recall=0.9479, Precision=0.6425\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.39016985945306515, K=35, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.33934939857632657, margin=0.2803978732059837, lpl_weight=0.9175736717610383\n",
      " - ratio=0.49012793516805014, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2855, LPL: 1.3863, Contrastive: 0.1640\n",
      "Epoch 50, Loss: 1.2831, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 1.2831, LPL: 1.3863, Contrastive: 0.1337\n",
      " - Metrics: Accuracy=0.7652, F1=0.7625, Recall=0.9435, Precision=0.6397\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.39016985945306515, K=35, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.33934939857632657, margin=0.2803978732059837, lpl_weight=0.9175736717610383\n",
      " - ratio=0.49012793516805014, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2855, LPL: 1.3863, Contrastive: 0.1640\n",
      "Epoch 50, Loss: 1.2831, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 1.2831, LPL: 1.3863, Contrastive: 0.1341\n",
      " - Metrics: Accuracy=0.7696, F1=0.7667, Recall=0.9477, Precision=0.6437\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.39016985945306515, K=35, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.33934939857632657, margin=0.2803978732059837, lpl_weight=0.9175736717610383\n",
      " - ratio=0.49012793516805014, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2855, LPL: 1.3863, Contrastive: 0.1640\n",
      "Epoch 50, Loss: 1.2831, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 1.2831, LPL: 1.3863, Contrastive: 0.1338\n",
      " - Metrics: Accuracy=0.7623, F1=0.7594, Recall=0.9393, Precision=0.6373\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.39016985945306515, K=35, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.33934939857632657, margin=0.2803978732059837, lpl_weight=0.9175736717610383\n",
      " - ratio=0.49012793516805014, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2855, LPL: 1.3863, Contrastive: 0.1640\n",
      "Epoch 50, Loss: 1.2831, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 1.2835, LPL: 1.3863, Contrastive: 0.1397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:31:50,528] Trial 40 finished with value: 0.7635562553852437 and parameters: {'alpha': 0.39016985945306515, 'K': 35, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': None, 'dropout': 0.33934939857632657, 'margin': 0.2803978732059837, 'lpl_weight': 0.9175736717610383, 'ratio': 0.49012793516805014, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7662, F1=0.7634, Recall=0.9440, Precision=0.6408\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102192916.csv.\n",
      "Average F1 over 5 seeds: 0.7636  0.0026\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.24522470729452986, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.354930032749189, margin=0.1384979553653943, lpl_weight=0.52269236122648\n",
      " - ratio=0.22668193448720078, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8215, LPL: 1.3863, Contrastive: 0.2031\n",
      "Epoch 50, Loss: 0.8153, LPL: 1.3863, Contrastive: 0.1901\n",
      " - Metrics: Accuracy=0.8995, F1=0.8718, Recall=0.8555, Precision=0.8887\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.24522470729452986, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.354930032749189, margin=0.1384979553653943, lpl_weight=0.52269236122648\n",
      " - ratio=0.22668193448720078, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8215, LPL: 1.3863, Contrastive: 0.2031\n",
      "Epoch 50, Loss: 0.8153, LPL: 1.3863, Contrastive: 0.1901\n",
      " - Metrics: Accuracy=0.8963, F1=0.8676, Recall=0.8502, Precision=0.8857\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.24522470729452986, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.354930032749189, margin=0.1384979553653943, lpl_weight=0.52269236122648\n",
      " - ratio=0.22668193448720078, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8215, LPL: 1.3863, Contrastive: 0.2031\n",
      "Epoch 50, Loss: 0.8153, LPL: 1.3863, Contrastive: 0.1901\n",
      " - Metrics: Accuracy=0.8986, F1=0.8705, Recall=0.8533, Precision=0.8883\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.24522470729452986, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.354930032749189, margin=0.1384979553653943, lpl_weight=0.52269236122648\n",
      " - ratio=0.22668193448720078, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8215, LPL: 1.3863, Contrastive: 0.2031\n",
      "Epoch 50, Loss: 0.8153, LPL: 1.3863, Contrastive: 0.1901\n",
      " - Metrics: Accuracy=0.8972, F1=0.8687, Recall=0.8512, Precision=0.8869\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.24522470729452986, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.354930032749189, margin=0.1384979553653943, lpl_weight=0.52269236122648\n",
      " - ratio=0.22668193448720078, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8215, LPL: 1.3863, Contrastive: 0.2031\n",
      "Epoch 50, Loss: 0.8153, LPL: 1.3863, Contrastive: 0.1901\n",
      "Epoch 100, Loss: 0.8161, LPL: 1.3863, Contrastive: 0.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:34:28,191] Trial 41 finished with value: 0.8685531402172277 and parameters: {'alpha': 0.24522470729452986, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.354930032749189, 'margin': 0.1384979553653943, 'lpl_weight': 0.52269236122648, 'ratio': 0.22668193448720078, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8938, F1=0.8643, Recall=0.8465, Precision=0.8829\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102193150.csv.\n",
      "Average F1 over 5 seeds: 0.8686  0.0026\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.25449270706914956, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.297262532462752, margin=0.20420396116996298, lpl_weight=0.7766392377170065\n",
      " - ratio=0.18411696581407255, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1161, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 50, Loss: 1.1129, LPL: 1.3863, Contrastive: 0.1624\n",
      " - Metrics: Accuracy=0.8971, F1=0.8634, Recall=0.8146, Precision=0.9185\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.25449270706914956, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.297262532462752, margin=0.20420396116996298, lpl_weight=0.7766392377170065\n",
      " - ratio=0.18411696581407255, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1161, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 50, Loss: 1.1129, LPL: 1.3863, Contrastive: 0.1624\n",
      " - Metrics: Accuracy=0.8990, F1=0.8652, Recall=0.8119, Precision=0.9260\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.25449270706914956, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.297262532462752, margin=0.20420396116996298, lpl_weight=0.7766392377170065\n",
      " - ratio=0.18411696581407255, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1161, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 50, Loss: 1.1129, LPL: 1.3863, Contrastive: 0.1624\n",
      " - Metrics: Accuracy=0.8994, F1=0.8658, Recall=0.8126, Precision=0.9266\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.25449270706914956, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.297262532462752, margin=0.20420396116996298, lpl_weight=0.7766392377170065\n",
      " - ratio=0.18411696581407255, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1161, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 50, Loss: 1.1129, LPL: 1.3863, Contrastive: 0.1624\n",
      " - Metrics: Accuracy=0.8980, F1=0.8644, Recall=0.8142, Precision=0.9213\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.25449270706914956, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.297262532462752, margin=0.20420396116996298, lpl_weight=0.7766392377170065\n",
      " - ratio=0.18411696581407255, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1161, LPL: 1.3863, Contrastive: 0.1766\n",
      "Epoch 50, Loss: 1.1129, LPL: 1.3863, Contrastive: 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:37:03,392] Trial 42 finished with value: 0.8637303185838453 and parameters: {'alpha': 0.25449270706914956, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.297262532462752, 'margin': 0.20420396116996298, 'lpl_weight': 0.7766392377170065, 'ratio': 0.18411696581407255, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8941, F1=0.8597, Recall=0.8127, Precision=0.9125\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102193428.csv.\n",
      "Average F1 over 5 seeds: 0.8637  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3423972978018683, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3421189615777172, margin=0.15564977728149906, lpl_weight=0.5804285194927092\n",
      " - ratio=0.14771121438457344, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8869, LPL: 1.3863, Contrastive: 0.1959\n",
      "Epoch 50, Loss: 0.8812, LPL: 1.3863, Contrastive: 0.1825\n",
      " - Metrics: Accuracy=0.8933, F1=0.8544, Recall=0.7836, Precision=0.9391\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3423972978018683, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3421189615777172, margin=0.15564977728149906, lpl_weight=0.5804285194927092\n",
      " - ratio=0.14771121438457344, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8869, LPL: 1.3863, Contrastive: 0.1959\n",
      "Epoch 50, Loss: 0.8812, LPL: 1.3863, Contrastive: 0.1825\n",
      " - Metrics: Accuracy=0.8938, F1=0.8548, Recall=0.7825, Precision=0.9419\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3423972978018683, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3421189615777172, margin=0.15564977728149906, lpl_weight=0.5804285194927092\n",
      " - ratio=0.14771121438457344, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8869, LPL: 1.3863, Contrastive: 0.1959\n",
      "Epoch 50, Loss: 0.8812, LPL: 1.3863, Contrastive: 0.1825\n",
      " - Metrics: Accuracy=0.8981, F1=0.8609, Recall=0.7897, Precision=0.9463\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3423972978018683, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3421189615777172, margin=0.15564977728149906, lpl_weight=0.5804285194927092\n",
      " - ratio=0.14771121438457344, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8869, LPL: 1.3863, Contrastive: 0.1959\n",
      "Epoch 50, Loss: 0.8812, LPL: 1.3863, Contrastive: 0.1825\n",
      " - Metrics: Accuracy=0.8951, F1=0.8565, Recall=0.7843, Precision=0.9435\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3423972978018683, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3421189615777172, margin=0.15564977728149906, lpl_weight=0.5804285194927092\n",
      " - ratio=0.14771121438457344, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8869, LPL: 1.3863, Contrastive: 0.1959\n",
      "Epoch 50, Loss: 0.8812, LPL: 1.3863, Contrastive: 0.1825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:39:41,705] Trial 43 finished with value: 0.8568409823648718 and parameters: {'alpha': 0.3423972978018683, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3421189615777172, 'margin': 0.15564977728149906, 'lpl_weight': 0.5804285194927092, 'ratio': 0.14771121438457344, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8956, F1=0.8576, Recall=0.7870, Precision=0.9419\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102193703.csv.\n",
      "Average F1 over 5 seeds: 0.8568  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4423180516287843, K=35, layers=3, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.38295255594851974, margin=0.21590113156855267, lpl_weight=0.5310295048368994\n",
      " - ratio=0.2158038835834677, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8158, LPL: 1.3863, Contrastive: 0.1697\n",
      "Epoch 50, Loss: 0.8117, LPL: 1.3863, Contrastive: 0.1611\n",
      " - Metrics: Accuracy=0.8743, F1=0.8438, Recall=0.8497, Precision=0.8379\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4423180516287843, K=35, layers=3, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.38295255594851974, margin=0.21590113156855267, lpl_weight=0.5310295048368994\n",
      " - ratio=0.2158038835834677, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8158, LPL: 1.3863, Contrastive: 0.1697\n",
      "Epoch 50, Loss: 0.8116, LPL: 1.3863, Contrastive: 0.1609\n",
      " - Metrics: Accuracy=0.8838, F1=0.8532, Recall=0.8460, Precision=0.8606\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4423180516287843, K=35, layers=3, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.38295255594851974, margin=0.21590113156855267, lpl_weight=0.5310295048368994\n",
      " - ratio=0.2158038835834677, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8158, LPL: 1.3863, Contrastive: 0.1697\n",
      "Epoch 50, Loss: 0.8111, LPL: 1.3863, Contrastive: 0.1599\n",
      " - Metrics: Accuracy=0.8764, F1=0.8454, Recall=0.8462, Precision=0.8445\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4423180516287843, K=35, layers=3, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.38295255594851974, margin=0.21590113156855267, lpl_weight=0.5310295048368994\n",
      " - ratio=0.2158038835834677, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8158, LPL: 1.3863, Contrastive: 0.1697\n",
      "Epoch 50, Loss: 0.8118, LPL: 1.3863, Contrastive: 0.1612\n",
      " - Metrics: Accuracy=0.8849, F1=0.8555, Recall=0.8536, Precision=0.8575\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4423180516287843, K=35, layers=3, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.38295255594851974, margin=0.21590113156855267, lpl_weight=0.5310295048368994\n",
      " - ratio=0.2158038835834677, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.8158, LPL: 1.3863, Contrastive: 0.1697\n",
      "Epoch 50, Loss: 0.8111, LPL: 1.3863, Contrastive: 0.1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:42:05,270] Trial 44 finished with value: 0.8512365875764821 and parameters: {'alpha': 0.4423180516287843, 'K': 35, 'layers': 3, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.38295255594851974, 'margin': 0.21590113156855267, 'lpl_weight': 0.5310295048368994, 'ratio': 0.2158038835834677, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8874, F1=0.8583, Recall=0.8541, Precision=0.8625\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102193941.csv.\n",
      "Average F1 over 5 seeds: 0.8512  0.0057\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6221708417527005, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.4180497437619611, margin=0.1287810814344722, lpl_weight=0.6375099770861594\n",
      " - ratio=0.2487383232636047, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9591, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 50, Loss: 0.9542, LPL: 1.3863, Contrastive: 0.1943\n",
      " - Metrics: Accuracy=0.8926, F1=0.8656, Recall=0.8660, Precision=0.8652\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6221708417527005, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.4180497437619611, margin=0.1287810814344722, lpl_weight=0.6375099770861594\n",
      " - ratio=0.2487383232636047, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9591, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 50, Loss: 0.9542, LPL: 1.3863, Contrastive: 0.1943\n",
      " - Metrics: Accuracy=0.8902, F1=0.8626, Recall=0.8629, Precision=0.8623\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6221708417527005, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.4180497437619611, margin=0.1287810814344722, lpl_weight=0.6375099770861594\n",
      " - ratio=0.2487383232636047, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9591, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 50, Loss: 0.9542, LPL: 1.3863, Contrastive: 0.1943\n",
      " - Metrics: Accuracy=0.8915, F1=0.8644, Recall=0.8655, Precision=0.8632\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6221708417527005, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.4180497437619611, margin=0.1287810814344722, lpl_weight=0.6375099770861594\n",
      " - ratio=0.2487383232636047, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9591, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 50, Loss: 0.9542, LPL: 1.3863, Contrastive: 0.1943\n",
      " - Metrics: Accuracy=0.8933, F1=0.8665, Recall=0.8669, Precision=0.8660\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6221708417527005, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.4180497437619611, margin=0.1287810814344722, lpl_weight=0.6375099770861594\n",
      " - ratio=0.2487383232636047, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9591, LPL: 1.3863, Contrastive: 0.2078\n",
      "Epoch 50, Loss: 0.9542, LPL: 1.3863, Contrastive: 0.1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:44:42,251] Trial 45 finished with value: 0.8648270493989383 and parameters: {'alpha': 0.6221708417527005, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.4180497437619611, 'margin': 0.1287810814344722, 'lpl_weight': 0.6375099770861594, 'ratio': 0.2487383232636047, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8920, F1=0.8651, Recall=0.8669, Precision=0.8633\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102194205.csv.\n",
      "Average F1 over 5 seeds: 0.8648  0.0013\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.21676566579893783, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.31609202624545657, margin=0.25620246041407974, lpl_weight=0.6780609481466504\n",
      " - ratio=0.2863699624112641, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9920, LPL: 1.3863, Contrastive: 0.1616\n",
      "Epoch 50, Loss: 0.9857, LPL: 1.3863, Contrastive: 0.1421\n",
      "Epoch 100, Loss: 1.0027, LPL: 1.3863, Contrastive: 0.1949\n",
      " - Metrics: Accuracy=0.8784, F1=0.8536, Recall=0.8872, Precision=0.8224\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.21676566579893783, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.31609202624545657, margin=0.25620246041407974, lpl_weight=0.6780609481466504\n",
      " - ratio=0.2863699624112641, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9920, LPL: 1.3863, Contrastive: 0.1616\n",
      "Epoch 50, Loss: 0.9857, LPL: 1.3863, Contrastive: 0.1421\n",
      "Epoch 100, Loss: 1.0042, LPL: 1.3863, Contrastive: 0.1993\n",
      " - Metrics: Accuracy=0.8697, F1=0.8430, Recall=0.8756, Precision=0.8127\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.21676566579893783, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.31609202624545657, margin=0.25620246041407974, lpl_weight=0.6780609481466504\n",
      " - ratio=0.2863699624112641, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9920, LPL: 1.3863, Contrastive: 0.1616\n",
      "Epoch 50, Loss: 0.9857, LPL: 1.3863, Contrastive: 0.1421\n",
      "Epoch 100, Loss: 0.9992, LPL: 1.3863, Contrastive: 0.1839\n",
      " - Metrics: Accuracy=0.8834, F1=0.8596, Recall=0.8935, Precision=0.8282\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.21676566579893783, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.31609202624545657, margin=0.25620246041407974, lpl_weight=0.6780609481466504\n",
      " - ratio=0.2863699624112641, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9920, LPL: 1.3863, Contrastive: 0.1616\n",
      "Epoch 50, Loss: 0.9857, LPL: 1.3863, Contrastive: 0.1421\n",
      "Epoch 100, Loss: 0.9992, LPL: 1.3863, Contrastive: 0.1839\n",
      " - Metrics: Accuracy=0.8842, F1=0.8605, Recall=0.8942, Precision=0.8293\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.21676566579893783, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.31609202624545657, margin=0.25620246041407974, lpl_weight=0.6780609481466504\n",
      " - ratio=0.2863699624112641, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9920, LPL: 1.3863, Contrastive: 0.1616\n",
      "Epoch 50, Loss: 0.9857, LPL: 1.3863, Contrastive: 0.1421\n",
      "Epoch 100, Loss: 0.9912, LPL: 1.3863, Contrastive: 0.1589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:47:50,938] Trial 46 finished with value: 0.8545190959434077 and parameters: {'alpha': 0.21676566579893783, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.31609202624545657, 'margin': 0.25620246041407974, 'lpl_weight': 0.6780609481466504, 'ratio': 0.2863699624112641, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8807, F1=0.8560, Recall=0.8879, Precision=0.8263\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102194442.csv.\n",
      "Average F1 over 5 seeds: 0.8545  0.0063\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1636456511761546, K=28, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.44263941863710865, margin=0.3265200876525105, lpl_weight=0.9411381823249618\n",
      " - ratio=0.25124281150142813, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3159, LPL: 1.3863, Contrastive: 0.1910\n",
      "Epoch 50, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1180\n",
      "Epoch 100, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1166\n",
      " - Metrics: Accuracy=0.8728, F1=0.8399, Recall=0.8357, Precision=0.8443\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1636456511761546, K=28, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.44263941863710865, margin=0.3265200876525105, lpl_weight=0.9411381823249618\n",
      " - ratio=0.25124281150142813, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3159, LPL: 1.3863, Contrastive: 0.1910\n",
      "Epoch 50, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1180\n",
      "Epoch 100, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1174\n",
      " - Metrics: Accuracy=0.8701, F1=0.8357, Recall=0.8272, Precision=0.8443\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1636456511761546, K=28, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.44263941863710865, margin=0.3265200876525105, lpl_weight=0.9411381823249618\n",
      " - ratio=0.25124281150142813, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3159, LPL: 1.3863, Contrastive: 0.1910\n",
      "Epoch 50, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1180\n",
      "Epoch 100, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1176\n",
      " - Metrics: Accuracy=0.8771, F1=0.8443, Recall=0.8345, Precision=0.8543\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1636456511761546, K=28, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.44263941863710865, margin=0.3265200876525105, lpl_weight=0.9411381823249618\n",
      " - ratio=0.25124281150142813, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3159, LPL: 1.3863, Contrastive: 0.1910\n",
      "Epoch 50, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1180\n",
      "Epoch 100, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1166\n",
      " - Metrics: Accuracy=0.8928, F1=0.8627, Recall=0.8432, Precision=0.8831\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1636456511761546, K=28, layers=1, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.44263941863710865, margin=0.3265200876525105, lpl_weight=0.9411381823249618\n",
      " - ratio=0.25124281150142813, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3159, LPL: 1.3863, Contrastive: 0.1910\n",
      "Epoch 50, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1180\n",
      "Epoch 100, Loss: 1.3116, LPL: 1.3863, Contrastive: 0.1168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:50:22,717] Trial 47 finished with value: 0.84801516362035 and parameters: {'alpha': 0.1636456511761546, 'K': 28, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.44263941863710865, 'margin': 0.3265200876525105, 'lpl_weight': 0.9411381823249618, 'ratio': 0.25124281150142813, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8880, F1=0.8575, Recall=0.8436, Precision=0.8719\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102194751.csv.\n",
      "Average F1 over 5 seeds: 0.8480  0.0104\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5418649928183584, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.4712234044151848, margin=0.49146263864232076, lpl_weight=0.8636898476530639\n",
      " - ratio=0.16100766801806152, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2153, LPL: 1.3863, Contrastive: 0.1317\n",
      " - Metrics: Accuracy=0.8902, F1=0.8527, Recall=0.7952, Precision=0.9191\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5418649928183584, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.4712234044151848, margin=0.49146263864232076, lpl_weight=0.8636898476530639\n",
      " - ratio=0.16100766801806152, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2153, LPL: 1.3863, Contrastive: 0.1317\n",
      " - Metrics: Accuracy=0.8865, F1=0.8470, Recall=0.7860, Precision=0.9181\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5418649928183584, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.4712234044151848, margin=0.49146263864232076, lpl_weight=0.8636898476530639\n",
      " - ratio=0.16100766801806152, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2153, LPL: 1.3863, Contrastive: 0.1317\n",
      " - Metrics: Accuracy=0.8886, F1=0.8497, Recall=0.7883, Precision=0.9213\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5418649928183584, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.4712234044151848, margin=0.49146263864232076, lpl_weight=0.8636898476530639\n",
      " - ratio=0.16100766801806152, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2153, LPL: 1.3863, Contrastive: 0.1317\n",
      " - Metrics: Accuracy=0.8876, F1=0.8483, Recall=0.7865, Precision=0.9205\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5418649928183584, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.4712234044151848, margin=0.49146263864232076, lpl_weight=0.8636898476530639\n",
      " - ratio=0.16100766801806152, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2153, LPL: 1.3863, Contrastive: 0.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:52:25,623] Trial 48 finished with value: 0.8487383206548911 and parameters: {'alpha': 0.5418649928183584, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.4712234044151848, 'margin': 0.49146263864232076, 'lpl_weight': 0.8636898476530639, 'ratio': 0.16100766801806152, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8862, F1=0.8461, Recall=0.7832, Precision=0.9200\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102195022.csv.\n",
      "Average F1 over 5 seeds: 0.8487  0.0023\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2996158017024331, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.26104594893162225, margin=0.18986715507677804, lpl_weight=0.36238673799233323\n",
      " - ratio=0.21947906861102798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6184, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.6097, LPL: 1.3863, Contrastive: 0.1683\n",
      " - Metrics: Accuracy=0.9003, F1=0.8729, Recall=0.8568, Precision=0.8896\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2996158017024331, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.26104594893162225, margin=0.18986715507677804, lpl_weight=0.36238673799233323\n",
      " - ratio=0.21947906861102798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6184, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.6097, LPL: 1.3863, Contrastive: 0.1683\n",
      " - Metrics: Accuracy=0.8963, F1=0.8676, Recall=0.8509, Precision=0.8850\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2996158017024331, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.26104594893162225, margin=0.18986715507677804, lpl_weight=0.36238673799233323\n",
      " - ratio=0.21947906861102798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6184, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.6097, LPL: 1.3863, Contrastive: 0.1683\n",
      " - Metrics: Accuracy=0.8998, F1=0.8720, Recall=0.8550, Precision=0.8898\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2996158017024331, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.26104594893162225, margin=0.18986715507677804, lpl_weight=0.36238673799233323\n",
      " - ratio=0.21947906861102798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6184, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.6097, LPL: 1.3863, Contrastive: 0.1683\n",
      " - Metrics: Accuracy=0.8978, F1=0.8693, Recall=0.8516, Precision=0.8879\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2996158017024331, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.26104594893162225, margin=0.18986715507677804, lpl_weight=0.36238673799233323\n",
      " - ratio=0.21947906861102798, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6184, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.6097, LPL: 1.3863, Contrastive: 0.1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:55:11,651] Trial 49 finished with value: 0.8691800620299386 and parameters: {'alpha': 0.2996158017024331, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.26104594893162225, 'margin': 0.18986715507677804, 'lpl_weight': 0.36238673799233323, 'ratio': 0.21947906861102798, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8933, F1=0.8640, Recall=0.8485, Precision=0.8801\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102195225.csv.\n",
      "Average F1 over 5 seeds: 0.8692  0.0032\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3023613188423666, K=34, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.2574966287142945, margin=0.4250836590714022, lpl_weight=0.362183490342077\n",
      " - ratio=0.182683512923091, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5677, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 50, Loss: 0.5565, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 100, Loss: 0.5568, LPL: 1.3863, Contrastive: 0.0858\n",
      " - Metrics: Accuracy=0.9002, F1=0.8665, Recall=0.8112, Precision=0.9300\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3023613188423666, K=34, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.2574966287142945, margin=0.4250836590714022, lpl_weight=0.362183490342077\n",
      " - ratio=0.182683512923091, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5677, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 50, Loss: 0.5565, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 100, Loss: 0.5568, LPL: 1.3863, Contrastive: 0.0858\n",
      " - Metrics: Accuracy=0.8986, F1=0.8646, Recall=0.8109, Precision=0.9259\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3023613188423666, K=34, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.2574966287142945, margin=0.4250836590714022, lpl_weight=0.362183490342077\n",
      " - ratio=0.182683512923091, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5677, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 50, Loss: 0.5565, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 100, Loss: 0.5606, LPL: 1.3863, Contrastive: 0.0917\n",
      " - Metrics: Accuracy=0.8999, F1=0.8673, Recall=0.8194, Precision=0.9212\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3023613188423666, K=34, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.2574966287142945, margin=0.4250836590714022, lpl_weight=0.362183490342077\n",
      " - ratio=0.182683512923091, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5677, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 50, Loss: 0.5565, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 100, Loss: 0.5613, LPL: 1.3863, Contrastive: 0.0928\n",
      " - Metrics: Accuracy=0.8979, F1=0.8634, Recall=0.8080, Precision=0.9270\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3023613188423666, K=34, layers=1, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.2574966287142945, margin=0.4250836590714022, lpl_weight=0.362183490342077\n",
      " - ratio=0.182683512923091, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5677, LPL: 1.3863, Contrastive: 0.1029\n",
      "Epoch 50, Loss: 0.5565, LPL: 1.3863, Contrastive: 0.0853\n",
      "Epoch 100, Loss: 0.5581, LPL: 1.3863, Contrastive: 0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 19:58:33,139] Trial 50 finished with value: 0.8649753995731103 and parameters: {'alpha': 0.3023613188423666, 'K': 34, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.2574966287142945, 'margin': 0.4250836590714022, 'lpl_weight': 0.362183490342077, 'ratio': 0.182683512923091, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8973, F1=0.8630, Recall=0.8094, Precision=0.9242\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102195511.csv.\n",
      "Average F1 over 5 seeds: 0.8650  0.0017\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.27231737339085105, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21334953343099816, margin=0.19065741381495185, lpl_weight=0.25578660851092555\n",
      " - ratio=0.2250586948977386, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4899, LPL: 1.3863, Contrastive: 0.1818\n",
      "Epoch 50, Loss: 0.4795, LPL: 1.3863, Contrastive: 0.1678\n",
      " - Metrics: Accuracy=0.8948, F1=0.8657, Recall=0.8491, Precision=0.8830\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.27231737339085105, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21334953343099816, margin=0.19065741381495185, lpl_weight=0.25578660851092555\n",
      " - ratio=0.2250586948977386, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4899, LPL: 1.3863, Contrastive: 0.1818\n",
      "Epoch 50, Loss: 0.4795, LPL: 1.3863, Contrastive: 0.1678\n",
      " - Metrics: Accuracy=0.8897, F1=0.8597, Recall=0.8460, Precision=0.8738\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.27231737339085105, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21334953343099816, margin=0.19065741381495185, lpl_weight=0.25578660851092555\n",
      " - ratio=0.2250586948977386, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4899, LPL: 1.3863, Contrastive: 0.1818\n",
      "Epoch 50, Loss: 0.4795, LPL: 1.3863, Contrastive: 0.1678\n",
      " - Metrics: Accuracy=0.9040, F1=0.8772, Recall=0.8589, Precision=0.8964\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.27231737339085105, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21334953343099816, margin=0.19065741381495185, lpl_weight=0.25578660851092555\n",
      " - ratio=0.2250586948977386, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4899, LPL: 1.3863, Contrastive: 0.1818\n",
      "Epoch 50, Loss: 0.4795, LPL: 1.3863, Contrastive: 0.1678\n",
      " - Metrics: Accuracy=0.9013, F1=0.8742, Recall=0.8590, Precision=0.8899\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.27231737339085105, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21334953343099816, margin=0.19065741381495185, lpl_weight=0.25578660851092555\n",
      " - ratio=0.2250586948977386, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4899, LPL: 1.3863, Contrastive: 0.1818\n",
      "Epoch 50, Loss: 0.4795, LPL: 1.3863, Contrastive: 0.1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:01:09,135] Trial 51 finished with value: 0.8692912420624298 and parameters: {'alpha': 0.27231737339085105, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.21334953343099816, 'margin': 0.19065741381495185, 'lpl_weight': 0.25578660851092555, 'ratio': 0.2250586948977386, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8978, F1=0.8696, Recall=0.8536, Precision=0.8862\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102195833.csv.\n",
      "Average F1 over 5 seeds: 0.8693  0.0062\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3557540489242812, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21302224236732972, margin=0.19049635009127083, lpl_weight=0.2654127264902855\n",
      " - ratio=0.1996321654087723, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5015, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.4913, LPL: 1.3863, Contrastive: 0.1679\n",
      " - Metrics: Accuracy=0.9006, F1=0.8701, Recall=0.8337, Precision=0.9099\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3557540489242812, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21302224236732972, margin=0.19049635009127083, lpl_weight=0.2654127264902855\n",
      " - ratio=0.1996321654087723, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5015, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.4913, LPL: 1.3863, Contrastive: 0.1679\n",
      " - Metrics: Accuracy=0.9003, F1=0.8700, Recall=0.8353, Precision=0.9077\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3557540489242812, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21302224236732972, margin=0.19049635009127083, lpl_weight=0.2654127264902855\n",
      " - ratio=0.1996321654087723, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5015, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.4913, LPL: 1.3863, Contrastive: 0.1679\n",
      " - Metrics: Accuracy=0.9017, F1=0.8716, Recall=0.8350, Precision=0.9114\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3557540489242812, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21302224236732972, margin=0.19049635009127083, lpl_weight=0.2654127264902855\n",
      " - ratio=0.1996321654087723, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5015, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.4913, LPL: 1.3863, Contrastive: 0.1679\n",
      " - Metrics: Accuracy=0.8999, F1=0.8693, Recall=0.8338, Precision=0.9080\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3557540489242812, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.21302224236732972, margin=0.19049635009127083, lpl_weight=0.2654127264902855\n",
      " - ratio=0.1996321654087723, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5015, LPL: 1.3863, Contrastive: 0.1819\n",
      "Epoch 50, Loss: 0.4913, LPL: 1.3863, Contrastive: 0.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:03:45,299] Trial 52 finished with value: 0.8697753710428365 and parameters: {'alpha': 0.3557540489242812, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.21302224236732972, 'margin': 0.19049635009127083, 'lpl_weight': 0.2654127264902855, 'ratio': 0.1996321654087723, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8991, F1=0.8679, Recall=0.8300, Precision=0.9094\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102200109.csv.\n",
      "Average F1 over 5 seeds: 0.8698  0.0012\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.358245492783453, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.19296443667715635, margin=0.22788193805087512, lpl_weight=0.1882749133932064\n",
      " - ratio=0.27580270248747896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3965, LPL: 1.3863, Contrastive: 0.1670\n",
      "Epoch 50, Loss: 0.3853, LPL: 1.3863, Contrastive: 0.1531\n",
      " - Metrics: Accuracy=0.8841, F1=0.8591, Recall=0.8843, Precision=0.8352\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.358245492783453, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.19296443667715635, margin=0.22788193805087512, lpl_weight=0.1882749133932064\n",
      " - ratio=0.27580270248747896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3965, LPL: 1.3863, Contrastive: 0.1670\n",
      "Epoch 50, Loss: 0.3853, LPL: 1.3863, Contrastive: 0.1531\n",
      " - Metrics: Accuracy=0.8779, F1=0.8514, Recall=0.8753, Precision=0.8287\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.358245492783453, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.19296443667715635, margin=0.22788193805087512, lpl_weight=0.1882749133932064\n",
      " - ratio=0.27580270248747896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3965, LPL: 1.3863, Contrastive: 0.1670\n",
      "Epoch 50, Loss: 0.3853, LPL: 1.3863, Contrastive: 0.1531\n",
      " - Metrics: Accuracy=0.8877, F1=0.8633, Recall=0.8879, Precision=0.8401\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.358245492783453, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.19296443667715635, margin=0.22788193805087512, lpl_weight=0.1882749133932064\n",
      " - ratio=0.27580270248747896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3965, LPL: 1.3863, Contrastive: 0.1670\n",
      "Epoch 50, Loss: 0.3853, LPL: 1.3863, Contrastive: 0.1531\n",
      " - Metrics: Accuracy=0.8878, F1=0.8635, Recall=0.8888, Precision=0.8396\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.358245492783453, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.19296443667715635, margin=0.22788193805087512, lpl_weight=0.1882749133932064\n",
      " - ratio=0.27580270248747896, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3965, LPL: 1.3863, Contrastive: 0.1670\n",
      "Epoch 50, Loss: 0.3853, LPL: 1.3863, Contrastive: 0.1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:06:27,239] Trial 53 finished with value: 0.8587110444557087 and parameters: {'alpha': 0.358245492783453, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.19296443667715635, 'margin': 0.22788193805087512, 'lpl_weight': 0.1882749133932064, 'ratio': 0.27580270248747896, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8819, F1=0.8563, Recall=0.8810, Precision=0.8330\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102200345.csv.\n",
      "Average F1 over 5 seeds: 0.8587  0.0046\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2838598341369865, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.16244771475754755, margin=0.17699801967973738, lpl_weight=0.28080567297056597\n",
      " - ratio=0.19752817136191647, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5249, LPL: 1.3863, Contrastive: 0.1886\n",
      "Epoch 50, Loss: 0.5140, LPL: 1.3863, Contrastive: 0.1734\n",
      " - Metrics: Accuracy=0.9028, F1=0.8734, Recall=0.8400, Precision=0.9097\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2838598341369865, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.16244771475754755, margin=0.17699801967973738, lpl_weight=0.28080567297056597\n",
      " - ratio=0.19752817136191647, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5249, LPL: 1.3863, Contrastive: 0.1886\n",
      "Epoch 50, Loss: 0.5140, LPL: 1.3863, Contrastive: 0.1734\n",
      " - Metrics: Accuracy=0.9010, F1=0.8720, Recall=0.8436, Precision=0.9023\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2838598341369865, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.16244771475754755, margin=0.17699801967973738, lpl_weight=0.28080567297056597\n",
      " - ratio=0.19752817136191647, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5249, LPL: 1.3863, Contrastive: 0.1886\n",
      "Epoch 50, Loss: 0.5140, LPL: 1.3863, Contrastive: 0.1734\n",
      " - Metrics: Accuracy=0.9013, F1=0.8714, Recall=0.8377, Precision=0.9079\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2838598341369865, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.16244771475754755, margin=0.17699801967973738, lpl_weight=0.28080567297056597\n",
      " - ratio=0.19752817136191647, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5249, LPL: 1.3863, Contrastive: 0.1886\n",
      "Epoch 50, Loss: 0.5140, LPL: 1.3863, Contrastive: 0.1734\n",
      " - Metrics: Accuracy=0.9059, F1=0.8775, Recall=0.8438, Precision=0.9139\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2838598341369865, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.16244771475754755, margin=0.17699801967973738, lpl_weight=0.28080567297056597\n",
      " - ratio=0.19752817136191647, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5249, LPL: 1.3863, Contrastive: 0.1886\n",
      "Epoch 50, Loss: 0.5140, LPL: 1.3863, Contrastive: 0.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:09:01,475] Trial 54 finished with value: 0.8725406446687483 and parameters: {'alpha': 0.2838598341369865, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.16244771475754755, 'margin': 0.17699801967973738, 'lpl_weight': 0.28080567297056597, 'ratio': 0.19752817136191647, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8986, F1=0.8684, Recall=0.8382, Precision=0.9009\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102200627.csv.\n",
      "Average F1 over 5 seeds: 0.8725  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.15611507894756882, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.13453661017322022, margin=0.9580220136659225, lpl_weight=0.2871173191450821\n",
      " - ratio=0.20608533599016238, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4537, LPL: 1.3863, Contrastive: 0.0780\n",
      " - Metrics: Accuracy=0.8634, F1=0.8225, Recall=0.7925, Precision=0.8548\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.15611507894756882, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.13453661017322022, margin=0.9580220136659225, lpl_weight=0.2871173191450821\n",
      " - ratio=0.20608533599016238, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4537, LPL: 1.3863, Contrastive: 0.0780\n",
      " - Metrics: Accuracy=0.8648, F1=0.8253, Recall=0.7995, Precision=0.8529\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.15611507894756882, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.13453661017322022, margin=0.9580220136659225, lpl_weight=0.2871173191450821\n",
      " - ratio=0.20608533599016238, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4537, LPL: 1.3863, Contrastive: 0.0780\n",
      " - Metrics: Accuracy=0.8652, F1=0.8254, Recall=0.7976, Precision=0.8551\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.15611507894756882, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.13453661017322022, margin=0.9580220136659225, lpl_weight=0.2871173191450821\n",
      " - ratio=0.20608533599016238, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4537, LPL: 1.3863, Contrastive: 0.0780\n",
      " - Metrics: Accuracy=0.8689, F1=0.8306, Recall=0.8043, Precision=0.8586\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.15611507894756882, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.13453661017322022, margin=0.9580220136659225, lpl_weight=0.2871173191450821\n",
      " - ratio=0.20608533599016238, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4537, LPL: 1.3863, Contrastive: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:11:09,768] Trial 55 finished with value: 0.8259570826436029 and parameters: {'alpha': 0.15611507894756882, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.13453661017322022, 'margin': 0.9580220136659225, 'lpl_weight': 0.2871173191450821, 'ratio': 0.20608533599016238, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8658, F1=0.8260, Recall=0.7977, Precision=0.8564\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102200901.csv.\n",
      "Average F1 over 5 seeds: 0.8260  0.0026\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9550993283073252, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.16105738284311047, margin=0.10370756589321314, lpl_weight=0.16523921731862434\n",
      " - ratio=0.1914049076558119, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4107, LPL: 1.3863, Contrastive: 0.2176\n",
      "Epoch 50, Loss: 0.4001, LPL: 1.3863, Contrastive: 0.2049\n",
      " - Metrics: Accuracy=0.9057, F1=0.8771, Recall=0.8432, Precision=0.9140\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9550993283073252, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.16105738284311047, margin=0.10370756589321314, lpl_weight=0.16523921731862434\n",
      " - ratio=0.1914049076558119, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4107, LPL: 1.3863, Contrastive: 0.2176\n",
      "Epoch 50, Loss: 0.4001, LPL: 1.3863, Contrastive: 0.2049\n",
      " - Metrics: Accuracy=0.8995, F1=0.8692, Recall=0.8366, Precision=0.9046\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9550993283073252, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.16105738284311047, margin=0.10370756589321314, lpl_weight=0.16523921731862434\n",
      " - ratio=0.1914049076558119, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4107, LPL: 1.3863, Contrastive: 0.2176\n",
      "Epoch 50, Loss: 0.4001, LPL: 1.3863, Contrastive: 0.2049\n",
      " - Metrics: Accuracy=0.9031, F1=0.8737, Recall=0.8389, Precision=0.9115\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9550993283073252, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.16105738284311047, margin=0.10370756589321314, lpl_weight=0.16523921731862434\n",
      " - ratio=0.1914049076558119, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4107, LPL: 1.3863, Contrastive: 0.2176\n",
      "Epoch 50, Loss: 0.4001, LPL: 1.3863, Contrastive: 0.2049\n",
      " - Metrics: Accuracy=0.8992, F1=0.8681, Recall=0.8306, Precision=0.9092\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9550993283073252, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.16105738284311047, margin=0.10370756589321314, lpl_weight=0.16523921731862434\n",
      " - ratio=0.1914049076558119, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4107, LPL: 1.3863, Contrastive: 0.2176\n",
      "Epoch 50, Loss: 0.4001, LPL: 1.3863, Contrastive: 0.2049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:14:02,524] Trial 56 finished with value: 0.8711219699554802 and parameters: {'alpha': 0.9550993283073252, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.16105738284311047, 'margin': 0.10370756589321314, 'lpl_weight': 0.16523921731862434, 'ratio': 0.1914049076558119, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8983, F1=0.8674, Recall=0.8326, Precision=0.9052\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102201109.csv.\n",
      "Average F1 over 5 seeds: 0.8711  0.0037\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9635101729408904, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.10791945128139016, margin=0.1091485849751077, lpl_weight=0.16792189377534306\n",
      " - ratio=0.1900278169194019, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4128, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 0.4013, LPL: 1.3863, Contrastive: 0.2025\n",
      " - Metrics: Accuracy=0.8880, F1=0.8550, Recall=0.8267, Precision=0.8854\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9635101729408904, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.10791945128139016, margin=0.1091485849751077, lpl_weight=0.16792189377534306\n",
      " - ratio=0.1900278169194019, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4128, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 0.4013, LPL: 1.3863, Contrastive: 0.2025\n",
      " - Metrics: Accuracy=0.8942, F1=0.8636, Recall=0.8389, Precision=0.8899\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9635101729408904, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.10791945128139016, margin=0.1091485849751077, lpl_weight=0.16792189377534306\n",
      " - ratio=0.1900278169194019, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4128, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 0.4013, LPL: 1.3863, Contrastive: 0.2025\n",
      " - Metrics: Accuracy=0.8929, F1=0.8624, Recall=0.8401, Precision=0.8858\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9635101729408904, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.10791945128139016, margin=0.1091485849751077, lpl_weight=0.16792189377534306\n",
      " - ratio=0.1900278169194019, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4128, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 0.4013, LPL: 1.3863, Contrastive: 0.2025\n",
      " - Metrics: Accuracy=0.8989, F1=0.8689, Recall=0.8390, Precision=0.9010\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9635101729408904, K=34, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.10791945128139016, margin=0.1091485849751077, lpl_weight=0.16792189377534306\n",
      " - ratio=0.1900278169194019, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4128, LPL: 1.3863, Contrastive: 0.2164\n",
      "Epoch 50, Loss: 0.4013, LPL: 1.3863, Contrastive: 0.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:17:08,521] Trial 57 finished with value: 0.8578940081960749 and parameters: {'alpha': 0.9635101729408904, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.10791945128139016, 'margin': 0.1091485849751077, 'lpl_weight': 0.16792189377534306, 'ratio': 0.1900278169194019, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8761, F1=0.8396, Recall=0.8118, Precision=0.8693\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102201402.csv.\n",
      "Average F1 over 5 seeds: 0.8579  0.0102\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8823854869480405, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17097341018761802, margin=0.7191411205524483, lpl_weight=0.2319324418569389\n",
      " - ratio=0.14303781815740885, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3948, LPL: 1.3863, Contrastive: 0.0954\n",
      " - Metrics: Accuracy=0.8868, F1=0.8473, Recall=0.7864, Precision=0.9184\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8823854869480405, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17097341018761802, margin=0.7191411205524483, lpl_weight=0.2319324418569389\n",
      " - ratio=0.14303781815740885, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3948, LPL: 1.3863, Contrastive: 0.0954\n",
      " - Metrics: Accuracy=0.8827, F1=0.8409, Recall=0.7759, Precision=0.9178\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8823854869480405, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17097341018761802, margin=0.7191411205524483, lpl_weight=0.2319324418569389\n",
      " - ratio=0.14303781815740885, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3948, LPL: 1.3863, Contrastive: 0.0954\n",
      " - Metrics: Accuracy=0.8888, F1=0.8500, Recall=0.7892, Precision=0.9210\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8823854869480405, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17097341018761802, margin=0.7191411205524483, lpl_weight=0.2319324418569389\n",
      " - ratio=0.14303781815740885, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3948, LPL: 1.3863, Contrastive: 0.0954\n",
      " - Metrics: Accuracy=0.8851, F1=0.8441, Recall=0.7788, Precision=0.9214\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8823854869480405, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17097341018761802, margin=0.7191411205524483, lpl_weight=0.2319324418569389\n",
      " - ratio=0.14303781815740885, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.3948, LPL: 1.3863, Contrastive: 0.0954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:19:17,189] Trial 58 finished with value: 0.8454350882597572 and parameters: {'alpha': 0.8823854869480405, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.17097341018761802, 'margin': 0.7191411205524483, 'lpl_weight': 0.2319324418569389, 'ratio': 0.14303781815740885, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8852, F1=0.8448, Recall=0.7825, Precision=0.9179\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102201708.csv.\n",
      "Average F1 over 5 seeds: 0.8454  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4093387638551411, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.15395401849637125, margin=0.36710693822270396, lpl_weight=0.30230560060118594\n",
      " - ratio=0.10042397384108492, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5065, LPL: 1.3863, Contrastive: 0.1253\n",
      "Epoch 50, Loss: 0.4910, LPL: 1.3863, Contrastive: 0.1031\n",
      "Epoch 100, Loss: 0.5221, LPL: 1.3863, Contrastive: 0.1476\n",
      " - Metrics: Accuracy=0.8935, F1=0.8550, Recall=0.7863, Precision=0.9369\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4093387638551411, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.15395401849637125, margin=0.36710693822270396, lpl_weight=0.30230560060118594\n",
      " - ratio=0.10042397384108492, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5065, LPL: 1.3863, Contrastive: 0.1253\n",
      "Epoch 50, Loss: 0.4910, LPL: 1.3863, Contrastive: 0.1031\n",
      "Epoch 100, Loss: 0.5174, LPL: 1.3863, Contrastive: 0.1409\n",
      " - Metrics: Accuracy=0.8847, F1=0.8410, Recall=0.7639, Precision=0.9355\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4093387638551411, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.15395401849637125, margin=0.36710693822270396, lpl_weight=0.30230560060118594\n",
      " - ratio=0.10042397384108492, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5065, LPL: 1.3863, Contrastive: 0.1253\n",
      "Epoch 50, Loss: 0.4910, LPL: 1.3863, Contrastive: 0.1031\n",
      "Epoch 100, Loss: 0.5204, LPL: 1.3863, Contrastive: 0.1452\n",
      " - Metrics: Accuracy=0.8899, F1=0.8496, Recall=0.7783, Precision=0.9353\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4093387638551411, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.15395401849637125, margin=0.36710693822270396, lpl_weight=0.30230560060118594\n",
      " - ratio=0.10042397384108492, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5065, LPL: 1.3863, Contrastive: 0.1253\n",
      "Epoch 50, Loss: 0.4910, LPL: 1.3863, Contrastive: 0.1031\n",
      "Epoch 100, Loss: 0.5522, LPL: 1.3863, Contrastive: 0.1907\n",
      " - Metrics: Accuracy=0.8747, F1=0.8296, Recall=0.7637, Precision=0.9079\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4093387638551411, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.15395401849637125, margin=0.36710693822270396, lpl_weight=0.30230560060118594\n",
      " - ratio=0.10042397384108492, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5065, LPL: 1.3863, Contrastive: 0.1253\n",
      "Epoch 50, Loss: 0.4910, LPL: 1.3863, Contrastive: 0.1031\n",
      "Epoch 100, Loss: 0.5134, LPL: 1.3863, Contrastive: 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:22:29,732] Trial 59 finished with value: 0.844564910712918 and parameters: {'alpha': 0.4093387638551411, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.15395401849637125, 'margin': 0.36710693822270396, 'lpl_weight': 0.30230560060118594, 'ratio': 0.10042397384108492, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8885, F1=0.8476, Recall=0.7761, Precision=0.9336\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102201917.csv.\n",
      "Average F1 over 5 seeds: 0.8446  0.0087\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9320433637303075, K=35, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.16705027171368902, margin=0.15593662386629809, lpl_weight=0.13851395155977964\n",
      " - ratio=0.19783229398941615, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3699, LPL: 1.3863, Contrastive: 0.2065\n",
      "Epoch 50, Loss: 0.3539, LPL: 1.3863, Contrastive: 0.1879\n",
      "Epoch 100, Loss: 0.3865, LPL: 1.3863, Contrastive: 0.2257\n",
      " - Metrics: Accuracy=0.8957, F1=0.8654, Recall=0.8395, Precision=0.8930\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9320433637303075, K=35, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.16705027171368902, margin=0.15593662386629809, lpl_weight=0.13851395155977964\n",
      " - ratio=0.19783229398941615, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3699, LPL: 1.3863, Contrastive: 0.2065\n",
      "Epoch 50, Loss: 0.3539, LPL: 1.3863, Contrastive: 0.1879\n",
      "Epoch 100, Loss: 0.4936, LPL: 1.3863, Contrastive: 0.3501\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8305, F1=0.7849, Recall=0.7747, Precision=0.7954\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9320433637303075, K=35, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.16705027171368902, margin=0.15593662386629809, lpl_weight=0.13851395155977964\n",
      " - ratio=0.19783229398941615, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3699, LPL: 1.3863, Contrastive: 0.2065\n",
      "Epoch 50, Loss: 0.3537, LPL: 1.3863, Contrastive: 0.1877\n",
      " - Metrics: Accuracy=0.8478, F1=0.8076, Recall=0.7994, Precision=0.8159\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9320433637303075, K=35, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.16705027171368902, margin=0.15593662386629809, lpl_weight=0.13851395155977964\n",
      " - ratio=0.19783229398941615, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3699, LPL: 1.3863, Contrastive: 0.2065\n",
      "Epoch 50, Loss: 0.3538, LPL: 1.3863, Contrastive: 0.1878\n",
      " - Metrics: Accuracy=0.8699, F1=0.8334, Recall=0.8150, Precision=0.8527\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9320433637303075, K=35, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.16705027171368902, margin=0.15593662386629809, lpl_weight=0.13851395155977964\n",
      " - ratio=0.19783229398941615, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3699, LPL: 1.3863, Contrastive: 0.2065\n",
      "Epoch 50, Loss: 0.3540, LPL: 1.3863, Contrastive: 0.1880\n",
      "Epoch 100, Loss: 0.4844, LPL: 1.3863, Contrastive: 0.3393\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:28:43,228] Trial 60 finished with value: 0.8110090896209041 and parameters: {'alpha': 0.9320433637303075, 'K': 35, 'layers': 3, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.16705027171368902, 'margin': 0.15593662386629809, 'lpl_weight': 0.13851395155977964, 'ratio': 0.19783229398941615, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8129, F1=0.7637, Recall=0.7572, Precision=0.7703\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102202229.csv.\n",
      "Average F1 over 5 seeds: 0.8110  0.0358\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.27247088896586574, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22823919418040137, margin=0.18652330108073545, lpl_weight=0.26430104930498266\n",
      " - ratio=0.23660191160447633, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5125, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4930, LPL: 1.3863, Contrastive: 0.1721\n",
      "Epoch 100, Loss: 0.4912, LPL: 1.3863, Contrastive: 0.1696\n",
      " - Metrics: Accuracy=0.8966, F1=0.8696, Recall=0.8634, Precision=0.8759\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.27247088896586574, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22823919418040137, margin=0.18652330108073545, lpl_weight=0.26430104930498266\n",
      " - ratio=0.23660191160447633, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5125, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4930, LPL: 1.3863, Contrastive: 0.1721\n",
      " - Metrics: Accuracy=0.8958, F1=0.8683, Recall=0.8606, Precision=0.8763\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.27247088896586574, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22823919418040137, margin=0.18652330108073545, lpl_weight=0.26430104930498266\n",
      " - ratio=0.23660191160447633, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5125, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4930, LPL: 1.3863, Contrastive: 0.1721\n",
      " - Metrics: Accuracy=0.9013, F1=0.8752, Recall=0.8665, Precision=0.8839\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.27247088896586574, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22823919418040137, margin=0.18652330108073545, lpl_weight=0.26430104930498266\n",
      " - ratio=0.23660191160447633, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5125, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4930, LPL: 1.3863, Contrastive: 0.1721\n",
      " - Metrics: Accuracy=0.8941, F1=0.8662, Recall=0.8582, Precision=0.8744\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.27247088896586574, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22823919418040137, margin=0.18652330108073545, lpl_weight=0.26430104930498266\n",
      " - ratio=0.23660191160447633, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5125, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4930, LPL: 1.3863, Contrastive: 0.1721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:31:10,950] Trial 61 finished with value: 0.8697832733470268 and parameters: {'alpha': 0.27247088896586574, 'K': 35, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.22823919418040137, 'margin': 0.18652330108073545, 'lpl_weight': 0.26430104930498266, 'ratio': 0.23660191160447633, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8969, F1=0.8696, Recall=0.8606, Precision=0.8789\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102202843.csv.\n",
      "Average F1 over 5 seeds: 0.8698  0.0030\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.46248932697205825, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.23354747985030833, margin=0.131636455512848, lpl_weight=0.26110443358926494\n",
      " - ratio=0.24186892378160774, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5270, LPL: 1.3863, Contrastive: 0.2234\n",
      "Epoch 50, Loss: 0.5061, LPL: 1.3863, Contrastive: 0.1951\n",
      " - Metrics: Accuracy=0.8947, F1=0.8677, Recall=0.8641, Precision=0.8712\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.46248932697205825, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.23354747985030833, margin=0.131636455512848, lpl_weight=0.26110443358926494\n",
      " - ratio=0.24186892378160774, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5270, LPL: 1.3863, Contrastive: 0.2234\n",
      "Epoch 50, Loss: 0.5061, LPL: 1.3863, Contrastive: 0.1951\n",
      " - Metrics: Accuracy=0.8926, F1=0.8648, Recall=0.8603, Precision=0.8694\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.46248932697205825, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.23354747985030833, margin=0.131636455512848, lpl_weight=0.26110443358926494\n",
      " - ratio=0.24186892378160774, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5270, LPL: 1.3863, Contrastive: 0.2234\n",
      "Epoch 50, Loss: 0.5061, LPL: 1.3863, Contrastive: 0.1951\n",
      " - Metrics: Accuracy=0.8955, F1=0.8690, Recall=0.8677, Precision=0.8702\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.46248932697205825, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.23354747985030833, margin=0.131636455512848, lpl_weight=0.26110443358926494\n",
      " - ratio=0.24186892378160774, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5270, LPL: 1.3863, Contrastive: 0.2234\n",
      "Epoch 50, Loss: 0.5061, LPL: 1.3863, Contrastive: 0.1951\n",
      " - Metrics: Accuracy=0.8958, F1=0.8690, Recall=0.8650, Precision=0.8730\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.46248932697205825, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.23354747985030833, margin=0.131636455512848, lpl_weight=0.26110443358926494\n",
      " - ratio=0.24186892378160774, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5270, LPL: 1.3863, Contrastive: 0.2234\n",
      "Epoch 50, Loss: 0.5061, LPL: 1.3863, Contrastive: 0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:33:36,420] Trial 62 finished with value: 0.8676164263345788 and parameters: {'alpha': 0.46248932697205825, 'K': 35, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.23354747985030833, 'margin': 0.131636455512848, 'lpl_weight': 0.26110443358926494, 'ratio': 0.24186892378160774, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8947, F1=0.8677, Recall=0.8643, Precision=0.8711\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102203111.csv.\n",
      "Average F1 over 5 seeds: 0.8676  0.0015\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.32403770716065605, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.2152694234643498, margin=0.25971792214872047, lpl_weight=0.31957295817881404\n",
      " - ratio=0.261049851030585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5587, LPL: 1.3863, Contrastive: 0.1700\n",
      "Epoch 50, Loss: 0.5402, LPL: 1.3863, Contrastive: 0.1428\n",
      "Epoch 100, Loss: 0.5390, LPL: 1.3863, Contrastive: 0.1411\n",
      " - Metrics: Accuracy=0.8788, F1=0.8507, Recall=0.8644, Precision=0.8375\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.32403770716065605, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.2152694234643498, margin=0.25971792214872047, lpl_weight=0.31957295817881404\n",
      " - ratio=0.261049851030585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5587, LPL: 1.3863, Contrastive: 0.1700\n",
      "Epoch 50, Loss: 0.5402, LPL: 1.3863, Contrastive: 0.1428\n",
      "Epoch 100, Loss: 0.5390, LPL: 1.3863, Contrastive: 0.1411\n",
      " - Metrics: Accuracy=0.8747, F1=0.8458, Recall=0.8603, Precision=0.8317\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.32403770716065605, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.2152694234643498, margin=0.25971792214872047, lpl_weight=0.31957295817881404\n",
      " - ratio=0.261049851030585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5587, LPL: 1.3863, Contrastive: 0.1700\n",
      "Epoch 50, Loss: 0.5402, LPL: 1.3863, Contrastive: 0.1428\n",
      "Epoch 100, Loss: 0.5390, LPL: 1.3863, Contrastive: 0.1411\n",
      " - Metrics: Accuracy=0.8814, F1=0.8542, Recall=0.8698, Precision=0.8390\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.32403770716065605, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.2152694234643498, margin=0.25971792214872047, lpl_weight=0.31957295817881404\n",
      " - ratio=0.261049851030585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5587, LPL: 1.3863, Contrastive: 0.1700\n",
      "Epoch 50, Loss: 0.5402, LPL: 1.3863, Contrastive: 0.1428\n",
      "Epoch 100, Loss: 0.5390, LPL: 1.3863, Contrastive: 0.1411\n",
      " - Metrics: Accuracy=0.8815, F1=0.8540, Recall=0.8681, Precision=0.8404\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.32403770716065605, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.2152694234643498, margin=0.25971792214872047, lpl_weight=0.31957295817881404\n",
      " - ratio=0.261049851030585, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5587, LPL: 1.3863, Contrastive: 0.1700\n",
      "Epoch 50, Loss: 0.5402, LPL: 1.3863, Contrastive: 0.1428\n",
      "Epoch 100, Loss: 0.5390, LPL: 1.3863, Contrastive: 0.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:36:21,913] Trial 63 finished with value: 0.85140247760263 and parameters: {'alpha': 0.32403770716065605, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.2152694234643498, 'margin': 0.25971792214872047, 'lpl_weight': 0.31957295817881404, 'ratio': 0.261049851030585, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8801, F1=0.8523, Recall=0.8668, Precision=0.8384\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102203336.csv.\n",
      "Average F1 over 5 seeds: 0.8514  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3602891298178081, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1167049302801279, margin=0.16556025720074946, lpl_weight=0.2118704246070391\n",
      " - ratio=0.1620774717518845, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.2105\n",
      "Epoch 50, Loss: 0.4369, LPL: 1.3863, Contrastive: 0.1817\n",
      "Epoch 100, Loss: 0.4544, LPL: 1.3863, Contrastive: 0.2039\n",
      " - Metrics: Accuracy=0.9007, F1=0.8685, Recall=0.8212, Precision=0.9216\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3602891298178081, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1167049302801279, margin=0.16556025720074946, lpl_weight=0.2118704246070391\n",
      " - ratio=0.1620774717518845, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.2105\n",
      "Epoch 50, Loss: 0.4369, LPL: 1.3863, Contrastive: 0.1817\n",
      "Epoch 100, Loss: 0.4544, LPL: 1.3863, Contrastive: 0.2039\n",
      " - Metrics: Accuracy=0.8978, F1=0.8640, Recall=0.8126, Precision=0.9223\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3602891298178081, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1167049302801279, margin=0.16556025720074946, lpl_weight=0.2118704246070391\n",
      " - ratio=0.1620774717518845, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.2105\n",
      "Epoch 50, Loss: 0.4369, LPL: 1.3863, Contrastive: 0.1817\n",
      "Epoch 100, Loss: 0.4544, LPL: 1.3863, Contrastive: 0.2039\n",
      " - Metrics: Accuracy=0.8996, F1=0.8665, Recall=0.8163, Precision=0.9234\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3602891298178081, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1167049302801279, margin=0.16556025720074946, lpl_weight=0.2118704246070391\n",
      " - ratio=0.1620774717518845, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.2105\n",
      "Epoch 50, Loss: 0.4369, LPL: 1.3863, Contrastive: 0.1817\n",
      "Epoch 100, Loss: 0.4544, LPL: 1.3863, Contrastive: 0.2039\n",
      " - Metrics: Accuracy=0.8988, F1=0.8650, Recall=0.8116, Precision=0.9260\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3602891298178081, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1167049302801279, margin=0.16556025720074946, lpl_weight=0.2118704246070391\n",
      " - ratio=0.1620774717518845, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4596, LPL: 1.3863, Contrastive: 0.2105\n",
      "Epoch 50, Loss: 0.4369, LPL: 1.3863, Contrastive: 0.1817\n",
      "Epoch 100, Loss: 0.4544, LPL: 1.3863, Contrastive: 0.2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:38:57,395] Trial 64 finished with value: 0.8656853597328457 and parameters: {'alpha': 0.3602891298178081, 'K': 35, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.1167049302801279, 'margin': 0.16556025720074946, 'lpl_weight': 0.2118704246070391, 'ratio': 0.1620774717518845, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8980, F1=0.8644, Recall=0.8143, Precision=0.9210\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102203621.csv.\n",
      "Average F1 over 5 seeds: 0.8657  0.0017\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.27990876549273724, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.14844634580355398, margin=0.22187643682181923, lpl_weight=0.15498227365670764\n",
      " - ratio=0.19972593061133795, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3712, LPL: 1.3863, Contrastive: 0.1850\n",
      "Epoch 50, Loss: 0.3480, LPL: 1.3863, Contrastive: 0.1575\n",
      " - Metrics: Accuracy=0.8973, F1=0.8665, Recall=0.8339, Precision=0.9017\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.27990876549273724, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.14844634580355398, margin=0.22187643682181923, lpl_weight=0.15498227365670764\n",
      " - ratio=0.19972593061133795, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3712, LPL: 1.3863, Contrastive: 0.1850\n",
      "Epoch 50, Loss: 0.3480, LPL: 1.3863, Contrastive: 0.1575\n",
      " - Metrics: Accuracy=0.8966, F1=0.8653, Recall=0.8310, Precision=0.9025\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.27990876549273724, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.14844634580355398, margin=0.22187643682181923, lpl_weight=0.15498227365670764\n",
      " - ratio=0.19972593061133795, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3712, LPL: 1.3863, Contrastive: 0.1850\n",
      "Epoch 50, Loss: 0.3480, LPL: 1.3863, Contrastive: 0.1575\n",
      " - Metrics: Accuracy=0.9010, F1=0.8713, Recall=0.8391, Precision=0.9061\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.27990876549273724, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.14844634580355398, margin=0.22187643682181923, lpl_weight=0.15498227365670764\n",
      " - ratio=0.19972593061133795, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3712, LPL: 1.3863, Contrastive: 0.1850\n",
      "Epoch 50, Loss: 0.3480, LPL: 1.3863, Contrastive: 0.1575\n",
      " - Metrics: Accuracy=0.9001, F1=0.8697, Recall=0.8345, Precision=0.9079\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.27990876549273724, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.14844634580355398, margin=0.22187643682181923, lpl_weight=0.15498227365670764\n",
      " - ratio=0.19972593061133795, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3712, LPL: 1.3863, Contrastive: 0.1850\n",
      "Epoch 50, Loss: 0.3480, LPL: 1.3863, Contrastive: 0.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:41:24,545] Trial 65 finished with value: 0.8675665464160938 and parameters: {'alpha': 0.27990876549273724, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.14844634580355398, 'margin': 0.22187643682181923, 'lpl_weight': 0.15498227365670764, 'ratio': 0.19972593061133795, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8965, F1=0.8651, Recall=0.8312, Precision=0.9019\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102203857.csv.\n",
      "Average F1 over 5 seeds: 0.8676  0.0025\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.19839329682144385, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20135913899913954, margin=0.1308742629497795, lpl_weight=0.40690083401735433\n",
      " - ratio=0.21374517419284603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6974, LPL: 1.3863, Contrastive: 0.2248\n",
      "Epoch 50, Loss: 0.6807, LPL: 1.3863, Contrastive: 0.1967\n",
      " - Metrics: Accuracy=0.9016, F1=0.8735, Recall=0.8503, Precision=0.8979\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.19839329682144385, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20135913899913954, margin=0.1308742629497795, lpl_weight=0.40690083401735433\n",
      " - ratio=0.21374517419284603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6974, LPL: 1.3863, Contrastive: 0.2248\n",
      "Epoch 50, Loss: 0.6807, LPL: 1.3863, Contrastive: 0.1967\n",
      " - Metrics: Accuracy=0.8972, F1=0.8675, Recall=0.8424, Precision=0.8942\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.19839329682144385, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20135913899913954, margin=0.1308742629497795, lpl_weight=0.40690083401735433\n",
      " - ratio=0.21374517419284603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6974, LPL: 1.3863, Contrastive: 0.2248\n",
      "Epoch 50, Loss: 0.6807, LPL: 1.3863, Contrastive: 0.1967\n",
      "Epoch 100, Loss: 0.6791, LPL: 1.3863, Contrastive: 0.1939\n",
      "Epoch 150, Loss: 0.6792, LPL: 1.3863, Contrastive: 0.1941\n",
      " - Metrics: Accuracy=0.9032, F1=0.8750, Recall=0.8484, Precision=0.9034\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.19839329682144385, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20135913899913954, margin=0.1308742629497795, lpl_weight=0.40690083401735433\n",
      " - ratio=0.21374517419284603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6974, LPL: 1.3863, Contrastive: 0.2248\n",
      "Epoch 50, Loss: 0.6807, LPL: 1.3863, Contrastive: 0.1967\n",
      " - Metrics: Accuracy=0.9027, F1=0.8748, Recall=0.8508, Precision=0.9002\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.19839329682144385, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20135913899913954, margin=0.1308742629497795, lpl_weight=0.40690083401735433\n",
      " - ratio=0.21374517419284603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6974, LPL: 1.3863, Contrastive: 0.2248\n",
      "Epoch 50, Loss: 0.6807, LPL: 1.3863, Contrastive: 0.1967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:43:52,373] Trial 66 finished with value: 0.8723746408797304 and parameters: {'alpha': 0.19839329682144385, 'K': 33, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.20135913899913954, 'margin': 0.1308742629497795, 'lpl_weight': 0.40690083401735433, 'ratio': 0.21374517419284603, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8997, F1=0.8710, Recall=0.8483, Precision=0.8951\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102204124.csv.\n",
      "Average F1 over 5 seeds: 0.8724  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.13268585792649093, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1976659462181079, margin=0.10123033161357942, lpl_weight=0.1965901838686341\n",
      " - ratio=0.1912870857924978, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5887, LPL: 1.3863, Contrastive: 0.3935\n",
      " - Metrics: Accuracy=0.8803, F1=0.8417, Recall=0.7964, Precision=0.8923\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.13268585792649093, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1976659462181079, margin=0.10123033161357942, lpl_weight=0.1965901838686341\n",
      " - ratio=0.1912870857924978, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5887, LPL: 1.3863, Contrastive: 0.3935\n",
      " - Metrics: Accuracy=0.8784, F1=0.8394, Recall=0.7956, Precision=0.8884\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.13268585792649093, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1976659462181079, margin=0.10123033161357942, lpl_weight=0.1965901838686341\n",
      " - ratio=0.1912870857924978, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5887, LPL: 1.3863, Contrastive: 0.3935\n",
      " - Metrics: Accuracy=0.8844, F1=0.8473, Recall=0.8029, Precision=0.8969\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.13268585792649093, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1976659462181079, margin=0.10123033161357942, lpl_weight=0.1965901838686341\n",
      " - ratio=0.1912870857924978, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5887, LPL: 1.3863, Contrastive: 0.3935\n",
      " - Metrics: Accuracy=0.8791, F1=0.8401, Recall=0.7949, Precision=0.8907\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.13268585792649093, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.1976659462181079, margin=0.10123033161357942, lpl_weight=0.1965901838686341\n",
      " - ratio=0.1912870857924978, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5887, LPL: 1.3863, Contrastive: 0.3935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:45:55,229] Trial 67 finished with value: 0.8414964570344947 and parameters: {'alpha': 0.13268585792649093, 'K': 33, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.1976659462181079, 'margin': 0.10123033161357942, 'lpl_weight': 0.1965901838686341, 'ratio': 0.1912870857924978, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8782, F1=0.8390, Recall=0.7948, Precision=0.8884\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102204352.csv.\n",
      "Average F1 over 5 seeds: 0.8415  0.0030\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.22491298040591007, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18234292347495168, margin=0.2455887214700156, lpl_weight=0.33340757127090065\n",
      " - ratio=0.21669880965164995, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5790, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 0.5609, LPL: 1.3863, Contrastive: 0.1481\n",
      " - Metrics: Accuracy=0.9015, F1=0.8733, Recall=0.8500, Precision=0.8978\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.22491298040591007, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18234292347495168, margin=0.2455887214700156, lpl_weight=0.33340757127090065\n",
      " - ratio=0.21669880965164995, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5790, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 0.5609, LPL: 1.3863, Contrastive: 0.1481\n",
      " - Metrics: Accuracy=0.8973, F1=0.8679, Recall=0.8444, Precision=0.8926\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.22491298040591007, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18234292347495168, margin=0.2455887214700156, lpl_weight=0.33340757127090065\n",
      " - ratio=0.21669880965164995, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5790, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 0.5609, LPL: 1.3863, Contrastive: 0.1481\n",
      " - Metrics: Accuracy=0.9024, F1=0.8744, Recall=0.8504, Precision=0.8998\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.22491298040591007, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18234292347495168, margin=0.2455887214700156, lpl_weight=0.33340757127090065\n",
      " - ratio=0.21669880965164995, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5790, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 0.5609, LPL: 1.3863, Contrastive: 0.1481\n",
      " - Metrics: Accuracy=0.9007, F1=0.8723, Recall=0.8484, Precision=0.8975\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.22491298040591007, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18234292347495168, margin=0.2455887214700156, lpl_weight=0.33340757127090065\n",
      " - ratio=0.21669880965164995, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5790, LPL: 1.3863, Contrastive: 0.1753\n",
      "Epoch 50, Loss: 0.5609, LPL: 1.3863, Contrastive: 0.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:48:20,505] Trial 68 finished with value: 0.8721744664845005 and parameters: {'alpha': 0.22491298040591007, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.18234292347495168, 'margin': 0.2455887214700156, 'lpl_weight': 0.33340757127090065, 'ratio': 0.21669880965164995, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9014, F1=0.8731, Recall=0.8497, Precision=0.8979\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102204555.csv.\n",
      "Average F1 over 5 seeds: 0.8722  0.0023\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.20456125840403094, K=34, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.18251621989612918, margin=0.24696384764374096, lpl_weight=0.39974622199493753\n",
      " - ratio=0.2108183938960624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.1666\n",
      "Epoch 50, Loss: 0.6426, LPL: 1.3863, Contrastive: 0.1473\n",
      "Epoch 100, Loss: 0.6497, LPL: 1.3863, Contrastive: 0.1592\n",
      " - Metrics: Accuracy=0.9063, F1=0.8801, Recall=0.8611, Precision=0.8999\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.20456125840403094, K=34, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.18251621989612918, margin=0.24696384764374096, lpl_weight=0.39974622199493753\n",
      " - ratio=0.2108183938960624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.1666\n",
      "Epoch 50, Loss: 0.6426, LPL: 1.3863, Contrastive: 0.1473\n",
      " - Metrics: Accuracy=0.8895, F1=0.8584, Recall=0.8380, Precision=0.8797\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.20456125840403094, K=34, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.18251621989612918, margin=0.24696384764374096, lpl_weight=0.39974622199493753\n",
      " - ratio=0.2108183938960624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.1666\n",
      "Epoch 50, Loss: 0.6426, LPL: 1.3863, Contrastive: 0.1473\n",
      " - Metrics: Accuracy=0.8959, F1=0.8664, Recall=0.8450, Precision=0.8890\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.20456125840403094, K=34, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.18251621989612918, margin=0.24696384764374096, lpl_weight=0.39974622199493753\n",
      " - ratio=0.2108183938960624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.1666\n",
      "Epoch 50, Loss: 0.6426, LPL: 1.3863, Contrastive: 0.1473\n",
      " - Metrics: Accuracy=0.8974, F1=0.8689, Recall=0.8510, Precision=0.8874\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.20456125840403094, K=34, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.18251621989612918, margin=0.24696384764374096, lpl_weight=0.39974622199493753\n",
      " - ratio=0.2108183938960624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.1666\n",
      "Epoch 50, Loss: 0.6426, LPL: 1.3863, Contrastive: 0.1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:50:32,939] Trial 69 finished with value: 0.8679347574825542 and parameters: {'alpha': 0.20456125840403094, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.18251621989612918, 'margin': 0.24696384764374096, 'lpl_weight': 0.39974622199493753, 'ratio': 0.2108183938960624, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8949, F1=0.8660, Recall=0.8504, Precision=0.8821\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102204820.csv.\n",
      "Average F1 over 5 seeds: 0.8679  0.0070\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1856112732337955, K=30, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.16195453607679916, margin=0.2802041113030831, lpl_weight=0.33265609777217975\n",
      " - ratio=0.25881195099070214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5697, LPL: 1.3863, Contrastive: 0.1627\n",
      "Epoch 50, Loss: 0.5512, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 0.5514, LPL: 1.3863, Contrastive: 0.1352\n",
      " - Metrics: Accuracy=0.8855, F1=0.8588, Recall=0.8715, Precision=0.8464\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1856112732337955, K=30, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.16195453607679916, margin=0.2802041113030831, lpl_weight=0.33265609777217975\n",
      " - ratio=0.25881195099070214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5697, LPL: 1.3863, Contrastive: 0.1627\n",
      "Epoch 50, Loss: 0.5512, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 0.5544, LPL: 1.3863, Contrastive: 0.1397\n",
      " - Metrics: Accuracy=0.8865, F1=0.8595, Recall=0.8692, Precision=0.8501\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1856112732337955, K=30, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.16195453607679916, margin=0.2802041113030831, lpl_weight=0.33265609777217975\n",
      " - ratio=0.25881195099070214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5697, LPL: 1.3863, Contrastive: 0.1627\n",
      "Epoch 50, Loss: 0.5512, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 0.5544, LPL: 1.3863, Contrastive: 0.1397\n",
      " - Metrics: Accuracy=0.8903, F1=0.8646, Recall=0.8763, Precision=0.8531\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1856112732337955, K=30, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.16195453607679916, margin=0.2802041113030831, lpl_weight=0.33265609777217975\n",
      " - ratio=0.25881195099070214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5697, LPL: 1.3863, Contrastive: 0.1627\n",
      "Epoch 50, Loss: 0.5512, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 0.5544, LPL: 1.3863, Contrastive: 0.1397\n",
      " - Metrics: Accuracy=0.8922, F1=0.8670, Recall=0.8792, Precision=0.8550\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1856112732337955, K=30, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.16195453607679916, margin=0.2802041113030831, lpl_weight=0.33265609777217975\n",
      " - ratio=0.25881195099070214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5697, LPL: 1.3863, Contrastive: 0.1627\n",
      "Epoch 50, Loss: 0.5512, LPL: 1.3863, Contrastive: 0.1349\n",
      "Epoch 100, Loss: 0.5548, LPL: 1.3863, Contrastive: 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:53:04,300] Trial 70 finished with value: 0.861147929419084 and parameters: {'alpha': 0.1856112732337955, 'K': 30, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': None, 'dropout': 0.16195453607679916, 'margin': 0.2802041113030831, 'lpl_weight': 0.33265609777217975, 'ratio': 0.25881195099070214, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8833, F1=0.8559, Recall=0.8676, Precision=0.8445\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102205033.csv.\n",
      "Average F1 over 5 seeds: 0.8611  0.0040\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2171841244191305, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22001678509832698, margin=0.17182843263610875, lpl_weight=0.2760230273911791\n",
      " - ratio=0.23756978451492816, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5312, LPL: 1.3863, Contrastive: 0.2053\n",
      "Epoch 50, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1786\n",
      " - Metrics: Accuracy=0.8954, F1=0.8680, Recall=0.8610, Precision=0.8751\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2171841244191305, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22001678509832698, margin=0.17182843263610875, lpl_weight=0.2760230273911791\n",
      " - ratio=0.23756978451492816, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5312, LPL: 1.3863, Contrastive: 0.2053\n",
      "Epoch 50, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1786\n",
      " - Metrics: Accuracy=0.8909, F1=0.8622, Recall=0.8545, Precision=0.8701\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2171841244191305, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22001678509832698, margin=0.17182843263610875, lpl_weight=0.2760230273911791\n",
      " - ratio=0.23756978451492816, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5312, LPL: 1.3863, Contrastive: 0.2053\n",
      "Epoch 50, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1786\n",
      "Epoch 100, Loss: 0.5286, LPL: 1.3863, Contrastive: 0.2016\n",
      " - Metrics: Accuracy=0.8938, F1=0.8665, Recall=0.8626, Precision=0.8705\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2171841244191305, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22001678509832698, margin=0.17182843263610875, lpl_weight=0.2760230273911791\n",
      " - ratio=0.23756978451492816, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5312, LPL: 1.3863, Contrastive: 0.2053\n",
      "Epoch 50, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1786\n",
      " - Metrics: Accuracy=0.8956, F1=0.8682, Recall=0.8604, Precision=0.8760\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2171841244191305, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22001678509832698, margin=0.17182843263610875, lpl_weight=0.2760230273911791\n",
      " - ratio=0.23756978451492816, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5312, LPL: 1.3863, Contrastive: 0.2053\n",
      "Epoch 50, Loss: 0.5119, LPL: 1.3863, Contrastive: 0.1786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:55:31,201] Trial 71 finished with value: 0.8663060800127209 and parameters: {'alpha': 0.2171841244191305, 'K': 33, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.22001678509832698, 'margin': 0.17182843263610875, 'lpl_weight': 0.2760230273911791, 'ratio': 0.23756978451492816, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8945, F1=0.8667, Recall=0.8592, Precision=0.8744\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102205304.csv.\n",
      "Average F1 over 5 seeds: 0.8663  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.24576457506293065, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.13467540209101572, margin=0.20041911792610775, lpl_weight=0.38033342432213774\n",
      " - ratio=0.21668212549628685, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6477, LPL: 1.3863, Contrastive: 0.1944\n",
      "Epoch 50, Loss: 0.6301, LPL: 1.3863, Contrastive: 0.1660\n",
      "Epoch 100, Loss: 0.6288, LPL: 1.3863, Contrastive: 0.1639\n",
      " - Metrics: Accuracy=0.8922, F1=0.8625, Recall=0.8469, Precision=0.8788\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.24576457506293065, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.13467540209101572, margin=0.20041911792610775, lpl_weight=0.38033342432213774\n",
      " - ratio=0.21668212549628685, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6477, LPL: 1.3863, Contrastive: 0.1944\n",
      "Epoch 50, Loss: 0.6301, LPL: 1.3863, Contrastive: 0.1660\n",
      "Epoch 100, Loss: 0.6287, LPL: 1.3863, Contrastive: 0.1637\n",
      " - Metrics: Accuracy=0.8962, F1=0.8672, Recall=0.8483, Precision=0.8870\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.24576457506293065, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.13467540209101572, margin=0.20041911792610775, lpl_weight=0.38033342432213774\n",
      " - ratio=0.21668212549628685, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6477, LPL: 1.3863, Contrastive: 0.1944\n",
      "Epoch 50, Loss: 0.6301, LPL: 1.3863, Contrastive: 0.1660\n",
      "Epoch 100, Loss: 0.6289, LPL: 1.3863, Contrastive: 0.1640\n",
      " - Metrics: Accuracy=0.8991, F1=0.8714, Recall=0.8556, Precision=0.8877\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.24576457506293065, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.13467540209101572, margin=0.20041911792610775, lpl_weight=0.38033342432213774\n",
      " - ratio=0.21668212549628685, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6477, LPL: 1.3863, Contrastive: 0.1944\n",
      "Epoch 50, Loss: 0.6301, LPL: 1.3863, Contrastive: 0.1660\n",
      "Epoch 100, Loss: 0.6288, LPL: 1.3863, Contrastive: 0.1639\n",
      " - Metrics: Accuracy=0.8910, F1=0.8610, Recall=0.8455, Precision=0.8771\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.24576457506293065, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.13467540209101572, margin=0.20041911792610775, lpl_weight=0.38033342432213774\n",
      " - ratio=0.21668212549628685, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6477, LPL: 1.3863, Contrastive: 0.1944\n",
      "Epoch 50, Loss: 0.6301, LPL: 1.3863, Contrastive: 0.1660\n",
      "Epoch 100, Loss: 0.6289, LPL: 1.3863, Contrastive: 0.1640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 20:58:12,871] Trial 72 finished with value: 0.8650633082297936 and parameters: {'alpha': 0.24576457506293065, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.13467540209101572, 'margin': 0.20041911792610775, 'lpl_weight': 0.38033342432213774, 'ratio': 0.21668212549628685, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8929, F1=0.8632, Recall=0.8463, Precision=0.8808\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102205531.csv.\n",
      "Average F1 over 5 seeds: 0.8651  0.0038\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1532608252126889, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24104944639056233, margin=0.1307049721084915, lpl_weight=0.45765672415490044\n",
      " - ratio=0.1684018023073369, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7557, LPL: 1.3863, Contrastive: 0.2236\n",
      "Epoch 50, Loss: 0.7405, LPL: 1.3863, Contrastive: 0.1955\n",
      " - Metrics: Accuracy=0.8996, F1=0.8656, Recall=0.8095, Precision=0.9301\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1532608252126889, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24104944639056233, margin=0.1307049721084915, lpl_weight=0.45765672415490044\n",
      " - ratio=0.1684018023073369, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7557, LPL: 1.3863, Contrastive: 0.2236\n",
      "Epoch 50, Loss: 0.7405, LPL: 1.3863, Contrastive: 0.1955\n",
      " - Metrics: Accuracy=0.8977, F1=0.8633, Recall=0.8088, Precision=0.9257\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1532608252126889, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24104944639056233, margin=0.1307049721084915, lpl_weight=0.45765672415490044\n",
      " - ratio=0.1684018023073369, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7557, LPL: 1.3863, Contrastive: 0.2236\n",
      "Epoch 50, Loss: 0.7405, LPL: 1.3863, Contrastive: 0.1955\n",
      " - Metrics: Accuracy=0.9009, F1=0.8672, Recall=0.8100, Precision=0.9330\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1532608252126889, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24104944639056233, margin=0.1307049721084915, lpl_weight=0.45765672415490044\n",
      " - ratio=0.1684018023073369, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7557, LPL: 1.3863, Contrastive: 0.2236\n",
      "Epoch 50, Loss: 0.7405, LPL: 1.3863, Contrastive: 0.1955\n",
      " - Metrics: Accuracy=0.8991, F1=0.8647, Recall=0.8069, Precision=0.9314\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1532608252126889, K=35, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24104944639056233, margin=0.1307049721084915, lpl_weight=0.45765672415490044\n",
      " - ratio=0.1684018023073369, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7557, LPL: 1.3863, Contrastive: 0.2236\n",
      "Epoch 50, Loss: 0.7405, LPL: 1.3863, Contrastive: 0.1955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:00:39,540] Trial 73 finished with value: 0.8647507052578535 and parameters: {'alpha': 0.1532608252126889, 'K': 35, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.24104944639056233, 'margin': 0.1307049721084915, 'lpl_weight': 0.45765672415490044, 'ratio': 0.1684018023073369, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8980, F1=0.8630, Recall=0.8041, Precision=0.9312\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102205812.csv.\n",
      "Average F1 over 5 seeds: 0.8648  0.0015\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3209543426245564, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18816106224239026, margin=0.23532830796094265, lpl_weight=0.22933125563939233\n",
      " - ratio=0.18323656325536997, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4560, LPL: 1.3863, Contrastive: 0.1792\n",
      "Epoch 50, Loss: 0.4351, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 100, Loss: 0.4383, LPL: 1.3863, Contrastive: 0.1562\n",
      " - Metrics: Accuracy=0.9005, F1=0.8701, Recall=0.8337, Precision=0.9098\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3209543426245564, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18816106224239026, margin=0.23532830796094265, lpl_weight=0.22933125563939233\n",
      " - ratio=0.18323656325536997, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4560, LPL: 1.3863, Contrastive: 0.1792\n",
      "Epoch 50, Loss: 0.4351, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 100, Loss: 0.4383, LPL: 1.3863, Contrastive: 0.1562\n",
      " - Metrics: Accuracy=0.8970, F1=0.8653, Recall=0.8281, Precision=0.9061\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3209543426245564, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18816106224239026, margin=0.23532830796094265, lpl_weight=0.22933125563939233\n",
      " - ratio=0.18323656325536997, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4560, LPL: 1.3863, Contrastive: 0.1792\n",
      "Epoch 50, Loss: 0.4351, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 100, Loss: 0.4334, LPL: 1.3863, Contrastive: 0.1498\n",
      " - Metrics: Accuracy=0.8996, F1=0.8686, Recall=0.8312, Precision=0.9095\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3209543426245564, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18816106224239026, margin=0.23532830796094265, lpl_weight=0.22933125563939233\n",
      " - ratio=0.18323656325536997, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4560, LPL: 1.3863, Contrastive: 0.1792\n",
      "Epoch 50, Loss: 0.4351, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 100, Loss: 0.4348, LPL: 1.3863, Contrastive: 0.1517\n",
      " - Metrics: Accuracy=0.8908, F1=0.8556, Recall=0.8102, Precision=0.9064\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3209543426245564, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.18816106224239026, margin=0.23532830796094265, lpl_weight=0.22933125563939233\n",
      " - ratio=0.18323656325536997, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4560, LPL: 1.3863, Contrastive: 0.1792\n",
      "Epoch 50, Loss: 0.4351, LPL: 1.3863, Contrastive: 0.1520\n",
      "Epoch 100, Loss: 0.4383, LPL: 1.3863, Contrastive: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:03:13,155] Trial 74 finished with value: 0.865259895997007 and parameters: {'alpha': 0.3209543426245564, 'K': 33, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.18816106224239026, 'margin': 0.23532830796094265, 'lpl_weight': 0.22933125563939233, 'ratio': 0.18323656325536997, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8985, F1=0.8667, Recall=0.8267, Precision=0.9109\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102210039.csv.\n",
      "Average F1 over 5 seeds: 0.8653  0.0051\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6880821077300132, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.17414961452376854, margin=0.15814229896288765, lpl_weight=0.33272346168247724\n",
      " - ratio=0.14986250023073233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6030, LPL: 1.3863, Contrastive: 0.2125\n",
      "Epoch 50, Loss: 0.5839, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.5868, LPL: 1.3863, Contrastive: 0.1881\n",
      " - Metrics: Accuracy=0.8977, F1=0.8628, Recall=0.8057, Precision=0.9286\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6880821077300132, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.17414961452376854, margin=0.15814229896288765, lpl_weight=0.33272346168247724\n",
      " - ratio=0.14986250023073233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6030, LPL: 1.3863, Contrastive: 0.2125\n",
      "Epoch 50, Loss: 0.5839, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.5823, LPL: 1.3863, Contrastive: 0.1814\n",
      " - Metrics: Accuracy=0.8926, F1=0.8557, Recall=0.7975, Precision=0.9231\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6880821077300132, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.17414961452376854, margin=0.15814229896288765, lpl_weight=0.33272346168247724\n",
      " - ratio=0.14986250023073233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6030, LPL: 1.3863, Contrastive: 0.2125\n",
      "Epoch 50, Loss: 0.5839, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.5826, LPL: 1.3863, Contrastive: 0.1819\n",
      " - Metrics: Accuracy=0.8948, F1=0.8559, Recall=0.7825, Precision=0.9445\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6880821077300132, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.17414961452376854, margin=0.15814229896288765, lpl_weight=0.33272346168247724\n",
      " - ratio=0.14986250023073233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6030, LPL: 1.3863, Contrastive: 0.2125\n",
      "Epoch 50, Loss: 0.5839, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.5824, LPL: 1.3863, Contrastive: 0.1816\n",
      " - Metrics: Accuracy=0.8998, F1=0.8640, Recall=0.7971, Precision=0.9432\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6880821077300132, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.17414961452376854, margin=0.15814229896288765, lpl_weight=0.33272346168247724\n",
      " - ratio=0.14986250023073233, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6030, LPL: 1.3863, Contrastive: 0.2125\n",
      "Epoch 50, Loss: 0.5839, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.5902, LPL: 1.3863, Contrastive: 0.1933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:05:49,133] Trial 75 finished with value: 0.8600283191641431 and parameters: {'alpha': 0.6880821077300132, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.17414961452376854, 'margin': 0.15814229896288765, 'lpl_weight': 0.33272346168247724, 'ratio': 0.14986250023073233, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8977, F1=0.8617, Recall=0.7982, Precision=0.9363\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102210313.csv.\n",
      "Average F1 over 5 seeds: 0.8600  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1864272728354317, K=34, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.19994305637269313, margin=0.20060167536439455, lpl_weight=0.40813738661467\n",
      " - ratio=0.1986196943094127, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1758\n",
      "Epoch 50, Loss: 0.6625, LPL: 1.3863, Contrastive: 0.1634\n",
      " - Metrics: Accuracy=0.8926, F1=0.8612, Recall=0.8340, Precision=0.8901\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1864272728354317, K=34, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.19994305637269313, margin=0.20060167536439455, lpl_weight=0.40813738661467\n",
      " - ratio=0.1986196943094127, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1758\n",
      "Epoch 50, Loss: 0.6625, LPL: 1.3863, Contrastive: 0.1634\n",
      " - Metrics: Accuracy=0.8940, F1=0.8630, Recall=0.8359, Precision=0.8919\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1864272728354317, K=34, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.19994305637269313, margin=0.20060167536439455, lpl_weight=0.40813738661467\n",
      " - ratio=0.1986196943094127, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1758\n",
      "Epoch 50, Loss: 0.6625, LPL: 1.3863, Contrastive: 0.1634\n",
      " - Metrics: Accuracy=0.8823, F1=0.8478, Recall=0.8206, Precision=0.8769\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1864272728354317, K=34, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.19994305637269313, margin=0.20060167536439455, lpl_weight=0.40813738661467\n",
      " - ratio=0.1986196943094127, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1758\n",
      "Epoch 50, Loss: 0.6625, LPL: 1.3863, Contrastive: 0.1634\n",
      " - Metrics: Accuracy=0.8973, F1=0.8668, Recall=0.8370, Precision=0.8989\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1864272728354317, K=34, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.19994305637269313, margin=0.20060167536439455, lpl_weight=0.40813738661467\n",
      " - ratio=0.1986196943094127, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6699, LPL: 1.3863, Contrastive: 0.1758\n",
      "Epoch 50, Loss: 0.6625, LPL: 1.3863, Contrastive: 0.1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:08:55,439] Trial 76 finished with value: 0.8605432757401712 and parameters: {'alpha': 0.1864272728354317, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.19994305637269313, 'margin': 0.20060167536439455, 'lpl_weight': 0.40813738661467, 'ratio': 0.1986196943094127, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8949, F1=0.8639, Recall=0.8356, Precision=0.8943\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102210549.csv.\n",
      "Average F1 over 5 seeds: 0.8605  0.0066\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.23435850422547974, K=35, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15890413291709723, margin=0.12790734715822855, lpl_weight=0.3057665241866438\n",
      " - ratio=0.2229565377112882, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5939, LPL: 1.3863, Contrastive: 0.2449\n",
      "Epoch 50, Loss: 0.5632, LPL: 1.3863, Contrastive: 0.2006\n",
      " - Metrics: Accuracy=0.8612, F1=0.8254, Recall=0.8215, Precision=0.8295\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.23435850422547974, K=35, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15890413291709723, margin=0.12790734715822855, lpl_weight=0.3057665241866438\n",
      " - ratio=0.2229565377112882, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5939, LPL: 1.3863, Contrastive: 0.2449\n",
      "Epoch 50, Loss: 0.5625, LPL: 1.3863, Contrastive: 0.1997\n",
      " - Metrics: Accuracy=0.8715, F1=0.8373, Recall=0.8274, Precision=0.8473\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.23435850422547974, K=35, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15890413291709723, margin=0.12790734715822855, lpl_weight=0.3057665241866438\n",
      " - ratio=0.2229565377112882, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5940, LPL: 1.3863, Contrastive: 0.2450\n",
      "Epoch 50, Loss: 0.5625, LPL: 1.3863, Contrastive: 0.1997\n",
      " - Metrics: Accuracy=0.8629, F1=0.8272, Recall=0.8215, Precision=0.8330\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.23435850422547974, K=35, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15890413291709723, margin=0.12790734715822855, lpl_weight=0.3057665241866438\n",
      " - ratio=0.2229565377112882, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5939, LPL: 1.3863, Contrastive: 0.2449\n",
      "Epoch 50, Loss: 0.5624, LPL: 1.3863, Contrastive: 0.1995\n",
      " - Metrics: Accuracy=0.8868, F1=0.8572, Recall=0.8505, Precision=0.8639\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.23435850422547974, K=35, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15890413291709723, margin=0.12790734715822855, lpl_weight=0.3057665241866438\n",
      " - ratio=0.2229565377112882, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5939, LPL: 1.3863, Contrastive: 0.2449\n",
      "Epoch 50, Loss: 0.5626, LPL: 1.3863, Contrastive: 0.1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:11:22,640] Trial 77 finished with value: 0.8376253354653451 and parameters: {'alpha': 0.23435850422547974, 'K': 35, 'layers': 3, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.15890413291709723, 'margin': 0.12790734715822855, 'lpl_weight': 0.3057665241866438, 'ratio': 0.2229565377112882, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8739, F1=0.8411, Recall=0.8356, Precision=0.8466\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102210855.csv.\n",
      "Average F1 over 5 seeds: 0.8376  0.0114\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.26561937031961586, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20570436334285588, margin=0.18111834765038343, lpl_weight=0.49681336216385213\n",
      " - ratio=0.348882027329592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8526, LPL: 1.3863, Contrastive: 0.3256\n",
      " - Metrics: Accuracy=0.8748, F1=0.8483, Recall=0.8766, Precision=0.8218\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.26561937031961586, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20570436334285588, margin=0.18111834765038343, lpl_weight=0.49681336216385213\n",
      " - ratio=0.348882027329592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8526, LPL: 1.3863, Contrastive: 0.3256\n",
      " - Metrics: Accuracy=0.8700, F1=0.8427, Recall=0.8716, Precision=0.8156\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.26561937031961586, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20570436334285588, margin=0.18111834765038343, lpl_weight=0.49681336216385213\n",
      " - ratio=0.348882027329592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8526, LPL: 1.3863, Contrastive: 0.3256\n",
      " - Metrics: Accuracy=0.8754, F1=0.8488, Recall=0.8761, Precision=0.8233\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.26561937031961586, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20570436334285588, margin=0.18111834765038343, lpl_weight=0.49681336216385213\n",
      " - ratio=0.348882027329592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8526, LPL: 1.3863, Contrastive: 0.3256\n",
      " - Metrics: Accuracy=0.8764, F1=0.8502, Recall=0.8786, Precision=0.8236\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.26561937031961586, K=34, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.20570436334285588, margin=0.18111834765038343, lpl_weight=0.49681336216385213\n",
      " - ratio=0.348882027329592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8526, LPL: 1.3863, Contrastive: 0.3256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:13:22,877] Trial 78 finished with value: 0.8461350221851583 and parameters: {'alpha': 0.26561937031961586, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.20570436334285588, 'margin': 0.18111834765038343, 'lpl_weight': 0.49681336216385213, 'ratio': 0.348882027329592, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8684, F1=0.8407, Recall=0.8692, Precision=0.8139\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102211122.csv.\n",
      "Average F1 over 5 seeds: 0.8461  0.0038\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1358720307440334, K=35, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1403494577791364, margin=0.1540978389907265, lpl_weight=0.18440513500446132\n",
      " - ratio=0.13635290301740186, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4145, LPL: 1.3863, Contrastive: 0.1948\n",
      "Epoch 50, Loss: 0.4047, LPL: 1.3863, Contrastive: 0.1828\n",
      " - Metrics: Accuracy=0.8928, F1=0.8573, Recall=0.8061, Precision=0.9155\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1358720307440334, K=35, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1403494577791364, margin=0.1540978389907265, lpl_weight=0.18440513500446132\n",
      " - ratio=0.13635290301740186, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4145, LPL: 1.3863, Contrastive: 0.1948\n",
      "Epoch 50, Loss: 0.4047, LPL: 1.3863, Contrastive: 0.1828\n",
      " - Metrics: Accuracy=0.8898, F1=0.8528, Recall=0.7990, Precision=0.9144\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1358720307440334, K=35, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1403494577791364, margin=0.1540978389907265, lpl_weight=0.18440513500446132\n",
      " - ratio=0.13635290301740186, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4145, LPL: 1.3863, Contrastive: 0.1948\n",
      "Epoch 50, Loss: 0.4047, LPL: 1.3863, Contrastive: 0.1828\n",
      " - Metrics: Accuracy=0.8968, F1=0.8617, Recall=0.8050, Precision=0.9272\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1358720307440334, K=35, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1403494577791364, margin=0.1540978389907265, lpl_weight=0.18440513500446132\n",
      " - ratio=0.13635290301740186, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4145, LPL: 1.3863, Contrastive: 0.1948\n",
      "Epoch 50, Loss: 0.4047, LPL: 1.3863, Contrastive: 0.1828\n",
      " - Metrics: Accuracy=0.8934, F1=0.8565, Recall=0.7962, Precision=0.9267\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1358720307440334, K=35, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1403494577791364, margin=0.1540978389907265, lpl_weight=0.18440513500446132\n",
      " - ratio=0.13635290301740186, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4145, LPL: 1.3863, Contrastive: 0.1948\n",
      "Epoch 50, Loss: 0.4047, LPL: 1.3863, Contrastive: 0.1828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:16:26,919] Trial 79 finished with value: 0.8565352211296038 and parameters: {'alpha': 0.1358720307440334, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.1403494577791364, 'margin': 0.1540978389907265, 'lpl_weight': 0.18440513500446132, 'ratio': 0.13635290301740186, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8912, F1=0.8543, Recall=0.7986, Precision=0.9184\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102211322.csv.\n",
      "Average F1 over 5 seeds: 0.8565  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.42098196408017596, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22740704801635928, margin=0.2745060642150283, lpl_weight=0.3449822728057635\n",
      " - ratio=0.27597344016660375, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5861, LPL: 1.3863, Contrastive: 0.1647\n",
      "Epoch 50, Loss: 0.5680, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.8901, F1=0.8660, Recall=0.8893, Precision=0.8439\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.42098196408017596, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22740704801635928, margin=0.2745060642150283, lpl_weight=0.3449822728057635\n",
      " - ratio=0.27597344016660375, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5861, LPL: 1.3863, Contrastive: 0.1647\n",
      "Epoch 50, Loss: 0.5680, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.8875, F1=0.8629, Recall=0.8866, Precision=0.8405\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.42098196408017596, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22740704801635928, margin=0.2745060642150283, lpl_weight=0.3449822728057635\n",
      " - ratio=0.27597344016660375, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5861, LPL: 1.3863, Contrastive: 0.1647\n",
      "Epoch 50, Loss: 0.5680, LPL: 1.3863, Contrastive: 0.1370\n",
      " - Metrics: Accuracy=0.8880, F1=0.8635, Recall=0.8870, Precision=0.8413\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.42098196408017596, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22740704801635928, margin=0.2745060642150283, lpl_weight=0.3449822728057635\n",
      " - ratio=0.27597344016660375, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5861, LPL: 1.3863, Contrastive: 0.1647\n",
      "Epoch 50, Loss: 0.5680, LPL: 1.3863, Contrastive: 0.1370\n",
      "Epoch 100, Loss: 0.5675, LPL: 1.3863, Contrastive: 0.1363\n",
      " - Metrics: Accuracy=0.8894, F1=0.8651, Recall=0.8884, Precision=0.8431\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.42098196408017596, K=33, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.22740704801635928, margin=0.2745060642150283, lpl_weight=0.3449822728057635\n",
      " - ratio=0.27597344016660375, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5861, LPL: 1.3863, Contrastive: 0.1647\n",
      "Epoch 50, Loss: 0.5680, LPL: 1.3863, Contrastive: 0.1370\n",
      "Epoch 100, Loss: 0.5674, LPL: 1.3863, Contrastive: 0.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:19:00,327] Trial 80 finished with value: 0.8629680768207043 and parameters: {'alpha': 0.42098196408017596, 'K': 33, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.22740704801635928, 'margin': 0.2745060642150283, 'lpl_weight': 0.3449822728057635, 'ratio': 0.27597344016660375, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8827, F1=0.8572, Recall=0.8818, Precision=0.8340\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102211626.csv.\n",
      "Average F1 over 5 seeds: 0.8630  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.36928007866219226, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3652396778607502, margin=0.11711266196860717, lpl_weight=0.8050661935950636\n",
      " - ratio=0.23774096880961043, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1574, LPL: 1.3863, Contrastive: 0.2123\n",
      "Epoch 50, Loss: 1.1549, LPL: 1.3863, Contrastive: 0.1993\n",
      " - Metrics: Accuracy=0.8942, F1=0.8665, Recall=0.8602, Precision=0.8729\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.36928007866219226, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3652396778607502, margin=0.11711266196860717, lpl_weight=0.8050661935950636\n",
      " - ratio=0.23774096880961043, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1574, LPL: 1.3863, Contrastive: 0.2123\n",
      "Epoch 50, Loss: 1.1549, LPL: 1.3863, Contrastive: 0.1993\n",
      " - Metrics: Accuracy=0.8909, F1=0.8622, Recall=0.8547, Precision=0.8699\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.36928007866219226, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3652396778607502, margin=0.11711266196860717, lpl_weight=0.8050661935950636\n",
      " - ratio=0.23774096880961043, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1574, LPL: 1.3863, Contrastive: 0.2123\n",
      "Epoch 50, Loss: 1.1549, LPL: 1.3863, Contrastive: 0.1993\n",
      " - Metrics: Accuracy=0.8966, F1=0.8695, Recall=0.8629, Precision=0.8763\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.36928007866219226, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3652396778607502, margin=0.11711266196860717, lpl_weight=0.8050661935950636\n",
      " - ratio=0.23774096880961043, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1574, LPL: 1.3863, Contrastive: 0.2123\n",
      "Epoch 50, Loss: 1.1549, LPL: 1.3863, Contrastive: 0.1993\n",
      " - Metrics: Accuracy=0.8945, F1=0.8669, Recall=0.8602, Precision=0.8736\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.36928007866219226, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.3652396778607502, margin=0.11711266196860717, lpl_weight=0.8050661935950636\n",
      " - ratio=0.23774096880961043, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1574, LPL: 1.3863, Contrastive: 0.2123\n",
      "Epoch 50, Loss: 1.1549, LPL: 1.3863, Contrastive: 0.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:21:32,442] Trial 81 finished with value: 0.8655564631717787 and parameters: {'alpha': 0.36928007866219226, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.3652396778607502, 'margin': 0.11711266196860717, 'lpl_weight': 0.8050661935950636, 'ratio': 0.23774096880961043, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8912, F1=0.8626, Recall=0.8557, Precision=0.8697\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102211900.csv.\n",
      "Average F1 over 5 seeds: 0.8656  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.31558134705841556, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17900692563978182, margin=0.1481033313317639, lpl_weight=0.26047800296999696\n",
      " - ratio=0.20790919186233175, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5099, LPL: 1.3863, Contrastive: 0.2012\n",
      "Epoch 50, Loss: 0.4987, LPL: 1.3863, Contrastive: 0.1861\n",
      " - Metrics: Accuracy=0.9027, F1=0.8742, Recall=0.8469, Precision=0.9034\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.31558134705841556, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17900692563978182, margin=0.1481033313317639, lpl_weight=0.26047800296999696\n",
      " - ratio=0.20790919186233175, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5099, LPL: 1.3863, Contrastive: 0.2012\n",
      "Epoch 50, Loss: 0.4987, LPL: 1.3863, Contrastive: 0.1861\n",
      " - Metrics: Accuracy=0.8997, F1=0.8707, Recall=0.8460, Precision=0.8970\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.31558134705841556, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17900692563978182, margin=0.1481033313317639, lpl_weight=0.26047800296999696\n",
      " - ratio=0.20790919186233175, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5099, LPL: 1.3863, Contrastive: 0.2012\n",
      "Epoch 50, Loss: 0.4987, LPL: 1.3863, Contrastive: 0.1861\n",
      " - Metrics: Accuracy=0.8963, F1=0.8665, Recall=0.8427, Precision=0.8918\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.31558134705841556, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17900692563978182, margin=0.1481033313317639, lpl_weight=0.26047800296999696\n",
      " - ratio=0.20790919186233175, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5099, LPL: 1.3863, Contrastive: 0.2012\n",
      "Epoch 50, Loss: 0.4988, LPL: 1.3863, Contrastive: 0.1862\n",
      " - Metrics: Accuracy=0.9047, F1=0.8769, Recall=0.8499, Precision=0.9057\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.31558134705841556, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17900692563978182, margin=0.1481033313317639, lpl_weight=0.26047800296999696\n",
      " - ratio=0.20790919186233175, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5099, LPL: 1.3863, Contrastive: 0.2012\n",
      "Epoch 50, Loss: 0.4988, LPL: 1.3863, Contrastive: 0.1862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:24:09,855] Trial 82 finished with value: 0.8716463957805587 and parameters: {'alpha': 0.31558134705841556, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.17900692563978182, 'margin': 0.1481033313317639, 'lpl_weight': 0.26047800296999696, 'ratio': 0.20790919186233175, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8993, F1=0.8698, Recall=0.8425, Precision=0.8989\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102212132.csv.\n",
      "Average F1 over 5 seeds: 0.8716  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.31417311912962914, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17742251524836886, margin=0.22027847009895582, lpl_weight=0.25257165058772424\n",
      " - ratio=0.20521204475244603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4773, LPL: 1.3863, Contrastive: 0.1701\n",
      "Epoch 50, Loss: 0.4668, LPL: 1.3863, Contrastive: 0.1561\n",
      " - Metrics: Accuracy=0.8999, F1=0.8706, Recall=0.8430, Precision=0.9001\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.31417311912962914, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17742251524836886, margin=0.22027847009895582, lpl_weight=0.25257165058772424\n",
      " - ratio=0.20521204475244603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4773, LPL: 1.3863, Contrastive: 0.1701\n",
      "Epoch 50, Loss: 0.4668, LPL: 1.3863, Contrastive: 0.1561\n",
      " - Metrics: Accuracy=0.8940, F1=0.8623, Recall=0.8312, Precision=0.8959\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.31417311912962914, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17742251524836886, margin=0.22027847009895582, lpl_weight=0.25257165058772424\n",
      " - ratio=0.20521204475244603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4773, LPL: 1.3863, Contrastive: 0.1701\n",
      "Epoch 50, Loss: 0.4668, LPL: 1.3863, Contrastive: 0.1561\n",
      " - Metrics: Accuracy=0.8980, F1=0.8685, Recall=0.8437, Precision=0.8948\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.31417311912962914, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17742251524836886, margin=0.22027847009895582, lpl_weight=0.25257165058772424\n",
      " - ratio=0.20521204475244603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4773, LPL: 1.3863, Contrastive: 0.1701\n",
      "Epoch 50, Loss: 0.4668, LPL: 1.3863, Contrastive: 0.1561\n",
      " - Metrics: Accuracy=0.9002, F1=0.8706, Recall=0.8405, Precision=0.9030\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.31417311912962914, K=34, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.17742251524836886, margin=0.22027847009895582, lpl_weight=0.25257165058772424\n",
      " - ratio=0.20521204475244603, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4773, LPL: 1.3863, Contrastive: 0.1701\n",
      "Epoch 50, Loss: 0.4668, LPL: 1.3863, Contrastive: 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:26:48,857] Trial 83 finished with value: 0.8673936449469594 and parameters: {'alpha': 0.31417311912962914, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.17742251524836886, 'margin': 0.22027847009895582, 'lpl_weight': 0.25257165058772424, 'ratio': 0.20521204475244603, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8958, F1=0.8649, Recall=0.8347, Precision=0.8973\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102212409.csv.\n",
      "Average F1 over 5 seeds: 0.8674  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.22420386913823412, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.24654496958462774, margin=0.150550182120443, lpl_weight=0.23250790590019868\n",
      " - ratio=0.17544569106055213, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4748, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4640, LPL: 1.3863, Contrastive: 0.1847\n",
      " - Metrics: Accuracy=0.9050, F1=0.8743, Recall=0.8268, Precision=0.9275\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.22420386913823412, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.24654496958462774, margin=0.150550182120443, lpl_weight=0.23250790590019868\n",
      " - ratio=0.17544569106055213, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4748, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4640, LPL: 1.3863, Contrastive: 0.1847\n",
      " - Metrics: Accuracy=0.9008, F1=0.8688, Recall=0.8218, Precision=0.9214\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.22420386913823412, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.24654496958462774, margin=0.150550182120443, lpl_weight=0.23250790590019868\n",
      " - ratio=0.17544569106055213, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4748, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4640, LPL: 1.3863, Contrastive: 0.1847\n",
      " - Metrics: Accuracy=0.9008, F1=0.8681, Recall=0.8170, Precision=0.9260\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.22420386913823412, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.24654496958462774, margin=0.150550182120443, lpl_weight=0.23250790590019868\n",
      " - ratio=0.17544569106055213, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4748, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4640, LPL: 1.3863, Contrastive: 0.1847\n",
      " - Metrics: Accuracy=0.9030, F1=0.8715, Recall=0.8237, Precision=0.9251\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.22420386913823412, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.24654496958462774, margin=0.150550182120443, lpl_weight=0.23250790590019868\n",
      " - ratio=0.17544569106055213, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4748, LPL: 1.3863, Contrastive: 0.1986\n",
      "Epoch 50, Loss: 0.4640, LPL: 1.3863, Contrastive: 0.1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:29:21,695] Trial 84 finished with value: 0.8693402625767502 and parameters: {'alpha': 0.22420386913823412, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.24654496958462774, 'margin': 0.150550182120443, 'lpl_weight': 0.23250790590019868, 'ratio': 0.17544569106055213, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8977, F1=0.8641, Recall=0.8140, Precision=0.9207\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102212648.csv.\n",
      "Average F1 over 5 seeds: 0.8693  0.0034\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2894113170897268, K=35, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.20528007766745185, margin=0.17643135509418237, lpl_weight=0.27302834515255814\n",
      " - ratio=0.37441069795726367, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1909\n",
      "Epoch 50, Loss: 0.5054, LPL: 1.3863, Contrastive: 0.1745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8438, F1=0.8259, Recall=0.9276, Precision=0.7443\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2894113170897268, K=35, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.20528007766745185, margin=0.17643135509418237, lpl_weight=0.27302834515255814\n",
      " - ratio=0.37441069795726367, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1909\n",
      "Epoch 50, Loss: 0.5054, LPL: 1.3863, Contrastive: 0.1745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8382, F1=0.8196, Recall=0.9205, Precision=0.7386\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2894113170897268, K=35, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.20528007766745185, margin=0.17643135509418237, lpl_weight=0.27302834515255814\n",
      " - ratio=0.37441069795726367, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1909\n",
      "Epoch 50, Loss: 0.5054, LPL: 1.3863, Contrastive: 0.1745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8459, F1=0.8283, Recall=0.9304, Precision=0.7464\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2894113170897268, K=35, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.20528007766745185, margin=0.17643135509418237, lpl_weight=0.27302834515255814\n",
      " - ratio=0.37441069795726367, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1909\n",
      "Epoch 50, Loss: 0.5054, LPL: 1.3863, Contrastive: 0.1745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8453, F1=0.8275, Recall=0.9294, Precision=0.7458\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2894113170897268, K=35, layers=2, hidden=128, out=64\n",
      " - norm=graphnorm, dropout=0.20528007766745185, margin=0.17643135509418237, lpl_weight=0.27302834515255814\n",
      " - ratio=0.37441069795726367, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5173, LPL: 1.3863, Contrastive: 0.1909\n",
      "Epoch 50, Loss: 0.5054, LPL: 1.3863, Contrastive: 0.1745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n",
      "[I 2025-02-21 21:31:36,120] Trial 85 finished with value: 0.8250190314360664 and parameters: {'alpha': 0.2894113170897268, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.20528007766745185, 'margin': 0.17643135509418237, 'lpl_weight': 0.27302834515255814, 'ratio': 0.37441069795726367, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8420, F1=0.8238, Recall=0.9250, Precision=0.7426\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102212921.csv.\n",
      "Average F1 over 5 seeds: 0.8250  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.48510613437196864, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18706272257326356, margin=0.20137577103608784, lpl_weight=0.20344075404877865\n",
      " - ratio=0.18823145897312643, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4235, LPL: 1.3863, Contrastive: 0.1776\n",
      "Epoch 50, Loss: 0.4125, LPL: 1.3863, Contrastive: 0.1637\n",
      " - Metrics: Accuracy=0.9039, F1=0.8749, Recall=0.8413, Precision=0.9114\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.48510613437196864, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18706272257326356, margin=0.20137577103608784, lpl_weight=0.20344075404877865\n",
      " - ratio=0.18823145897312643, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4235, LPL: 1.3863, Contrastive: 0.1776\n",
      "Epoch 50, Loss: 0.4125, LPL: 1.3863, Contrastive: 0.1637\n",
      "Epoch 100, Loss: 0.4267, LPL: 1.3863, Contrastive: 0.1816\n",
      " - Metrics: Accuracy=0.9025, F1=0.8732, Recall=0.8404, Precision=0.9087\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.48510613437196864, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18706272257326356, margin=0.20137577103608784, lpl_weight=0.20344075404877865\n",
      " - ratio=0.18823145897312643, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4235, LPL: 1.3863, Contrastive: 0.1776\n",
      "Epoch 50, Loss: 0.4125, LPL: 1.3863, Contrastive: 0.1637\n",
      " - Metrics: Accuracy=0.8951, F1=0.8623, Recall=0.8220, Precision=0.9067\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.48510613437196864, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18706272257326356, margin=0.20137577103608784, lpl_weight=0.20344075404877865\n",
      " - ratio=0.18823145897312643, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4235, LPL: 1.3863, Contrastive: 0.1776\n",
      "Epoch 50, Loss: 0.4125, LPL: 1.3863, Contrastive: 0.1637\n",
      "Epoch 100, Loss: 0.4249, LPL: 1.3863, Contrastive: 0.1793\n",
      " - Metrics: Accuracy=0.9041, F1=0.8749, Recall=0.8400, Precision=0.9129\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.48510613437196864, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18706272257326356, margin=0.20137577103608784, lpl_weight=0.20344075404877865\n",
      " - ratio=0.18823145897312643, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4235, LPL: 1.3863, Contrastive: 0.1776\n",
      "Epoch 50, Loss: 0.4125, LPL: 1.3863, Contrastive: 0.1637\n",
      "Epoch 100, Loss: 0.4267, LPL: 1.3863, Contrastive: 0.1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:34:17,833] Trial 86 finished with value: 0.87162120949307 and parameters: {'alpha': 0.48510613437196864, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.18706272257326356, 'margin': 0.20137577103608784, 'lpl_weight': 0.20344075404877865, 'ratio': 0.18823145897312643, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9025, F1=0.8728, Recall=0.8371, Precision=0.9116\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102213136.csv.\n",
      "Average F1 over 5 seeds: 0.8716  0.0048\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.25784351194734945, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1871931529616839, margin=0.24529675536741768, lpl_weight=0.30534307807654143\n",
      " - ratio=0.2167237660515552, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1604\n",
      "Epoch 50, Loss: 0.5250, LPL: 1.3863, Contrastive: 0.1464\n",
      " - Metrics: Accuracy=0.9013, F1=0.8739, Recall=0.8564, Precision=0.8922\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.25784351194734945, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1871931529616839, margin=0.24529675536741768, lpl_weight=0.30534307807654143\n",
      " - ratio=0.2167237660515552, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1604\n",
      "Epoch 50, Loss: 0.5250, LPL: 1.3863, Contrastive: 0.1464\n",
      " - Metrics: Accuracy=0.8978, F1=0.8691, Recall=0.8495, Precision=0.8896\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.25784351194734945, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1871931529616839, margin=0.24529675536741768, lpl_weight=0.30534307807654143\n",
      " - ratio=0.2167237660515552, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1604\n",
      "Epoch 50, Loss: 0.5250, LPL: 1.3863, Contrastive: 0.1464\n",
      " - Metrics: Accuracy=0.9025, F1=0.8755, Recall=0.8589, Precision=0.8928\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.25784351194734945, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1871931529616839, margin=0.24529675536741768, lpl_weight=0.30534307807654143\n",
      " - ratio=0.2167237660515552, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1604\n",
      "Epoch 50, Loss: 0.5250, LPL: 1.3863, Contrastive: 0.1464\n",
      " - Metrics: Accuracy=0.9014, F1=0.8735, Recall=0.8524, Precision=0.8955\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.25784351194734945, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.1871931529616839, margin=0.24529675536741768, lpl_weight=0.30534307807654143\n",
      " - ratio=0.2167237660515552, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5347, LPL: 1.3863, Contrastive: 0.1604\n",
      "Epoch 50, Loss: 0.5250, LPL: 1.3863, Contrastive: 0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:36:52,915] Trial 87 finished with value: 0.8726424628149865 and parameters: {'alpha': 0.25784351194734945, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.1871931529616839, 'margin': 0.24529675536741768, 'lpl_weight': 0.30534307807654143, 'ratio': 0.2167237660515552, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8993, F1=0.8712, Recall=0.8523, Precision=0.8909\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102213417.csv.\n",
      "Average F1 over 5 seeds: 0.8726  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.201490427917387, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1201163332510215, margin=0.23964790724146778, lpl_weight=0.1342683766574367\n",
      " - ratio=0.21409216560235214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3255, LPL: 1.3863, Contrastive: 0.1610\n",
      "Epoch 50, Loss: 0.3141, LPL: 1.3863, Contrastive: 0.1478\n",
      " - Metrics: Accuracy=0.9024, F1=0.8752, Recall=0.8570, Precision=0.8943\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.201490427917387, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1201163332510215, margin=0.23964790724146778, lpl_weight=0.1342683766574367\n",
      " - ratio=0.21409216560235214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3255, LPL: 1.3863, Contrastive: 0.1610\n",
      "Epoch 50, Loss: 0.3141, LPL: 1.3863, Contrastive: 0.1478\n",
      " - Metrics: Accuracy=0.8901, F1=0.8600, Recall=0.8455, Precision=0.8751\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.201490427917387, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1201163332510215, margin=0.23964790724146778, lpl_weight=0.1342683766574367\n",
      " - ratio=0.21409216560235214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3255, LPL: 1.3863, Contrastive: 0.1610\n",
      "Epoch 50, Loss: 0.3141, LPL: 1.3863, Contrastive: 0.1478\n",
      " - Metrics: Accuracy=0.9030, F1=0.8762, Recall=0.8599, Precision=0.8932\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.201490427917387, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1201163332510215, margin=0.23964790724146778, lpl_weight=0.1342683766574367\n",
      " - ratio=0.21409216560235214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3255, LPL: 1.3863, Contrastive: 0.1610\n",
      "Epoch 50, Loss: 0.3141, LPL: 1.3863, Contrastive: 0.1478\n",
      " - Metrics: Accuracy=0.8959, F1=0.8673, Recall=0.8513, Precision=0.8838\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.201490427917387, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.1201163332510215, margin=0.23964790724146778, lpl_weight=0.1342683766574367\n",
      " - ratio=0.21409216560235214, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3255, LPL: 1.3863, Contrastive: 0.1610\n",
      "Epoch 50, Loss: 0.3141, LPL: 1.3863, Contrastive: 0.1478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:40:00,798] Trial 88 finished with value: 0.8686270446895753 and parameters: {'alpha': 0.201490427917387, 'K': 33, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': None, 'dropout': 0.1201163332510215, 'margin': 0.23964790724146778, 'lpl_weight': 0.1342683766574367, 'ratio': 0.21409216560235214, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8935, F1=0.8643, Recall=0.8491, Precision=0.8801\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102213652.csv.\n",
      "Average F1 over 5 seeds: 0.8686  0.0063\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2610684398072343, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18566836891692762, margin=0.3031484994499624, lpl_weight=0.21102394685700954\n",
      " - ratio=0.18923318203815817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4036, LPL: 1.3863, Contrastive: 0.1407\n",
      "Epoch 50, Loss: 0.3914, LPL: 1.3863, Contrastive: 0.1252\n",
      " - Metrics: Accuracy=0.9012, F1=0.8709, Recall=0.8342, Precision=0.9110\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2610684398072343, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18566836891692762, margin=0.3031484994499624, lpl_weight=0.21102394685700954\n",
      " - ratio=0.18923318203815817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4036, LPL: 1.3863, Contrastive: 0.1407\n",
      "Epoch 50, Loss: 0.3914, LPL: 1.3863, Contrastive: 0.1252\n",
      " - Metrics: Accuracy=0.8988, F1=0.8681, Recall=0.8338, Precision=0.9054\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2610684398072343, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18566836891692762, margin=0.3031484994499624, lpl_weight=0.21102394685700954\n",
      " - ratio=0.18923318203815817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4036, LPL: 1.3863, Contrastive: 0.1407\n",
      "Epoch 50, Loss: 0.3914, LPL: 1.3863, Contrastive: 0.1252\n",
      " - Metrics: Accuracy=0.9024, F1=0.8728, Recall=0.8389, Precision=0.9097\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2610684398072343, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18566836891692762, margin=0.3031484994499624, lpl_weight=0.21102394685700954\n",
      " - ratio=0.18923318203815817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4036, LPL: 1.3863, Contrastive: 0.1407\n",
      "Epoch 50, Loss: 0.3914, LPL: 1.3863, Contrastive: 0.1252\n",
      " - Metrics: Accuracy=0.9020, F1=0.8723, Recall=0.8376, Precision=0.9099\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2610684398072343, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18566836891692762, margin=0.3031484994499624, lpl_weight=0.21102394685700954\n",
      " - ratio=0.18923318203815817, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4036, LPL: 1.3863, Contrastive: 0.1407\n",
      "Epoch 50, Loss: 0.3914, LPL: 1.3863, Contrastive: 0.1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:42:42,471] Trial 89 finished with value: 0.8701341078543161 and parameters: {'alpha': 0.2610684398072343, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.18566836891692762, 'margin': 0.3031484994499624, 'lpl_weight': 0.21102394685700954, 'ratio': 0.18923318203815817, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8978, F1=0.8666, Recall=0.8315, Precision=0.9048\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102214000.csv.\n",
      "Average F1 over 5 seeds: 0.8701  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8424899436804545, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18607835396079572, margin=0.32221551163342377, lpl_weight=0.2051749945563274\n",
      " - ratio=0.18588335691599592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4543, LPL: 1.3863, Contrastive: 0.2137\n",
      " - Metrics: Accuracy=0.8849, F1=0.8443, Recall=0.7818, Precision=0.9177\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8424899436804545, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18607835396079572, margin=0.32221551163342377, lpl_weight=0.2051749945563274\n",
      " - ratio=0.18588335691599592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4543, LPL: 1.3863, Contrastive: 0.2137\n",
      " - Metrics: Accuracy=0.8827, F1=0.8413, Recall=0.7783, Precision=0.9153\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8424899436804545, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18607835396079572, margin=0.32221551163342377, lpl_weight=0.2051749945563274\n",
      " - ratio=0.18588335691599592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4543, LPL: 1.3863, Contrastive: 0.2137\n",
      " - Metrics: Accuracy=0.8893, F1=0.8505, Recall=0.7886, Precision=0.9230\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8424899436804545, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18607835396079572, margin=0.32221551163342377, lpl_weight=0.2051749945563274\n",
      " - ratio=0.18588335691599592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4543, LPL: 1.3863, Contrastive: 0.2137\n",
      " - Metrics: Accuracy=0.8898, F1=0.8509, Recall=0.7873, Precision=0.9256\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8424899436804545, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18607835396079572, margin=0.32221551163342377, lpl_weight=0.2051749945563274\n",
      " - ratio=0.18588335691599592, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.4543, LPL: 1.3863, Contrastive: 0.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:44:44,725] Trial 90 finished with value: 0.8463192909936188 and parameters: {'alpha': 0.8424899436804545, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.18607835396079572, 'margin': 0.32221551163342377, 'lpl_weight': 0.2051749945563274, 'ratio': 0.18588335691599592, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8850, F1=0.8446, Recall=0.7822, Precision=0.9178\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102214242.csv.\n",
      "Average F1 over 5 seeds: 0.8463  0.0038\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.261481751135179, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.16620505990497478, margin=0.2928417689224114, lpl_weight=0.15988119976050966\n",
      " - ratio=0.44418260959373734, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3426, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 0.3296, LPL: 1.3863, Contrastive: 0.1285\n",
      "Epoch 100, Loss: 0.4017, LPL: 1.3863, Contrastive: 0.2144\n",
      " - Metrics: Accuracy=0.7798, F1=0.7675, Recall=0.9101, Precision=0.6635\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.261481751135179, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.16620505990497478, margin=0.2928417689224114, lpl_weight=0.15988119976050966\n",
      " - ratio=0.44418260959373734, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3426, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 0.3296, LPL: 1.3863, Contrastive: 0.1285\n",
      "Epoch 100, Loss: 0.3689, LPL: 1.3863, Contrastive: 0.1753\n",
      " - Metrics: Accuracy=0.7956, F1=0.7851, Recall=0.9352, Precision=0.6766\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.261481751135179, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.16620505990497478, margin=0.2928417689224114, lpl_weight=0.15988119976050966\n",
      " - ratio=0.44418260959373734, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3426, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 0.3296, LPL: 1.3863, Contrastive: 0.1285\n",
      "Epoch 100, Loss: 0.4092, LPL: 1.3863, Contrastive: 0.2232\n",
      " - Metrics: Accuracy=0.7837, F1=0.7712, Recall=0.9129, Precision=0.6676\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.261481751135179, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.16620505990497478, margin=0.2928417689224114, lpl_weight=0.15988119976050966\n",
      " - ratio=0.44418260959373734, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3426, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 0.3296, LPL: 1.3863, Contrastive: 0.1285\n",
      "Epoch 100, Loss: 0.3641, LPL: 1.3863, Contrastive: 0.1696\n",
      " - Metrics: Accuracy=0.7955, F1=0.7850, Recall=0.9347, Precision=0.6766\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.261481751135179, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.16620505990497478, margin=0.2928417689224114, lpl_weight=0.15988119976050966\n",
      " - ratio=0.44418260959373734, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3426, LPL: 1.3863, Contrastive: 0.1439\n",
      "Epoch 50, Loss: 0.3296, LPL: 1.3863, Contrastive: 0.1285\n",
      "Epoch 100, Loss: 0.4000, LPL: 1.3863, Contrastive: 0.2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:47:33,856] Trial 91 finished with value: 0.7782127897332745 and parameters: {'alpha': 0.261481751135179, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.16620505990497478, 'margin': 0.2928417689224114, 'lpl_weight': 0.15988119976050966, 'ratio': 0.44418260959373734, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7930, F1=0.7822, Recall=0.9309, Precision=0.6745\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102214444.csv.\n",
      "Average F1 over 5 seeds: 0.7782  0.0074\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2879927360010038, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.19412608311684998, margin=0.21014325088733715, lpl_weight=0.31194034411782334\n",
      " - ratio=0.22716371048743114, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5521, LPL: 1.3863, Contrastive: 0.1740\n",
      "Epoch 50, Loss: 0.5425, LPL: 1.3863, Contrastive: 0.1600\n",
      " - Metrics: Accuracy=0.8962, F1=0.8678, Recall=0.8528, Precision=0.8833\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2879927360010038, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.19412608311684998, margin=0.21014325088733715, lpl_weight=0.31194034411782334\n",
      " - ratio=0.22716371048743114, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5521, LPL: 1.3863, Contrastive: 0.1740\n",
      "Epoch 50, Loss: 0.5425, LPL: 1.3863, Contrastive: 0.1600\n",
      " - Metrics: Accuracy=0.8955, F1=0.8671, Recall=0.8535, Precision=0.8812\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2879927360010038, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.19412608311684998, margin=0.21014325088733715, lpl_weight=0.31194034411782334\n",
      " - ratio=0.22716371048743114, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5521, LPL: 1.3863, Contrastive: 0.1740\n",
      "Epoch 50, Loss: 0.5425, LPL: 1.3863, Contrastive: 0.1600\n",
      " - Metrics: Accuracy=0.8986, F1=0.8716, Recall=0.8618, Precision=0.8817\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2879927360010038, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.19412608311684998, margin=0.21014325088733715, lpl_weight=0.31194034411782334\n",
      " - ratio=0.22716371048743114, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5521, LPL: 1.3863, Contrastive: 0.1740\n",
      "Epoch 50, Loss: 0.5425, LPL: 1.3863, Contrastive: 0.1600\n",
      " - Metrics: Accuracy=0.8957, F1=0.8675, Recall=0.8543, Precision=0.8810\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2879927360010038, K=34, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.19412608311684998, margin=0.21014325088733715, lpl_weight=0.31194034411782334\n",
      " - ratio=0.22716371048743114, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5521, LPL: 1.3863, Contrastive: 0.1740\n",
      "Epoch 50, Loss: 0.5425, LPL: 1.3863, Contrastive: 0.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:50:08,136] Trial 92 finished with value: 0.8685777821112127 and parameters: {'alpha': 0.2879927360010038, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.19412608311684998, 'margin': 0.21014325088733715, 'lpl_weight': 0.31194034411782334, 'ratio': 0.22716371048743114, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8971, F1=0.8689, Recall=0.8536, Precision=0.8847\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102214733.csv.\n",
      "Average F1 over 5 seeds: 0.8686  0.0016\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2388206460666491, K=29, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15225967510123173, margin=0.26203646505810835, lpl_weight=0.2863608284713956\n",
      " - ratio=0.2473656942887056, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5072, LPL: 1.3863, Contrastive: 0.1544\n",
      "Epoch 50, Loss: 0.4969, LPL: 1.3863, Contrastive: 0.1400\n",
      " - Metrics: Accuracy=0.8948, F1=0.8683, Recall=0.8687, Precision=0.8679\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2388206460666491, K=29, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15225967510123173, margin=0.26203646505810835, lpl_weight=0.2863608284713956\n",
      " - ratio=0.2473656942887056, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5072, LPL: 1.3863, Contrastive: 0.1544\n",
      "Epoch 50, Loss: 0.4969, LPL: 1.3863, Contrastive: 0.1400\n",
      " - Metrics: Accuracy=0.8879, F1=0.8602, Recall=0.8635, Precision=0.8570\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2388206460666491, K=29, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15225967510123173, margin=0.26203646505810835, lpl_weight=0.2863608284713956\n",
      " - ratio=0.2473656942887056, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5072, LPL: 1.3863, Contrastive: 0.1544\n",
      "Epoch 50, Loss: 0.4969, LPL: 1.3863, Contrastive: 0.1400\n",
      " - Metrics: Accuracy=0.8954, F1=0.8691, Recall=0.8693, Precision=0.8689\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2388206460666491, K=29, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15225967510123173, margin=0.26203646505810835, lpl_weight=0.2863608284713956\n",
      " - ratio=0.2473656942887056, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5072, LPL: 1.3863, Contrastive: 0.1544\n",
      "Epoch 50, Loss: 0.4969, LPL: 1.3863, Contrastive: 0.1400\n",
      " - Metrics: Accuracy=0.8933, F1=0.8666, Recall=0.8674, Precision=0.8658\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2388206460666491, K=29, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15225967510123173, margin=0.26203646505810835, lpl_weight=0.2863608284713956\n",
      " - ratio=0.2473656942887056, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5072, LPL: 1.3863, Contrastive: 0.1544\n",
      "Epoch 50, Loss: 0.4969, LPL: 1.3863, Contrastive: 0.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:52:40,847] Trial 93 finished with value: 0.865962933127402 and parameters: {'alpha': 0.2388206460666491, 'K': 29, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.15225967510123173, 'margin': 0.26203646505810835, 'lpl_weight': 0.2863608284713956, 'ratio': 0.2473656942887056, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8925, F1=0.8656, Recall=0.8663, Precision=0.8649\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102215008.csv.\n",
      "Average F1 over 5 seeds: 0.8660  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.33473694224342493, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18050400111440143, margin=0.12121296247253115, lpl_weight=0.25015907888549044\n",
      " - ratio=0.19388516302487063, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5074, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.4953, LPL: 1.3863, Contrastive: 0.1981\n",
      " - Metrics: Accuracy=0.9053, F1=0.8766, Recall=0.8428, Precision=0.9133\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.33473694224342493, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18050400111440143, margin=0.12121296247253115, lpl_weight=0.25015907888549044\n",
      " - ratio=0.19388516302487063, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5074, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.4953, LPL: 1.3863, Contrastive: 0.1981\n",
      " - Metrics: Accuracy=0.9020, F1=0.8722, Recall=0.8375, Precision=0.9099\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.33473694224342493, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18050400111440143, margin=0.12121296247253115, lpl_weight=0.25015907888549044\n",
      " - ratio=0.19388516302487063, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5074, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.4953, LPL: 1.3863, Contrastive: 0.1980\n",
      " - Metrics: Accuracy=0.9059, F1=0.8769, Recall=0.8389, Precision=0.9185\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.33473694224342493, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18050400111440143, margin=0.12121296247253115, lpl_weight=0.25015907888549044\n",
      " - ratio=0.19388516302487063, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5074, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.4953, LPL: 1.3863, Contrastive: 0.1981\n",
      " - Metrics: Accuracy=0.9049, F1=0.8757, Recall=0.8383, Precision=0.9164\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.33473694224342493, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18050400111440143, margin=0.12121296247253115, lpl_weight=0.25015907888549044\n",
      " - ratio=0.19388516302487063, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5074, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.4955, LPL: 1.3863, Contrastive: 0.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:55:22,463] Trial 94 finished with value: 0.8742346129091849 and parameters: {'alpha': 0.33473694224342493, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.18050400111440143, 'margin': 0.12121296247253115, 'lpl_weight': 0.25015907888549044, 'ratio': 0.19388516302487063, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9004, F1=0.8698, Recall=0.8328, Precision=0.9103\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102215240.csv.\n",
      "Average F1 over 5 seeds: 0.8742  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5234732213023464, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17576516045636184, margin=0.12158478588988364, lpl_weight=0.10787803031519594\n",
      " - ratio=0.17767483668519016, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3406, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.3265, LPL: 1.3863, Contrastive: 0.1984\n",
      " - Metrics: Accuracy=0.9035, F1=0.8724, Recall=0.8262, Precision=0.9241\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5234732213023464, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17576516045636184, margin=0.12158478588988364, lpl_weight=0.10787803031519594\n",
      " - ratio=0.17767483668519016, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3406, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.3265, LPL: 1.3863, Contrastive: 0.1984\n",
      " - Metrics: Accuracy=0.9007, F1=0.8688, Recall=0.8230, Precision=0.9201\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5234732213023464, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17576516045636184, margin=0.12158478588988364, lpl_weight=0.10787803031519594\n",
      " - ratio=0.17767483668519016, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3406, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.3265, LPL: 1.3863, Contrastive: 0.1983\n",
      " - Metrics: Accuracy=0.9017, F1=0.8699, Recall=0.8226, Precision=0.9229\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5234732213023464, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17576516045636184, margin=0.12158478588988364, lpl_weight=0.10787803031519594\n",
      " - ratio=0.17767483668519016, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3406, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.3265, LPL: 1.3863, Contrastive: 0.1983\n",
      " - Metrics: Accuracy=0.8989, F1=0.8657, Recall=0.8157, Precision=0.9221\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5234732213023464, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.17576516045636184, margin=0.12158478588988364, lpl_weight=0.10787803031519594\n",
      " - ratio=0.17767483668519016, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3406, LPL: 1.3863, Contrastive: 0.2141\n",
      "Epoch 50, Loss: 0.3265, LPL: 1.3863, Contrastive: 0.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 21:57:58,690] Trial 95 finished with value: 0.8686696512673487 and parameters: {'alpha': 0.5234732213023464, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.17576516045636184, 'margin': 0.12158478588988364, 'lpl_weight': 0.10787803031519594, 'ratio': 0.17767483668519016, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9000, F1=0.8666, Recall=0.8128, Precision=0.9280\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102215522.csv.\n",
      "Average F1 over 5 seeds: 0.8687  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.33056829007648636, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14205295604318097, margin=0.14934391782090645, lpl_weight=0.17552399838189858\n",
      " - ratio=0.19407220123625332, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4097, LPL: 1.3863, Contrastive: 0.2019\n",
      "Epoch 50, Loss: 0.3962, LPL: 1.3863, Contrastive: 0.1854\n",
      " - Metrics: Accuracy=0.9041, F1=0.8747, Recall=0.8381, Precision=0.9146\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.33056829007648636, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14205295604318097, margin=0.14934391782090645, lpl_weight=0.17552399838189858\n",
      " - ratio=0.19407220123625332, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4097, LPL: 1.3863, Contrastive: 0.2019\n",
      "Epoch 50, Loss: 0.3962, LPL: 1.3863, Contrastive: 0.1854\n",
      " - Metrics: Accuracy=0.8994, F1=0.8687, Recall=0.8330, Precision=0.9076\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.33056829007648636, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14205295604318097, margin=0.14934391782090645, lpl_weight=0.17552399838189858\n",
      " - ratio=0.19407220123625332, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4097, LPL: 1.3863, Contrastive: 0.2019\n",
      "Epoch 50, Loss: 0.3962, LPL: 1.3863, Contrastive: 0.1854\n",
      " - Metrics: Accuracy=0.9035, F1=0.8740, Recall=0.8381, Precision=0.9131\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.33056829007648636, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14205295604318097, margin=0.14934391782090645, lpl_weight=0.17552399838189858\n",
      " - ratio=0.19407220123625332, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4097, LPL: 1.3863, Contrastive: 0.2019\n",
      "Epoch 50, Loss: 0.3962, LPL: 1.3863, Contrastive: 0.1854\n",
      " - Metrics: Accuracy=0.9038, F1=0.8743, Recall=0.8376, Precision=0.9143\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.33056829007648636, K=31, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14205295604318097, margin=0.14934391782090645, lpl_weight=0.17552399838189858\n",
      " - ratio=0.19407220123625332, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4097, LPL: 1.3863, Contrastive: 0.2019\n",
      "Epoch 50, Loss: 0.3962, LPL: 1.3863, Contrastive: 0.1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:00:30,432] Trial 96 finished with value: 0.8727248295103239 and parameters: {'alpha': 0.33056829007648636, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.14205295604318097, 'margin': 0.14934391782090645, 'lpl_weight': 0.17552399838189858, 'ratio': 0.19407220123625332, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9020, F1=0.8720, Recall=0.8353, Precision=0.9120\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102215758.csv.\n",
      "Average F1 over 5 seeds: 0.8727  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.32176502098855747, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14381062029895925, margin=0.14277903055043734, lpl_weight=0.17886352384933246\n",
      " - ratio=0.1634356117255546, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4162, LPL: 1.3863, Contrastive: 0.2049\n",
      "Epoch 50, Loss: 0.4024, LPL: 1.3863, Contrastive: 0.1881\n",
      " - Metrics: Accuracy=0.9040, F1=0.8724, Recall=0.8215, Precision=0.9300\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.32176502098855747, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14381062029895925, margin=0.14277903055043734, lpl_weight=0.17886352384933246\n",
      " - ratio=0.1634356117255546, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4162, LPL: 1.3863, Contrastive: 0.2049\n",
      "Epoch 50, Loss: 0.4024, LPL: 1.3863, Contrastive: 0.1881\n",
      " - Metrics: Accuracy=0.9003, F1=0.8668, Recall=0.8121, Precision=0.9295\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.32176502098855747, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14381062029895925, margin=0.14277903055043734, lpl_weight=0.17886352384933246\n",
      " - ratio=0.1634356117255546, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4162, LPL: 1.3863, Contrastive: 0.2049\n",
      "Epoch 50, Loss: 0.4024, LPL: 1.3863, Contrastive: 0.1880\n",
      " - Metrics: Accuracy=0.9021, F1=0.8697, Recall=0.8183, Precision=0.9280\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.32176502098855747, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14381062029895925, margin=0.14277903055043734, lpl_weight=0.17886352384933246\n",
      " - ratio=0.1634356117255546, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4162, LPL: 1.3863, Contrastive: 0.2049\n",
      "Epoch 50, Loss: 0.4024, LPL: 1.3863, Contrastive: 0.1881\n",
      " - Metrics: Accuracy=0.9004, F1=0.8666, Recall=0.8098, Precision=0.9319\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.32176502098855747, K=32, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.14381062029895925, margin=0.14277903055043734, lpl_weight=0.17886352384933246\n",
      " - ratio=0.1634356117255546, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4162, LPL: 1.3863, Contrastive: 0.2049\n",
      "Epoch 50, Loss: 0.4024, LPL: 1.3863, Contrastive: 0.1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:03:05,021] Trial 97 finished with value: 0.8684310047034624 and parameters: {'alpha': 0.32176502098855747, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.14381062029895925, 'margin': 0.14277903055043734, 'lpl_weight': 0.17886352384933246, 'ratio': 0.1634356117255546, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8995, F1=0.8667, Recall=0.8179, Precision=0.9217\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102220030.csv.\n",
      "Average F1 over 5 seeds: 0.8684  0.0023\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.48256039271278767, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15901028160211172, margin=0.10639351341870959, lpl_weight=0.2325810829408509\n",
      " - ratio=0.20977693064439082, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4932, LPL: 1.3863, Contrastive: 0.2225\n",
      "Epoch 50, Loss: 0.4793, LPL: 1.3863, Contrastive: 0.2044\n",
      " - Metrics: Accuracy=0.9024, F1=0.8747, Recall=0.8535, Precision=0.8971\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.48256039271278767, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15901028160211172, margin=0.10639351341870959, lpl_weight=0.2325810829408509\n",
      " - ratio=0.20977693064439082, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4932, LPL: 1.3863, Contrastive: 0.2225\n",
      "Epoch 50, Loss: 0.4793, LPL: 1.3863, Contrastive: 0.2044\n",
      " - Metrics: Accuracy=0.8969, F1=0.8673, Recall=0.8436, Precision=0.8924\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.48256039271278767, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15901028160211172, margin=0.10639351341870959, lpl_weight=0.2325810829408509\n",
      " - ratio=0.20977693064439082, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4932, LPL: 1.3863, Contrastive: 0.2225\n",
      "Epoch 50, Loss: 0.4793, LPL: 1.3863, Contrastive: 0.2044\n",
      " - Metrics: Accuracy=0.9038, F1=0.8761, Recall=0.8514, Precision=0.9023\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.48256039271278767, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15901028160211172, margin=0.10639351341870959, lpl_weight=0.2325810829408509\n",
      " - ratio=0.20977693064439082, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4932, LPL: 1.3863, Contrastive: 0.2225\n",
      "Epoch 50, Loss: 0.4793, LPL: 1.3863, Contrastive: 0.2044\n",
      " - Metrics: Accuracy=0.9038, F1=0.8766, Recall=0.8549, Precision=0.8994\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.48256039271278767, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.15901028160211172, margin=0.10639351341870959, lpl_weight=0.2325810829408509\n",
      " - ratio=0.20977693064439082, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.4932, LPL: 1.3863, Contrastive: 0.2225\n",
      "Epoch 50, Loss: 0.4793, LPL: 1.3863, Contrastive: 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:05:41,359] Trial 98 finished with value: 0.8731123342367499 and parameters: {'alpha': 0.48256039271278767, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.15901028160211172, 'margin': 0.10639351341870959, 'lpl_weight': 0.2325810829408509, 'ratio': 0.20977693064439082, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8999, F1=0.8709, Recall=0.8447, Precision=0.8987\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102220305.csv.\n",
      "Average F1 over 5 seeds: 0.8731  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.33737490324687214, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15254646016424606, margin=0.16780192566367524, lpl_weight=0.6003564058838708\n",
      " - ratio=0.20517796411393624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9109, LPL: 1.3863, Contrastive: 0.1968\n",
      "Epoch 50, Loss: 0.9036, LPL: 1.3863, Contrastive: 0.1785\n",
      " - Metrics: Accuracy=0.9015, F1=0.8731, Recall=0.8490, Precision=0.8987\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.33737490324687214, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15254646016424606, margin=0.16780192566367524, lpl_weight=0.6003564058838708\n",
      " - ratio=0.20517796411393624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9109, LPL: 1.3863, Contrastive: 0.1968\n",
      "Epoch 50, Loss: 0.9036, LPL: 1.3863, Contrastive: 0.1785\n",
      " - Metrics: Accuracy=0.8954, F1=0.8654, Recall=0.8417, Precision=0.8905\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.33737490324687214, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15254646016424606, margin=0.16780192566367524, lpl_weight=0.6003564058838708\n",
      " - ratio=0.20517796411393624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9109, LPL: 1.3863, Contrastive: 0.1968\n",
      "Epoch 50, Loss: 0.9036, LPL: 1.3863, Contrastive: 0.1785\n",
      " - Metrics: Accuracy=0.8993, F1=0.8707, Recall=0.8489, Precision=0.8937\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.33737490324687214, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15254646016424606, margin=0.16780192566367524, lpl_weight=0.6003564058838708\n",
      " - ratio=0.20517796411393624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9109, LPL: 1.3863, Contrastive: 0.1968\n",
      "Epoch 50, Loss: 0.9036, LPL: 1.3863, Contrastive: 0.1785\n",
      " - Metrics: Accuracy=0.9013, F1=0.8733, Recall=0.8517, Precision=0.8959\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.33737490324687214, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15254646016424606, margin=0.16780192566367524, lpl_weight=0.6003564058838708\n",
      " - ratio=0.20517796411393624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9109, LPL: 1.3863, Contrastive: 0.1968\n",
      "Epoch 50, Loss: 0.9036, LPL: 1.3863, Contrastive: 0.1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:08:00,464] Trial 99 finished with value: 0.8701494293856019 and parameters: {'alpha': 0.33737490324687214, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.15254646016424606, 'margin': 0.16780192566367524, 'lpl_weight': 0.6003564058838708, 'ratio': 0.20517796411393624, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 22 with value: 0.8749015333712882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8978, F1=0.8683, Recall=0.8436, Precision=0.8944\n",
      "Done. Results written to pubmed_experimentations\\pubmed_sar_2102220541.csv.\n",
      "Average F1 over 5 seeds: 0.8701  0.0030\n",
      "Best trial:\n",
      "  Average F1: 0.8749015333712882\n",
      "  Best parameters:\n",
      "    alpha: 0.25503455062799246\n",
      "    K: 34\n",
      "    layers: 2\n",
      "    hidden_channels: 128\n",
      "    out_channels: 128\n",
      "    norm: graphnorm\n",
      "    dropout: 0.34674827917164924\n",
      "    margin: 0.16177445978937793\n",
      "    lpl_weight: 0.8360928606739102\n",
      "    ratio: 0.21468635530396302\n",
      "    aggregation: sum\n",
      "    treatment: relabeling\n"
     ]
    }
   ],
   "source": [
    "from train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"pubmed\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": 1,#trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"pubmed_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization WikiCS\n",
    "#### SCAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:08:00,492] A new study created in memory with name: no-name-dd1a6520-6978-4618-b794-15799f53f943\n",
      "Downloading https://github.com/pmernyei/wiki-cs-dataset/raw/master/dataset/data.json\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.26230288428650056, K=28, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15989127092269012, margin=0.1360543722031557, lpl_weight=0.7861329047415934\n",
      " - ratio=0.33320739969764335, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1423, LPL: 1.3863, Contrastive: 0.2456\n",
      " - Metrics: Accuracy=0.9227, F1=0.8492, Recall=0.9511, Precision=0.7670\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.26230288428650056, K=28, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15989127092269012, margin=0.1360543722031557, lpl_weight=0.7861329047415934\n",
      " - ratio=0.33320739969764335, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1423, LPL: 1.3863, Contrastive: 0.2456\n",
      " - Metrics: Accuracy=0.9296, F1=0.8619, Recall=0.9601, Precision=0.7820\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.26230288428650056, K=28, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15989127092269012, margin=0.1360543722031557, lpl_weight=0.7861329047415934\n",
      " - ratio=0.33320739969764335, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1423, LPL: 1.3863, Contrastive: 0.2456\n",
      " - Metrics: Accuracy=0.9313, F1=0.8647, Recall=0.9589, Precision=0.7873\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.26230288428650056, K=28, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15989127092269012, margin=0.1360543722031557, lpl_weight=0.7861329047415934\n",
      " - ratio=0.33320739969764335, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1423, LPL: 1.3863, Contrastive: 0.2456\n",
      " - Metrics: Accuracy=0.9284, F1=0.8598, Recall=0.9593, Precision=0.7790\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.26230288428650056, K=28, layers=1, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.15989127092269012, margin=0.1360543722031557, lpl_weight=0.7861329047415934\n",
      " - ratio=0.33320739969764335, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1423, LPL: 1.3863, Contrastive: 0.2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:09:43,133] Trial 0 finished with value: 0.8593218951028216 and parameters: {'alpha': 0.26230288428650056, 'K': 28, 'layers': 1, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.15989127092269012, 'margin': 0.1360543722031557, 'lpl_weight': 0.7861329047415934, 'ratio': 0.33320739969764335, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 0 with value: 0.8593218951028216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9292, F1=0.8610, Recall=0.9582, Precision=0.7817\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102220800.csv.\n",
      "Average F1 over 5 seeds: 0.8593  0.0053\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9732421061358966, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12516915630102776, margin=0.9613217965088279, lpl_weight=0.8738782539513014\n",
      " - ratio=0.11919029146719083, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9409, F1=0.8685, Recall=0.8518, Precision=0.8859\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9732421061358966, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12516915630102776, margin=0.9613217965088279, lpl_weight=0.8738782539513014\n",
      " - ratio=0.11919029146719083, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9430, F1=0.8731, Recall=0.8563, Precision=0.8905\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9732421061358966, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12516915630102776, margin=0.9613217965088279, lpl_weight=0.8738782539513014\n",
      " - ratio=0.11919029146719083, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9452, F1=0.8780, Recall=0.8611, Precision=0.8956\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9732421061358966, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12516915630102776, margin=0.9613217965088279, lpl_weight=0.8738782539513014\n",
      " - ratio=0.11919029146719083, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9440, F1=0.8754, Recall=0.8585, Precision=0.8929\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9732421061358966, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12516915630102776, margin=0.9613217965088279, lpl_weight=0.8738782539513014\n",
      " - ratio=0.11919029146719083, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:14:27,614] Trial 1 finished with value: 0.8728018668753851 and parameters: {'alpha': 0.9732421061358966, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.12516915630102776, 'margin': 0.9613217965088279, 'lpl_weight': 0.8738782539513014, 'ratio': 0.11919029146719083, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 1 with value: 0.8728018668753851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9412, F1=0.8691, Recall=0.8522, Precision=0.8866\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102220943.csv.\n",
      "Average F1 over 5 seeds: 0.8728  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8600240011455991, K=30, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.4501758613784027, margin=0.579305291646898, lpl_weight=0.9144370093608337\n",
      " - ratio=0.2818078603877726, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2848, LPL: 1.3863, Contrastive: 0.2000\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8984, F1=0.8009, Recall=0.8925, Precision=0.7263\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8600240011455991, K=30, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.4501758613784027, margin=0.579305291646898, lpl_weight=0.9144370093608337\n",
      " - ratio=0.2818078603877726, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2848, LPL: 1.3863, Contrastive: 0.2000\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9012, F1=0.8053, Recall=0.8925, Precision=0.7337\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8600240011455991, K=30, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.4501758613784027, margin=0.579305291646898, lpl_weight=0.9144370093608337\n",
      " - ratio=0.2818078603877726, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2848, LPL: 1.3863, Contrastive: 0.2000\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8951, F1=0.7969, Recall=0.8985, Precision=0.7159\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8600240011455991, K=30, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.4501758613784027, margin=0.579305291646898, lpl_weight=0.9144370093608337\n",
      " - ratio=0.2818078603877726, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2848, LPL: 1.3863, Contrastive: 0.2000\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8988, F1=0.8026, Recall=0.8985, Precision=0.7252\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8600240011455991, K=30, layers=1, hidden=64, out=256\n",
      " - norm=None, dropout=0.4501758613784027, margin=0.579305291646898, lpl_weight=0.9144370093608337\n",
      " - ratio=0.2818078603877726, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.2848, LPL: 1.3863, Contrastive: 0.2000\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:19:13,239] Trial 2 finished with value: 0.800803764410054 and parameters: {'alpha': 0.8600240011455991, 'K': 30, 'layers': 1, 'hidden_channels': 64, 'out_channels': 256, 'norm': None, 'dropout': 0.4501758613784027, 'margin': 0.579305291646898, 'lpl_weight': 0.9144370093608337, 'ratio': 0.2818078603877726, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 1 with value: 0.8728018668753851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8963, F1=0.7983, Recall=0.8962, Precision=0.7197\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102221427.csv.\n",
      "Average F1 over 5 seeds: 0.8008  0.0030\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.78746087819085, K=27, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4433937480816078, margin=0.41873103722433735, lpl_weight=0.4527111913184111\n",
      " - ratio=0.3664377396018502, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7701, LPL: 1.3863, Contrastive: 0.2604\n",
      " - Metrics: Accuracy=0.9049, F1=0.8235, Recall=0.9690, Precision=0.7159\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.78746087819085, K=27, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4433937480816078, margin=0.41873103722433735, lpl_weight=0.4527111913184111\n",
      " - ratio=0.3664377396018502, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7701, LPL: 1.3863, Contrastive: 0.2604\n",
      " - Metrics: Accuracy=0.9068, F1=0.8263, Recall=0.9675, Precision=0.7210\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.78746087819085, K=27, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4433937480816078, margin=0.41873103722433735, lpl_weight=0.4527111913184111\n",
      " - ratio=0.3664377396018502, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7701, LPL: 1.3863, Contrastive: 0.2604\n",
      " - Metrics: Accuracy=0.9050, F1=0.8238, Recall=0.9701, Precision=0.7158\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.78746087819085, K=27, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4433937480816078, margin=0.41873103722433735, lpl_weight=0.4527111913184111\n",
      " - ratio=0.3664377396018502, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7701, LPL: 1.3863, Contrastive: 0.2604\n",
      " - Metrics: Accuracy=0.9060, F1=0.8255, Recall=0.9713, Precision=0.7178\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.78746087819085, K=27, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4433937480816078, margin=0.41873103722433735, lpl_weight=0.4527111913184111\n",
      " - ratio=0.3664377396018502, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7701, LPL: 1.3863, Contrastive: 0.2604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:20:52,639] Trial 3 finished with value: 0.8247413260312391 and parameters: {'alpha': 0.78746087819085, 'K': 27, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.4433937480816078, 'margin': 0.41873103722433735, 'lpl_weight': 0.4527111913184111, 'ratio': 0.3664377396018502, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.8728018668753851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9056, F1=0.8247, Recall=0.9701, Precision=0.7172\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102221913.csv.\n",
      "Average F1 over 5 seeds: 0.8247  0.0010\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6461119102012606, K=27, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.19822553426759934, margin=0.9515571188808567, lpl_weight=0.5029821271843351\n",
      " - ratio=0.387254952216878, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8622, F1=0.7563, Recall=0.9336, Precision=0.6356\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6461119102012606, K=27, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.19822553426759934, margin=0.9515571188808567, lpl_weight=0.5029821271843351\n",
      " - ratio=0.387254952216878, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8721, F1=0.7698, Recall=0.9339, Precision=0.6548\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6461119102012606, K=27, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.19822553426759934, margin=0.9515571188808567, lpl_weight=0.5029821271843351\n",
      " - ratio=0.387254952216878, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8631, F1=0.7568, Recall=0.9302, Precision=0.6378\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6461119102012606, K=27, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.19822553426759934, margin=0.9515571188808567, lpl_weight=0.5029821271843351\n",
      " - ratio=0.387254952216878, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8653, F1=0.7612, Recall=0.9377, Precision=0.6407\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6461119102012606, K=27, layers=1, hidden=256, out=256\n",
      " - norm=None, dropout=0.19822553426759934, margin=0.9515571188808567, lpl_weight=0.5029821271843351\n",
      " - ratio=0.387254952216878, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:26:35,465] Trial 4 finished with value: 0.7593613984430474 and parameters: {'alpha': 0.6461119102012606, 'K': 27, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': None, 'dropout': 0.19822553426759934, 'margin': 0.9515571188808567, 'lpl_weight': 0.5029821271843351, 'ratio': 0.387254952216878, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 1 with value: 0.8728018668753851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8600, F1=0.7527, Recall=0.9306, Precision=0.6319\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102222052.csv.\n",
      "Average F1 over 5 seeds: 0.7594  0.0059\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7597981608017028, K=35, layers=3, hidden=64, out=64\n",
      " - norm=None, dropout=0.37376477937286556, margin=0.4850035483661632, lpl_weight=0.23515632094486633\n",
      " - ratio=0.46297470326458534, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8107, F1=0.6905, Recall=0.9224, Precision=0.5518\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7597981608017028, K=35, layers=3, hidden=64, out=64\n",
      " - norm=None, dropout=0.37376477937286556, margin=0.4850035483661632, lpl_weight=0.23515632094486633\n",
      " - ratio=0.46297470326458534, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8032, F1=0.6819, Recall=0.9212, Precision=0.5412\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7597981608017028, K=35, layers=3, hidden=64, out=64\n",
      " - norm=None, dropout=0.37376477937286556, margin=0.4850035483661632, lpl_weight=0.23515632094486633\n",
      " - ratio=0.46297470326458534, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8035, F1=0.6811, Recall=0.9164, Precision=0.5419\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7597981608017028, K=35, layers=3, hidden=64, out=64\n",
      " - norm=None, dropout=0.37376477937286556, margin=0.4850035483661632, lpl_weight=0.23515632094486633\n",
      " - ratio=0.46297470326458534, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8097, F1=0.6906, Recall=0.9276, Precision=0.5500\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7597981608017028, K=35, layers=3, hidden=64, out=64\n",
      " - norm=None, dropout=0.37376477937286556, margin=0.4850035483661632, lpl_weight=0.23515632094486633\n",
      " - ratio=0.46297470326458534, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:29:57,761] Trial 5 finished with value: 0.6819227034557822 and parameters: {'alpha': 0.7597981608017028, 'K': 35, 'layers': 3, 'hidden_channels': 64, 'out_channels': 64, 'norm': None, 'dropout': 0.37376477937286556, 'margin': 0.4850035483661632, 'lpl_weight': 0.23515632094486633, 'ratio': 0.46297470326458534, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 1 with value: 0.8728018668753851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7896, F1=0.6656, Recall=0.9145, Precision=0.5232\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102222635.csv.\n",
      "Average F1 over 5 seeds: 0.6819  0.0091\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.33178738960850884, K=34, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.31707040491761096, margin=0.1308698355654633, lpl_weight=0.3269625481864584\n",
      " - ratio=0.3384854431179214, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5924, LPL: 1.3863, Contrastive: 0.2067\n",
      "Epoch 50, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.1940\n",
      " - Metrics: Accuracy=0.8982, F1=0.8127, Recall=0.9645, Precision=0.7022\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.33178738960850884, K=34, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.31707040491761096, margin=0.1308698355654633, lpl_weight=0.3269625481864584\n",
      " - ratio=0.3384854431179214, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5924, LPL: 1.3863, Contrastive: 0.2067\n",
      "Epoch 50, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.1940\n",
      " - Metrics: Accuracy=0.8941, F1=0.8063, Recall=0.9623, Precision=0.6938\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.33178738960850884, K=34, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.31707040491761096, margin=0.1308698355654633, lpl_weight=0.3269625481864584\n",
      " - ratio=0.3384854431179214, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5924, LPL: 1.3863, Contrastive: 0.2067\n",
      "Epoch 50, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.1940\n",
      " - Metrics: Accuracy=0.8927, F1=0.8043, Recall=0.9627, Precision=0.6907\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.33178738960850884, K=34, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.31707040491761096, margin=0.1308698355654633, lpl_weight=0.3269625481864584\n",
      " - ratio=0.3384854431179214, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5924, LPL: 1.3863, Contrastive: 0.2067\n",
      "Epoch 50, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.1940\n",
      " - Metrics: Accuracy=0.9315, F1=0.8657, Recall=0.9634, Precision=0.7859\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.33178738960850884, K=34, layers=3, hidden=256, out=64\n",
      " - norm=None, dropout=0.31707040491761096, margin=0.1308698355654633, lpl_weight=0.3269625481864584\n",
      " - ratio=0.3384854431179214, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5924, LPL: 1.3863, Contrastive: 0.2067\n",
      "Epoch 50, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.1940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:32:08,014] Trial 6 finished with value: 0.8186798071442235 and parameters: {'alpha': 0.33178738960850884, 'K': 34, 'layers': 3, 'hidden_channels': 256, 'out_channels': 64, 'norm': None, 'dropout': 0.31707040491761096, 'margin': 0.1308698355654633, 'lpl_weight': 0.3269625481864584, 'ratio': 0.3384854431179214, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.8728018668753851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8921, F1=0.8045, Recall=0.9690, Precision=0.6877\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102222957.csv.\n",
      "Average F1 over 5 seeds: 0.8187  0.0237\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6387605099586346, K=25, layers=2, hidden=256, out=64\n",
      " - norm=None, dropout=0.44227518739251437, margin=0.5684888628364444, lpl_weight=0.33515457874327126\n",
      " - ratio=0.30271797846093645, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.2765\n",
      " - Metrics: Accuracy=0.8939, F1=0.8032, Recall=0.9455, Precision=0.6982\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6387605099586346, K=25, layers=2, hidden=256, out=64\n",
      " - norm=None, dropout=0.44227518739251437, margin=0.5684888628364444, lpl_weight=0.33515457874327126\n",
      " - ratio=0.30271797846093645, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.2765\n",
      " - Metrics: Accuracy=0.9019, F1=0.8158, Recall=0.9492, Precision=0.7153\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6387605099586346, K=25, layers=2, hidden=256, out=64\n",
      " - norm=None, dropout=0.44227518739251437, margin=0.5684888628364444, lpl_weight=0.33515457874327126\n",
      " - ratio=0.30271797846093645, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.2765\n",
      " - Metrics: Accuracy=0.8956, F1=0.8052, Recall=0.9425, Precision=0.7028\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6387605099586346, K=25, layers=2, hidden=256, out=64\n",
      " - norm=None, dropout=0.44227518739251437, margin=0.5684888628364444, lpl_weight=0.33515457874327126\n",
      " - ratio=0.30271797846093645, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.2765\n",
      " - Metrics: Accuracy=0.9007, F1=0.8144, Recall=0.9518, Precision=0.7117\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6387605099586346, K=25, layers=2, hidden=256, out=64\n",
      " - norm=None, dropout=0.44227518739251437, margin=0.5684888628364444, lpl_weight=0.33515457874327126\n",
      " - ratio=0.30271797846093645, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.6484, LPL: 1.3863, Contrastive: 0.2765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:33:26,917] Trial 7 finished with value: 0.8093036639890636 and parameters: {'alpha': 0.6387605099586346, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': None, 'dropout': 0.44227518739251437, 'margin': 0.5684888628364444, 'lpl_weight': 0.33515457874327126, 'ratio': 0.30271797846093645, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 1 with value: 0.8728018668753851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8968, F1=0.8078, Recall=0.9470, Precision=0.7043\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102223208.csv.\n",
      "Average F1 over 5 seeds: 0.8093  0.0050\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7747382784185234, K=35, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2163137727607794, margin=0.5675813801514884, lpl_weight=0.36587898308306455\n",
      " - ratio=0.35168702940845986, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8978, F1=0.8017, Recall=0.9022, Precision=0.7213\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7747382784185234, K=35, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2163137727607794, margin=0.5675813801514884, lpl_weight=0.36587898308306455\n",
      " - ratio=0.35168702940845986, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8913, F1=0.7915, Recall=0.9011, Precision=0.7056\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7747382784185234, K=35, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2163137727607794, margin=0.5675813801514884, lpl_weight=0.36587898308306455\n",
      " - ratio=0.35168702940845986, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8957, F1=0.7978, Recall=0.8985, Precision=0.7174\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7747382784185234, K=35, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2163137727607794, margin=0.5675813801514884, lpl_weight=0.36587898308306455\n",
      " - ratio=0.35168702940845986, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8825, F1=0.7802, Recall=0.9108, Precision=0.6823\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7747382784185234, K=35, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.2163137727607794, margin=0.5675813801514884, lpl_weight=0.36587898308306455\n",
      " - ratio=0.35168702940845986, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:41:41,233] Trial 8 finished with value: 0.7900432686469028 and parameters: {'alpha': 0.7747382784185234, 'K': 35, 'layers': 3, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.2163137727607794, 'margin': 0.5675813801514884, 'lpl_weight': 0.36587898308306455, 'ratio': 0.35168702940845986, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 1 with value: 0.8728018668753851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8837, F1=0.7791, Recall=0.8959, Precision=0.6893\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102223326.csv.\n",
      "Average F1 over 5 seeds: 0.7900  0.0091\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7251301981467673, K=33, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.15251225732900406, margin=0.44227162058489855, lpl_weight=0.7447141517579541\n",
      " - ratio=0.1957601763574317, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0821, LPL: 1.3863, Contrastive: 0.1946\n",
      " - Metrics: Accuracy=0.9433, F1=0.8842, Recall=0.9451, Precision=0.8307\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7251301981467673, K=33, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.15251225732900406, margin=0.44227162058489855, lpl_weight=0.7447141517579541\n",
      " - ratio=0.1957601763574317, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0821, LPL: 1.3863, Contrastive: 0.1946\n",
      " - Metrics: Accuracy=0.9421, F1=0.8819, Recall=0.9433, Precision=0.8280\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7251301981467673, K=33, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.15251225732900406, margin=0.44227162058489855, lpl_weight=0.7447141517579541\n",
      " - ratio=0.1957601763574317, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0821, LPL: 1.3863, Contrastive: 0.1946\n",
      " - Metrics: Accuracy=0.9415, F1=0.8811, Recall=0.9459, Precision=0.8246\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7251301981467673, K=33, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.15251225732900406, margin=0.44227162058489855, lpl_weight=0.7447141517579541\n",
      " - ratio=0.1957601763574317, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0821, LPL: 1.3863, Contrastive: 0.1946\n",
      " - Metrics: Accuracy=0.9443, F1=0.8864, Recall=0.9496, Precision=0.8311\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7251301981467673, K=33, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.15251225732900406, margin=0.44227162058489855, lpl_weight=0.7447141517579541\n",
      " - ratio=0.1957601763574317, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.0821, LPL: 1.3863, Contrastive: 0.1946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:43:23,673] Trial 9 finished with value: 0.883848773989067 and parameters: {'alpha': 0.7251301981467673, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.15251225732900406, 'margin': 0.44227162058489855, 'lpl_weight': 0.7447141517579541, 'ratio': 0.1957601763574317, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9438, F1=0.8856, Recall=0.9511, Precision=0.8286\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102224141.csv.\n",
      "Average F1 over 5 seeds: 0.8838  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4214952945029362, K=32, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.26639001411691626, margin=0.776023350516898, lpl_weight=0.6814282020357242\n",
      " - ratio=0.17568384473142618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0135, LPL: 1.3863, Contrastive: 0.2161\n",
      " - Metrics: Accuracy=0.9267, F1=0.8531, Recall=0.9298, Precision=0.7880\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4214952945029362, K=32, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.26639001411691626, margin=0.776023350516898, lpl_weight=0.6814282020357242\n",
      " - ratio=0.17568384473142618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0135, LPL: 1.3863, Contrastive: 0.2161\n",
      " - Metrics: Accuracy=0.9268, F1=0.8534, Recall=0.9302, Precision=0.7884\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4214952945029362, K=32, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.26639001411691626, margin=0.776023350516898, lpl_weight=0.6814282020357242\n",
      " - ratio=0.17568384473142618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0135, LPL: 1.3863, Contrastive: 0.2161\n",
      " - Metrics: Accuracy=0.9248, F1=0.8493, Recall=0.9257, Precision=0.7846\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4214952945029362, K=32, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.26639001411691626, margin=0.776023350516898, lpl_weight=0.6814282020357242\n",
      " - ratio=0.17568384473142618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0135, LPL: 1.3863, Contrastive: 0.2161\n",
      " - Metrics: Accuracy=0.9268, F1=0.8534, Recall=0.9302, Precision=0.7884\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4214952945029362, K=32, layers=2, hidden=128, out=256\n",
      " - norm=layernorm, dropout=0.26639001411691626, margin=0.776023350516898, lpl_weight=0.6814282020357242\n",
      " - ratio=0.17568384473142618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0135, LPL: 1.3863, Contrastive: 0.2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:45:09,976] Trial 10 finished with value: 0.8521232876712329 and parameters: {'alpha': 0.4214952945029362, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.26639001411691626, 'margin': 0.776023350516898, 'lpl_weight': 0.6814282020357242, 'ratio': 0.17568384473142618, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9258, F1=0.8514, Recall=0.9280, Precision=0.7865\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102224323.csv.\n",
      "Average F1 over 5 seeds: 0.8521  0.0016\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9798105912372816, K=32, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.10490908837537213, margin=0.3292159252856468, lpl_weight=0.9706525326885688\n",
      " - ratio=0.10731500810999182, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9393, F1=0.8617, Recall=0.8253, Precision=0.9013\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9798105912372816, K=32, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.10490908837537213, margin=0.3292159252856468, lpl_weight=0.9706525326885688\n",
      " - ratio=0.10731500810999182, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9415, F1=0.8665, Recall=0.8298, Precision=0.9066\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9798105912372816, K=32, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.10490908837537213, margin=0.3292159252856468, lpl_weight=0.9706525326885688\n",
      " - ratio=0.10731500810999182, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9425, F1=0.8688, Recall=0.8320, Precision=0.9091\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9798105912372816, K=32, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.10490908837537213, margin=0.3292159252856468, lpl_weight=0.9706525326885688\n",
      " - ratio=0.10731500810999182, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9440, F1=0.8725, Recall=0.8365, Precision=0.9117\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9798105912372816, K=32, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.10490908837537213, margin=0.3292159252856468, lpl_weight=0.9706525326885688\n",
      " - ratio=0.10731500810999182, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:49:13,965] Trial 11 finished with value: 0.8663474205534442 and parameters: {'alpha': 0.9798105912372816, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.10490908837537213, 'margin': 0.3292159252856468, 'lpl_weight': 0.9706525326885688, 'ratio': 0.10731500810999182, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9395, F1=0.8623, Recall=0.8272, Precision=0.9004\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102224510.csv.\n",
      "Average F1 over 5 seeds: 0.8663  0.0041\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9460863589107003, K=31, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.11588414684188963, margin=0.7719676312012917, lpl_weight=0.6897411727802087\n",
      " - ratio=0.19817110004009997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0298, LPL: 1.3863, Contrastive: 0.2374\n",
      " - Metrics: Accuracy=0.9090, F1=0.8246, Recall=0.9347, Precision=0.7378\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9460863589107003, K=31, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.11588414684188963, margin=0.7719676312012917, lpl_weight=0.6897411727802087\n",
      " - ratio=0.19817110004009997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0298, LPL: 1.3863, Contrastive: 0.2374\n",
      " - Metrics: Accuracy=0.9124, F1=0.8312, Recall=0.9421, Precision=0.7437\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9460863589107003, K=31, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.11588414684188963, margin=0.7719676312012917, lpl_weight=0.6897411727802087\n",
      " - ratio=0.19817110004009997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0298, LPL: 1.3863, Contrastive: 0.2374\n",
      " - Metrics: Accuracy=0.9117, F1=0.8299, Recall=0.9406, Precision=0.7425\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9460863589107003, K=31, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.11588414684188963, margin=0.7719676312012917, lpl_weight=0.6897411727802087\n",
      " - ratio=0.19817110004009997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0298, LPL: 1.3863, Contrastive: 0.2374\n",
      " - Metrics: Accuracy=0.9131, F1=0.8325, Recall=0.9436, Precision=0.7448\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9460863589107003, K=31, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.11588414684188963, margin=0.7719676312012917, lpl_weight=0.6897411727802087\n",
      " - ratio=0.19817110004009997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0298, LPL: 1.3863, Contrastive: 0.2374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:50:40,496] Trial 12 finished with value: 0.8293100609254076 and parameters: {'alpha': 0.9460863589107003, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.11588414684188963, 'margin': 0.7719676312012917, 'lpl_weight': 0.6897411727802087, 'ratio': 0.19817110004009997, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9109, F1=0.8283, Recall=0.9388, Precision=0.7410\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102224914.csv.\n",
      "Average F1 over 5 seeds: 0.8293  0.0027\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4872054121922268, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1706813464261256, margin=0.9639834996835986, lpl_weight=0.7980122829946829\n",
      " - ratio=0.10576254995973317, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9465, F1=0.8776, Recall=0.8380, Precision=0.9212\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4872054121922268, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1706813464261256, margin=0.9639834996835986, lpl_weight=0.7980122829946829\n",
      " - ratio=0.10576254995973317, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9486, F1=0.8823, Recall=0.8425, Precision=0.9261\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4872054121922268, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1706813464261256, margin=0.9639834996835986, lpl_weight=0.7980122829946829\n",
      " - ratio=0.10576254995973317, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9481, F1=0.8814, Recall=0.8421, Precision=0.9246\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4872054121922268, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1706813464261256, margin=0.9639834996835986, lpl_weight=0.7980122829946829\n",
      " - ratio=0.10576254995973317, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9487, F1=0.8827, Recall=0.8429, Precision=0.9265\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4872054121922268, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1706813464261256, margin=0.9639834996835986, lpl_weight=0.7980122829946829\n",
      " - ratio=0.10576254995973317, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:55:23,021] Trial 13 finished with value: 0.8806190272448756 and parameters: {'alpha': 0.4872054121922268, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.1706813464261256, 'margin': 0.9639834996835986, 'lpl_weight': 0.7980122829946829, 'ratio': 0.10576254995973317, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9471, F1=0.8790, Recall=0.8391, Precision=0.9228\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102225040.csv.\n",
      "Average F1 over 5 seeds: 0.8806  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4611509013359218, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2475424980350169, margin=0.7795611068074775, lpl_weight=0.6400752815696047\n",
      " - ratio=0.20753607672214863, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8794, F1=0.7714, Recall=0.8888, Precision=0.6815\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4611509013359218, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2475424980350169, margin=0.7795611068074775, lpl_weight=0.6400752815696047\n",
      " - ratio=0.20753607672214863, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8793, F1=0.7712, Recall=0.8880, Precision=0.6815\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4611509013359218, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2475424980350169, margin=0.7795611068074775, lpl_weight=0.6400752815696047\n",
      " - ratio=0.20753607672214863, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8830, F1=0.7782, Recall=0.8962, Precision=0.6876\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4611509013359218, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2475424980350169, margin=0.7795611068074775, lpl_weight=0.6400752815696047\n",
      " - ratio=0.20753607672214863, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8833, F1=0.7786, Recall=0.8966, Precision=0.6881\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4611509013359218, K=33, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.2475424980350169, margin=0.7795611068074775, lpl_weight=0.6400752815696047\n",
      " - ratio=0.20753607672214863, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 22:59:30,337] Trial 14 finished with value: 0.7744113261767509 and parameters: {'alpha': 0.4611509013359218, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.2475424980350169, 'margin': 0.7795611068074775, 'lpl_weight': 0.6400752815696047, 'ratio': 0.20753607672214863, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8801, F1=0.7727, Recall=0.8903, Precision=0.6826\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102225523.csv.\n",
      "Average F1 over 5 seeds: 0.7744  0.0033\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.565039725184114, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1742557401858137, margin=0.301086692087436, lpl_weight=0.8120490339096402\n",
      " - ratio=0.244987206077827, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1676, LPL: 1.3863, Contrastive: 0.2225\n",
      " - Metrics: Accuracy=0.8817, F1=0.7890, Recall=0.9657, Precision=0.6669\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.565039725184114, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1742557401858137, margin=0.301086692087436, lpl_weight=0.8120490339096402\n",
      " - ratio=0.244987206077827, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1676, LPL: 1.3863, Contrastive: 0.2225\n",
      " - Metrics: Accuracy=0.8824, F1=0.7902, Recall=0.9672, Precision=0.6680\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.565039725184114, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1742557401858137, margin=0.301086692087436, lpl_weight=0.8120490339096402\n",
      " - ratio=0.244987206077827, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1676, LPL: 1.3863, Contrastive: 0.2225\n",
      " - Metrics: Accuracy=0.8833, F1=0.7917, Recall=0.9690, Precision=0.6692\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.565039725184114, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1742557401858137, margin=0.301086692087436, lpl_weight=0.8120490339096402\n",
      " - ratio=0.244987206077827, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1676, LPL: 1.3863, Contrastive: 0.2225\n",
      " - Metrics: Accuracy=0.8843, F1=0.7935, Recall=0.9713, Precision=0.6708\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.565039725184114, K=29, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.1742557401858137, margin=0.301086692087436, lpl_weight=0.8120490339096402\n",
      " - ratio=0.244987206077827, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1676, LPL: 1.3863, Contrastive: 0.2225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:01:17,459] Trial 15 finished with value: 0.7913388228118329 and parameters: {'alpha': 0.565039725184114, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.1742557401858137, 'margin': 0.301086692087436, 'lpl_weight': 0.8120490339096402, 'ratio': 0.244987206077827, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8836, F1=0.7923, Recall=0.9698, Precision=0.6698\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102225930.csv.\n",
      "Average F1 over 5 seeds: 0.7913  0.0016\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.20655034345959777, K=25, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32431599710454495, margin=0.6639867471853809, lpl_weight=0.582454114712558\n",
      " - ratio=0.15403055701863413, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8783, LPL: 1.3863, Contrastive: 0.1696\n",
      " - Metrics: Accuracy=0.9341, F1=0.8627, Recall=0.9041, Precision=0.8249\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.20655034345959777, K=25, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32431599710454495, margin=0.6639867471853809, lpl_weight=0.582454114712558\n",
      " - ratio=0.15403055701863413, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8783, LPL: 1.3863, Contrastive: 0.1696\n",
      " - Metrics: Accuracy=0.9343, F1=0.8630, Recall=0.9044, Precision=0.8253\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.20655034345959777, K=25, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32431599710454495, margin=0.6639867471853809, lpl_weight=0.582454114712558\n",
      " - ratio=0.15403055701863413, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8783, LPL: 1.3863, Contrastive: 0.1696\n",
      " - Metrics: Accuracy=0.9343, F1=0.8630, Recall=0.9044, Precision=0.8253\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.20655034345959777, K=25, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32431599710454495, margin=0.6639867471853809, lpl_weight=0.582454114712558\n",
      " - ratio=0.15403055701863413, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8783, LPL: 1.3863, Contrastive: 0.1696\n",
      " - Metrics: Accuracy=0.9358, F1=0.8663, Recall=0.9078, Precision=0.8283\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.20655034345959777, K=25, layers=3, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.32431599710454495, margin=0.6639867471853809, lpl_weight=0.582454114712558\n",
      " - ratio=0.15403055701863413, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8783, LPL: 1.3863, Contrastive: 0.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:02:46,592] Trial 16 finished with value: 0.8632591273374889 and parameters: {'alpha': 0.20655034345959777, 'K': 25, 'layers': 3, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.32431599710454495, 'margin': 0.6639867471853809, 'lpl_weight': 0.582454114712558, 'ratio': 0.15403055701863413, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9334, F1=0.8613, Recall=0.9026, Precision=0.8236\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102230117.csv.\n",
      "Average F1 over 5 seeds: 0.8633  0.0016\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.48840648272557063, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2525355598113078, margin=0.26658224035792, lpl_weight=0.7608749917999764\n",
      " - ratio=0.1404892582224804, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9314, F1=0.8533, Recall=0.8720, Precision=0.8355\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.48840648272557063, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2525355598113078, margin=0.26658224035792, lpl_weight=0.7608749917999764\n",
      " - ratio=0.1404892582224804, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9315, F1=0.8537, Recall=0.8723, Precision=0.8358\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.48840648272557063, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2525355598113078, margin=0.26658224035792, lpl_weight=0.7608749917999764\n",
      " - ratio=0.1404892582224804, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9334, F1=0.8577, Recall=0.8764, Precision=0.8398\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.48840648272557063, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2525355598113078, margin=0.26658224035792, lpl_weight=0.7608749917999764\n",
      " - ratio=0.1404892582224804, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9353, F1=0.8617, Recall=0.8806, Precision=0.8437\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.48840648272557063, K=33, layers=2, hidden=256, out=128\n",
      " - norm=None, dropout=0.2525355598113078, margin=0.26658224035792, lpl_weight=0.7608749917999764\n",
      " - ratio=0.1404892582224804, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:07:42,257] Trial 17 finished with value: 0.8556712328767124 and parameters: {'alpha': 0.48840648272557063, 'K': 33, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': None, 'dropout': 0.2525355598113078, 'margin': 0.26658224035792, 'lpl_weight': 0.7608749917999764, 'ratio': 0.1404892582224804, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9307, F1=0.8519, Recall=0.8705, Precision=0.8340\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102230246.csv.\n",
      "Average F1 over 5 seeds: 0.8557  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.13517898954586444, K=29, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1599941690708811, margin=0.681623392164721, lpl_weight=0.8623731972442724\n",
      " - ratio=0.23858032421455685, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2117, LPL: 1.3863, Contrastive: 0.1180\n",
      " - Metrics: Accuracy=0.9293, F1=0.8593, Recall=0.9425, Precision=0.7896\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.13517898954586444, K=29, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1599941690708811, margin=0.681623392164721, lpl_weight=0.8623731972442724\n",
      " - ratio=0.23858032421455685, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2117, LPL: 1.3863, Contrastive: 0.1180\n",
      " - Metrics: Accuracy=0.9279, F1=0.8571, Recall=0.9448, Precision=0.7843\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.13517898954586444, K=29, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1599941690708811, margin=0.681623392164721, lpl_weight=0.8623731972442724\n",
      " - ratio=0.23858032421455685, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2117, LPL: 1.3863, Contrastive: 0.1179\n",
      " - Metrics: Accuracy=0.9271, F1=0.8554, Recall=0.9421, Precision=0.7834\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.13517898954586444, K=29, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1599941690708811, margin=0.681623392164721, lpl_weight=0.8623731972442724\n",
      " - ratio=0.23858032421455685, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2117, LPL: 1.3863, Contrastive: 0.1179\n",
      " - Metrics: Accuracy=0.9304, F1=0.8619, Recall=0.9481, Precision=0.7900\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.13517898954586444, K=29, layers=3, hidden=128, out=256\n",
      " - norm=graphnorm, dropout=0.1599941690708811, margin=0.681623392164721, lpl_weight=0.8623731972442724\n",
      " - ratio=0.23858032421455685, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.2117, LPL: 1.3863, Contrastive: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:09:28,824] Trial 18 finished with value: 0.8587081506998768 and parameters: {'alpha': 0.13517898954586444, 'K': 29, 'layers': 3, 'hidden_channels': 128, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1599941690708811, 'margin': 0.681623392164721, 'lpl_weight': 0.8623731972442724, 'ratio': 0.23858032421455685, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9297, F1=0.8598, Recall=0.9410, Precision=0.7915\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102230742.csv.\n",
      "Average F1 over 5 seeds: 0.8587  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6488780920597148, K=31, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3759221465602574, margin=0.871765121425558, lpl_weight=0.153739345781362\n",
      " - ratio=0.10633362467881548, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3751, LPL: 1.3863, Contrastive: 0.1914\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9309, F1=0.8423, Recall=0.8055, Precision=0.8826\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6488780920597148, K=31, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3759221465602574, margin=0.871765121425558, lpl_weight=0.153739345781362\n",
      " - ratio=0.10633362467881548, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3751, LPL: 1.3863, Contrastive: 0.1914\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9367, F1=0.8554, Recall=0.8178, Precision=0.8965\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6488780920597148, K=31, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3759221465602574, margin=0.871765121425558, lpl_weight=0.153739345781362\n",
      " - ratio=0.10633362467881548, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3751, LPL: 1.3863, Contrastive: 0.1914\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9328, F1=0.8465, Recall=0.8093, Precision=0.8874\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6488780920597148, K=31, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3759221465602574, margin=0.871765121425558, lpl_weight=0.153739345781362\n",
      " - ratio=0.10633362467881548, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3751, LPL: 1.3863, Contrastive: 0.1914\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9355, F1=0.8527, Recall=0.8160, Precision=0.8930\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6488780920597148, K=31, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3759221465602574, margin=0.871765121425558, lpl_weight=0.153739345781362\n",
      " - ratio=0.10633362467881548, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3751, LPL: 1.3863, Contrastive: 0.1914\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:13:10,366] Trial 19 finished with value: 0.8479554617795488 and parameters: {'alpha': 0.6488780920597148, 'K': 31, 'layers': 1, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.3759221465602574, 'margin': 0.871765121425558, 'lpl_weight': 0.153739345781362, 'ratio': 0.10633362467881548, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9311, F1=0.8428, Recall=0.8066, Precision=0.8824\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102230928.csv.\n",
      "Average F1 over 5 seeds: 0.8480  0.0053\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.36748825286508846, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4957728340453175, margin=0.39795791368981115, lpl_weight=0.9858562675375475\n",
      " - ratio=0.16659579257212845, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3709, LPL: 1.3863, Contrastive: 0.2945\n",
      " - Metrics: Accuracy=0.9307, F1=0.8588, Recall=0.9209, Precision=0.8046\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.36748825286508846, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4957728340453175, margin=0.39795791368981115, lpl_weight=0.9858562675375475\n",
      " - ratio=0.16659579257212845, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3709, LPL: 1.3863, Contrastive: 0.2945\n",
      " - Metrics: Accuracy=0.9315, F1=0.8606, Recall=0.9227, Precision=0.8063\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.36748825286508846, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4957728340453175, margin=0.39795791368981115, lpl_weight=0.9858562675375475\n",
      " - ratio=0.16659579257212845, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3709, LPL: 1.3863, Contrastive: 0.2945\n",
      " - Metrics: Accuracy=0.9298, F1=0.8571, Recall=0.9190, Precision=0.8030\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.36748825286508846, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4957728340453175, margin=0.39795791368981115, lpl_weight=0.9858562675375475\n",
      " - ratio=0.16659579257212845, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3709, LPL: 1.3863, Contrastive: 0.2945\n",
      " - Metrics: Accuracy=0.9319, F1=0.8613, Recall=0.9235, Precision=0.8069\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.36748825286508846, K=27, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.4957728340453175, margin=0.39795791368981115, lpl_weight=0.9858562675375475\n",
      " - ratio=0.16659579257212845, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3709, LPL: 1.3863, Contrastive: 0.2945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:14:57,609] Trial 20 finished with value: 0.8594604003481287 and parameters: {'alpha': 0.36748825286508846, 'K': 27, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.4957728340453175, 'margin': 0.39795791368981115, 'lpl_weight': 0.9858562675375475, 'ratio': 0.16659579257212845, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9310, F1=0.8595, Recall=0.9216, Precision=0.8053\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102231310.csv.\n",
      "Average F1 over 5 seeds: 0.8595  0.0015\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8773957302509282, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12735627932843616, margin=0.925701730080321, lpl_weight=0.8778002069997946\n",
      " - ratio=0.13020800726973453, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9367, F1=0.8620, Recall=0.8638, Precision=0.8602\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8773957302509282, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12735627932843616, margin=0.925701730080321, lpl_weight=0.8778002069997946\n",
      " - ratio=0.13020800726973453, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9364, F1=0.8614, Recall=0.8630, Precision=0.8598\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8773957302509282, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12735627932843616, margin=0.925701730080321, lpl_weight=0.8778002069997946\n",
      " - ratio=0.13020800726973453, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9397, F1=0.8685, Recall=0.8701, Precision=0.8669\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8773957302509282, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12735627932843616, margin=0.925701730080321, lpl_weight=0.8778002069997946\n",
      " - ratio=0.13020800726973453, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9398, F1=0.8689, Recall=0.8705, Precision=0.8672\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8773957302509282, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.12735627932843616, margin=0.925701730080321, lpl_weight=0.8778002069997946\n",
      " - ratio=0.13020800726973453, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:19:43,234] Trial 21 finished with value: 0.864285268228682 and parameters: {'alpha': 0.8773957302509282, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.12735627932843616, 'margin': 0.925701730080321, 'lpl_weight': 0.8778002069997946, 'ratio': 0.13020800726973453, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9361, F1=0.8607, Recall=0.8626, Precision=0.8588\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102231457.csv.\n",
      "Average F1 over 5 seeds: 0.8643  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5566065144226955, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14475592808940538, margin=0.9997021391974561, lpl_weight=0.75555351151599\n",
      " - ratio=0.20910497294392655, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8851, F1=0.7827, Recall=0.9037, Precision=0.6903\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5566065144226955, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14475592808940538, margin=0.9997021391974561, lpl_weight=0.75555351151599\n",
      " - ratio=0.20910497294392655, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8848, F1=0.7821, Recall=0.9029, Precision=0.6898\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5566065144226955, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14475592808940538, margin=0.9997021391974561, lpl_weight=0.75555351151599\n",
      " - ratio=0.20910497294392655, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8868, F1=0.7860, Recall=0.9074, Precision=0.6932\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5566065144226955, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14475592808940538, margin=0.9997021391974561, lpl_weight=0.75555351151599\n",
      " - ratio=0.20910497294392655, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8904, F1=0.7928, Recall=0.9153, Precision=0.6992\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5566065144226955, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14475592808940538, margin=0.9997021391974561, lpl_weight=0.75555351151599\n",
      " - ratio=0.20910497294392655, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:24:27,183] Trial 22 finished with value: 0.7852570320077594 and parameters: {'alpha': 0.5566065144226955, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.14475592808940538, 'margin': 0.9997021391974561, 'lpl_weight': 0.75555351151599, 'ratio': 0.20910497294392655, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8851, F1=0.7827, Recall=0.9037, Precision=0.6903\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102231943.csv.\n",
      "Average F1 over 5 seeds: 0.7853  0.0040\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7147195301452283, K=31, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.21506414382836686, margin=0.8483414306967929, lpl_weight=0.8398011272179937\n",
      " - ratio=0.10669918550461086, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9456, F1=0.8759, Recall=0.8380, Precision=0.9174\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7147195301452283, K=31, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.21506414382836686, margin=0.8483414306967929, lpl_weight=0.8398011272179937\n",
      " - ratio=0.10669918550461086, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9480, F1=0.8814, Recall=0.8432, Precision=0.9232\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7147195301452283, K=31, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.21506414382836686, margin=0.8483414306967929, lpl_weight=0.8398011272179937\n",
      " - ratio=0.10669918550461086, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9476, F1=0.8804, Recall=0.8425, Precision=0.9220\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7147195301452283, K=31, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.21506414382836686, margin=0.8483414306967929, lpl_weight=0.8398011272179937\n",
      " - ratio=0.10669918550461086, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9490, F1=0.8836, Recall=0.8462, Precision=0.9246\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7147195301452283, K=31, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.21506414382836686, margin=0.8483414306967929, lpl_weight=0.8398011272179937\n",
      " - ratio=0.10669918550461086, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:29:17,176] Trial 23 finished with value: 0.8801335175345919 and parameters: {'alpha': 0.7147195301452283, 'K': 31, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.21506414382836686, 'margin': 0.8483414306967929, 'lpl_weight': 0.8398011272179937, 'ratio': 0.10669918550461086, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9471, F1=0.8793, Recall=0.8414, Precision=0.9208\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102232427.csv.\n",
      "Average F1 over 5 seeds: 0.8801  0.0025\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6967255440889167, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.20604719887429707, margin=0.8821469932690399, lpl_weight=0.5984788208298597\n",
      " - ratio=0.17212891599582988, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9130, F1=0.8246, Recall=0.8932, Precision=0.7658\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6967255440889167, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.20604719887429707, margin=0.8821469932690399, lpl_weight=0.5984788208298597\n",
      " - ratio=0.17212891599582988, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9124, F1=0.8234, Recall=0.8918, Precision=0.7647\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6967255440889167, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.20604719887429707, margin=0.8821469932690399, lpl_weight=0.5984788208298597\n",
      " - ratio=0.17212891599582988, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9141, F1=0.8268, Recall=0.8955, Precision=0.7679\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6967255440889167, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.20604719887429707, margin=0.8821469932690399, lpl_weight=0.5984788208298597\n",
      " - ratio=0.17212891599582988, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9158, F1=0.8303, Recall=0.8992, Precision=0.7711\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6967255440889167, K=32, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.20604719887429707, margin=0.8821469932690399, lpl_weight=0.5984788208298597\n",
      " - ratio=0.17212891599582988, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:34:09,613] Trial 24 finished with value: 0.8260270686292757 and parameters: {'alpha': 0.6967255440889167, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.20604719887429707, 'margin': 0.8821469932690399, 'lpl_weight': 0.5984788208298597, 'ratio': 0.17212891599582988, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9133, F1=0.8251, Recall=0.8936, Precision=0.7663\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102232917.csv.\n",
      "Average F1 over 5 seeds: 0.8260  0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.5216162557668662, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18776657372922095, margin=0.8527893286126123, lpl_weight=0.7325532101374678\n",
      " - ratio=0.24606481755381973, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8497, F1=0.7322, Recall=0.8977, Precision=0.6183\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5216162557668662, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18776657372922095, margin=0.8527893286126123, lpl_weight=0.7325532101374678\n",
      " - ratio=0.24606481755381973, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8514, F1=0.7353, Recall=0.9015, Precision=0.6208\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5216162557668662, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18776657372922095, margin=0.8527893286126123, lpl_weight=0.7325532101374678\n",
      " - ratio=0.24606481755381973, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8536, F1=0.7392, Recall=0.9063, Precision=0.6242\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5216162557668662, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18776657372922095, margin=0.8527893286126123, lpl_weight=0.7325532101374678\n",
      " - ratio=0.24606481755381973, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8541, F1=0.7401, Recall=0.9074, Precision=0.6249\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5216162557668662, K=33, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.18776657372922095, margin=0.8527893286126123, lpl_weight=0.7325532101374678\n",
      " - ratio=0.24606481755381973, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:38:17,687] Trial 25 finished with value: 0.7364895722332166 and parameters: {'alpha': 0.5216162557668662, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.18776657372922095, 'margin': 0.8527893286126123, 'lpl_weight': 0.7325532101374678, 'ratio': 0.24606481755381973, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8516, F1=0.7356, Recall=0.9018, Precision=0.6211\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102233409.csv.\n",
      "Average F1 over 5 seeds: 0.7365  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.593664126388303, K=31, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.22716291809039232, margin=0.6630699288591556, lpl_weight=0.6704312507884198\n",
      " - ratio=0.14752406117168076, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9410, F1=0.8714, Recall=0.8723, Precision=0.8704\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.593664126388303, K=31, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.22716291809039232, margin=0.6630699288591556, lpl_weight=0.6704312507884198\n",
      " - ratio=0.14752406117168076, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9401, F1=0.8697, Recall=0.8731, Precision=0.8663\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.593664126388303, K=31, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.22716291809039232, margin=0.6630699288591556, lpl_weight=0.6704312507884198\n",
      " - ratio=0.14752406117168076, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9427, F1=0.8749, Recall=0.8761, Precision=0.8738\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.593664126388303, K=31, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.22716291809039232, margin=0.6630699288591556, lpl_weight=0.6704312507884198\n",
      " - ratio=0.14752406117168076, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9429, F1=0.8757, Recall=0.8783, Precision=0.8731\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.593664126388303, K=31, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.22716291809039232, margin=0.6630699288591556, lpl_weight=0.6704312507884198\n",
      " - ratio=0.14752406117168076, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:43:05,910] Trial 26 finished with value: 0.8720242658146322 and parameters: {'alpha': 0.593664126388303, 'K': 31, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.22716291809039232, 'margin': 0.6630699288591556, 'lpl_weight': 0.6704312507884198, 'ratio': 0.14752406117168076, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9395, F1=0.8685, Recall=0.8723, Precision=0.8646\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102233817.csv.\n",
      "Average F1 over 5 seeds: 0.8720  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7118748971716021, K=34, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.23273939477059422, margin=0.48474386879718173, lpl_weight=0.8046099128410424\n",
      " - ratio=0.19080320955606445, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8879, F1=0.7812, Recall=0.8742, Precision=0.7061\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7118748971716021, K=34, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.23273939477059422, margin=0.48474386879718173, lpl_weight=0.8046099128410424\n",
      " - ratio=0.19080320955606445, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8878, F1=0.7811, Recall=0.8746, Precision=0.7057\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7118748971716021, K=34, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.23273939477059422, margin=0.48474386879718173, lpl_weight=0.8046099128410424\n",
      " - ratio=0.19080320955606445, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8888, F1=0.7830, Recall=0.8761, Precision=0.7078\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7118748971716021, K=34, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.23273939477059422, margin=0.48474386879718173, lpl_weight=0.8046099128410424\n",
      " - ratio=0.19080320955606445, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8902, F1=0.7857, Recall=0.8791, Precision=0.7102\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7118748971716021, K=34, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.23273939477059422, margin=0.48474386879718173, lpl_weight=0.8046099128410424\n",
      " - ratio=0.19080320955606445, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:50:14,480] Trial 27 finished with value: 0.7807204100679979 and parameters: {'alpha': 0.7118748971716021, 'K': 34, 'layers': 3, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.23273939477059422, 'margin': 0.48474386879718173, 'lpl_weight': 0.8046099128410424, 'ratio': 0.19080320955606445, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8835, F1=0.7726, Recall=0.8645, Precision=0.6984\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102234305.csv.\n",
      "Average F1 over 5 seeds: 0.7807  0.0044\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8347962087404929, K=28, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3019154237765802, margin=0.8108493188971375, lpl_weight=0.942180572586299\n",
      " - ratio=0.10167761981594943, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3207, LPL: 1.3863, Contrastive: 0.2524\n",
      " - Metrics: Accuracy=0.9380, F1=0.8534, Recall=0.7880, Precision=0.9308\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8347962087404929, K=28, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3019154237765802, margin=0.8108493188971375, lpl_weight=0.942180572586299\n",
      " - ratio=0.10167761981594943, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3207, LPL: 1.3863, Contrastive: 0.2524\n",
      " - Metrics: Accuracy=0.9397, F1=0.8583, Recall=0.7981, Precision=0.9284\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8347962087404929, K=28, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3019154237765802, margin=0.8108493188971375, lpl_weight=0.942180572586299\n",
      " - ratio=0.10167761981594943, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3207, LPL: 1.3863, Contrastive: 0.2524\n",
      " - Metrics: Accuracy=0.9403, F1=0.8589, Recall=0.7932, Precision=0.9365\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8347962087404929, K=28, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3019154237765802, margin=0.8108493188971375, lpl_weight=0.942180572586299\n",
      " - ratio=0.10167761981594943, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3207, LPL: 1.3863, Contrastive: 0.2524\n",
      " - Metrics: Accuracy=0.9386, F1=0.8548, Recall=0.7898, Precision=0.9313\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8347962087404929, K=28, layers=2, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3019154237765802, margin=0.8108493188971375, lpl_weight=0.942180572586299\n",
      " - ratio=0.10167761981594943, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.3207, LPL: 1.3863, Contrastive: 0.2524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:51:33,099] Trial 28 finished with value: 0.8561037110809522 and parameters: {'alpha': 0.8347962087404929, 'K': 28, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.3019154237765802, 'margin': 0.8108493188971375, 'lpl_weight': 0.942180572586299, 'ratio': 0.10167761981594943, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9385, F1=0.8551, Recall=0.7928, Precision=0.9279\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102235014.csv.\n",
      "Average F1 over 5 seeds: 0.8561  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.39818695076964894, K=28, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.15763962877398197, margin=0.7054069579857356, lpl_weight=0.80253541763296\n",
      " - ratio=0.28245358020768213, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1508, LPL: 1.3863, Contrastive: 0.1936\n",
      " - Metrics: Accuracy=0.9269, F1=0.8564, Recall=0.9518, Precision=0.7784\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.39818695076964894, K=28, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.15763962877398197, margin=0.7054069579857356, lpl_weight=0.80253541763296\n",
      " - ratio=0.28245358020768213, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1508, LPL: 1.3863, Contrastive: 0.1936\n",
      " - Metrics: Accuracy=0.9270, F1=0.8565, Recall=0.9511, Precision=0.7790\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.39818695076964894, K=28, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.15763962877398197, margin=0.7054069579857356, lpl_weight=0.80253541763296\n",
      " - ratio=0.28245358020768213, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1508, LPL: 1.3863, Contrastive: 0.1936\n",
      " - Metrics: Accuracy=0.9252, F1=0.8537, Recall=0.9526, Precision=0.7733\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.39818695076964894, K=28, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.15763962877398197, margin=0.7054069579857356, lpl_weight=0.80253541763296\n",
      " - ratio=0.28245358020768213, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1508, LPL: 1.3863, Contrastive: 0.1936\n",
      " - Metrics: Accuracy=0.9284, F1=0.8592, Recall=0.9541, Precision=0.7814\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.39818695076964894, K=28, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.15763962877398197, margin=0.7054069579857356, lpl_weight=0.80253541763296\n",
      " - ratio=0.28245358020768213, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1508, LPL: 1.3863, Contrastive: 0.1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:53:14,562] Trial 29 finished with value: 0.8579561294387403 and parameters: {'alpha': 0.39818695076964894, 'K': 28, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.15763962877398197, 'margin': 0.7054069579857356, 'lpl_weight': 0.80253541763296, 'ratio': 0.28245358020768213, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9310, F1=0.8641, Recall=0.9574, Precision=0.7873\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102235133.csv.\n",
      "Average F1 over 5 seeds: 0.8580  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.31606729631106495, K=31, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.28614201943601353, margin=0.2201273468348493, lpl_weight=0.4927309002648224\n",
      " - ratio=0.4879944179527624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7884, LPL: 1.3863, Contrastive: 0.2077\n",
      "Epoch 50, Loss: 0.7666, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.6680, F1=0.5719, Recall=0.9686, Precision=0.4057\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.31606729631106495, K=31, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.28614201943601353, margin=0.2201273468348493, lpl_weight=0.4927309002648224\n",
      " - ratio=0.4879944179527624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7884, LPL: 1.3863, Contrastive: 0.2077\n",
      "Epoch 50, Loss: 0.7666, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.6677, F1=0.5714, Recall=0.9675, Precision=0.4054\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.31606729631106495, K=31, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.28614201943601353, margin=0.2201273468348493, lpl_weight=0.4927309002648224\n",
      " - ratio=0.4879944179527624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7884, LPL: 1.3863, Contrastive: 0.2077\n",
      "Epoch 50, Loss: 0.7666, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.6699, F1=0.5741, Recall=0.9720, Precision=0.4074\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.31606729631106495, K=31, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.28614201943601353, margin=0.2201273468348493, lpl_weight=0.4927309002648224\n",
      " - ratio=0.4879944179527624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7884, LPL: 1.3863, Contrastive: 0.2077\n",
      "Epoch 50, Loss: 0.7666, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.6675, F1=0.5712, Recall=0.9672, Precision=0.4053\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.31606729631106495, K=31, layers=2, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.28614201943601353, margin=0.2201273468348493, lpl_weight=0.4927309002648224\n",
      " - ratio=0.4879944179527624, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7884, LPL: 1.3863, Contrastive: 0.2077\n",
      "Epoch 50, Loss: 0.7666, LPL: 1.3863, Contrastive: 0.1648\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 23:57:19,617] Trial 30 finished with value: 0.5723481548297249 and parameters: {'alpha': 0.31606729631106495, 'K': 31, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.28614201943601353, 'margin': 0.2201273468348493, 'lpl_weight': 0.4927309002648224, 'ratio': 0.4879944179527624, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6689, F1=0.5731, Recall=0.9705, Precision=0.4066\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102235314.csv.\n",
      "Average F1 over 5 seeds: 0.5723  0.0011\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9286770793598897, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.13384206128446832, margin=0.9806846248177988, lpl_weight=0.8781204444414098\n",
      " - ratio=0.1278261231269074, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9380, F1=0.8644, Recall=0.8623, Precision=0.8665\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9286770793598897, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.13384206128446832, margin=0.9806846248177988, lpl_weight=0.8781204444414098\n",
      " - ratio=0.1278261231269074, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9376, F1=0.8634, Recall=0.8611, Precision=0.8657\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9286770793598897, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.13384206128446832, margin=0.9806846248177988, lpl_weight=0.8781204444414098\n",
      " - ratio=0.1278261231269074, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9407, F1=0.8701, Recall=0.8679, Precision=0.8724\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9286770793598897, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.13384206128446832, margin=0.9806846248177988, lpl_weight=0.8781204444414098\n",
      " - ratio=0.1278261231269074, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9412, F1=0.8713, Recall=0.8690, Precision=0.8735\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9286770793598897, K=30, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.13384206128446832, margin=0.9806846248177988, lpl_weight=0.8781204444414098\n",
      " - ratio=0.1278261231269074, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:02:05,937] Trial 31 finished with value: 0.8661353158976715 and parameters: {'alpha': 0.9286770793598897, 'K': 30, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.13384206128446832, 'margin': 0.9806846248177988, 'lpl_weight': 0.8781204444414098, 'ratio': 0.1278261231269074, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9368, F1=0.8615, Recall=0.8593, Precision=0.8638\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2102235719.csv.\n",
      "Average F1 over 5 seeds: 0.8661  0.0039\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8975981069146669, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17454874903446663, margin=0.9187237062783083, lpl_weight=0.844856458382856\n",
      " - ratio=0.11737960485367951, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9419, F1=0.8701, Recall=0.8503, Precision=0.8909\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8975981069146669, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17454874903446663, margin=0.9187237062783083, lpl_weight=0.844856458382856\n",
      " - ratio=0.11737960485367951, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9438, F1=0.8743, Recall=0.8544, Precision=0.8952\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8975981069146669, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17454874903446663, margin=0.9187237062783083, lpl_weight=0.844856458382856\n",
      " - ratio=0.11737960485367951, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9458, F1=0.8789, Recall=0.8589, Precision=0.8999\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8975981069146669, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17454874903446663, margin=0.9187237062783083, lpl_weight=0.844856458382856\n",
      " - ratio=0.11737960485367951, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9450, F1=0.8771, Recall=0.8574, Precision=0.8976\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8975981069146669, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.17454874903446663, margin=0.9187237062783083, lpl_weight=0.844856458382856\n",
      " - ratio=0.11737960485367951, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:06:53,820] Trial 32 finished with value: 0.8740353665156576 and parameters: {'alpha': 0.8975981069146669, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.17454874903446663, 'margin': 0.9187237062783083, 'lpl_weight': 0.844856458382856, 'ratio': 0.11737960485367951, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9417, F1=0.8697, Recall=0.8499, Precision=0.8905\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202000206.csv.\n",
      "Average F1 over 5 seeds: 0.8740  0.0037\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8895376090017778, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.18049774171084698, margin=0.8906547470136408, lpl_weight=0.8204170692730309\n",
      " - ratio=0.13081637737456417, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9359, F1=0.8605, Recall=0.8634, Precision=0.8576\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8895376090017778, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.18049774171084698, margin=0.8906547470136408, lpl_weight=0.8204170692730309\n",
      " - ratio=0.13081637737456417, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9360, F1=0.8607, Recall=0.8634, Precision=0.8579\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8895376090017778, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.18049774171084698, margin=0.8906547470136408, lpl_weight=0.8204170692730309\n",
      " - ratio=0.13081637737456417, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9394, F1=0.8681, Recall=0.8708, Precision=0.8654\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8895376090017778, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.18049774171084698, margin=0.8906547470136408, lpl_weight=0.8204170692730309\n",
      " - ratio=0.13081637737456417, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9393, F1=0.8679, Recall=0.8705, Precision=0.8653\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8895376090017778, K=29, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.18049774171084698, margin=0.8906547470136408, lpl_weight=0.8204170692730309\n",
      " - ratio=0.13081637737456417, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:11:37,683] Trial 33 finished with value: 0.863256088979546 and parameters: {'alpha': 0.8895376090017778, 'K': 29, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.18049774171084698, 'margin': 0.8906547470136408, 'lpl_weight': 0.8204170692730309, 'ratio': 0.13081637737456417, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9353, F1=0.8592, Recall=0.8619, Precision=0.8565\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202000653.csv.\n",
      "Average F1 over 5 seeds: 0.8633  0.0039\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8198854927752273, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1672092525982424, margin=0.9234958380957836, lpl_weight=0.9149376555211542\n",
      " - ratio=0.10056962629056874, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9468, F1=0.8770, Recall=0.8287, Precision=0.9312\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8198854927752273, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1672092525982424, margin=0.9234958380957836, lpl_weight=0.9149376555211542\n",
      " - ratio=0.10056962629056874, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9488, F1=0.8816, Recall=0.8328, Precision=0.9366\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8198854927752273, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1672092525982424, margin=0.9234958380957836, lpl_weight=0.9149376555211542\n",
      " - ratio=0.10056962629056874, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9489, F1=0.8819, Recall=0.8331, Precision=0.9366\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8198854927752273, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1672092525982424, margin=0.9234958380957836, lpl_weight=0.9149376555211542\n",
      " - ratio=0.10056962629056874, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9499, F1=0.8842, Recall=0.8354, Precision=0.9392\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8198854927752273, K=26, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.1672092525982424, margin=0.9234958380957836, lpl_weight=0.9149376555211542\n",
      " - ratio=0.10056962629056874, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:16:13,516] Trial 34 finished with value: 0.8810306263108124 and parameters: {'alpha': 0.8198854927752273, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.1672092525982424, 'margin': 0.9234958380957836, 'lpl_weight': 0.9149376555211542, 'ratio': 0.10056962629056874, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9483, F1=0.8805, Recall=0.8317, Precision=0.9353\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202001137.csv.\n",
      "Average F1 over 5 seeds: 0.8810  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8070458430588632, K=26, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14824511704886162, margin=0.838983021824369, lpl_weight=0.9013719346196207\n",
      " - ratio=0.2252300806007999, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8729, F1=0.7659, Recall=0.9082, Precision=0.6622\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8070458430588632, K=26, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14824511704886162, margin=0.838983021824369, lpl_weight=0.9013719346196207\n",
      " - ratio=0.2252300806007999, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8734, F1=0.7669, Recall=0.9093, Precision=0.6630\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8070458430588632, K=26, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14824511704886162, margin=0.838983021824369, lpl_weight=0.9013719346196207\n",
      " - ratio=0.2252300806007999, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8739, F1=0.7678, Recall=0.9104, Precision=0.6639\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8070458430588632, K=26, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14824511704886162, margin=0.838983021824369, lpl_weight=0.9013719346196207\n",
      " - ratio=0.2252300806007999, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8782, F1=0.7757, Recall=0.9197, Precision=0.6707\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8070458430588632, K=26, layers=1, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.14824511704886162, margin=0.838983021824369, lpl_weight=0.9013719346196207\n",
      " - ratio=0.2252300806007999, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:20:49,647] Trial 35 finished with value: 0.7682669604911065 and parameters: {'alpha': 0.8070458430588632, 'K': 26, 'layers': 1, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.14824511704886162, 'margin': 0.838983021824369, 'lpl_weight': 0.9013719346196207, 'ratio': 0.2252300806007999, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8724, F1=0.7650, Recall=0.9071, Precision=0.6614\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202001613.csv.\n",
      "Average F1 over 5 seeds: 0.7683  0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.7169835282614992, K=26, layers=2, hidden=256, out=256\n",
      " - norm=None, dropout=0.20371310890476102, margin=0.49383582624970385, lpl_weight=0.920252249262975\n",
      " - ratio=0.1572954089300057, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9380, F1=0.8667, Recall=0.8794, Precision=0.8542\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7169835282614992, K=26, layers=2, hidden=256, out=256\n",
      " - norm=None, dropout=0.20371310890476102, margin=0.49383582624970385, lpl_weight=0.920252249262975\n",
      " - ratio=0.1572954089300057, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9391, F1=0.8689, Recall=0.8820, Precision=0.8562\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7169835282614992, K=26, layers=2, hidden=256, out=256\n",
      " - norm=None, dropout=0.20371310890476102, margin=0.49383582624970385, lpl_weight=0.920252249262975\n",
      " - ratio=0.1572954089300057, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9354, F1=0.8623, Recall=0.8839, Precision=0.8418\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7169835282614992, K=26, layers=2, hidden=256, out=256\n",
      " - norm=None, dropout=0.20371310890476102, margin=0.49383582624970385, lpl_weight=0.920252249262975\n",
      " - ratio=0.1572954089300057, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9376, F1=0.8670, Recall=0.8880, Precision=0.8469\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7169835282614992, K=26, layers=2, hidden=256, out=256\n",
      " - norm=None, dropout=0.20371310890476102, margin=0.49383582624970385, lpl_weight=0.920252249262975\n",
      " - ratio=0.1572954089300057, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:26:31,266] Trial 36 finished with value: 0.8645109545511698 and parameters: {'alpha': 0.7169835282614992, 'K': 26, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': None, 'dropout': 0.20371310890476102, 'margin': 0.49383582624970385, 'lpl_weight': 0.920252249262975, 'ratio': 0.1572954089300057, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9332, F1=0.8577, Recall=0.8794, Precision=0.8369\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202002049.csv.\n",
      "Average F1 over 5 seeds: 0.8645  0.0040\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6067010260212491, K=26, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.12064148362334146, margin=0.9418590043455305, lpl_weight=0.724701931369337\n",
      " - ratio=0.4097831880577564, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0391, LPL: 1.3863, Contrastive: 0.1252\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8675, F1=0.7609, Recall=0.9205, Precision=0.6484\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6067010260212491, K=26, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.12064148362334146, margin=0.9418590043455305, lpl_weight=0.724701931369337\n",
      " - ratio=0.4097831880577564, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0391, LPL: 1.3863, Contrastive: 0.1252\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8610, F1=0.7525, Recall=0.9231, Precision=0.6351\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6067010260212491, K=26, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.12064148362334146, margin=0.9418590043455305, lpl_weight=0.724701931369337\n",
      " - ratio=0.4097831880577564, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0391, LPL: 1.3863, Contrastive: 0.1252\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8540, F1=0.7425, Recall=0.9194, Precision=0.6228\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6067010260212491, K=26, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.12064148362334146, margin=0.9418590043455305, lpl_weight=0.724701931369337\n",
      " - ratio=0.4097831880577564, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0391, LPL: 1.3863, Contrastive: 0.1252\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8580, F1=0.7500, Recall=0.9302, Precision=0.6283\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6067010260212491, K=26, layers=2, hidden=64, out=128\n",
      " - norm=None, dropout=0.12064148362334146, margin=0.9418590043455305, lpl_weight=0.724701931369337\n",
      " - ratio=0.4097831880577564, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 1.0391, LPL: 1.3863, Contrastive: 0.1252\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:30:15,676] Trial 37 finished with value: 0.7510475090750399 and parameters: {'alpha': 0.6067010260212491, 'K': 26, 'layers': 2, 'hidden_channels': 64, 'out_channels': 128, 'norm': None, 'dropout': 0.12064148362334146, 'margin': 0.9418590043455305, 'lpl_weight': 0.724701931369337, 'ratio': 0.4097831880577564, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8597, F1=0.7493, Recall=0.9160, Precision=0.6339\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202002631.csv.\n",
      "Average F1 over 5 seeds: 0.7510  0.0059\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7510632888541356, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10328040170244769, margin=0.3926648518943777, lpl_weight=0.9827390998797211\n",
      " - ratio=0.17619178493240428, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3659, LPL: 1.3863, Contrastive: 0.2052\n",
      " - Metrics: Accuracy=0.9324, F1=0.8647, Recall=0.9433, Precision=0.7982\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7510632888541356, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10328040170244769, margin=0.3926648518943777, lpl_weight=0.9827390998797211\n",
      " - ratio=0.17619178493240428, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3659, LPL: 1.3863, Contrastive: 0.2052\n",
      " - Metrics: Accuracy=0.9334, F1=0.8667, Recall=0.9455, Precision=0.8001\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7510632888541356, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10328040170244769, margin=0.3926648518943777, lpl_weight=0.9827390998797211\n",
      " - ratio=0.17619178493240428, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3659, LPL: 1.3863, Contrastive: 0.2052\n",
      " - Metrics: Accuracy=0.9324, F1=0.8647, Recall=0.9433, Precision=0.7982\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7510632888541356, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10328040170244769, margin=0.3926648518943777, lpl_weight=0.9827390998797211\n",
      " - ratio=0.17619178493240428, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3659, LPL: 1.3863, Contrastive: 0.2052\n",
      " - Metrics: Accuracy=0.9331, F1=0.8660, Recall=0.9448, Precision=0.7994\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7510632888541356, K=34, layers=1, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.10328040170244769, margin=0.3926648518943777, lpl_weight=0.9827390998797211\n",
      " - ratio=0.17619178493240428, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3659, LPL: 1.3863, Contrastive: 0.2052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:32:02,961] Trial 38 finished with value: 0.8661077844311379 and parameters: {'alpha': 0.7510632888541356, 'K': 34, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.10328040170244769, 'margin': 0.3926648518943777, 'lpl_weight': 0.9827390998797211, 'ratio': 0.17619178493240428, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9343, F1=0.8684, Recall=0.9474, Precision=0.8016\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202003015.csv.\n",
      "Average F1 over 5 seeds: 0.8661  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8388635932518026, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16264147620772948, margin=0.5203176054852479, lpl_weight=0.7709117702543137\n",
      " - ratio=0.10041869949895196, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9452, F1=0.8718, Recall=0.8134, Precision=0.9392\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8388635932518026, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16264147620772948, margin=0.5203176054852479, lpl_weight=0.7709117702543137\n",
      " - ratio=0.10041869949895196, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9462, F1=0.8749, Recall=0.8212, Precision=0.9362\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8388635932518026, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16264147620772948, margin=0.5203176054852479, lpl_weight=0.7709117702543137\n",
      " - ratio=0.10041869949895196, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9480, F1=0.8784, Recall=0.8201, Precision=0.9458\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8388635932518026, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16264147620772948, margin=0.5203176054852479, lpl_weight=0.7709117702543137\n",
      " - ratio=0.10041869949895196, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9480, F1=0.8789, Recall=0.8234, Precision=0.9423\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8388635932518026, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16264147620772948, margin=0.5203176054852479, lpl_weight=0.7709117702543137\n",
      " - ratio=0.10041869949895196, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:35:46,978] Trial 39 finished with value: 0.8762242351109913 and parameters: {'alpha': 0.8388635932518026, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.16264147620772948, 'margin': 0.5203176054852479, 'lpl_weight': 0.7709117702543137, 'ratio': 0.10041869949895196, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9472, F1=0.8771, Recall=0.8231, Precision=0.9387\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202003203.csv.\n",
      "Average F1 over 5 seeds: 0.8762  0.0026\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.684174950909227, K=28, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1945825579616962, margin=0.6105622430498754, lpl_weight=0.6041215688511938\n",
      " - ratio=0.2629404211454139, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8333, F1=0.7106, Recall=0.8940, Precision=0.5896\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.684174950909227, K=28, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1945825579616962, margin=0.6105622430498754, lpl_weight=0.6041215688511938\n",
      " - ratio=0.2629404211454139, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8322, F1=0.7088, Recall=0.8921, Precision=0.5879\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.684174950909227, K=28, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1945825579616962, margin=0.6105622430498754, lpl_weight=0.6041215688511938\n",
      " - ratio=0.2629404211454139, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8329, F1=0.7095, Recall=0.8910, Precision=0.5894\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.684174950909227, K=28, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1945825579616962, margin=0.6105622430498754, lpl_weight=0.6041215688511938\n",
      " - ratio=0.2629404211454139, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8367, F1=0.7166, Recall=0.9018, Precision=0.5945\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.684174950909227, K=28, layers=3, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.1945825579616962, margin=0.6105622430498754, lpl_weight=0.6041215688511938\n",
      " - ratio=0.2629404211454139, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:43:47,053] Trial 40 finished with value: 0.7097955090994366 and parameters: {'alpha': 0.684174950909227, 'K': 28, 'layers': 3, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.1945825579616962, 'margin': 0.6105622430498754, 'lpl_weight': 0.6041215688511938, 'ratio': 0.2629404211454139, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8292, F1=0.7036, Recall=0.8850, Precision=0.5838\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202003547.csv.\n",
      "Average F1 over 5 seeds: 0.7098  0.0042\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7912101647958285, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16417983051312515, margin=0.5114319374312404, lpl_weight=0.779947379560689\n",
      " - ratio=0.12051002508121092, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9422, F1=0.8689, Recall=0.8361, Precision=0.9043\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7912101647958285, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16417983051312515, margin=0.5114319374312404, lpl_weight=0.779947379560689\n",
      " - ratio=0.12051002508121092, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9425, F1=0.8696, Recall=0.8376, Precision=0.9041\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7912101647958285, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16417983051312515, margin=0.5114319374312404, lpl_weight=0.779947379560689\n",
      " - ratio=0.12051002508121092, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9450, F1=0.8746, Recall=0.8384, Precision=0.9141\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7912101647958285, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16417983051312515, margin=0.5114319374312404, lpl_weight=0.779947379560689\n",
      " - ratio=0.12051002508121092, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9453, F1=0.8762, Recall=0.8455, Precision=0.9093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=5:\n",
      " - alpha=0.7912101647958285, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.16417983051312515, margin=0.5114319374312404, lpl_weight=0.779947379560689\n",
      " - ratio=0.12051002508121092, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:47:30,421] Trial 41 finished with value: 0.8708264137674167 and parameters: {'alpha': 0.7912101647958285, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.16417983051312515, 'margin': 0.5114319374312404, 'lpl_weight': 0.779947379560689, 'ratio': 0.12051002508121092, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9403, F1=0.8648, Recall=0.8346, Precision=0.8973\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202004347.csv.\n",
      "Average F1 over 5 seeds: 0.8708  0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.8447828151231033, K=30, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.13661549177097157, margin=0.44092650811982437, lpl_weight=0.7149795800044271\n",
      " - ratio=0.10283760553990373, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9439, F1=0.8691, Recall=0.8126, Precision=0.9339\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8447828151231033, K=30, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.13661549177097157, margin=0.44092650811982437, lpl_weight=0.7149795800044271\n",
      " - ratio=0.10283760553990373, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9463, F1=0.8751, Recall=0.8212, Precision=0.9366\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8447828151231033, K=30, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.13661549177097157, margin=0.44092650811982437, lpl_weight=0.7149795800044271\n",
      " - ratio=0.10283760553990373, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9480, F1=0.8791, Recall=0.8249, Precision=0.9408\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8447828151231033, K=30, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.13661549177097157, margin=0.44092650811982437, lpl_weight=0.7149795800044271\n",
      " - ratio=0.10283760553990373, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9486, F1=0.8809, Recall=0.8294, Precision=0.9391\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8447828151231033, K=30, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.13661549177097157, margin=0.44092650811982437, lpl_weight=0.7149795800044271\n",
      " - ratio=0.10283760553990373, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:51:09,144] Trial 42 finished with value: 0.8757425097396506 and parameters: {'alpha': 0.8447828151231033, 'K': 30, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.13661549177097157, 'margin': 0.44092650811982437, 'lpl_weight': 0.7149795800044271, 'ratio': 0.10283760553990373, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9462, F1=0.8746, Recall=0.8201, Precision=0.9369\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202004730.csv.\n",
      "Average F1 over 5 seeds: 0.8757  0.0041\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9995024389331734, K=33, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.22760442718634327, margin=0.5372685664558081, lpl_weight=0.9338123686431891\n",
      " - ratio=0.14972426589480942, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9348, F1=0.8576, Recall=0.8574, Precision=0.8577\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9995024389331734, K=33, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.22760442718634327, margin=0.5372685664558081, lpl_weight=0.9338123686431891\n",
      " - ratio=0.14972426589480942, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9355, F1=0.8597, Recall=0.8634, Precision=0.8560\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9995024389331734, K=33, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.22760442718634327, margin=0.5372685664558081, lpl_weight=0.9338123686431891\n",
      " - ratio=0.14972426589480942, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9356, F1=0.8601, Recall=0.8649, Precision=0.8553\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9995024389331734, K=33, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.22760442718634327, margin=0.5372685664558081, lpl_weight=0.9338123686431891\n",
      " - ratio=0.14972426589480942, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9381, F1=0.8652, Recall=0.8675, Precision=0.8630\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9995024389331734, K=33, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.22760442718634327, margin=0.5372685664558081, lpl_weight=0.9338123686431891\n",
      " - ratio=0.14972426589480942, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:54:56,671] Trial 43 finished with value: 0.859459228086757 and parameters: {'alpha': 0.9995024389331734, 'K': 33, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.22760442718634327, 'margin': 0.5372685664558081, 'lpl_weight': 0.9338123686431891, 'ratio': 0.14972426589480942, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9333, F1=0.8547, Recall=0.8567, Precision=0.8528\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202005109.csv.\n",
      "Average F1 over 5 seeds: 0.8595  0.0034\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7361287712598844, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18801886727041858, margin=0.7262756185330888, lpl_weight=0.8433495724243045\n",
      " - ratio=0.13028150899448326, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9385, F1=0.8625, Recall=0.8429, Precision=0.8831\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7361287712598844, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18801886727041858, margin=0.7262756185330888, lpl_weight=0.8433495724243045\n",
      " - ratio=0.13028150899448326, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9386, F1=0.8639, Recall=0.8503, Precision=0.8778\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7361287712598844, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18801886727041858, margin=0.7262756185330888, lpl_weight=0.8433495724243045\n",
      " - ratio=0.13028150899448326, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9417, F1=0.8695, Recall=0.8485, Precision=0.8917\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7361287712598844, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18801886727041858, margin=0.7262756185330888, lpl_weight=0.8433495724243045\n",
      " - ratio=0.13028150899448326, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9415, F1=0.8701, Recall=0.8552, Precision=0.8856\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7361287712598844, K=32, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18801886727041858, margin=0.7262756185330888, lpl_weight=0.8433495724243045\n",
      " - ratio=0.13028150899448326, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:58:41,285] Trial 44 finished with value: 0.8653451878723006 and parameters: {'alpha': 0.7361287712598844, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.18801886727041858, 'margin': 0.7262756185330888, 'lpl_weight': 0.8433495724243045, 'ratio': 0.13028150899448326, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9372, F1=0.8607, Recall=0.8477, Precision=0.8741\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202005456.csv.\n",
      "Average F1 over 5 seeds: 0.8653  0.0038\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6600500436855703, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15815256384062215, margin=0.599588805242781, lpl_weight=0.5352966833525497\n",
      " - ratio=0.18738241592747856, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8300, LPL: 1.3863, Contrastive: 0.1892\n",
      " - Metrics: Accuracy=0.9372, F1=0.8712, Recall=0.9280, Precision=0.8210\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6600500436855703, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15815256384062215, margin=0.599588805242781, lpl_weight=0.5352966833525497\n",
      " - ratio=0.18738241592747856, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8300, LPL: 1.3863, Contrastive: 0.1892\n",
      " - Metrics: Accuracy=0.9397, F1=0.8764, Recall=0.9343, Precision=0.8253\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6600500436855703, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15815256384062215, margin=0.599588805242781, lpl_weight=0.5352966833525497\n",
      " - ratio=0.18738241592747856, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8300, LPL: 1.3863, Contrastive: 0.1892\n",
      " - Metrics: Accuracy=0.9372, F1=0.8713, Recall=0.9291, Precision=0.8204\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6600500436855703, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15815256384062215, margin=0.599588805242781, lpl_weight=0.5352966833525497\n",
      " - ratio=0.18738241592747856, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8300, LPL: 1.3863, Contrastive: 0.1892\n",
      " - Metrics: Accuracy=0.9403, F1=0.8774, Recall=0.9336, Precision=0.8276\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6600500436855703, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.15815256384062215, margin=0.599588805242781, lpl_weight=0.5352966833525497\n",
      " - ratio=0.18738241592747856, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8300, LPL: 1.3863, Contrastive: 0.1892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 00:59:59,710] Trial 45 finished with value: 0.8746513816474094 and parameters: {'alpha': 0.6600500436855703, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.15815256384062215, 'margin': 0.599588805242781, 'lpl_weight': 0.5352966833525497, 'ratio': 0.18738241592747856, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9401, F1=0.8769, Recall=0.9321, Precision=0.8279\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202005841.csv.\n",
      "Average F1 over 5 seeds: 0.8747  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8303037101969165, K=35, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.21290474828891143, margin=0.3493244898168671, lpl_weight=0.6701317486298253\n",
      " - ratio=0.10039569745785705, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9448, F1=0.8707, Recall=0.8119, Precision=0.9387\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8303037101969165, K=35, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.21290474828891143, margin=0.3493244898168671, lpl_weight=0.6701317486298253\n",
      " - ratio=0.10039569745785705, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9468, F1=0.8757, Recall=0.8182, Precision=0.9420\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8303037101969165, K=35, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.21290474828891143, margin=0.3493244898168671, lpl_weight=0.6701317486298253\n",
      " - ratio=0.10039569745785705, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9476, F1=0.8776, Recall=0.8201, Precision=0.9437\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8303037101969165, K=35, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.21290474828891143, margin=0.3493244898168671, lpl_weight=0.6701317486298253\n",
      " - ratio=0.10039569745785705, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9485, F1=0.8798, Recall=0.8234, Precision=0.9443\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.8303037101969165, K=35, layers=2, hidden=128, out=128\n",
      " - norm=None, dropout=0.21290474828891143, margin=0.3493244898168671, lpl_weight=0.6701317486298253\n",
      " - ratio=0.10039569745785705, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:04:11,916] Trial 46 finished with value: 0.8749079285967885 and parameters: {'alpha': 0.8303037101969165, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': None, 'dropout': 0.21290474828891143, 'margin': 0.3493244898168671, 'lpl_weight': 0.6701317486298253, 'ratio': 0.10039569745785705, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 9 with value: 0.883848773989067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9446, F1=0.8708, Recall=0.8149, Precision=0.9349\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202005959.csv.\n",
      "Average F1 over 5 seeds: 0.8749  0.0036\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7738911567919408, K=32, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2650420015732019, margin=0.4545082436376272, lpl_weight=0.7704729244985603\n",
      " - ratio=0.14340267860279593, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1214, LPL: 1.3863, Contrastive: 0.2321\n",
      " - Metrics: Accuracy=0.9492, F1=0.8893, Recall=0.8906, Precision=0.8880\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7738911567919408, K=32, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2650420015732019, margin=0.4545082436376272, lpl_weight=0.7704729244985603\n",
      " - ratio=0.14340267860279593, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1214, LPL: 1.3863, Contrastive: 0.2321\n",
      " - Metrics: Accuracy=0.9500, F1=0.8908, Recall=0.8906, Precision=0.8910\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7738911567919408, K=32, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2650420015732019, margin=0.4545082436376272, lpl_weight=0.7704729244985603\n",
      " - ratio=0.14340267860279593, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1214, LPL: 1.3863, Contrastive: 0.2321\n",
      " - Metrics: Accuracy=0.9488, F1=0.8881, Recall=0.8876, Precision=0.8886\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7738911567919408, K=32, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2650420015732019, margin=0.4545082436376272, lpl_weight=0.7704729244985603\n",
      " - ratio=0.14340267860279593, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1214, LPL: 1.3863, Contrastive: 0.2321\n",
      " - Metrics: Accuracy=0.9513, F1=0.8934, Recall=0.8914, Precision=0.8954\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7738911567919408, K=32, layers=2, hidden=256, out=64\n",
      " - norm=graphnorm, dropout=0.2650420015732019, margin=0.4545082436376272, lpl_weight=0.7704729244985603\n",
      " - ratio=0.14340267860279593, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1214, LPL: 1.3863, Contrastive: 0.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:05:31,214] Trial 47 finished with value: 0.8912812556765894 and parameters: {'alpha': 0.7738911567919408, 'K': 32, 'layers': 2, 'hidden_channels': 256, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.2650420015732019, 'margin': 0.4545082436376272, 'lpl_weight': 0.7704729244985603, 'ratio': 0.14340267860279593, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 47 with value: 0.8912812556765894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9519, F1=0.8948, Recall=0.8936, Precision=0.8960\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202010411.csv.\n",
      "Average F1 over 5 seeds: 0.8913  0.0025\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6168959774886476, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27255282153777893, margin=0.45860618343657117, lpl_weight=0.38779404778714577\n",
      " - ratio=0.14626609481613123, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6829, LPL: 1.3863, Contrastive: 0.2374\n",
      " - Metrics: Accuracy=0.9421, F1=0.8777, Recall=0.9067, Precision=0.8505\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6168959774886476, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27255282153777893, margin=0.45860618343657117, lpl_weight=0.38779404778714577\n",
      " - ratio=0.14626609481613123, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6829, LPL: 1.3863, Contrastive: 0.2374\n",
      " - Metrics: Accuracy=0.9444, F1=0.8824, Recall=0.9115, Precision=0.8550\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6168959774886476, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27255282153777893, margin=0.45860618343657117, lpl_weight=0.38779404778714577\n",
      " - ratio=0.14626609481613123, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6829, LPL: 1.3863, Contrastive: 0.2374\n",
      " - Metrics: Accuracy=0.9423, F1=0.8780, Recall=0.9071, Precision=0.8508\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6168959774886476, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27255282153777893, margin=0.45860618343657117, lpl_weight=0.38779404778714577\n",
      " - ratio=0.14626609481613123, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6829, LPL: 1.3863, Contrastive: 0.2374\n",
      " - Metrics: Accuracy=0.9437, F1=0.8809, Recall=0.9100, Precision=0.8536\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6168959774886476, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27255282153777893, margin=0.45860618343657117, lpl_weight=0.38779404778714577\n",
      " - ratio=0.14626609481613123, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6829, LPL: 1.3863, Contrastive: 0.2374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:07:18,769] Trial 48 finished with value: 0.8797109304426378 and parameters: {'alpha': 0.6168959774886476, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.27255282153777893, 'margin': 0.45860618343657117, 'lpl_weight': 0.38779404778714577, 'ratio': 0.14626609481613123, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 47 with value: 0.8912812556765894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9430, F1=0.8795, Recall=0.9085, Precision=0.8522\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202010531.csv.\n",
      "Average F1 over 5 seeds: 0.8797  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7737855160992445, K=25, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2500011135168946, margin=0.18632622366549284, lpl_weight=0.6423885252067315\n",
      " - ratio=0.31711233262470534, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9947, LPL: 1.3863, Contrastive: 0.2913\n",
      " - Metrics: Accuracy=0.9282, F1=0.8598, Recall=0.9616, Precision=0.7775\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7737855160992445, K=25, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2500011135168946, margin=0.18632622366549284, lpl_weight=0.6423885252067315\n",
      " - ratio=0.31711233262470534, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9947, LPL: 1.3863, Contrastive: 0.2913\n",
      " - Metrics: Accuracy=0.9322, F1=0.8668, Recall=0.9630, Precision=0.7880\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7737855160992445, K=25, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2500011135168946, margin=0.18632622366549284, lpl_weight=0.6423885252067315\n",
      " - ratio=0.31711233262470534, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9947, LPL: 1.3863, Contrastive: 0.2913\n",
      " - Metrics: Accuracy=0.9274, F1=0.8585, Recall=0.9616, Precision=0.7754\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7737855160992445, K=25, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2500011135168946, margin=0.18632622366549284, lpl_weight=0.6423885252067315\n",
      " - ratio=0.31711233262470534, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9947, LPL: 1.3863, Contrastive: 0.2913\n",
      " - Metrics: Accuracy=0.9285, F1=0.8609, Recall=0.9672, Precision=0.7757\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7737855160992445, K=25, layers=2, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.2500011135168946, margin=0.18632622366549284, lpl_weight=0.6423885252067315\n",
      " - ratio=0.31711233262470534, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.9947, LPL: 1.3863, Contrastive: 0.2913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:08:39,834] Trial 49 finished with value: 0.8615292870885753 and parameters: {'alpha': 0.7737855160992445, 'K': 25, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.2500011135168946, 'margin': 0.18632622366549284, 'lpl_weight': 0.6423885252067315, 'ratio': 0.31711233262470534, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 47 with value: 0.8912812556765894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9292, F1=0.8616, Recall=0.9630, Precision=0.7795\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202010718.csv.\n",
      "Average F1 over 5 seeds: 0.8615  0.0028\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5145176200006807, K=33, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31301835543247825, margin=0.9547862338757434, lpl_weight=0.8928360716224606\n",
      " - ratio=0.168825746735347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2576, LPL: 1.3863, Contrastive: 0.1855\n",
      " - Metrics: Accuracy=0.9252, F1=0.8483, Recall=0.9134, Precision=0.7919\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5145176200006807, K=33, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31301835543247825, margin=0.9547862338757434, lpl_weight=0.8928360716224606\n",
      " - ratio=0.168825746735347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2576, LPL: 1.3863, Contrastive: 0.1855\n",
      " - Metrics: Accuracy=0.9281, F1=0.8542, Recall=0.9197, Precision=0.7974\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5145176200006807, K=33, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31301835543247825, margin=0.9547862338757434, lpl_weight=0.8928360716224606\n",
      " - ratio=0.168825746735347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2576, LPL: 1.3863, Contrastive: 0.1855\n",
      " - Metrics: Accuracy=0.9237, F1=0.8452, Recall=0.9100, Precision=0.7890\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5145176200006807, K=33, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31301835543247825, margin=0.9547862338757434, lpl_weight=0.8928360716224606\n",
      " - ratio=0.168825746735347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2576, LPL: 1.3863, Contrastive: 0.1855\n",
      " - Metrics: Accuracy=0.9262, F1=0.8504, Recall=0.9156, Precision=0.7939\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5145176200006807, K=33, layers=3, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.31301835543247825, margin=0.9547862338757434, lpl_weight=0.8928360716224606\n",
      " - ratio=0.168825746735347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2576, LPL: 1.3863, Contrastive: 0.1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:10:16,339] Trial 50 finished with value: 0.8488819552782111 and parameters: {'alpha': 0.5145176200006807, 'K': 33, 'layers': 3, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.31301835543247825, 'margin': 0.9547862338757434, 'lpl_weight': 0.8928360716224606, 'ratio': 0.168825746735347, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 47 with value: 0.8912812556765894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9242, F1=0.8462, Recall=0.9112, Precision=0.7900\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202010839.csv.\n",
      "Average F1 over 5 seeds: 0.8489  0.0032\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6329163593420954, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27770485396349487, margin=0.4403898453858425, lpl_weight=0.4370330698508676\n",
      " - ratio=0.1422423547376967, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7403, LPL: 1.3863, Contrastive: 0.2387\n",
      " - Metrics: Accuracy=0.9447, F1=0.8822, Recall=0.9044, Precision=0.8611\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6329163593420954, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27770485396349487, margin=0.4403898453858425, lpl_weight=0.4370330698508676\n",
      " - ratio=0.1422423547376967, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7403, LPL: 1.3863, Contrastive: 0.2387\n",
      " - Metrics: Accuracy=0.9471, F1=0.8873, Recall=0.9097, Precision=0.8660\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6329163593420954, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27770485396349487, margin=0.4403898453858425, lpl_weight=0.4370330698508676\n",
      " - ratio=0.1422423547376967, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7403, LPL: 1.3863, Contrastive: 0.2387\n",
      " - Metrics: Accuracy=0.9450, F1=0.8829, Recall=0.9052, Precision=0.8618\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6329163593420954, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27770485396349487, margin=0.4403898453858425, lpl_weight=0.4370330698508676\n",
      " - ratio=0.1422423547376967, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7403, LPL: 1.3863, Contrastive: 0.2387\n",
      " - Metrics: Accuracy=0.9462, F1=0.8855, Recall=0.9078, Precision=0.8643\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6329163593420954, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.27770485396349487, margin=0.4403898453858425, lpl_weight=0.4370330698508676\n",
      " - ratio=0.1422423547376967, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7403, LPL: 1.3863, Contrastive: 0.2387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:12:04,138] Trial 51 finished with value: 0.8839614054250864 and parameters: {'alpha': 0.6329163593420954, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.27770485396349487, 'margin': 0.4403898453858425, 'lpl_weight': 0.4370330698508676, 'ratio': 0.1422423547376967, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 47 with value: 0.8912812556765894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9445, F1=0.8818, Recall=0.9041, Precision=0.8607\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202011016.csv.\n",
      "Average F1 over 5 seeds: 0.8840  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4532547718639971, K=33, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34075074646577175, margin=0.3569587828747774, lpl_weight=0.4816517770412137\n",
      " - ratio=0.1189829965821889, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7994, LPL: 1.3863, Contrastive: 0.2541\n",
      " - Metrics: Accuracy=0.9533, F1=0.8960, Recall=0.8783, Precision=0.9145\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4532547718639971, K=33, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34075074646577175, margin=0.3569587828747774, lpl_weight=0.4816517770412137\n",
      " - ratio=0.1189829965821889, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7994, LPL: 1.3863, Contrastive: 0.2541\n",
      " - Metrics: Accuracy=0.9537, F1=0.8968, Recall=0.8791, Precision=0.9153\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4532547718639971, K=33, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34075074646577175, margin=0.3569587828747774, lpl_weight=0.4816517770412137\n",
      " - ratio=0.1189829965821889, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7994, LPL: 1.3863, Contrastive: 0.2541\n",
      " - Metrics: Accuracy=0.9515, F1=0.8919, Recall=0.8742, Precision=0.9102\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4532547718639971, K=33, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34075074646577175, margin=0.3569587828747774, lpl_weight=0.4816517770412137\n",
      " - ratio=0.1189829965821889, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7994, LPL: 1.3863, Contrastive: 0.2541\n",
      " - Metrics: Accuracy=0.9544, F1=0.8983, Recall=0.8806, Precision=0.9168\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4532547718639971, K=33, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34075074646577175, margin=0.3569587828747774, lpl_weight=0.4816517770412137\n",
      " - ratio=0.1189829965821889, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7994, LPL: 1.3863, Contrastive: 0.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:13:50,579] Trial 52 finished with value: 0.8948971820258949 and parameters: {'alpha': 0.4532547718639971, 'K': 33, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.34075074646577175, 'margin': 0.3569587828747774, 'lpl_weight': 0.4816517770412137, 'ratio': 0.1189829965821889, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 52 with value: 0.8948971820258949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9513, F1=0.8915, Recall=0.8738, Precision=0.9098\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202011204.csv.\n",
      "Average F1 over 5 seeds: 0.8949  0.0027\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.45456651504744916, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34296987585956495, margin=0.3641111895335952, lpl_weight=0.4028996263438126\n",
      " - ratio=0.14050353814875127, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7105, LPL: 1.3863, Contrastive: 0.2545\n",
      " - Metrics: Accuracy=0.9471, F1=0.8869, Recall=0.9063, Precision=0.8684\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.45456651504744916, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34296987585956495, margin=0.3641111895335952, lpl_weight=0.4028996263438126\n",
      " - ratio=0.14050353814875127, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7105, LPL: 1.3863, Contrastive: 0.2545\n",
      " - Metrics: Accuracy=0.9491, F1=0.8913, Recall=0.9108, Precision=0.8727\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.45456651504744916, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34296987585956495, margin=0.3641111895335952, lpl_weight=0.4028996263438126\n",
      " - ratio=0.14050353814875127, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7105, LPL: 1.3863, Contrastive: 0.2545\n",
      " - Metrics: Accuracy=0.9454, F1=0.8833, Recall=0.9026, Precision=0.8648\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.45456651504744916, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34296987585956495, margin=0.3641111895335952, lpl_weight=0.4028996263438126\n",
      " - ratio=0.14050353814875127, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7105, LPL: 1.3863, Contrastive: 0.2545\n",
      " - Metrics: Accuracy=0.9476, F1=0.8880, Recall=0.9074, Precision=0.8695\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.45456651504744916, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34296987585956495, margin=0.3641111895335952, lpl_weight=0.4028996263438126\n",
      " - ratio=0.14050353814875127, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7105, LPL: 1.3863, Contrastive: 0.2545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:15:37,612] Trial 53 finished with value: 0.8872328767123288 and parameters: {'alpha': 0.45456651504744916, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.34296987585956495, 'margin': 0.3641111895335952, 'lpl_weight': 0.4028996263438126, 'ratio': 0.14050353814875127, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 52 with value: 0.8948971820258949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9469, F1=0.8866, Recall=0.9059, Precision=0.8680\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202011350.csv.\n",
      "Average F1 over 5 seeds: 0.8872  0.0026\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4761406662501068, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3404235951866134, margin=0.3730030921067997, lpl_weight=0.41887428924655307\n",
      " - ratio=0.20848886765100483, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7282, LPL: 1.3863, Contrastive: 0.2538\n",
      " - Metrics: Accuracy=0.9093, F1=0.8283, Recall=0.9552, Precision=0.7311\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4761406662501068, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3404235951866134, margin=0.3730030921067997, lpl_weight=0.41887428924655307\n",
      " - ratio=0.20848886765100483, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7282, LPL: 1.3863, Contrastive: 0.2538\n",
      " - Metrics: Accuracy=0.9085, F1=0.8267, Recall=0.9533, Precision=0.7297\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4761406662501068, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3404235951866134, margin=0.3730030921067997, lpl_weight=0.41887428924655307\n",
      " - ratio=0.20848886765100483, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7282, LPL: 1.3863, Contrastive: 0.2538\n",
      " - Metrics: Accuracy=0.9090, F1=0.8276, Recall=0.9545, Precision=0.7306\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4761406662501068, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3404235951866134, margin=0.3730030921067997, lpl_weight=0.41887428924655307\n",
      " - ratio=0.20848886765100483, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7282, LPL: 1.3863, Contrastive: 0.2538\n",
      " - Metrics: Accuracy=0.9103, F1=0.8302, Recall=0.9574, Precision=0.7329\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4761406662501068, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3404235951866134, margin=0.3730030921067997, lpl_weight=0.41887428924655307\n",
      " - ratio=0.20848886765100483, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7282, LPL: 1.3863, Contrastive: 0.2538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:17:25,378] Trial 54 finished with value: 0.8282893672115229 and parameters: {'alpha': 0.4761406662501068, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.3404235951866134, 'margin': 0.3730030921067997, 'lpl_weight': 0.41887428924655307, 'ratio': 0.20848886765100483, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 52 with value: 0.8948971820258949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9095, F1=0.8286, Recall=0.9556, Precision=0.7314\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202011537.csv.\n",
      "Average F1 over 5 seeds: 0.8283  0.0012\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.45277520100956237, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3545708871295375, margin=0.30559473909035745, lpl_weight=0.2885094615516922\n",
      " - ratio=0.13813975133539902, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.2584\n",
      " - Metrics: Accuracy=0.9503, F1=0.8934, Recall=0.9089, Precision=0.8784\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.45277520100956237, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3545708871295375, margin=0.30559473909035745, lpl_weight=0.2885094615516922\n",
      " - ratio=0.13813975133539902, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.2584\n",
      " - Metrics: Accuracy=0.9515, F1=0.8960, Recall=0.9115, Precision=0.8810\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.45277520100956237, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3545708871295375, margin=0.30559473909035745, lpl_weight=0.2885094615516922\n",
      " - ratio=0.13813975133539902, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.2584\n",
      " - Metrics: Accuracy=0.9498, F1=0.8923, Recall=0.9078, Precision=0.8773\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.45277520100956237, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3545708871295375, margin=0.30559473909035745, lpl_weight=0.2885094615516922\n",
      " - ratio=0.13813975133539902, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.2584\n",
      " - Metrics: Accuracy=0.9502, F1=0.8930, Recall=0.9085, Precision=0.8781\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.45277520100956237, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3545708871295375, margin=0.30559473909035745, lpl_weight=0.2885094615516922\n",
      " - ratio=0.13813975133539902, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5838, LPL: 1.3863, Contrastive: 0.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:19:12,220] Trial 55 finished with value: 0.8939277196844616 and parameters: {'alpha': 0.45277520100956237, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.3545708871295375, 'margin': 0.30559473909035745, 'lpl_weight': 0.2885094615516922, 'ratio': 0.13813975133539902, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 52 with value: 0.8948971820258949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9510, F1=0.8949, Recall=0.9104, Precision=0.8799\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202011725.csv.\n",
      "Average F1 over 5 seeds: 0.8939  0.0013\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3283985968421443, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3689521171974476, margin=0.3067587965679119, lpl_weight=0.277701050694148\n",
      " - ratio=0.18363799991565216, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5742, LPL: 1.3863, Contrastive: 0.2620\n",
      " - Metrics: Accuracy=0.9262, F1=0.8541, Recall=0.9440, Precision=0.7798\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3283985968421443, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3689521171974476, margin=0.3067587965679119, lpl_weight=0.277701050694148\n",
      " - ratio=0.18363799991565216, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5742, LPL: 1.3863, Contrastive: 0.2620\n",
      " - Metrics: Accuracy=0.9250, F1=0.8517, Recall=0.9414, Precision=0.7777\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3283985968421443, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3689521171974476, margin=0.3067587965679119, lpl_weight=0.277701050694148\n",
      " - ratio=0.18363799991565216, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5742, LPL: 1.3863, Contrastive: 0.2620\n",
      " - Metrics: Accuracy=0.9262, F1=0.8541, Recall=0.9440, Precision=0.7798\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3283985968421443, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3689521171974476, margin=0.3067587965679119, lpl_weight=0.277701050694148\n",
      " - ratio=0.18363799991565216, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5742, LPL: 1.3863, Contrastive: 0.2620\n",
      " - Metrics: Accuracy=0.9274, F1=0.8565, Recall=0.9466, Precision=0.7820\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3283985968421443, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.3689521171974476, margin=0.3067587965679119, lpl_weight=0.277701050694148\n",
      " - ratio=0.18363799991565216, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5742, LPL: 1.3863, Contrastive: 0.2620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:20:58,675] Trial 56 finished with value: 0.8548463356973995 and parameters: {'alpha': 0.3283985968421443, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.3689521171974476, 'margin': 0.3067587965679119, 'lpl_weight': 0.277701050694148, 'ratio': 0.18363799991565216, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 52 with value: 0.8948971820258949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9280, F1=0.8578, Recall=0.9481, Precision=0.7832\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202011912.csv.\n",
      "Average F1 over 5 seeds: 0.8548  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.41703665635652964, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34879169389609993, margin=0.426083837082737, lpl_weight=0.4582556154571607\n",
      " - ratio=0.13866052734381018, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7736, LPL: 1.3863, Contrastive: 0.2553\n",
      " - Metrics: Accuracy=0.9444, F1=0.8809, Recall=0.8970, Precision=0.8653\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.41703665635652964, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34879169389609993, margin=0.426083837082737, lpl_weight=0.4582556154571607\n",
      " - ratio=0.13866052734381018, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7736, LPL: 1.3863, Contrastive: 0.2553\n",
      " - Metrics: Accuracy=0.9458, F1=0.8838, Recall=0.9000, Precision=0.8682\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.41703665635652964, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34879169389609993, margin=0.426083837082737, lpl_weight=0.4582556154571607\n",
      " - ratio=0.13866052734381018, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7736, LPL: 1.3863, Contrastive: 0.2553\n",
      " - Metrics: Accuracy=0.9441, F1=0.8801, Recall=0.8962, Precision=0.8646\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.41703665635652964, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34879169389609993, margin=0.426083837082737, lpl_weight=0.4582556154571607\n",
      " - ratio=0.13866052734381018, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7736, LPL: 1.3863, Contrastive: 0.2553\n",
      " - Metrics: Accuracy=0.9468, F1=0.8860, Recall=0.9022, Precision=0.8704\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.41703665635652964, K=35, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.34879169389609993, margin=0.426083837082737, lpl_weight=0.4582556154571607\n",
      " - ratio=0.13866052734381018, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7736, LPL: 1.3863, Contrastive: 0.2553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:22:45,685] Trial 57 finished with value: 0.8825513196480937 and parameters: {'alpha': 0.41703665635652964, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.34879169389609993, 'margin': 0.426083837082737, 'lpl_weight': 0.4582556154571607, 'ratio': 0.13866052734381018, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 52 with value: 0.8948971820258949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9450, F1=0.8820, Recall=0.8981, Precision=0.8664\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202012058.csv.\n",
      "Average F1 over 5 seeds: 0.8826  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5281565478648429, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40408545505646154, margin=0.27749111418599404, lpl_weight=0.31471383845174916\n",
      " - ratio=0.15973540244189094, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6226, LPL: 1.3863, Contrastive: 0.2718\n",
      " - Metrics: Accuracy=0.9398, F1=0.8759, Recall=0.9276, Precision=0.8297\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5281565478648429, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40408545505646154, margin=0.27749111418599404, lpl_weight=0.31471383845174916\n",
      " - ratio=0.15973540244189094, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6226, LPL: 1.3863, Contrastive: 0.2718\n",
      " - Metrics: Accuracy=0.9412, F1=0.8787, Recall=0.9306, Precision=0.8324\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5281565478648429, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40408545505646154, margin=0.27749111418599404, lpl_weight=0.31471383845174916\n",
      " - ratio=0.15973540244189094, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6226, LPL: 1.3863, Contrastive: 0.2718\n",
      " - Metrics: Accuracy=0.9400, F1=0.8763, Recall=0.9280, Precision=0.8301\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5281565478648429, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40408545505646154, margin=0.27749111418599404, lpl_weight=0.31471383845174916\n",
      " - ratio=0.15973540244189094, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6226, LPL: 1.3863, Contrastive: 0.2718\n",
      " - Metrics: Accuracy=0.9412, F1=0.8787, Recall=0.9306, Precision=0.8324\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5281565478648429, K=34, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.40408545505646154, margin=0.27749111418599404, lpl_weight=0.31471383845174916\n",
      " - ratio=0.15973540244189094, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6226, LPL: 1.3863, Contrastive: 0.2718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:24:31,226] Trial 58 finished with value: 0.8779696862883327 and parameters: {'alpha': 0.5281565478648429, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.40408545505646154, 'margin': 0.27749111418599404, 'lpl_weight': 0.31471383845174916, 'ratio': 0.15973540244189094, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 52 with value: 0.8948971820258949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9419, F1=0.8802, Recall=0.9321, Precision=0.8337\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202012245.csv.\n",
      "Average F1 over 5 seeds: 0.8780  0.0016\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4411144196949293, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.40005872482894056, margin=0.34109158971690823, lpl_weight=0.23030161199822796\n",
      " - ratio=0.22558113383347578, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5133, LPL: 1.3863, Contrastive: 0.2520\n",
      " - Metrics: Accuracy=0.9392, F1=0.8774, Recall=0.9511, Precision=0.8143\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4411144196949293, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.40005872482894056, margin=0.34109158971690823, lpl_weight=0.23030161199822796\n",
      " - ratio=0.22558113383347578, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5133, LPL: 1.3863, Contrastive: 0.2520\n",
      " - Metrics: Accuracy=0.9372, F1=0.8743, Recall=0.9537, Precision=0.8070\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4411144196949293, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.40005872482894056, margin=0.34109158971690823, lpl_weight=0.23030161199822796\n",
      " - ratio=0.22558113383347578, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5133, LPL: 1.3863, Contrastive: 0.2520\n",
      " - Metrics: Accuracy=0.9371, F1=0.8738, Recall=0.9515, Precision=0.8079\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4411144196949293, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.40005872482894056, margin=0.34109158971690823, lpl_weight=0.23030161199822796\n",
      " - ratio=0.22558113383347578, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5133, LPL: 1.3863, Contrastive: 0.2520\n",
      " - Metrics: Accuracy=0.9397, F1=0.8786, Recall=0.9533, Precision=0.8147\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4411144196949293, K=33, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.40005872482894056, margin=0.34109158971690823, lpl_weight=0.23030161199822796\n",
      " - ratio=0.22558113383347578, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.5133, LPL: 1.3863, Contrastive: 0.2520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:26:11,853] Trial 59 finished with value: 0.875532926671033 and parameters: {'alpha': 0.4411144196949293, 'K': 33, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.40005872482894056, 'margin': 0.34109158971690823, 'lpl_weight': 0.23030161199822796, 'ratio': 0.22558113383347578, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 52 with value: 0.8948971820258949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9368, F1=0.8736, Recall=0.9545, Precision=0.8054\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202012431.csv.\n",
      "Average F1 over 5 seeds: 0.8755  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.35311903596690347, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.33346577358656093, margin=0.2168968766296331, lpl_weight=0.4316770237528901\n",
      " - ratio=0.12084606536176754, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7456, LPL: 1.3863, Contrastive: 0.2590\n",
      " - Metrics: Accuracy=0.9568, F1=0.9042, Recall=0.8895, Precision=0.9194\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.35311903596690347, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.33346577358656093, margin=0.2168968766296331, lpl_weight=0.4316770237528901\n",
      " - ratio=0.12084606536176754, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7456, LPL: 1.3863, Contrastive: 0.2590\n",
      " - Metrics: Accuracy=0.9565, F1=0.9034, Recall=0.8888, Precision=0.9186\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.35311903596690347, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.33346577358656093, margin=0.2168968766296331, lpl_weight=0.4316770237528901\n",
      " - ratio=0.12084606536176754, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7456, LPL: 1.3863, Contrastive: 0.2590\n",
      " - Metrics: Accuracy=0.9555, F1=0.9012, Recall=0.8865, Precision=0.9163\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.35311903596690347, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.33346577358656093, margin=0.2168968766296331, lpl_weight=0.4316770237528901\n",
      " - ratio=0.12084606536176754, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7456, LPL: 1.3863, Contrastive: 0.2590\n",
      " - Metrics: Accuracy=0.9560, F1=0.9023, Recall=0.8876, Precision=0.9174\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.35311903596690347, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.33346577358656093, margin=0.2168968766296331, lpl_weight=0.4316770237528901\n",
      " - ratio=0.12084606536176754, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7456, LPL: 1.3863, Contrastive: 0.2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:27:58,203] Trial 60 finished with value: 0.9027509011572757 and parameters: {'alpha': 0.35311903596690347, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.33346577358656093, 'margin': 0.2168968766296331, 'lpl_weight': 0.4316770237528901, 'ratio': 0.12084606536176754, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 60 with value: 0.9027509011572757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9562, F1=0.9027, Recall=0.8880, Precision=0.9178\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202012611.csv.\n",
      "Average F1 over 5 seeds: 0.9028  0.0010\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2917976884446246, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.34365114817277626, margin=0.20212498827396955, lpl_weight=0.4405129792448993\n",
      " - ratio=0.12494651944218, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7577, LPL: 1.3863, Contrastive: 0.2627\n",
      " - Metrics: Accuracy=0.9562, F1=0.9037, Recall=0.8962, Precision=0.9112\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2917976884446246, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.34365114817277626, margin=0.20212498827396955, lpl_weight=0.4405129792448993\n",
      " - ratio=0.12494651944218, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7577, LPL: 1.3863, Contrastive: 0.2627\n",
      " - Metrics: Accuracy=0.9564, F1=0.9040, Recall=0.8966, Precision=0.9116\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2917976884446246, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.34365114817277626, margin=0.20212498827396955, lpl_weight=0.4405129792448993\n",
      " - ratio=0.12494651944218, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7577, LPL: 1.3863, Contrastive: 0.2627\n",
      " - Metrics: Accuracy=0.9554, F1=0.9018, Recall=0.8944, Precision=0.9093\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2917976884446246, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.34365114817277626, margin=0.20212498827396955, lpl_weight=0.4405129792448993\n",
      " - ratio=0.12494651944218, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7577, LPL: 1.3863, Contrastive: 0.2627\n",
      " - Metrics: Accuracy=0.9547, F1=0.9003, Recall=0.8929, Precision=0.9078\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2917976884446246, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.34365114817277626, margin=0.20212498827396955, lpl_weight=0.4405129792448993\n",
      " - ratio=0.12494651944218, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7577, LPL: 1.3863, Contrastive: 0.2627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:29:44,642] Trial 61 finished with value: 0.9022958223560407 and parameters: {'alpha': 0.2917976884446246, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.34365114817277626, 'margin': 0.20212498827396955, 'lpl_weight': 0.4405129792448993, 'ratio': 0.12494651944218, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 60 with value: 0.9027509011572757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9554, F1=0.9018, Recall=0.8944, Precision=0.9093\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202012758.csv.\n",
      "Average F1 over 5 seeds: 0.9023  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.29052072527725126, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3405773436405099, margin=0.1622818502931161, lpl_weight=0.43824982911238847\n",
      " - ratio=0.12038245881377217, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7574, LPL: 1.3863, Contrastive: 0.2668\n",
      " - Metrics: Accuracy=0.9560, F1=0.9022, Recall=0.8869, Precision=0.9181\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.29052072527725126, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3405773436405099, margin=0.1622818502931161, lpl_weight=0.43824982911238847\n",
      " - ratio=0.12038245881377217, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7574, LPL: 1.3863, Contrastive: 0.2668\n",
      " - Metrics: Accuracy=0.9568, F1=0.9041, Recall=0.8888, Precision=0.9200\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.29052072527725126, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3405773436405099, margin=0.1622818502931161, lpl_weight=0.43824982911238847\n",
      " - ratio=0.12038245881377217, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7574, LPL: 1.3863, Contrastive: 0.2668\n",
      " - Metrics: Accuracy=0.9558, F1=0.9018, Recall=0.8865, Precision=0.9177\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.29052072527725126, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3405773436405099, margin=0.1622818502931161, lpl_weight=0.43824982911238847\n",
      " - ratio=0.12038245881377217, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7574, LPL: 1.3863, Contrastive: 0.2668\n",
      " - Metrics: Accuracy=0.9555, F1=0.9011, Recall=0.8858, Precision=0.9169\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.29052072527725126, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3405773436405099, margin=0.1622818502931161, lpl_weight=0.43824982911238847\n",
      " - ratio=0.12038245881377217, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7574, LPL: 1.3863, Contrastive: 0.2668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:31:30,041] Trial 62 finished with value: 0.90199354471236 and parameters: {'alpha': 0.29052072527725126, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3405773436405099, 'margin': 0.1622818502931161, 'lpl_weight': 0.43824982911238847, 'ratio': 0.12038245881377217, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 60 with value: 0.9027509011572757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9553, F1=0.9007, Recall=0.8854, Precision=0.9165\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202012944.csv.\n",
      "Average F1 over 5 seeds: 0.9020  0.0012\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.26335116201374076, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3378423731190347, margin=0.15885979866676905, lpl_weight=0.37319068962295715\n",
      " - ratio=0.12635399841899767, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6846, LPL: 1.3863, Contrastive: 0.2667\n",
      " - Metrics: Accuracy=0.9553, F1=0.9019, Recall=0.8970, Precision=0.9068\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.26335116201374076, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3378423731190347, margin=0.15885979866676905, lpl_weight=0.37319068962295715\n",
      " - ratio=0.12635399841899767, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6846, LPL: 1.3863, Contrastive: 0.2667\n",
      " - Metrics: Accuracy=0.9562, F1=0.9037, Recall=0.8988, Precision=0.9087\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.26335116201374076, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3378423731190347, margin=0.15885979866676905, lpl_weight=0.37319068962295715\n",
      " - ratio=0.12635399841899767, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6846, LPL: 1.3863, Contrastive: 0.2667\n",
      " - Metrics: Accuracy=0.9555, F1=0.9022, Recall=0.8973, Precision=0.9072\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.26335116201374076, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3378423731190347, margin=0.15885979866676905, lpl_weight=0.37319068962295715\n",
      " - ratio=0.12635399841899767, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6846, LPL: 1.3863, Contrastive: 0.2667\n",
      " - Metrics: Accuracy=0.9546, F1=0.9004, Recall=0.8955, Precision=0.9053\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.26335116201374076, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3378423731190347, margin=0.15885979866676905, lpl_weight=0.37319068962295715\n",
      " - ratio=0.12635399841899767, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6846, LPL: 1.3863, Contrastive: 0.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:33:23,747] Trial 63 finished with value: 0.9020829423906924 and parameters: {'alpha': 0.26335116201374076, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3378423731190347, 'margin': 0.15885979866676905, 'lpl_weight': 0.37319068962295715, 'ratio': 0.12635399841899767, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 60 with value: 0.9027509011572757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9555, F1=0.9022, Recall=0.8973, Precision=0.9072\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202013130.csv.\n",
      "Average F1 over 5 seeds: 0.9021  0.0011\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2523220280779685, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.36097035324944754, margin=0.10237366729889852, lpl_weight=0.3657383621425004\n",
      " - ratio=0.11888833589307433, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6847, LPL: 1.3863, Contrastive: 0.2802\n",
      "Epoch 50, Loss: 0.6369, LPL: 1.3863, Contrastive: 0.2048\n",
      "Epoch 100, Loss: 0.6369, LPL: 1.3863, Contrastive: 0.2048\n",
      " - Metrics: Accuracy=0.9533, F1=0.8958, Recall=0.8779, Precision=0.9145\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2523220280779685, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.36097035324944754, margin=0.10237366729889852, lpl_weight=0.3657383621425004\n",
      " - ratio=0.11888833589307433, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6847, LPL: 1.3863, Contrastive: 0.2802\n",
      "Epoch 50, Loss: 0.6369, LPL: 1.3863, Contrastive: 0.2048\n",
      "Epoch 100, Loss: 0.6365, LPL: 1.3863, Contrastive: 0.2042\n",
      " - Metrics: Accuracy=0.9522, F1=0.8935, Recall=0.8757, Precision=0.9121\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2523220280779685, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.36097035324944754, margin=0.10237366729889852, lpl_weight=0.3657383621425004\n",
      " - ratio=0.11888833589307433, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6847, LPL: 1.3863, Contrastive: 0.2802\n",
      "Epoch 50, Loss: 0.6369, LPL: 1.3863, Contrastive: 0.2048\n",
      "Epoch 100, Loss: 0.6366, LPL: 1.3863, Contrastive: 0.2044\n",
      " - Metrics: Accuracy=0.9497, F1=0.8878, Recall=0.8701, Precision=0.9063\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2523220280779685, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.36097035324944754, margin=0.10237366729889852, lpl_weight=0.3657383621425004\n",
      " - ratio=0.11888833589307433, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6847, LPL: 1.3863, Contrastive: 0.2802\n",
      "Epoch 50, Loss: 0.6369, LPL: 1.3863, Contrastive: 0.2048\n",
      "Epoch 100, Loss: 0.6365, LPL: 1.3863, Contrastive: 0.2041\n",
      " - Metrics: Accuracy=0.9521, F1=0.8934, Recall=0.8757, Precision=0.9118\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2523220280779685, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.36097035324944754, margin=0.10237366729889852, lpl_weight=0.3657383621425004\n",
      " - ratio=0.11888833589307433, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6847, LPL: 1.3863, Contrastive: 0.2802\n",
      "Epoch 50, Loss: 0.6369, LPL: 1.3863, Contrastive: 0.2048\n",
      "Epoch 100, Loss: 0.6368, LPL: 1.3863, Contrastive: 0.2047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:36:09,014] Trial 64 finished with value: 0.8945765235592162 and parameters: {'alpha': 0.2523220280779685, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.36097035324944754, 'margin': 0.10237366729889852, 'lpl_weight': 0.3657383621425004, 'ratio': 0.11888833589307433, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 60 with value: 0.9027509011572757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9562, F1=0.9023, Recall=0.8843, Precision=0.9211\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202013323.csv.\n",
      "Average F1 over 5 seeds: 0.8946  0.0047\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.24420575134921743, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3599991944711314, margin=0.103458174066901, lpl_weight=0.3376161192895486\n",
      " - ratio=0.12172103712818252, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6534, LPL: 1.3863, Contrastive: 0.2798\n",
      "Epoch 50, Loss: 0.6034, LPL: 1.3863, Contrastive: 0.2043\n",
      "Epoch 100, Loss: 0.6047, LPL: 1.3863, Contrastive: 0.2063\n",
      " - Metrics: Accuracy=0.9562, F1=0.9029, Recall=0.8899, Precision=0.9162\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.24420575134921743, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3599991944711314, margin=0.103458174066901, lpl_weight=0.3376161192895486\n",
      " - ratio=0.12172103712818252, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6534, LPL: 1.3863, Contrastive: 0.2798\n",
      "Epoch 50, Loss: 0.6034, LPL: 1.3863, Contrastive: 0.2043\n",
      "Epoch 100, Loss: 0.6045, LPL: 1.3863, Contrastive: 0.2060\n",
      " - Metrics: Accuracy=0.9587, F1=0.9085, Recall=0.8955, Precision=0.9220\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.24420575134921743, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3599991944711314, margin=0.103458174066901, lpl_weight=0.3376161192895486\n",
      " - ratio=0.12172103712818252, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6534, LPL: 1.3863, Contrastive: 0.2798\n",
      "Epoch 50, Loss: 0.6034, LPL: 1.3863, Contrastive: 0.2043\n",
      "Epoch 100, Loss: 0.6043, LPL: 1.3863, Contrastive: 0.2057\n",
      " - Metrics: Accuracy=0.9539, F1=0.8979, Recall=0.8850, Precision=0.9112\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.24420575134921743, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3599991944711314, margin=0.103458174066901, lpl_weight=0.3376161192895486\n",
      " - ratio=0.12172103712818252, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6534, LPL: 1.3863, Contrastive: 0.2798\n",
      "Epoch 50, Loss: 0.6034, LPL: 1.3863, Contrastive: 0.2043\n",
      "Epoch 100, Loss: 0.6039, LPL: 1.3863, Contrastive: 0.2052\n",
      " - Metrics: Accuracy=0.9558, F1=0.9021, Recall=0.8891, Precision=0.9154\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.24420575134921743, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3599991944711314, margin=0.103458174066901, lpl_weight=0.3376161192895486\n",
      " - ratio=0.12172103712818252, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6534, LPL: 1.3863, Contrastive: 0.2798\n",
      "Epoch 50, Loss: 0.6034, LPL: 1.3863, Contrastive: 0.2043\n",
      "Epoch 100, Loss: 0.6043, LPL: 1.3863, Contrastive: 0.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:38:54,211] Trial 65 finished with value: 0.9032380231016853 and parameters: {'alpha': 0.24420575134921743, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3599991944711314, 'margin': 0.103458174066901, 'lpl_weight': 0.3376161192895486, 'ratio': 0.12172103712818252, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9570, F1=0.9048, Recall=0.8918, Precision=0.9181\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202013609.csv.\n",
      "Average F1 over 5 seeds: 0.9032  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.24417512297246607, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3299120814681346, margin=0.1237646317112481, lpl_weight=0.35538587720570175\n",
      " - ratio=0.11745609039780638, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6672, LPL: 1.3863, Contrastive: 0.2707\n",
      "Epoch 50, Loss: 0.6186, LPL: 1.3863, Contrastive: 0.1953\n",
      "Epoch 100, Loss: 0.6444, LPL: 1.3863, Contrastive: 0.2353\n",
      " - Metrics: Accuracy=0.9540, F1=0.8972, Recall=0.8768, Precision=0.9187\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.24417512297246607, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3299120814681346, margin=0.1237646317112481, lpl_weight=0.35538587720570175\n",
      " - ratio=0.11745609039780638, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6672, LPL: 1.3863, Contrastive: 0.2707\n",
      "Epoch 50, Loss: 0.6186, LPL: 1.3863, Contrastive: 0.1953\n",
      "Epoch 100, Loss: 0.6356, LPL: 1.3863, Contrastive: 0.2218\n",
      " - Metrics: Accuracy=0.9376, F1=0.8607, Recall=0.8417, Precision=0.8805\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.24417512297246607, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3299120814681346, margin=0.1237646317112481, lpl_weight=0.35538587720570175\n",
      " - ratio=0.11745609039780638, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6672, LPL: 1.3863, Contrastive: 0.2707\n",
      "Epoch 50, Loss: 0.6186, LPL: 1.3863, Contrastive: 0.1953\n",
      "Epoch 100, Loss: 0.6445, LPL: 1.3863, Contrastive: 0.2355\n",
      " - Metrics: Accuracy=0.9571, F1=0.9041, Recall=0.8835, Precision=0.9257\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.24417512297246607, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3299120814681346, margin=0.1237646317112481, lpl_weight=0.35538587720570175\n",
      " - ratio=0.11745609039780638, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6672, LPL: 1.3863, Contrastive: 0.2707\n",
      "Epoch 50, Loss: 0.6186, LPL: 1.3863, Contrastive: 0.1953\n",
      "Epoch 100, Loss: 0.6370, LPL: 1.3863, Contrastive: 0.2239\n",
      " - Metrics: Accuracy=0.9576, F1=0.9053, Recall=0.8847, Precision=0.9269\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.24417512297246607, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3299120814681346, margin=0.1237646317112481, lpl_weight=0.35538587720570175\n",
      " - ratio=0.11745609039780638, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6672, LPL: 1.3863, Contrastive: 0.2707\n",
      "Epoch 50, Loss: 0.6186, LPL: 1.3863, Contrastive: 0.1953\n",
      "Epoch 100, Loss: 0.6380, LPL: 1.3863, Contrastive: 0.2255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:41:40,990] Trial 66 finished with value: 0.8940625382699924 and parameters: {'alpha': 0.24417512297246607, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3299120814681346, 'margin': 0.1237646317112481, 'lpl_weight': 0.35538587720570175, 'ratio': 0.11745609039780638, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9566, F1=0.9030, Recall=0.8824, Precision=0.9245\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202013854.csv.\n",
      "Average F1 over 5 seeds: 0.8941  0.0169\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.16132247847010375, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3931397390809836, margin=0.10036096889231783, lpl_weight=0.49024245075060946\n",
      " - ratio=0.11684272557949997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8258, LPL: 1.3863, Contrastive: 0.2867\n",
      "Epoch 50, Loss: 0.7845, LPL: 1.3863, Contrastive: 0.2058\n",
      "Epoch 100, Loss: 0.7845, LPL: 1.3863, Contrastive: 0.2057\n",
      " - Metrics: Accuracy=0.9520, F1=0.8925, Recall=0.8712, Precision=0.9149\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.16132247847010375, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3931397390809836, margin=0.10036096889231783, lpl_weight=0.49024245075060946\n",
      " - ratio=0.11684272557949997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8258, LPL: 1.3863, Contrastive: 0.2867\n",
      "Epoch 50, Loss: 0.7845, LPL: 1.3863, Contrastive: 0.2058\n",
      "Epoch 100, Loss: 0.7841, LPL: 1.3863, Contrastive: 0.2050\n",
      " - Metrics: Accuracy=0.9562, F1=0.9021, Recall=0.8806, Precision=0.9247\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.16132247847010375, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3931397390809836, margin=0.10036096889231783, lpl_weight=0.49024245075060946\n",
      " - ratio=0.11684272557949997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8258, LPL: 1.3863, Contrastive: 0.2867\n",
      "Epoch 50, Loss: 0.7845, LPL: 1.3863, Contrastive: 0.2058\n",
      "Epoch 100, Loss: 0.7844, LPL: 1.3863, Contrastive: 0.2055\n",
      " - Metrics: Accuracy=0.9566, F1=0.9029, Recall=0.8813, Precision=0.9255\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.16132247847010375, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3931397390809836, margin=0.10036096889231783, lpl_weight=0.49024245075060946\n",
      " - ratio=0.11684272557949997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8258, LPL: 1.3863, Contrastive: 0.2867\n",
      "Epoch 50, Loss: 0.7845, LPL: 1.3863, Contrastive: 0.2058\n",
      "Epoch 100, Loss: 0.7844, LPL: 1.3863, Contrastive: 0.2056\n",
      " - Metrics: Accuracy=0.9456, F1=0.8784, Recall=0.8574, Precision=0.9004\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.16132247847010375, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3931397390809836, margin=0.10036096889231783, lpl_weight=0.49024245075060946\n",
      " - ratio=0.11684272557949997, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8258, LPL: 1.3863, Contrastive: 0.2867\n",
      "Epoch 50, Loss: 0.7845, LPL: 1.3863, Contrastive: 0.2058\n",
      "Epoch 100, Loss: 0.7844, LPL: 1.3863, Contrastive: 0.2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:44:28,543] Trial 67 finished with value: 0.8967495219885278 and parameters: {'alpha': 0.16132247847010375, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3931397390809836, 'margin': 0.10036096889231783, 'lpl_weight': 0.49024245075060946, 'ratio': 0.11684272557949997, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9588, F1=0.9078, Recall=0.8862, Precision=0.9306\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202014141.csv.\n",
      "Average F1 over 5 seeds: 0.8967  0.0104\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1731028804444235, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3890071745774446, margin=0.1768292535948418, lpl_weight=0.48923092611900404\n",
      " - ratio=0.16007374724473697, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8187, LPL: 1.3863, Contrastive: 0.2750\n",
      " - Metrics: Accuracy=0.9426, F1=0.8816, Recall=0.9343, Precision=0.8346\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1731028804444235, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3890071745774446, margin=0.1768292535948418, lpl_weight=0.48923092611900404\n",
      " - ratio=0.16007374724473697, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8187, LPL: 1.3863, Contrastive: 0.2750\n",
      " - Metrics: Accuracy=0.9443, F1=0.8852, Recall=0.9380, Precision=0.8379\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1731028804444235, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3890071745774446, margin=0.1768292535948418, lpl_weight=0.48923092611900404\n",
      " - ratio=0.16007374724473697, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8187, LPL: 1.3863, Contrastive: 0.2750\n",
      " - Metrics: Accuracy=0.9427, F1=0.8820, Recall=0.9347, Precision=0.8349\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1731028804444235, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3890071745774446, margin=0.1768292535948418, lpl_weight=0.48923092611900404\n",
      " - ratio=0.16007374724473697, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8187, LPL: 1.3863, Contrastive: 0.2750\n",
      " - Metrics: Accuracy=0.9426, F1=0.8816, Recall=0.9343, Precision=0.8346\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1731028804444235, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3890071745774446, margin=0.1768292535948418, lpl_weight=0.48923092611900404\n",
      " - ratio=0.16007374724473697, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8187, LPL: 1.3863, Contrastive: 0.2750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:46:14,891] Trial 68 finished with value: 0.8831983092638254 and parameters: {'alpha': 0.1731028804444235, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3890071745774446, 'margin': 0.1768292535948418, 'lpl_weight': 0.48923092611900404, 'ratio': 0.16007374724473697, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9444, F1=0.8855, Recall=0.9384, Precision=0.8383\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202014428.csv.\n",
      "Average F1 over 5 seeds: 0.8832  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2843144444496024, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4305050454154599, margin=0.1649154385751293, lpl_weight=0.5359399547751225\n",
      " - ratio=0.11583030981693898, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8754, LPL: 1.3863, Contrastive: 0.2853\n",
      " - Metrics: Accuracy=0.9562, F1=0.9019, Recall=0.8787, Precision=0.9264\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2843144444496024, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4305050454154599, margin=0.1649154385751293, lpl_weight=0.5359399547751225\n",
      " - ratio=0.11583030981693898, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8754, LPL: 1.3863, Contrastive: 0.2853\n",
      " - Metrics: Accuracy=0.9540, F1=0.8969, Recall=0.8738, Precision=0.9213\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2843144444496024, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4305050454154599, margin=0.1649154385751293, lpl_weight=0.5359399547751225\n",
      " - ratio=0.11583030981693898, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8754, LPL: 1.3863, Contrastive: 0.2853\n",
      " - Metrics: Accuracy=0.9554, F1=0.9000, Recall=0.8768, Precision=0.9244\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2843144444496024, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4305050454154599, margin=0.1649154385751293, lpl_weight=0.5359399547751225\n",
      " - ratio=0.11583030981693898, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8754, LPL: 1.3863, Contrastive: 0.2853\n",
      " - Metrics: Accuracy=0.9540, F1=0.8969, Recall=0.8738, Precision=0.9213\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2843144444496024, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4305050454154599, margin=0.1649154385751293, lpl_weight=0.5359399547751225\n",
      " - ratio=0.11583030981693898, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8754, LPL: 1.3863, Contrastive: 0.2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:48:00,649] Trial 69 finished with value: 0.8989272030651343 and parameters: {'alpha': 0.2843144444496024, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4305050454154599, 'margin': 0.1649154385751293, 'lpl_weight': 0.5359399547751225, 'ratio': 0.11583030981693898, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9549, F1=0.8989, Recall=0.8757, Precision=0.9233\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202014614.csv.\n",
      "Average F1 over 5 seeds: 0.8989  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.11410582629772092, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47233229184119846, margin=0.1739420824203348, lpl_weight=0.5334413742757028\n",
      " - ratio=0.3692945581696079, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8768, LPL: 1.3863, Contrastive: 0.2943\n",
      " - Metrics: Accuracy=0.7787, F1=0.6700, Recall=0.9810, Precision=0.5087\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.11410582629772092, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47233229184119846, margin=0.1739420824203348, lpl_weight=0.5334413742757028\n",
      " - ratio=0.3692945581696079, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8768, LPL: 1.3863, Contrastive: 0.2943\n",
      " - Metrics: Accuracy=0.7798, F1=0.6715, Recall=0.9832, Precision=0.5099\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.11410582629772092, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47233229184119846, margin=0.1739420824203348, lpl_weight=0.5334413742757028\n",
      " - ratio=0.3692945581696079, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8768, LPL: 1.3863, Contrastive: 0.2943\n",
      " - Metrics: Accuracy=0.7804, F1=0.6725, Recall=0.9847, Precision=0.5106\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.11410582629772092, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47233229184119846, margin=0.1739420824203348, lpl_weight=0.5334413742757028\n",
      " - ratio=0.3692945581696079, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8768, LPL: 1.3863, Contrastive: 0.2943\n",
      " - Metrics: Accuracy=0.7808, F1=0.6730, Recall=0.9854, Precision=0.5110\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.11410582629772092, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.47233229184119846, margin=0.1739420824203348, lpl_weight=0.5334413742757028\n",
      " - ratio=0.3692945581696079, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8768, LPL: 1.3863, Contrastive: 0.2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:49:47,994] Trial 70 finished with value: 0.6720203951561505 and parameters: {'alpha': 0.11410582629772092, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.47233229184119846, 'margin': 0.1739420824203348, 'lpl_weight': 0.5334413742757028, 'ratio': 0.3692945581696079, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7808, F1=0.6730, Recall=0.9854, Precision=0.5110\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202014800.csv.\n",
      "Average F1 over 5 seeds: 0.6720  0.0012\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2899958950774016, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4306570755927658, margin=0.22799728246461132, lpl_weight=0.47402188514595744\n",
      " - ratio=0.11631143185996076, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8045, LPL: 1.3863, Contrastive: 0.2803\n",
      " - Metrics: Accuracy=0.9557, F1=0.9008, Recall=0.8783, Precision=0.9246\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2899958950774016, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4306570755927658, margin=0.22799728246461132, lpl_weight=0.47402188514595744\n",
      " - ratio=0.11631143185996076, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8045, LPL: 1.3863, Contrastive: 0.2803\n",
      " - Metrics: Accuracy=0.9564, F1=0.9024, Recall=0.8798, Precision=0.9261\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2899958950774016, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4306570755927658, margin=0.22799728246461132, lpl_weight=0.47402188514595744\n",
      " - ratio=0.11631143185996076, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8045, LPL: 1.3863, Contrastive: 0.2803\n",
      " - Metrics: Accuracy=0.9547, F1=0.8985, Recall=0.8761, Precision=0.9222\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2899958950774016, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4306570755927658, margin=0.22799728246461132, lpl_weight=0.47402188514595744\n",
      " - ratio=0.11631143185996076, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8045, LPL: 1.3863, Contrastive: 0.2803\n",
      " - Metrics: Accuracy=0.9552, F1=0.8997, Recall=0.8772, Precision=0.9234\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2899958950774016, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4306570755927658, margin=0.22799728246461132, lpl_weight=0.47402188514595744\n",
      " - ratio=0.11631143185996076, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8045, LPL: 1.3863, Contrastive: 0.2803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:51:33,848] Trial 71 finished with value: 0.900229709035222 and parameters: {'alpha': 0.2899958950774016, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4306570755927658, 'margin': 0.22799728246461132, 'lpl_weight': 0.47402188514595744, 'ratio': 0.11631143185996076, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9552, F1=0.8997, Recall=0.8772, Precision=0.9234\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202014948.csv.\n",
      "Average F1 over 5 seeds: 0.9002  0.0013\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.29021671522998604, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4340532125519921, margin=0.22447947114758782, lpl_weight=0.5649198108906938\n",
      " - ratio=0.115687096646645, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9056, LPL: 1.3863, Contrastive: 0.2814\n",
      " - Metrics: Accuracy=0.9556, F1=0.9003, Recall=0.8768, Precision=0.9252\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.29021671522998604, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4340532125519921, margin=0.22447947114758782, lpl_weight=0.5649198108906938\n",
      " - ratio=0.115687096646645, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9056, LPL: 1.3863, Contrastive: 0.2814\n",
      " - Metrics: Accuracy=0.9562, F1=0.9019, Recall=0.8783, Precision=0.9267\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.29021671522998604, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4340532125519921, margin=0.22447947114758782, lpl_weight=0.5649198108906938\n",
      " - ratio=0.115687096646645, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9056, LPL: 1.3863, Contrastive: 0.2814\n",
      " - Metrics: Accuracy=0.9549, F1=0.8988, Recall=0.8753, Precision=0.9236\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.29021671522998604, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4340532125519921, margin=0.22447947114758782, lpl_weight=0.5649198108906938\n",
      " - ratio=0.115687096646645, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9056, LPL: 1.3863, Contrastive: 0.2814\n",
      " - Metrics: Accuracy=0.9556, F1=0.9003, Recall=0.8768, Precision=0.9252\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.29021671522998604, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4340532125519921, margin=0.22447947114758782, lpl_weight=0.5649198108906938\n",
      " - ratio=0.115687096646645, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9056, LPL: 1.3863, Contrastive: 0.2814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:53:19,312] Trial 72 finished with value: 0.9003449597546954 and parameters: {'alpha': 0.29021671522998604, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4340532125519921, 'margin': 0.22447947114758782, 'lpl_weight': 0.5649198108906938, 'ratio': 0.115687096646645, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9556, F1=0.9003, Recall=0.8768, Precision=0.9252\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202015133.csv.\n",
      "Average F1 over 5 seeds: 0.9003  0.0010\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.28570608558953753, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4198608436815835, margin=0.23085997888647106, lpl_weight=0.5526655816901015\n",
      " - ratio=0.12894060220408676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8903, LPL: 1.3863, Contrastive: 0.2776\n",
      " - Metrics: Accuracy=0.9541, F1=0.8997, Recall=0.8992, Precision=0.9002\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.28570608558953753, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4198608436815835, margin=0.23085997888647106, lpl_weight=0.5526655816901015\n",
      " - ratio=0.12894060220408676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8903, LPL: 1.3863, Contrastive: 0.2776\n",
      " - Metrics: Accuracy=0.9553, F1=0.9023, Recall=0.9018, Precision=0.9028\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.28570608558953753, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4198608436815835, margin=0.23085997888647106, lpl_weight=0.5526655816901015\n",
      " - ratio=0.12894060220408676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8903, LPL: 1.3863, Contrastive: 0.2776\n",
      " - Metrics: Accuracy=0.9539, F1=0.8993, Recall=0.8988, Precision=0.8999\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.28570608558953753, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4198608436815835, margin=0.23085997888647106, lpl_weight=0.5526655816901015\n",
      " - ratio=0.12894060220408676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8903, LPL: 1.3863, Contrastive: 0.2776\n",
      " - Metrics: Accuracy=0.9533, F1=0.8979, Recall=0.8973, Precision=0.8984\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.28570608558953753, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4198608436815835, margin=0.23085997888647106, lpl_weight=0.5526655816901015\n",
      " - ratio=0.12894060220408676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8903, LPL: 1.3863, Contrastive: 0.2776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:55:05,074] Trial 73 finished with value: 0.8996451914098973 and parameters: {'alpha': 0.28570608558953753, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4198608436815835, 'margin': 0.23085997888647106, 'lpl_weight': 0.5526655816901015, 'ratio': 0.12894060220408676, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9538, F1=0.8990, Recall=0.8985, Precision=0.8995\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202015319.csv.\n",
      "Average F1 over 5 seeds: 0.8996  0.0015\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.36950748539573297, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.41919624460916166, margin=0.22612337590139453, lpl_weight=0.5614197032674689\n",
      " - ratio=0.12903007811844563, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9001, LPL: 1.3863, Contrastive: 0.2777\n",
      " - Metrics: Accuracy=0.9547, F1=0.9010, Recall=0.9007, Precision=0.9014\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.36950748539573297, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.41919624460916166, margin=0.22612337590139453, lpl_weight=0.5614197032674689\n",
      " - ratio=0.12903007811844563, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9001, LPL: 1.3863, Contrastive: 0.2777\n",
      " - Metrics: Accuracy=0.9552, F1=0.9022, Recall=0.9018, Precision=0.9025\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.36950748539573297, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.41919624460916166, margin=0.22612337590139453, lpl_weight=0.5614197032674689\n",
      " - ratio=0.12903007811844563, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9001, LPL: 1.3863, Contrastive: 0.2777\n",
      " - Metrics: Accuracy=0.9537, F1=0.8988, Recall=0.8985, Precision=0.8991\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.36950748539573297, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.41919624460916166, margin=0.22612337590139453, lpl_weight=0.5614197032674689\n",
      " - ratio=0.12903007811844563, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9001, LPL: 1.3863, Contrastive: 0.2777\n",
      " - Metrics: Accuracy=0.9537, F1=0.8988, Recall=0.8985, Precision=0.8991\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.36950748539573297, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.41919624460916166, margin=0.22612337590139453, lpl_weight=0.5614197032674689\n",
      " - ratio=0.12903007811844563, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9001, LPL: 1.3863, Contrastive: 0.2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:56:51,286] Trial 74 finished with value: 0.8999253174010455 and parameters: {'alpha': 0.36950748539573297, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.41919624460916166, 'margin': 0.22612337590139453, 'lpl_weight': 0.5614197032674689, 'ratio': 0.12903007811844563, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9537, F1=0.8988, Recall=0.8985, Precision=0.8991\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202015505.csv.\n",
      "Average F1 over 5 seeds: 0.8999  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.35964115795794305, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4524855480827714, margin=0.21549898729052577, lpl_weight=0.44349315348331936\n",
      " - ratio=0.1541614208899742, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7741, LPL: 1.3863, Contrastive: 0.2863\n",
      " - Metrics: Accuracy=0.9439, F1=0.8830, Recall=0.9257, Precision=0.8441\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.35964115795794305, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4524855480827714, margin=0.21549898729052577, lpl_weight=0.44349315348331936\n",
      " - ratio=0.1541614208899742, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7741, LPL: 1.3863, Contrastive: 0.2863\n",
      " - Metrics: Accuracy=0.9454, F1=0.8862, Recall=0.9291, Precision=0.8472\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.35964115795794305, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4524855480827714, margin=0.21549898729052577, lpl_weight=0.44349315348331936\n",
      " - ratio=0.1541614208899742, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7741, LPL: 1.3863, Contrastive: 0.2863\n",
      " - Metrics: Accuracy=0.9442, F1=0.8837, Recall=0.9265, Precision=0.8448\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.35964115795794305, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4524855480827714, margin=0.21549898729052577, lpl_weight=0.44349315348331936\n",
      " - ratio=0.1541614208899742, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7741, LPL: 1.3863, Contrastive: 0.2863\n",
      " - Metrics: Accuracy=0.9445, F1=0.8845, Recall=0.9272, Precision=0.8455\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.35964115795794305, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4524855480827714, margin=0.21549898729052577, lpl_weight=0.44349315348331936\n",
      " - ratio=0.1541614208899742, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7741, LPL: 1.3863, Contrastive: 0.2863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 01:58:37,271] Trial 75 finished with value: 0.8848139576286274 and parameters: {'alpha': 0.35964115795794305, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4524855480827714, 'margin': 0.21549898729052577, 'lpl_weight': 0.44349315348331936, 'ratio': 0.1541614208899742, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9456, F1=0.8866, Recall=0.9295, Precision=0.8475\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202015651.csv.\n",
      "Average F1 over 5 seeds: 0.8848  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2288400524173242, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3037621128479933, margin=0.2562382851946287, lpl_weight=0.5678308124018494\n",
      " - ratio=0.130735459454235, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8952, LPL: 1.3863, Contrastive: 0.2499\n",
      " - Metrics: Accuracy=0.9547, F1=0.9014, Recall=0.9041, Precision=0.8987\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2288400524173242, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3037621128479933, margin=0.2562382851946287, lpl_weight=0.5678308124018494\n",
      " - ratio=0.130735459454235, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8952, LPL: 1.3863, Contrastive: 0.2499\n",
      " - Metrics: Accuracy=0.9552, F1=0.9025, Recall=0.9052, Precision=0.8998\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2288400524173242, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3037621128479933, margin=0.2562382851946287, lpl_weight=0.5678308124018494\n",
      " - ratio=0.130735459454235, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8952, LPL: 1.3863, Contrastive: 0.2499\n",
      " - Metrics: Accuracy=0.9539, F1=0.8995, Recall=0.9022, Precision=0.8968\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2288400524173242, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3037621128479933, margin=0.2562382851946287, lpl_weight=0.5678308124018494\n",
      " - ratio=0.130735459454235, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8952, LPL: 1.3863, Contrastive: 0.2499\n",
      " - Metrics: Accuracy=0.9540, F1=0.8999, Recall=0.9026, Precision=0.8972\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2288400524173242, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3037621128479933, margin=0.2562382851946287, lpl_weight=0.5678308124018494\n",
      " - ratio=0.130735459454235, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8952, LPL: 1.3863, Contrastive: 0.2499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:00:23,048] Trial 76 finished with value: 0.9004838109415705 and parameters: {'alpha': 0.2288400524173242, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3037621128479933, 'margin': 0.2562382851946287, 'lpl_weight': 0.5678308124018494, 'ratio': 0.130735459454235, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9537, F1=0.8991, Recall=0.9018, Precision=0.8965\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202015837.csv.\n",
      "Average F1 over 5 seeds: 0.9005  0.0013\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2131665443215796, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29836384845590164, margin=0.1505092056455714, lpl_weight=0.3914569859322614\n",
      " - ratio=0.11080504298680173, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7014, LPL: 1.3863, Contrastive: 0.2609\n",
      "Epoch 50, Loss: 0.6545, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.6544, LPL: 1.3863, Contrastive: 0.1835\n",
      " - Metrics: Accuracy=0.9521, F1=0.8914, Recall=0.8596, Precision=0.9256\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2131665443215796, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29836384845590164, margin=0.1505092056455714, lpl_weight=0.3914569859322614\n",
      " - ratio=0.11080504298680173, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7014, LPL: 1.3863, Contrastive: 0.2609\n",
      "Epoch 50, Loss: 0.6545, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.6559, LPL: 1.3863, Contrastive: 0.1861\n",
      " - Metrics: Accuracy=0.9565, F1=0.9015, Recall=0.8694, Precision=0.9361\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2131665443215796, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29836384845590164, margin=0.1505092056455714, lpl_weight=0.3914569859322614\n",
      " - ratio=0.11080504298680173, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7014, LPL: 1.3863, Contrastive: 0.2609\n",
      "Epoch 50, Loss: 0.6545, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.6539, LPL: 1.3863, Contrastive: 0.1827\n",
      " - Metrics: Accuracy=0.9476, F1=0.8814, Recall=0.8499, Precision=0.9152\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2131665443215796, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29836384845590164, margin=0.1505092056455714, lpl_weight=0.3914569859322614\n",
      " - ratio=0.11080504298680173, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7014, LPL: 1.3863, Contrastive: 0.2609\n",
      "Epoch 50, Loss: 0.6545, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.6543, LPL: 1.3863, Contrastive: 0.1835\n",
      " - Metrics: Accuracy=0.9514, F1=0.8899, Recall=0.8582, Precision=0.9240\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2131665443215796, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29836384845590164, margin=0.1505092056455714, lpl_weight=0.3914569859322614\n",
      " - ratio=0.11080504298680173, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7014, LPL: 1.3863, Contrastive: 0.2609\n",
      "Epoch 50, Loss: 0.6545, LPL: 1.3863, Contrastive: 0.1838\n",
      "Epoch 100, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.1833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:03:03,369] Trial 77 finished with value: 0.8903425585446099 and parameters: {'alpha': 0.2131665443215796, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.29836384845590164, 'margin': 0.1505092056455714, 'lpl_weight': 0.3914569859322614, 'ratio': 0.11080504298680173, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9503, F1=0.8876, Recall=0.8559, Precision=0.9216\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202020023.csv.\n",
      "Average F1 over 5 seeds: 0.8903  0.0065\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2258079344734938, K=35, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3205123765860619, margin=0.256656931305036, lpl_weight=0.5178744023818923\n",
      " - ratio=0.16619236697479545, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8337, LPL: 1.3863, Contrastive: 0.2401\n",
      " - Metrics: Accuracy=0.9380, F1=0.8737, Recall=0.9362, Precision=0.8191\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2258079344734938, K=35, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3205123765860619, margin=0.256656931305036, lpl_weight=0.5178744023818923\n",
      " - ratio=0.16619236697479545, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8337, LPL: 1.3863, Contrastive: 0.2401\n",
      " - Metrics: Accuracy=0.9392, F1=0.8762, Recall=0.9388, Precision=0.8214\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2258079344734938, K=35, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3205123765860619, margin=0.256656931305036, lpl_weight=0.5178744023818923\n",
      " - ratio=0.16619236697479545, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8337, LPL: 1.3863, Contrastive: 0.2401\n",
      " - Metrics: Accuracy=0.9396, F1=0.8769, Recall=0.9395, Precision=0.8220\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2258079344734938, K=35, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3205123765860619, margin=0.256656931305036, lpl_weight=0.5178744023818923\n",
      " - ratio=0.16619236697479545, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8337, LPL: 1.3863, Contrastive: 0.2401\n",
      " - Metrics: Accuracy=0.9367, F1=0.8709, Recall=0.9332, Precision=0.8165\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2258079344734938, K=35, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3205123765860619, margin=0.256656931305036, lpl_weight=0.5178744023818923\n",
      " - ratio=0.16619236697479545, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8337, LPL: 1.3863, Contrastive: 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:04:48,094] Trial 78 finished with value: 0.8747604946873369 and parameters: {'alpha': 0.2258079344734938, 'K': 35, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3205123765860619, 'margin': 0.256656931305036, 'lpl_weight': 0.5178744023818923, 'ratio': 0.16619236697479545, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9392, F1=0.8762, Recall=0.9388, Precision=0.8214\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202020303.csv.\n",
      "Average F1 over 5 seeds: 0.8748  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2842254803398601, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3780242913165631, margin=0.20241974236359017, lpl_weight=0.4653796419390174\n",
      " - ratio=0.4032845071298676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7895, LPL: 1.3863, Contrastive: 0.2700\n",
      " - Metrics: Accuracy=0.7493, F1=0.6421, Recall=0.9825, Precision=0.4769\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2842254803398601, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3780242913165631, margin=0.20241974236359017, lpl_weight=0.4653796419390174\n",
      " - ratio=0.4032845071298676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7895, LPL: 1.3863, Contrastive: 0.2700\n",
      " - Metrics: Accuracy=0.7508, F1=0.6443, Recall=0.9858, Precision=0.4785\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2842254803398601, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3780242913165631, margin=0.20241974236359017, lpl_weight=0.4653796419390174\n",
      " - ratio=0.4032845071298676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7895, LPL: 1.3863, Contrastive: 0.2700\n",
      " - Metrics: Accuracy=0.7515, F1=0.6453, Recall=0.9873, Precision=0.4793\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2842254803398601, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3780242913165631, margin=0.20241974236359017, lpl_weight=0.4653796419390174\n",
      " - ratio=0.4032845071298676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7895, LPL: 1.3863, Contrastive: 0.2700\n",
      " - Metrics: Accuracy=0.7511, F1=0.6448, Recall=0.9866, Precision=0.4789\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2842254803398601, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3780242913165631, margin=0.20241974236359017, lpl_weight=0.4653796419390174\n",
      " - ratio=0.4032845071298676, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7895, LPL: 1.3863, Contrastive: 0.2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:06:35,624] Trial 79 finished with value: 0.6444010734325445 and parameters: {'alpha': 0.2842254803398601, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3780242913165631, 'margin': 0.20241974236359017, 'lpl_weight': 0.4653796419390174, 'ratio': 0.4032845071298676, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7516, F1=0.6455, Recall=0.9877, Precision=0.4794\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202020448.csv.\n",
      "Average F1 over 5 seeds: 0.6444  0.0012\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.18856477881482003, K=35, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4593419052591663, margin=0.2441088314803271, lpl_weight=0.42412464401167826\n",
      " - ratio=0.1796249913166548, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7530, LPL: 1.3863, Contrastive: 0.2867\n",
      " - Metrics: Accuracy=0.9280, F1=0.8568, Recall=0.9403, Precision=0.7869\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.18856477881482003, K=35, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4593419052591663, margin=0.2441088314803271, lpl_weight=0.42412464401167826\n",
      " - ratio=0.1796249913166548, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7530, LPL: 1.3863, Contrastive: 0.2867\n",
      " - Metrics: Accuracy=0.9284, F1=0.8575, Recall=0.9410, Precision=0.7876\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.18856477881482003, K=35, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4593419052591663, margin=0.2441088314803271, lpl_weight=0.42412464401167826\n",
      " - ratio=0.1796249913166548, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7530, LPL: 1.3863, Contrastive: 0.2867\n",
      " - Metrics: Accuracy=0.9282, F1=0.8571, Recall=0.9406, Precision=0.7873\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.18856477881482003, K=35, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4593419052591663, margin=0.2441088314803271, lpl_weight=0.42412464401167826\n",
      " - ratio=0.1796249913166548, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7530, LPL: 1.3863, Contrastive: 0.2867\n",
      " - Metrics: Accuracy=0.9296, F1=0.8599, Recall=0.9436, Precision=0.7898\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.18856477881482003, K=35, layers=1, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.4593419052591663, margin=0.2441088314803271, lpl_weight=0.42412464401167826\n",
      " - ratio=0.1796249913166548, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7530, LPL: 1.3863, Contrastive: 0.2867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:08:22,341] Trial 80 finished with value: 0.8587755102040816 and parameters: {'alpha': 0.18856477881482003, 'K': 35, 'layers': 1, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.4593419052591663, 'margin': 0.2441088314803271, 'lpl_weight': 0.42412464401167826, 'ratio': 0.1796249913166548, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9309, F1=0.8626, Recall=0.9466, Precision=0.7923\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202020635.csv.\n",
      "Average F1 over 5 seeds: 0.8588  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3609203608142616, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29954556522435305, margin=0.1277814999822958, lpl_weight=0.576954421104853\n",
      " - ratio=0.13192092489178034, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9119, LPL: 1.3863, Contrastive: 0.2650\n",
      "Epoch 50, Loss: 0.8819, LPL: 1.3863, Contrastive: 0.1940\n",
      "Epoch 100, Loss: 0.8818, LPL: 1.3863, Contrastive: 0.1939\n",
      " - Metrics: Accuracy=0.9518, F1=0.8953, Recall=0.9000, Precision=0.8907\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3609203608142616, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29954556522435305, margin=0.1277814999822958, lpl_weight=0.576954421104853\n",
      " - ratio=0.13192092489178034, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9119, LPL: 1.3863, Contrastive: 0.2650\n",
      "Epoch 50, Loss: 0.8819, LPL: 1.3863, Contrastive: 0.1940\n",
      "Epoch 100, Loss: 0.8820, LPL: 1.3863, Contrastive: 0.1942\n",
      " - Metrics: Accuracy=0.9557, F1=0.9038, Recall=0.9085, Precision=0.8992\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3609203608142616, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29954556522435305, margin=0.1277814999822958, lpl_weight=0.576954421104853\n",
      " - ratio=0.13192092489178034, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9119, LPL: 1.3863, Contrastive: 0.2650\n",
      "Epoch 50, Loss: 0.8819, LPL: 1.3863, Contrastive: 0.1940\n",
      "Epoch 100, Loss: 0.8839, LPL: 1.3863, Contrastive: 0.1987\n",
      " - Metrics: Accuracy=0.9552, F1=0.9027, Recall=0.9074, Precision=0.8980\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3609203608142616, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29954556522435305, margin=0.1277814999822958, lpl_weight=0.576954421104853\n",
      " - ratio=0.13192092489178034, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9119, LPL: 1.3863, Contrastive: 0.2650\n",
      "Epoch 50, Loss: 0.8819, LPL: 1.3863, Contrastive: 0.1940\n",
      "Epoch 100, Loss: 0.8838, LPL: 1.3863, Contrastive: 0.1985\n",
      " - Metrics: Accuracy=0.9539, F1=0.8997, Recall=0.9044, Precision=0.8951\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3609203608142616, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29954556522435305, margin=0.1277814999822958, lpl_weight=0.576954421104853\n",
      " - ratio=0.13192092489178034, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9119, LPL: 1.3863, Contrastive: 0.2650\n",
      "Epoch 50, Loss: 0.8819, LPL: 1.3863, Contrastive: 0.1940\n",
      "Epoch 100, Loss: 0.8924, LPL: 1.3863, Contrastive: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:11:02,589] Trial 81 finished with value: 0.9005569996286669 and parameters: {'alpha': 0.3609203608142616, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.29954556522435305, 'margin': 0.1277814999822958, 'lpl_weight': 0.576954421104853, 'ratio': 0.13192092489178034, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9545, F1=0.9012, Recall=0.9059, Precision=0.8966\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202020822.csv.\n",
      "Average F1 over 5 seeds: 0.9006  0.0030\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.31060510486300885, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30471620130747734, margin=0.1397401068254001, lpl_weight=0.588966861639873\n",
      " - ratio=0.12716390164739508, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9249, LPL: 1.3863, Contrastive: 0.2638\n",
      "Epoch 50, Loss: 0.8939, LPL: 1.3863, Contrastive: 0.1883\n",
      "Epoch 100, Loss: 0.8944, LPL: 1.3863, Contrastive: 0.1896\n",
      " - Metrics: Accuracy=0.9449, F1=0.8791, Recall=0.8757, Precision=0.8826\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.31060510486300885, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30471620130747734, margin=0.1397401068254001, lpl_weight=0.588966861639873\n",
      " - ratio=0.12716390164739508, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9249, LPL: 1.3863, Contrastive: 0.2638\n",
      "Epoch 50, Loss: 0.8939, LPL: 1.3863, Contrastive: 0.1883\n",
      "Epoch 100, Loss: 0.8939, LPL: 1.3863, Contrastive: 0.1884\n",
      " - Metrics: Accuracy=0.9519, F1=0.8945, Recall=0.8910, Precision=0.8980\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.31060510486300885, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30471620130747734, margin=0.1397401068254001, lpl_weight=0.588966861639873\n",
      " - ratio=0.12716390164739508, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9249, LPL: 1.3863, Contrastive: 0.2638\n",
      "Epoch 50, Loss: 0.8939, LPL: 1.3863, Contrastive: 0.1883\n",
      "Epoch 100, Loss: 0.8940, LPL: 1.3863, Contrastive: 0.1887\n",
      " - Metrics: Accuracy=0.9519, F1=0.8945, Recall=0.8910, Precision=0.8980\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.31060510486300885, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30471620130747734, margin=0.1397401068254001, lpl_weight=0.588966861639873\n",
      " - ratio=0.12716390164739508, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9249, LPL: 1.3863, Contrastive: 0.2638\n",
      "Epoch 50, Loss: 0.8939, LPL: 1.3863, Contrastive: 0.1883\n",
      "Epoch 100, Loss: 0.8942, LPL: 1.3863, Contrastive: 0.1891\n",
      " - Metrics: Accuracy=0.9474, F1=0.8848, Recall=0.8813, Precision=0.8883\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.31060510486300885, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.30471620130747734, margin=0.1397401068254001, lpl_weight=0.588966861639873\n",
      " - ratio=0.12716390164739508, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9249, LPL: 1.3863, Contrastive: 0.2638\n",
      "Epoch 50, Loss: 0.8939, LPL: 1.3863, Contrastive: 0.1883\n",
      "Epoch 100, Loss: 0.8938, LPL: 1.3863, Contrastive: 0.1882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:13:45,368] Trial 82 finished with value: 0.8886640434701143 and parameters: {'alpha': 0.31060510486300885, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.30471620130747734, 'margin': 0.1397401068254001, 'lpl_weight': 0.588966861639873, 'ratio': 0.12716390164739508, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9500, F1=0.8904, Recall=0.8869, Precision=0.8939\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202021102.csv.\n",
      "Average F1 over 5 seeds: 0.8887  0.0060\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.30368904811217345, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3297641281320831, margin=0.19609390364857368, lpl_weight=0.3450161052329456\n",
      " - ratio=0.1256969360916397, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6488, LPL: 1.3863, Contrastive: 0.2603\n",
      " - Metrics: Accuracy=0.9561, F1=0.9034, Recall=0.8973, Precision=0.9096\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.30368904811217345, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3297641281320831, margin=0.19609390364857368, lpl_weight=0.3450161052329456\n",
      " - ratio=0.1256969360916397, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6488, LPL: 1.3863, Contrastive: 0.2603\n",
      " - Metrics: Accuracy=0.9562, F1=0.9038, Recall=0.8977, Precision=0.9100\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.30368904811217345, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3297641281320831, margin=0.19609390364857368, lpl_weight=0.3450161052329456\n",
      " - ratio=0.1256969360916397, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6488, LPL: 1.3863, Contrastive: 0.2603\n",
      " - Metrics: Accuracy=0.9539, F1=0.8985, Recall=0.8925, Precision=0.9047\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.30368904811217345, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3297641281320831, margin=0.19609390364857368, lpl_weight=0.3450161052329456\n",
      " - ratio=0.1256969360916397, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6488, LPL: 1.3863, Contrastive: 0.2603\n",
      " - Metrics: Accuracy=0.9549, F1=0.9008, Recall=0.8947, Precision=0.9069\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.30368904811217345, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3297641281320831, margin=0.19609390364857368, lpl_weight=0.3450161052329456\n",
      " - ratio=0.1256969360916397, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6488, LPL: 1.3863, Contrastive: 0.2603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:15:32,218] Trial 83 finished with value: 0.9017662532882375 and parameters: {'alpha': 0.30368904811217345, 'K': 33, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3297641281320831, 'margin': 0.19609390364857368, 'lpl_weight': 0.3450161052329456, 'ratio': 0.1256969360916397, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9556, F1=0.9023, Recall=0.8962, Precision=0.9084\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202021345.csv.\n",
      "Average F1 over 5 seeds: 0.9018  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3558806398702784, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3332302396633455, margin=0.19672854445722518, lpl_weight=0.32796887831828986\n",
      " - ratio=0.15213815432485808, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6300, LPL: 1.3863, Contrastive: 0.2610\n",
      " - Metrics: Accuracy=0.9465, F1=0.8881, Recall=0.9276, Precision=0.8519\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3558806398702784, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3332302396633455, margin=0.19672854445722518, lpl_weight=0.32796887831828986\n",
      " - ratio=0.15213815432485808, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6300, LPL: 1.3863, Contrastive: 0.2610\n",
      " - Metrics: Accuracy=0.9487, F1=0.8928, Recall=0.9324, Precision=0.8564\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3558806398702784, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3332302396633455, margin=0.19672854445722518, lpl_weight=0.32796887831828986\n",
      " - ratio=0.15213815432485808, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6300, LPL: 1.3863, Contrastive: 0.2610\n",
      " - Metrics: Accuracy=0.9484, F1=0.8921, Recall=0.9317, Precision=0.8557\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3558806398702784, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3332302396633455, margin=0.19672854445722518, lpl_weight=0.32796887831828986\n",
      " - ratio=0.15213815432485808, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6300, LPL: 1.3863, Contrastive: 0.2610\n",
      " - Metrics: Accuracy=0.9465, F1=0.8881, Recall=0.9276, Precision=0.8519\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3558806398702784, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3332302396633455, margin=0.19672854445722518, lpl_weight=0.32796887831828986\n",
      " - ratio=0.15213815432485808, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6300, LPL: 1.3863, Contrastive: 0.2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:17:17,454] Trial 84 finished with value: 0.8905646890636169 and parameters: {'alpha': 0.3558806398702784, 'K': 33, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3332302396633455, 'margin': 0.19672854445722518, 'lpl_weight': 0.32796887831828986, 'ratio': 0.15213815432485808, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9482, F1=0.8917, Recall=0.9313, Precision=0.8553\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202021532.csv.\n",
      "Average F1 over 5 seeds: 0.8906  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.23766311950343721, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2878710251805119, margin=0.12313218307440696, lpl_weight=0.6150634121089159\n",
      " - ratio=0.1342058964949578, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9543, LPL: 1.3863, Contrastive: 0.2641\n",
      " - Metrics: Accuracy=0.9535, F1=0.8994, Recall=0.9082, Precision=0.8909\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.23766311950343721, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2878710251805119, margin=0.12313218307440696, lpl_weight=0.6150634121089159\n",
      " - ratio=0.1342058964949578, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9543, LPL: 1.3863, Contrastive: 0.2641\n",
      " - Metrics: Accuracy=0.9547, F1=0.9020, Recall=0.9108, Precision=0.8934\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.23766311950343721, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2878710251805119, margin=0.12313218307440696, lpl_weight=0.6150634121089159\n",
      " - ratio=0.1342058964949578, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9543, LPL: 1.3863, Contrastive: 0.2641\n",
      " - Metrics: Accuracy=0.9544, F1=0.9013, Recall=0.9100, Precision=0.8927\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.23766311950343721, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2878710251805119, margin=0.12313218307440696, lpl_weight=0.6150634121089159\n",
      " - ratio=0.1342058964949578, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9543, LPL: 1.3863, Contrastive: 0.2641\n",
      " - Metrics: Accuracy=0.9525, F1=0.8972, Recall=0.9059, Precision=0.8887\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.23766311950343721, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2878710251805119, margin=0.12313218307440696, lpl_weight=0.6150634121089159\n",
      " - ratio=0.1342058964949578, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9543, LPL: 1.3863, Contrastive: 0.2641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:19:03,413] Trial 85 finished with value: 0.900332717190388 and parameters: {'alpha': 0.23766311950343721, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.2878710251805119, 'margin': 0.12313218307440696, 'lpl_weight': 0.6150634121089159, 'ratio': 0.1342058964949578, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9545, F1=0.9017, Recall=0.9104, Precision=0.8931\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202021717.csv.\n",
      "Average F1 over 5 seeds: 0.9003  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2670447224489501, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3108759950637202, margin=0.280118936737585, lpl_weight=0.23748951318706282\n",
      " - ratio=0.10973152161385501, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5198, LPL: 1.3863, Contrastive: 0.2499\n",
      " - Metrics: Accuracy=0.9562, F1=0.9007, Recall=0.8667, Precision=0.9374\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2670447224489501, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3108759950637202, margin=0.280118936737585, lpl_weight=0.23748951318706282\n",
      " - ratio=0.10973152161385501, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5198, LPL: 1.3863, Contrastive: 0.2499\n",
      " - Metrics: Accuracy=0.9545, F1=0.8968, Recall=0.8630, Precision=0.9334\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2670447224489501, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3108759950637202, margin=0.280118936737585, lpl_weight=0.23748951318706282\n",
      " - ratio=0.10973152161385501, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5198, LPL: 1.3863, Contrastive: 0.2499\n",
      " - Metrics: Accuracy=0.9544, F1=0.8964, Recall=0.8626, Precision=0.9330\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2670447224489501, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3108759950637202, margin=0.280118936737585, lpl_weight=0.23748951318706282\n",
      " - ratio=0.10973152161385501, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5198, LPL: 1.3863, Contrastive: 0.2499\n",
      " - Metrics: Accuracy=0.9552, F1=0.8984, Recall=0.8645, Precision=0.9350\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2670447224489501, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3108759950637202, margin=0.280118936737585, lpl_weight=0.23748951318706282\n",
      " - ratio=0.10973152161385501, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5198, LPL: 1.3863, Contrastive: 0.2499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:20:48,985] Trial 86 finished with value: 0.8975174553917766 and parameters: {'alpha': 0.2670447224489501, 'K': 33, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3108759950637202, 'margin': 0.280118936737585, 'lpl_weight': 0.23748951318706282, 'ratio': 0.10973152161385501, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9539, F1=0.8953, Recall=0.8615, Precision=0.9318\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202021903.csv.\n",
      "Average F1 over 5 seeds: 0.8975  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3902071803987793, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3279399170947383, margin=0.15771525718114504, lpl_weight=0.35235155070050556\n",
      " - ratio=0.4482807508885919, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6600, LPL: 1.3863, Contrastive: 0.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7113, F1=0.6101, Recall=0.9866, Precision=0.4416\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3902071803987793, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3279399170947383, margin=0.15771525718114504, lpl_weight=0.35235155070050556\n",
      " - ratio=0.4482807508885919, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6600, LPL: 1.3863, Contrastive: 0.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7115, F1=0.6103, Recall=0.9869, Precision=0.4418\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3902071803987793, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3279399170947383, margin=0.15771525718114504, lpl_weight=0.35235155070050556\n",
      " - ratio=0.4482807508885919, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6600, LPL: 1.3863, Contrastive: 0.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7127, F1=0.6120, Recall=0.9895, Precision=0.4429\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3902071803987793, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3279399170947383, margin=0.15771525718114504, lpl_weight=0.35235155070050556\n",
      " - ratio=0.4482807508885919, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6600, LPL: 1.3863, Contrastive: 0.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7120, F1=0.6110, Recall=0.9881, Precision=0.4423\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3902071803987793, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3279399170947383, margin=0.15771525718114504, lpl_weight=0.35235155070050556\n",
      " - ratio=0.4482807508885919, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6600, LPL: 1.3863, Contrastive: 0.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ADASYN encountered an error: ValueError('No samples will be generated with the provided ratio settings.')\n",
      "[I 2025-02-22 02:22:35,105] Trial 87 finished with value: 0.6111726685133887 and parameters: {'alpha': 0.3902071803987793, 'K': 33, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3279399170947383, 'margin': 0.15771525718114504, 'lpl_weight': 0.35235155070050556, 'ratio': 0.4482807508885919, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7130, F1=0.6124, Recall=0.9903, Precision=0.4433\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202022049.csv.\n",
      "Average F1 over 5 seeds: 0.6112  0.0009\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3399195682254165, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29310231029701056, margin=0.18650376494245402, lpl_weight=0.5747318664691266\n",
      " - ratio=0.1992230805879598, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9051, LPL: 1.3863, Contrastive: 0.2548\n",
      " - Metrics: Accuracy=0.9175, F1=0.8414, Recall=0.9552, Precision=0.7518\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3399195682254165, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29310231029701056, margin=0.18650376494245402, lpl_weight=0.5747318664691266\n",
      " - ratio=0.1992230805879598, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9051, LPL: 1.3863, Contrastive: 0.2548\n",
      " - Metrics: Accuracy=0.9180, F1=0.8423, Recall=0.9563, Precision=0.7526\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3399195682254165, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29310231029701056, margin=0.18650376494245402, lpl_weight=0.5747318664691266\n",
      " - ratio=0.1992230805879598, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9051, LPL: 1.3863, Contrastive: 0.2548\n",
      " - Metrics: Accuracy=0.9180, F1=0.8423, Recall=0.9563, Precision=0.7526\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3399195682254165, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29310231029701056, margin=0.18650376494245402, lpl_weight=0.5747318664691266\n",
      " - ratio=0.1992230805879598, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9051, LPL: 1.3863, Contrastive: 0.2548\n",
      " - Metrics: Accuracy=0.9184, F1=0.8430, Recall=0.9571, Precision=0.7532\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3399195682254165, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29310231029701056, margin=0.18650376494245402, lpl_weight=0.5747318664691266\n",
      " - ratio=0.1992230805879598, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9051, LPL: 1.3863, Contrastive: 0.2548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:24:21,484] Trial 88 finished with value: 0.8431366102252179 and parameters: {'alpha': 0.3399195682254165, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.29310231029701056, 'margin': 0.18650376494245402, 'lpl_weight': 0.5747318664691266, 'ratio': 0.1992230805879598, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9203, F1=0.8466, Recall=0.9612, Precision=0.7565\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202022235.csv.\n",
      "Average F1 over 5 seeds: 0.8431  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3122955457393229, K=34, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3608074975325208, margin=0.13887952398762687, lpl_weight=0.30570591074641323\n",
      " - ratio=0.12503018788345074, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6066, LPL: 1.3863, Contrastive: 0.2634\n",
      " - Metrics: Accuracy=0.9534, F1=0.8975, Recall=0.8903, Precision=0.9048\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3122955457393229, K=34, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3608074975325208, margin=0.13887952398762687, lpl_weight=0.30570591074641323\n",
      " - ratio=0.12503018788345074, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6067, LPL: 1.3863, Contrastive: 0.2634\n",
      " - Metrics: Accuracy=0.9538, F1=0.8982, Recall=0.8910, Precision=0.9055\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3122955457393229, K=34, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3608074975325208, margin=0.13887952398762687, lpl_weight=0.30570591074641323\n",
      " - ratio=0.12503018788345074, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6067, LPL: 1.3863, Contrastive: 0.2634\n",
      " - Metrics: Accuracy=0.9526, F1=0.8956, Recall=0.8884, Precision=0.9029\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3122955457393229, K=34, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3608074975325208, margin=0.13887952398762687, lpl_weight=0.30570591074641323\n",
      " - ratio=0.12503018788345074, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6067, LPL: 1.3863, Contrastive: 0.2634\n",
      " - Metrics: Accuracy=0.9521, F1=0.8944, Recall=0.8873, Precision=0.9017\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3122955457393229, K=34, layers=2, hidden=64, out=256\n",
      " - norm=layernorm, dropout=0.3608074975325208, margin=0.13887952398762687, lpl_weight=0.30570591074641323\n",
      " - ratio=0.12503018788345074, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6067, LPL: 1.3863, Contrastive: 0.2634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:26:03,959] Trial 89 finished with value: 0.8961806208842897 and parameters: {'alpha': 0.3122955457393229, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3608074975325208, 'margin': 0.13887952398762687, 'lpl_weight': 0.30570591074641323, 'ratio': 0.12503018788345074, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9524, F1=0.8952, Recall=0.8880, Precision=0.9025\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202022421.csv.\n",
      "Average F1 over 5 seeds: 0.8962  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2620521248364047, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31933657989112396, margin=0.24870283213938332, lpl_weight=0.6236537927562051\n",
      " - ratio=0.16399896351937737, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9600, LPL: 1.3863, Contrastive: 0.2536\n",
      " - Metrics: Accuracy=0.9397, F1=0.8767, Recall=0.9358, Precision=0.8247\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2620521248364047, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31933657989112396, margin=0.24870283213938332, lpl_weight=0.6236537927562051\n",
      " - ratio=0.16399896351937737, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9600, LPL: 1.3863, Contrastive: 0.2536\n",
      " - Metrics: Accuracy=0.9411, F1=0.8795, Recall=0.9388, Precision=0.8273\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2620521248364047, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31933657989112396, margin=0.24870283213938332, lpl_weight=0.6236537927562051\n",
      " - ratio=0.16399896351937737, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9600, LPL: 1.3863, Contrastive: 0.2536\n",
      " - Metrics: Accuracy=0.9399, F1=0.8771, Recall=0.9362, Precision=0.8250\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2620521248364047, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31933657989112396, margin=0.24870283213938332, lpl_weight=0.6236537927562051\n",
      " - ratio=0.16399896351937737, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9600, LPL: 1.3863, Contrastive: 0.2536\n",
      " - Metrics: Accuracy=0.9401, F1=0.8774, Recall=0.9365, Precision=0.8253\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2620521248364047, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.31933657989112396, margin=0.24870283213938332, lpl_weight=0.6236537927562051\n",
      " - ratio=0.16399896351937737, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9600, LPL: 1.3863, Contrastive: 0.2536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:27:49,556] Trial 90 finished with value: 0.8788949116978493 and parameters: {'alpha': 0.2620521248364047, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.31933657989112396, 'margin': 0.24870283213938332, 'lpl_weight': 0.6236537927562051, 'ratio': 0.16399896351937737, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9432, F1=0.8837, Recall=0.9433, Precision=0.8313\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202022604.csv.\n",
      "Average F1 over 5 seeds: 0.8789  0.0026\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.23787177572231955, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29025569892592934, margin=0.13500870377514376, lpl_weight=0.6356940535226474\n",
      " - ratio=0.1353059904350665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9768, LPL: 1.3863, Contrastive: 0.2623\n",
      "Epoch 50, Loss: 0.9507, LPL: 1.3863, Contrastive: 0.1907\n",
      "Epoch 100, Loss: 0.9506, LPL: 1.3863, Contrastive: 0.1903\n",
      " - Metrics: Accuracy=0.9553, F1=0.9035, Recall=0.9141, Precision=0.8931\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.23787177572231955, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29025569892592934, margin=0.13500870377514376, lpl_weight=0.6356940535226474\n",
      " - ratio=0.1353059904350665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9768, LPL: 1.3863, Contrastive: 0.2623\n",
      "Epoch 50, Loss: 0.9507, LPL: 1.3863, Contrastive: 0.1907\n",
      "Epoch 100, Loss: 0.9508, LPL: 1.3863, Contrastive: 0.1909\n",
      " - Metrics: Accuracy=0.9556, F1=0.9043, Recall=0.9149, Precision=0.8939\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.23787177572231955, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29025569892592934, margin=0.13500870377514376, lpl_weight=0.6356940535226474\n",
      " - ratio=0.1353059904350665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9768, LPL: 1.3863, Contrastive: 0.2623\n",
      "Epoch 50, Loss: 0.9507, LPL: 1.3863, Contrastive: 0.1907\n",
      "Epoch 100, Loss: 0.9509, LPL: 1.3863, Contrastive: 0.1910\n",
      " - Metrics: Accuracy=0.9533, F1=0.8991, Recall=0.9097, Precision=0.8888\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.23787177572231955, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29025569892592934, margin=0.13500870377514376, lpl_weight=0.6356940535226474\n",
      " - ratio=0.1353059904350665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9768, LPL: 1.3863, Contrastive: 0.2623\n",
      "Epoch 50, Loss: 0.9507, LPL: 1.3863, Contrastive: 0.1907\n",
      "Epoch 100, Loss: 0.9508, LPL: 1.3863, Contrastive: 0.1910\n",
      " - Metrics: Accuracy=0.9551, F1=0.9032, Recall=0.9138, Precision=0.8928\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.23787177572231955, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29025569892592934, margin=0.13500870377514376, lpl_weight=0.6356940535226474\n",
      " - ratio=0.1353059904350665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9768, LPL: 1.3863, Contrastive: 0.2623\n",
      "Epoch 50, Loss: 0.9507, LPL: 1.3863, Contrastive: 0.1907\n",
      "Epoch 100, Loss: 0.9509, LPL: 1.3863, Contrastive: 0.1912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:30:30,761] Trial 91 finished with value: 0.9027854639365429 and parameters: {'alpha': 0.23787177572231955, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.29025569892592934, 'margin': 0.13500870377514376, 'lpl_weight': 0.6356940535226474, 'ratio': 0.1353059904350665, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9555, F1=0.9039, Recall=0.9145, Precision=0.8935\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202022749.csv.\n",
      "Average F1 over 5 seeds: 0.9028  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.20448383597474906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3058538469986032, margin=0.12169077653985823, lpl_weight=0.5095099845099639\n",
      " - ratio=0.14865161457425746, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8374, LPL: 1.3863, Contrastive: 0.2671\n",
      "Epoch 50, Loss: 0.8028, LPL: 1.3863, Contrastive: 0.1967\n",
      "Epoch 100, Loss: 0.8130, LPL: 1.3863, Contrastive: 0.2174\n",
      " - Metrics: Accuracy=0.9467, F1=0.8878, Recall=0.9212, Precision=0.8566\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.20448383597474906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3058538469986032, margin=0.12169077653985823, lpl_weight=0.5095099845099639\n",
      " - ratio=0.14865161457425746, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8374, LPL: 1.3863, Contrastive: 0.2671\n",
      "Epoch 50, Loss: 0.8028, LPL: 1.3863, Contrastive: 0.1967\n",
      "Epoch 100, Loss: 0.8123, LPL: 1.3863, Contrastive: 0.2160\n",
      " - Metrics: Accuracy=0.9482, F1=0.8910, Recall=0.9246, Precision=0.8598\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.20448383597474906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3058538469986032, margin=0.12169077653985823, lpl_weight=0.5095099845099639\n",
      " - ratio=0.14865161457425746, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8374, LPL: 1.3863, Contrastive: 0.2671\n",
      "Epoch 50, Loss: 0.8028, LPL: 1.3863, Contrastive: 0.1967\n",
      "Epoch 100, Loss: 0.8120, LPL: 1.3863, Contrastive: 0.2154\n",
      " - Metrics: Accuracy=0.9474, F1=0.8892, Recall=0.9227, Precision=0.8580\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.20448383597474906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3058538469986032, margin=0.12169077653985823, lpl_weight=0.5095099845099639\n",
      " - ratio=0.14865161457425746, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8374, LPL: 1.3863, Contrastive: 0.2671\n",
      "Epoch 50, Loss: 0.8028, LPL: 1.3863, Contrastive: 0.1967\n",
      "Epoch 100, Loss: 0.8142, LPL: 1.3863, Contrastive: 0.2198\n",
      " - Metrics: Accuracy=0.9463, F1=0.8871, Recall=0.9205, Precision=0.8560\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.20448383597474906, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3058538469986032, margin=0.12169077653985823, lpl_weight=0.5095099845099639\n",
      " - ratio=0.14865161457425746, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8374, LPL: 1.3863, Contrastive: 0.2671\n",
      "Epoch 50, Loss: 0.8028, LPL: 1.3863, Contrastive: 0.1967\n",
      "Epoch 100, Loss: 0.8123, LPL: 1.3863, Contrastive: 0.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:33:11,455] Trial 92 finished with value: 0.8889928057553955 and parameters: {'alpha': 0.20448383597474906, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3058538469986032, 'margin': 0.12169077653985823, 'lpl_weight': 0.5095099845099639, 'ratio': 0.14865161457425746, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9477, F1=0.8899, Recall=0.9235, Precision=0.8587\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202023030.csv.\n",
      "Average F1 over 5 seeds: 0.8890  0.0014\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.14613114617739842, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2813295384766847, margin=0.2050325707941829, lpl_weight=0.6401346971715338\n",
      " - ratio=0.13610262058507513, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9775, LPL: 1.3863, Contrastive: 0.2504\n",
      " - Metrics: Accuracy=0.9533, F1=0.8994, Recall=0.9115, Precision=0.8877\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.14613114617739842, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2813295384766847, margin=0.2050325707941829, lpl_weight=0.6401346971715338\n",
      " - ratio=0.13610262058507513, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9775, LPL: 1.3863, Contrastive: 0.2504\n",
      " - Metrics: Accuracy=0.9533, F1=0.8994, Recall=0.9115, Precision=0.8877\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.14613114617739842, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2813295384766847, margin=0.2050325707941829, lpl_weight=0.6401346971715338\n",
      " - ratio=0.13610262058507513, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9775, LPL: 1.3863, Contrastive: 0.2504\n",
      " - Metrics: Accuracy=0.9530, F1=0.8987, Recall=0.9108, Precision=0.8870\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.14613114617739842, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2813295384766847, margin=0.2050325707941829, lpl_weight=0.6401346971715338\n",
      " - ratio=0.13610262058507513, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9775, LPL: 1.3863, Contrastive: 0.2504\n",
      " - Metrics: Accuracy=0.9523, F1=0.8972, Recall=0.9093, Precision=0.8855\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.14613114617739842, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2813295384766847, margin=0.2050325707941829, lpl_weight=0.6401346971715338\n",
      " - ratio=0.13610262058507513, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9775, LPL: 1.3863, Contrastive: 0.2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:34:57,269] Trial 93 finished with value: 0.8987108655616943 and parameters: {'alpha': 0.14613114617739842, 'K': 33, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.2813295384766847, 'margin': 0.2050325707941829, 'lpl_weight': 0.6401346971715338, 'ratio': 0.13610262058507513, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9530, F1=0.8987, Recall=0.9108, Precision=0.8870\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202023311.csv.\n",
      "Average F1 over 5 seeds: 0.8987  0.0008\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.34093616919348996, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2662337722183412, margin=0.15879591001492416, lpl_weight=0.3803898083252837\n",
      " - ratio=0.10884213074651225, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6849, LPL: 1.3863, Contrastive: 0.2542\n",
      "Epoch 50, Loss: 0.6390, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 100, Loss: 0.6382, LPL: 1.3863, Contrastive: 0.1789\n",
      " - Metrics: Accuracy=0.9562, F1=0.9003, Recall=0.8649, Precision=0.9388\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.34093616919348996, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2662337722183412, margin=0.15879591001492416, lpl_weight=0.3803898083252837\n",
      " - ratio=0.10884213074651225, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6849, LPL: 1.3863, Contrastive: 0.2542\n",
      "Epoch 50, Loss: 0.6390, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 100, Loss: 0.6382, LPL: 1.3863, Contrastive: 0.1790\n",
      " - Metrics: Accuracy=0.9568, F1=0.9019, Recall=0.8664, Precision=0.9404\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.34093616919348996, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2662337722183412, margin=0.15879591001492416, lpl_weight=0.3803898083252837\n",
      " - ratio=0.10884213074651225, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6849, LPL: 1.3863, Contrastive: 0.2542\n",
      "Epoch 50, Loss: 0.6390, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 100, Loss: 0.6382, LPL: 1.3863, Contrastive: 0.1789\n",
      " - Metrics: Accuracy=0.9541, F1=0.8957, Recall=0.8604, Precision=0.9340\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.34093616919348996, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2662337722183412, margin=0.15879591001492416, lpl_weight=0.3803898083252837\n",
      " - ratio=0.10884213074651225, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6849, LPL: 1.3863, Contrastive: 0.2542\n",
      "Epoch 50, Loss: 0.6390, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 100, Loss: 0.6382, LPL: 1.3863, Contrastive: 0.1790\n",
      " - Metrics: Accuracy=0.9534, F1=0.8941, Recall=0.8589, Precision=0.9323\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.34093616919348996, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.2662337722183412, margin=0.15879591001492416, lpl_weight=0.3803898083252837\n",
      " - ratio=0.10884213074651225, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6849, LPL: 1.3863, Contrastive: 0.2542\n",
      "Epoch 50, Loss: 0.6390, LPL: 1.3863, Contrastive: 0.1803\n",
      "Epoch 100, Loss: 0.6382, LPL: 1.3863, Contrastive: 0.1789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:37:37,485] Trial 94 finished with value: 0.8984651253157179 and parameters: {'alpha': 0.34093616919348996, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.2662337722183412, 'margin': 0.15879591001492416, 'lpl_weight': 0.3803898083252837, 'ratio': 0.10884213074651225, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9562, F1=0.9003, Recall=0.8649, Precision=0.9388\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202023457.csv.\n",
      "Average F1 over 5 seeds: 0.8985  0.0030\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.22474857237559595, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3358502827822042, margin=0.10795275148265351, lpl_weight=0.41164940765895797\n",
      " - ratio=0.12487949963976347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7323, LPL: 1.3863, Contrastive: 0.2747\n",
      "Epoch 50, Loss: 0.6899, LPL: 1.3863, Contrastive: 0.2027\n",
      "Epoch 100, Loss: 0.6892, LPL: 1.3863, Contrastive: 0.2015\n",
      " - Metrics: Accuracy=0.9562, F1=0.9034, Recall=0.8959, Precision=0.9112\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.22474857237559595, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3358502827822042, margin=0.10795275148265351, lpl_weight=0.41164940765895797\n",
      " - ratio=0.12487949963976347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7323, LPL: 1.3863, Contrastive: 0.2747\n",
      "Epoch 50, Loss: 0.6899, LPL: 1.3863, Contrastive: 0.2027\n",
      "Epoch 100, Loss: 0.6892, LPL: 1.3863, Contrastive: 0.2015\n",
      " - Metrics: Accuracy=0.9515, F1=0.8933, Recall=0.8858, Precision=0.9009\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.22474857237559595, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3358502827822042, margin=0.10795275148265351, lpl_weight=0.41164940765895797\n",
      " - ratio=0.12487949963976347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7323, LPL: 1.3863, Contrastive: 0.2747\n",
      "Epoch 50, Loss: 0.6899, LPL: 1.3863, Contrastive: 0.2027\n",
      "Epoch 100, Loss: 0.6896, LPL: 1.3863, Contrastive: 0.2022\n",
      " - Metrics: Accuracy=0.9444, F1=0.8775, Recall=0.8701, Precision=0.8850\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.22474857237559595, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3358502827822042, margin=0.10795275148265351, lpl_weight=0.41164940765895797\n",
      " - ratio=0.12487949963976347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7323, LPL: 1.3863, Contrastive: 0.2747\n",
      "Epoch 50, Loss: 0.6899, LPL: 1.3863, Contrastive: 0.2027\n",
      "Epoch 100, Loss: 0.6894, LPL: 1.3863, Contrastive: 0.2019\n",
      " - Metrics: Accuracy=0.9517, F1=0.8937, Recall=0.8862, Precision=0.9013\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.22474857237559595, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3358502827822042, margin=0.10795275148265351, lpl_weight=0.41164940765895797\n",
      " - ratio=0.12487949963976347, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7323, LPL: 1.3863, Contrastive: 0.2747\n",
      "Epoch 50, Loss: 0.6899, LPL: 1.3863, Contrastive: 0.2027\n",
      "Epoch 100, Loss: 0.6892, LPL: 1.3863, Contrastive: 0.2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:40:18,032] Trial 95 finished with value: 0.8908714473931866 and parameters: {'alpha': 0.22474857237559595, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3358502827822042, 'margin': 0.10795275148265351, 'lpl_weight': 0.41164940765895797, 'ratio': 0.12487949963976347, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9485, F1=0.8865, Recall=0.8791, Precision=0.8941\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202023737.csv.\n",
      "Average F1 over 5 seeds: 0.8909  0.0086\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.20042711330357948, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3517004722539851, margin=0.1423634439213108, lpl_weight=0.3432065702066566\n",
      " - ratio=0.14381969572167977, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.2717\n",
      " - Metrics: Accuracy=0.9505, F1=0.8949, Recall=0.9201, Precision=0.8710\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.20042711330357948, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3517004722539851, margin=0.1423634439213108, lpl_weight=0.3432065702066566\n",
      " - ratio=0.14381969572167977, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.2717\n",
      " - Metrics: Accuracy=0.9500, F1=0.8938, Recall=0.9190, Precision=0.8700\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.20042711330357948, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3517004722539851, margin=0.1423634439213108, lpl_weight=0.3432065702066566\n",
      " - ratio=0.14381969572167977, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.2717\n",
      " - Metrics: Accuracy=0.9515, F1=0.8971, Recall=0.9224, Precision=0.8731\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.20042711330357948, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3517004722539851, margin=0.1423634439213108, lpl_weight=0.3432065702066566\n",
      " - ratio=0.14381969572167977, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.2717\n",
      " - Metrics: Accuracy=0.9498, F1=0.8934, Recall=0.9186, Precision=0.8696\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.20042711330357948, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3517004722539851, margin=0.1423634439213108, lpl_weight=0.3432065702066566\n",
      " - ratio=0.14381969572167977, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6542, LPL: 1.3863, Contrastive: 0.2717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:42:09,805] Trial 96 finished with value: 0.8951896895988384 and parameters: {'alpha': 0.20042711330357948, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3517004722539851, 'margin': 0.1423634439213108, 'lpl_weight': 0.3432065702066566, 'ratio': 0.14381969572167977, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9514, F1=0.8967, Recall=0.9220, Precision=0.8728\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202024018.csv.\n",
      "Average F1 over 5 seeds: 0.8952  0.0015\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.30726146561326717, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3158219983276883, margin=0.1827710402001645, lpl_weight=0.6906818931305019\n",
      " - ratio=0.11010836995287482, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0377, LPL: 1.3863, Contrastive: 0.2593\n",
      " - Metrics: Accuracy=0.9545, F1=0.8969, Recall=0.8638, Precision=0.9327\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.30726146561326717, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3158219983276883, margin=0.1827710402001645, lpl_weight=0.6906818931305019\n",
      " - ratio=0.11010836995287482, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0377, LPL: 1.3863, Contrastive: 0.2593\n",
      " - Metrics: Accuracy=0.9559, F1=0.9000, Recall=0.8667, Precision=0.9359\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.30726146561326717, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3158219983276883, margin=0.1827710402001645, lpl_weight=0.6906818931305019\n",
      " - ratio=0.11010836995287482, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0377, LPL: 1.3863, Contrastive: 0.2593\n",
      " - Metrics: Accuracy=0.9556, F1=0.8992, Recall=0.8660, Precision=0.9351\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.30726146561326717, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3158219983276883, margin=0.1827710402001645, lpl_weight=0.6906818931305019\n",
      " - ratio=0.11010836995287482, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0377, LPL: 1.3863, Contrastive: 0.2593\n",
      " - Metrics: Accuracy=0.9542, F1=0.8961, Recall=0.8630, Precision=0.9319\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.30726146561326717, K=33, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3158219983276883, margin=0.1827710402001645, lpl_weight=0.6906818931305019\n",
      " - ratio=0.11010836995287482, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0377, LPL: 1.3863, Contrastive: 0.2593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:43:55,852] Trial 97 finished with value: 0.897829457364341 and parameters: {'alpha': 0.30726146561326717, 'K': 33, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3158219983276883, 'margin': 0.1827710402001645, 'lpl_weight': 0.6906818931305019, 'ratio': 0.11010836995287482, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9545, F1=0.8969, Recall=0.8638, Precision=0.9327\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202024209.csv.\n",
      "Average F1 over 5 seeds: 0.8978  0.0015\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3890407667243634, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3684329397541969, margin=0.28213984967210753, lpl_weight=0.5692192747618261\n",
      " - ratio=0.17160513007470618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9023, LPL: 1.3863, Contrastive: 0.2627\n",
      " - Metrics: Accuracy=0.9346, F1=0.8680, Recall=0.9392, Precision=0.8069\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3890407667243634, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3684329397541969, margin=0.28213984967210753, lpl_weight=0.5692192747618261\n",
      " - ratio=0.17160513007470618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9023, LPL: 1.3863, Contrastive: 0.2627\n",
      " - Metrics: Accuracy=0.9345, F1=0.8677, Recall=0.9388, Precision=0.8066\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3890407667243634, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3684329397541969, margin=0.28213984967210753, lpl_weight=0.5692192747618261\n",
      " - ratio=0.17160513007470618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9023, LPL: 1.3863, Contrastive: 0.2627\n",
      " - Metrics: Accuracy=0.9346, F1=0.8680, Recall=0.9392, Precision=0.8069\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3890407667243634, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3684329397541969, margin=0.28213984967210753, lpl_weight=0.5692192747618261\n",
      " - ratio=0.17160513007470618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9023, LPL: 1.3863, Contrastive: 0.2627\n",
      " - Metrics: Accuracy=0.9351, F1=0.8691, Recall=0.9403, Precision=0.8079\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3890407667243634, K=34, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.3684329397541969, margin=0.28213984967210753, lpl_weight=0.5692192747618261\n",
      " - ratio=0.17160513007470618, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9023, LPL: 1.3863, Contrastive: 0.2627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:45:43,053] Trial 98 finished with value: 0.8690012075211317 and parameters: {'alpha': 0.3890407667243634, 'K': 34, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.3684329397541969, 'margin': 0.28213984967210753, 'lpl_weight': 0.5692192747618261, 'ratio': 0.17160513007470618, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9367, F1=0.8722, Recall=0.9436, Precision=0.8108\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202024355.csv.\n",
      "Average F1 over 5 seeds: 0.8690  0.0017\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2674220264381494, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29383389263041026, margin=0.3220483530925544, lpl_weight=0.24958944411343165\n",
      " - ratio=0.1328521041800462, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5294, LPL: 1.3863, Contrastive: 0.2444\n",
      " - Metrics: Accuracy=0.9525, F1=0.8970, Recall=0.9033, Precision=0.8907\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2674220264381494, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29383389263041026, margin=0.3220483530925544, lpl_weight=0.24958944411343165\n",
      " - ratio=0.1328521041800462, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5294, LPL: 1.3863, Contrastive: 0.2444\n",
      " - Metrics: Accuracy=0.9530, F1=0.8981, Recall=0.9044, Precision=0.8918\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2674220264381494, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29383389263041026, margin=0.3220483530925544, lpl_weight=0.24958944411343165\n",
      " - ratio=0.1328521041800462, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5294, LPL: 1.3863, Contrastive: 0.2444\n",
      " - Metrics: Accuracy=0.9516, F1=0.8951, Recall=0.9015, Precision=0.8888\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2674220264381494, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29383389263041026, margin=0.3220483530925544, lpl_weight=0.24958944411343165\n",
      " - ratio=0.1328521041800462, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5294, LPL: 1.3863, Contrastive: 0.2444\n",
      " - Metrics: Accuracy=0.9521, F1=0.8962, Recall=0.9026, Precision=0.8900\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2674220264381494, K=35, layers=2, hidden=256, out=256\n",
      " - norm=layernorm, dropout=0.29383389263041026, margin=0.3220483530925544, lpl_weight=0.24958944411343165\n",
      " - ratio=0.1328521041800462, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.5294, LPL: 1.3863, Contrastive: 0.2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:47:28,648] Trial 99 finished with value: 0.8966641957005189 and parameters: {'alpha': 0.2674220264381494, 'K': 35, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'layernorm', 'dropout': 0.29383389263041026, 'margin': 0.3220483530925544, 'lpl_weight': 0.24958944411343165, 'ratio': 0.1328521041800462, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 65 with value: 0.9032380231016853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9525, F1=0.8970, Recall=0.9033, Precision=0.8907\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202024543.csv.\n",
      "Average F1 over 5 seeds: 0.8967  0.0010\n",
      "Best trial:\n",
      "  Average F1: 0.9032380231016853\n",
      "  Best parameters:\n",
      "    alpha: 0.24420575134921743\n",
      "    K: 35\n",
      "    layers: 2\n",
      "    hidden_channels: 256\n",
      "    out_channels: 256\n",
      "    norm: layernorm\n",
      "    dropout: 0.3599991944711314\n",
      "    margin: 0.103458174066901\n",
      "    lpl_weight: 0.3376161192895486\n",
      "    ratio: 0.12172103712818252\n",
      "    aggregation: mean\n",
      "    treatment: relabeling\n"
     ]
    }
   ],
   "source": [
    "from train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"wiki-cs\",      \n",
    "        \"mechanism\": \"SCAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": 1,#trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"wikics_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization WikiCS\n",
    "#### SAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:47:28,675] A new study created in memory with name: no-name-f19039dc-b2d8-4648-8747-7fb17d61d8be\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.3550773461077843, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.17407591637864495, margin=0.8374569479625883, lpl_weight=0.8173330453434202\n",
      " - ratio=0.3813444753483398, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8799, F1=0.7801, Recall=0.9302, Precision=0.6717\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3550773461077843, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.17407591637864495, margin=0.8374569479625883, lpl_weight=0.8173330453434202\n",
      " - ratio=0.3813444753483398, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8814, F1=0.7820, Recall=0.9295, Precision=0.6750\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3550773461077843, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.17407591637864495, margin=0.8374569479625883, lpl_weight=0.8173330453434202\n",
      " - ratio=0.3813444753483398, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8653, F1=0.7592, Recall=0.9272, Precision=0.6427\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3550773461077843, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.17407591637864495, margin=0.8374569479625883, lpl_weight=0.8173330453434202\n",
      " - ratio=0.3813444753483398, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8811, F1=0.7815, Recall=0.9287, Precision=0.6746\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3550773461077843, K=28, layers=2, hidden=256, out=128\n",
      " - norm=layernorm, dropout=0.17407591637864495, margin=0.8374569479625883, lpl_weight=0.8173330453434202\n",
      " - ratio=0.3813444753483398, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:52:07,574] Trial 0 finished with value: 0.7742154815877793 and parameters: {'alpha': 0.3550773461077843, 'K': 28, 'layers': 2, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.17407591637864495, 'margin': 0.8374569479625883, 'lpl_weight': 0.8173330453434202, 'ratio': 0.3813444753483398, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 0 with value: 0.7742154815877793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8722, F1=0.7683, Recall=0.9250, Precision=0.6569\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202024728.csv.\n",
      "Average F1 over 5 seeds: 0.7742  0.0091\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.1468476903620278, K=30, layers=3, hidden=256, out=256\n",
      " - norm=None, dropout=0.2604250215724403, margin=0.6300817434970215, lpl_weight=0.9842938185771135\n",
      " - ratio=0.21732563206062605, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9248, F1=0.8431, Recall=0.8824, Precision=0.8071\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.1468476903620278, K=30, layers=3, hidden=256, out=256\n",
      " - norm=None, dropout=0.2604250215724403, margin=0.6300817434970215, lpl_weight=0.9842938185771135\n",
      " - ratio=0.21732563206062605, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9250, F1=0.8442, Recall=0.8876, Precision=0.8047\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.1468476903620278, K=30, layers=3, hidden=256, out=256\n",
      " - norm=None, dropout=0.2604250215724403, margin=0.6300817434970215, lpl_weight=0.9842938185771135\n",
      " - ratio=0.21732563206062605, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9218, F1=0.8372, Recall=0.8783, Precision=0.7998\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.1468476903620278, K=30, layers=3, hidden=256, out=256\n",
      " - norm=None, dropout=0.2604250215724403, margin=0.6300817434970215, lpl_weight=0.9842938185771135\n",
      " - ratio=0.21732563206062605, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9180, F1=0.8304, Recall=0.8761, Precision=0.7892\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.1468476903620278, K=30, layers=3, hidden=256, out=256\n",
      " - norm=None, dropout=0.2604250215724403, margin=0.6300817434970215, lpl_weight=0.9842938185771135\n",
      " - ratio=0.21732563206062605, pos_weight=1, aggregation=sum, treatment=removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 02:59:19,505] Trial 1 finished with value: 0.8373743794722011 and parameters: {'alpha': 0.1468476903620278, 'K': 30, 'layers': 3, 'hidden_channels': 256, 'out_channels': 256, 'norm': None, 'dropout': 0.2604250215724403, 'margin': 0.6300817434970215, 'lpl_weight': 0.9842938185771135, 'ratio': 0.21732563206062605, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 1 with value: 0.8373743794722011.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9194, F1=0.8321, Recall=0.8720, Precision=0.7956\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202025207.csv.\n",
      "Average F1 over 5 seeds: 0.8374  0.0056\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7164528196997917, K=26, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24589508104809144, margin=0.23516822645506263, lpl_weight=0.8015410071733854\n",
      " - ratio=0.345024808906908, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1484, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 1.1410, LPL: 1.3863, Contrastive: 0.1504\n",
      "Epoch 100, Loss: 1.1409, LPL: 1.3863, Contrastive: 0.1496\n",
      "Epoch 150, Loss: 1.1407, LPL: 1.3863, Contrastive: 0.1489\n",
      "Epoch 200, Loss: 1.1405, LPL: 1.3863, Contrastive: 0.1480\n",
      "Epoch 250, Loss: 1.1405, LPL: 1.3863, Contrastive: 0.1479\n",
      "Epoch 300, Loss: 1.1405, LPL: 1.3863, Contrastive: 0.1478\n",
      "Epoch 350, Loss: 1.1405, LPL: 1.3863, Contrastive: 0.1478\n",
      " - Metrics: Accuracy=0.9365, F1=0.8735, Recall=0.9578, Precision=0.8029\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7164528196997917, K=26, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24589508104809144, margin=0.23516822645506263, lpl_weight=0.8015410071733854\n",
      " - ratio=0.345024808906908, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1484, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 1.1410, LPL: 1.3863, Contrastive: 0.1504\n",
      "Epoch 100, Loss: 1.1409, LPL: 1.3863, Contrastive: 0.1500\n",
      "Epoch 150, Loss: 1.1406, LPL: 1.3863, Contrastive: 0.1485\n",
      "Epoch 200, Loss: 1.1406, LPL: 1.3863, Contrastive: 0.1481\n",
      "Epoch 250, Loss: 1.1405, LPL: 1.3863, Contrastive: 0.1479\n",
      "Epoch 300, Loss: 1.1405, LPL: 1.3863, Contrastive: 0.1478\n",
      " - Metrics: Accuracy=0.9435, F1=0.8854, Recall=0.9530, Precision=0.8267\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7164528196997917, K=26, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24589508104809144, margin=0.23516822645506263, lpl_weight=0.8015410071733854\n",
      " - ratio=0.345024808906908, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1484, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 1.1410, LPL: 1.3863, Contrastive: 0.1504\n",
      " - Metrics: Accuracy=0.9380, F1=0.8761, Recall=0.9582, Precision=0.8070\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7164528196997917, K=26, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24589508104809144, margin=0.23516822645506263, lpl_weight=0.8015410071733854\n",
      " - ratio=0.345024808906908, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1484, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 1.1410, LPL: 1.3863, Contrastive: 0.1504\n",
      "Epoch 100, Loss: 1.1410, LPL: 1.3863, Contrastive: 0.1505\n",
      " - Metrics: Accuracy=0.9406, F1=0.8803, Recall=0.9541, Precision=0.8171\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7164528196997917, K=26, layers=3, hidden=256, out=128\n",
      " - norm=graphnorm, dropout=0.24589508104809144, margin=0.23516822645506263, lpl_weight=0.8015410071733854\n",
      " - ratio=0.345024808906908, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 1.1484, LPL: 1.3863, Contrastive: 0.1875\n",
      "Epoch 50, Loss: 1.1410, LPL: 1.3863, Contrastive: 0.1504\n",
      "Epoch 100, Loss: 1.1408, LPL: 1.3863, Contrastive: 0.1493\n",
      "Epoch 150, Loss: 1.1406, LPL: 1.3863, Contrastive: 0.1482\n",
      "Epoch 200, Loss: 1.1406, LPL: 1.3863, Contrastive: 0.1482\n",
      "Epoch 250, Loss: 1.1405, LPL: 1.3863, Contrastive: 0.1479\n",
      "Epoch 300, Loss: 1.1405, LPL: 1.3863, Contrastive: 0.1478\n",
      "Epoch 350, Loss: 1.1405, LPL: 1.3863, Contrastive: 0.1478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:03:55,828] Trial 2 finished with value: 0.8786677931826496 and parameters: {'alpha': 0.7164528196997917, 'K': 26, 'layers': 3, 'hidden_channels': 256, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.24589508104809144, 'margin': 0.23516822645506263, 'lpl_weight': 0.8015410071733854, 'ratio': 0.345024808906908, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 2 with value: 0.8786677931826496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9392, F1=0.8780, Recall=0.9563, Precision=0.8115\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202025919.csv.\n",
      "Average F1 over 5 seeds: 0.8787  0.0040\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.21412920452847894, K=33, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.3691499637281893, margin=0.5766567041941985, lpl_weight=0.21510877297185393\n",
      " - ratio=0.21470880369483636, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4540, LPL: 1.3863, Contrastive: 0.1985\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9258, F1=0.8430, Recall=0.8701, Precision=0.8176\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.21412920452847894, K=33, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.3691499637281893, margin=0.5766567041941985, lpl_weight=0.21510877297185393\n",
      " - ratio=0.21470880369483636, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4540, LPL: 1.3863, Contrastive: 0.1985\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9243, F1=0.8403, Recall=0.8701, Precision=0.8125\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.21412920452847894, K=33, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.3691499637281893, margin=0.5766567041941985, lpl_weight=0.21510877297185393\n",
      " - ratio=0.21470880369483636, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4540, LPL: 1.3863, Contrastive: 0.1985\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9211, F1=0.8353, Recall=0.8738, Precision=0.8001\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.21412920452847894, K=33, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.3691499637281893, margin=0.5766567041941985, lpl_weight=0.21510877297185393\n",
      " - ratio=0.21470880369483636, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4540, LPL: 1.3863, Contrastive: 0.1985\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9279, F1=0.8473, Recall=0.8742, Precision=0.8220\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.21412920452847894, K=33, layers=1, hidden=64, out=64\n",
      " - norm=None, dropout=0.3691499637281893, margin=0.5766567041941985, lpl_weight=0.21510877297185393\n",
      " - ratio=0.21470880369483636, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.4540, LPL: 1.3863, Contrastive: 0.1985\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:07:44,568] Trial 3 finished with value: 0.8397631714127162 and parameters: {'alpha': 0.21412920452847894, 'K': 33, 'layers': 1, 'hidden_channels': 64, 'out_channels': 64, 'norm': None, 'dropout': 0.3691499637281893, 'margin': 0.5766567041941985, 'lpl_weight': 0.21510877297185393, 'ratio': 0.21470880369483636, 'aggregation': 'sum', 'treatment': 'removal'}. Best is trial 2 with value: 0.8786677931826496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9201, F1=0.8328, Recall=0.8694, Precision=0.7992\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202030355.csv.\n",
      "Average F1 over 5 seeds: 0.8398  0.0052\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6451778772871141, K=32, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24667633811668757, margin=0.8245674320086332, lpl_weight=0.9251376501654867\n",
      " - ratio=0.49803625503504956, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2918, LPL: 1.3863, Contrastive: 0.1245\n",
      " - Metrics: Accuracy=0.6632, F1=0.5704, Recall=0.9765, Precision=0.4028\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6451778772871141, K=32, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24667633811668757, margin=0.8245674320086332, lpl_weight=0.9251376501654867\n",
      " - ratio=0.49803625503504956, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2918, LPL: 1.3863, Contrastive: 0.1244\n",
      " - Metrics: Accuracy=0.6644, F1=0.5718, Recall=0.9787, Precision=0.4039\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.6451778772871141, K=32, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24667633811668757, margin=0.8245674320086332, lpl_weight=0.9251376501654867\n",
      " - ratio=0.49803625503504956, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2918, LPL: 1.3863, Contrastive: 0.1244\n",
      " - Metrics: Accuracy=0.6652, F1=0.5729, Recall=0.9806, Precision=0.4047\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6451778772871141, K=32, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24667633811668757, margin=0.8245674320086332, lpl_weight=0.9251376501654867\n",
      " - ratio=0.49803625503504956, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2918, LPL: 1.3863, Contrastive: 0.1245\n",
      " - Metrics: Accuracy=0.6641, F1=0.5713, Recall=0.9776, Precision=0.4036\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6451778772871141, K=32, layers=3, hidden=64, out=128\n",
      " - norm=graphnorm, dropout=0.24667633811668757, margin=0.8245674320086332, lpl_weight=0.9251376501654867\n",
      " - ratio=0.49803625503504956, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2918, LPL: 1.3863, Contrastive: 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:09:14,933] Trial 4 finished with value: 0.5714411003131501 and parameters: {'alpha': 0.6451778772871141, 'K': 32, 'layers': 3, 'hidden_channels': 64, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.24667633811668757, 'margin': 0.8245674320086332, 'lpl_weight': 0.9251376501654867, 'ratio': 0.49803625503504956, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 2 with value: 0.8786677931826496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.6635, F1=0.5708, Recall=0.9772, Precision=0.4031\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202030744.csv.\n",
      "Average F1 over 5 seeds: 0.5714  0.0009\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.7951892960054192, K=28, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.30941143645876645, margin=0.6553717394505225, lpl_weight=0.5073836592848766\n",
      " - ratio=0.2907919647306121, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8401, LPL: 1.3863, Contrastive: 0.2775\n",
      " - Metrics: Accuracy=0.9157, F1=0.8390, Recall=0.9589, Precision=0.7457\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.7951892960054192, K=28, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.30941143645876645, margin=0.6553717394505225, lpl_weight=0.5073836592848766\n",
      " - ratio=0.2907919647306121, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8401, LPL: 1.3863, Contrastive: 0.2775\n",
      " - Metrics: Accuracy=0.9164, F1=0.8389, Recall=0.9504, Precision=0.7508\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.7951892960054192, K=28, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.30941143645876645, margin=0.6553717394505225, lpl_weight=0.5073836592848766\n",
      " - ratio=0.2907919647306121, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8401, LPL: 1.3863, Contrastive: 0.2775\n",
      " - Metrics: Accuracy=0.9133, F1=0.8346, Recall=0.9548, Precision=0.7412\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.7951892960054192, K=28, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.30941143645876645, margin=0.6553717394505225, lpl_weight=0.5073836592848766\n",
      " - ratio=0.2907919647306121, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8401, LPL: 1.3863, Contrastive: 0.2775\n",
      " - Metrics: Accuracy=0.9176, F1=0.8412, Recall=0.9533, Precision=0.7527\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.7951892960054192, K=28, layers=2, hidden=128, out=128\n",
      " - norm=layernorm, dropout=0.30941143645876645, margin=0.6553717394505225, lpl_weight=0.5073836592848766\n",
      " - ratio=0.2907919647306121, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.8401, LPL: 1.3863, Contrastive: 0.2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:10:39,764] Trial 5 finished with value: 0.8385406169867469 and parameters: {'alpha': 0.7951892960054192, 'K': 28, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'layernorm', 'dropout': 0.30941143645876645, 'margin': 0.6553717394505225, 'lpl_weight': 0.5073836592848766, 'ratio': 0.2907919647306121, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 2 with value: 0.8786677931826496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9163, F1=0.8390, Recall=0.9522, Precision=0.7499\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202030914.csv.\n",
      "Average F1 over 5 seeds: 0.8385  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.8202753198010627, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.42384412653168446, margin=0.6556346955744689, lpl_weight=0.490861511542783\n",
      " - ratio=0.4138667892697069, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.7183, F1=0.6032, Recall=0.9351, Precision=0.4452\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.8202753198010627, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.42384412653168446, margin=0.6556346955744689, lpl_weight=0.490861511542783\n",
      " - ratio=0.4138667892697069, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.7204, F1=0.6061, Recall=0.9395, Precision=0.4473\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.8202753198010627, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.42384412653168446, margin=0.6556346955744689, lpl_weight=0.490861511542783\n",
      " - ratio=0.4138667892697069, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.7198, F1=0.6053, Recall=0.9384, Precision=0.4467\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.8202753198010627, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.42384412653168446, margin=0.6556346955744689, lpl_weight=0.490861511542783\n",
      " - ratio=0.4138667892697069, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.7199, F1=0.6053, Recall=0.9384, Precision=0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=5:\n",
      " - alpha=0.8202753198010627, K=35, layers=2, hidden=128, out=128\n",
      " - norm=graphnorm, dropout=0.42384412653168446, margin=0.6556346955744689, lpl_weight=0.490861511542783\n",
      " - ratio=0.4138667892697069, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:15:01,869] Trial 6 finished with value: 0.6041270100490823 and parameters: {'alpha': 0.8202753198010627, 'K': 35, 'layers': 2, 'hidden_channels': 128, 'out_channels': 128, 'norm': 'graphnorm', 'dropout': 0.42384412653168446, 'margin': 0.6556346955744689, 'lpl_weight': 0.490861511542783, 'ratio': 0.4138667892697069, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 2 with value: 0.8786677931826496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.7166, F1=0.6008, Recall=0.9313, Precision=0.4434\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202031039.csv.\n",
      "Average F1 over 5 seeds: 0.6041  0.0019\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2798721414675672, K=35, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.11434331893297506, margin=0.2944731714250123, lpl_weight=0.7771278701081328\n",
      " - ratio=0.3084095063121354, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1080, LPL: 1.3863, Contrastive: 0.1374\n",
      "Epoch 50, Loss: 1.1059, LPL: 1.3863, Contrastive: 0.1280\n",
      "Epoch 100, Loss: 1.1064, LPL: 1.3863, Contrastive: 0.1305\n",
      " - Metrics: Accuracy=0.8235, F1=0.7138, Recall=0.9612, Precision=0.5677\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2798721414675672, K=35, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.11434331893297506, margin=0.2944731714250123, lpl_weight=0.7771278701081328\n",
      " - ratio=0.3084095063121354, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1080, LPL: 1.3863, Contrastive: 0.1374\n",
      "Epoch 50, Loss: 1.1059, LPL: 1.3863, Contrastive: 0.1280\n",
      "Epoch 100, Loss: 1.1067, LPL: 1.3863, Contrastive: 0.1319\n",
      " - Metrics: Accuracy=0.8233, F1=0.7134, Recall=0.9608, Precision=0.5673\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2798721414675672, K=35, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.11434331893297506, margin=0.2944731714250123, lpl_weight=0.7771278701081328\n",
      " - ratio=0.3084095063121354, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1080, LPL: 1.3863, Contrastive: 0.1374\n",
      "Epoch 50, Loss: 1.1059, LPL: 1.3863, Contrastive: 0.1280\n",
      "Epoch 100, Loss: 1.1067, LPL: 1.3863, Contrastive: 0.1319\n",
      " - Metrics: Accuracy=0.8269, F1=0.7195, Recall=0.9694, Precision=0.5720\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2798721414675672, K=35, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.11434331893297506, margin=0.2944731714250123, lpl_weight=0.7771278701081328\n",
      " - ratio=0.3084095063121354, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1080, LPL: 1.3863, Contrastive: 0.1374\n",
      "Epoch 50, Loss: 1.1059, LPL: 1.3863, Contrastive: 0.1280\n",
      "Epoch 100, Loss: 1.1060, LPL: 1.3863, Contrastive: 0.1286\n",
      " - Metrics: Accuracy=0.8295, F1=0.7235, Recall=0.9742, Precision=0.5754\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2798721414675672, K=35, layers=3, hidden=128, out=64\n",
      " - norm=layernorm, dropout=0.11434331893297506, margin=0.2944731714250123, lpl_weight=0.7771278701081328\n",
      " - ratio=0.3084095063121354, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.1080, LPL: 1.3863, Contrastive: 0.1374\n",
      "Epoch 50, Loss: 1.1059, LPL: 1.3863, Contrastive: 0.1280\n",
      "Epoch 100, Loss: 1.1076, LPL: 1.3863, Contrastive: 0.1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:17:28,831] Trial 7 finished with value: 0.7179046049737889 and parameters: {'alpha': 0.2798721414675672, 'K': 35, 'layers': 3, 'hidden_channels': 128, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.11434331893297506, 'margin': 0.2944731714250123, 'lpl_weight': 0.7771278701081328, 'ratio': 0.3084095063121354, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 2 with value: 0.8786677931826496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8269, F1=0.7193, Recall=0.9686, Precision=0.5721\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202031501.csv.\n",
      "Average F1 over 5 seeds: 0.7179  0.0038\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.9201321466843501, K=33, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3661164141398804, margin=0.11924432051521215, lpl_weight=0.4316583629303069\n",
      " - ratio=0.3618843754683655, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2931\n",
      " - Metrics: Accuracy=0.9074, F1=0.8264, Recall=0.9634, Precision=0.7236\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.9201321466843501, K=33, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3661164141398804, margin=0.11924432051521215, lpl_weight=0.4316583629303069\n",
      " - ratio=0.3618843754683655, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2931\n",
      " - Metrics: Accuracy=0.9078, F1=0.8268, Recall=0.9612, Precision=0.7254\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.9201321466843501, K=33, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3661164141398804, margin=0.11924432051521215, lpl_weight=0.4316583629303069\n",
      " - ratio=0.3618843754683655, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2931\n",
      " - Metrics: Accuracy=0.9115, F1=0.8331, Recall=0.9653, Precision=0.7328\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.9201321466843501, K=33, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3661164141398804, margin=0.11924432051521215, lpl_weight=0.4316583629303069\n",
      " - ratio=0.3618843754683655, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2931\n",
      " - Metrics: Accuracy=0.9107, F1=0.8320, Recall=0.9660, Precision=0.7307\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.9201321466843501, K=33, layers=1, hidden=64, out=64\n",
      " - norm=layernorm, dropout=0.3661164141398804, margin=0.11924432051521215, lpl_weight=0.4316583629303069\n",
      " - ratio=0.3618843754683655, pos_weight=1, aggregation=mean, treatment=removal\n",
      "Epoch 0, Loss: 0.7650, LPL: 1.3863, Contrastive: 0.2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:18:45,006] Trial 8 finished with value: 0.8301352422366571 and parameters: {'alpha': 0.9201321466843501, 'K': 33, 'layers': 1, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'layernorm', 'dropout': 0.3661164141398804, 'margin': 0.11924432051521215, 'lpl_weight': 0.4316583629303069, 'ratio': 0.3618843754683655, 'aggregation': 'mean', 'treatment': 'removal'}. Best is trial 2 with value: 0.8786677931826496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9113, F1=0.8323, Recall=0.9616, Precision=0.7337\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202031728.csv.\n",
      "Average F1 over 5 seeds: 0.8301  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4891944095418663, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.3246947968546697, margin=0.19586502961020133, lpl_weight=0.9136627811437449\n",
      " - ratio=0.1288401407938026, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2877, LPL: 1.3863, Contrastive: 0.2447\n",
      " - Metrics: Accuracy=0.9520, F1=0.8950, Recall=0.8944, Precision=0.8957\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4891944095418663, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.3246947968546697, margin=0.19586502961020133, lpl_weight=0.9136627811437449\n",
      " - ratio=0.1288401407938026, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2877, LPL: 1.3863, Contrastive: 0.2447\n",
      " - Metrics: Accuracy=0.9523, F1=0.8958, Recall=0.8951, Precision=0.8964\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4891944095418663, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.3246947968546697, margin=0.19586502961020133, lpl_weight=0.9136627811437449\n",
      " - ratio=0.1288401407938026, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2877, LPL: 1.3863, Contrastive: 0.2447\n",
      " - Metrics: Accuracy=0.9533, F1=0.8980, Recall=0.8973, Precision=0.8987\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4891944095418663, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.3246947968546697, margin=0.19586502961020133, lpl_weight=0.9136627811437449\n",
      " - ratio=0.1288401407938026, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2877, LPL: 1.3863, Contrastive: 0.2447\n",
      " - Metrics: Accuracy=0.9533, F1=0.8980, Recall=0.8973, Precision=0.8987\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4891944095418663, K=34, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.3246947968546697, margin=0.19586502961020133, lpl_weight=0.9136627811437449\n",
      " - ratio=0.1288401407938026, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2877, LPL: 1.3863, Contrastive: 0.2447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:20:11,804] Trial 9 finished with value: 0.8965259618976467 and parameters: {'alpha': 0.4891944095418663, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.3246947968546697, 'margin': 0.19586502961020133, 'lpl_weight': 0.9136627811437449, 'ratio': 0.1288401407938026, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9523, F1=0.8958, Recall=0.8951, Precision=0.8964\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202031845.csv.\n",
      "Average F1 over 5 seeds: 0.8965  0.0013\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4749332279428061, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.47708393499044843, margin=0.39971110691572365, lpl_weight=0.6416569415111978\n",
      " - ratio=0.10672010377924665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9862, LPL: 1.3863, Contrastive: 0.2698\n",
      " - Metrics: Accuracy=0.9502, F1=0.8862, Recall=0.8477, Precision=0.9285\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4749332279428061, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.47708393499044843, margin=0.39971110691572365, lpl_weight=0.6416569415111978\n",
      " - ratio=0.10672010377924665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9862, LPL: 1.3863, Contrastive: 0.2698\n",
      " - Metrics: Accuracy=0.9490, F1=0.8835, Recall=0.8451, Precision=0.9256\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4749332279428061, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.47708393499044843, margin=0.39971110691572365, lpl_weight=0.6416569415111978\n",
      " - ratio=0.10672010377924665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9862, LPL: 1.3863, Contrastive: 0.2698\n",
      " - Metrics: Accuracy=0.9529, F1=0.8925, Recall=0.8537, Precision=0.9350\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4749332279428061, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.47708393499044843, margin=0.39971110691572365, lpl_weight=0.6416569415111978\n",
      " - ratio=0.10672010377924665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9862, LPL: 1.3863, Contrastive: 0.2698\n",
      " - Metrics: Accuracy=0.9503, F1=0.8866, Recall=0.8481, Precision=0.9289\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4749332279428061, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.47708393499044843, margin=0.39971110691572365, lpl_weight=0.6416569415111978\n",
      " - ratio=0.10672010377924665, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9862, LPL: 1.3863, Contrastive: 0.2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:21:57,655] Trial 10 finished with value: 0.8871024390243903 and parameters: {'alpha': 0.4749332279428061, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.47708393499044843, 'margin': 0.39971110691572365, 'lpl_weight': 0.6416569415111978, 'ratio': 0.10672010377924665, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9503, F1=0.8866, Recall=0.8481, Precision=0.9289\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202032011.csv.\n",
      "Average F1 over 5 seeds: 0.8871  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.44416278445733537, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.493816126596233, margin=0.3980906196143004, lpl_weight=0.6906170916751744\n",
      " - ratio=0.1083792762455136, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0424, LPL: 1.3863, Contrastive: 0.2749\n",
      " - Metrics: Accuracy=0.9508, F1=0.8880, Recall=0.8522, Precision=0.9269\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.44416278445733537, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.493816126596233, margin=0.3980906196143004, lpl_weight=0.6906170916751744\n",
      " - ratio=0.1083792762455136, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0424, LPL: 1.3863, Contrastive: 0.2749\n",
      " - Metrics: Accuracy=0.9497, F1=0.8856, Recall=0.8499, Precision=0.9245\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.44416278445733537, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.493816126596233, margin=0.3980906196143004, lpl_weight=0.6906170916751744\n",
      " - ratio=0.1083792762455136, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0424, LPL: 1.3863, Contrastive: 0.2749\n",
      " - Metrics: Accuracy=0.9532, F1=0.8934, Recall=0.8574, Precision=0.9326\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.44416278445733537, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.493816126596233, margin=0.3980906196143004, lpl_weight=0.6906170916751744\n",
      " - ratio=0.1083792762455136, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0424, LPL: 1.3863, Contrastive: 0.2749\n",
      " - Metrics: Accuracy=0.9506, F1=0.8876, Recall=0.8518, Precision=0.9265\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.44416278445733537, K=30, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.493816126596233, margin=0.3980906196143004, lpl_weight=0.6906170916751744\n",
      " - ratio=0.1083792762455136, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0424, LPL: 1.3863, Contrastive: 0.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:23:43,174] Trial 11 finished with value: 0.888681446907818 and parameters: {'alpha': 0.44416278445733537, 'K': 30, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.493816126596233, 'margin': 0.3980906196143004, 'lpl_weight': 0.6906170916751744, 'ratio': 0.1083792762455136, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9511, F1=0.8888, Recall=0.8529, Precision=0.9277\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202032157.csv.\n",
      "Average F1 over 5 seeds: 0.8887  0.0026\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.49021727733575937, K=29, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48644365686795743, margin=0.41108515930729234, lpl_weight=0.6592954824922149\n",
      " - ratio=0.1007313533236868, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0068, LPL: 1.3863, Contrastive: 0.2725\n",
      " - Metrics: Accuracy=0.9481, F1=0.8801, Recall=0.8317, Precision=0.9346\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.49021727733575937, K=29, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48644365686795743, margin=0.41108515930729234, lpl_weight=0.6592954824922149\n",
      " - ratio=0.1007313533236868, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0068, LPL: 1.3863, Contrastive: 0.2725\n",
      " - Metrics: Accuracy=0.9471, F1=0.8777, Recall=0.8294, Precision=0.9320\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.49021727733575937, K=29, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48644365686795743, margin=0.41108515930729234, lpl_weight=0.6592954824922149\n",
      " - ratio=0.1007313533236868, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0068, LPL: 1.3863, Contrastive: 0.2725\n",
      " - Metrics: Accuracy=0.9515, F1=0.8880, Recall=0.8391, Precision=0.9430\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.49021727733575937, K=29, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48644365686795743, margin=0.41108515930729234, lpl_weight=0.6592954824922149\n",
      " - ratio=0.1007313533236868, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0068, LPL: 1.3863, Contrastive: 0.2725\n",
      " - Metrics: Accuracy=0.9485, F1=0.8809, Recall=0.8324, Precision=0.9354\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.49021727733575937, K=29, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48644365686795743, margin=0.41108515930729234, lpl_weight=0.6592954824922149\n",
      " - ratio=0.1007313533236868, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0068, LPL: 1.3863, Contrastive: 0.2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:25:28,493] Trial 12 finished with value: 0.8814536835868061 and parameters: {'alpha': 0.49021727733575937, 'K': 29, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.48644365686795743, 'margin': 0.41108515930729234, 'lpl_weight': 0.6592954824922149, 'ratio': 0.1007313533236868, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9483, F1=0.8805, Recall=0.8320, Precision=0.9350\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202032343.csv.\n",
      "Average F1 over 5 seeds: 0.8815  0.0035\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.38845056865179234, K=25, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.40085873886823825, margin=0.10273615730029428, lpl_weight=0.3240822670333826\n",
      " - ratio=0.17166742105611707, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6349, LPL: 1.3863, Contrastive: 0.2746\n",
      " - Metrics: Accuracy=0.9361, F1=0.8710, Recall=0.9425, Precision=0.8096\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.38845056865179234, K=25, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.40085873886823825, margin=0.10273615730029428, lpl_weight=0.3240822670333826\n",
      " - ratio=0.17166742105611707, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6349, LPL: 1.3863, Contrastive: 0.2746\n",
      " - Metrics: Accuracy=0.9357, F1=0.8703, Recall=0.9418, Precision=0.8089\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.38845056865179234, K=25, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.40085873886823825, margin=0.10273615730029428, lpl_weight=0.3240822670333826\n",
      " - ratio=0.17166742105611707, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6349, LPL: 1.3863, Contrastive: 0.2746\n",
      " - Metrics: Accuracy=0.9378, F1=0.8744, Recall=0.9462, Precision=0.8128\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.38845056865179234, K=25, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.40085873886823825, margin=0.10273615730029428, lpl_weight=0.3240822670333826\n",
      " - ratio=0.17166742105611707, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6349, LPL: 1.3863, Contrastive: 0.2746\n",
      " - Metrics: Accuracy=0.9349, F1=0.8686, Recall=0.9399, Precision=0.8073\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.38845056865179234, K=25, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.40085873886823825, margin=0.10273615730029428, lpl_weight=0.3240822670333826\n",
      " - ratio=0.17166742105611707, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6349, LPL: 1.3863, Contrastive: 0.2746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:27:10,607] Trial 13 finished with value: 0.8714729216971369 and parameters: {'alpha': 0.38845056865179234, 'K': 25, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.40085873886823825, 'margin': 0.10273615730029428, 'lpl_weight': 0.3240822670333826, 'ratio': 0.17166742105611707, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9371, F1=0.8731, Recall=0.9448, Precision=0.8115\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202032528.csv.\n",
      "Average F1 over 5 seeds: 0.8715  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5873305042061799, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.32213697759643584, margin=0.4284510898354512, lpl_weight=0.6506356446622595\n",
      " - ratio=0.1727408888444639, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.2264\n",
      " - Metrics: Accuracy=0.9319, F1=0.8628, Recall=0.9354, Precision=0.8006\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5873305042061799, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.32213697759643584, margin=0.4284510898354512, lpl_weight=0.6506356446622595\n",
      " - ratio=0.1727408888444639, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.2264\n",
      " - Metrics: Accuracy=0.9290, F1=0.8569, Recall=0.9291, Precision=0.7952\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5873305042061799, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.32213697759643584, margin=0.4284510898354512, lpl_weight=0.6506356446622595\n",
      " - ratio=0.1727408888444639, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.2264\n",
      " - Metrics: Accuracy=0.9319, F1=0.8628, Recall=0.9354, Precision=0.8006\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5873305042061799, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.32213697759643584, margin=0.4284510898354512, lpl_weight=0.6506356446622595\n",
      " - ratio=0.1727408888444639, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.2264\n",
      " - Metrics: Accuracy=0.9314, F1=0.8618, Recall=0.9343, Precision=0.7997\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5873305042061799, K=31, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.32213697759643584, margin=0.4284510898354512, lpl_weight=0.6506356446622595\n",
      " - ratio=0.1727408888444639, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9811, LPL: 1.3863, Contrastive: 0.2264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:28:28,899] Trial 14 finished with value: 0.8609399208125323 and parameters: {'alpha': 0.5873305042061799, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.32213697759643584, 'margin': 0.4284510898354512, 'lpl_weight': 0.6506356446622595, 'ratio': 0.1727408888444639, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9307, F1=0.8604, Recall=0.9328, Precision=0.7984\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202032710.csv.\n",
      "Average F1 over 5 seeds: 0.8609  0.0022\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.42535373194458426, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4303722193233806, margin=0.262579712421941, lpl_weight=0.8879243230742375\n",
      " - ratio=0.1516309482182124, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2602, LPL: 1.3863, Contrastive: 0.2610\n",
      " - Metrics: Accuracy=0.9465, F1=0.8880, Recall=0.9265, Precision=0.8526\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.42535373194458426, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4303722193233806, margin=0.262579712421941, lpl_weight=0.8879243230742375\n",
      " - ratio=0.1516309482182124, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2602, LPL: 1.3863, Contrastive: 0.2610\n",
      " - Metrics: Accuracy=0.9439, F1=0.8826, Recall=0.9209, Precision=0.8475\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.42535373194458426, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4303722193233806, margin=0.262579712421941, lpl_weight=0.8879243230742375\n",
      " - ratio=0.1516309482182124, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2602, LPL: 1.3863, Contrastive: 0.2610\n",
      " - Metrics: Accuracy=0.9465, F1=0.8880, Recall=0.9265, Precision=0.8526\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.42535373194458426, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4303722193233806, margin=0.262579712421941, lpl_weight=0.8879243230742375\n",
      " - ratio=0.1516309482182124, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2602, LPL: 1.3863, Contrastive: 0.2610\n",
      " - Metrics: Accuracy=0.9456, F1=0.8862, Recall=0.9246, Precision=0.8509\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.42535373194458426, K=33, layers=1, hidden=128, out=256\n",
      " - norm=None, dropout=0.4303722193233806, margin=0.262579712421941, lpl_weight=0.8879243230742375\n",
      " - ratio=0.1516309482182124, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.2602, LPL: 1.3863, Contrastive: 0.2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:30:13,234] Trial 15 finished with value: 0.8865116279069767 and parameters: {'alpha': 0.42535373194458426, 'K': 33, 'layers': 1, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.4303722193233806, 'margin': 0.262579712421941, 'lpl_weight': 0.8879243230742375, 'ratio': 0.1516309482182124, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9463, F1=0.8877, Recall=0.9261, Precision=0.8523\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202032828.csv.\n",
      "Average F1 over 5 seeds: 0.8865  0.0020\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5601729592521851, K=27, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18449493995672228, margin=0.47680774959257394, lpl_weight=0.1046266535364595\n",
      " - ratio=0.23132249182182651, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3204, LPL: 1.3863, Contrastive: 0.1958\n",
      " - Metrics: Accuracy=0.8920, F1=0.8030, Recall=0.9616, Precision=0.6893\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5601729592521851, K=27, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18449493995672228, margin=0.47680774959257394, lpl_weight=0.1046266535364595\n",
      " - ratio=0.23132249182182651, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3204, LPL: 1.3863, Contrastive: 0.1958\n",
      " - Metrics: Accuracy=0.8886, F1=0.7968, Recall=0.9541, Precision=0.6840\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5601729592521851, K=27, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18449493995672228, margin=0.47680774959257394, lpl_weight=0.1046266535364595\n",
      " - ratio=0.23132249182182651, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3204, LPL: 1.3863, Contrastive: 0.1958\n",
      " - Metrics: Accuracy=0.8911, F1=0.8014, Recall=0.9597, Precision=0.6880\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5601729592521851, K=27, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18449493995672228, margin=0.47680774959257394, lpl_weight=0.1046266535364595\n",
      " - ratio=0.23132249182182651, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3204, LPL: 1.3863, Contrastive: 0.1958\n",
      " - Metrics: Accuracy=0.8903, F1=0.7999, Recall=0.9578, Precision=0.6866\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5601729592521851, K=27, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.18449493995672228, margin=0.47680774959257394, lpl_weight=0.1046266535364595\n",
      " - ratio=0.23132249182182651, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.3204, LPL: 1.3863, Contrastive: 0.1958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:31:29,382] Trial 16 finished with value: 0.8007481296758104 and parameters: {'alpha': 0.5601729592521851, 'K': 27, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.18449493995672228, 'margin': 0.47680774959257394, 'lpl_weight': 0.1046266535364595, 'ratio': 0.23132249182182651, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8918, F1=0.8027, Recall=0.9612, Precision=0.6891\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202033013.csv.\n",
      "Average F1 over 5 seeds: 0.8007  0.0023\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3028785443357372, K=30, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.45035791867601255, margin=0.30791603174531207, lpl_weight=0.6908393682285237\n",
      " - ratio=0.14355504918434525, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0389, LPL: 1.3863, Contrastive: 0.2626\n",
      " - Metrics: Accuracy=0.9432, F1=0.8792, Recall=0.9037, Precision=0.8561\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3028785443357372, K=30, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.45035791867601255, margin=0.30791603174531207, lpl_weight=0.6908393682285237\n",
      " - ratio=0.14355504918434525, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0389, LPL: 1.3863, Contrastive: 0.2626\n",
      " - Metrics: Accuracy=0.9432, F1=0.8792, Recall=0.9037, Precision=0.8561\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3028785443357372, K=30, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.45035791867601255, margin=0.30791603174531207, lpl_weight=0.6908393682285237\n",
      " - ratio=0.14355504918434525, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0389, LPL: 1.3863, Contrastive: 0.2626\n",
      " - Metrics: Accuracy=0.9457, F1=0.8847, Recall=0.9093, Precision=0.8614\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3028785443357372, K=30, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.45035791867601255, margin=0.30791603174531207, lpl_weight=0.6908393682285237\n",
      " - ratio=0.14355504918434525, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0389, LPL: 1.3863, Contrastive: 0.2626\n",
      " - Metrics: Accuracy=0.9440, F1=0.8811, Recall=0.9056, Precision=0.8579\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3028785443357372, K=30, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.45035791867601255, margin=0.30791603174531207, lpl_weight=0.6908393682285237\n",
      " - ratio=0.14355504918434525, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.0389, LPL: 1.3863, Contrastive: 0.2626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:32:46,587] Trial 17 finished with value: 0.8804067550390412 and parameters: {'alpha': 0.3028785443357372, 'K': 30, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.45035791867601255, 'margin': 0.30791603174531207, 'lpl_weight': 0.6908393682285237, 'ratio': 0.14355504918434525, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9425, F1=0.8778, Recall=0.9022, Precision=0.8547\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202033129.csv.\n",
      "Average F1 over 5 seeds: 0.8804  0.0024\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.6713338047602755, K=34, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.3608835663518776, margin=0.20174439176799544, lpl_weight=0.759487687942064\n",
      " - ratio=0.26463021046964674, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8260, F1=0.6988, Recall=0.8817, Precision=0.5788\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.6713338047602755, K=34, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.3608835663518776, margin=0.20174439176799544, lpl_weight=0.759487687942064\n",
      " - ratio=0.26463021046964674, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8269, F1=0.7004, Recall=0.8835, Precision=0.5801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=3:\n",
      " - alpha=0.6713338047602755, K=34, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.3608835663518776, margin=0.20174439176799544, lpl_weight=0.759487687942064\n",
      " - ratio=0.26463021046964674, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8251, F1=0.6972, Recall=0.8791, Precision=0.5776\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.6713338047602755, K=34, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.3608835663518776, margin=0.20174439176799544, lpl_weight=0.759487687942064\n",
      " - ratio=0.26463021046964674, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.8226, F1=0.6929, Recall=0.8742, Precision=0.5739\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.6713338047602755, K=34, layers=3, hidden=64, out=256\n",
      " - norm=None, dropout=0.3608835663518776, margin=0.20174439176799544, lpl_weight=0.759487687942064\n",
      " - ratio=0.26463021046964674, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:37:13,480] Trial 18 finished with value: 0.6955858099488126 and parameters: {'alpha': 0.6713338047602755, 'K': 34, 'layers': 3, 'hidden_channels': 64, 'out_channels': 256, 'norm': None, 'dropout': 0.3608835663518776, 'margin': 0.20174439176799544, 'lpl_weight': 0.759487687942064, 'ratio': 0.26463021046964674, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8201, F1=0.6887, Recall=0.8690, Precision=0.5703\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202033246.csv.\n",
      "Average F1 over 5 seeds: 0.6956  0.0043\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.505058520807655, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19828281817996302, margin=0.9300948546764582, lpl_weight=0.9813113301081402\n",
      " - ratio=0.13832438908213518, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3645, LPL: 1.3863, Contrastive: 0.2212\n",
      " - Metrics: Accuracy=0.9403, F1=0.8718, Recall=0.8873, Precision=0.8569\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.505058520807655, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19828281817996302, margin=0.9300948546764582, lpl_weight=0.9813113301081402\n",
      " - ratio=0.13832438908213518, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3645, LPL: 1.3863, Contrastive: 0.2212\n",
      " - Metrics: Accuracy=0.9397, F1=0.8707, Recall=0.8862, Precision=0.8558\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.505058520807655, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19828281817996302, margin=0.9300948546764582, lpl_weight=0.9813113301081402\n",
      " - ratio=0.13832438908213518, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3645, LPL: 1.3863, Contrastive: 0.2212\n",
      " - Metrics: Accuracy=0.9423, F1=0.8762, Recall=0.8918, Precision=0.8612\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.505058520807655, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19828281817996302, margin=0.9300948546764582, lpl_weight=0.9813113301081402\n",
      " - ratio=0.13832438908213518, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3645, LPL: 1.3863, Contrastive: 0.2212\n",
      " - Metrics: Accuracy=0.9391, F1=0.8692, Recall=0.8847, Precision=0.8544\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.505058520807655, K=31, layers=2, hidden=256, out=256\n",
      " - norm=graphnorm, dropout=0.19828281817996302, margin=0.9300948546764582, lpl_weight=0.9813113301081402\n",
      " - ratio=0.13832438908213518, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 1.3645, LPL: 1.3863, Contrastive: 0.2212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:39:08,523] Trial 19 finished with value: 0.8728406381808179 and parameters: {'alpha': 0.505058520807655, 'K': 31, 'layers': 2, 'hidden_channels': 256, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.19828281817996302, 'margin': 0.9300948546764582, 'lpl_weight': 0.9813113301081402, 'ratio': 0.13832438908213518, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9423, F1=0.8762, Recall=0.8918, Precision=0.8612\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202033713.csv.\n",
      "Average F1 over 5 seeds: 0.8728  0.0029\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.10175443273478207, K=29, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.10613932156047395, margin=0.5031775624694288, lpl_weight=0.5763015787659878\n",
      " - ratio=0.19588872533146073, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8756, LPL: 1.3863, Contrastive: 0.1810\n",
      " - Metrics: Accuracy=0.9180, F1=0.8415, Recall=0.9500, Precision=0.7552\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.10175443273478207, K=29, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.10613932156047395, margin=0.5031775624694288, lpl_weight=0.5763015787659878\n",
      " - ratio=0.19588872533146073, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8756, LPL: 1.3863, Contrastive: 0.1810\n",
      " - Metrics: Accuracy=0.9156, F1=0.8368, Recall=0.9448, Precision=0.7510\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.10175443273478207, K=29, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.10613932156047395, margin=0.5031775624694288, lpl_weight=0.5763015787659878\n",
      " - ratio=0.19588872533146073, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8756, LPL: 1.3863, Contrastive: 0.1810\n",
      " - Metrics: Accuracy=0.9170, F1=0.8395, Recall=0.9477, Precision=0.7534\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.10175443273478207, K=29, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.10613932156047395, margin=0.5031775624694288, lpl_weight=0.5763015787659878\n",
      " - ratio=0.19588872533146073, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8756, LPL: 1.3863, Contrastive: 0.1810\n",
      " - Metrics: Accuracy=0.9177, F1=0.8408, Recall=0.9492, Precision=0.7546\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.10175443273478207, K=29, layers=2, hidden=128, out=64\n",
      " - norm=None, dropout=0.10613932156047395, margin=0.5031775624694288, lpl_weight=0.5763015787659878\n",
      " - ratio=0.19588872533146073, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8756, LPL: 1.3863, Contrastive: 0.1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:40:24,672] Trial 20 finished with value: 0.8400066126632503 and parameters: {'alpha': 0.10175443273478207, 'K': 29, 'layers': 2, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.10613932156047395, 'margin': 0.5031775624694288, 'lpl_weight': 0.5763015787659878, 'ratio': 0.19588872533146073, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9180, F1=0.8415, Recall=0.9500, Precision=0.7552\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202033908.csv.\n",
      "Average F1 over 5 seeds: 0.8400  0.0017\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.44398507196438874, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48271074770376887, margin=0.3701134601087326, lpl_weight=0.600948401387977\n",
      " - ratio=0.11128856080992346, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9415, LPL: 1.3863, Contrastive: 0.2717\n",
      " - Metrics: Accuracy=0.9516, F1=0.8906, Recall=0.8596, Precision=0.9238\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.44398507196438874, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48271074770376887, margin=0.3701134601087326, lpl_weight=0.600948401387977\n",
      " - ratio=0.11128856080992346, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9415, LPL: 1.3863, Contrastive: 0.2717\n",
      " - Metrics: Accuracy=0.9511, F1=0.8894, Recall=0.8585, Precision=0.9226\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.44398507196438874, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48271074770376887, margin=0.3701134601087326, lpl_weight=0.600948401387977\n",
      " - ratio=0.11128856080992346, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9415, LPL: 1.3863, Contrastive: 0.2717\n",
      " - Metrics: Accuracy=0.9521, F1=0.8917, Recall=0.8608, Precision=0.9250\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.44398507196438874, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48271074770376887, margin=0.3701134601087326, lpl_weight=0.600948401387977\n",
      " - ratio=0.11128856080992346, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9415, LPL: 1.3863, Contrastive: 0.2717\n",
      " - Metrics: Accuracy=0.9518, F1=0.8910, Recall=0.8600, Precision=0.9242\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.44398507196438874, K=31, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.48271074770376887, margin=0.3701134601087326, lpl_weight=0.600948401387977\n",
      " - ratio=0.11128856080992346, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9415, LPL: 1.3863, Contrastive: 0.2717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:42:10,240] Trial 21 finished with value: 0.8909512761020881 and parameters: {'alpha': 0.44398507196438874, 'K': 31, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.48271074770376887, 'margin': 0.3701134601087326, 'lpl_weight': 0.600948401387977, 'ratio': 0.11128856080992346, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9523, F1=0.8921, Recall=0.8611, Precision=0.9254\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202034024.csv.\n",
      "Average F1 over 5 seeds: 0.8910  0.0009\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.4188437878308243, K=32, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.49758237302726527, margin=0.34456997648869025, lpl_weight=0.38330509934921014\n",
      " - ratio=0.1057237189013455, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7018, LPL: 1.3863, Contrastive: 0.2764\n",
      " - Metrics: Accuracy=0.9500, F1=0.8856, Recall=0.8455, Precision=0.9298\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.4188437878308243, K=32, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.49758237302726527, margin=0.34456997648869025, lpl_weight=0.38330509934921014\n",
      " - ratio=0.1057237189013455, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7018, LPL: 1.3863, Contrastive: 0.2764\n",
      " - Metrics: Accuracy=0.9503, F1=0.8864, Recall=0.8462, Precision=0.9306\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.4188437878308243, K=32, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.49758237302726527, margin=0.34456997648869025, lpl_weight=0.38330509934921014\n",
      " - ratio=0.1057237189013455, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7018, LPL: 1.3863, Contrastive: 0.2764\n",
      " - Metrics: Accuracy=0.9533, F1=0.8931, Recall=0.8526, Precision=0.9376\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.4188437878308243, K=32, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.49758237302726527, margin=0.34456997648869025, lpl_weight=0.38330509934921014\n",
      " - ratio=0.1057237189013455, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7018, LPL: 1.3863, Contrastive: 0.2764\n",
      " - Metrics: Accuracy=0.9493, F1=0.8841, Recall=0.8440, Precision=0.9282\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.4188437878308243, K=32, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.49758237302726527, margin=0.34456997648869025, lpl_weight=0.38330509934921014\n",
      " - ratio=0.1057237189013455, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.7018, LPL: 1.3863, Contrastive: 0.2764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:43:56,968] Trial 22 finished with value: 0.8870381231671554 and parameters: {'alpha': 0.4188437878308243, 'K': 32, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.49758237302726527, 'margin': 0.34456997648869025, 'lpl_weight': 0.38330509934921014, 'ratio': 0.1057237189013455, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9502, F1=0.8860, Recall=0.8458, Precision=0.9302\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202034210.csv.\n",
      "Average F1 over 5 seeds: 0.8870  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3106111669462044, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.4566487403112796, margin=0.1899335852411718, lpl_weight=0.5702518859088721\n",
      " - ratio=0.1362224856472562, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9079, LPL: 1.3863, Contrastive: 0.2730\n",
      " - Metrics: Accuracy=0.9503, F1=0.8930, Recall=0.9052, Precision=0.8812\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.3106111669462044, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.4566487403112796, margin=0.1899335852411718, lpl_weight=0.5702518859088721\n",
      " - ratio=0.1362224856472562, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9079, LPL: 1.3863, Contrastive: 0.2730\n",
      " - Metrics: Accuracy=0.9507, F1=0.8938, Recall=0.9059, Precision=0.8819\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.3106111669462044, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.4566487403112796, margin=0.1899335852411718, lpl_weight=0.5702518859088721\n",
      " - ratio=0.1362224856472562, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9079, LPL: 1.3863, Contrastive: 0.2730\n",
      " - Metrics: Accuracy=0.9531, F1=0.8989, Recall=0.9112, Precision=0.8870\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.3106111669462044, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.4566487403112796, margin=0.1899335852411718, lpl_weight=0.5702518859088721\n",
      " - ratio=0.1362224856472562, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9079, LPL: 1.3863, Contrastive: 0.2730\n",
      " - Metrics: Accuracy=0.9517, F1=0.8960, Recall=0.9082, Precision=0.8841\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.3106111669462044, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.4566487403112796, margin=0.1899335852411718, lpl_weight=0.5702518859088721\n",
      " - ratio=0.1362224856472562, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9079, LPL: 1.3863, Contrastive: 0.2730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:45:41,393] Trial 23 finished with value: 0.8955993371386486 and parameters: {'alpha': 0.3106111669462044, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.4566487403112796, 'margin': 0.1899335852411718, 'lpl_weight': 0.5702518859088721, 'ratio': 0.1362224856472562, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9519, F1=0.8963, Recall=0.9085, Precision=0.8844\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202034357.csv.\n",
      "Average F1 over 5 seeds: 0.8956  0.0021\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.2723884217467225, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.45293653051734906, margin=0.1860637157723942, lpl_weight=0.559742756630731\n",
      " - ratio=0.25678538332674405, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8959, LPL: 1.3863, Contrastive: 0.2725\n",
      " - Metrics: Accuracy=0.8740, F1=0.7793, Recall=0.9716, Precision=0.6506\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.2723884217467225, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.45293653051734906, margin=0.1860637157723942, lpl_weight=0.559742756630731\n",
      " - ratio=0.25678538332674405, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8959, LPL: 1.3863, Contrastive: 0.2725\n",
      " - Metrics: Accuracy=0.8742, F1=0.7796, Recall=0.9720, Precision=0.6508\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.2723884217467225, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.45293653051734906, margin=0.1860637157723942, lpl_weight=0.559742756630731\n",
      " - ratio=0.25678538332674405, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8959, LPL: 1.3863, Contrastive: 0.2725\n",
      " - Metrics: Accuracy=0.8740, F1=0.7793, Recall=0.9716, Precision=0.6506\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.2723884217467225, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.45293653051734906, margin=0.1860637157723942, lpl_weight=0.559742756630731\n",
      " - ratio=0.25678538332674405, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8959, LPL: 1.3863, Contrastive: 0.2725\n",
      " - Metrics: Accuracy=0.8733, F1=0.7781, Recall=0.9701, Precision=0.6496\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.2723884217467225, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.45293653051734906, margin=0.1860637157723942, lpl_weight=0.559742756630731\n",
      " - ratio=0.25678538332674405, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8959, LPL: 1.3863, Contrastive: 0.2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:47:26,032] Trial 24 finished with value: 0.7794610778443113 and parameters: {'alpha': 0.2723884217467225, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.45293653051734906, 'margin': 0.1860637157723942, 'lpl_weight': 0.559742756630731, 'ratio': 0.25678538332674405, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.8749, F1=0.7808, Recall=0.9735, Precision=0.6518\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202034541.csv.\n",
      "Average F1 over 5 seeds: 0.7795  0.0009\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.35459778040099116, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.3965752651543097, margin=0.16163626739972783, lpl_weight=0.30785279222386513\n",
      " - ratio=0.1869922321560975, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6092, LPL: 1.3863, Contrastive: 0.2635\n",
      " - Metrics: Accuracy=0.9273, F1=0.8571, Recall=0.9530, Precision=0.7788\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.35459778040099116, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.3965752651543097, margin=0.16163626739972783, lpl_weight=0.30785279222386513\n",
      " - ratio=0.1869922321560975, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6092, LPL: 1.3863, Contrastive: 0.2635\n",
      " - Metrics: Accuracy=0.9254, F1=0.8534, Recall=0.9489, Precision=0.7755\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.35459778040099116, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.3965752651543097, margin=0.16163626739972783, lpl_weight=0.30785279222386513\n",
      " - ratio=0.1869922321560975, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6092, LPL: 1.3863, Contrastive: 0.2635\n",
      " - Metrics: Accuracy=0.9285, F1=0.8595, Recall=0.9556, Precision=0.7810\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.35459778040099116, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.3965752651543097, margin=0.16163626739972783, lpl_weight=0.30785279222386513\n",
      " - ratio=0.1869922321560975, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6092, LPL: 1.3863, Contrastive: 0.2635\n",
      " - Metrics: Accuracy=0.9271, F1=0.8568, Recall=0.9526, Precision=0.7785\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.35459778040099116, K=34, layers=2, hidden=128, out=256\n",
      " - norm=None, dropout=0.3965752651543097, margin=0.16163626739972783, lpl_weight=0.30785279222386513\n",
      " - ratio=0.1869922321560975, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.6092, LPL: 1.3863, Contrastive: 0.2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:49:09,859] Trial 25 finished with value: 0.8570757092496223 and parameters: {'alpha': 0.35459778040099116, 'K': 34, 'layers': 2, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.3965752651543097, 'margin': 0.16163626739972783, 'lpl_weight': 0.30785279222386513, 'ratio': 0.1869922321560975, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9280, F1=0.8585, Recall=0.9545, Precision=0.7800\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202034726.csv.\n",
      "Average F1 over 5 seeds: 0.8571  0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=1:\n",
      " - alpha=0.20826229810944635, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3422123336466514, margin=0.3321389179888582, lpl_weight=0.8571574132092182\n",
      " - ratio=0.13848229181180158, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9292, F1=0.8482, Recall=0.8645, Precision=0.8325\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.20826229810944635, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3422123336466514, margin=0.3321389179888582, lpl_weight=0.8571574132092182\n",
      " - ratio=0.13848229181180158, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9280, F1=0.8456, Recall=0.8619, Precision=0.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed=3:\n",
      " - alpha=0.20826229810944635, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3422123336466514, margin=0.3321389179888582, lpl_weight=0.8571574132092182\n",
      " - ratio=0.13848229181180158, pos_weight=1, aggregation=sum, treatment=relabeling\n",
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9281, F1=0.8459, Recall=0.8615, Precision=0.8308\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.20826229810944635, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3422123336466514, margin=0.3321389179888582, lpl_weight=0.8571574132092182\n",
      " - ratio=0.13848229181180158, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      " - Metrics: Accuracy=0.9288, F1=0.8474, Recall=0.8630, Precision=0.8323\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.20826229810944635, K=35, layers=1, hidden=128, out=64\n",
      " - norm=None, dropout=0.3422123336466514, margin=0.3321389179888582, lpl_weight=0.8571574132092182\n",
      " - ratio=0.13848229181180158, pos_weight=1, aggregation=sum, treatment=relabeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector error: ValueError('Input contains NaN.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:53:08,623] Trial 26 finished with value: 0.8459733144424962 and parameters: {'alpha': 0.20826229810944635, 'K': 35, 'layers': 1, 'hidden_channels': 128, 'out_channels': 64, 'norm': None, 'dropout': 0.3422123336466514, 'margin': 0.3321389179888582, 'lpl_weight': 0.8571574132092182, 'ratio': 0.13848229181180158, 'aggregation': 'sum', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9267, F1=0.8428, Recall=0.8585, Precision=0.8276\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202034909.csv.\n",
      "Average F1 over 5 seeds: 0.8460  0.0018\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5939423913275778, K=32, layers=3, hidden=128, out=256\n",
      " - norm=None, dropout=0.28164706996065314, margin=0.23799005091964257, lpl_weight=0.60101683177752\n",
      " - ratio=0.15842543456082916, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9065, LPL: 1.3863, Contrastive: 0.1837\n",
      "Epoch 50, Loss: 0.8923, LPL: 1.3863, Contrastive: 0.1482\n",
      " - Metrics: Accuracy=0.9411, F1=0.8783, Recall=0.9280, Precision=0.8337\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5939423913275778, K=32, layers=3, hidden=128, out=256\n",
      " - norm=None, dropout=0.28164706996065314, margin=0.23799005091964257, lpl_weight=0.60101683177752\n",
      " - ratio=0.15842543456082916, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9065, LPL: 1.3863, Contrastive: 0.1837\n",
      "Epoch 50, Loss: 0.8923, LPL: 1.3863, Contrastive: 0.1482\n",
      " - Metrics: Accuracy=0.9421, F1=0.8804, Recall=0.9302, Precision=0.8357\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5939423913275778, K=32, layers=3, hidden=128, out=256\n",
      " - norm=None, dropout=0.28164706996065314, margin=0.23799005091964257, lpl_weight=0.60101683177752\n",
      " - ratio=0.15842543456082916, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9065, LPL: 1.3863, Contrastive: 0.1837\n",
      "Epoch 50, Loss: 0.8923, LPL: 1.3863, Contrastive: 0.1482\n",
      " - Metrics: Accuracy=0.9447, F1=0.8857, Recall=0.9358, Precision=0.8407\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5939423913275778, K=32, layers=3, hidden=128, out=256\n",
      " - norm=None, dropout=0.28164706996065314, margin=0.23799005091964257, lpl_weight=0.60101683177752\n",
      " - ratio=0.15842543456082916, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9065, LPL: 1.3863, Contrastive: 0.1837\n",
      "Epoch 50, Loss: 0.8923, LPL: 1.3863, Contrastive: 0.1482\n",
      " - Metrics: Accuracy=0.9427, F1=0.8815, Recall=0.9313, Precision=0.8367\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5939423913275778, K=32, layers=3, hidden=128, out=256\n",
      " - norm=None, dropout=0.28164706996065314, margin=0.23799005091964257, lpl_weight=0.60101683177752\n",
      " - ratio=0.15842543456082916, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.9065, LPL: 1.3863, Contrastive: 0.1837\n",
      "Epoch 50, Loss: 0.8923, LPL: 1.3863, Contrastive: 0.1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:55:40,522] Trial 27 finished with value: 0.8824589295177532 and parameters: {'alpha': 0.5939423913275778, 'K': 32, 'layers': 3, 'hidden_channels': 128, 'out_channels': 256, 'norm': None, 'dropout': 0.28164706996065314, 'margin': 0.23799005091964257, 'lpl_weight': 0.60101683177752, 'ratio': 0.15842543456082916, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9450, F1=0.8864, Recall=0.9365, Precision=0.8414\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202035308.csv.\n",
      "Average F1 over 5 seeds: 0.8825  0.0031\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.5186537938015142, K=34, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.45413115096218115, margin=0.14513996325002754, lpl_weight=0.4768964848328673\n",
      " - ratio=0.13048294540682323, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8083, LPL: 1.3863, Contrastive: 0.2814\n",
      " - Metrics: Accuracy=0.9507, F1=0.8926, Recall=0.8947, Precision=0.8904\n",
      "Running experiment with seed=2:\n",
      " - alpha=0.5186537938015142, K=34, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.45413115096218115, margin=0.14513996325002754, lpl_weight=0.4768964848328673\n",
      " - ratio=0.13048294540682323, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8083, LPL: 1.3863, Contrastive: 0.2814\n",
      " - Metrics: Accuracy=0.9505, F1=0.8922, Recall=0.8944, Precision=0.8900\n",
      "Running experiment with seed=3:\n",
      " - alpha=0.5186537938015142, K=34, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.45413115096218115, margin=0.14513996325002754, lpl_weight=0.4768964848328673\n",
      " - ratio=0.13048294540682323, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8083, LPL: 1.3863, Contrastive: 0.2814\n",
      " - Metrics: Accuracy=0.9522, F1=0.8959, Recall=0.8981, Precision=0.8938\n",
      "Running experiment with seed=4:\n",
      " - alpha=0.5186537938015142, K=34, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.45413115096218115, margin=0.14513996325002754, lpl_weight=0.4768964848328673\n",
      " - ratio=0.13048294540682323, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8083, LPL: 1.3863, Contrastive: 0.2814\n",
      " - Metrics: Accuracy=0.9500, F1=0.8911, Recall=0.8932, Precision=0.8889\n",
      "Running experiment with seed=5:\n",
      " - alpha=0.5186537938015142, K=34, layers=2, hidden=64, out=256\n",
      " - norm=graphnorm, dropout=0.45413115096218115, margin=0.14513996325002754, lpl_weight=0.4768964848328673\n",
      " - ratio=0.13048294540682323, pos_weight=1, aggregation=mean, treatment=relabeling\n",
      "Epoch 0, Loss: 0.8083, LPL: 1.3863, Contrastive: 0.2814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 03:57:24,656] Trial 28 finished with value: 0.8930925339787749 and parameters: {'alpha': 0.5186537938015142, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 256, 'norm': 'graphnorm', 'dropout': 0.45413115096218115, 'margin': 0.14513996325002754, 'lpl_weight': 0.4768964848328673, 'ratio': 0.13048294540682323, 'aggregation': 'mean', 'treatment': 'relabeling'}. Best is trial 9 with value: 0.8965259618976467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Metrics: Accuracy=0.9512, F1=0.8937, Recall=0.8959, Precision=0.8915\n",
      "Done. Results written to wiki-cs_experimentations\\wikics_sar_2202035540.csv.\n",
      "Average F1 over 5 seeds: 0.8931  0.0016\n",
      "Running experiment with seed=1:\n",
      " - alpha=0.3288732664619557, K=34, layers=2, hidden=64, out=64\n",
      " - norm=graphnorm, dropout=0.40592581280698875, margin=0.16108055330874504, lpl_weight=0.4642332714768575\n",
      " - ratio=0.24161947437424713, pos_weight=1, aggregation=sum, treatment=removal\n",
      "Epoch 0, Loss: 0.7837, LPL: 1.3863, Contrastive: 0.2615\n",
      "Epoch 50, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 100, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 150, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 200, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 250, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 300, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 350, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 400, Loss: nan, LPL: 1.3863, Contrastive: nan\n",
      "Epoch 450, Loss: nan, LPL: 1.3863, Contrastive: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Anomaly detector WeightedIsoForest error: ValueError('Input contains NaN.')\n",
      "[W 2025-02-22 03:58:03,577] Trial 29 failed with parameters: {'alpha': 0.3288732664619557, 'K': 34, 'layers': 2, 'hidden_channels': 64, 'out_channels': 64, 'norm': 'graphnorm', 'dropout': 0.40592581280698875, 'margin': 0.16108055330874504, 'lpl_weight': 0.4642332714768575, 'ratio': 0.24161947437424713, 'aggregation': 'sum', 'treatment': 'removal'} because of the following error: NotFittedError('need to call fit or load_model beforehand').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\romai\\AppData\\Local\\Temp\\ipykernel_220368\\2657924698.py\", line 34, in objective\n",
      "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\NNIF-GNN\\train_NNIF_GNN.py\", line 570, in run_nnif_gnn_experiment\n",
      "    predicted = pnn_model.predict(features_np)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\NNIF-GNN\\NNIF.py\", line 657, in predict\n",
      "    return self.base_classifier_.predict(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1633, in predict\n",
      "    class_probs = super().predict(\n",
      "                  ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1248, in predict\n",
      "    predts = self.get_booster().inplace_predict(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 853, in get_booster\n",
      "    raise NotFittedError(\"need to call fit or load_model beforehand\")\n",
      "sklearn.exceptions.NotFittedError: need to call fit or load_model beforehand\n",
      "[W 2025-02-22 03:58:03,577] Trial 29 failed with value None.\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Create an Optuna study to maximize the F1 score.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Print out the best hyperparameters and corresponding F1 score.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[12], line 34\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     11\u001b[0m params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwiki-cs\u001b[39m\u001b[38;5;124m\"\u001b[39m,      \n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmechanism\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikics_sar.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m }\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Call the experiment function with these parameters.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# run_nnif_gnn_experiment returns (avg_f1, std_f1)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m avg_f1, std_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_nnif_gnn_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# We aim to maximize F1 score.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_f1\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\NNIF-GNN\\train_NNIF_GNN.py:570\u001b[0m, in \u001b[0;36mrun_nnif_gnn_experiment\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# Fit PNN on the labeled/unlabeled data\u001b[39;00m\n\u001b[0;32m    569\u001b[0m pnn_model\u001b[38;5;241m.\u001b[39mfit(features_np, y_labels)\n\u001b[1;32m--> 570\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mpnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m predicted_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(predicted)\u001b[38;5;241m.\u001b[39mto(embeddings\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# Determine reliable neg/pos\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\NNIF-GNN\\NNIF.py:657\u001b[0m, in \u001b[0;36mPNN.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_classifier_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPNN is not fitted. Call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_classifier_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\xgboost\\sklearn.py:1633\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1625\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1626\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1632\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1633\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1640\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1641\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\xgboost\\sklearn.py:1248\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1248\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1249\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1250\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1251\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1252\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1253\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1254\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1255\u001b[0m         )\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1257\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\romai\\Desktop\\gnn\\gnn_pu\\.conda\\Lib\\site-packages\\xgboost\\sklearn.py:853\u001b[0m, in \u001b[0;36mXGBModel.get_booster\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[1;32m--> 853\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to call fit or load_model beforehand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\n",
      "\u001b[1;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "from train_NNIF_GNN import run_nnif_gnn_experiment\n",
    "import optuna\n",
    "from typing import Dict, Any\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "    It builds a parameter dictionary, calls the experiment function, and\n",
    "    returns the average F1 score.\n",
    "    \"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"dataset_name\": \"wiki-cs\",      \n",
    "        \"mechanism\": \"SAR\",\n",
    "        \"train_pct\": 0.5,\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        \"K\": trial.suggest_int(\"K\", 25, 35),\n",
    "        \"layers\": trial.suggest_int(\"layers\", 1, 3),\n",
    "        \"hidden_channels\": trial.suggest_categorical(\"hidden_channels\", [64, 128, 256]),\n",
    "        \"out_channels\": trial.suggest_categorical(\"out_channels\", [64, 128, 256]),\n",
    "        \"norm\": trial.suggest_categorical(\"norm\", [None, \"layernorm\", \"graphnorm\"]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        \"margin\": trial.suggest_float(\"margin\", 0.1, 1.0),\n",
    "        \"lpl_weight\": trial.suggest_float(\"lpl_weight\", 0.1, 1.0),\n",
    "        \"ratio\": trial.suggest_float(\"ratio\", 0.1, 0.5),\n",
    "        \"pos_weight\": 1,#trial.suggest_float(\"pos_weight\", 0.5, 2.0),\n",
    "        \"aggregation\": trial.suggest_categorical(\"aggregation\", [\"sum\", \"mean\"]),\n",
    "        \"treatment\": trial.suggest_categorical(\"treatment\", [\"removal\", \"relabeling\"]),\n",
    "        \"seeds\": 5,\n",
    "        \"output_csv\": \"wikics_sar.csv\"\n",
    "    }\n",
    "    \n",
    "    # Call the experiment function with these parameters.\n",
    "    # run_nnif_gnn_experiment returns (avg_f1, std_f1)\n",
    "    avg_f1, std_f1 = run_nnif_gnn_experiment(params)\n",
    "    \n",
    "    # We aim to maximize F1 score.\n",
    "    return avg_f1\n",
    "\n",
    "# Create an Optuna study to maximize the F1 score.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print out the best hyperparameters and corresponding F1 score.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Average F1:\", trial.value)\n",
    "print(\"  Best parameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
